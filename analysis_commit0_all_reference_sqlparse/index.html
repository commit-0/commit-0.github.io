
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.37">
    
    
      
        <title>Analysis commit0 all reference sqlparse - Commit-0</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.8c3ca2c6.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#reference-gold-sqlparse" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Commit-0" class="md-header__button md-logo" aria-label="Commit-0" data-md-component="logo">
      
  <img src="../logo2.webp" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Commit-0
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Analysis commit0 all reference sqlparse
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Commit-0" class="md-nav__button md-logo" aria-label="Commit-0" data-md-component="logo">
      
  <img src="../logo2.webp" alt="logo">

    </a>
    Commit-0
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../setupdist/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Commit0
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Agent
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Leaderboard
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pytest-summary-for-test-tests" class="md-nav__link">
    <span class="md-ellipsis">
      Pytest Summary for test tests
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#failed-pytests" class="md-nav__link">
    <span class="md-ellipsis">
      Failed pytests:
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Failed pytests:">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#test_formatpytestoutputformattest_python_multiple_statements_with_formatting" class="md-nav__link">
    <span class="md-ellipsis">
      test_format.py::TestOutputFormat::test_python_multiple_statements_with_formatting
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_formatpytest_format_right_margin" class="md-nav__link">
    <span class="md-ellipsis">
      test_format.py::test_format_right_margin
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_regressionspytest_issue484_comments_and_newlines" class="md-nav__link">
    <span class="md-ellipsis">
      test_regressions.py::test_issue484_comments_and_newlines
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#patch-diff" class="md-nav__link">
    <span class="md-ellipsis">
      Patch diff
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<p><a href="/analysis_commit0_all_reference">back to Reference (Gold) summary</a></p>
<h1 id="reference-gold-sqlparse"><strong>Reference (Gold)</strong>: sqlparse</h1>
<h2 id="pytest-summary-for-test-tests">Pytest Summary for test <code>tests</code></h2>
<table>
<thead>
<tr>
<th style="text-align: left;">status</th>
<th style="text-align: center;">count</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">passed</td>
<td style="text-align: center;">460</td>
</tr>
<tr>
<td style="text-align: left;">xfailed</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: left;">xpassed</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: left;">total</td>
<td style="text-align: center;">463</td>
</tr>
<tr>
<td style="text-align: left;">collected</td>
<td style="text-align: center;">463</td>
</tr>
</tbody>
</table>
<h2 id="failed-pytests">Failed pytests:</h2>
<h3 id="test_formatpytestoutputformattest_python_multiple_statements_with_formatting">test_format.py::TestOutputFormat::test_python_multiple_statements_with_formatting</h3>
<details><summary> <pre>test_format.py::TestOutputFormat::test_python_multiple_statements_with_formatting</pre></summary><pre>
self = <tests.test_format.TestOutputFormat object at 0x7f82370db250>

    @pytest.mark.xfail(reason="Needs fixing")
    def test_python_multiple_statements_with_formatting(self):
        sql = 'select * from foo; select 1 from dual'
        f = lambda sql: sqlparse.format(sql, output_format='python',
                                        reindent=True)
>       assert f(sql) == '\n'.join([
            "sql = ('select * '",
            "       'from foo;')",
            "sql2 = ('select 1 '",
            "        'from dual')"])
E       assert "sql = ('sele... 'from dual')" == "sql = ('sele... 'from dual')"
E         
E         Skipping 38 identical leading characters in diff, use -v to show
E           
E         - sql2 = ('select 1 '
E         ?          --------
E         + sql2 = (' '
E         +         '
E         + select 1 '
E                   'from dual')

tests/test_format.py:644: AssertionError
</pre>
</details>
<h3 id="test_formatpytest_format_right_margin">test_format.py::test_format_right_margin</h3>
<details><summary> <pre>test_format.py::test_format_right_margin</pre></summary><pre>
@pytest.mark.xfail(reason="Needs fixing")
    def test_format_right_margin():
        # TODO: Needs better test, only raises exception right now
>       sqlparse.format('foo', right_margin="79")

tests/test_format.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
sqlparse/__init__.py:59: in format
    return ''.join(stack.run(sql, encoding))
sqlparse/engine/filter_stack.py:42: in run
    filter_.process(stmt)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlparse.filters.right_margin.RightMarginFilter object at 0x7f82363531f0>
group = <Statement 'foo' at 0x7F82360761C0>

    def process(self, group):
        # return
        # group.tokens = self._process(group, group.tokens)
>       raise NotImplementedError
E       NotImplementedError

sqlparse/filters/right_margin.py:48: NotImplementedError
</pre>
</details>
<h3 id="test_regressionspytest_issue484_comments_and_newlines">test_regressions.py::test_issue484_comments_and_newlines</h3>
<details><summary> <pre>test_regressions.py::test_issue484_comments_and_newlines</pre></summary><pre>

</pre>
</details>

<h2 id="patch-diff">Patch diff</h2>
<div class="highlight"><pre><span></span><code><span class="gh">diff --git a/sqlparse/cli.py b/sqlparse/cli.py</span>
<span class="gh">index 51e62e6..4e7e0d7 100755</span>
<span class="gd">--- a/sqlparse/cli.py</span>
<span class="gi">+++ b/sqlparse/cli.py</span>
<span class="gu">@@ -1,3 +1,11 @@</span>
<span class="gi">+#!/usr/bin/env python</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+</span>
<span class="w"> </span>&quot;&quot;&quot;Module that contains the command line app.

<span class="w"> </span>Why does this file exist, and why not put this in __main__?
<span class="gu">@@ -10,13 +18,186 @@ Why does this file exist, and why not put this in __main__?</span>
<span class="w"> </span>    there&#39;s no ``sqlparse.__main__`` in ``sys.modules``.
<span class="w"> </span>  Also see (1) from http://click.pocoo.org/5/setuptools/#setuptools-integration
<span class="w"> </span>&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>import argparse
<span class="w"> </span>import sys
<span class="w"> </span>from io import TextIOWrapper
<span class="gi">+</span>
<span class="w"> </span>import sqlparse
<span class="w"> </span>from sqlparse.exceptions import SQLParseError


<span class="gi">+# TODO: Add CLI Tests</span>
<span class="gi">+# TODO: Simplify formatter by using argparse `type` arguments</span>
<span class="gi">+def create_parser():</span>
<span class="gi">+    _CASE_CHOICES = [&#39;upper&#39;, &#39;lower&#39;, &#39;capitalize&#39;]</span>
<span class="gi">+</span>
<span class="gi">+    parser = argparse.ArgumentParser(</span>
<span class="gi">+        prog=&#39;sqlformat&#39;,</span>
<span class="gi">+        description=&#39;Format FILE according to OPTIONS. Use &quot;-&quot; as FILE &#39;</span>
<span class="gi">+                    &#39;to read from stdin.&#39;,</span>
<span class="gi">+        usage=&#39;%(prog)s  [OPTIONS] FILE, ...&#39;,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    parser.add_argument(&#39;filename&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    parser.add_argument(</span>
<span class="gi">+        &#39;-o&#39;, &#39;--outfile&#39;,</span>
<span class="gi">+        dest=&#39;outfile&#39;,</span>
<span class="gi">+        metavar=&#39;FILE&#39;,</span>
<span class="gi">+        help=&#39;write output to FILE (defaults to stdout)&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    parser.add_argument(</span>
<span class="gi">+        &#39;--version&#39;,</span>
<span class="gi">+        action=&#39;version&#39;,</span>
<span class="gi">+        version=sqlparse.__version__)</span>
<span class="gi">+</span>
<span class="gi">+    group = parser.add_argument_group(&#39;Formatting Options&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    group.add_argument(</span>
<span class="gi">+        &#39;-k&#39;, &#39;--keywords&#39;,</span>
<span class="gi">+        metavar=&#39;CHOICE&#39;,</span>
<span class="gi">+        dest=&#39;keyword_case&#39;,</span>
<span class="gi">+        choices=_CASE_CHOICES,</span>
<span class="gi">+        help=&#39;change case of keywords, CHOICE is one of {}&#39;.format(</span>
<span class="gi">+            &#39;, &#39;.join(&#39;&quot;{}&quot;&#39;.format(x) for x in _CASE_CHOICES)))</span>
<span class="gi">+</span>
<span class="gi">+    group.add_argument(</span>
<span class="gi">+        &#39;-i&#39;, &#39;--identifiers&#39;,</span>
<span class="gi">+        metavar=&#39;CHOICE&#39;,</span>
<span class="gi">+        dest=&#39;identifier_case&#39;,</span>
<span class="gi">+        choices=_CASE_CHOICES,</span>
<span class="gi">+        help=&#39;change case of identifiers, CHOICE is one of {}&#39;.format(</span>
<span class="gi">+            &#39;, &#39;.join(&#39;&quot;{}&quot;&#39;.format(x) for x in _CASE_CHOICES)))</span>
<span class="gi">+</span>
<span class="gi">+    group.add_argument(</span>
<span class="gi">+        &#39;-l&#39;, &#39;--language&#39;,</span>
<span class="gi">+        metavar=&#39;LANG&#39;,</span>
<span class="gi">+        dest=&#39;output_format&#39;,</span>
<span class="gi">+        choices=[&#39;python&#39;, &#39;php&#39;],</span>
<span class="gi">+        help=&#39;output a snippet in programming language LANG, &#39;</span>
<span class="gi">+             &#39;choices are &quot;python&quot;, &quot;php&quot;&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    group.add_argument(</span>
<span class="gi">+        &#39;--strip-comments&#39;,</span>
<span class="gi">+        dest=&#39;strip_comments&#39;,</span>
<span class="gi">+        action=&#39;store_true&#39;,</span>
<span class="gi">+        default=False,</span>
<span class="gi">+        help=&#39;remove comments&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    group.add_argument(</span>
<span class="gi">+        &#39;-r&#39;, &#39;--reindent&#39;,</span>
<span class="gi">+        dest=&#39;reindent&#39;,</span>
<span class="gi">+        action=&#39;store_true&#39;,</span>
<span class="gi">+        default=False,</span>
<span class="gi">+        help=&#39;reindent statements&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    group.add_argument(</span>
<span class="gi">+        &#39;--indent_width&#39;,</span>
<span class="gi">+        dest=&#39;indent_width&#39;,</span>
<span class="gi">+        default=2,</span>
<span class="gi">+        type=int,</span>
<span class="gi">+        help=&#39;indentation width (defaults to 2 spaces)&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    group.add_argument(</span>
<span class="gi">+        &#39;--indent_after_first&#39;,</span>
<span class="gi">+        dest=&#39;indent_after_first&#39;,</span>
<span class="gi">+        action=&#39;store_true&#39;,</span>
<span class="gi">+        default=False,</span>
<span class="gi">+        help=&#39;indent after first line of statement (e.g. SELECT)&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    group.add_argument(</span>
<span class="gi">+        &#39;--indent_columns&#39;,</span>
<span class="gi">+        dest=&#39;indent_columns&#39;,</span>
<span class="gi">+        action=&#39;store_true&#39;,</span>
<span class="gi">+        default=False,</span>
<span class="gi">+        help=&#39;indent all columns by indent_width instead of keyword length&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    group.add_argument(</span>
<span class="gi">+        &#39;-a&#39;, &#39;--reindent_aligned&#39;,</span>
<span class="gi">+        action=&#39;store_true&#39;,</span>
<span class="gi">+        default=False,</span>
<span class="gi">+        help=&#39;reindent statements to aligned format&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    group.add_argument(</span>
<span class="gi">+        &#39;-s&#39;, &#39;--use_space_around_operators&#39;,</span>
<span class="gi">+        action=&#39;store_true&#39;,</span>
<span class="gi">+        default=False,</span>
<span class="gi">+        help=&#39;place spaces around mathematical operators&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    group.add_argument(</span>
<span class="gi">+        &#39;--wrap_after&#39;,</span>
<span class="gi">+        dest=&#39;wrap_after&#39;,</span>
<span class="gi">+        default=0,</span>
<span class="gi">+        type=int,</span>
<span class="gi">+        help=&#39;Column after which lists should be wrapped&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    group.add_argument(</span>
<span class="gi">+        &#39;--comma_first&#39;,</span>
<span class="gi">+        dest=&#39;comma_first&#39;,</span>
<span class="gi">+        default=False,</span>
<span class="gi">+        type=bool,</span>
<span class="gi">+        help=&#39;Insert linebreak before comma (default False)&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    group.add_argument(</span>
<span class="gi">+        &#39;--compact&#39;,</span>
<span class="gi">+        dest=&#39;compact&#39;,</span>
<span class="gi">+        default=False,</span>
<span class="gi">+        type=bool,</span>
<span class="gi">+        help=&#39;Try to produce more compact output (default False)&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    group.add_argument(</span>
<span class="gi">+        &#39;--encoding&#39;,</span>
<span class="gi">+        dest=&#39;encoding&#39;,</span>
<span class="gi">+        default=&#39;utf-8&#39;,</span>
<span class="gi">+        help=&#39;Specify the input encoding (default utf-8)&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    return parser</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>def _error(msg):
<span class="w"> </span>    &quot;&quot;&quot;Print msg and optionally exit with return code exit_.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    sys.stderr.write(&#39;[ERROR] {}\n&#39;.format(msg))</span>
<span class="gi">+    return 1</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def main(args=None):</span>
<span class="gi">+    parser = create_parser()</span>
<span class="gi">+    args = parser.parse_args(args)</span>
<span class="gi">+</span>
<span class="gi">+    if args.filename == &#39;-&#39;:  # read from stdin</span>
<span class="gi">+        wrapper = TextIOWrapper(sys.stdin.buffer, encoding=args.encoding)</span>
<span class="gi">+        try:</span>
<span class="gi">+            data = wrapper.read()</span>
<span class="gi">+        finally:</span>
<span class="gi">+            wrapper.detach()</span>
<span class="gi">+    else:</span>
<span class="gi">+        try:</span>
<span class="gi">+            with open(args.filename, encoding=args.encoding) as f:</span>
<span class="gi">+                data = &#39;&#39;.join(f.readlines())</span>
<span class="gi">+        except OSError as e:</span>
<span class="gi">+            return _error(</span>
<span class="gi">+                &#39;Failed to read {}: {}&#39;.format(args.filename, e))</span>
<span class="gi">+</span>
<span class="gi">+    close_stream = False</span>
<span class="gi">+    if args.outfile:</span>
<span class="gi">+        try:</span>
<span class="gi">+            stream = open(args.outfile, &#39;w&#39;, encoding=args.encoding)</span>
<span class="gi">+            close_stream = True</span>
<span class="gi">+        except OSError as e:</span>
<span class="gi">+            return _error(&#39;Failed to open {}: {}&#39;.format(args.outfile, e))</span>
<span class="gi">+    else:</span>
<span class="gi">+        stream = sys.stdout</span>
<span class="gi">+</span>
<span class="gi">+    formatter_opts = vars(args)</span>
<span class="gi">+    try:</span>
<span class="gi">+        formatter_opts = sqlparse.formatter.validate_options(formatter_opts)</span>
<span class="gi">+    except SQLParseError as e:</span>
<span class="gi">+        return _error(&#39;Invalid options: {}&#39;.format(e))</span>
<span class="gi">+</span>
<span class="gi">+    s = sqlparse.format(data, **formatter_opts)</span>
<span class="gi">+    stream.write(s)</span>
<span class="gi">+    stream.flush()</span>
<span class="gi">+    if close_stream:</span>
<span class="gi">+        stream.close()</span>
<span class="gi">+    return 0</span>
<span class="gh">diff --git a/sqlparse/engine/filter_stack.py b/sqlparse/engine/filter_stack.py</span>
<span class="gh">index c622b24..3feba37 100644</span>
<span class="gd">--- a/sqlparse/engine/filter_stack.py</span>
<span class="gi">+++ b/sqlparse/engine/filter_stack.py</span>
<span class="gu">@@ -1,4 +1,12 @@</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+</span>
<span class="w"> </span>&quot;&quot;&quot;filter&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>from sqlparse import lexer
<span class="w"> </span>from sqlparse.engine import grouping
<span class="w"> </span>from sqlparse.engine.statement_splitter import StatementSplitter
<span class="gu">@@ -6,7 +14,6 @@ from sqlparse.filters import StripTrailingSemicolonFilter</span>


<span class="w"> </span>class FilterStack:
<span class="gd">-</span>
<span class="w"> </span>    def __init__(self, strip_semicolon=False):
<span class="w"> </span>        self.preprocess = []
<span class="w"> </span>        self.stmtprocess = []
<span class="gu">@@ -14,3 +21,27 @@ class FilterStack:</span>
<span class="w"> </span>        self._grouping = False
<span class="w"> </span>        if strip_semicolon:
<span class="w"> </span>            self.stmtprocess.append(StripTrailingSemicolonFilter())
<span class="gi">+</span>
<span class="gi">+    def enable_grouping(self):</span>
<span class="gi">+        self._grouping = True</span>
<span class="gi">+</span>
<span class="gi">+    def run(self, sql, encoding=None):</span>
<span class="gi">+        stream = lexer.tokenize(sql, encoding)</span>
<span class="gi">+        # Process token stream</span>
<span class="gi">+        for filter_ in self.preprocess:</span>
<span class="gi">+            stream = filter_.process(stream)</span>
<span class="gi">+</span>
<span class="gi">+        stream = StatementSplitter().process(stream)</span>
<span class="gi">+</span>
<span class="gi">+        # Output: Stream processed Statements</span>
<span class="gi">+        for stmt in stream:</span>
<span class="gi">+            if self._grouping:</span>
<span class="gi">+                stmt = grouping.group(stmt)</span>
<span class="gi">+</span>
<span class="gi">+            for filter_ in self.stmtprocess:</span>
<span class="gi">+                filter_.process(stmt)</span>
<span class="gi">+</span>
<span class="gi">+            for filter_ in self.postprocess:</span>
<span class="gi">+                stmt = filter_.process(stmt)</span>
<span class="gi">+</span>
<span class="gi">+            yield stmt</span>
<span class="gh">diff --git a/sqlparse/engine/grouping.py b/sqlparse/engine/grouping.py</span>
<span class="gh">index a730974..a63f4da 100644</span>
<span class="gd">--- a/sqlparse/engine/grouping.py</span>
<span class="gi">+++ b/sqlparse/engine/grouping.py</span>
<span class="gu">@@ -1,23 +1,486 @@</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+</span>
<span class="w"> </span>from sqlparse import sql
<span class="w"> </span>from sqlparse import tokens as T
<span class="w"> </span>from sqlparse.utils import recurse, imt
<span class="gd">-T_NUMERICAL = T.Number, T.Number.Integer, T.Number.Float</span>
<span class="gd">-T_STRING = T.String, T.String.Single, T.String.Symbol</span>
<span class="gd">-T_NAME = T.Name, T.Name.Placeholder</span>
<span class="gi">+</span>
<span class="gi">+T_NUMERICAL = (T.Number, T.Number.Integer, T.Number.Float)</span>
<span class="gi">+T_STRING = (T.String, T.String.Single, T.String.Symbol)</span>
<span class="gi">+T_NAME = (T.Name, T.Name.Placeholder)</span>


<span class="w"> </span>def _group_matching(tlist, cls):
<span class="w"> </span>    &quot;&quot;&quot;Groups Tokens that have beginning and end.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    opens = []</span>
<span class="gi">+    tidx_offset = 0</span>
<span class="gi">+    for idx, token in enumerate(list(tlist)):</span>
<span class="gi">+        tidx = idx - tidx_offset</span>
<span class="gi">+</span>
<span class="gi">+        if token.is_whitespace:</span>
<span class="gi">+            # ~50% of tokens will be whitespace. Will checking early</span>
<span class="gi">+            # for them avoid 3 comparisons, but then add 1 more comparison</span>
<span class="gi">+            # for the other ~50% of tokens...</span>
<span class="gi">+            continue</span>
<span class="gi">+</span>
<span class="gi">+        if token.is_group and not isinstance(token, cls):</span>
<span class="gi">+            # Check inside previously grouped (i.e. parenthesis) if group</span>
<span class="gi">+            # of different type is inside (i.e., case). though ideally  should</span>
<span class="gi">+            # should check for all open/close tokens at once to avoid recursion</span>
<span class="gi">+            _group_matching(token, cls)</span>
<span class="gi">+            continue</span>
<span class="gi">+</span>
<span class="gi">+        if token.match(*cls.M_OPEN):</span>
<span class="gi">+            opens.append(tidx)</span>
<span class="gi">+</span>
<span class="gi">+        elif token.match(*cls.M_CLOSE):</span>
<span class="gi">+            try:</span>
<span class="gi">+                open_idx = opens.pop()</span>
<span class="gi">+            except IndexError:</span>
<span class="gi">+                # this indicates invalid sql and unbalanced tokens.</span>
<span class="gi">+                # instead of break, continue in case other &quot;valid&quot; groups exist</span>
<span class="gi">+                continue</span>
<span class="gi">+            close_idx = tidx</span>
<span class="gi">+            tlist.group_tokens(cls, open_idx, close_idx)</span>
<span class="gi">+            tidx_offset += close_idx - open_idx</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group_brackets(tlist):</span>
<span class="gi">+    _group_matching(tlist, sql.SquareBrackets)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group_parenthesis(tlist):</span>
<span class="gi">+    _group_matching(tlist, sql.Parenthesis)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group_case(tlist):</span>
<span class="gi">+    _group_matching(tlist, sql.Case)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group_if(tlist):</span>
<span class="gi">+    _group_matching(tlist, sql.If)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group_for(tlist):</span>
<span class="gi">+    _group_matching(tlist, sql.For)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group_begin(tlist):</span>
<span class="gi">+    _group_matching(tlist, sql.Begin)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group_typecasts(tlist):</span>
<span class="gi">+    def match(token):</span>
<span class="gi">+        return token.match(T.Punctuation, &#39;::&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    def valid(token):</span>
<span class="gi">+        return token is not None</span>
<span class="gi">+</span>
<span class="gi">+    def post(tlist, pidx, tidx, nidx):</span>
<span class="gi">+        return pidx, nidx</span>
<span class="gi">+</span>
<span class="gi">+    valid_prev = valid_next = valid</span>
<span class="gi">+    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group_tzcasts(tlist):</span>
<span class="gi">+    def match(token):</span>
<span class="gi">+        return token.ttype == T.Keyword.TZCast</span>
<span class="gi">+</span>
<span class="gi">+    def valid_prev(token):</span>
<span class="gi">+        return token is not None</span>
<span class="gi">+</span>
<span class="gi">+    def valid_next(token):</span>
<span class="gi">+        return token is not None and (</span>
<span class="gi">+            token.is_whitespace</span>
<span class="gi">+            or token.match(T.Keyword, &#39;AS&#39;)</span>
<span class="gi">+            or token.match(*sql.TypedLiteral.M_CLOSE)</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def post(tlist, pidx, tidx, nidx):</span>
<span class="gi">+        return pidx, nidx</span>
<span class="gi">+</span>
<span class="gi">+    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group_typed_literal(tlist):</span>
<span class="gi">+    # definitely not complete, see e.g.:</span>
<span class="gi">+    # https://docs.microsoft.com/en-us/sql/odbc/reference/appendixes/interval-literal-syntax</span>
<span class="gi">+    # https://docs.microsoft.com/en-us/sql/odbc/reference/appendixes/interval-literals</span>
<span class="gi">+    # https://www.postgresql.org/docs/9.1/datatype-datetime.html</span>
<span class="gi">+    # https://www.postgresql.org/docs/9.1/functions-datetime.html</span>
<span class="gi">+    def match(token):</span>
<span class="gi">+        return imt(token, m=sql.TypedLiteral.M_OPEN)</span>
<span class="gi">+</span>
<span class="gi">+    def match_to_extend(token):</span>
<span class="gi">+        return isinstance(token, sql.TypedLiteral)</span>
<span class="gi">+</span>
<span class="gi">+    def valid_prev(token):</span>
<span class="gi">+        return token is not None</span>
<span class="gi">+</span>
<span class="gi">+    def valid_next(token):</span>
<span class="gi">+        return token is not None and token.match(*sql.TypedLiteral.M_CLOSE)</span>
<span class="gi">+</span>
<span class="gi">+    def valid_final(token):</span>
<span class="gi">+        return token is not None and token.match(*sql.TypedLiteral.M_EXTEND)</span>
<span class="gi">+</span>
<span class="gi">+    def post(tlist, pidx, tidx, nidx):</span>
<span class="gi">+        return tidx, nidx</span>
<span class="gi">+</span>
<span class="gi">+    _group(tlist, sql.TypedLiteral, match, valid_prev, valid_next,</span>
<span class="gi">+           post, extend=False)</span>
<span class="gi">+    _group(tlist, sql.TypedLiteral, match_to_extend, valid_prev, valid_final,</span>
<span class="gi">+           post, extend=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group_period(tlist):</span>
<span class="gi">+    def match(token):</span>
<span class="gi">+        for ttype, value in ((T.Punctuation, &#39;.&#39;),</span>
<span class="gi">+                             (T.Operator, &#39;-&gt;&#39;),</span>
<span class="gi">+                             (T.Operator, &#39;-&gt;&gt;&#39;)):</span>
<span class="gi">+            if token.match(ttype, value):</span>
<span class="gi">+                return True</span>
<span class="gi">+        return False</span>
<span class="gi">+</span>
<span class="gi">+    def valid_prev(token):</span>
<span class="gi">+        sqlcls = sql.SquareBrackets, sql.Identifier</span>
<span class="gi">+        ttypes = T.Name, T.String.Symbol</span>
<span class="gi">+        return imt(token, i=sqlcls, t=ttypes)</span>
<span class="gi">+</span>
<span class="gi">+    def valid_next(token):</span>
<span class="gi">+        # issue261, allow invalid next token</span>
<span class="gi">+        return True</span>
<span class="gi">+</span>
<span class="gi">+    def post(tlist, pidx, tidx, nidx):</span>
<span class="gi">+        # next_ validation is being performed here. issue261</span>
<span class="gi">+        sqlcls = sql.SquareBrackets, sql.Function</span>
<span class="gi">+        ttypes = T.Name, T.String.Symbol, T.Wildcard, T.String.Single</span>
<span class="gi">+        next_ = tlist[nidx] if nidx is not None else None</span>
<span class="gi">+        valid_next = imt(next_, i=sqlcls, t=ttypes)</span>
<span class="gi">+</span>
<span class="gi">+        return (pidx, nidx) if valid_next else (pidx, tidx)</span>
<span class="gi">+</span>
<span class="gi">+    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group_as(tlist):</span>
<span class="gi">+    def match(token):</span>
<span class="gi">+        return token.is_keyword and token.normalized == &#39;AS&#39;</span>
<span class="gi">+</span>
<span class="gi">+    def valid_prev(token):</span>
<span class="gi">+        return token.normalized == &#39;NULL&#39; or not token.is_keyword</span>
<span class="gi">+</span>
<span class="gi">+    def valid_next(token):</span>
<span class="gi">+        ttypes = T.DML, T.DDL, T.CTE</span>
<span class="gi">+        return not imt(token, t=ttypes) and token is not None</span>
<span class="gi">+</span>
<span class="gi">+    def post(tlist, pidx, tidx, nidx):</span>
<span class="gi">+        return pidx, nidx</span>
<span class="gi">+</span>
<span class="gi">+    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group_assignment(tlist):</span>
<span class="gi">+    def match(token):</span>
<span class="gi">+        return token.match(T.Assignment, &#39;:=&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    def valid(token):</span>
<span class="gi">+        return token is not None and token.ttype not in (T.Keyword,)</span>
<span class="gi">+</span>
<span class="gi">+    def post(tlist, pidx, tidx, nidx):</span>
<span class="gi">+        m_semicolon = T.Punctuation, &#39;;&#39;</span>
<span class="gi">+        snidx, _ = tlist.token_next_by(m=m_semicolon, idx=nidx)</span>
<span class="gi">+        nidx = snidx or nidx</span>
<span class="gi">+        return pidx, nidx</span>
<span class="gi">+</span>
<span class="gi">+    valid_prev = valid_next = valid</span>
<span class="gi">+    _group(tlist, sql.Assignment, match, valid_prev, valid_next, post)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group_comparison(tlist):</span>
<span class="gi">+    sqlcls = (sql.Parenthesis, sql.Function, sql.Identifier,</span>
<span class="gi">+              sql.Operation, sql.TypedLiteral)</span>
<span class="gi">+    ttypes = T_NUMERICAL + T_STRING + T_NAME</span>
<span class="gi">+</span>
<span class="gi">+    def match(token):</span>
<span class="gi">+        return token.ttype == T.Operator.Comparison</span>
<span class="gi">+</span>
<span class="gi">+    def valid(token):</span>
<span class="gi">+        if imt(token, t=ttypes, i=sqlcls):</span>
<span class="gi">+            return True</span>
<span class="gi">+        elif token and token.is_keyword and token.normalized == &#39;NULL&#39;:</span>
<span class="gi">+            return True</span>
<span class="gi">+        else:</span>
<span class="gi">+            return False</span>
<span class="gi">+</span>
<span class="gi">+    def post(tlist, pidx, tidx, nidx):</span>
<span class="gi">+        return pidx, nidx</span>
<span class="gi">+</span>
<span class="gi">+    valid_prev = valid_next = valid</span>
<span class="gi">+    _group(tlist, sql.Comparison, match,</span>
<span class="gi">+           valid_prev, valid_next, post, extend=False)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@recurse(sql.Identifier)</span>
<span class="gi">+def group_identifier(tlist):</span>
<span class="gi">+    ttypes = (T.String.Symbol, T.Name)</span>
<span class="gi">+</span>
<span class="gi">+    tidx, token = tlist.token_next_by(t=ttypes)</span>
<span class="gi">+    while token:</span>
<span class="gi">+        tlist.group_tokens(sql.Identifier, tidx, tidx)</span>
<span class="gi">+        tidx, token = tlist.token_next_by(t=ttypes, idx=tidx)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@recurse(sql.Over)</span>
<span class="gi">+def group_over(tlist):</span>
<span class="gi">+    tidx, token = tlist.token_next_by(m=sql.Over.M_OPEN)</span>
<span class="gi">+    while token:</span>
<span class="gi">+        nidx, next_ = tlist.token_next(tidx)</span>
<span class="gi">+        if imt(next_, i=sql.Parenthesis, t=T.Name):</span>
<span class="gi">+            tlist.group_tokens(sql.Over, tidx, nidx)</span>
<span class="gi">+        tidx, token = tlist.token_next_by(m=sql.Over.M_OPEN, idx=tidx)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group_arrays(tlist):</span>
<span class="gi">+    sqlcls = sql.SquareBrackets, sql.Identifier, sql.Function</span>
<span class="gi">+    ttypes = T.Name, T.String.Symbol</span>
<span class="gi">+</span>
<span class="gi">+    def match(token):</span>
<span class="gi">+        return isinstance(token, sql.SquareBrackets)</span>
<span class="gi">+</span>
<span class="gi">+    def valid_prev(token):</span>
<span class="gi">+        return imt(token, i=sqlcls, t=ttypes)</span>
<span class="gi">+</span>
<span class="gi">+    def valid_next(token):</span>
<span class="gi">+        return True</span>
<span class="gi">+</span>
<span class="gi">+    def post(tlist, pidx, tidx, nidx):</span>
<span class="gi">+        return pidx, tidx</span>
<span class="gi">+</span>
<span class="gi">+    _group(tlist, sql.Identifier, match,</span>
<span class="gi">+           valid_prev, valid_next, post, extend=True, recurse=False)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group_operator(tlist):</span>
<span class="gi">+    ttypes = T_NUMERICAL + T_STRING + T_NAME</span>
<span class="gi">+    sqlcls = (sql.SquareBrackets, sql.Parenthesis, sql.Function,</span>
<span class="gi">+              sql.Identifier, sql.Operation, sql.TypedLiteral)</span>
<span class="gi">+</span>
<span class="gi">+    def match(token):</span>
<span class="gi">+        return imt(token, t=(T.Operator, T.Wildcard))</span>
<span class="gi">+</span>
<span class="gi">+    def valid(token):</span>
<span class="gi">+        return imt(token, i=sqlcls, t=ttypes) \</span>
<span class="gi">+            or (token and token.match(</span>
<span class="gi">+                T.Keyword,</span>
<span class="gi">+                (&#39;CURRENT_DATE&#39;, &#39;CURRENT_TIME&#39;, &#39;CURRENT_TIMESTAMP&#39;)))</span>
<span class="gi">+</span>
<span class="gi">+    def post(tlist, pidx, tidx, nidx):</span>
<span class="gi">+        tlist[tidx].ttype = T.Operator</span>
<span class="gi">+        return pidx, nidx</span>
<span class="gi">+</span>
<span class="gi">+    valid_prev = valid_next = valid</span>
<span class="gi">+    _group(tlist, sql.Operation, match,</span>
<span class="gi">+           valid_prev, valid_next, post, extend=False)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group_identifier_list(tlist):</span>
<span class="gi">+    m_role = T.Keyword, (&#39;null&#39;, &#39;role&#39;)</span>
<span class="gi">+    sqlcls = (sql.Function, sql.Case, sql.Identifier, sql.Comparison,</span>
<span class="gi">+              sql.IdentifierList, sql.Operation)</span>
<span class="gi">+    ttypes = (T_NUMERICAL + T_STRING + T_NAME</span>
<span class="gi">+              + (T.Keyword, T.Comment, T.Wildcard))</span>
<span class="gi">+</span>
<span class="gi">+    def match(token):</span>
<span class="gi">+        return token.match(T.Punctuation, &#39;,&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    def valid(token):</span>
<span class="gi">+        return imt(token, i=sqlcls, m=m_role, t=ttypes)</span>
<span class="gi">+</span>
<span class="gi">+    def post(tlist, pidx, tidx, nidx):</span>
<span class="gi">+        return pidx, nidx</span>
<span class="gi">+</span>
<span class="gi">+    valid_prev = valid_next = valid</span>
<span class="gi">+    _group(tlist, sql.IdentifierList, match,</span>
<span class="gi">+           valid_prev, valid_next, post, extend=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@recurse(sql.Comment)</span>
<span class="gi">+def group_comments(tlist):</span>
<span class="gi">+    tidx, token = tlist.token_next_by(t=T.Comment)</span>
<span class="gi">+    while token:</span>
<span class="gi">+        eidx, end = tlist.token_not_matching(</span>
<span class="gi">+            lambda tk: imt(tk, t=T.Comment) or tk.is_newline, idx=tidx)</span>
<span class="gi">+        if end is not None:</span>
<span class="gi">+            eidx, end = tlist.token_prev(eidx, skip_ws=False)</span>
<span class="gi">+            tlist.group_tokens(sql.Comment, tidx, eidx)</span>
<span class="gi">+</span>
<span class="gi">+        tidx, token = tlist.token_next_by(t=T.Comment, idx=tidx)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@recurse(sql.Where)</span>
<span class="gi">+def group_where(tlist):</span>
<span class="gi">+    tidx, token = tlist.token_next_by(m=sql.Where.M_OPEN)</span>
<span class="gi">+    while token:</span>
<span class="gi">+        eidx, end = tlist.token_next_by(m=sql.Where.M_CLOSE, idx=tidx)</span>
<span class="gi">+</span>
<span class="gi">+        if end is None:</span>
<span class="gi">+            end = tlist._groupable_tokens[-1]</span>
<span class="gi">+        else:</span>
<span class="gi">+            end = tlist.tokens[eidx - 1]</span>
<span class="gi">+        # TODO: convert this to eidx instead of end token.</span>
<span class="gi">+        # i think above values are len(tlist) and eidx-1</span>
<span class="gi">+        eidx = tlist.token_index(end)</span>
<span class="gi">+        tlist.group_tokens(sql.Where, tidx, eidx)</span>
<span class="gi">+        tidx, token = tlist.token_next_by(m=sql.Where.M_OPEN, idx=tidx)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@recurse()</span>
<span class="gi">+def group_aliased(tlist):</span>
<span class="gi">+    I_ALIAS = (sql.Parenthesis, sql.Function, sql.Case, sql.Identifier,</span>
<span class="gi">+               sql.Operation, sql.Comparison)</span>
<span class="gi">+</span>
<span class="gi">+    tidx, token = tlist.token_next_by(i=I_ALIAS, t=T.Number)</span>
<span class="gi">+    while token:</span>
<span class="gi">+        nidx, next_ = tlist.token_next(tidx)</span>
<span class="gi">+        if isinstance(next_, sql.Identifier):</span>
<span class="gi">+            tlist.group_tokens(sql.Identifier, tidx, nidx, extend=True)</span>
<span class="gi">+        tidx, token = tlist.token_next_by(i=I_ALIAS, t=T.Number, idx=tidx)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@recurse(sql.Function)</span>
<span class="gi">+def group_functions(tlist):</span>
<span class="gi">+    has_create = False</span>
<span class="gi">+    has_table = False</span>
<span class="gi">+    has_as = False</span>
<span class="gi">+    for tmp_token in tlist.tokens:</span>
<span class="gi">+        if tmp_token.value.upper() == &#39;CREATE&#39;:</span>
<span class="gi">+            has_create = True</span>
<span class="gi">+        if tmp_token.value.upper() == &#39;TABLE&#39;:</span>
<span class="gi">+            has_table = True</span>
<span class="gi">+        if tmp_token.value == &#39;AS&#39;:</span>
<span class="gi">+            has_as = True</span>
<span class="gi">+    if has_create and has_table and not has_as:</span>
<span class="gi">+        return</span>
<span class="gi">+</span>
<span class="gi">+    tidx, token = tlist.token_next_by(t=T.Name)</span>
<span class="gi">+    while token:</span>
<span class="gi">+        nidx, next_ = tlist.token_next(tidx)</span>
<span class="gi">+        if isinstance(next_, sql.Parenthesis):</span>
<span class="gi">+            over_idx, over = tlist.token_next(nidx)</span>
<span class="gi">+            if over and isinstance(over, sql.Over):</span>
<span class="gi">+                eidx = over_idx</span>
<span class="gi">+            else:</span>
<span class="gi">+                eidx = nidx</span>
<span class="gi">+            tlist.group_tokens(sql.Function, tidx, eidx)</span>
<span class="gi">+        tidx, token = tlist.token_next_by(t=T.Name, idx=tidx)</span>


<span class="w"> </span>@recurse(sql.Identifier)
<span class="w"> </span>def group_order(tlist):
<span class="w"> </span>    &quot;&quot;&quot;Group together Identifier and Asc/Desc token&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    tidx, token = tlist.token_next_by(t=T.Keyword.Order)</span>
<span class="gi">+    while token:</span>
<span class="gi">+        pidx, prev_ = tlist.token_prev(tidx)</span>
<span class="gi">+        if imt(prev_, i=sql.Identifier, t=T.Number):</span>
<span class="gi">+            tlist.group_tokens(sql.Identifier, pidx, tidx)</span>
<span class="gi">+            tidx = pidx</span>
<span class="gi">+        tidx, token = tlist.token_next_by(t=T.Keyword.Order, idx=tidx)</span>
<span class="gi">+</span>

<span class="gi">+@recurse()</span>
<span class="gi">+def align_comments(tlist):</span>
<span class="gi">+    tidx, token = tlist.token_next_by(i=sql.Comment)</span>
<span class="gi">+    while token:</span>
<span class="gi">+        pidx, prev_ = tlist.token_prev(tidx)</span>
<span class="gi">+        if isinstance(prev_, sql.TokenList):</span>
<span class="gi">+            tlist.group_tokens(sql.TokenList, pidx, tidx, extend=True)</span>
<span class="gi">+            tidx = pidx</span>
<span class="gi">+        tidx, token = tlist.token_next_by(i=sql.Comment, idx=tidx)</span>

<span class="gd">-def _group(tlist, cls, match, valid_prev=lambda t: True, valid_next=lambda</span>
<span class="gd">-    t: True, post=None, extend=True, recurse=True):</span>
<span class="gi">+</span>
<span class="gi">+def group_values(tlist):</span>
<span class="gi">+    tidx, token = tlist.token_next_by(m=(T.Keyword, &#39;VALUES&#39;))</span>
<span class="gi">+    start_idx = tidx</span>
<span class="gi">+    end_idx = -1</span>
<span class="gi">+    while token:</span>
<span class="gi">+        if isinstance(token, sql.Parenthesis):</span>
<span class="gi">+            end_idx = tidx</span>
<span class="gi">+        tidx, token = tlist.token_next(tidx)</span>
<span class="gi">+    if end_idx != -1:</span>
<span class="gi">+        tlist.group_tokens(sql.Values, start_idx, end_idx, extend=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def group(stmt):</span>
<span class="gi">+    for func in [</span>
<span class="gi">+        group_comments,</span>
<span class="gi">+</span>
<span class="gi">+        # _group_matching</span>
<span class="gi">+        group_brackets,</span>
<span class="gi">+        group_parenthesis,</span>
<span class="gi">+        group_case,</span>
<span class="gi">+        group_if,</span>
<span class="gi">+        group_for,</span>
<span class="gi">+        group_begin,</span>
<span class="gi">+</span>
<span class="gi">+        group_over,</span>
<span class="gi">+        group_functions,</span>
<span class="gi">+        group_where,</span>
<span class="gi">+        group_period,</span>
<span class="gi">+        group_arrays,</span>
<span class="gi">+        group_identifier,</span>
<span class="gi">+        group_order,</span>
<span class="gi">+        group_typecasts,</span>
<span class="gi">+        group_tzcasts,</span>
<span class="gi">+        group_typed_literal,</span>
<span class="gi">+        group_operator,</span>
<span class="gi">+        group_comparison,</span>
<span class="gi">+        group_as,</span>
<span class="gi">+        group_aliased,</span>
<span class="gi">+        group_assignment,</span>
<span class="gi">+</span>
<span class="gi">+        align_comments,</span>
<span class="gi">+        group_identifier_list,</span>
<span class="gi">+        group_values,</span>
<span class="gi">+    ]:</span>
<span class="gi">+        func(stmt)</span>
<span class="gi">+    return stmt</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _group(tlist, cls, match,</span>
<span class="gi">+           valid_prev=lambda t: True,</span>
<span class="gi">+           valid_next=lambda t: True,</span>
<span class="gi">+           post=None,</span>
<span class="gi">+           extend=True,</span>
<span class="gi">+           recurse=True</span>
<span class="gi">+           ):</span>
<span class="w"> </span>    &quot;&quot;&quot;Groups together tokens that are joined by a middle token. i.e. x &lt; y&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    tidx_offset = 0</span>
<span class="gi">+    pidx, prev_ = None, None</span>
<span class="gi">+    for idx, token in enumerate(list(tlist)):</span>
<span class="gi">+        tidx = idx - tidx_offset</span>
<span class="gi">+        if tidx &lt; 0:  # tidx shouldn&#39;t get negative</span>
<span class="gi">+            continue</span>
<span class="gi">+</span>
<span class="gi">+        if token.is_whitespace:</span>
<span class="gi">+            continue</span>
<span class="gi">+</span>
<span class="gi">+        if recurse and token.is_group and not isinstance(token, cls):</span>
<span class="gi">+            _group(token, cls, match, valid_prev, valid_next, post, extend)</span>
<span class="gi">+</span>
<span class="gi">+        if match(token):</span>
<span class="gi">+            nidx, next_ = tlist.token_next(tidx)</span>
<span class="gi">+            if prev_ and valid_prev(prev_) and valid_next(next_):</span>
<span class="gi">+                from_idx, to_idx = post(tlist, pidx, tidx, nidx)</span>
<span class="gi">+                grp = tlist.group_tokens(cls, from_idx, to_idx, extend=extend)</span>
<span class="gi">+</span>
<span class="gi">+                tidx_offset += to_idx - from_idx</span>
<span class="gi">+                pidx, prev_ = from_idx, grp</span>
<span class="gi">+                continue</span>
<span class="gi">+</span>
<span class="gi">+        pidx, prev_ = tidx, token</span>
<span class="gh">diff --git a/sqlparse/engine/statement_splitter.py b/sqlparse/engine/statement_splitter.py</span>
<span class="gh">index c9a1569..6c69d30 100644</span>
<span class="gd">--- a/sqlparse/engine/statement_splitter.py</span>
<span class="gi">+++ b/sqlparse/engine/statement_splitter.py</span>
<span class="gu">@@ -1,3 +1,10 @@</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+</span>
<span class="w"> </span>from sqlparse import sql, tokens as T


<span class="gu">@@ -9,12 +16,100 @@ class StatementSplitter:</span>

<span class="w"> </span>    def _reset(self):
<span class="w"> </span>        &quot;&quot;&quot;Set the filter attributes to its default values&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._in_declare = False</span>
<span class="gi">+        self._in_case = False</span>
<span class="gi">+        self._is_create = False</span>
<span class="gi">+        self._begin_depth = 0</span>
<span class="gi">+</span>
<span class="gi">+        self.consume_ws = False</span>
<span class="gi">+        self.tokens = []</span>
<span class="gi">+        self.level = 0</span>

<span class="w"> </span>    def _change_splitlevel(self, ttype, value):
<span class="w"> </span>        &quot;&quot;&quot;Get the new split level (increase, decrease or remain equal)&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+</span>
<span class="gi">+        # parenthesis increase/decrease a level</span>
<span class="gi">+        if ttype is T.Punctuation and value == &#39;(&#39;:</span>
<span class="gi">+            return 1</span>
<span class="gi">+        elif ttype is T.Punctuation and value == &#39;)&#39;:</span>
<span class="gi">+            return -1</span>
<span class="gi">+        elif ttype not in T.Keyword:  # if normal token return</span>
<span class="gi">+            return 0</span>
<span class="gi">+</span>
<span class="gi">+        # Everything after here is ttype = T.Keyword</span>
<span class="gi">+        # Also to note, once entered an If statement you are done and basically</span>
<span class="gi">+        # returning</span>
<span class="gi">+        unified = value.upper()</span>
<span class="gi">+</span>
<span class="gi">+        # three keywords begin with CREATE, but only one of them is DDL</span>
<span class="gi">+        # DDL Create though can contain more words such as &quot;or replace&quot;</span>
<span class="gi">+        if ttype is T.Keyword.DDL and unified.startswith(&#39;CREATE&#39;):</span>
<span class="gi">+            self._is_create = True</span>
<span class="gi">+            return 0</span>
<span class="gi">+</span>
<span class="gi">+        # can have nested declare inside of being...</span>
<span class="gi">+        if unified == &#39;DECLARE&#39; and self._is_create and self._begin_depth == 0:</span>
<span class="gi">+            self._in_declare = True</span>
<span class="gi">+            return 1</span>
<span class="gi">+</span>
<span class="gi">+        if unified == &#39;BEGIN&#39;:</span>
<span class="gi">+            self._begin_depth += 1</span>
<span class="gi">+            if self._is_create:</span>
<span class="gi">+                # FIXME(andi): This makes no sense.  ## this comment neither</span>
<span class="gi">+                return 1</span>
<span class="gi">+            return 0</span>
<span class="gi">+</span>
<span class="gi">+        # BEGIN and CASE/WHEN both end with END</span>
<span class="gi">+        if unified == &#39;END&#39;:</span>
<span class="gi">+            if not self._in_case:</span>
<span class="gi">+                self._begin_depth = max(0, self._begin_depth - 1)</span>
<span class="gi">+            else:</span>
<span class="gi">+                self._in_case = False</span>
<span class="gi">+            return -1</span>
<span class="gi">+</span>
<span class="gi">+        if (unified in (&#39;IF&#39;, &#39;FOR&#39;, &#39;WHILE&#39;, &#39;CASE&#39;)</span>
<span class="gi">+                and self._is_create and self._begin_depth &gt; 0):</span>
<span class="gi">+            if unified == &#39;CASE&#39;:</span>
<span class="gi">+                self._in_case = True</span>
<span class="gi">+            return 1</span>
<span class="gi">+</span>
<span class="gi">+        if unified in (&#39;END IF&#39;, &#39;END FOR&#39;, &#39;END WHILE&#39;):</span>
<span class="gi">+            return -1</span>
<span class="gi">+</span>
<span class="gi">+        # Default</span>
<span class="gi">+        return 0</span>

<span class="w"> </span>    def process(self, stream):
<span class="w"> </span>        &quot;&quot;&quot;Process the stream&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        EOS_TTYPE = T.Whitespace, T.Comment.Single</span>
<span class="gi">+</span>
<span class="gi">+        # Run over all stream tokens</span>
<span class="gi">+        for ttype, value in stream:</span>
<span class="gi">+            # Yield token if we finished a statement and there&#39;s no whitespaces</span>
<span class="gi">+            # It will count newline token as a non whitespace. In this context</span>
<span class="gi">+            # whitespace ignores newlines.</span>
<span class="gi">+            # why don&#39;t multi line comments also count?</span>
<span class="gi">+            if self.consume_ws and ttype not in EOS_TTYPE:</span>
<span class="gi">+                yield sql.Statement(self.tokens)</span>
<span class="gi">+</span>
<span class="gi">+                # Reset filter and prepare to process next statement</span>
<span class="gi">+                self._reset()</span>
<span class="gi">+</span>
<span class="gi">+            # Change current split level (increase, decrease or remain equal)</span>
<span class="gi">+            self.level += self._change_splitlevel(ttype, value)</span>
<span class="gi">+</span>
<span class="gi">+            # Append the token to the current statement</span>
<span class="gi">+            self.tokens.append(sql.Token(ttype, value))</span>
<span class="gi">+</span>
<span class="gi">+            # Check if we get the end of a statement</span>
<span class="gi">+            # Issue762: Allow GO (or &quot;GO 2&quot;) as statement splitter.</span>
<span class="gi">+            # When implementing a language toggle, it&#39;s not only to add</span>
<span class="gi">+            # keywords it&#39;s also to change some rules, like this splitting</span>
<span class="gi">+            # rule.</span>
<span class="gi">+            if (self.level &lt;= 0 and ttype is T.Punctuation and value == &#39;;&#39;) \</span>
<span class="gi">+                    or (ttype is T.Keyword and value.split()[0] == &#39;GO&#39;):</span>
<span class="gi">+                self.consume_ws = True</span>
<span class="gi">+</span>
<span class="gi">+        # Yield pending statement (if any)</span>
<span class="gi">+        if self.tokens and not all(t.is_whitespace for t in self.tokens):</span>
<span class="gi">+            yield sql.Statement(self.tokens)</span>
<span class="gh">diff --git a/sqlparse/exceptions.py b/sqlparse/exceptions.py</span>
<span class="gh">index eda09d7..11285da 100644</span>
<span class="gd">--- a/sqlparse/exceptions.py</span>
<span class="gi">+++ b/sqlparse/exceptions.py</span>
<span class="gu">@@ -1,3 +1,10 @@</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+</span>
<span class="w"> </span>&quot;&quot;&quot;Exceptions used in this package.&quot;&quot;&quot;


<span class="gh">diff --git a/sqlparse/filters/aligned_indent.py b/sqlparse/filters/aligned_indent.py</span>
<span class="gh">index d29169a..dc60926 100644</span>
<span class="gd">--- a/sqlparse/filters/aligned_indent.py</span>
<span class="gi">+++ b/sqlparse/filters/aligned_indent.py</span>
<span class="gu">@@ -1,14 +1,25 @@</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+</span>
<span class="w"> </span>from sqlparse import sql, tokens as T
<span class="w"> </span>from sqlparse.utils import offset, indent


<span class="w"> </span>class AlignedIndentFilter:
<span class="gd">-    join_words = (</span>
<span class="gd">-        &#39;((LEFT\\s+|RIGHT\\s+|FULL\\s+)?(INNER\\s+|OUTER\\s+|STRAIGHT\\s+)?|(CROSS\\s+|NATURAL\\s+)?)?JOIN\\b&#39;</span>
<span class="gd">-        )</span>
<span class="gd">-    by_words = &#39;(GROUP|ORDER)\\s+BY\\b&#39;</span>
<span class="gd">-    split_words = (&#39;FROM&#39;, join_words, &#39;ON&#39;, by_words, &#39;WHERE&#39;, &#39;AND&#39;, &#39;OR&#39;,</span>
<span class="gd">-        &#39;HAVING&#39;, &#39;LIMIT&#39;, &#39;UNION&#39;, &#39;VALUES&#39;, &#39;SET&#39;, &#39;BETWEEN&#39;, &#39;EXCEPT&#39;)</span>
<span class="gi">+    join_words = (r&#39;((LEFT\s+|RIGHT\s+|FULL\s+)?&#39;</span>
<span class="gi">+                  r&#39;(INNER\s+|OUTER\s+|STRAIGHT\s+)?|&#39;</span>
<span class="gi">+                  r&#39;(CROSS\s+|NATURAL\s+)?)?JOIN\b&#39;)</span>
<span class="gi">+    by_words = r&#39;(GROUP|ORDER)\s+BY\b&#39;</span>
<span class="gi">+    split_words = (&#39;FROM&#39;,</span>
<span class="gi">+                   join_words, &#39;ON&#39;, by_words,</span>
<span class="gi">+                   &#39;WHERE&#39;, &#39;AND&#39;, &#39;OR&#39;,</span>
<span class="gi">+                   &#39;HAVING&#39;, &#39;LIMIT&#39;,</span>
<span class="gi">+                   &#39;UNION&#39;, &#39;VALUES&#39;,</span>
<span class="gi">+                   &#39;SET&#39;, &#39;BETWEEN&#39;, &#39;EXCEPT&#39;)</span>

<span class="w"> </span>    def __init__(self, char=&#39; &#39;, n=&#39;\n&#39;):
<span class="w"> </span>        self.n = n
<span class="gu">@@ -16,3 +27,109 @@ class AlignedIndentFilter:</span>
<span class="w"> </span>        self.indent = 0
<span class="w"> </span>        self.char = char
<span class="w"> </span>        self._max_kwd_len = len(&#39;select&#39;)
<span class="gi">+</span>
<span class="gi">+    def nl(self, offset=1):</span>
<span class="gi">+        # offset = 1 represent a single space after SELECT</span>
<span class="gi">+        offset = -len(offset) if not isinstance(offset, int) else offset</span>
<span class="gi">+        # add two for the space and parenthesis</span>
<span class="gi">+        indent = self.indent * (2 + self._max_kwd_len)</span>
<span class="gi">+</span>
<span class="gi">+        return sql.Token(T.Whitespace, self.n + self.char * (</span>
<span class="gi">+            self._max_kwd_len + offset + indent + self.offset))</span>
<span class="gi">+</span>
<span class="gi">+    def _process_statement(self, tlist):</span>
<span class="gi">+        if len(tlist.tokens) &gt; 0 and tlist.tokens[0].is_whitespace \</span>
<span class="gi">+                and self.indent == 0:</span>
<span class="gi">+            tlist.tokens.pop(0)</span>
<span class="gi">+</span>
<span class="gi">+        # process the main query body</span>
<span class="gi">+        self._process(sql.TokenList(tlist.tokens))</span>
<span class="gi">+</span>
<span class="gi">+    def _process_parenthesis(self, tlist):</span>
<span class="gi">+        # if this isn&#39;t a subquery, don&#39;t re-indent</span>
<span class="gi">+        _, token = tlist.token_next_by(m=(T.DML, &#39;SELECT&#39;))</span>
<span class="gi">+        if token is not None:</span>
<span class="gi">+            with indent(self):</span>
<span class="gi">+                tlist.insert_after(tlist[0], self.nl(&#39;SELECT&#39;))</span>
<span class="gi">+                # process the inside of the parenthesis</span>
<span class="gi">+                self._process_default(tlist)</span>
<span class="gi">+</span>
<span class="gi">+            # de-indent last parenthesis</span>
<span class="gi">+            tlist.insert_before(tlist[-1], self.nl())</span>
<span class="gi">+</span>
<span class="gi">+    def _process_identifierlist(self, tlist):</span>
<span class="gi">+        # columns being selected</span>
<span class="gi">+        identifiers = list(tlist.get_identifiers())</span>
<span class="gi">+        identifiers.pop(0)</span>
<span class="gi">+        [tlist.insert_before(token, self.nl()) for token in identifiers]</span>
<span class="gi">+        self._process_default(tlist)</span>
<span class="gi">+</span>
<span class="gi">+    def _process_case(self, tlist):</span>
<span class="gi">+        offset_ = len(&#39;case &#39;) + len(&#39;when &#39;)</span>
<span class="gi">+        cases = tlist.get_cases(skip_ws=True)</span>
<span class="gi">+        # align the end as well</span>
<span class="gi">+        end_token = tlist.token_next_by(m=(T.Keyword, &#39;END&#39;))[1]</span>
<span class="gi">+        cases.append((None, [end_token]))</span>
<span class="gi">+</span>
<span class="gi">+        condition_width = [len(&#39; &#39;.join(map(str, cond))) if cond else 0</span>
<span class="gi">+                           for cond, _ in cases]</span>
<span class="gi">+        max_cond_width = max(condition_width)</span>
<span class="gi">+</span>
<span class="gi">+        for i, (cond, value) in enumerate(cases):</span>
<span class="gi">+            # cond is None when &#39;else or end&#39;</span>
<span class="gi">+            stmt = cond[0] if cond else value[0]</span>
<span class="gi">+</span>
<span class="gi">+            if i &gt; 0:</span>
<span class="gi">+                tlist.insert_before(stmt, self.nl(offset_ - len(str(stmt))))</span>
<span class="gi">+            if cond:</span>
<span class="gi">+                ws = sql.Token(T.Whitespace, self.char * (</span>
<span class="gi">+                    max_cond_width - condition_width[i]))</span>
<span class="gi">+                tlist.insert_after(cond[-1], ws)</span>
<span class="gi">+</span>
<span class="gi">+    def _next_token(self, tlist, idx=-1):</span>
<span class="gi">+        split_words = T.Keyword, self.split_words, True</span>
<span class="gi">+        tidx, token = tlist.token_next_by(m=split_words, idx=idx)</span>
<span class="gi">+        # treat &quot;BETWEEN x and y&quot; as a single statement</span>
<span class="gi">+        if token and token.normalized == &#39;BETWEEN&#39;:</span>
<span class="gi">+            tidx, token = self._next_token(tlist, tidx)</span>
<span class="gi">+            if token and token.normalized == &#39;AND&#39;:</span>
<span class="gi">+                tidx, token = self._next_token(tlist, tidx)</span>
<span class="gi">+        return tidx, token</span>
<span class="gi">+</span>
<span class="gi">+    def _split_kwds(self, tlist):</span>
<span class="gi">+        tidx, token = self._next_token(tlist)</span>
<span class="gi">+        while token:</span>
<span class="gi">+            # joins, group/order by are special case. only consider the first</span>
<span class="gi">+            # word as aligner</span>
<span class="gi">+            if (</span>
<span class="gi">+                token.match(T.Keyword, self.join_words, regex=True)</span>
<span class="gi">+                or token.match(T.Keyword, self.by_words, regex=True)</span>
<span class="gi">+            ):</span>
<span class="gi">+                token_indent = token.value.split()[0]</span>
<span class="gi">+            else:</span>
<span class="gi">+                token_indent = str(token)</span>
<span class="gi">+            tlist.insert_before(token, self.nl(token_indent))</span>
<span class="gi">+            tidx += 1</span>
<span class="gi">+            tidx, token = self._next_token(tlist, tidx)</span>
<span class="gi">+</span>
<span class="gi">+    def _process_default(self, tlist):</span>
<span class="gi">+        self._split_kwds(tlist)</span>
<span class="gi">+        # process any sub-sub statements</span>
<span class="gi">+        for sgroup in tlist.get_sublists():</span>
<span class="gi">+            idx = tlist.token_index(sgroup)</span>
<span class="gi">+            pidx, prev_ = tlist.token_prev(idx)</span>
<span class="gi">+            # HACK: make &quot;group/order by&quot; work. Longer than max_len.</span>
<span class="gi">+            offset_ = 3 if (</span>
<span class="gi">+                prev_ and prev_.match(T.Keyword, self.by_words, regex=True)</span>
<span class="gi">+            ) else 0</span>
<span class="gi">+            with offset(self, offset_):</span>
<span class="gi">+                self._process(sgroup)</span>
<span class="gi">+</span>
<span class="gi">+    def _process(self, tlist):</span>
<span class="gi">+        func_name = &#39;_process_{cls}&#39;.format(cls=type(tlist).__name__)</span>
<span class="gi">+        func = getattr(self, func_name.lower(), self._process_default)</span>
<span class="gi">+        func(tlist)</span>
<span class="gi">+</span>
<span class="gi">+    def process(self, stmt):</span>
<span class="gi">+        self._process(stmt)</span>
<span class="gi">+        return stmt</span>
<span class="gh">diff --git a/sqlparse/filters/others.py b/sqlparse/filters/others.py</span>
<span class="gh">index a5dc327..3388a78 100644</span>
<span class="gd">--- a/sqlparse/filters/others.py</span>
<span class="gi">+++ b/sqlparse/filters/others.py</span>
<span class="gu">@@ -1,23 +1,149 @@</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+</span>
<span class="w"> </span>import re
<span class="gi">+</span>
<span class="w"> </span>from sqlparse import sql, tokens as T
<span class="w"> </span>from sqlparse.utils import split_unquoted_newlines


<span class="w"> </span>class StripCommentsFilter:
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _process(tlist):</span>
<span class="gi">+        def get_next_comment():</span>
<span class="gi">+            # TODO(andi) Comment types should be unified, see related issue38</span>
<span class="gi">+            return tlist.token_next_by(i=sql.Comment, t=T.Comment)</span>
<span class="gi">+</span>
<span class="gi">+        def _get_insert_token(token):</span>
<span class="gi">+            &quot;&quot;&quot;Returns either a whitespace or the line breaks from token.&quot;&quot;&quot;</span>
<span class="gi">+            # See issue484 why line breaks should be preserved.</span>
<span class="gi">+            # Note: The actual value for a line break is replaced by \n</span>
<span class="gi">+            # in SerializerUnicode which will be executed in the</span>
<span class="gi">+            # postprocessing state.</span>
<span class="gi">+            m = re.search(r&#39;([\r\n]+) *$&#39;, token.value)</span>
<span class="gi">+            if m is not None:</span>
<span class="gi">+                return sql.Token(T.Whitespace.Newline, m.groups()[0])</span>
<span class="gi">+            else:</span>
<span class="gi">+                return sql.Token(T.Whitespace, &#39; &#39;)</span>
<span class="gi">+</span>
<span class="gi">+        tidx, token = get_next_comment()</span>
<span class="gi">+        while token:</span>
<span class="gi">+            pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)</span>
<span class="gi">+            nidx, next_ = tlist.token_next(tidx, skip_ws=False)</span>
<span class="gi">+            # Replace by whitespace if prev and next exist and if they&#39;re not</span>
<span class="gi">+            # whitespaces. This doesn&#39;t apply if prev or next is a parenthesis.</span>
<span class="gi">+            if (prev_ is None or next_ is None</span>
<span class="gi">+                    or prev_.is_whitespace or prev_.match(T.Punctuation, &#39;(&#39;)</span>
<span class="gi">+                    or next_.is_whitespace or next_.match(T.Punctuation, &#39;)&#39;)):</span>
<span class="gi">+                # Insert a whitespace to ensure the following SQL produces</span>
<span class="gi">+                # a valid SQL (see #425).</span>
<span class="gi">+                if prev_ is not None and not prev_.match(T.Punctuation, &#39;(&#39;):</span>
<span class="gi">+                    tlist.tokens.insert(tidx, _get_insert_token(token))</span>
<span class="gi">+                tlist.tokens.remove(token)</span>
<span class="gi">+            else:</span>
<span class="gi">+                tlist.tokens[tidx] = _get_insert_token(token)</span>
<span class="gi">+</span>
<span class="gi">+            tidx, token = get_next_comment()</span>
<span class="gi">+</span>
<span class="gi">+    def process(self, stmt):</span>
<span class="gi">+        [self.process(sgroup) for sgroup in stmt.get_sublists()]</span>
<span class="gi">+        StripCommentsFilter._process(stmt)</span>
<span class="gi">+        return stmt</span>


<span class="w"> </span>class StripWhitespaceFilter:
<span class="gd">-    pass</span>
<span class="gi">+    def _stripws(self, tlist):</span>
<span class="gi">+        func_name = &#39;_stripws_{cls}&#39;.format(cls=type(tlist).__name__)</span>
<span class="gi">+        func = getattr(self, func_name.lower(), self._stripws_default)</span>
<span class="gi">+        func(tlist)</span>
<span class="gi">+</span>
<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _stripws_default(tlist):</span>
<span class="gi">+        last_was_ws = False</span>
<span class="gi">+        is_first_char = True</span>
<span class="gi">+        for token in tlist.tokens:</span>
<span class="gi">+            if token.is_whitespace:</span>
<span class="gi">+                token.value = &#39;&#39; if last_was_ws or is_first_char else &#39; &#39;</span>
<span class="gi">+            last_was_ws = token.is_whitespace</span>
<span class="gi">+            is_first_char = False</span>
<span class="gi">+</span>
<span class="gi">+    def _stripws_identifierlist(self, tlist):</span>
<span class="gi">+        # Removes newlines before commas, see issue140</span>
<span class="gi">+        last_nl = None</span>
<span class="gi">+        for token in list(tlist.tokens):</span>
<span class="gi">+            if last_nl and token.ttype is T.Punctuation and token.value == &#39;,&#39;:</span>
<span class="gi">+                tlist.tokens.remove(last_nl)</span>
<span class="gi">+            last_nl = token if token.is_whitespace else None</span>
<span class="gi">+</span>
<span class="gi">+            # next_ = tlist.token_next(token, skip_ws=False)</span>
<span class="gi">+            # if (next_ and not next_.is_whitespace and</span>
<span class="gi">+            #             token.ttype is T.Punctuation and token.value == &#39;,&#39;):</span>
<span class="gi">+            #     tlist.insert_after(token, sql.Token(T.Whitespace, &#39; &#39;))</span>
<span class="gi">+        return self._stripws_default(tlist)</span>
<span class="gi">+</span>
<span class="gi">+    def _stripws_parenthesis(self, tlist):</span>
<span class="gi">+        while tlist.tokens[1].is_whitespace:</span>
<span class="gi">+            tlist.tokens.pop(1)</span>
<span class="gi">+        while tlist.tokens[-2].is_whitespace:</span>
<span class="gi">+            tlist.tokens.pop(-2)</span>
<span class="gi">+        if tlist.tokens[-2].is_group:</span>
<span class="gi">+            # save to remove the last whitespace</span>
<span class="gi">+            while tlist.tokens[-2].tokens[-1].is_whitespace:</span>
<span class="gi">+                tlist.tokens[-2].tokens.pop(-1)</span>
<span class="gi">+        self._stripws_default(tlist)</span>
<span class="gi">+</span>
<span class="gi">+    def process(self, stmt, depth=0):</span>
<span class="gi">+        [self.process(sgroup, depth + 1) for sgroup in stmt.get_sublists()]</span>
<span class="gi">+        self._stripws(stmt)</span>
<span class="gi">+        if depth == 0 and stmt.tokens and stmt.tokens[-1].is_whitespace:</span>
<span class="gi">+            stmt.tokens.pop(-1)</span>
<span class="gi">+        return stmt</span>


<span class="w"> </span>class SpacesAroundOperatorsFilter:
<span class="gd">-    pass</span>
<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _process(tlist):</span>
<span class="gi">+</span>
<span class="gi">+        ttypes = (T.Operator, T.Comparison)</span>
<span class="gi">+        tidx, token = tlist.token_next_by(t=ttypes)</span>
<span class="gi">+        while token:</span>
<span class="gi">+            nidx, next_ = tlist.token_next(tidx, skip_ws=False)</span>
<span class="gi">+            if next_ and next_.ttype != T.Whitespace:</span>
<span class="gi">+                tlist.insert_after(tidx, sql.Token(T.Whitespace, &#39; &#39;))</span>
<span class="gi">+</span>
<span class="gi">+            pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)</span>
<span class="gi">+            if prev_ and prev_.ttype != T.Whitespace:</span>
<span class="gi">+                tlist.insert_before(tidx, sql.Token(T.Whitespace, &#39; &#39;))</span>
<span class="gi">+                tidx += 1  # has to shift since token inserted before it</span>
<span class="gi">+</span>
<span class="gi">+            # assert tlist.token_index(token) == tidx</span>
<span class="gi">+            tidx, token = tlist.token_next_by(t=ttypes, idx=tidx)</span>
<span class="gi">+</span>
<span class="gi">+    def process(self, stmt):</span>
<span class="gi">+        [self.process(sgroup) for sgroup in stmt.get_sublists()]</span>
<span class="gi">+        SpacesAroundOperatorsFilter._process(stmt)</span>
<span class="gi">+        return stmt</span>


<span class="w"> </span>class StripTrailingSemicolonFilter:
<span class="gd">-    pass</span>

<span class="gi">+    def process(self, stmt):</span>
<span class="gi">+        while stmt.tokens and (stmt.tokens[-1].is_whitespace</span>
<span class="gi">+                               or stmt.tokens[-1].value == &#39;;&#39;):</span>
<span class="gi">+            stmt.tokens.pop()</span>
<span class="gi">+        return stmt</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# ---------------------------</span>
<span class="gi">+# postprocess</span>

<span class="w"> </span>class SerializerUnicode:
<span class="gd">-    pass</span>
<span class="gi">+    @staticmethod</span>
<span class="gi">+    def process(stmt):</span>
<span class="gi">+        lines = split_unquoted_newlines(stmt)</span>
<span class="gi">+        return &#39;\n&#39;.join(line.rstrip() for line in lines)</span>
<span class="gh">diff --git a/sqlparse/filters/output.py b/sqlparse/filters/output.py</span>
<span class="gh">index d7e0078..253537e 100644</span>
<span class="gd">--- a/sqlparse/filters/output.py</span>
<span class="gi">+++ b/sqlparse/filters/output.py</span>
<span class="gu">@@ -1,3 +1,10 @@</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+</span>
<span class="w"> </span>from sqlparse import sql, tokens as T


<span class="gu">@@ -8,10 +15,108 @@ class OutputFilter:</span>
<span class="w"> </span>        self.varname = self.varname_prefix + varname
<span class="w"> </span>        self.count = 0

<span class="gi">+    def _process(self, stream, varname, has_nl):</span>
<span class="gi">+        raise NotImplementedError</span>
<span class="gi">+</span>
<span class="gi">+    def process(self, stmt):</span>
<span class="gi">+        self.count += 1</span>
<span class="gi">+        if self.count &gt; 1:</span>
<span class="gi">+            varname = &#39;{f.varname}{f.count}&#39;.format(f=self)</span>
<span class="gi">+        else:</span>
<span class="gi">+            varname = self.varname</span>
<span class="gi">+</span>
<span class="gi">+        has_nl = len(str(stmt).strip().splitlines()) &gt; 1</span>
<span class="gi">+        stmt.tokens = self._process(stmt.tokens, varname, has_nl)</span>
<span class="gi">+        return stmt</span>
<span class="gi">+</span>

<span class="w"> </span>class OutputPythonFilter(OutputFilter):
<span class="gd">-    pass</span>
<span class="gi">+    def _process(self, stream, varname, has_nl):</span>
<span class="gi">+        # SQL query assignation to varname</span>
<span class="gi">+        if self.count &gt; 1:</span>
<span class="gi">+            yield sql.Token(T.Whitespace, &#39;\n&#39;)</span>
<span class="gi">+        yield sql.Token(T.Name, varname)</span>
<span class="gi">+        yield sql.Token(T.Whitespace, &#39; &#39;)</span>
<span class="gi">+        yield sql.Token(T.Operator, &#39;=&#39;)</span>
<span class="gi">+        yield sql.Token(T.Whitespace, &#39; &#39;)</span>
<span class="gi">+        if has_nl:</span>
<span class="gi">+            yield sql.Token(T.Operator, &#39;(&#39;)</span>
<span class="gi">+        yield sql.Token(T.Text, &quot;&#39;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        # Print the tokens on the quote</span>
<span class="gi">+        for token in stream:</span>
<span class="gi">+            # Token is a new line separator</span>
<span class="gi">+            if token.is_whitespace and &#39;\n&#39; in token.value:</span>
<span class="gi">+                # Close quote and add a new line</span>
<span class="gi">+                yield sql.Token(T.Text, &quot; &#39;&quot;)</span>
<span class="gi">+                yield sql.Token(T.Whitespace, &#39;\n&#39;)</span>
<span class="gi">+</span>
<span class="gi">+                # Quote header on secondary lines</span>
<span class="gi">+                yield sql.Token(T.Whitespace, &#39; &#39; * (len(varname) + 4))</span>
<span class="gi">+                yield sql.Token(T.Text, &quot;&#39;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+                # Indentation</span>
<span class="gi">+                after_lb = token.value.split(&#39;\n&#39;, 1)[1]</span>
<span class="gi">+                if after_lb:</span>
<span class="gi">+                    yield sql.Token(T.Whitespace, after_lb)</span>
<span class="gi">+                continue</span>
<span class="gi">+</span>
<span class="gi">+            # Token has escape chars</span>
<span class="gi">+            elif &quot;&#39;&quot; in token.value:</span>
<span class="gi">+                token.value = token.value.replace(&quot;&#39;&quot;, &quot;\\&#39;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+            # Put the token</span>
<span class="gi">+            yield sql.Token(T.Text, token.value)</span>
<span class="gi">+</span>
<span class="gi">+        # Close quote</span>
<span class="gi">+        yield sql.Token(T.Text, &quot;&#39;&quot;)</span>
<span class="gi">+        if has_nl:</span>
<span class="gi">+            yield sql.Token(T.Operator, &#39;)&#39;)</span>


<span class="w"> </span>class OutputPHPFilter(OutputFilter):
<span class="w"> </span>    varname_prefix = &#39;$&#39;
<span class="gi">+</span>
<span class="gi">+    def _process(self, stream, varname, has_nl):</span>
<span class="gi">+        # SQL query assignation to varname (quote header)</span>
<span class="gi">+        if self.count &gt; 1:</span>
<span class="gi">+            yield sql.Token(T.Whitespace, &#39;\n&#39;)</span>
<span class="gi">+        yield sql.Token(T.Name, varname)</span>
<span class="gi">+        yield sql.Token(T.Whitespace, &#39; &#39;)</span>
<span class="gi">+        if has_nl:</span>
<span class="gi">+            yield sql.Token(T.Whitespace, &#39; &#39;)</span>
<span class="gi">+        yield sql.Token(T.Operator, &#39;=&#39;)</span>
<span class="gi">+        yield sql.Token(T.Whitespace, &#39; &#39;)</span>
<span class="gi">+        yield sql.Token(T.Text, &#39;&quot;&#39;)</span>
<span class="gi">+</span>
<span class="gi">+        # Print the tokens on the quote</span>
<span class="gi">+        for token in stream:</span>
<span class="gi">+            # Token is a new line separator</span>
<span class="gi">+            if token.is_whitespace and &#39;\n&#39; in token.value:</span>
<span class="gi">+                # Close quote and add a new line</span>
<span class="gi">+                yield sql.Token(T.Text, &#39; &quot;;&#39;)</span>
<span class="gi">+                yield sql.Token(T.Whitespace, &#39;\n&#39;)</span>
<span class="gi">+</span>
<span class="gi">+                # Quote header on secondary lines</span>
<span class="gi">+                yield sql.Token(T.Name, varname)</span>
<span class="gi">+                yield sql.Token(T.Whitespace, &#39; &#39;)</span>
<span class="gi">+                yield sql.Token(T.Operator, &#39;.=&#39;)</span>
<span class="gi">+                yield sql.Token(T.Whitespace, &#39; &#39;)</span>
<span class="gi">+                yield sql.Token(T.Text, &#39;&quot;&#39;)</span>
<span class="gi">+</span>
<span class="gi">+                # Indentation</span>
<span class="gi">+                after_lb = token.value.split(&#39;\n&#39;, 1)[1]</span>
<span class="gi">+                if after_lb:</span>
<span class="gi">+                    yield sql.Token(T.Whitespace, after_lb)</span>
<span class="gi">+                continue</span>
<span class="gi">+</span>
<span class="gi">+            # Token has escape chars</span>
<span class="gi">+            elif &#39;&quot;&#39; in token.value:</span>
<span class="gi">+                token.value = token.value.replace(&#39;&quot;&#39;, &#39;\\&quot;&#39;)</span>
<span class="gi">+</span>
<span class="gi">+            # Put the token</span>
<span class="gi">+            yield sql.Token(T.Text, token.value)</span>
<span class="gi">+</span>
<span class="gi">+        # Close quote</span>
<span class="gi">+        yield sql.Token(T.Text, &#39;&quot;&#39;)</span>
<span class="gi">+        yield sql.Token(T.Punctuation, &#39;;&#39;)</span>
<span class="gh">diff --git a/sqlparse/filters/reindent.py b/sqlparse/filters/reindent.py</span>
<span class="gh">index cccce71..7dc2b82 100644</span>
<span class="gd">--- a/sqlparse/filters/reindent.py</span>
<span class="gi">+++ b/sqlparse/filters/reindent.py</span>
<span class="gu">@@ -1,11 +1,18 @@</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+</span>
<span class="w"> </span>from sqlparse import sql, tokens as T
<span class="w"> </span>from sqlparse.utils import offset, indent


<span class="w"> </span>class ReindentFilter:
<span class="gd">-</span>
<span class="gd">-    def __init__(self, width=2, char=&#39; &#39;, wrap_after=0, n=&#39;\n&#39;, comma_first</span>
<span class="gd">-        =False, indent_after_first=False, indent_columns=False, compact=False):</span>
<span class="gi">+    def __init__(self, width=2, char=&#39; &#39;, wrap_after=0, n=&#39;\n&#39;,</span>
<span class="gi">+                 comma_first=False, indent_after_first=False,</span>
<span class="gi">+                 indent_columns=False, compact=False):</span>
<span class="w"> </span>        self.n = n
<span class="w"> </span>        self.width = width
<span class="w"> </span>        self.char = char
<span class="gu">@@ -21,4 +28,220 @@ class ReindentFilter:</span>

<span class="w"> </span>    def _flatten_up_to_token(self, token):
<span class="w"> </span>        &quot;&quot;&quot;Yields all tokens up to token but excluding current.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if token.is_group:</span>
<span class="gi">+            token = next(token.flatten())</span>
<span class="gi">+</span>
<span class="gi">+        for t in self._curr_stmt.flatten():</span>
<span class="gi">+            if t == token:</span>
<span class="gi">+                break</span>
<span class="gi">+            yield t</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def leading_ws(self):</span>
<span class="gi">+        return self.offset + self.indent * self.width</span>
<span class="gi">+</span>
<span class="gi">+    def _get_offset(self, token):</span>
<span class="gi">+        raw = &#39;&#39;.join(map(str, self._flatten_up_to_token(token)))</span>
<span class="gi">+        line = (raw or &#39;\n&#39;).splitlines()[-1]</span>
<span class="gi">+        # Now take current offset into account and return relative offset.</span>
<span class="gi">+        return len(line) - len(self.char * self.leading_ws)</span>
<span class="gi">+</span>
<span class="gi">+    def nl(self, offset=0):</span>
<span class="gi">+        return sql.Token(</span>
<span class="gi">+            T.Whitespace,</span>
<span class="gi">+            self.n + self.char * max(0, self.leading_ws + offset))</span>
<span class="gi">+</span>
<span class="gi">+    def _next_token(self, tlist, idx=-1):</span>
<span class="gi">+        split_words = (&#39;FROM&#39;, &#39;STRAIGHT_JOIN$&#39;, &#39;JOIN$&#39;, &#39;AND&#39;, &#39;OR&#39;,</span>
<span class="gi">+                       &#39;GROUP BY&#39;, &#39;ORDER BY&#39;, &#39;UNION&#39;, &#39;VALUES&#39;,</span>
<span class="gi">+                       &#39;SET&#39;, &#39;BETWEEN&#39;, &#39;EXCEPT&#39;, &#39;HAVING&#39;, &#39;LIMIT&#39;)</span>
<span class="gi">+        m_split = T.Keyword, split_words, True</span>
<span class="gi">+        tidx, token = tlist.token_next_by(m=m_split, idx=idx)</span>
<span class="gi">+</span>
<span class="gi">+        if token and token.normalized == &#39;BETWEEN&#39;:</span>
<span class="gi">+            tidx, token = self._next_token(tlist, tidx)</span>
<span class="gi">+</span>
<span class="gi">+            if token and token.normalized == &#39;AND&#39;:</span>
<span class="gi">+                tidx, token = self._next_token(tlist, tidx)</span>
<span class="gi">+</span>
<span class="gi">+        return tidx, token</span>
<span class="gi">+</span>
<span class="gi">+    def _split_kwds(self, tlist):</span>
<span class="gi">+        tidx, token = self._next_token(tlist)</span>
<span class="gi">+        while token:</span>
<span class="gi">+            pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)</span>
<span class="gi">+            uprev = str(prev_)</span>
<span class="gi">+</span>
<span class="gi">+            if prev_ and prev_.is_whitespace:</span>
<span class="gi">+                del tlist.tokens[pidx]</span>
<span class="gi">+                tidx -= 1</span>
<span class="gi">+</span>
<span class="gi">+            if not (uprev.endswith(&#39;\n&#39;) or uprev.endswith(&#39;\r&#39;)):</span>
<span class="gi">+                tlist.insert_before(tidx, self.nl())</span>
<span class="gi">+                tidx += 1</span>
<span class="gi">+</span>
<span class="gi">+            tidx, token = self._next_token(tlist, tidx)</span>
<span class="gi">+</span>
<span class="gi">+    def _split_statements(self, tlist):</span>
<span class="gi">+        ttypes = T.Keyword.DML, T.Keyword.DDL</span>
<span class="gi">+        tidx, token = tlist.token_next_by(t=ttypes)</span>
<span class="gi">+        while token:</span>
<span class="gi">+            pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)</span>
<span class="gi">+            if prev_ and prev_.is_whitespace:</span>
<span class="gi">+                del tlist.tokens[pidx]</span>
<span class="gi">+                tidx -= 1</span>
<span class="gi">+            # only break if it&#39;s not the first token</span>
<span class="gi">+            if prev_:</span>
<span class="gi">+                tlist.insert_before(tidx, self.nl())</span>
<span class="gi">+                tidx += 1</span>
<span class="gi">+            tidx, token = tlist.token_next_by(t=ttypes, idx=tidx)</span>
<span class="gi">+</span>
<span class="gi">+    def _process(self, tlist):</span>
<span class="gi">+        func_name = &#39;_process_{cls}&#39;.format(cls=type(tlist).__name__)</span>
<span class="gi">+        func = getattr(self, func_name.lower(), self._process_default)</span>
<span class="gi">+        func(tlist)</span>
<span class="gi">+</span>
<span class="gi">+    def _process_where(self, tlist):</span>
<span class="gi">+        tidx, token = tlist.token_next_by(m=(T.Keyword, &#39;WHERE&#39;))</span>
<span class="gi">+        if not token:</span>
<span class="gi">+            return</span>
<span class="gi">+        # issue121, errors in statement fixed??</span>
<span class="gi">+        tlist.insert_before(tidx, self.nl())</span>
<span class="gi">+        with indent(self):</span>
<span class="gi">+            self._process_default(tlist)</span>
<span class="gi">+</span>
<span class="gi">+    def _process_parenthesis(self, tlist):</span>
<span class="gi">+        ttypes = T.Keyword.DML, T.Keyword.DDL</span>
<span class="gi">+        _, is_dml_dll = tlist.token_next_by(t=ttypes)</span>
<span class="gi">+        fidx, first = tlist.token_next_by(m=sql.Parenthesis.M_OPEN)</span>
<span class="gi">+        if first is None:</span>
<span class="gi">+            return</span>
<span class="gi">+</span>
<span class="gi">+        with indent(self, 1 if is_dml_dll else 0):</span>
<span class="gi">+            tlist.tokens.insert(0, self.nl()) if is_dml_dll else None</span>
<span class="gi">+            with offset(self, self._get_offset(first) + 1):</span>
<span class="gi">+                self._process_default(tlist, not is_dml_dll)</span>
<span class="gi">+</span>
<span class="gi">+    def _process_function(self, tlist):</span>
<span class="gi">+        self._last_func = tlist[0]</span>
<span class="gi">+        self._process_default(tlist)</span>
<span class="gi">+</span>
<span class="gi">+    def _process_identifierlist(self, tlist):</span>
<span class="gi">+        identifiers = list(tlist.get_identifiers())</span>
<span class="gi">+        if self.indent_columns:</span>
<span class="gi">+            first = next(identifiers[0].flatten())</span>
<span class="gi">+            num_offset = 1 if self.char == &#39;\t&#39; else self.width</span>
<span class="gi">+        else:</span>
<span class="gi">+            first = next(identifiers.pop(0).flatten())</span>
<span class="gi">+            num_offset = 1 if self.char == &#39;\t&#39; else self._get_offset(first)</span>
<span class="gi">+</span>
<span class="gi">+        if not tlist.within(sql.Function) and not tlist.within(sql.Values):</span>
<span class="gi">+            with offset(self, num_offset):</span>
<span class="gi">+                position = 0</span>
<span class="gi">+                for token in identifiers:</span>
<span class="gi">+                    # Add 1 for the &quot;,&quot; separator</span>
<span class="gi">+                    position += len(token.value) + 1</span>
<span class="gi">+                    if position &gt; (self.wrap_after - self.offset):</span>
<span class="gi">+                        adjust = 0</span>
<span class="gi">+                        if self.comma_first:</span>
<span class="gi">+                            adjust = -2</span>
<span class="gi">+                            _, comma = tlist.token_prev(</span>
<span class="gi">+                                tlist.token_index(token))</span>
<span class="gi">+                            if comma is None:</span>
<span class="gi">+                                continue</span>
<span class="gi">+                            token = comma</span>
<span class="gi">+                        tlist.insert_before(token, self.nl(offset=adjust))</span>
<span class="gi">+                        if self.comma_first:</span>
<span class="gi">+                            _, ws = tlist.token_next(</span>
<span class="gi">+                                tlist.token_index(token), skip_ws=False)</span>
<span class="gi">+                            if (ws is not None</span>
<span class="gi">+                                    and ws.ttype is not T.Text.Whitespace):</span>
<span class="gi">+                                tlist.insert_after(</span>
<span class="gi">+                                    token, sql.Token(T.Whitespace, &#39; &#39;))</span>
<span class="gi">+                        position = 0</span>
<span class="gi">+        else:</span>
<span class="gi">+            # ensure whitespace</span>
<span class="gi">+            for token in tlist:</span>
<span class="gi">+                _, next_ws = tlist.token_next(</span>
<span class="gi">+                    tlist.token_index(token), skip_ws=False)</span>
<span class="gi">+                if token.value == &#39;,&#39; and not next_ws.is_whitespace:</span>
<span class="gi">+                    tlist.insert_after(</span>
<span class="gi">+                        token, sql.Token(T.Whitespace, &#39; &#39;))</span>
<span class="gi">+</span>
<span class="gi">+            end_at = self.offset + sum(len(i.value) + 1 for i in identifiers)</span>
<span class="gi">+            adjusted_offset = 0</span>
<span class="gi">+            if (self.wrap_after &gt; 0</span>
<span class="gi">+                    and end_at &gt; (self.wrap_after - self.offset)</span>
<span class="gi">+                    and self._last_func):</span>
<span class="gi">+                adjusted_offset = -len(self._last_func.value) - 1</span>
<span class="gi">+</span>
<span class="gi">+            with offset(self, adjusted_offset), indent(self):</span>
<span class="gi">+                if adjusted_offset &lt; 0:</span>
<span class="gi">+                    tlist.insert_before(identifiers[0], self.nl())</span>
<span class="gi">+                position = 0</span>
<span class="gi">+                for token in identifiers:</span>
<span class="gi">+                    # Add 1 for the &quot;,&quot; separator</span>
<span class="gi">+                    position += len(token.value) + 1</span>
<span class="gi">+                    if (self.wrap_after &gt; 0</span>
<span class="gi">+                            and position &gt; (self.wrap_after - self.offset)):</span>
<span class="gi">+                        adjust = 0</span>
<span class="gi">+                        tlist.insert_before(token, self.nl(offset=adjust))</span>
<span class="gi">+                        position = 0</span>
<span class="gi">+        self._process_default(tlist)</span>
<span class="gi">+</span>
<span class="gi">+    def _process_case(self, tlist):</span>
<span class="gi">+        iterable = iter(tlist.get_cases())</span>
<span class="gi">+        cond, _ = next(iterable)</span>
<span class="gi">+        first = next(cond[0].flatten())</span>
<span class="gi">+</span>
<span class="gi">+        with offset(self, self._get_offset(tlist[0])):</span>
<span class="gi">+            with offset(self, self._get_offset(first)):</span>
<span class="gi">+                for cond, value in iterable:</span>
<span class="gi">+                    str_cond = &#39;&#39;.join(str(x) for x in cond or [])</span>
<span class="gi">+                    str_value = &#39;&#39;.join(str(x) for x in value)</span>
<span class="gi">+                    end_pos = self.offset + 1 + len(str_cond) + len(str_value)</span>
<span class="gi">+                    if (not self.compact and end_pos &gt; self.wrap_after):</span>
<span class="gi">+                        token = value[0] if cond is None else cond[0]</span>
<span class="gi">+                        tlist.insert_before(token, self.nl())</span>
<span class="gi">+</span>
<span class="gi">+                # Line breaks on group level are done. let&#39;s add an offset of</span>
<span class="gi">+                # len &quot;when &quot;, &quot;then &quot;, &quot;else &quot;</span>
<span class="gi">+                with offset(self, len(&quot;WHEN &quot;)):</span>
<span class="gi">+                    self._process_default(tlist)</span>
<span class="gi">+            end_idx, end = tlist.token_next_by(m=sql.Case.M_CLOSE)</span>
<span class="gi">+            if end_idx is not None and not self.compact:</span>
<span class="gi">+                tlist.insert_before(end_idx, self.nl())</span>
<span class="gi">+</span>
<span class="gi">+    def _process_values(self, tlist):</span>
<span class="gi">+        tlist.insert_before(0, self.nl())</span>
<span class="gi">+        tidx, token = tlist.token_next_by(i=sql.Parenthesis)</span>
<span class="gi">+        first_token = token</span>
<span class="gi">+        while token:</span>
<span class="gi">+            ptidx, ptoken = tlist.token_next_by(m=(T.Punctuation, &#39;,&#39;),</span>
<span class="gi">+                                                idx=tidx)</span>
<span class="gi">+            if ptoken:</span>
<span class="gi">+                if self.comma_first:</span>
<span class="gi">+                    adjust = -2</span>
<span class="gi">+                    offset = self._get_offset(first_token) + adjust</span>
<span class="gi">+                    tlist.insert_before(ptoken, self.nl(offset))</span>
<span class="gi">+                else:</span>
<span class="gi">+                    tlist.insert_after(ptoken,</span>
<span class="gi">+                                       self.nl(self._get_offset(token)))</span>
<span class="gi">+            tidx, token = tlist.token_next_by(i=sql.Parenthesis, idx=tidx)</span>
<span class="gi">+</span>
<span class="gi">+    def _process_default(self, tlist, stmts=True):</span>
<span class="gi">+        self._split_statements(tlist) if stmts else None</span>
<span class="gi">+        self._split_kwds(tlist)</span>
<span class="gi">+        for sgroup in tlist.get_sublists():</span>
<span class="gi">+            self._process(sgroup)</span>
<span class="gi">+</span>
<span class="gi">+    def process(self, stmt):</span>
<span class="gi">+        self._curr_stmt = stmt</span>
<span class="gi">+        self._process(stmt)</span>
<span class="gi">+</span>
<span class="gi">+        if self._last_stmt is not None:</span>
<span class="gi">+            nl = &#39;\n&#39; if str(self._last_stmt).endswith(&#39;\n&#39;) else &#39;\n\n&#39;</span>
<span class="gi">+            stmt.tokens.insert(0, sql.Token(T.Whitespace, nl))</span>
<span class="gi">+</span>
<span class="gi">+        self._last_stmt = stmt</span>
<span class="gi">+        return stmt</span>
<span class="gh">diff --git a/sqlparse/filters/right_margin.py b/sqlparse/filters/right_margin.py</span>
<span class="gh">index 4e1ebce..3e67056 100644</span>
<span class="gd">--- a/sqlparse/filters/right_margin.py</span>
<span class="gi">+++ b/sqlparse/filters/right_margin.py</span>
<span class="gu">@@ -1,10 +1,48 @@</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+</span>
<span class="w"> </span>import re
<span class="gi">+</span>
<span class="w"> </span>from sqlparse import sql, tokens as T


<span class="gi">+# FIXME: Doesn&#39;t work</span>
<span class="w"> </span>class RightMarginFilter:
<span class="gd">-    keep_together = ()</span>
<span class="gi">+    keep_together = (</span>
<span class="gi">+        # sql.TypeCast, sql.Identifier, sql.Alias,</span>
<span class="gi">+    )</span>

<span class="w"> </span>    def __init__(self, width=79):
<span class="w"> </span>        self.width = width
<span class="w"> </span>        self.line = &#39;&#39;
<span class="gi">+</span>
<span class="gi">+    def _process(self, group, stream):</span>
<span class="gi">+        for token in stream:</span>
<span class="gi">+            if token.is_whitespace and &#39;\n&#39; in token.value:</span>
<span class="gi">+                if token.value.endswith(&#39;\n&#39;):</span>
<span class="gi">+                    self.line = &#39;&#39;</span>
<span class="gi">+                else:</span>
<span class="gi">+                    self.line = token.value.splitlines()[-1]</span>
<span class="gi">+            elif token.is_group and type(token) not in self.keep_together:</span>
<span class="gi">+                token.tokens = self._process(token, token.tokens)</span>
<span class="gi">+            else:</span>
<span class="gi">+                val = str(token)</span>
<span class="gi">+                if len(self.line) + len(val) &gt; self.width:</span>
<span class="gi">+                    match = re.search(r&#39;^ +&#39;, self.line)</span>
<span class="gi">+                    if match is not None:</span>
<span class="gi">+                        indent = match.group()</span>
<span class="gi">+                    else:</span>
<span class="gi">+                        indent = &#39;&#39;</span>
<span class="gi">+                    yield sql.Token(T.Whitespace, &#39;\n{}&#39;.format(indent))</span>
<span class="gi">+                    self.line = indent</span>
<span class="gi">+                self.line += val</span>
<span class="gi">+            yield token</span>
<span class="gi">+</span>
<span class="gi">+    def process(self, group):</span>
<span class="gi">+        # return</span>
<span class="gi">+        # group.tokens = self._process(group, group.tokens)</span>
<span class="gi">+        raise NotImplementedError</span>
<span class="gh">diff --git a/sqlparse/filters/tokens.py b/sqlparse/filters/tokens.py</span>
<span class="gh">index 5e61dcd..cc00a84 100644</span>
<span class="gd">--- a/sqlparse/filters/tokens.py</span>
<span class="gi">+++ b/sqlparse/filters/tokens.py</span>
<span class="gu">@@ -1,3 +1,10 @@</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+</span>
<span class="w"> </span>from sqlparse import tokens as T


<span class="gu">@@ -8,6 +15,12 @@ class _CaseFilter:</span>
<span class="w"> </span>        case = case or &#39;upper&#39;
<span class="w"> </span>        self.convert = getattr(str, case)

<span class="gi">+    def process(self, stream):</span>
<span class="gi">+        for ttype, value in stream:</span>
<span class="gi">+            if ttype in self.ttype:</span>
<span class="gi">+                value = self.convert(value)</span>
<span class="gi">+            yield ttype, value</span>
<span class="gi">+</span>

<span class="w"> </span>class KeywordCaseFilter(_CaseFilter):
<span class="w"> </span>    ttype = T.Keyword
<span class="gu">@@ -16,9 +29,31 @@ class KeywordCaseFilter(_CaseFilter):</span>
<span class="w"> </span>class IdentifierCaseFilter(_CaseFilter):
<span class="w"> </span>    ttype = T.Name, T.String.Symbol

<span class="gi">+    def process(self, stream):</span>
<span class="gi">+        for ttype, value in stream:</span>
<span class="gi">+            if ttype in self.ttype and value.strip()[0] != &#39;&quot;&#39;:</span>
<span class="gi">+                value = self.convert(value)</span>
<span class="gi">+            yield ttype, value</span>

<span class="gd">-class TruncateStringFilter:</span>

<span class="gi">+class TruncateStringFilter:</span>
<span class="w"> </span>    def __init__(self, width, char):
<span class="w"> </span>        self.width = width
<span class="w"> </span>        self.char = char
<span class="gi">+</span>
<span class="gi">+    def process(self, stream):</span>
<span class="gi">+        for ttype, value in stream:</span>
<span class="gi">+            if ttype != T.Literal.String.Single:</span>
<span class="gi">+                yield ttype, value</span>
<span class="gi">+                continue</span>
<span class="gi">+</span>
<span class="gi">+            if value[:2] == &quot;&#39;&#39;&quot;:</span>
<span class="gi">+                inner = value[2:-2]</span>
<span class="gi">+                quote = &quot;&#39;&#39;&quot;</span>
<span class="gi">+            else:</span>
<span class="gi">+                inner = value[1:-1]</span>
<span class="gi">+                quote = &quot;&#39;&quot;</span>
<span class="gi">+</span>
<span class="gi">+            if len(inner) &gt; self.width:</span>
<span class="gi">+                value = &#39;&#39;.join((quote, inner[:self.width], self.char, quote))</span>
<span class="gi">+            yield ttype, value</span>
<span class="gh">diff --git a/sqlparse/formatter.py b/sqlparse/formatter.py</span>
<span class="gh">index 71775a6..72f2c19 100644</span>
<span class="gd">--- a/sqlparse/formatter.py</span>
<span class="gi">+++ b/sqlparse/formatter.py</span>
<span class="gu">@@ -1,11 +1,137 @@</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+</span>
<span class="w"> </span>&quot;&quot;&quot;SQL formatter&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>from sqlparse import filters
<span class="w"> </span>from sqlparse.exceptions import SQLParseError


<span class="gd">-def validate_options(options):</span>
<span class="gi">+def validate_options(options):  # noqa: C901</span>
<span class="w"> </span>    &quot;&quot;&quot;Validates options.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    kwcase = options.get(&#39;keyword_case&#39;)</span>
<span class="gi">+    if kwcase not in [None, &#39;upper&#39;, &#39;lower&#39;, &#39;capitalize&#39;]:</span>
<span class="gi">+        raise SQLParseError(&#39;Invalid value for keyword_case: &#39;</span>
<span class="gi">+                            &#39;{!r}&#39;.format(kwcase))</span>
<span class="gi">+</span>
<span class="gi">+    idcase = options.get(&#39;identifier_case&#39;)</span>
<span class="gi">+    if idcase not in [None, &#39;upper&#39;, &#39;lower&#39;, &#39;capitalize&#39;]:</span>
<span class="gi">+        raise SQLParseError(&#39;Invalid value for identifier_case: &#39;</span>
<span class="gi">+                            &#39;{!r}&#39;.format(idcase))</span>
<span class="gi">+</span>
<span class="gi">+    ofrmt = options.get(&#39;output_format&#39;)</span>
<span class="gi">+    if ofrmt not in [None, &#39;sql&#39;, &#39;python&#39;, &#39;php&#39;]:</span>
<span class="gi">+        raise SQLParseError(&#39;Unknown output format: &#39;</span>
<span class="gi">+                            &#39;{!r}&#39;.format(ofrmt))</span>
<span class="gi">+</span>
<span class="gi">+    strip_comments = options.get(&#39;strip_comments&#39;, False)</span>
<span class="gi">+    if strip_comments not in [True, False]:</span>
<span class="gi">+        raise SQLParseError(&#39;Invalid value for strip_comments: &#39;</span>
<span class="gi">+                            &#39;{!r}&#39;.format(strip_comments))</span>
<span class="gi">+</span>
<span class="gi">+    space_around_operators = options.get(&#39;use_space_around_operators&#39;, False)</span>
<span class="gi">+    if space_around_operators not in [True, False]:</span>
<span class="gi">+        raise SQLParseError(&#39;Invalid value for use_space_around_operators: &#39;</span>
<span class="gi">+                            &#39;{!r}&#39;.format(space_around_operators))</span>
<span class="gi">+</span>
<span class="gi">+    strip_ws = options.get(&#39;strip_whitespace&#39;, False)</span>
<span class="gi">+    if strip_ws not in [True, False]:</span>
<span class="gi">+        raise SQLParseError(&#39;Invalid value for strip_whitespace: &#39;</span>
<span class="gi">+                            &#39;{!r}&#39;.format(strip_ws))</span>
<span class="gi">+</span>
<span class="gi">+    truncate_strings = options.get(&#39;truncate_strings&#39;)</span>
<span class="gi">+    if truncate_strings is not None:</span>
<span class="gi">+        try:</span>
<span class="gi">+            truncate_strings = int(truncate_strings)</span>
<span class="gi">+        except (ValueError, TypeError):</span>
<span class="gi">+            raise SQLParseError(&#39;Invalid value for truncate_strings: &#39;</span>
<span class="gi">+                                &#39;{!r}&#39;.format(truncate_strings))</span>
<span class="gi">+        if truncate_strings &lt;= 1:</span>
<span class="gi">+            raise SQLParseError(&#39;Invalid value for truncate_strings: &#39;</span>
<span class="gi">+                                &#39;{!r}&#39;.format(truncate_strings))</span>
<span class="gi">+        options[&#39;truncate_strings&#39;] = truncate_strings</span>
<span class="gi">+        options[&#39;truncate_char&#39;] = options.get(&#39;truncate_char&#39;, &#39;[...]&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    indent_columns = options.get(&#39;indent_columns&#39;, False)</span>
<span class="gi">+    if indent_columns not in [True, False]:</span>
<span class="gi">+        raise SQLParseError(&#39;Invalid value for indent_columns: &#39;</span>
<span class="gi">+                            &#39;{!r}&#39;.format(indent_columns))</span>
<span class="gi">+    elif indent_columns:</span>
<span class="gi">+        options[&#39;reindent&#39;] = True  # enforce reindent</span>
<span class="gi">+    options[&#39;indent_columns&#39;] = indent_columns</span>
<span class="gi">+</span>
<span class="gi">+    reindent = options.get(&#39;reindent&#39;, False)</span>
<span class="gi">+    if reindent not in [True, False]:</span>
<span class="gi">+        raise SQLParseError(&#39;Invalid value for reindent: &#39;</span>
<span class="gi">+                            &#39;{!r}&#39;.format(reindent))</span>
<span class="gi">+    elif reindent:</span>
<span class="gi">+        options[&#39;strip_whitespace&#39;] = True</span>
<span class="gi">+</span>
<span class="gi">+    reindent_aligned = options.get(&#39;reindent_aligned&#39;, False)</span>
<span class="gi">+    if reindent_aligned not in [True, False]:</span>
<span class="gi">+        raise SQLParseError(&#39;Invalid value for reindent_aligned: &#39;</span>
<span class="gi">+                            &#39;{!r}&#39;.format(reindent))</span>
<span class="gi">+    elif reindent_aligned:</span>
<span class="gi">+        options[&#39;strip_whitespace&#39;] = True</span>
<span class="gi">+</span>
<span class="gi">+    indent_after_first = options.get(&#39;indent_after_first&#39;, False)</span>
<span class="gi">+    if indent_after_first not in [True, False]:</span>
<span class="gi">+        raise SQLParseError(&#39;Invalid value for indent_after_first: &#39;</span>
<span class="gi">+                            &#39;{!r}&#39;.format(indent_after_first))</span>
<span class="gi">+    options[&#39;indent_after_first&#39;] = indent_after_first</span>
<span class="gi">+</span>
<span class="gi">+    indent_tabs = options.get(&#39;indent_tabs&#39;, False)</span>
<span class="gi">+    if indent_tabs not in [True, False]:</span>
<span class="gi">+        raise SQLParseError(&#39;Invalid value for indent_tabs: &#39;</span>
<span class="gi">+                            &#39;{!r}&#39;.format(indent_tabs))</span>
<span class="gi">+    elif indent_tabs:</span>
<span class="gi">+        options[&#39;indent_char&#39;] = &#39;\t&#39;</span>
<span class="gi">+    else:</span>
<span class="gi">+        options[&#39;indent_char&#39;] = &#39; &#39;</span>
<span class="gi">+</span>
<span class="gi">+    indent_width = options.get(&#39;indent_width&#39;, 2)</span>
<span class="gi">+    try:</span>
<span class="gi">+        indent_width = int(indent_width)</span>
<span class="gi">+    except (TypeError, ValueError):</span>
<span class="gi">+        raise SQLParseError(&#39;indent_width requires an integer&#39;)</span>
<span class="gi">+    if indent_width &lt; 1:</span>
<span class="gi">+        raise SQLParseError(&#39;indent_width requires a positive integer&#39;)</span>
<span class="gi">+    options[&#39;indent_width&#39;] = indent_width</span>
<span class="gi">+</span>
<span class="gi">+    wrap_after = options.get(&#39;wrap_after&#39;, 0)</span>
<span class="gi">+    try:</span>
<span class="gi">+        wrap_after = int(wrap_after)</span>
<span class="gi">+    except (TypeError, ValueError):</span>
<span class="gi">+        raise SQLParseError(&#39;wrap_after requires an integer&#39;)</span>
<span class="gi">+    if wrap_after &lt; 0:</span>
<span class="gi">+        raise SQLParseError(&#39;wrap_after requires a positive integer&#39;)</span>
<span class="gi">+    options[&#39;wrap_after&#39;] = wrap_after</span>
<span class="gi">+</span>
<span class="gi">+    comma_first = options.get(&#39;comma_first&#39;, False)</span>
<span class="gi">+    if comma_first not in [True, False]:</span>
<span class="gi">+        raise SQLParseError(&#39;comma_first requires a boolean value&#39;)</span>
<span class="gi">+    options[&#39;comma_first&#39;] = comma_first</span>
<span class="gi">+</span>
<span class="gi">+    compact = options.get(&#39;compact&#39;, False)</span>
<span class="gi">+    if compact not in [True, False]:</span>
<span class="gi">+        raise SQLParseError(&#39;compact requires a boolean value&#39;)</span>
<span class="gi">+    options[&#39;compact&#39;] = compact</span>
<span class="gi">+</span>
<span class="gi">+    right_margin = options.get(&#39;right_margin&#39;)</span>
<span class="gi">+    if right_margin is not None:</span>
<span class="gi">+        try:</span>
<span class="gi">+            right_margin = int(right_margin)</span>
<span class="gi">+        except (TypeError, ValueError):</span>
<span class="gi">+            raise SQLParseError(&#39;right_margin requires an integer&#39;)</span>
<span class="gi">+        if right_margin &lt; 10:</span>
<span class="gi">+            raise SQLParseError(&#39;right_margin requires an integer &gt; 10&#39;)</span>
<span class="gi">+    options[&#39;right_margin&#39;] = right_margin</span>
<span class="gi">+</span>
<span class="gi">+    return options</span>


<span class="w"> </span>def build_filter_stack(stack, options):
<span class="gu">@@ -15,4 +141,64 @@ def build_filter_stack(stack, options):</span>
<span class="w"> </span>      stack: :class:`~sqlparse.filters.FilterStack` instance
<span class="w"> </span>      options: Dictionary with options validated by validate_options.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # Token filter</span>
<span class="gi">+    if options.get(&#39;keyword_case&#39;):</span>
<span class="gi">+        stack.preprocess.append(</span>
<span class="gi">+            filters.KeywordCaseFilter(options[&#39;keyword_case&#39;]))</span>
<span class="gi">+</span>
<span class="gi">+    if options.get(&#39;identifier_case&#39;):</span>
<span class="gi">+        stack.preprocess.append(</span>
<span class="gi">+            filters.IdentifierCaseFilter(options[&#39;identifier_case&#39;]))</span>
<span class="gi">+</span>
<span class="gi">+    if options.get(&#39;truncate_strings&#39;):</span>
<span class="gi">+        stack.preprocess.append(filters.TruncateStringFilter(</span>
<span class="gi">+            width=options[&#39;truncate_strings&#39;], char=options[&#39;truncate_char&#39;]))</span>
<span class="gi">+</span>
<span class="gi">+    if options.get(&#39;use_space_around_operators&#39;, False):</span>
<span class="gi">+        stack.enable_grouping()</span>
<span class="gi">+        stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())</span>
<span class="gi">+</span>
<span class="gi">+    # After grouping</span>
<span class="gi">+    if options.get(&#39;strip_comments&#39;):</span>
<span class="gi">+        stack.enable_grouping()</span>
<span class="gi">+        stack.stmtprocess.append(filters.StripCommentsFilter())</span>
<span class="gi">+</span>
<span class="gi">+    if options.get(&#39;strip_whitespace&#39;) or options.get(&#39;reindent&#39;):</span>
<span class="gi">+        stack.enable_grouping()</span>
<span class="gi">+        stack.stmtprocess.append(filters.StripWhitespaceFilter())</span>
<span class="gi">+</span>
<span class="gi">+    if options.get(&#39;reindent&#39;):</span>
<span class="gi">+        stack.enable_grouping()</span>
<span class="gi">+        stack.stmtprocess.append(</span>
<span class="gi">+            filters.ReindentFilter(</span>
<span class="gi">+                char=options[&#39;indent_char&#39;],</span>
<span class="gi">+                width=options[&#39;indent_width&#39;],</span>
<span class="gi">+                indent_after_first=options[&#39;indent_after_first&#39;],</span>
<span class="gi">+                indent_columns=options[&#39;indent_columns&#39;],</span>
<span class="gi">+                wrap_after=options[&#39;wrap_after&#39;],</span>
<span class="gi">+                comma_first=options[&#39;comma_first&#39;],</span>
<span class="gi">+                compact=options[&#39;compact&#39;],))</span>
<span class="gi">+</span>
<span class="gi">+    if options.get(&#39;reindent_aligned&#39;, False):</span>
<span class="gi">+        stack.enable_grouping()</span>
<span class="gi">+        stack.stmtprocess.append(</span>
<span class="gi">+            filters.AlignedIndentFilter(char=options[&#39;indent_char&#39;]))</span>
<span class="gi">+</span>
<span class="gi">+    if options.get(&#39;right_margin&#39;):</span>
<span class="gi">+        stack.enable_grouping()</span>
<span class="gi">+        stack.stmtprocess.append(</span>
<span class="gi">+            filters.RightMarginFilter(width=options[&#39;right_margin&#39;]))</span>
<span class="gi">+</span>
<span class="gi">+    # Serializer</span>
<span class="gi">+    if options.get(&#39;output_format&#39;):</span>
<span class="gi">+        frmt = options[&#39;output_format&#39;]</span>
<span class="gi">+        if frmt.lower() == &#39;php&#39;:</span>
<span class="gi">+            fltr = filters.OutputPHPFilter()</span>
<span class="gi">+        elif frmt.lower() == &#39;python&#39;:</span>
<span class="gi">+            fltr = filters.OutputPythonFilter()</span>
<span class="gi">+        else:</span>
<span class="gi">+            fltr = None</span>
<span class="gi">+        if fltr is not None:</span>
<span class="gi">+            stack.postprocess.append(fltr)</span>
<span class="gi">+</span>
<span class="gi">+    return stack</span>
<span class="gh">diff --git a/sqlparse/keywords.py b/sqlparse/keywords.py</span>
<span class="gh">index a20236c..dfafedb 100644</span>
<span class="gd">--- a/sqlparse/keywords.py</span>
<span class="gi">+++ b/sqlparse/keywords.py</span>
<span class="gu">@@ -1,377 +1,1001 @@</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+</span>
<span class="w"> </span>from sqlparse import tokens
<span class="gi">+</span>
<span class="gi">+# object() only supports &quot;is&quot; and is useful as a marker</span>
<span class="gi">+# use this marker to specify that the given regex in SQL_REGEX</span>
<span class="gi">+# shall be processed further through a lookup in the KEYWORDS dictionaries</span>
<span class="w"> </span>PROCESS_AS_KEYWORD = object()
<span class="gd">-SQL_REGEX = [(&#39;(--|# )\\+.*?(\\r\\n|\\r|\\n|$)&#39;, tokens.Comment.Single.Hint</span>
<span class="gd">-    ), (&#39;/\\*\\+[\\s\\S]*?\\*/&#39;, tokens.Comment.Multiline.Hint), (</span>
<span class="gd">-    &#39;(--|# ).*?(\\r\\n|\\r|\\n|$)&#39;, tokens.Comment.Single), (</span>
<span class="gd">-    &#39;/\\*[\\s\\S]*?\\*/&#39;, tokens.Comment.Multiline), (&#39;(\\r\\n|\\r|\\n)&#39;,</span>
<span class="gd">-    tokens.Newline), (&#39;\\s+?&#39;, tokens.Whitespace), (&#39;:=&#39;, tokens.Assignment</span>
<span class="gd">-    ), (&#39;::&#39;, tokens.Punctuation), (&#39;\\*&#39;, tokens.Wildcard), (</span>
<span class="gd">-    &#39;`(``|[^`])*`&#39;, tokens.Name), (&#39;(|[^])*&#39;, tokens.Name), (</span>
<span class="gd">-    &#39;((?&lt;![\\w\\&quot;\\$])\\$(?:[_A-Z-]\\w*)?\\$)[\\s\\S]*?\\1&#39;, tokens.</span>
<span class="gd">-    Literal), (&#39;\\?&#39;, tokens.Name.Placeholder), (&#39;%(\\(\\w+\\))?s&#39;, tokens.</span>
<span class="gd">-    Name.Placeholder), (&#39;(?&lt;!\\w)[$:?]\\w+&#39;, tokens.Name.Placeholder), (</span>
<span class="gd">-    &#39;\\\\\\w+&#39;, tokens.Command), (&#39;(CASE|IN|VALUES|USING|FROM|AS)\\b&#39;,</span>
<span class="gd">-    tokens.Keyword), (&#39;(@|##|#)[A-Z-]\\w+&#39;, tokens.Name), (</span>
<span class="gd">-    &#39;[A-Z-]\\w*(?=\\s*\\.)&#39;, tokens.Name), (&#39;(?&lt;=\\.)[A-Z-]\\w*&#39;,</span>
<span class="gd">-    tokens.Name), (&#39;[A-Z-]\\w*(?=\\()&#39;, tokens.Name), (&#39;-?0x[\\dA-F]+&#39;,</span>
<span class="gd">-    tokens.Number.Hexadecimal), (&#39;-?\\d+(\\.\\d+)?E-?\\d+&#39;, tokens.Number.</span>
<span class="gd">-    Float), (&#39;(?![_A-Z-])-?(\\d+(\\.\\d*)|\\.\\d+)(?![_A-Z-])&#39;, tokens.</span>
<span class="gd">-    Number.Float), (&#39;(?![_A-Z-])-?\\d+(?![_A-Z-])&#39;, tokens.Number.</span>
<span class="gd">-    Integer), (&quot;&#39;(&#39;&#39;|\\\\&#39;|[^&#39;])*&#39;&quot;, tokens.String.Single), (</span>
<span class="gd">-    &#39;&quot;(&quot;&quot;|\\\\&quot;|[^&quot;])*&quot;&#39;, tokens.String.Symbol), (&#39;(&quot;&quot;|&quot;.*?[^\\\\]&quot;)&#39;,</span>
<span class="gd">-    tokens.String.Symbol), (&#39;(?&lt;![\\w\\])])(\\[[^\\]\\[]+\\])&#39;, tokens.Name</span>
<span class="gd">-    ), (</span>
<span class="gd">-    &#39;((LEFT\\s+|RIGHT\\s+|FULL\\s+)?(INNER\\s+|OUTER\\s+|STRAIGHT\\s+)?|(CROSS\\s+|NATURAL\\s+)?)?JOIN\\b&#39;</span>
<span class="gd">-    , tokens.Keyword), (&#39;END(\\s+IF|\\s+LOOP|\\s+WHILE)?\\b&#39;, tokens.</span>
<span class="gd">-    Keyword), (&#39;NOT\\s+NULL\\b&#39;, tokens.Keyword), (</span>
<span class="gd">-    &#39;(ASC|DESC)(\\s+NULLS\\s+(FIRST|LAST))?\\b&#39;, tokens.Keyword.Order), (</span>
<span class="gd">-    &#39;(ASC|DESC)\\b&#39;, tokens.Keyword.Order), (&#39;NULLS\\s+(FIRST|LAST)\\b&#39;,</span>
<span class="gd">-    tokens.Keyword.Order), (&#39;UNION\\s+ALL\\b&#39;, tokens.Keyword), (</span>
<span class="gd">-    &#39;CREATE(\\s+OR\\s+REPLACE)?\\b&#39;, tokens.Keyword.DDL), (</span>
<span class="gd">-    &#39;DOUBLE\\s+PRECISION\\b&#39;, tokens.Name.Builtin), (&#39;GROUP\\s+BY\\b&#39;,</span>
<span class="gd">-    tokens.Keyword), (&#39;ORDER\\s+BY\\b&#39;, tokens.Keyword), (</span>
<span class="gd">-    &#39;PRIMARY\\s+KEY\\b&#39;, tokens.Keyword), (&#39;HANDLER\\s+FOR\\b&#39;, tokens.</span>
<span class="gd">-    Keyword), (&#39;GO(\\s\\d+)\\b&#39;, tokens.Keyword), (</span>
<span class="gd">-    &#39;(LATERAL\\s+VIEW\\s+)(EXPLODE|INLINE|PARSE_URL_TUPLE|POSEXPLODE|STACK)\\b&#39;</span>
<span class="gd">-    , tokens.Keyword), (&quot;(AT|WITH&#39;)\\s+TIME\\s+ZONE\\s+&#39;[^&#39;]+&#39;&quot;, tokens.</span>
<span class="gd">-    Keyword.TZCast), (&#39;(NOT\\s+)?(LIKE|ILIKE|RLIKE)\\b&#39;, tokens.Operator.</span>
<span class="gd">-    Comparison), (&#39;(NOT\\s+)?(REGEXP)\\b&#39;, tokens.Operator.Comparison), (</span>
<span class="gd">-    &#39;\\w[$#\\w]*&#39;, PROCESS_AS_KEYWORD), (&#39;[;:()\\[\\],\\.]&#39;, tokens.</span>
<span class="gd">-    Punctuation), (&#39;(\\-&gt;&gt;?|#&gt;&gt;?|@&gt;|&lt;@|\\?\\|?|\\?&amp;|\\-|#\\-)&#39;, tokens.</span>
<span class="gd">-    Operator), (&#39;[&lt;&gt;=~!]+&#39;, tokens.Operator.Comparison), (&#39;[+/@#%^&amp;|^-]+&#39;,</span>
<span class="gd">-    tokens.Operator)]</span>
<span class="gd">-KEYWORDS = {&#39;ABORT&#39;: tokens.Keyword, &#39;ABS&#39;: tokens.Keyword, &#39;ABSOLUTE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;ACCESS&#39;: tokens.Keyword, &#39;ADA&#39;: tokens.Keyword, &#39;ADD&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;ADMIN&#39;: tokens.Keyword, &#39;AFTER&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;AGGREGATE&#39;: tokens.Keyword, &#39;ALIAS&#39;: tokens.Keyword, &#39;ALL&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;ALLOCATE&#39;: tokens.Keyword, &#39;ANALYSE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;ANALYZE&#39;: tokens.Keyword, &#39;ANY&#39;: tokens.Keyword, &#39;ARRAYLEN&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;ARE&#39;: tokens.Keyword, &#39;ASENSITIVE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;ASSERTION&#39;: tokens.Keyword, &#39;ASSIGNMENT&#39;: tokens.Keyword, &#39;ASYMMETRIC&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;AT&#39;: tokens.Keyword, &#39;ATOMIC&#39;: tokens.Keyword, &#39;AUDIT&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;AUTHORIZATION&#39;: tokens.Keyword, &#39;AUTO_INCREMENT&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;AVG&#39;: tokens.Keyword, &#39;BACKWARD&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;BEFORE&#39;: tokens.Keyword, &#39;BEGIN&#39;: tokens.Keyword, &#39;BETWEEN&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;BITVAR&#39;: tokens.Keyword, &#39;BIT_LENGTH&#39;: tokens.Keyword, &#39;BOTH&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;BREADTH&#39;: tokens.Keyword, &#39;CACHE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;CALL&#39;: tokens.Keyword, &#39;CALLED&#39;: tokens.Keyword, &#39;CARDINALITY&#39;: tokens</span>
<span class="gd">-    .Keyword, &#39;CASCADE&#39;: tokens.Keyword, &#39;CASCADED&#39;: tokens.Keyword, &#39;CAST&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;CATALOG&#39;: tokens.Keyword, &#39;CATALOG_NAME&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;CHAIN&#39;: tokens.Keyword, &#39;CHARACTERISTICS&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;CHARACTER_LENGTH&#39;: tokens.Keyword, &#39;CHARACTER_SET_CATALOG&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;CHARACTER_SET_NAME&#39;: tokens.Keyword, &#39;CHARACTER_SET_SCHEMA&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;CHAR_LENGTH&#39;: tokens.Keyword, &#39;CHARSET&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;CHECK&#39;: tokens.Keyword, &#39;CHECKED&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;CHECKPOINT&#39;: tokens.Keyword, &#39;CLASS&#39;: tokens.Keyword, &#39;CLASS_ORIGIN&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;CLOB&#39;: tokens.Keyword, &#39;CLOSE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;CLUSTER&#39;: tokens.Keyword, &#39;COALESCE&#39;: tokens.Keyword, &#39;COBOL&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;COLLATE&#39;: tokens.Keyword, &#39;COLLATION&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;COLLATION_CATALOG&#39;: tokens.Keyword, &#39;COLLATION_NAME&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;COLLATION_SCHEMA&#39;: tokens.Keyword, &#39;COLLECT&#39;: tokens.Keyword, &#39;COLUMN&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;COLUMN_NAME&#39;: tokens.Keyword, &#39;COMPRESS&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;COMMAND_FUNCTION&#39;: tokens.Keyword, &#39;COMMAND_FUNCTION_CODE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;COMMENT&#39;: tokens.Keyword, &#39;COMMIT&#39;: tokens.Keyword.DML,</span>
<span class="gd">-    &#39;COMMITTED&#39;: tokens.Keyword, &#39;COMPLETION&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;CONCURRENTLY&#39;: tokens.Keyword, &#39;CONDITION_NUMBER&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;CONNECT&#39;: tokens.Keyword, &#39;CONNECTION&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;CONNECTION_NAME&#39;: tokens.Keyword, &#39;CONSTRAINT&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;CONSTRAINTS&#39;: tokens.Keyword, &#39;CONSTRAINT_CATALOG&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;CONSTRAINT_NAME&#39;: tokens.Keyword, &#39;CONSTRAINT_SCHEMA&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;CONSTRUCTOR&#39;: tokens.Keyword, &#39;CONTAINS&#39;: tokens.Keyword, &#39;CONTINUE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;CONVERSION&#39;: tokens.Keyword, &#39;CONVERT&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;COPY&#39;: tokens.Keyword, &#39;CORRESPONDING&#39;: tokens.Keyword, &#39;COUNT&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;CREATEDB&#39;: tokens.Keyword, &#39;CREATEUSER&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;CROSS&#39;: tokens.Keyword, &#39;CUBE&#39;: tokens.Keyword, &#39;CURRENT&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;CURRENT_DATE&#39;: tokens.Keyword, &#39;CURRENT_PATH&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;CURRENT_ROLE&#39;: tokens.Keyword, &#39;CURRENT_TIME&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;CURRENT_TIMESTAMP&#39;: tokens.Keyword, &#39;CURRENT_USER&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;CURSOR&#39;: tokens.Keyword, &#39;CURSOR_NAME&#39;: tokens.Keyword, &#39;CYCLE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;DATA&#39;: tokens.Keyword, &#39;DATABASE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;DATETIME_INTERVAL_CODE&#39;: tokens.Keyword, &#39;DATETIME_INTERVAL_PRECISION&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;DAY&#39;: tokens.Keyword, &#39;DEALLOCATE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;DECLARE&#39;: tokens.Keyword, &#39;DEFAULT&#39;: tokens.Keyword, &#39;DEFAULTS&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;DEFERRABLE&#39;: tokens.Keyword, &#39;DEFERRED&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;DEFINED&#39;: tokens.Keyword, &#39;DEFINER&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;DELIMITER&#39;: tokens.Keyword, &#39;DELIMITERS&#39;: tokens.Keyword, &#39;DEREF&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;DESCRIBE&#39;: tokens.Keyword, &#39;DESCRIPTOR&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;DESTROY&#39;: tokens.Keyword, &#39;DESTRUCTOR&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;DETERMINISTIC&#39;: tokens.Keyword, &#39;DIAGNOSTICS&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;DICTIONARY&#39;: tokens.Keyword, &#39;DISABLE&#39;: tokens.Keyword, &#39;DISCONNECT&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;DISPATCH&#39;: tokens.Keyword, &#39;DIV&#39;: tokens.Operator,</span>
<span class="gd">-    &#39;DO&#39;: tokens.Keyword, &#39;DOMAIN&#39;: tokens.Keyword, &#39;DYNAMIC&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;DYNAMIC_FUNCTION&#39;: tokens.Keyword, &#39;DYNAMIC_FUNCTION_CODE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;EACH&#39;: tokens.Keyword, &#39;ENABLE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;ENCODING&#39;: tokens.Keyword, &#39;ENCRYPTED&#39;: tokens.Keyword, &#39;END-EXEC&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;ENGINE&#39;: tokens.Keyword, &#39;EQUALS&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;ESCAPE&#39;: tokens.Keyword, &#39;EVERY&#39;: tokens.Keyword, &#39;EXCEPT&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;EXCEPTION&#39;: tokens.Keyword, &#39;EXCLUDING&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;EXCLUSIVE&#39;: tokens.Keyword, &#39;EXEC&#39;: tokens.Keyword, &#39;EXECUTE&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;EXISTING&#39;: tokens.Keyword, &#39;EXISTS&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;EXPLAIN&#39;: tokens.Keyword, &#39;EXTERNAL&#39;: tokens.Keyword, &#39;EXTRACT&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;FALSE&#39;: tokens.Keyword, &#39;FETCH&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;FILE&#39;: tokens.Keyword, &#39;FINAL&#39;: tokens.Keyword, &#39;FIRST&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;FORCE&#39;: tokens.Keyword, &#39;FOREACH&#39;: tokens.Keyword, &#39;FOREIGN&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;FORTRAN&#39;: tokens.Keyword, &#39;FORWARD&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;FOUND&#39;: tokens.Keyword, &#39;FREE&#39;: tokens.Keyword, &#39;FREEZE&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;FULL&#39;: tokens.Keyword, &#39;FUNCTION&#39;: tokens.Keyword, &#39;GENERAL&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;GENERATED&#39;: tokens.Keyword, &#39;GET&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;GLOBAL&#39;: tokens.Keyword, &#39;GO&#39;: tokens.Keyword, &#39;GOTO&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;GRANTED&#39;: tokens.Keyword, &#39;GROUPING&#39;: tokens.Keyword, &#39;HAVING&#39;: tokens</span>
<span class="gd">-    .Keyword, &#39;HIERARCHY&#39;: tokens.Keyword, &#39;HOLD&#39;: tokens.Keyword, &#39;HOUR&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;HOST&#39;: tokens.Keyword, &#39;IDENTIFIED&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;IDENTITY&#39;: tokens.Keyword, &#39;IGNORE&#39;: tokens.Keyword, &#39;ILIKE&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;IMMEDIATE&#39;: tokens.Keyword, &#39;IMMUTABLE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;IMPLEMENTATION&#39;: tokens.Keyword, &#39;IMPLICIT&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;INCLUDING&#39;: tokens.Keyword, &#39;INCREMENT&#39;: tokens.Keyword, &#39;INDEX&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;INDICATOR&#39;: tokens.Keyword, &#39;INFIX&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;INHERITS&#39;: tokens.Keyword, &#39;INITIAL&#39;: tokens.Keyword, &#39;INITIALIZE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;INITIALLY&#39;: tokens.Keyword, &#39;INOUT&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;INPUT&#39;: tokens.Keyword, &#39;INSENSITIVE&#39;: tokens.Keyword, &#39;INSTANTIABLE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;INSTEAD&#39;: tokens.Keyword, &#39;INTERSECT&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;INTO&#39;: tokens.Keyword, &#39;INVOKER&#39;: tokens.Keyword, &#39;IS&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;ISNULL&#39;: tokens.Keyword, &#39;ISOLATION&#39;: tokens.Keyword, &#39;ITERATE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;KEY&#39;: tokens.Keyword, &#39;KEY_MEMBER&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;KEY_TYPE&#39;: tokens.Keyword, &#39;LANCOMPILER&#39;: tokens.Keyword, &#39;LANGUAGE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;LARGE&#39;: tokens.Keyword, &#39;LAST&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;LATERAL&#39;: tokens.Keyword, &#39;LEADING&#39;: tokens.Keyword, &#39;LENGTH&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;LESS&#39;: tokens.Keyword, &#39;LEVEL&#39;: tokens.Keyword, &#39;LIMIT&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;LISTEN&#39;: tokens.Keyword, &#39;LOAD&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;LOCAL&#39;: tokens.Keyword, &#39;LOCALTIME&#39;: tokens.Keyword, &#39;LOCALTIMESTAMP&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;LOCATION&#39;: tokens.Keyword, &#39;LOCATOR&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;LOCK&#39;: tokens.Keyword, &#39;LOWER&#39;: tokens.Keyword, &#39;MAP&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;MATCH&#39;: tokens.Keyword, &#39;MAXEXTENTS&#39;: tokens.Keyword, &#39;MAXVALUE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;MESSAGE_LENGTH&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;MESSAGE_OCTET_LENGTH&#39;: tokens.Keyword, &#39;MESSAGE_TEXT&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;METHOD&#39;: tokens.Keyword, &#39;MINUTE&#39;: tokens.Keyword, &#39;MINUS&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;MINVALUE&#39;: tokens.Keyword, &#39;MOD&#39;: tokens.Keyword, &#39;MODE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;MODIFIES&#39;: tokens.Keyword, &#39;MODIFY&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;MONTH&#39;: tokens.Keyword, &#39;MORE&#39;: tokens.Keyword, &#39;MOVE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;MUMPS&#39;: tokens.Keyword, &#39;NAMES&#39;: tokens.Keyword, &#39;NATIONAL&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;NATURAL&#39;: tokens.Keyword, &#39;NCHAR&#39;: tokens.Keyword, &#39;NCLOB&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;NEW&#39;: tokens.Keyword, &#39;NEXT&#39;: tokens.Keyword, &#39;NO&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;NOAUDIT&#39;: tokens.Keyword, &#39;NOCOMPRESS&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;NOCREATEDB&#39;: tokens.Keyword, &#39;NOCREATEUSER&#39;: tokens.Keyword, &#39;NONE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;NOT&#39;: tokens.Keyword, &#39;NOTFOUND&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;NOTHING&#39;: tokens.Keyword, &#39;NOTIFY&#39;: tokens.Keyword, &#39;NOTNULL&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;NOWAIT&#39;: tokens.Keyword, &#39;NULL&#39;: tokens.Keyword, &#39;NULLABLE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;NULLIF&#39;: tokens.Keyword, &#39;OBJECT&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;OCTET_LENGTH&#39;: tokens.Keyword, &#39;OF&#39;: tokens.Keyword, &#39;OFF&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;OFFLINE&#39;: tokens.Keyword, &#39;OFFSET&#39;: tokens.Keyword, &#39;OIDS&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;OLD&#39;: tokens.Keyword, &#39;ONLINE&#39;: tokens.Keyword, &#39;ONLY&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;OPEN&#39;: tokens.Keyword, &#39;OPERATION&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;OPERATOR&#39;: tokens.Keyword, &#39;OPTION&#39;: tokens.Keyword, &#39;OPTIONS&#39;: tokens</span>
<span class="gd">-    .Keyword, &#39;ORDINALITY&#39;: tokens.Keyword, &#39;OUT&#39;: tokens.Keyword, &#39;OUTPUT&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;OVERLAPS&#39;: tokens.Keyword, &#39;OVERLAY&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;OVERRIDING&#39;: tokens.Keyword, &#39;OWNER&#39;: tokens.Keyword, &#39;QUARTER&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;PAD&#39;: tokens.Keyword, &#39;PARAMETER&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;PARAMETERS&#39;: tokens.Keyword, &#39;PARAMETER_MODE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;PARAMETER_NAME&#39;: tokens.Keyword, &#39;PARAMETER_ORDINAL_POSITION&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;PARAMETER_SPECIFIC_CATALOG&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;PARAMETER_SPECIFIC_NAME&#39;: tokens.Keyword, &#39;PARAMETER_SPECIFIC_SCHEMA&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;PARTIAL&#39;: tokens.Keyword, &#39;PASCAL&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;PCTFREE&#39;: tokens.Keyword, &#39;PENDANT&#39;: tokens.Keyword, &#39;PLACING&#39;: tokens</span>
<span class="gd">-    .Keyword, &#39;PLI&#39;: tokens.Keyword, &#39;POSITION&#39;: tokens.Keyword, &#39;POSTFIX&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;PRECISION&#39;: tokens.Keyword, &#39;PREFIX&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;PREORDER&#39;: tokens.Keyword, &#39;PREPARE&#39;: tokens.Keyword, &#39;PRESERVE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;PRIMARY&#39;: tokens.Keyword, &#39;PRIOR&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;PRIVILEGES&#39;: tokens.Keyword, &#39;PROCEDURAL&#39;: tokens.Keyword, &#39;PROCEDURE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;PUBLIC&#39;: tokens.Keyword, &#39;RAISE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;RAW&#39;: tokens.Keyword, &#39;READ&#39;: tokens.Keyword, &#39;READS&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;RECHECK&#39;: tokens.Keyword, &#39;RECURSIVE&#39;: tokens.Keyword, &#39;REF&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;REFERENCES&#39;: tokens.Keyword, &#39;REFERENCING&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;REINDEX&#39;: tokens.Keyword, &#39;RELATIVE&#39;: tokens.Keyword, &#39;RENAME&#39;: tokens</span>
<span class="gd">-    .Keyword, &#39;REPEATABLE&#39;: tokens.Keyword, &#39;RESET&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;RESOURCE&#39;: tokens.Keyword, &#39;RESTART&#39;: tokens.Keyword, &#39;RESTRICT&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;RESULT&#39;: tokens.Keyword, &#39;RETURN&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;RETURNED_LENGTH&#39;: tokens.Keyword, &#39;RETURNED_OCTET_LENGTH&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;RETURNED_SQLSTATE&#39;: tokens.Keyword, &#39;RETURNING&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;RETURNS&#39;: tokens.Keyword, &#39;RIGHT&#39;: tokens.Keyword, &#39;ROLE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;ROLLBACK&#39;: tokens.Keyword.DML, &#39;ROLLUP&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;ROUTINE&#39;: tokens.Keyword, &#39;ROUTINE_CATALOG&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;ROUTINE_NAME&#39;: tokens.Keyword, &#39;ROUTINE_SCHEMA&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;ROWS&#39;: tokens.Keyword, &#39;ROW_COUNT&#39;: tokens.Keyword, &#39;RULE&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;SAVE_POINT&#39;: tokens.Keyword, &#39;SCALE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;SCHEMA&#39;: tokens.Keyword, &#39;SCHEMA_NAME&#39;: tokens.Keyword, &#39;SCOPE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;SCROLL&#39;: tokens.Keyword, &#39;SEARCH&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;SECOND&#39;: tokens.Keyword, &#39;SECURITY&#39;: tokens.Keyword, &#39;SELF&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;SENSITIVE&#39;: tokens.Keyword, &#39;SEQUENCE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;SERIALIZABLE&#39;: tokens.Keyword, &#39;SERVER_NAME&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;SESSION&#39;: tokens.Keyword, &#39;SESSION_USER&#39;: tokens.Keyword, &#39;SETOF&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;SETS&#39;: tokens.Keyword, &#39;SHARE&#39;: tokens.Keyword, &#39;SHOW&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;SIMILAR&#39;: tokens.Keyword, &#39;SIMPLE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;SIZE&#39;: tokens.Keyword, &#39;SOME&#39;: tokens.Keyword, &#39;SOURCE&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;SPACE&#39;: tokens.Keyword, &#39;SPECIFIC&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;SPECIFICTYPE&#39;: tokens.Keyword, &#39;SPECIFIC_NAME&#39;: tokens.Keyword, &#39;SQL&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;SQLBUF&#39;: tokens.Keyword, &#39;SQLCODE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;SQLERROR&#39;: tokens.Keyword, &#39;SQLEXCEPTION&#39;: tokens.Keyword, &#39;SQLSTATE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;SQLWARNING&#39;: tokens.Keyword, &#39;STABLE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;START&#39;: tokens.Keyword.DML, &#39;STATEMENT&#39;: tokens.Keyword, &#39;STATIC&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;STATISTICS&#39;: tokens.Keyword, &#39;STDIN&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;STDOUT&#39;: tokens.Keyword, &#39;STORAGE&#39;: tokens.Keyword, &#39;STRICT&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;STRUCTURE&#39;: tokens.Keyword, &#39;STYPE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;SUBCLASS_ORIGIN&#39;: tokens.Keyword, &#39;SUBLIST&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;SUBSTRING&#39;: tokens.Keyword, &#39;SUCCESSFUL&#39;: tokens.Keyword, &#39;SUM&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;SYMMETRIC&#39;: tokens.Keyword, &#39;SYNONYM&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;SYSID&#39;: tokens.Keyword, &#39;SYSTEM&#39;: tokens.Keyword, &#39;SYSTEM_USER&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;TABLE&#39;: tokens.Keyword, &#39;TABLE_NAME&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;TEMP&#39;: tokens.Keyword, &#39;TEMPLATE&#39;: tokens.Keyword, &#39;TEMPORARY&#39;: tokens</span>
<span class="gd">-    .Keyword, &#39;TERMINATE&#39;: tokens.Keyword, &#39;THAN&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;TIMESTAMP&#39;: tokens.Keyword, &#39;TIMEZONE_HOUR&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;TIMEZONE_MINUTE&#39;: tokens.Keyword, &#39;TO&#39;: tokens.Keyword, &#39;TOAST&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;TRAILING&#39;: tokens.Keyword, &#39;TRANSATION&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;TRANSACTIONS_COMMITTED&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;TRANSACTIONS_ROLLED_BACK&#39;: tokens.Keyword, &#39;TRANSATION_ACTIVE&#39;: tokens</span>
<span class="gd">-    .Keyword, &#39;TRANSFORM&#39;: tokens.Keyword, &#39;TRANSFORMS&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;TRANSLATE&#39;: tokens.Keyword, &#39;TRANSLATION&#39;: tokens.Keyword, &#39;TREAT&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;TRIGGER&#39;: tokens.Keyword, &#39;TRIGGER_CATALOG&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;TRIGGER_NAME&#39;: tokens.Keyword, &#39;TRIGGER_SCHEMA&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;TRIM&#39;: tokens.Keyword, &#39;TRUE&#39;: tokens.Keyword, &#39;TRUSTED&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;TYPE&#39;: tokens.Keyword, &#39;UID&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;UNCOMMITTED&#39;: tokens.Keyword, &#39;UNDER&#39;: tokens.Keyword, &#39;UNENCRYPTED&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;UNION&#39;: tokens.Keyword, &#39;UNIQUE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;UNKNOWN&#39;: tokens.Keyword, &#39;UNLISTEN&#39;: tokens.Keyword, &#39;UNNAMED&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;UNNEST&#39;: tokens.Keyword, &#39;UNTIL&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;UPPER&#39;: tokens.Keyword, &#39;USAGE&#39;: tokens.Keyword, &#39;USE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;USER&#39;: tokens.Keyword, &#39;USER_DEFINED_TYPE_CATALOG&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;USER_DEFINED_TYPE_NAME&#39;: tokens.Keyword, &#39;USER_DEFINED_TYPE_SCHEMA&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;USING&#39;: tokens.Keyword, &#39;VACUUM&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;VALID&#39;: tokens.Keyword, &#39;VALIDATE&#39;: tokens.Keyword, &#39;VALIDATOR&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;VALUES&#39;: tokens.Keyword, &#39;VARIABLE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;VERBOSE&#39;: tokens.Keyword, &#39;VERSION&#39;: tokens.Keyword, &#39;VIEW&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;VOLATILE&#39;: tokens.Keyword, &#39;WEEK&#39;: tokens.Keyword, &#39;WHENEVER&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;WITH&#39;: tokens.Keyword.CTE, &#39;WITHOUT&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;WORK&#39;: tokens.Keyword, &#39;WRITE&#39;: tokens.Keyword, &#39;YEAR&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;ZONE&#39;: tokens.Keyword, &#39;ARRAY&#39;: tokens.Name.Builtin, &#39;BIGINT&#39;: tokens.</span>
<span class="gd">-    Name.Builtin, &#39;BINARY&#39;: tokens.Name.Builtin, &#39;BIT&#39;: tokens.Name.Builtin,</span>
<span class="gd">-    &#39;BLOB&#39;: tokens.Name.Builtin, &#39;BOOLEAN&#39;: tokens.Name.Builtin, &#39;CHAR&#39;:</span>
<span class="gd">-    tokens.Name.Builtin, &#39;CHARACTER&#39;: tokens.Name.Builtin, &#39;DATE&#39;: tokens.</span>
<span class="gd">-    Name.Builtin, &#39;DEC&#39;: tokens.Name.Builtin, &#39;DECIMAL&#39;: tokens.Name.</span>
<span class="gd">-    Builtin, &#39;FILE_TYPE&#39;: tokens.Name.Builtin, &#39;FLOAT&#39;: tokens.Name.Builtin,</span>
<span class="gd">-    &#39;INT&#39;: tokens.Name.Builtin, &#39;INT8&#39;: tokens.Name.Builtin, &#39;INTEGER&#39;:</span>
<span class="gd">-    tokens.Name.Builtin, &#39;INTERVAL&#39;: tokens.Name.Builtin, &#39;LONG&#39;: tokens.</span>
<span class="gd">-    Name.Builtin, &#39;NATURALN&#39;: tokens.Name.Builtin, &#39;NVARCHAR&#39;: tokens.Name.</span>
<span class="gd">-    Builtin, &#39;NUMBER&#39;: tokens.Name.Builtin, &#39;NUMERIC&#39;: tokens.Name.Builtin,</span>
<span class="gd">-    &#39;PLS_INTEGER&#39;: tokens.Name.Builtin, &#39;POSITIVE&#39;: tokens.Name.Builtin,</span>
<span class="gd">-    &#39;POSITIVEN&#39;: tokens.Name.Builtin, &#39;REAL&#39;: tokens.Name.Builtin, &#39;ROWID&#39;:</span>
<span class="gd">-    tokens.Name.Builtin, &#39;ROWLABEL&#39;: tokens.Name.Builtin, &#39;ROWNUM&#39;: tokens.</span>
<span class="gd">-    Name.Builtin, &#39;SERIAL&#39;: tokens.Name.Builtin, &#39;SERIAL8&#39;: tokens.Name.</span>
<span class="gd">-    Builtin, &#39;SIGNED&#39;: tokens.Name.Builtin, &#39;SIGNTYPE&#39;: tokens.Name.Builtin,</span>
<span class="gd">-    &#39;SIMPLE_DOUBLE&#39;: tokens.Name.Builtin, &#39;SIMPLE_FLOAT&#39;: tokens.Name.</span>
<span class="gd">-    Builtin, &#39;SIMPLE_INTEGER&#39;: tokens.Name.Builtin, &#39;SMALLINT&#39;: tokens.Name</span>
<span class="gd">-    .Builtin, &#39;SYS_REFCURSOR&#39;: tokens.Name.Builtin, &#39;SYSDATE&#39;: tokens.Name,</span>
<span class="gd">-    &#39;TEXT&#39;: tokens.Name.Builtin, &#39;TINYINT&#39;: tokens.Name.Builtin, &#39;UNSIGNED&#39;:</span>
<span class="gd">-    tokens.Name.Builtin, &#39;UROWID&#39;: tokens.Name.Builtin, &#39;UTL_FILE&#39;: tokens.</span>
<span class="gd">-    Name.Builtin, &#39;VARCHAR&#39;: tokens.Name.Builtin, &#39;VARCHAR2&#39;: tokens.Name.</span>
<span class="gd">-    Builtin, &#39;VARYING&#39;: tokens.Name.Builtin}</span>
<span class="gd">-KEYWORDS_COMMON = {&#39;SELECT&#39;: tokens.Keyword.DML, &#39;INSERT&#39;: tokens.Keyword.</span>
<span class="gd">-    DML, &#39;DELETE&#39;: tokens.Keyword.DML, &#39;UPDATE&#39;: tokens.Keyword.DML,</span>
<span class="gd">-    &#39;UPSERT&#39;: tokens.Keyword.DML, &#39;REPLACE&#39;: tokens.Keyword.DML, &#39;MERGE&#39;:</span>
<span class="gd">-    tokens.Keyword.DML, &#39;DROP&#39;: tokens.Keyword.DDL, &#39;CREATE&#39;: tokens.</span>
<span class="gd">-    Keyword.DDL, &#39;ALTER&#39;: tokens.Keyword.DDL, &#39;TRUNCATE&#39;: tokens.Keyword.</span>
<span class="gd">-    DDL, &#39;GRANT&#39;: tokens.Keyword.DCL, &#39;REVOKE&#39;: tokens.Keyword.DCL, &#39;WHERE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;FROM&#39;: tokens.Keyword, &#39;INNER&#39;: tokens.Keyword, &#39;JOIN&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;STRAIGHT_JOIN&#39;: tokens.Keyword, &#39;AND&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;OR&#39;: tokens.Keyword, &#39;LIKE&#39;: tokens.Keyword, &#39;ON&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;IN&#39;: tokens.Keyword, &#39;SET&#39;: tokens.Keyword, &#39;BY&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;GROUP&#39;: tokens.Keyword, &#39;ORDER&#39;: tokens.Keyword, &#39;LEFT&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;OUTER&#39;: tokens.Keyword, &#39;FULL&#39;: tokens.Keyword, &#39;IF&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;END&#39;: tokens.Keyword, &#39;THEN&#39;: tokens.Keyword, &#39;LOOP&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;AS&#39;: tokens.Keyword, &#39;ELSE&#39;: tokens.Keyword, &#39;FOR&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;WHILE&#39;: tokens.Keyword, &#39;CASE&#39;: tokens.Keyword, &#39;WHEN&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;MIN&#39;: tokens.Keyword, &#39;MAX&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;DISTINCT&#39;: tokens.Keyword}</span>
<span class="gd">-KEYWORDS_ORACLE = {&#39;ARCHIVE&#39;: tokens.Keyword, &#39;ARCHIVELOG&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;BACKUP&#39;: tokens.Keyword, &#39;BECOME&#39;: tokens.Keyword, &#39;BLOCK&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;BODY&#39;: tokens.Keyword, &#39;CANCEL&#39;: tokens.Keyword, &#39;CHANGE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;COMPILE&#39;: tokens.Keyword, &#39;CONTENTS&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;CONTROLFILE&#39;: tokens.Keyword, &#39;DATAFILE&#39;: tokens.Keyword, &#39;DBA&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;DISMOUNT&#39;: tokens.Keyword, &#39;DOUBLE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;DUMP&#39;: tokens.Keyword, &#39;ELSIF&#39;: tokens.Keyword, &#39;EVENTS&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;EXCEPTIONS&#39;: tokens.Keyword, &#39;EXPLAIN&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;EXTENT&#39;: tokens.Keyword, &#39;EXTERNALLY&#39;: tokens.Keyword, &#39;FLUSH&#39;: tokens</span>
<span class="gd">-    .Keyword, &#39;FREELIST&#39;: tokens.Keyword, &#39;FREELISTS&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;INDICATOR&#39;: tokens.Keyword, &#39;INITRANS&#39;: tokens.Keyword, &#39;INSTANCE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;LAYER&#39;: tokens.Keyword, &#39;LINK&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;LISTS&#39;: tokens.Keyword, &#39;LOGFILE&#39;: tokens.Keyword, &#39;MANAGE&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;MANUAL&#39;: tokens.Keyword, &#39;MAXDATAFILES&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;MAXINSTANCES&#39;: tokens.Keyword, &#39;MAXLOGFILES&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;MAXLOGHISTORY&#39;: tokens.Keyword, &#39;MAXLOGMEMBERS&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;MAXTRANS&#39;: tokens.Keyword, &#39;MINEXTENTS&#39;: tokens.Keyword, &#39;MODULE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;MOUNT&#39;: tokens.Keyword, &#39;NOARCHIVELOG&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;NOCACHE&#39;: tokens.Keyword, &#39;NOCYCLE&#39;: tokens.Keyword, &#39;NOMAXVALUE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;NOMINVALUE&#39;: tokens.Keyword, &#39;NOORDER&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;NORESETLOGS&#39;: tokens.Keyword, &#39;NORMAL&#39;: tokens.Keyword, &#39;NOSORT&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;OPTIMAL&#39;: tokens.Keyword, &#39;OWN&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;PACKAGE&#39;: tokens.Keyword, &#39;PARALLEL&#39;: tokens.Keyword, &#39;PCTINCREASE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;PCTUSED&#39;: tokens.Keyword, &#39;PLAN&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;PRIVATE&#39;: tokens.Keyword, &#39;PROFILE&#39;: tokens.Keyword, &#39;QUOTA&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;RECOVER&#39;: tokens.Keyword, &#39;RESETLOGS&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;RESTRICTED&#39;: tokens.Keyword, &#39;REUSE&#39;: tokens.Keyword, &#39;ROLES&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;SAVEPOINT&#39;: tokens.Keyword, &#39;SCN&#39;: tokens.Keyword, &#39;SECTION&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;SEGMENT&#39;: tokens.Keyword, &#39;SHARED&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;SNAPSHOT&#39;: tokens.Keyword, &#39;SORT&#39;: tokens.Keyword, &#39;STATEMENT_ID&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;STOP&#39;: tokens.Keyword, &#39;SWITCH&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;TABLES&#39;: tokens.Keyword, &#39;TABLESPACE&#39;: tokens.Keyword, &#39;THREAD&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;TIME&#39;: tokens.Keyword, &#39;TRACING&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;TRANSACTION&#39;: tokens.Keyword, &#39;TRIGGERS&#39;: tokens.Keyword, &#39;UNLIMITED&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;UNLOCK&#39;: tokens.Keyword}</span>
<span class="gd">-KEYWORDS_MYSQL = {&#39;ROW&#39;: tokens.Keyword}</span>
<span class="gd">-KEYWORDS_PLPGSQL = {&#39;CONFLICT&#39;: tokens.Keyword, &#39;WINDOW&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;PARTITION&#39;: tokens.Keyword, &#39;OVER&#39;: tokens.Keyword, &#39;PERFORM&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;NOTICE&#39;: tokens.Keyword, &#39;PLPGSQL&#39;: tokens.Keyword, &#39;INHERIT&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;INDEXES&#39;: tokens.Keyword, &#39;ON_ERROR_STOP&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;BYTEA&#39;: tokens.Keyword, &#39;BIGSERIAL&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;BIT VARYING&#39;: tokens.Keyword, &#39;BOX&#39;: tokens.Keyword, &#39;CHARACTER&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;CHARACTER VARYING&#39;: tokens.Keyword, &#39;CIDR&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;CIRCLE&#39;: tokens.Keyword, &#39;DOUBLE PRECISION&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;INET&#39;: tokens.Keyword, &#39;JSON&#39;: tokens.Keyword, &#39;JSONB&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;LINE&#39;: tokens.Keyword, &#39;LSEG&#39;: tokens.Keyword, &#39;MACADDR&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;MONEY&#39;: tokens.Keyword, &#39;PATH&#39;: tokens.Keyword, &#39;PG_LSN&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;POINT&#39;: tokens.Keyword, &#39;POLYGON&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;SMALLSERIAL&#39;: tokens.Keyword, &#39;TSQUERY&#39;: tokens.Keyword, &#39;TSVECTOR&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;TXID_SNAPSHOT&#39;: tokens.Keyword, &#39;UUID&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;XML&#39;: tokens.Keyword, &#39;FOR&#39;: tokens.Keyword, &#39;IN&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;LOOP&#39;: tokens.Keyword}</span>
<span class="gd">-KEYWORDS_HQL = {&#39;EXPLODE&#39;: tokens.Keyword, &#39;DIRECTORY&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;DISTRIBUTE&#39;: tokens.Keyword, &#39;INCLUDE&#39;: tokens.Keyword, &#39;LOCATE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;OVERWRITE&#39;: tokens.Keyword, &#39;POSEXPLODE&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;ARRAY_CONTAINS&#39;: tokens.Keyword, &#39;CMP&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;COLLECT_LIST&#39;: tokens.Keyword, &#39;CONCAT&#39;: tokens.Keyword, &#39;CONDITION&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;DATE_ADD&#39;: tokens.Keyword, &#39;DATE_SUB&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;DECODE&#39;: tokens.Keyword, &#39;DBMS_OUTPUT&#39;: tokens.Keyword, &#39;ELEMENTS&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;EXCHANGE&#39;: tokens.Keyword, &#39;EXTENDED&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;FLOOR&#39;: tokens.Keyword, &#39;FOLLOWING&#39;: tokens.Keyword, &#39;FROM_UNIXTIME&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;FTP&#39;: tokens.Keyword, &#39;HOUR&#39;: tokens.Keyword, &#39;INLINE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;INSTR&#39;: tokens.Keyword, &#39;LEN&#39;: tokens.Keyword, &#39;MAP&#39;:</span>
<span class="gd">-    tokens.Name.Builtin, &#39;MAXELEMENT&#39;: tokens.Keyword, &#39;MAXINDEX&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;MAX_PART_DATE&#39;: tokens.Keyword, &#39;MAX_PART_INT&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;MAX_PART_STRING&#39;: tokens.Keyword, &#39;MINELEMENT&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;MININDEX&#39;: tokens.Keyword, &#39;MIN_PART_DATE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;MIN_PART_INT&#39;: tokens.Keyword, &#39;MIN_PART_STRING&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;NOW&#39;: tokens.Keyword, &#39;NVL&#39;: tokens.Keyword, &#39;NVL2&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;PARSE_URL_TUPLE&#39;: tokens.Keyword, &#39;PART_LOC&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;PART_COUNT&#39;: tokens.Keyword, &#39;PART_COUNT_BY&#39;: tokens.Keyword, &#39;PRINT&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;PUT_LINE&#39;: tokens.Keyword, &#39;RANGE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;REDUCE&#39;: tokens.Keyword, &#39;REGEXP_REPLACE&#39;: tokens.Keyword, &#39;RESIGNAL&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;RTRIM&#39;: tokens.Keyword, &#39;SIGN&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;SIGNAL&#39;: tokens.Keyword, &#39;SIN&#39;: tokens.Keyword, &#39;SPLIT&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;SQRT&#39;: tokens.Keyword, &#39;STACK&#39;: tokens.Keyword, &#39;STR&#39;: tokens</span>
<span class="gd">-    .Keyword, &#39;STRING&#39;: tokens.Name.Builtin, &#39;STRUCT&#39;: tokens.Name.Builtin,</span>
<span class="gd">-    &#39;SUBSTR&#39;: tokens.Keyword, &#39;SUMMARY&#39;: tokens.Keyword, &#39;TBLPROPERTIES&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;TIMESTAMP&#39;: tokens.Name.Builtin, &#39;TIMESTAMP_ISO&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;TO_CHAR&#39;: tokens.Keyword, &#39;TO_DATE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;TO_TIMESTAMP&#39;: tokens.Keyword, &#39;TRUNC&#39;: tokens.Keyword, &#39;UNBOUNDED&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;UNIQUEJOIN&#39;: tokens.Keyword, &#39;UNIX_TIMESTAMP&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;UTC_TIMESTAMP&#39;: tokens.Keyword, &#39;VIEWS&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;EXIT&#39;: tokens.Keyword, &#39;BREAK&#39;: tokens.Keyword, &#39;LEAVE&#39;: tokens.Keyword}</span>
<span class="gd">-KEYWORDS_MSACCESS = {&#39;DISTINCTROW&#39;: tokens.Keyword}</span>
<span class="gd">-KEYWORDS_SNOWFLAKE = {&#39;ACCOUNT&#39;: tokens.Keyword, &#39;GSCLUSTER&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;ISSUE&#39;: tokens.Keyword, &#39;ORGANIZATION&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;PIVOT&#39;: tokens.Keyword, &#39;QUALIFY&#39;: tokens.Keyword, &#39;REGEXP&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;RLIKE&#39;: tokens.Keyword, &#39;SAMPLE&#39;: tokens.Keyword, &#39;TRY_CAST&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;UNPIVOT&#39;: tokens.Keyword, &#39;VARIANT&#39;: tokens.Name.Builtin}</span>
<span class="gd">-KEYWORDS_BIGQUERY = {&#39;ASSERT_ROWS_MODIFIED&#39;: tokens.Keyword, &#39;DEFINE&#39;:</span>
<span class="gd">-    tokens.Keyword, &#39;ENUM&#39;: tokens.Keyword, &#39;HASH&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;LOOKUP&#39;: tokens.Keyword, &#39;PRECEDING&#39;: tokens.Keyword, &#39;PROTO&#39;: tokens.</span>
<span class="gd">-    Keyword, &#39;RESPECT&#39;: tokens.Keyword, &#39;TABLESAMPLE&#39;: tokens.Keyword,</span>
<span class="gd">-    &#39;BIGNUMERIC&#39;: tokens.Name.Builtin}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+SQL_REGEX = [</span>
<span class="gi">+    (r&#39;(--|# )\+.*?(\r\n|\r|\n|$)&#39;, tokens.Comment.Single.Hint),</span>
<span class="gi">+    (r&#39;/\*\+[\s\S]*?\*/&#39;, tokens.Comment.Multiline.Hint),</span>
<span class="gi">+</span>
<span class="gi">+    (r&#39;(--|# ).*?(\r\n|\r|\n|$)&#39;, tokens.Comment.Single),</span>
<span class="gi">+    (r&#39;/\*[\s\S]*?\*/&#39;, tokens.Comment.Multiline),</span>
<span class="gi">+</span>
<span class="gi">+    (r&#39;(\r\n|\r|\n)&#39;, tokens.Newline),</span>
<span class="gi">+    (r&#39;\s+?&#39;, tokens.Whitespace),</span>
<span class="gi">+</span>
<span class="gi">+    (r&#39;:=&#39;, tokens.Assignment),</span>
<span class="gi">+    (r&#39;::&#39;, tokens.Punctuation),</span>
<span class="gi">+</span>
<span class="gi">+    (r&#39;\*&#39;, tokens.Wildcard),</span>
<span class="gi">+</span>
<span class="gi">+    (r&quot;`(``|[^`])*`&quot;, tokens.Name),</span>
<span class="gi">+    (r&quot;(|[^])*&quot;, tokens.Name),</span>
<span class="gi">+    (r&#39;((?&lt;![\w\&quot;\$])\$(?:[_A-Z-]\w*)?\$)[\s\S]*?\1&#39;, tokens.Literal),</span>
<span class="gi">+</span>
<span class="gi">+    (r&#39;\?&#39;, tokens.Name.Placeholder),</span>
<span class="gi">+    (r&#39;%(\(\w+\))?s&#39;, tokens.Name.Placeholder),</span>
<span class="gi">+    (r&#39;(?&lt;!\w)[$:?]\w+&#39;, tokens.Name.Placeholder),</span>
<span class="gi">+</span>
<span class="gi">+    (r&#39;\\\w+&#39;, tokens.Command),</span>
<span class="gi">+</span>
<span class="gi">+    # FIXME(andi): VALUES shouldn&#39;t be listed here</span>
<span class="gi">+    # see https://github.com/andialbrecht/sqlparse/pull/64</span>
<span class="gi">+    # AS and IN are special, it may be followed by a parenthesis, but</span>
<span class="gi">+    # are never functions, see issue183 and issue507</span>
<span class="gi">+    (r&#39;(CASE|IN|VALUES|USING|FROM|AS)\b&#39;, tokens.Keyword),</span>
<span class="gi">+</span>
<span class="gi">+    (r&#39;(@|##|#)[A-Z-]\w+&#39;, tokens.Name),</span>
<span class="gi">+</span>
<span class="gi">+    # see issue #39</span>
<span class="gi">+    # Spaces around period `schema . name` are valid identifier</span>
<span class="gi">+    # TODO: Spaces before period not implemented</span>
<span class="gi">+    (r&#39;[A-Z-]\w*(?=\s*\.)&#39;, tokens.Name),  # &#39;Name&#39;.</span>
<span class="gi">+    # FIXME(atronah): never match,</span>
<span class="gi">+    # because `re.match` doesn&#39;t work with look-behind regexp feature</span>
<span class="gi">+    (r&#39;(?&lt;=\.)[A-Z-]\w*&#39;, tokens.Name),  # .&#39;Name&#39;</span>
<span class="gi">+    (r&#39;[A-Z-]\w*(?=\()&#39;, tokens.Name),  # side effect: change kw to func</span>
<span class="gi">+    (r&#39;-?0x[\dA-F]+&#39;, tokens.Number.Hexadecimal),</span>
<span class="gi">+    (r&#39;-?\d+(\.\d+)?E-?\d+&#39;, tokens.Number.Float),</span>
<span class="gi">+    (r&#39;(?![_A-Z-])-?(\d+(\.\d*)|\.\d+)(?![_A-Z-])&#39;,</span>
<span class="gi">+     tokens.Number.Float),</span>
<span class="gi">+    (r&#39;(?![_A-Z-])-?\d+(?![_A-Z-])&#39;, tokens.Number.Integer),</span>
<span class="gi">+    (r&quot;&#39;(&#39;&#39;|\\&#39;|[^&#39;])*&#39;&quot;, tokens.String.Single),</span>
<span class="gi">+    # not a real string literal in ANSI SQL:</span>
<span class="gi">+    (r&#39;&quot;(&quot;&quot;|\\&quot;|[^&quot;])*&quot;&#39;, tokens.String.Symbol),</span>
<span class="gi">+    (r&#39;(&quot;&quot;|&quot;.*?[^\\]&quot;)&#39;, tokens.String.Symbol),</span>
<span class="gi">+    # sqlite names can be escaped with [square brackets]. left bracket</span>
<span class="gi">+    # cannot be preceded by word character or a right bracket --</span>
<span class="gi">+    # otherwise it&#39;s probably an array index</span>
<span class="gi">+    (r&#39;(?&lt;![\w\])])(\[[^\]\[]+\])&#39;, tokens.Name),</span>
<span class="gi">+    (r&#39;((LEFT\s+|RIGHT\s+|FULL\s+)?(INNER\s+|OUTER\s+|STRAIGHT\s+)?&#39;</span>
<span class="gi">+     r&#39;|(CROSS\s+|NATURAL\s+)?)?JOIN\b&#39;, tokens.Keyword),</span>
<span class="gi">+    (r&#39;END(\s+IF|\s+LOOP|\s+WHILE)?\b&#39;, tokens.Keyword),</span>
<span class="gi">+    (r&#39;NOT\s+NULL\b&#39;, tokens.Keyword),</span>
<span class="gi">+    (r&#39;(ASC|DESC)(\s+NULLS\s+(FIRST|LAST))?\b&#39;, tokens.Keyword.Order),</span>
<span class="gi">+    (r&#39;(ASC|DESC)\b&#39;, tokens.Keyword.Order),</span>
<span class="gi">+    (r&#39;NULLS\s+(FIRST|LAST)\b&#39;, tokens.Keyword.Order),</span>
<span class="gi">+    (r&#39;UNION\s+ALL\b&#39;, tokens.Keyword),</span>
<span class="gi">+    (r&#39;CREATE(\s+OR\s+REPLACE)?\b&#39;, tokens.Keyword.DDL),</span>
<span class="gi">+    (r&#39;DOUBLE\s+PRECISION\b&#39;, tokens.Name.Builtin),</span>
<span class="gi">+    (r&#39;GROUP\s+BY\b&#39;, tokens.Keyword),</span>
<span class="gi">+    (r&#39;ORDER\s+BY\b&#39;, tokens.Keyword),</span>
<span class="gi">+    (r&#39;PRIMARY\s+KEY\b&#39;, tokens.Keyword),</span>
<span class="gi">+    (r&#39;HANDLER\s+FOR\b&#39;, tokens.Keyword),</span>
<span class="gi">+    (r&#39;GO(\s\d+)\b&#39;, tokens.Keyword),</span>
<span class="gi">+    (r&#39;(LATERAL\s+VIEW\s+)&#39;</span>
<span class="gi">+     r&#39;(EXPLODE|INLINE|PARSE_URL_TUPLE|POSEXPLODE|STACK)\b&#39;,</span>
<span class="gi">+     tokens.Keyword),</span>
<span class="gi">+    (r&quot;(AT|WITH&#39;)\s+TIME\s+ZONE\s+&#39;[^&#39;]+&#39;&quot;, tokens.Keyword.TZCast),</span>
<span class="gi">+    (r&#39;(NOT\s+)?(LIKE|ILIKE|RLIKE)\b&#39;, tokens.Operator.Comparison),</span>
<span class="gi">+    (r&#39;(NOT\s+)?(REGEXP)\b&#39;, tokens.Operator.Comparison),</span>
<span class="gi">+    # Check for keywords, also returns tokens.Name if regex matches</span>
<span class="gi">+    # but the match isn&#39;t a keyword.</span>
<span class="gi">+    (r&#39;\w[$#\w]*&#39;, PROCESS_AS_KEYWORD),</span>
<span class="gi">+    (r&#39;[;:()\[\],\.]&#39;, tokens.Punctuation),</span>
<span class="gi">+    # JSON operators</span>
<span class="gi">+    (r&#39;(\-&gt;&gt;?|#&gt;&gt;?|@&gt;|&lt;@|\?\|?|\?&amp;|\-|#\-)&#39;, tokens.Operator),</span>
<span class="gi">+    (r&#39;[&lt;&gt;=~!]+&#39;, tokens.Operator.Comparison),</span>
<span class="gi">+    (r&#39;[+/@#%^&amp;|^-]+&#39;, tokens.Operator),</span>
<span class="gi">+]</span>
<span class="gi">+</span>
<span class="gi">+KEYWORDS = {</span>
<span class="gi">+    &#39;ABORT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ABS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ABSOLUTE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ACCESS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ADA&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ADD&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ADMIN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;AFTER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;AGGREGATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ALIAS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ALL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ALLOCATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ANALYSE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ANALYZE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ANY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ARRAYLEN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ARE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ASENSITIVE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ASSERTION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ASSIGNMENT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ASYMMETRIC&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;AT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ATOMIC&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;AUDIT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;AUTHORIZATION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;AUTO_INCREMENT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;AVG&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;BACKWARD&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;BEFORE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;BEGIN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;BETWEEN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;BITVAR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;BIT_LENGTH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;BOTH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;BREADTH&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    # &#39;C&#39;: tokens.Keyword,  # most likely this is an alias</span>
<span class="gi">+    &#39;CACHE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CALL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CALLED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CARDINALITY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CASCADE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CASCADED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CAST&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CATALOG&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CATALOG_NAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CHAIN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CHARACTERISTICS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CHARACTER_LENGTH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CHARACTER_SET_CATALOG&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CHARACTER_SET_NAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CHARACTER_SET_SCHEMA&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CHAR_LENGTH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CHARSET&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CHECK&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CHECKED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CHECKPOINT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CLASS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CLASS_ORIGIN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CLOB&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CLOSE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CLUSTER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COALESCE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COBOL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COLLATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COLLATION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COLLATION_CATALOG&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COLLATION_NAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COLLATION_SCHEMA&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COLLECT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COLUMN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COLUMN_NAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COMPRESS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COMMAND_FUNCTION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COMMAND_FUNCTION_CODE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COMMENT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COMMIT&#39;: tokens.Keyword.DML,</span>
<span class="gi">+    &#39;COMMITTED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COMPLETION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONCURRENTLY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONDITION_NUMBER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONNECT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONNECTION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONNECTION_NAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONSTRAINT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONSTRAINTS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONSTRAINT_CATALOG&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONSTRAINT_NAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONSTRAINT_SCHEMA&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONSTRUCTOR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONTAINS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONTINUE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONVERSION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONVERT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COPY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CORRESPONDING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COUNT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CREATEDB&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CREATEUSER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CROSS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CUBE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CURRENT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CURRENT_DATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CURRENT_PATH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CURRENT_ROLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CURRENT_TIME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CURRENT_TIMESTAMP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CURRENT_USER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CURSOR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CURSOR_NAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CYCLE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;DATA&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DATABASE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DATETIME_INTERVAL_CODE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DATETIME_INTERVAL_PRECISION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DAY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DEALLOCATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DECLARE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DEFAULT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DEFAULTS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DEFERRABLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DEFERRED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DEFINED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DEFINER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DELIMITER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DELIMITERS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DEREF&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DESCRIBE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DESCRIPTOR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DESTROY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DESTRUCTOR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DETERMINISTIC&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DIAGNOSTICS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DICTIONARY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DISABLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DISCONNECT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DISPATCH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DIV&#39;: tokens.Operator,</span>
<span class="gi">+    &#39;DO&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DOMAIN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DYNAMIC&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DYNAMIC_FUNCTION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DYNAMIC_FUNCTION_CODE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;EACH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ENABLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ENCODING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ENCRYPTED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;END-EXEC&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ENGINE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EQUALS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ESCAPE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EVERY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXCEPT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXCEPTION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXCLUDING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXCLUSIVE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXEC&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXECUTE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXISTING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXISTS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXPLAIN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXTERNAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXTRACT&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;FALSE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FETCH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FILE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FINAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FIRST&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FORCE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FOREACH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FOREIGN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FORTRAN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FORWARD&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FOUND&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FREE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FREEZE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FULL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FUNCTION&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    # &#39;G&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;GENERAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;GENERATED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;GET&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;GLOBAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;GO&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;GOTO&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;GRANTED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;GROUPING&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;HAVING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;HIERARCHY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;HOLD&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;HOUR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;HOST&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;IDENTIFIED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;IDENTITY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;IGNORE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ILIKE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;IMMEDIATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;IMMUTABLE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;IMPLEMENTATION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;IMPLICIT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INCLUDING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INCREMENT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INDEX&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;INDICATOR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INFIX&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INHERITS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INITIAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INITIALIZE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INITIALLY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INOUT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INPUT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INSENSITIVE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INSTANTIABLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INSTEAD&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INTERSECT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INTO&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INVOKER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;IS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ISNULL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ISOLATION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ITERATE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    # &#39;K&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;KEY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;KEY_MEMBER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;KEY_TYPE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;LANCOMPILER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LANGUAGE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LARGE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LAST&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LATERAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LEADING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LENGTH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LESS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LEVEL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LIMIT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LISTEN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LOAD&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LOCAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LOCALTIME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LOCALTIMESTAMP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LOCATION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LOCATOR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LOCK&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LOWER&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    # &#39;M&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MAP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MATCH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MAXEXTENTS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MAXVALUE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MESSAGE_LENGTH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MESSAGE_OCTET_LENGTH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MESSAGE_TEXT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;METHOD&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MINUTE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MINUS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MINVALUE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MOD&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MODE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MODIFIES&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MODIFY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MONTH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MORE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MOVE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MUMPS&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;NAMES&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NATIONAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NATURAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NCHAR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NCLOB&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NEW&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NEXT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NO&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOAUDIT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOCOMPRESS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOCREATEDB&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOCREATEUSER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NONE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOTFOUND&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOTHING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOTIFY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOTNULL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOWAIT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NULL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NULLABLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NULLIF&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;OBJECT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OCTET_LENGTH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OF&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OFF&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OFFLINE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OFFSET&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OIDS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OLD&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ONLINE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ONLY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OPEN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OPERATION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OPERATOR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OPTION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OPTIONS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ORDINALITY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OUT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OUTPUT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OVERLAPS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OVERLAY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OVERRIDING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OWNER&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;QUARTER&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;PAD&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PARAMETER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PARAMETERS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PARAMETER_MODE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PARAMETER_NAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PARAMETER_ORDINAL_POSITION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PARAMETER_SPECIFIC_CATALOG&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PARAMETER_SPECIFIC_NAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PARAMETER_SPECIFIC_SCHEMA&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PARTIAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PASCAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PCTFREE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PENDANT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PLACING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PLI&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;POSITION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;POSTFIX&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PRECISION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PREFIX&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PREORDER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PREPARE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PRESERVE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PRIMARY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PRIOR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PRIVILEGES&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PROCEDURAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PROCEDURE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PUBLIC&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;RAISE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RAW&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;READ&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;READS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RECHECK&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RECURSIVE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;REF&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;REFERENCES&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;REFERENCING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;REINDEX&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RELATIVE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RENAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;REPEATABLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RESET&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RESOURCE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RESTART&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RESTRICT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RESULT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RETURN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RETURNED_LENGTH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RETURNED_OCTET_LENGTH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RETURNED_SQLSTATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RETURNING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RETURNS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RIGHT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ROLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ROLLBACK&#39;: tokens.Keyword.DML,</span>
<span class="gi">+    &#39;ROLLUP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ROUTINE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ROUTINE_CATALOG&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ROUTINE_NAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ROUTINE_SCHEMA&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ROWS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ROW_COUNT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RULE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;SAVE_POINT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SCALE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SCHEMA&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SCHEMA_NAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SCOPE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SCROLL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SEARCH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SECOND&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SECURITY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SELF&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SENSITIVE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SEQUENCE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SERIALIZABLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SERVER_NAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SESSION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SESSION_USER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SETOF&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SETS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SHARE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SHOW&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SIMILAR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SIMPLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SIZE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SOME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SOURCE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SPACE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SPECIFIC&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SPECIFICTYPE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SPECIFIC_NAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SQL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SQLBUF&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SQLCODE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SQLERROR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SQLEXCEPTION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SQLSTATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SQLWARNING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;STABLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;START&#39;: tokens.Keyword.DML,</span>
<span class="gi">+    # &#39;STATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;STATEMENT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;STATIC&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;STATISTICS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;STDIN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;STDOUT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;STORAGE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;STRICT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;STRUCTURE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;STYPE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SUBCLASS_ORIGIN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SUBLIST&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SUBSTRING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SUCCESSFUL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SUM&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SYMMETRIC&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SYNONYM&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SYSID&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SYSTEM&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SYSTEM_USER&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;TABLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TABLE_NAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TEMP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TEMPLATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TEMPORARY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TERMINATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;THAN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TIMESTAMP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TIMEZONE_HOUR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TIMEZONE_MINUTE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TO&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TOAST&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRAILING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRANSATION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRANSACTIONS_COMMITTED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRANSACTIONS_ROLLED_BACK&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRANSATION_ACTIVE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRANSFORM&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRANSFORMS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRANSLATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRANSLATION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TREAT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRIGGER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRIGGER_CATALOG&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRIGGER_NAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRIGGER_SCHEMA&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRIM&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRUE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRUSTED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TYPE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;UID&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UNCOMMITTED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UNDER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UNENCRYPTED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UNION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UNIQUE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UNKNOWN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UNLISTEN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UNNAMED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UNNEST&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UNTIL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UPPER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;USAGE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;USE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;USER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;USER_DEFINED_TYPE_CATALOG&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;USER_DEFINED_TYPE_NAME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;USER_DEFINED_TYPE_SCHEMA&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;USING&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;VACUUM&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;VALID&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;VALIDATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;VALIDATOR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;VALUES&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;VARIABLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;VERBOSE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;VERSION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;VIEW&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;VOLATILE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;WEEK&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;WHENEVER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;WITH&#39;: tokens.Keyword.CTE,</span>
<span class="gi">+    &#39;WITHOUT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;WORK&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;WRITE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;YEAR&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;ZONE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    # Name.Builtin</span>
<span class="gi">+    &#39;ARRAY&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;BIGINT&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;BINARY&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;BIT&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;BLOB&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;BOOLEAN&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;CHAR&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;CHARACTER&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;DATE&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;DEC&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;DECIMAL&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;FILE_TYPE&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;FLOAT&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;INT&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;INT8&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;INTEGER&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;INTERVAL&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;LONG&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;NATURALN&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;NVARCHAR&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;NUMBER&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;NUMERIC&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;PLS_INTEGER&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;POSITIVE&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;POSITIVEN&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;REAL&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;ROWID&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;ROWLABEL&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;ROWNUM&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;SERIAL&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;SERIAL8&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;SIGNED&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;SIGNTYPE&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;SIMPLE_DOUBLE&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;SIMPLE_FLOAT&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;SIMPLE_INTEGER&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;SMALLINT&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;SYS_REFCURSOR&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;SYSDATE&#39;: tokens.Name,</span>
<span class="gi">+    &#39;TEXT&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;TINYINT&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;UNSIGNED&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;UROWID&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;UTL_FILE&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;VARCHAR&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;VARCHAR2&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;VARYING&#39;: tokens.Name.Builtin,</span>
<span class="gi">+}</span>
<span class="gi">+</span>
<span class="gi">+KEYWORDS_COMMON = {</span>
<span class="gi">+    &#39;SELECT&#39;: tokens.Keyword.DML,</span>
<span class="gi">+    &#39;INSERT&#39;: tokens.Keyword.DML,</span>
<span class="gi">+    &#39;DELETE&#39;: tokens.Keyword.DML,</span>
<span class="gi">+    &#39;UPDATE&#39;: tokens.Keyword.DML,</span>
<span class="gi">+    &#39;UPSERT&#39;: tokens.Keyword.DML,</span>
<span class="gi">+    &#39;REPLACE&#39;: tokens.Keyword.DML,</span>
<span class="gi">+    &#39;MERGE&#39;: tokens.Keyword.DML,</span>
<span class="gi">+    &#39;DROP&#39;: tokens.Keyword.DDL,</span>
<span class="gi">+    &#39;CREATE&#39;: tokens.Keyword.DDL,</span>
<span class="gi">+    &#39;ALTER&#39;: tokens.Keyword.DDL,</span>
<span class="gi">+    &#39;TRUNCATE&#39;: tokens.Keyword.DDL,</span>
<span class="gi">+    &#39;GRANT&#39;: tokens.Keyword.DCL,</span>
<span class="gi">+    &#39;REVOKE&#39;: tokens.Keyword.DCL,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;WHERE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FROM&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INNER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;JOIN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;STRAIGHT_JOIN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;AND&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LIKE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ON&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;IN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SET&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;BY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;GROUP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ORDER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LEFT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OUTER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FULL&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;IF&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;END&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;THEN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LOOP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;AS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ELSE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FOR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;WHILE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;CASE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;WHEN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MIN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MAX&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DISTINCT&#39;: tokens.Keyword,</span>
<span class="gi">+}</span>
<span class="gi">+</span>
<span class="gi">+KEYWORDS_ORACLE = {</span>
<span class="gi">+    &#39;ARCHIVE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ARCHIVELOG&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;BACKUP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;BECOME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;BLOCK&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;BODY&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;CANCEL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CHANGE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COMPILE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONTENTS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONTROLFILE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;DATAFILE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DBA&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DISMOUNT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DOUBLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DUMP&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;ELSIF&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EVENTS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXCEPTIONS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXPLAIN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXTENT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXTERNALLY&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;FLUSH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FREELIST&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FREELISTS&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    # groups seems too common as table name</span>
<span class="gi">+    # &#39;GROUPS&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;INDICATOR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INITRANS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INSTANCE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;LAYER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LINK&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LISTS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LOGFILE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;MANAGE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MANUAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MAXDATAFILES&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MAXINSTANCES&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MAXLOGFILES&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MAXLOGHISTORY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MAXLOGMEMBERS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MAXTRANS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MINEXTENTS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MODULE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MOUNT&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;NOARCHIVELOG&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOCACHE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOCYCLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOMAXVALUE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOMINVALUE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOORDER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NORESETLOGS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NORMAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOSORT&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;OPTIMAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OWN&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;PACKAGE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PARALLEL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PCTINCREASE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PCTUSED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PLAN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PRIVATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PROFILE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;QUOTA&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;RECOVER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RESETLOGS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RESTRICTED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;REUSE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ROLES&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;SAVEPOINT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SCN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SECTION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SEGMENT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SHARED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SNAPSHOT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SORT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;STATEMENT_ID&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;STOP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SWITCH&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;TABLES&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TABLESPACE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;THREAD&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TIME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRACING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRANSACTION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRIGGERS&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;UNLIMITED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UNLOCK&#39;: tokens.Keyword,</span>
<span class="gi">+}</span>
<span class="gi">+</span>
<span class="gi">+# MySQL</span>
<span class="gi">+KEYWORDS_MYSQL = {</span>
<span class="gi">+    &#39;ROW&#39;: tokens.Keyword,</span>
<span class="gi">+}</span>
<span class="gi">+</span>
<span class="gi">+# PostgreSQL Syntax</span>
<span class="gi">+KEYWORDS_PLPGSQL = {</span>
<span class="gi">+    &#39;CONFLICT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;WINDOW&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PARTITION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OVER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PERFORM&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOTICE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PLPGSQL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INHERIT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INDEXES&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ON_ERROR_STOP&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;BYTEA&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;BIGSERIAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;BIT VARYING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;BOX&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CHARACTER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CHARACTER VARYING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CIDR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CIRCLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DOUBLE PRECISION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INET&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;JSON&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;JSONB&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LINE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LSEG&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MACADDR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MONEY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PATH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PG_LSN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;POINT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;POLYGON&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SMALLSERIAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TSQUERY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TSVECTOR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TXID_SNAPSHOT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UUID&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;XML&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;FOR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;IN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LOOP&#39;: tokens.Keyword,</span>
<span class="gi">+}</span>
<span class="gi">+</span>
<span class="gi">+# Hive Syntax</span>
<span class="gi">+KEYWORDS_HQL = {</span>
<span class="gi">+    &#39;EXPLODE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DIRECTORY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DISTRIBUTE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INCLUDE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LOCATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;OVERWRITE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;POSEXPLODE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;ARRAY_CONTAINS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CMP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;COLLECT_LIST&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONCAT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;CONDITION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DATE_ADD&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DATE_SUB&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DECODE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DBMS_OUTPUT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ELEMENTS&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXCHANGE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;EXTENDED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FLOOR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FOLLOWING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FROM_UNIXTIME&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;FTP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;HOUR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INLINE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;INSTR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LEN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MAP&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;MAXELEMENT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MAXINDEX&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MAX_PART_DATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MAX_PART_INT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MAX_PART_STRING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MINELEMENT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MININDEX&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MIN_PART_DATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MIN_PART_INT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;MIN_PART_STRING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NOW&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NVL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;NVL2&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PARSE_URL_TUPLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PART_LOC&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PART_COUNT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PART_COUNT_BY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PRINT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PUT_LINE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RANGE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;REDUCE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;REGEXP_REPLACE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RESIGNAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RTRIM&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SIGN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SIGNAL&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SIN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SPLIT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SQRT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;STACK&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;STR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;STRING&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;STRUCT&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;SUBSTR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SUMMARY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TBLPROPERTIES&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TIMESTAMP&#39;: tokens.Name.Builtin,</span>
<span class="gi">+    &#39;TIMESTAMP_ISO&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TO_CHAR&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TO_DATE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TO_TIMESTAMP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRUNC&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UNBOUNDED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UNIQUEJOIN&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UNIX_TIMESTAMP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UTC_TIMESTAMP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;VIEWS&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;EXIT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;BREAK&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LEAVE&#39;: tokens.Keyword,</span>
<span class="gi">+}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+KEYWORDS_MSACCESS = {</span>
<span class="gi">+    &#39;DISTINCTROW&#39;: tokens.Keyword,</span>
<span class="gi">+}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+KEYWORDS_SNOWFLAKE = {</span>
<span class="gi">+    &#39;ACCOUNT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;GSCLUSTER&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ISSUE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ORGANIZATION&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PIVOT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;QUALIFY&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;REGEXP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RLIKE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;SAMPLE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TRY_CAST&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;UNPIVOT&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;VARIANT&#39;: tokens.Name.Builtin,</span>
<span class="gi">+}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+KEYWORDS_BIGQUERY = {</span>
<span class="gi">+    &#39;ASSERT_ROWS_MODIFIED&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;DEFINE&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;ENUM&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;HASH&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;LOOKUP&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PRECEDING&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;PROTO&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;RESPECT&#39;: tokens.Keyword,</span>
<span class="gi">+    &#39;TABLESAMPLE&#39;: tokens.Keyword,</span>
<span class="gi">+</span>
<span class="gi">+    &#39;BIGNUMERIC&#39;: tokens.Name.Builtin,</span>
<span class="gi">+}</span>
<span class="gh">diff --git a/sqlparse/lexer.py b/sqlparse/lexer.py</span>
<span class="gh">index cc76039..8f88d17 100644</span>
<span class="gd">--- a/sqlparse/lexer.py</span>
<span class="gi">+++ b/sqlparse/lexer.py</span>
<span class="gu">@@ -1,7 +1,21 @@</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+</span>
<span class="w"> </span>&quot;&quot;&quot;SQL Lexer&quot;&quot;&quot;
<span class="w"> </span>import re
<span class="w"> </span>from threading import Lock
<span class="gi">+</span>
<span class="gi">+# This code is based on the SqlLexer in pygments.</span>
<span class="gi">+# http://pygments.org/</span>
<span class="gi">+# It&#39;s separated from the rest of pygments to increase performance</span>
<span class="gi">+# and to allow some customizations.</span>
<span class="gi">+</span>
<span class="w"> </span>from io import TextIOBase
<span class="gi">+</span>
<span class="w"> </span>from sqlparse import tokens, keywords
<span class="w"> </span>from sqlparse.utils import consume

<span class="gu">@@ -9,35 +23,73 @@ from sqlparse.utils import consume</span>
<span class="w"> </span>class Lexer:
<span class="w"> </span>    &quot;&quot;&quot;The Lexer supports configurable syntax.
<span class="w"> </span>    To add support for additional keywords, use the `add_keywords` method.&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>    _default_instance = None
<span class="w"> </span>    _lock = Lock()

<span class="gi">+    # Development notes:</span>
<span class="gi">+    # - This class is prepared to be able to support additional SQL dialects</span>
<span class="gi">+    #   in the future by adding additional functions that take the place of</span>
<span class="gi">+    #   the function default_initialization().</span>
<span class="gi">+    # - The lexer class uses an explicit singleton behavior with the</span>
<span class="gi">+    #   instance-getter method get_default_instance(). This mechanism has</span>
<span class="gi">+    #   the advantage that the call signature of the entry-points to the</span>
<span class="gi">+    #   sqlparse library are not affected. Also, usage of sqlparse in third</span>
<span class="gi">+    #   party code does not need to be adapted. On the other hand, the current</span>
<span class="gi">+    #   implementation does not easily allow for multiple SQL dialects to be</span>
<span class="gi">+    #   parsed in the same process.</span>
<span class="gi">+    #   Such behavior can be supported in the future by passing a</span>
<span class="gi">+    #   suitably initialized lexer object as an additional parameter to the</span>
<span class="gi">+    #   entry-point functions (such as `parse`). Code will need to be written</span>
<span class="gi">+    #   to pass down and utilize such an object. The current implementation</span>
<span class="gi">+    #   is prepared to support this thread safe approach without the</span>
<span class="gi">+    #   default_instance part needing to change interface.</span>
<span class="gi">+</span>
<span class="w"> </span>    @classmethod
<span class="w"> </span>    def get_default_instance(cls):
<span class="w"> </span>        &quot;&quot;&quot;Returns the lexer instance used internally
<span class="w"> </span>        by the sqlparse core functions.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with cls._lock:</span>
<span class="gi">+            if cls._default_instance is None:</span>
<span class="gi">+                cls._default_instance = cls()</span>
<span class="gi">+                cls._default_instance.default_initialization()</span>
<span class="gi">+        return cls._default_instance</span>

<span class="w"> </span>    def default_initialization(self):
<span class="w"> </span>        &quot;&quot;&quot;Initialize the lexer with default dictionaries.
<span class="w"> </span>        Useful if you need to revert custom syntax settings.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.clear()</span>
<span class="gi">+        self.set_SQL_REGEX(keywords.SQL_REGEX)</span>
<span class="gi">+        self.add_keywords(keywords.KEYWORDS_COMMON)</span>
<span class="gi">+        self.add_keywords(keywords.KEYWORDS_ORACLE)</span>
<span class="gi">+        self.add_keywords(keywords.KEYWORDS_MYSQL)</span>
<span class="gi">+        self.add_keywords(keywords.KEYWORDS_PLPGSQL)</span>
<span class="gi">+        self.add_keywords(keywords.KEYWORDS_HQL)</span>
<span class="gi">+        self.add_keywords(keywords.KEYWORDS_MSACCESS)</span>
<span class="gi">+        self.add_keywords(keywords.KEYWORDS_SNOWFLAKE)</span>
<span class="gi">+        self.add_keywords(keywords.KEYWORDS_BIGQUERY)</span>
<span class="gi">+        self.add_keywords(keywords.KEYWORDS)</span>

<span class="w"> </span>    def clear(self):
<span class="w"> </span>        &quot;&quot;&quot;Clear all syntax configurations.
<span class="w"> </span>        Useful if you want to load a reduced set of syntax configurations.
<span class="w"> </span>        After this call, regexps and keyword dictionaries need to be loaded
<span class="w"> </span>        to make the lexer functional again.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._SQL_REGEX = []</span>
<span class="gi">+        self._keywords = []</span>

<span class="w"> </span>    def set_SQL_REGEX(self, SQL_REGEX):
<span class="w"> </span>        &quot;&quot;&quot;Set the list of regex that will parse the SQL.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        FLAGS = re.IGNORECASE | re.UNICODE</span>
<span class="gi">+        self._SQL_REGEX = [</span>
<span class="gi">+            (re.compile(rx, FLAGS).match, tt)</span>
<span class="gi">+            for rx, tt in SQL_REGEX</span>
<span class="gi">+        ]</span>

<span class="w"> </span>    def add_keywords(self, keywords):
<span class="w"> </span>        &quot;&quot;&quot;Add keyword dictionaries. Keywords are looked up in the same order
<span class="w"> </span>        that dictionaries were added.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._keywords.append(keywords)</span>

<span class="w"> </span>    def is_keyword(self, value):
<span class="w"> </span>        &quot;&quot;&quot;Checks for a keyword.
<span class="gu">@@ -45,7 +97,12 @@ class Lexer:</span>
<span class="w"> </span>        If the given value is in one of the KEYWORDS_* dictionary
<span class="w"> </span>        it&#39;s considered a keyword. Otherwise, tokens.Name is returned.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        val = value.upper()</span>
<span class="gi">+        for kwdict in self._keywords:</span>
<span class="gi">+            if val in kwdict:</span>
<span class="gi">+                return kwdict[val], value</span>
<span class="gi">+        else:</span>
<span class="gi">+            return tokens.Name, value</span>

<span class="w"> </span>    def get_tokens(self, text, encoding=None):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -60,7 +117,39 @@ class Lexer:</span>

<span class="w"> </span>        ``stack`` is the initial stack (default: ``[&#39;root&#39;]``)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(text, TextIOBase):</span>
<span class="gi">+            text = text.read()</span>
<span class="gi">+</span>
<span class="gi">+        if isinstance(text, str):</span>
<span class="gi">+            pass</span>
<span class="gi">+        elif isinstance(text, bytes):</span>
<span class="gi">+            if encoding:</span>
<span class="gi">+                text = text.decode(encoding)</span>
<span class="gi">+            else:</span>
<span class="gi">+                try:</span>
<span class="gi">+                    text = text.decode(&#39;utf-8&#39;)</span>
<span class="gi">+                except UnicodeDecodeError:</span>
<span class="gi">+                    text = text.decode(&#39;unicode-escape&#39;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise TypeError(&quot;Expected text or file-like object, got {!r}&quot;.</span>
<span class="gi">+                            format(type(text)))</span>
<span class="gi">+</span>
<span class="gi">+        iterable = enumerate(text)</span>
<span class="gi">+        for pos, char in iterable:</span>
<span class="gi">+            for rexmatch, action in self._SQL_REGEX:</span>
<span class="gi">+                m = rexmatch(text, pos)</span>
<span class="gi">+</span>
<span class="gi">+                if not m:</span>
<span class="gi">+                    continue</span>
<span class="gi">+                elif isinstance(action, tokens._TokenType):</span>
<span class="gi">+                    yield action, m.group()</span>
<span class="gi">+                elif action is keywords.PROCESS_AS_KEYWORD:</span>
<span class="gi">+                    yield self.is_keyword(m.group())</span>
<span class="gi">+</span>
<span class="gi">+                consume(iterable, m.end() - pos - 1)</span>
<span class="gi">+                break</span>
<span class="gi">+            else:</span>
<span class="gi">+                yield tokens.Error, char</span>


<span class="w"> </span>def tokenize(sql, encoding=None):
<span class="gu">@@ -69,4 +158,4 @@ def tokenize(sql, encoding=None):</span>
<span class="w"> </span>    Tokenize *sql* using the :class:`Lexer` and return a 2-tuple stream
<span class="w"> </span>    of ``(token type, value)`` items.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return Lexer.get_default_instance().get_tokens(sql, encoding)</span>
<span class="gh">diff --git a/sqlparse/sql.py b/sqlparse/sql.py</span>
<span class="gh">index 44fef09..1037375 100644</span>
<span class="gd">--- a/sqlparse/sql.py</span>
<span class="gi">+++ b/sqlparse/sql.py</span>
<span class="gu">@@ -1,5 +1,14 @@</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+</span>
<span class="w"> </span>&quot;&quot;&quot;This module contains classes representing syntactical elements of SQL.&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>import re
<span class="gi">+</span>
<span class="w"> </span>from sqlparse import tokens as T
<span class="w"> </span>from sqlparse.exceptions import SQLParseError
<span class="w"> </span>from sqlparse.utils import imt, remove_quotes
<span class="gu">@@ -10,11 +19,22 @@ class NameAliasMixin:</span>

<span class="w"> </span>    def get_real_name(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns the real name (object name) of this identifier.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # a.b</span>
<span class="gi">+        dot_idx, _ = self.token_next_by(m=(T.Punctuation, &#39;.&#39;))</span>
<span class="gi">+        return self._get_first_name(dot_idx, real_name=True)</span>

<span class="w"> </span>    def get_alias(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns the alias for this identifier or ``None``.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+</span>
<span class="gi">+        # &quot;name AS alias&quot;</span>
<span class="gi">+        kw_idx, kw = self.token_next_by(m=(T.Keyword, &#39;AS&#39;))</span>
<span class="gi">+        if kw is not None:</span>
<span class="gi">+            return self._get_first_name(kw_idx + 1, keywords=True)</span>
<span class="gi">+</span>
<span class="gi">+        # &quot;name alias&quot; or &quot;complicated column expression alias&quot;</span>
<span class="gi">+        _, ws = self.token_next_by(t=T.Whitespace)</span>
<span class="gi">+        if len(self.tokens) &gt; 2 and ws is not None:</span>
<span class="gi">+            return self._get_first_name(reverse=True)</span>


<span class="w"> </span>class Token:
<span class="gu">@@ -24,8 +44,9 @@ class Token:</span>
<span class="w"> </span>    ``value`` is the unchanged value of the token and ``ttype`` is
<span class="w"> </span>    the type of the token.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>    __slots__ = (&#39;value&#39;, &#39;ttype&#39;, &#39;parent&#39;, &#39;normalized&#39;, &#39;is_keyword&#39;,
<span class="gd">-        &#39;is_group&#39;, &#39;is_whitespace&#39;, &#39;is_newline&#39;)</span>
<span class="gi">+                 &#39;is_group&#39;, &#39;is_whitespace&#39;, &#39;is_newline&#39;)</span>

<span class="w"> </span>    def __init__(self, ttype, value):
<span class="w"> </span>        value = str(value)
<span class="gu">@@ -41,16 +62,30 @@ class Token:</span>
<span class="w"> </span>    def __str__(self):
<span class="w"> </span>        return self.value

<span class="gi">+    # Pending tokenlist __len__ bug fix</span>
<span class="gi">+    # def __len__(self):</span>
<span class="gi">+    #     return len(self.value)</span>
<span class="gi">+</span>
<span class="w"> </span>    def __repr__(self):
<span class="w"> </span>        cls = self._get_repr_name()
<span class="w"> </span>        value = self._get_repr_value()
<span class="gi">+</span>
<span class="w"> </span>        q = &#39;&quot;&#39; if value.startswith(&quot;&#39;&quot;) and value.endswith(&quot;&#39;&quot;) else &quot;&#39;&quot;
<span class="gd">-        return &#39;&lt;{cls} {q}{value}{q} at 0x{id:2X}&gt;&#39;.format(id=id(self), **</span>
<span class="gd">-            locals())</span>
<span class="gi">+        return &quot;&lt;{cls} {q}{value}{q} at 0x{id:2X}&gt;&quot;.format(</span>
<span class="gi">+            id=id(self), **locals())</span>
<span class="gi">+</span>
<span class="gi">+    def _get_repr_name(self):</span>
<span class="gi">+        return str(self.ttype).split(&#39;.&#39;)[-1]</span>
<span class="gi">+</span>
<span class="gi">+    def _get_repr_value(self):</span>
<span class="gi">+        raw = str(self)</span>
<span class="gi">+        if len(raw) &gt; 7:</span>
<span class="gi">+            raw = raw[:6] + &#39;...&#39;</span>
<span class="gi">+        return re.sub(r&#39;\s+&#39;, &#39; &#39;, raw)</span>

<span class="w"> </span>    def flatten(self):
<span class="w"> </span>        &quot;&quot;&quot;Resolve subgroups.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        yield self</span>

<span class="w"> </span>    def match(self, ttype, values, regex=False):
<span class="w"> </span>        &quot;&quot;&quot;Checks whether the token matches the given arguments.
<span class="gu">@@ -64,7 +99,27 @@ class Token:</span>
<span class="w"> </span>        If *regex* is ``True`` (default is ``False``) the given values are
<span class="w"> </span>        treated as regular expressions.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        type_matched = self.ttype is ttype</span>
<span class="gi">+        if not type_matched or values is None:</span>
<span class="gi">+            return type_matched</span>
<span class="gi">+</span>
<span class="gi">+        if isinstance(values, str):</span>
<span class="gi">+            values = (values,)</span>
<span class="gi">+</span>
<span class="gi">+        if regex:</span>
<span class="gi">+            # TODO: Add test for regex with is_keyboard = false</span>
<span class="gi">+            flag = re.IGNORECASE if self.is_keyword else 0</span>
<span class="gi">+            values = (re.compile(v, flag) for v in values)</span>
<span class="gi">+</span>
<span class="gi">+            for pattern in values:</span>
<span class="gi">+                if pattern.search(self.normalized):</span>
<span class="gi">+                    return True</span>
<span class="gi">+            return False</span>
<span class="gi">+</span>
<span class="gi">+        if self.is_keyword:</span>
<span class="gi">+            values = (v.upper() for v in values)</span>
<span class="gi">+</span>
<span class="gi">+        return self.normalized in values</span>

<span class="w"> </span>    def within(self, group_cls):
<span class="w"> </span>        &quot;&quot;&quot;Returns ``True`` if this token is within *group_cls*.
<span class="gu">@@ -72,15 +127,25 @@ class Token:</span>
<span class="w"> </span>        Use this method for example to check if an identifier is within
<span class="w"> </span>        a function: ``t.within(sql.Function)``.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        parent = self.parent</span>
<span class="gi">+        while parent:</span>
<span class="gi">+            if isinstance(parent, group_cls):</span>
<span class="gi">+                return True</span>
<span class="gi">+            parent = parent.parent</span>
<span class="gi">+        return False</span>

<span class="w"> </span>    def is_child_of(self, other):
<span class="w"> </span>        &quot;&quot;&quot;Returns ``True`` if this token is a direct child of *other*.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.parent == other</span>

<span class="w"> </span>    def has_ancestor(self, other):
<span class="w"> </span>        &quot;&quot;&quot;Returns ``True`` if *other* is in this tokens ancestry.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        parent = self.parent</span>
<span class="gi">+        while parent:</span>
<span class="gi">+            if parent == other:</span>
<span class="gi">+                return True</span>
<span class="gi">+            parent = parent.parent</span>
<span class="gi">+        return False</span>


<span class="w"> </span>class TokenList(Token):
<span class="gu">@@ -89,6 +154,7 @@ class TokenList(Token):</span>
<span class="w"> </span>    It has an additional instance attribute ``tokens`` which holds a
<span class="w"> </span>    list of child-tokens.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>    __slots__ = &#39;tokens&#39;

<span class="w"> </span>    def __init__(self, tokens=None):
<span class="gu">@@ -100,30 +166,90 @@ class TokenList(Token):</span>
<span class="w"> </span>    def __str__(self):
<span class="w"> </span>        return &#39;&#39;.join(token.value for token in self.flatten())

<span class="gi">+    # weird bug</span>
<span class="gi">+    # def __len__(self):</span>
<span class="gi">+    #     return len(self.tokens)</span>
<span class="gi">+</span>
<span class="w"> </span>    def __iter__(self):
<span class="w"> </span>        return iter(self.tokens)

<span class="w"> </span>    def __getitem__(self, item):
<span class="w"> </span>        return self.tokens[item]

<span class="gi">+    def _get_repr_name(self):</span>
<span class="gi">+        return type(self).__name__</span>
<span class="gi">+</span>
<span class="w"> </span>    def _pprint_tree(self, max_depth=None, depth=0, f=None, _pre=&#39;&#39;):
<span class="w"> </span>        &quot;&quot;&quot;Pretty-print the object tree.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        token_count = len(self.tokens)</span>
<span class="gi">+        for idx, token in enumerate(self.tokens):</span>
<span class="gi">+            cls = token._get_repr_name()</span>
<span class="gi">+            value = token._get_repr_value()</span>
<span class="gi">+</span>
<span class="gi">+            last = idx == (token_count - 1)</span>
<span class="gi">+            pre = &#39;`- &#39; if last else &#39;|- &#39;</span>
<span class="gi">+</span>
<span class="gi">+            q = &#39;&quot;&#39; if value.startswith(&quot;&#39;&quot;) and value.endswith(&quot;&#39;&quot;) else &quot;&#39;&quot;</span>
<span class="gi">+            print(&quot;{_pre}{pre}{idx} {cls} {q}{value}{q}&quot;</span>
<span class="gi">+                  .format(**locals()), file=f)</span>
<span class="gi">+</span>
<span class="gi">+            if token.is_group and (max_depth is None or depth &lt; max_depth):</span>
<span class="gi">+                parent_pre = &#39;   &#39; if last else &#39;|  &#39;</span>
<span class="gi">+                token._pprint_tree(max_depth, depth + 1, f, _pre + parent_pre)</span>

<span class="w"> </span>    def get_token_at_offset(self, offset):
<span class="w"> </span>        &quot;&quot;&quot;Returns the token that is on position offset.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        idx = 0</span>
<span class="gi">+        for token in self.flatten():</span>
<span class="gi">+            end = idx + len(token.value)</span>
<span class="gi">+            if idx &lt;= offset &lt; end:</span>
<span class="gi">+                return token</span>
<span class="gi">+            idx = end</span>

<span class="w"> </span>    def flatten(self):
<span class="w"> </span>        &quot;&quot;&quot;Generator yielding ungrouped tokens.

<span class="w"> </span>        This method is recursively called for all child tokens.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        try:</span>
<span class="gi">+            for token in self.tokens:</span>
<span class="gi">+                if token.is_group:</span>
<span class="gi">+                    yield from token.flatten()</span>
<span class="gi">+                else:</span>
<span class="gi">+                    yield token</span>
<span class="gi">+        except RecursionError as err:</span>
<span class="gi">+            raise SQLParseError(&#39;Maximum recursion depth exceeded&#39;) from err</span>
<span class="gi">+</span>
<span class="gi">+    def get_sublists(self):</span>
<span class="gi">+        for token in self.tokens:</span>
<span class="gi">+            if token.is_group:</span>
<span class="gi">+                yield token</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def _groupable_tokens(self):</span>
<span class="gi">+        return self.tokens</span>

<span class="w"> </span>    def _token_matching(self, funcs, start=0, end=None, reverse=False):
<span class="w"> </span>        &quot;&quot;&quot;next token that match functions&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if start is None:</span>
<span class="gi">+            return None</span>
<span class="gi">+</span>
<span class="gi">+        if not isinstance(funcs, (list, tuple)):</span>
<span class="gi">+            funcs = (funcs,)</span>
<span class="gi">+</span>
<span class="gi">+        if reverse:</span>
<span class="gi">+            assert end is None</span>
<span class="gi">+            indexes = range(start - 2, -1, -1)</span>
<span class="gi">+        else:</span>
<span class="gi">+            if end is None:</span>
<span class="gi">+                end = len(self.tokens)</span>
<span class="gi">+            indexes = range(start, end)</span>
<span class="gi">+        for idx in indexes:</span>
<span class="gi">+            token = self.tokens[idx]</span>
<span class="gi">+            for func in funcs:</span>
<span class="gi">+                if func(token):</span>
<span class="gi">+                    return idx, token</span>
<span class="gi">+        return None, None</span>

<span class="w"> </span>    def token_first(self, skip_ws=True, skip_cm=False):
<span class="w"> </span>        &quot;&quot;&quot;Returns the first child token.
<span class="gu">@@ -134,7 +260,23 @@ class TokenList(Token):</span>
<span class="w"> </span>        if *skip_cm* is ``True`` (default: ``False``), comments are
<span class="w"> </span>        ignored too.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # this on is inconsistent, using Comment instead of T.Comment...</span>
<span class="gi">+        def matcher(tk):</span>
<span class="gi">+            return not ((skip_ws and tk.is_whitespace)</span>
<span class="gi">+                        or (skip_cm and imt(tk, t=T.Comment, i=Comment)))</span>
<span class="gi">+        return self._token_matching(matcher)[1]</span>
<span class="gi">+</span>
<span class="gi">+    def token_next_by(self, i=None, m=None, t=None, idx=-1, end=None):</span>
<span class="gi">+        idx += 1</span>
<span class="gi">+        return self._token_matching(lambda tk: imt(tk, i, m, t), idx, end)</span>
<span class="gi">+</span>
<span class="gi">+    def token_not_matching(self, funcs, idx):</span>
<span class="gi">+        funcs = (funcs,) if not isinstance(funcs, (list, tuple)) else funcs</span>
<span class="gi">+        funcs = [lambda tk: not func(tk) for func in funcs]</span>
<span class="gi">+        return self._token_matching(funcs, idx)</span>
<span class="gi">+</span>
<span class="gi">+    def token_matching(self, funcs, idx):</span>
<span class="gi">+        return self._token_matching(funcs, idx)[1]</span>

<span class="w"> </span>    def token_prev(self, idx, skip_ws=True, skip_cm=False):
<span class="w"> </span>        &quot;&quot;&quot;Returns the previous token relative to *idx*.
<span class="gu">@@ -143,8 +285,9 @@ class TokenList(Token):</span>
<span class="w"> </span>        If *skip_cm* is ``True`` comments are ignored.
<span class="w"> </span>        ``None`` is returned if there&#39;s no previous token.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.token_next(idx, skip_ws, skip_cm, _reverse=True)</span>

<span class="gi">+    # TODO: May need to re-add default value to idx</span>
<span class="w"> </span>    def token_next(self, idx, skip_ws=True, skip_cm=False, _reverse=False):
<span class="w"> </span>        &quot;&quot;&quot;Returns the next token relative to *idx*.

<span class="gu">@@ -152,32 +295,75 @@ class TokenList(Token):</span>
<span class="w"> </span>        If *skip_cm* is ``True`` comments are ignored.
<span class="w"> </span>        ``None`` is returned if there&#39;s no next token.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if idx is None:</span>
<span class="gi">+            return None, None</span>
<span class="gi">+        idx += 1  # alot of code usage current pre-compensates for this</span>
<span class="gi">+</span>
<span class="gi">+        def matcher(tk):</span>
<span class="gi">+            return not ((skip_ws and tk.is_whitespace)</span>
<span class="gi">+                        or (skip_cm and imt(tk, t=T.Comment, i=Comment)))</span>
<span class="gi">+        return self._token_matching(matcher, idx, reverse=_reverse)</span>

<span class="w"> </span>    def token_index(self, token, start=0):
<span class="w"> </span>        &quot;&quot;&quot;Return list index of token.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        start = start if isinstance(start, int) else self.token_index(start)</span>
<span class="gi">+        return start + self.tokens[start:].index(token)</span>

<span class="gd">-    def group_tokens(self, grp_cls, start, end, include_end=True, extend=False</span>
<span class="gd">-        ):</span>
<span class="gi">+    def group_tokens(self, grp_cls, start, end, include_end=True,</span>
<span class="gi">+                     extend=False):</span>
<span class="w"> </span>        &quot;&quot;&quot;Replace tokens by an instance of *grp_cls*.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        start_idx = start</span>
<span class="gi">+        start = self.tokens[start_idx]</span>
<span class="gi">+</span>
<span class="gi">+        end_idx = end + include_end</span>
<span class="gi">+</span>
<span class="gi">+        # will be needed later for new group_clauses</span>
<span class="gi">+        # while skip_ws and tokens and tokens[-1].is_whitespace:</span>
<span class="gi">+        #     tokens = tokens[:-1]</span>
<span class="gi">+</span>
<span class="gi">+        if extend and isinstance(start, grp_cls):</span>
<span class="gi">+            subtokens = self.tokens[start_idx + 1:end_idx]</span>
<span class="gi">+</span>
<span class="gi">+            grp = start</span>
<span class="gi">+            grp.tokens.extend(subtokens)</span>
<span class="gi">+            del self.tokens[start_idx + 1:end_idx]</span>
<span class="gi">+            grp.value = str(start)</span>
<span class="gi">+        else:</span>
<span class="gi">+            subtokens = self.tokens[start_idx:end_idx]</span>
<span class="gi">+            grp = grp_cls(subtokens)</span>
<span class="gi">+            self.tokens[start_idx:end_idx] = [grp]</span>
<span class="gi">+            grp.parent = self</span>
<span class="gi">+</span>
<span class="gi">+        for token in subtokens:</span>
<span class="gi">+            token.parent = grp</span>
<span class="gi">+</span>
<span class="gi">+        return grp</span>

<span class="w"> </span>    def insert_before(self, where, token):
<span class="w"> </span>        &quot;&quot;&quot;Inserts *token* before *where*.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if not isinstance(where, int):</span>
<span class="gi">+            where = self.token_index(where)</span>
<span class="gi">+        token.parent = self</span>
<span class="gi">+        self.tokens.insert(where, token)</span>

<span class="w"> </span>    def insert_after(self, where, token, skip_ws=True):
<span class="w"> </span>        &quot;&quot;&quot;Inserts *token* after *where*.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if not isinstance(where, int):</span>
<span class="gi">+            where = self.token_index(where)</span>
<span class="gi">+        nidx, next_ = self.token_next(where, skip_ws=skip_ws)</span>
<span class="gi">+        token.parent = self</span>
<span class="gi">+        if next_ is None:</span>
<span class="gi">+            self.tokens.append(token)</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.tokens.insert(nidx, token)</span>

<span class="w"> </span>    def has_alias(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns ``True`` if an alias is present.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.get_alias() is not None</span>

<span class="w"> </span>    def get_alias(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns the alias for this identifier or ``None``.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return None</span>

<span class="w"> </span>    def get_name(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns the name of this identifier.
<span class="gu">@@ -186,23 +372,37 @@ class TokenList(Token):</span>
<span class="w"> </span>        be considered as the name under which the object corresponding to
<span class="w"> </span>        this identifier is known within the current statement.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.get_alias() or self.get_real_name()</span>

<span class="w"> </span>    def get_real_name(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns the real name (object name) of this identifier.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return None</span>

<span class="w"> </span>    def get_parent_name(self):
<span class="w"> </span>        &quot;&quot;&quot;Return name of the parent object if any.

<span class="w"> </span>        A parent object is identified by the first occurring dot.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        dot_idx, _ = self.token_next_by(m=(T.Punctuation, &#39;.&#39;))</span>
<span class="gi">+        _, prev_ = self.token_prev(dot_idx)</span>
<span class="gi">+        return remove_quotes(prev_.value) if prev_ is not None else None</span>

<span class="w"> </span>    def _get_first_name(self, idx=None, reverse=False, keywords=False,
<span class="gd">-        real_name=False):</span>
<span class="gi">+                        real_name=False):</span>
<span class="w"> </span>        &quot;&quot;&quot;Returns the name of the first token with a name&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+</span>
<span class="gi">+        tokens = self.tokens[idx:] if idx else self.tokens</span>
<span class="gi">+        tokens = reversed(tokens) if reverse else tokens</span>
<span class="gi">+        types = [T.Name, T.Wildcard, T.String.Symbol]</span>
<span class="gi">+</span>
<span class="gi">+        if keywords:</span>
<span class="gi">+            types.append(T.Keyword)</span>
<span class="gi">+</span>
<span class="gi">+        for token in tokens:</span>
<span class="gi">+            if token.ttype in types:</span>
<span class="gi">+                return remove_quotes(token.value)</span>
<span class="gi">+            elif isinstance(token, (Identifier, Function)):</span>
<span class="gi">+                return token.get_real_name() if real_name else token.get_name()</span>


<span class="w"> </span>class Statement(TokenList):
<span class="gu">@@ -218,7 +418,31 @@ class Statement(TokenList):</span>
<span class="w"> </span>        Whitespaces and comments at the beginning of the statement
<span class="w"> </span>        are ignored.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        token = self.token_first(skip_cm=True)</span>
<span class="gi">+        if token is None:</span>
<span class="gi">+            # An &quot;empty&quot; statement that either has not tokens at all</span>
<span class="gi">+            # or only whitespace tokens.</span>
<span class="gi">+            return &#39;UNKNOWN&#39;</span>
<span class="gi">+</span>
<span class="gi">+        elif token.ttype in (T.Keyword.DML, T.Keyword.DDL):</span>
<span class="gi">+            return token.normalized</span>
<span class="gi">+</span>
<span class="gi">+        elif token.ttype == T.Keyword.CTE:</span>
<span class="gi">+            # The WITH keyword should be followed by either an Identifier or</span>
<span class="gi">+            # an IdentifierList containing the CTE definitions;  the actual</span>
<span class="gi">+            # DML keyword (e.g. SELECT, INSERT) will follow next.</span>
<span class="gi">+            tidx = self.token_index(token)</span>
<span class="gi">+            while tidx is not None:</span>
<span class="gi">+                tidx, token = self.token_next(tidx, skip_ws=True)</span>
<span class="gi">+                if isinstance(token, (Identifier, IdentifierList)):</span>
<span class="gi">+                    tidx, token = self.token_next(tidx, skip_ws=True)</span>
<span class="gi">+</span>
<span class="gi">+                    if token is not None \</span>
<span class="gi">+                            and token.ttype == T.Keyword.DML:</span>
<span class="gi">+                        return token.normalized</span>
<span class="gi">+</span>
<span class="gi">+        # Hmm, probably invalid syntax, so return unknown.</span>
<span class="gi">+        return &#39;UNKNOWN&#39;</span>


<span class="w"> </span>class Identifier(NameAliasMixin, TokenList):
<span class="gu">@@ -229,37 +453,47 @@ class Identifier(NameAliasMixin, TokenList):</span>

<span class="w"> </span>    def is_wildcard(self):
<span class="w"> </span>        &quot;&quot;&quot;Return ``True`` if this identifier contains a wildcard.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        _, token = self.token_next_by(t=T.Wildcard)</span>
<span class="gi">+        return token is not None</span>

<span class="w"> </span>    def get_typecast(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns the typecast or ``None`` of this object as a string.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        midx, marker = self.token_next_by(m=(T.Punctuation, &#39;::&#39;))</span>
<span class="gi">+        nidx, next_ = self.token_next(midx, skip_ws=False)</span>
<span class="gi">+        return next_.value if next_ else None</span>

<span class="w"> </span>    def get_ordering(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns the ordering or ``None`` as uppercase string.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        _, ordering = self.token_next_by(t=T.Keyword.Order)</span>
<span class="gi">+        return ordering.normalized if ordering else None</span>

<span class="w"> </span>    def get_array_indices(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns an iterator of index token lists&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+</span>
<span class="gi">+        for token in self.tokens:</span>
<span class="gi">+            if isinstance(token, SquareBrackets):</span>
<span class="gi">+                # Use [1:-1] index to discard the square brackets</span>
<span class="gi">+                yield token.tokens[1:-1]</span>


<span class="w"> </span>class IdentifierList(TokenList):
<span class="gd">-    &quot;&quot;&quot;A list of :class:`~sqlparse.sql.Identifier`&#39;s.&quot;&quot;&quot;</span>
<span class="gi">+    &quot;&quot;&quot;A list of :class:`~sqlparse.sql.Identifier`\&#39;s.&quot;&quot;&quot;</span>

<span class="w"> </span>    def get_identifiers(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns the identifiers.

<span class="w"> </span>        Whitespaces and punctuations are not included in this generator.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        for token in self.tokens:</span>
<span class="gi">+            if not (token.is_whitespace or token.match(T.Punctuation, &#39;,&#39;)):</span>
<span class="gi">+                yield token</span>


<span class="w"> </span>class TypedLiteral(TokenList):
<span class="w"> </span>    &quot;&quot;&quot;A typed literal, such as &quot;date &#39;2001-09-28&#39;&quot; or &quot;interval &#39;2 hours&#39;&quot;.&quot;&quot;&quot;
<span class="gd">-    M_OPEN = [(T.Name.Builtin, None), (T.Keyword, &#39;TIMESTAMP&#39;)]</span>
<span class="gi">+    M_OPEN = [(T.Name.Builtin, None), (T.Keyword, &quot;TIMESTAMP&quot;)]</span>
<span class="w"> </span>    M_CLOSE = T.String.Single, None
<span class="gd">-    M_EXTEND = T.Keyword, (&#39;DAY&#39;, &#39;HOUR&#39;, &#39;MINUTE&#39;, &#39;MONTH&#39;, &#39;SECOND&#39;, &#39;YEAR&#39;)</span>
<span class="gi">+    M_EXTEND = T.Keyword, (&quot;DAY&quot;, &quot;HOUR&quot;, &quot;MINUTE&quot;, &quot;MONTH&quot;, &quot;SECOND&quot;, &quot;YEAR&quot;)</span>


<span class="w"> </span>class Parenthesis(TokenList):
<span class="gu">@@ -267,12 +501,20 @@ class Parenthesis(TokenList):</span>
<span class="w"> </span>    M_OPEN = T.Punctuation, &#39;(&#39;
<span class="w"> </span>    M_CLOSE = T.Punctuation, &#39;)&#39;

<span class="gi">+    @property</span>
<span class="gi">+    def _groupable_tokens(self):</span>
<span class="gi">+        return self.tokens[1:-1]</span>
<span class="gi">+</span>

<span class="w"> </span>class SquareBrackets(TokenList):
<span class="w"> </span>    &quot;&quot;&quot;Tokens between square brackets&quot;&quot;&quot;
<span class="w"> </span>    M_OPEN = T.Punctuation, &#39;[&#39;
<span class="w"> </span>    M_CLOSE = T.Punctuation, &#39;]&#39;

<span class="gi">+    @property</span>
<span class="gi">+    def _groupable_tokens(self):</span>
<span class="gi">+        return self.tokens[1:-1]</span>
<span class="gi">+</span>

<span class="w"> </span>class Assignment(TokenList):
<span class="w"> </span>    &quot;&quot;&quot;An assignment like &#39;var := val;&#39;&quot;&quot;&quot;
<span class="gu">@@ -293,16 +535,28 @@ class For(TokenList):</span>
<span class="w"> </span>class Comparison(TokenList):
<span class="w"> </span>    &quot;&quot;&quot;A comparison used for example in WHERE clauses.&quot;&quot;&quot;

<span class="gi">+    @property</span>
<span class="gi">+    def left(self):</span>
<span class="gi">+        return self.tokens[0]</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def right(self):</span>
<span class="gi">+        return self.tokens[-1]</span>
<span class="gi">+</span>

<span class="w"> </span>class Comment(TokenList):
<span class="w"> </span>    &quot;&quot;&quot;A comment.&quot;&quot;&quot;

<span class="gi">+    def is_multiline(self):</span>
<span class="gi">+        return self.tokens and self.tokens[0].ttype == T.Comment.Multiline</span>
<span class="gi">+</span>

<span class="w"> </span>class Where(TokenList):
<span class="w"> </span>    &quot;&quot;&quot;A WHERE clause.&quot;&quot;&quot;
<span class="w"> </span>    M_OPEN = T.Keyword, &#39;WHERE&#39;
<span class="gd">-    M_CLOSE = T.Keyword, (&#39;ORDER BY&#39;, &#39;GROUP BY&#39;, &#39;LIMIT&#39;, &#39;UNION&#39;,</span>
<span class="gd">-        &#39;UNION ALL&#39;, &#39;EXCEPT&#39;, &#39;HAVING&#39;, &#39;RETURNING&#39;, &#39;INTO&#39;)</span>
<span class="gi">+    M_CLOSE = T.Keyword, (</span>
<span class="gi">+        &#39;ORDER BY&#39;, &#39;GROUP BY&#39;, &#39;LIMIT&#39;, &#39;UNION&#39;, &#39;UNION ALL&#39;, &#39;EXCEPT&#39;,</span>
<span class="gi">+        &#39;HAVING&#39;, &#39;RETURNING&#39;, &#39;INTO&#39;)</span>


<span class="w"> </span>class Over(TokenList):
<span class="gu">@@ -326,7 +580,47 @@ class Case(TokenList):</span>

<span class="w"> </span>        If an ELSE exists condition is None.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        CONDITION = 1</span>
<span class="gi">+        VALUE = 2</span>
<span class="gi">+</span>
<span class="gi">+        ret = []</span>
<span class="gi">+        mode = CONDITION</span>
<span class="gi">+</span>
<span class="gi">+        for token in self.tokens:</span>
<span class="gi">+            # Set mode from the current statement</span>
<span class="gi">+            if token.match(T.Keyword, &#39;CASE&#39;):</span>
<span class="gi">+                continue</span>
<span class="gi">+</span>
<span class="gi">+            elif skip_ws and token.ttype in T.Whitespace:</span>
<span class="gi">+                continue</span>
<span class="gi">+</span>
<span class="gi">+            elif token.match(T.Keyword, &#39;WHEN&#39;):</span>
<span class="gi">+                ret.append(([], []))</span>
<span class="gi">+                mode = CONDITION</span>
<span class="gi">+</span>
<span class="gi">+            elif token.match(T.Keyword, &#39;THEN&#39;):</span>
<span class="gi">+                mode = VALUE</span>
<span class="gi">+</span>
<span class="gi">+            elif token.match(T.Keyword, &#39;ELSE&#39;):</span>
<span class="gi">+                ret.append((None, []))</span>
<span class="gi">+                mode = VALUE</span>
<span class="gi">+</span>
<span class="gi">+            elif token.match(T.Keyword, &#39;END&#39;):</span>
<span class="gi">+                mode = None</span>
<span class="gi">+</span>
<span class="gi">+            # First condition without preceding WHEN</span>
<span class="gi">+            if mode and not ret:</span>
<span class="gi">+                ret.append(([], []))</span>
<span class="gi">+</span>
<span class="gi">+            # Append token depending of the current mode</span>
<span class="gi">+            if mode == CONDITION:</span>
<span class="gi">+                ret[-1][0].append(token)</span>
<span class="gi">+</span>
<span class="gi">+            elif mode == VALUE:</span>
<span class="gi">+                ret[-1][1].append(token)</span>
<span class="gi">+</span>
<span class="gi">+        # Return cases list</span>
<span class="gi">+        return ret</span>


<span class="w"> </span>class Function(NameAliasMixin, TokenList):
<span class="gu">@@ -334,11 +628,22 @@ class Function(NameAliasMixin, TokenList):</span>

<span class="w"> </span>    def get_parameters(self):
<span class="w"> </span>        &quot;&quot;&quot;Return a list of parameters.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        parenthesis = self.token_next_by(i=Parenthesis)[1]</span>
<span class="gi">+        result = []</span>
<span class="gi">+        for token in parenthesis.tokens:</span>
<span class="gi">+            if isinstance(token, IdentifierList):</span>
<span class="gi">+                return token.get_identifiers()</span>
<span class="gi">+            elif imt(token, i=(Function, Identifier, TypedLiteral),</span>
<span class="gi">+                     t=T.Literal):</span>
<span class="gi">+                result.append(token)</span>
<span class="gi">+        return result</span>

<span class="w"> </span>    def get_window(self):
<span class="w"> </span>        &quot;&quot;&quot;Return the window if it exists.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        over_clause = self.token_next_by(i=Over)</span>
<span class="gi">+        if not over_clause:</span>
<span class="gi">+            return None</span>
<span class="gi">+        return over_clause[1].tokens[-1]</span>


<span class="w"> </span>class Begin(TokenList):
<span class="gh">diff --git a/sqlparse/tokens.py b/sqlparse/tokens.py</span>
<span class="gh">index 96e1269..143f66b 100644</span>
<span class="gd">--- a/sqlparse/tokens.py</span>
<span class="gi">+++ b/sqlparse/tokens.py</span>
<span class="gu">@@ -1,3 +1,14 @@</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+#</span>
<span class="gi">+# The Token implementation is based on pygment&#39;s token system written</span>
<span class="gi">+# by Georg Brandl.</span>
<span class="gi">+# http://pygments.org/</span>
<span class="gi">+</span>
<span class="w"> </span>&quot;&quot;&quot;Tokens&quot;&quot;&quot;


<span class="gu">@@ -8,6 +19,7 @@ class _TokenType(tuple):</span>
<span class="w"> </span>        return item is not None and (self is item or item[:len(self)] == self)

<span class="w"> </span>    def __getattr__(self, name):
<span class="gi">+        # don&#39;t mess with dunder</span>
<span class="w"> </span>        if name.startswith(&#39;__&#39;):
<span class="w"> </span>            return super().__getattr__(self, name)
<span class="w"> </span>        new = _TokenType(self + (name,))
<span class="gu">@@ -16,15 +28,21 @@ class _TokenType(tuple):</span>
<span class="w"> </span>        return new

<span class="w"> </span>    def __repr__(self):
<span class="gi">+        # self can be False only if its the `root` i.e. Token itself</span>
<span class="w"> </span>        return &#39;Token&#39; + (&#39;.&#39; if self else &#39;&#39;) + &#39;.&#39;.join(self)


<span class="w"> </span>Token = _TokenType()
<span class="gi">+</span>
<span class="gi">+# Special token types</span>
<span class="w"> </span>Text = Token.Text
<span class="w"> </span>Whitespace = Text.Whitespace
<span class="w"> </span>Newline = Whitespace.Newline
<span class="w"> </span>Error = Token.Error
<span class="gi">+# Text that doesn&#39;t belong to this lexer (e.g. HTML in PHP)</span>
<span class="w"> </span>Other = Token.Other
<span class="gi">+</span>
<span class="gi">+# Common token types for source code</span>
<span class="w"> </span>Keyword = Token.Keyword
<span class="w"> </span>Name = Token.Name
<span class="w"> </span>Literal = Token.Literal
<span class="gu">@@ -36,11 +54,18 @@ Comparison = Operator.Comparison</span>
<span class="w"> </span>Wildcard = Token.Wildcard
<span class="w"> </span>Comment = Token.Comment
<span class="w"> </span>Assignment = Token.Assignment
<span class="gi">+</span>
<span class="gi">+# Generic types for non-source code</span>
<span class="w"> </span>Generic = Token.Generic
<span class="w"> </span>Command = Generic.Command
<span class="gi">+</span>
<span class="gi">+# String and some others are not direct children of Token.</span>
<span class="gi">+# alias them:</span>
<span class="w"> </span>Token.Token = Token
<span class="w"> </span>Token.String = String
<span class="w"> </span>Token.Number = Number
<span class="gi">+</span>
<span class="gi">+# SQL specific tokens</span>
<span class="w"> </span>DML = Keyword.DML
<span class="w"> </span>DDL = Keyword.DDL
<span class="w"> </span>CTE = Keyword.CTE
<span class="gh">diff --git a/sqlparse/utils.py b/sqlparse/utils.py</span>
<span class="gh">index a99ca61..58c0245 100644</span>
<span class="gd">--- a/sqlparse/utils.py</span>
<span class="gi">+++ b/sqlparse/utils.py</span>
<span class="gu">@@ -1,21 +1,36 @@</span>
<span class="gi">+#</span>
<span class="gi">+# Copyright (C) 2009-2020 the sqlparse authors and contributors</span>
<span class="gi">+# &lt;see AUTHORS file&gt;</span>
<span class="gi">+#</span>
<span class="gi">+# This module is part of python-sqlparse and is released under</span>
<span class="gi">+# the BSD License: https://opensource.org/licenses/BSD-3-Clause</span>
<span class="gi">+</span>
<span class="w"> </span>import itertools
<span class="w"> </span>import re
<span class="w"> </span>from collections import deque
<span class="w"> </span>from contextlib import contextmanager
<span class="gd">-SPLIT_REGEX = re.compile(</span>
<span class="gd">-    &quot;&quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+# This regular expression replaces the home-cooked parser that was here before.</span>
<span class="gi">+# It is much faster, but requires an extra post-processing step to get the</span>
<span class="gi">+# desired results (that are compatible with what you would expect from the</span>
<span class="gi">+# str.splitlines() method).</span>
<span class="gi">+#</span>
<span class="gi">+# It matches groups of characters: newlines, quoted strings, or unquoted text,</span>
<span class="gi">+# and splits on that basis. The post-processing step puts those back together</span>
<span class="gi">+# into the actual lines of SQL.</span>
<span class="gi">+SPLIT_REGEX = re.compile(r&quot;&quot;&quot;</span>
<span class="w"> </span>(
<span class="w"> </span> (?:                     # Start of non-capturing group
<span class="gd">-  (?:\\r\\n|\\r|\\n)      |  # Match any single newline, or</span>
<span class="gd">-  [^\\r\\n&#39;&quot;]+          |  # Match any character series without quotes or</span>
<span class="gi">+  (?:\r\n|\r|\n)      |  # Match any single newline, or</span>
<span class="gi">+  [^\r\n&#39;&quot;]+          |  # Match any character series without quotes or</span>
<span class="w"> </span>                         # newlines, or
<span class="gd">-  &quot;(?:[^&quot;\\\\]|\\\\.)*&quot;   |  # Match double-quoted strings, or</span>
<span class="gd">-  &#39;(?:[^&#39;\\\\]|\\\\.)*&#39;      # Match single quoted strings</span>
<span class="gi">+  &quot;(?:[^&quot;\\]|\\.)*&quot;   |  # Match double-quoted strings, or</span>
<span class="gi">+  &#39;(?:[^&#39;\\]|\\.)*&#39;      # Match single quoted strings</span>
<span class="w"> </span> )
<span class="w"> </span>)
<span class="gd">-&quot;&quot;&quot;</span>
<span class="gd">-    , re.VERBOSE)</span>
<span class="gd">-LINE_MATCH = re.compile(&#39;(\\r\\n|\\r|\\n)&#39;)</span>
<span class="gi">+&quot;&quot;&quot;, re.VERBOSE)</span>
<span class="gi">+</span>
<span class="gi">+LINE_MATCH = re.compile(r&#39;(\r\n|\r|\n)&#39;)</span>


<span class="w"> </span>def split_unquoted_newlines(stmt):
<span class="gu">@@ -23,12 +38,26 @@ def split_unquoted_newlines(stmt):</span>

<span class="w"> </span>    Unlike str.splitlines(), this will ignore CR/LF/CR+LF if the requisite
<span class="w"> </span>    character is inside of a string.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    text = str(stmt)</span>
<span class="gi">+    lines = SPLIT_REGEX.split(text)</span>
<span class="gi">+    outputlines = [&#39;&#39;]</span>
<span class="gi">+    for line in lines:</span>
<span class="gi">+        if not line:</span>
<span class="gi">+            continue</span>
<span class="gi">+        elif LINE_MATCH.match(line):</span>
<span class="gi">+            outputlines.append(&#39;&#39;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            outputlines[-1] += line</span>
<span class="gi">+    return outputlines</span>


<span class="w"> </span>def remove_quotes(val):
<span class="w"> </span>    &quot;&quot;&quot;Helper that removes surrounding quotes from strings.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if val is None:</span>
<span class="gi">+        return</span>
<span class="gi">+    if val[0] in (&#39;&quot;&#39;, &quot;&#39;&quot;, &#39;`&#39;) and val[0] == val[-1]:</span>
<span class="gi">+        val = val[1:-1]</span>
<span class="gi">+    return val</span>


<span class="w"> </span>def recurse(*cls):
<span class="gu">@@ -37,7 +66,16 @@ def recurse(*cls):</span>
<span class="w"> </span>    :param cls: Classes to not recurse over
<span class="w"> </span>    :return: function
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    def wrap(f):</span>
<span class="gi">+        def wrapped_f(tlist):</span>
<span class="gi">+            for sgroup in tlist.get_sublists():</span>
<span class="gi">+                if not isinstance(sgroup, cls):</span>
<span class="gi">+                    wrapped_f(sgroup)</span>
<span class="gi">+            f(tlist)</span>
<span class="gi">+</span>
<span class="gi">+        return wrapped_f</span>
<span class="gi">+</span>
<span class="gi">+    return wrap</span>


<span class="w"> </span>def imt(token, i=None, m=None, t=None):
<span class="gu">@@ -48,9 +86,39 @@ def imt(token, i=None, m=None, t=None):</span>
<span class="w"> </span>    :param t: TokenType or Tuple/List of TokenTypes
<span class="w"> </span>    :return:  bool
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if token is None:</span>
<span class="gi">+        return False</span>
<span class="gi">+    if i and isinstance(token, i):</span>
<span class="gi">+        return True</span>
<span class="gi">+    if m:</span>
<span class="gi">+        if isinstance(m, list):</span>
<span class="gi">+            if any(token.match(*pattern) for pattern in m):</span>
<span class="gi">+                return True</span>
<span class="gi">+        elif token.match(*m):</span>
<span class="gi">+            return True</span>
<span class="gi">+    if t:</span>
<span class="gi">+        if isinstance(t, list):</span>
<span class="gi">+            if any(token.ttype in ttype for ttype in t):</span>
<span class="gi">+                return True</span>
<span class="gi">+        elif token.ttype in t:</span>
<span class="gi">+            return True</span>
<span class="gi">+    return False</span>


<span class="w"> </span>def consume(iterator, n):
<span class="w"> </span>    &quot;&quot;&quot;Advance the iterator n-steps ahead. If n is none, consume entirely.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    deque(itertools.islice(iterator, n), maxlen=0)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@contextmanager</span>
<span class="gi">+def offset(filter_, n=0):</span>
<span class="gi">+    filter_.offset += n</span>
<span class="gi">+    yield</span>
<span class="gi">+    filter_.offset -= n</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@contextmanager</span>
<span class="gi">+def indent(filter_, n=1):</span>
<span class="gi">+    filter_.indent += n</span>
<span class="gi">+    yield</span>
<span class="gi">+    filter_.indent -= n</span>
</code></pre></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.d6f25eb3.min.js"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../javascripts/tablesort.js"></script>
      
        <script src="../javascripts/tablesort.number.js"></script>
      
    
  </body>
</html>