{"created": 1732308235.854805, "duration": 0.8161578178405762, "exitcode": 1, "root": "/testbed", "environment": {}, "summary": {"passed": 83, "failed": 57, "total": 140, "collected": 150, "deselected": 10}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "tests", "type": "Package"}]}, {"nodeid": "tests/test_benchmark.py", "outcome": "passed", "result": [{"nodeid": "tests/test_benchmark.py::test_event_init", "type": "Function", "lineno": 17, "deselected": true}, {"nodeid": "tests/test_benchmark.py::test_timeout_init", "type": "Function", "lineno": 22, "deselected": true}, {"nodeid": "tests/test_benchmark.py::test_process_init", "type": "Function", "lineno": 27, "deselected": true}, {"nodeid": "tests/test_benchmark.py::test_environment_step", "type": "Function", "lineno": 35, "deselected": true}, {"nodeid": "tests/test_benchmark.py::test_condition_events", "type": "Function", "lineno": 45, "deselected": true}, {"nodeid": "tests/test_benchmark.py::test_condition_wait", "type": "Function", "lineno": 58, "deselected": true}, {"nodeid": "tests/test_benchmark.py::test_wait_for_proc", "type": "Function", "lineno": 71, "deselected": true}, {"nodeid": "tests/test_benchmark.py::test_store_sim", "type": "Function", "lineno": 92, "deselected": true}, {"nodeid": "tests/test_benchmark.py::test_resource_sim", "type": "Function", "lineno": 118, "deselected": true}, {"nodeid": "tests/test_benchmark.py::test_container_sim", "type": "Function", "lineno": 138, "deselected": true}]}, {"nodeid": "tests/test_condition.py", "outcome": "passed", "result": [{"nodeid": "tests/test_condition.py::test_operator_and", "type": "Function", "lineno": 3}, {"nodeid": "tests/test_condition.py::test_operator_and_blocked", "type": "Function", "lineno": 18}, {"nodeid": "tests/test_condition.py::test_operator_or", "type": "Function", "lineno": 31}, {"nodeid": "tests/test_condition.py::test_operator_nested_and", "type": "Function", "lineno": 44}, {"nodeid": "tests/test_condition.py::test_operator_nested_or", "type": "Function", "lineno": 59}, {"nodeid": "tests/test_condition.py::test_nested_cond_with_error", "type": "Function", "lineno": 75}, {"nodeid": "tests/test_condition.py::test_cond_with_error", "type": "Function", "lineno": 88}, {"nodeid": "tests/test_condition.py::test_cond_with_nested_error", "type": "Function", "lineno": 101}, {"nodeid": "tests/test_condition.py::test_cond_with_uncaught_error", "type": "Function", "lineno": 114}, {"nodeid": "tests/test_condition.py::test_iand_with_and_cond", "type": "Function", "lineno": 131}, {"nodeid": "tests/test_condition.py::test_iand_with_or_cond", "type": "Function", "lineno": 146}, {"nodeid": "tests/test_condition.py::test_ior_with_or_cond", "type": "Function", "lineno": 161}, {"nodeid": "tests/test_condition.py::test_ior_with_and_cond", "type": "Function", "lineno": 176}, {"nodeid": "tests/test_condition.py::test_immutable_results", "type": "Function", "lineno": 191}, {"nodeid": "tests/test_condition.py::test_shared_and_condition", "type": "Function", "lineno": 213}, {"nodeid": "tests/test_condition.py::test_shared_or_condition", "type": "Function", "lineno": 231}, {"nodeid": "tests/test_condition.py::test_condition_value", "type": "Function", "lineno": 249}, {"nodeid": "tests/test_condition.py::test_result_order", "type": "Function", "lineno": 268}, {"nodeid": "tests/test_condition.py::test_nested_result_order", "type": "Function", "lineno": 281}, {"nodeid": "tests/test_condition.py::test_all_of_empty_list", "type": "Function", "lineno": 295}, {"nodeid": "tests/test_condition.py::test_any_of_empty_list", "type": "Function", "lineno": 301}]}, {"nodeid": "tests/test_environment.py", "outcome": "passed", "result": [{"nodeid": "tests/test_environment.py::test_event_queue_empty", "type": "Function", "lineno": 8}, {"nodeid": "tests/test_environment.py::test_run_negative_until", "type": "Function", "lineno": 23}, {"nodeid": "tests/test_environment.py::test_run_resume", "type": "Function", "lineno": 31}, {"nodeid": "tests/test_environment.py::test_run_until_value", "type": "Function", "lineno": 53}, {"nodeid": "tests/test_environment.py::test_run_with_processed_event", "type": "Function", "lineno": 59}, {"nodeid": "tests/test_environment.py::test_run_with_untriggered_event", "type": "Function", "lineno": 72}]}, {"nodeid": "tests/test_event.py", "outcome": "passed", "result": [{"nodeid": "tests/test_event.py::test_succeed", "type": "Function", "lineno": 10}, {"nodeid": "tests/test_event.py::test_fail", "type": "Function", "lineno": 28}, {"nodeid": "tests/test_event.py::test_names", "type": "Function", "lineno": 46}, {"nodeid": "tests/test_event.py::test_value", "type": "Function", "lineno": 67}, {"nodeid": "tests/test_event.py::test_unavailable_value", "type": "Function", "lineno": 76}, {"nodeid": "tests/test_event.py::test_triggered", "type": "Function", "lineno": 85}, {"nodeid": "tests/test_event.py::test_callback_modification", "type": "Function", "lineno": 98}, {"nodeid": "tests/test_event.py::test_condition_callback_removal", "type": "Function", "lineno": 111}, {"nodeid": "tests/test_event.py::test_condition_nested_callback_removal", "type": "Function", "lineno": 121}]}, {"nodeid": "tests/test_exceptions.py", "outcome": "passed", "result": [{"nodeid": "tests/test_exceptions.py::test_error_forwarding", "type": "Function", "lineno": 12}, {"nodeid": "tests/test_exceptions.py::test_no_parent_process", "type": "Function", "lineno": 30}, {"nodeid": "tests/test_exceptions.py::test_crashing_child_traceback", "type": "Function", "lineno": 52}, {"nodeid": "tests/test_exceptions.py::test_exception_chaining", "type": "Function", "lineno": 71}, {"nodeid": "tests/test_exceptions.py::test_invalid_event", "type": "Function", "lineno": 142}, {"nodeid": "tests/test_exceptions.py::test_exception_handling", "type": "Function", "lineno": 153}, {"nodeid": "tests/test_exceptions.py::test_callback_exception_handling", "type": "Function", "lineno": 163}, {"nodeid": "tests/test_exceptions.py::test_process_exception_handling", "type": "Function", "lineno": 178}, {"nodeid": "tests/test_exceptions.py::test_process_exception_chaining", "type": "Function", "lineno": 197}, {"nodeid": "tests/test_exceptions.py::test_sys_excepthook", "type": "Function", "lineno": 228}]}, {"nodeid": "tests/test_interrupts.py", "outcome": "passed", "result": [{"nodeid": "tests/test_interrupts.py::test_interruption", "type": "Function", "lineno": 11}, {"nodeid": "tests/test_interrupts.py::test_concurrent_interrupts", "type": "Function", "lineno": 27}, {"nodeid": "tests/test_interrupts.py::test_concurrent_interrupts_and_events", "type": "Function", "lineno": 52}, {"nodeid": "tests/test_interrupts.py::test_init_interrupt", "type": "Function", "lineno": 80}, {"nodeid": "tests/test_interrupts.py::test_interrupt_terminated_process", "type": "Function", "lineno": 101}, {"nodeid": "tests/test_interrupts.py::test_multiple_interrupts", "type": "Function", "lineno": 125}, {"nodeid": "tests/test_interrupts.py::test_interrupt_self", "type": "Function", "lineno": 151}, {"nodeid": "tests/test_interrupts.py::test_immediate_interrupt", "type": "Function", "lineno": 162}, {"nodeid": "tests/test_interrupts.py::test_interrupt_event", "type": "Function", "lineno": 184}, {"nodeid": "tests/test_interrupts.py::test_concurrent_behaviour", "type": "Function", "lineno": 202}]}, {"nodeid": "tests/test_process.py", "outcome": "passed", "result": [{"nodeid": "tests/test_process.py::test_start_non_process", "type": "Function", "lineno": 10}, {"nodeid": "tests/test_process.py::test_get_state", "type": "Function", "lineno": 20}, {"nodeid": "tests/test_process.py::test_target", "type": "Function", "lineno": 38}, {"nodeid": "tests/test_process.py::test_wait_for_proc", "type": "Function", "lineno": 52}, {"nodeid": "tests/test_process.py::test_return_value", "type": "Function", "lineno": 68}, {"nodeid": "tests/test_process.py::test_child_exception", "type": "Function", "lineno": 85}, {"nodeid": "tests/test_process.py::test_interrupted_join", "type": "Function", "lineno": 100}, {"nodeid": "tests/test_process.py::test_interrupted_join_and_rejoin", "type": "Function", "lineno": 128}, {"nodeid": "tests/test_process.py::test_error_and_interrupted_join", "type": "Function", "lineno": 158}]}, {"nodeid": "tests/test_resources.py", "outcome": "passed", "result": [{"nodeid": "tests/test_resources.py::test_resource", "type": "Function", "lineno": 15}, {"nodeid": "tests/test_resources.py::test_resource_capacity", "type": "Function", "lineno": 42}, {"nodeid": "tests/test_resources.py::test_resource_context_manager", "type": "Function", "lineno": 47}, {"nodeid": "tests/test_resources.py::test_resource_slots", "type": "Function", "lineno": 66}, {"nodeid": "tests/test_resources.py::test_resource_continue_after_interrupt", "type": "Function", "lineno": 91}, {"nodeid": "tests/test_resources.py::test_resource_release_after_interrupt", "type": "Function", "lineno": 122}, {"nodeid": "tests/test_resources.py::test_resource_immediate_requests", "type": "Function", "lineno": 153}, {"nodeid": "tests/test_resources.py::test_resource_cm_exception", "type": "Function", "lineno": 181}, {"nodeid": "tests/test_resources.py::test_resource_with_condition", "type": "Function", "lineno": 203}, {"nodeid": "tests/test_resources.py::test_resource_with_priority_queue", "type": "Function", "lineno": 214}, {"nodeid": "tests/test_resources.py::test_sorted_queue_maxlen", "type": "Function", "lineno": 231}, {"nodeid": "tests/test_resources.py::test_get_users", "type": "Function", "lineno": 251}, {"nodeid": "tests/test_resources.py::test_preemptive_resource", "type": "Function", "lineno": 271}, {"nodeid": "tests/test_resources.py::test_preemptive_resource_timeout_0", "type": "Function", "lineno": 295}, {"nodeid": "tests/test_resources.py::test_mixed_preemption", "type": "Function", "lineno": 317}, {"nodeid": "tests/test_resources.py::test_nested_preemption", "type": "Function", "lineno": 353}, {"nodeid": "tests/test_resources.py::test_container", "type": "Function", "lineno": 421}, {"nodeid": "tests/test_resources.py::test_container_get_queued", "type": "Function", "lineno": 454}, {"nodeid": "tests/test_resources.py::test_initial_container_capacity", "type": "Function", "lineno": 475}, {"nodeid": "tests/test_resources.py::test_container_get_put_bounds", "type": "Function", "lineno": 480}, {"nodeid": "tests/test_resources.py::test_container_init_capacity[None-args0]", "type": "Function", "lineno": 488}, {"nodeid": "tests/test_resources.py::test_container_init_capacity[None-args1]", "type": "Function", "lineno": 488}, {"nodeid": "tests/test_resources.py::test_container_init_capacity[None-args2]", "type": "Function", "lineno": 488}, {"nodeid": "tests/test_resources.py::test_container_init_capacity[ValueError-args3]", "type": "Function", "lineno": 488}, {"nodeid": "tests/test_resources.py::test_container_init_capacity[ValueError-args4]", "type": "Function", "lineno": 488}, {"nodeid": "tests/test_resources.py::test_container_init_capacity[ValueError-args5]", "type": "Function", "lineno": 488}, {"nodeid": "tests/test_resources.py::test_container_init_capacity[ValueError-args6]", "type": "Function", "lineno": 488}, {"nodeid": "tests/test_resources.py::test_store", "type": "Function", "lineno": 513}, {"nodeid": "tests/test_resources.py::test_initial_store_capacity[Store]", "type": "Function", "lineno": 537}, {"nodeid": "tests/test_resources.py::test_initial_store_capacity[FilterStore]", "type": "Function", "lineno": 537}, {"nodeid": "tests/test_resources.py::test_store_capacity", "type": "Function", "lineno": 549}, {"nodeid": "tests/test_resources.py::test_store_cancel", "type": "Function", "lineno": 564}, {"nodeid": "tests/test_resources.py::test_priority_store_item_priority", "type": "Function", "lineno": 576}, {"nodeid": "tests/test_resources.py::test_priority_store_stable_order", "type": "Function", "lineno": 595}, {"nodeid": "tests/test_resources.py::test_filter_store", "type": "Function", "lineno": 618}, {"nodeid": "tests/test_resources.py::test_filter_store_get_after_mismatch", "type": "Function", "lineno": 632}, {"nodeid": "tests/test_resources.py::test_filter_calls_best_case", "type": "Function", "lineno": 665}, {"nodeid": "tests/test_resources.py::test_filter_calls_worst_case", "type": "Function", "lineno": 688}, {"nodeid": "tests/test_resources.py::test_immediate_put_request", "type": "Function", "lineno": 723}, {"nodeid": "tests/test_resources.py::test_immediate_get_request", "type": "Function", "lineno": 744}]}, {"nodeid": "tests/test_rt.py", "outcome": "passed", "result": [{"nodeid": "tests/test_rt.py::test_rt[0.1]", "type": "Function", "lineno": 23}, {"nodeid": "tests/test_rt.py::test_rt[0.05]", "type": "Function", "lineno": 23}, {"nodeid": "tests/test_rt.py::test_rt[0.15]", "type": "Function", "lineno": 23}, {"nodeid": "tests/test_rt.py::test_rt_multiple_call", "type": "Function", "lineno": 38}, {"nodeid": "tests/test_rt.py::test_rt_slow_sim_default_behavior", "type": "Function", "lineno": 60}, {"nodeid": "tests/test_rt.py::test_rt_slow_sim_no_error", "type": "Function", "lineno": 71}, {"nodeid": "tests/test_rt.py::test_rt_illegal_until", "type": "Function", "lineno": 84}, {"nodeid": "tests/test_rt.py::test_rt_sync", "type": "Function", "lineno": 94}, {"nodeid": "tests/test_rt.py::test_run_with_untriggered_event", "type": "Function", "lineno": 103}]}, {"nodeid": "tests/test_timeout.py", "outcome": "passed", "result": [{"nodeid": "tests/test_timeout.py::test_discrete_time_steps", "type": "Function", "lineno": 8}, {"nodeid": "tests/test_timeout.py::test_negative_timeout", "type": "Function", "lineno": 22}, {"nodeid": "tests/test_timeout.py::test_timeout_value", "type": "Function", "lineno": 33}, {"nodeid": "tests/test_timeout.py::test_shared_timeout", "type": "Function", "lineno": 50}, {"nodeid": "tests/test_timeout.py::test_triggered_timeout", "type": "Function", "lineno": 63}]}, {"nodeid": "tests/test_util.py", "outcome": "passed", "result": [{"nodeid": "tests/test_util.py::test_start_delayed", "type": "Function", "lineno": 11}, {"nodeid": "tests/test_util.py::test_start_delayed_error", "type": "Function", "lineno": 20}, {"nodeid": "tests/test_util.py::test_subscribe", "type": "Function", "lineno": 30}, {"nodeid": "tests/test_util.py::test_subscribe_terminated_proc", "type": "Function", "lineno": 53}, {"nodeid": "tests/test_util.py::test_subscribe_with_join", "type": "Function", "lineno": 71}, {"nodeid": "tests/test_util.py::test_subscribe_at_timeout", "type": "Function", "lineno": 93}, {"nodeid": "tests/test_util.py::test_subscribe_at_timeout_with_value", "type": "Function", "lineno": 109}, {"nodeid": "tests/test_util.py::test_all_of", "type": "Function", "lineno": 126}, {"nodeid": "tests/test_util.py::test_all_of_generator", "type": "Function", "lineno": 141}, {"nodeid": "tests/test_util.py::test_wait_for_all_with_errors", "type": "Function", "lineno": 156}, {"nodeid": "tests/test_util.py::test_all_of_chaining", "type": "Function", "lineno": 185}, {"nodeid": "tests/test_util.py::test_all_of_chaining_intermediate_results", "type": "Function", "lineno": 202}, {"nodeid": "tests/test_util.py::test_all_of_with_triggered_events", "type": "Function", "lineno": 225}, {"nodeid": "tests/test_util.py::test_any_of", "type": "Function", "lineno": 240}, {"nodeid": "tests/test_util.py::test_any_of_with_errors", "type": "Function", "lineno": 255}, {"nodeid": "tests/test_util.py::test_any_of_chaining", "type": "Function", "lineno": 276}, {"nodeid": "tests/test_util.py::test_any_of_with_triggered_events", "type": "Function", "lineno": 293}, {"nodeid": "tests/test_util.py::test_empty_any_of", "type": "Function", "lineno": 308}, {"nodeid": "tests/test_util.py::test_empty_all_of", "type": "Function", "lineno": 319}, {"nodeid": "tests/test_util.py::test_all_of_expansion", "type": "Function", "lineno": 330}]}, {"nodeid": "tests/test_version.py", "outcome": "passed", "result": [{"nodeid": "tests/test_version.py::test_simpy_version", "type": "Function", "lineno": 8}]}, {"nodeid": "tests", "outcome": "passed", "result": [{"nodeid": "tests/test_benchmark.py", "type": "Module"}, {"nodeid": "tests/test_condition.py", "type": "Module"}, {"nodeid": "tests/test_environment.py", "type": "Module"}, {"nodeid": "tests/test_event.py", "type": "Module"}, {"nodeid": "tests/test_exceptions.py", "type": "Module"}, {"nodeid": "tests/test_interrupts.py", "type": "Module"}, {"nodeid": "tests/test_process.py", "type": "Module"}, {"nodeid": "tests/test_resources.py", "type": "Module"}, {"nodeid": "tests/test_rt.py", "type": "Module"}, {"nodeid": "tests/test_timeout.py", "type": "Module"}, {"nodeid": "tests/test_util.py", "type": "Module"}, {"nodeid": "tests/test_version.py", "type": "Module"}]}], "tests": [{"nodeid": "tests/test_condition.py::test_operator_and", "lineno": 3, "outcome": "passed", "keywords": ["test_operator_and", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.0005293299999999945, "outcome": "passed"}, "call": {"duration": 0.0002654109999999932, "outcome": "passed"}, "teardown": {"duration": 0.00021879499999943874, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_operator_and_blocked", "lineno": 18, "outcome": "passed", "keywords": ["test_operator_and_blocked", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.0002528090000000205, "outcome": "passed"}, "call": {"duration": 0.00020116800000025137, "outcome": "passed"}, "teardown": {"duration": 0.000189823999999561, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_operator_or", "lineno": 31, "outcome": "passed", "keywords": ["test_operator_or", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00023934699999994535, "outcome": "passed"}, "call": {"duration": 0.00019580700000076945, "outcome": "passed"}, "teardown": {"duration": 0.00019941700000014606, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_operator_nested_and", "lineno": 44, "outcome": "passed", "keywords": ["test_operator_nested_and", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00023759199999950908, "outcome": "passed"}, "call": {"duration": 0.00019400000000047157, "outcome": "passed"}, "teardown": {"duration": 0.0002003899999998282, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_operator_nested_or", "lineno": 59, "outcome": "passed", "keywords": ["test_operator_nested_or", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00023645000000005467, "outcome": "passed"}, "call": {"duration": 0.00019284700000010702, "outcome": "passed"}, "teardown": {"duration": 0.00019344700000001325, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_nested_cond_with_error", "lineno": 75, "outcome": "passed", "keywords": ["test_nested_cond_with_error", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00023686900000008393, "outcome": "passed"}, "call": {"duration": 0.00019310999999966327, "outcome": "passed"}, "teardown": {"duration": 0.00020283499999962373, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_cond_with_error", "lineno": 88, "outcome": "passed", "keywords": ["test_cond_with_error", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.0002361979999996322, "outcome": "passed"}, "call": {"duration": 0.00020481299999985936, "outcome": "passed"}, "teardown": {"duration": 0.0001899000000005202, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_cond_with_nested_error", "lineno": 101, "outcome": "passed", "keywords": ["test_cond_with_nested_error", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00023319299999968734, "outcome": "passed"}, "call": {"duration": 0.00020950000000041769, "outcome": "passed"}, "teardown": {"duration": 0.00018616599999976557, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_cond_with_uncaught_error", "lineno": 114, "outcome": "failed", "keywords": ["test_cond_with_uncaught_error", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00023307699999985942, "outcome": "passed"}, "call": {"duration": 0.0003483079999995198, "outcome": "failed", "crash": {"path": "/testbed/tests/test_condition.py", "lineno": 127, "message": "Failed: DID NOT RAISE <class 'ValueError'>"}, "traceback": [{"path": "tests/test_condition.py", "lineno": 127, "message": "Failed"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea4db520>\n\n    def test_cond_with_uncaught_error(env):\n        \"\"\"Errors that happen after the condition has been triggered will not be\n        handled by the condition and cause the simulation to crash.\"\"\"\n    \n        def explode(env, delay):\n            yield env.timeout(delay)\n            raise ValueError(f'Onoes, failed after {delay}!')\n    \n        def process(env):\n            yield env.timeout(1) | env.process(explode(env, 2))\n    \n        env.process(process(env))\n>       with pytest.raises(ValueError, match='Onoes, failed after'):\nE       Failed: DID NOT RAISE <class 'ValueError'>\n\ntests/test_condition.py:127: Failed"}, "teardown": {"duration": 0.0002225479999999891, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_iand_with_and_cond", "lineno": 131, "outcome": "passed", "keywords": ["test_iand_with_and_cond", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00024876099999993073, "outcome": "passed"}, "call": {"duration": 0.00020542599999995304, "outcome": "passed"}, "teardown": {"duration": 0.0001926199999999767, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_iand_with_or_cond", "lineno": 146, "outcome": "passed", "keywords": ["test_iand_with_or_cond", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00023623999999955458, "outcome": "passed"}, "call": {"duration": 0.0002064869999998109, "outcome": "passed"}, "teardown": {"duration": 0.00018957899999971772, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_ior_with_or_cond", "lineno": 161, "outcome": "passed", "keywords": ["test_ior_with_or_cond", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00023344099999977885, "outcome": "passed"}, "call": {"duration": 0.0001964900000004377, "outcome": "passed"}, "teardown": {"duration": 0.0001925990000000155, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_ior_with_and_cond", "lineno": 176, "outcome": "passed", "keywords": ["test_ior_with_and_cond", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00023751199999999528, "outcome": "passed"}, "call": {"duration": 0.0001959520000003323, "outcome": "passed"}, "teardown": {"duration": 0.0001873300000001521, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_immutable_results", "lineno": 191, "outcome": "passed", "keywords": ["test_immutable_results", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00024482299999917245, "outcome": "passed"}, "call": {"duration": 0.00019379599999957975, "outcome": "passed"}, "teardown": {"duration": 0.00018733399999959488, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_shared_and_condition", "lineno": 213, "outcome": "passed", "keywords": ["test_shared_and_condition", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00024551300000030807, "outcome": "passed"}, "call": {"duration": 0.00022411899999941198, "outcome": "passed"}, "teardown": {"duration": 0.00018736900000071444, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_shared_or_condition", "lineno": 231, "outcome": "passed", "keywords": ["test_shared_or_condition", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00023751700000040898, "outcome": "passed"}, "call": {"duration": 0.00021556500000041723, "outcome": "passed"}, "teardown": {"duration": 0.00018847999999938025, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_condition_value", "lineno": 249, "outcome": "passed", "keywords": ["test_condition_value", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00023790699999981513, "outcome": "passed"}, "call": {"duration": 0.00019919100000009848, "outcome": "passed"}, "teardown": {"duration": 0.00019542200000000065, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_result_order", "lineno": 268, "outcome": "passed", "keywords": ["test_result_order", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00023858100000051508, "outcome": "passed"}, "call": {"duration": 0.00020709899999982184, "outcome": "passed"}, "teardown": {"duration": 0.0002021329999992716, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_nested_result_order", "lineno": 281, "outcome": "passed", "keywords": ["test_nested_result_order", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00023490099999978753, "outcome": "passed"}, "call": {"duration": 0.00021852500000019148, "outcome": "passed"}, "teardown": {"duration": 0.00019182400000072874, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_all_of_empty_list", "lineno": 295, "outcome": "failed", "keywords": ["test_all_of_empty_list", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00023648499999939787, "outcome": "passed"}, "call": {"duration": 0.00029352700000018217, "outcome": "failed", "crash": {"path": "/testbed/tests/test_condition.py", "lineno": 299, "message": "assert None\n +  where None = <None object at 0x7fabea4dc8e0>.triggered"}, "traceback": [{"path": "tests/test_condition.py", "lineno": 299, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea4dec20>\n\n    def test_all_of_empty_list(env):\n        \"\"\"AllOf with an empty list should immediately be triggered.\"\"\"\n        evt = env.all_of([])\n>       assert evt.triggered\nE       assert None\nE        +  where None = <None object at 0x7fabea4dc8e0>.triggered\n\ntests/test_condition.py:299: AssertionError"}, "teardown": {"duration": 0.00022329799999987188, "outcome": "passed"}}, {"nodeid": "tests/test_condition.py::test_any_of_empty_list", "lineno": 301, "outcome": "failed", "keywords": ["test_any_of_empty_list", "test_condition.py", "tests", "testbed", ""], "setup": {"duration": 0.00025481900000023927, "outcome": "passed"}, "call": {"duration": 0.0002721580000004664, "outcome": "failed", "crash": {"path": "/testbed/tests/test_condition.py", "lineno": 305, "message": "assert None\n +  where None = <None object at 0x7fabeb030370>.triggered"}, "traceback": [{"path": "tests/test_condition.py", "lineno": 305, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb032020>\n\n    def test_any_of_empty_list(env):\n        \"\"\"AnyOf with an empty list should immediately be triggered.\"\"\"\n        evt = env.any_of([])\n>       assert evt.triggered\nE       assert None\nE        +  where None = <None object at 0x7fabeb030370>.triggered\n\ntests/test_condition.py:305: AssertionError"}, "teardown": {"duration": 0.00022900000000003473, "outcome": "passed"}}, {"nodeid": "tests/test_environment.py::test_event_queue_empty", "lineno": 8, "outcome": "failed", "keywords": ["test_event_queue_empty", "test_environment.py", "tests", "testbed", ""], "setup": {"duration": 0.0002862079999994549, "outcome": "passed"}, "call": {"duration": 0.0003763640000000734, "outcome": "failed", "crash": {"path": "/testbed/tests/test_environment.py", "lineno": 21, "message": "assert [] == [0, 1]\n  \n  Right contains 2 more items, first extra item: 0\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_environment.py", "lineno": 21, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea4dcd90>, log = []\n\n    def test_event_queue_empty(env, log):\n        \"\"\"The simulation should stop if there are no more events, that means, no\n        more active process.\"\"\"\n    \n        def pem(env, log):\n            while env.now < 2:\n                log.append(env.now)\n                yield env.timeout(1)\n    \n        env.process(pem(env, log))\n        env.run(10)\n    \n>       assert log == [0, 1]\nE       assert [] == [0, 1]\nE         \nE         Right contains 2 more items, first extra item: 0\nE         Use -v to get more diff\n\ntests/test_environment.py:21: AssertionError"}, "teardown": {"duration": 0.0002316750000002088, "outcome": "passed"}}, {"nodeid": "tests/test_environment.py::test_run_negative_until", "lineno": 23, "outcome": "failed", "keywords": ["test_run_negative_until", "test_environment.py", "tests", "testbed", ""], "setup": {"duration": 0.000254744000000251, "outcome": "passed"}, "call": {"duration": 0.00035239400000008914, "outcome": "failed", "crash": {"path": "/testbed/tests/test_environment.py", "lineno": 26, "message": "Failed: DID NOT RAISE <class 'ValueError'>"}, "traceback": [{"path": "tests/test_environment.py", "lineno": 26, "message": "Failed"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb6477f0>\n\n    def test_run_negative_until(env):\n        \"\"\"Test passing a negative time to run.\"\"\"\n>       with pytest.raises(\n            ValueError, match='must be greater than the current simulation time'\n        ):\nE       Failed: DID NOT RAISE <class 'ValueError'>\n\ntests/test_environment.py:26: Failed"}, "teardown": {"duration": 0.0002335980000003346, "outcome": "passed"}}, {"nodeid": "tests/test_environment.py::test_run_resume", "lineno": 31, "outcome": "failed", "keywords": ["test_run_resume", "test_environment.py", "tests", "testbed", ""], "setup": {"duration": 0.00024133000000059468, "outcome": "passed"}, "call": {"duration": 0.0003191830000002227, "outcome": "failed", "crash": {"path": "/testbed/tests/test_environment.py", "lineno": 36, "message": "assert None == 0\n +  where None = <simpy.core.Environment object at 0x7fabea4dfa90>.now"}, "traceback": [{"path": "tests/test_environment.py", "lineno": 36, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea4dfa90>\n\n    def test_run_resume(env):\n        \"\"\"Stopped simulation can be resumed.\"\"\"\n        events = [env.timeout(t) for t in (5, 10, 15)]\n    \n>       assert env.now == 0\nE       assert None == 0\nE        +  where None = <simpy.core.Environment object at 0x7fabea4dfa90>.now\n\ntests/test_environment.py:36: AssertionError"}, "teardown": {"duration": 0.00021931699999999665, "outcome": "passed"}}, {"nodeid": "tests/test_environment.py::test_run_until_value", "lineno": 53, "outcome": "failed", "keywords": ["test_run_until_value", "test_environment.py", "tests", "testbed", ""], "setup": {"duration": 0.00024312399999981693, "outcome": "passed"}, "call": {"duration": 0.0003180450000002111, "outcome": "failed", "crash": {"path": "/testbed/tests/test_environment.py", "lineno": 57, "message": "assert None == 3.141592\n +  where None = <simpy.core.Environment object at 0x7fabeb6443a0>.now"}, "traceback": [{"path": "tests/test_environment.py", "lineno": 57, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb6443a0>\n\n    def test_run_until_value(env):\n        \"\"\"Anything that can be converted to a float is a valid until value.\"\"\"\n        env.run(until='3.141592')\n>       assert env.now == 3.141592\nE       assert None == 3.141592\nE        +  where None = <simpy.core.Environment object at 0x7fabeb6443a0>.now\n\ntests/test_environment.py:57: AssertionError"}, "teardown": {"duration": 0.00021930800000014017, "outcome": "passed"}}, {"nodeid": "tests/test_environment.py::test_run_with_processed_event", "lineno": 59, "outcome": "failed", "keywords": ["test_run_with_processed_event", "test_environment.py", "tests", "testbed", ""], "setup": {"duration": 0.0002388099999999227, "outcome": "passed"}, "call": {"duration": 0.0003229619999993716, "outcome": "failed", "crash": {"path": "/testbed/tests/test_environment.py", "lineno": 63, "message": "AssertionError: assert None == 'spam'\n +  where None = run(until=<None object at 0x7fabea4dec50>)\n +    where run = <simpy.core.Environment object at 0x7fabea4dc6a0>.run"}, "traceback": [{"path": "tests/test_environment.py", "lineno": 63, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea4dc6a0>\n\n    def test_run_with_processed_event(env):\n        \"\"\"An already processed event may also be passed as until value.\"\"\"\n        timeout = env.timeout(1, value='spam')\n>       assert env.run(until=timeout) == 'spam'\nE       AssertionError: assert None == 'spam'\nE        +  where None = run(until=<None object at 0x7fabea4dec50>)\nE        +    where run = <simpy.core.Environment object at 0x7fabea4dc6a0>.run\n\ntests/test_environment.py:63: AssertionError"}, "teardown": {"duration": 0.00021473199999988424, "outcome": "passed"}}, {"nodeid": "tests/test_environment.py::test_run_with_untriggered_event", "lineno": 72, "outcome": "failed", "keywords": ["test_run_with_untriggered_event", "test_environment.py", "tests", "testbed", ""], "setup": {"duration": 0.0002544630000000936, "outcome": "passed"}, "call": {"duration": 0.00021565000000034473, "outcome": "failed", "crash": {"path": "/testbed/tests/test_environment.py", "lineno": 74, "message": "Failed: DID NOT RAISE <class 'RuntimeError'>"}, "traceback": [{"path": "tests/test_environment.py", "lineno": 74, "message": "Failed"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb644040>\n\n    def test_run_with_untriggered_event(env):\n>       excinfo = pytest.raises(RuntimeError, env.run, until=env.event())\nE       Failed: DID NOT RAISE <class 'RuntimeError'>\n\ntests/test_environment.py:74: Failed"}, "teardown": {"duration": 0.00023337200000028702, "outcome": "passed"}}, {"nodeid": "tests/test_event.py::test_succeed", "lineno": 10, "outcome": "passed", "keywords": ["test_succeed", "test_event.py", "tests", "testbed", ""], "setup": {"duration": 0.00026060199999999867, "outcome": "passed"}, "call": {"duration": 0.00022932300000011452, "outcome": "passed"}, "teardown": {"duration": 0.00020037400000028072, "outcome": "passed"}}, {"nodeid": "tests/test_event.py::test_fail", "lineno": 28, "outcome": "passed", "keywords": ["test_fail", "test_event.py", "tests", "testbed", ""], "setup": {"duration": 0.0002360850000000525, "outcome": "passed"}, "call": {"duration": 0.00019288100000025565, "outcome": "passed"}, "teardown": {"duration": 0.0001980140000004127, "outcome": "passed"}}, {"nodeid": "tests/test_event.py::test_names", "lineno": 46, "outcome": "failed", "keywords": ["test_names", "test_event.py", "tests", "testbed", ""], "setup": {"duration": 0.00023747400000040386, "outcome": "passed"}, "call": {"duration": 0.00044807999999996184, "outcome": "failed", "crash": {"path": "/testbed/tests/test_event.py", "lineno": 52, "message": "AssertionError: assert None\n +  where None = <function match at 0x7fabeb8b0e50>('<Event\\\\(\\\\) object at 0x.*>', '<None object at 0x7fabea4df130>')\n +    where <function match at 0x7fabeb8b0e50> = re.match\n +    and   '<None object at 0x7fabea4df130>' = str(<None object at 0x7fabea4df130>)\n +      where <None object at 0x7fabea4df130> = Event()\n +        where Event = <simpy.core.Environment object at 0x7fabea4de380>.event"}, "traceback": [{"path": "tests/test_event.py", "lineno": 52, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea4de380>\n\n    def test_names(env):\n        def pem():\n            return\n            yield\n    \n>       assert re.match(r'<Event\\(\\) object at 0x.*>', str(env.event()))\nE       AssertionError: assert None\nE        +  where None = <function match at 0x7fabeb8b0e50>('<Event\\\\(\\\\) object at 0x.*>', '<None object at 0x7fabea4df130>')\nE        +    where <function match at 0x7fabeb8b0e50> = re.match\nE        +    and   '<None object at 0x7fabea4df130>' = str(<None object at 0x7fabea4df130>)\nE        +      where <None object at 0x7fabea4df130> = Event()\nE        +        where Event = <simpy.core.Environment object at 0x7fabea4de380>.event\n\ntests/test_event.py:52: AssertionError"}, "teardown": {"duration": 0.00022989300000020307, "outcome": "passed"}}, {"nodeid": "tests/test_event.py::test_value", "lineno": 67, "outcome": "failed", "keywords": ["test_value", "test_event.py", "tests", "testbed", ""], "setup": {"duration": 0.00024260400000031268, "outcome": "passed"}, "call": {"duration": 0.0003031069999996916, "outcome": "failed", "crash": {"path": "/testbed/tests/test_event.py", "lineno": 74, "message": "AssertionError: assert None == 'I am the value'\n +  where None = <None object at 0x7fabeb9232b0>.value"}, "traceback": [{"path": "tests/test_event.py", "lineno": 74, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb920850>\n\n    def test_value(env):\n        \"\"\"After an event has been triggered, its value becomes accessible.\"\"\"\n        event = env.timeout(0, 'I am the value')\n    \n        env.run()\n    \n>       assert event.value == 'I am the value'\nE       AssertionError: assert None == 'I am the value'\nE        +  where None = <None object at 0x7fabeb9232b0>.value\n\ntests/test_event.py:74: AssertionError"}, "teardown": {"duration": 0.00021584200000024367, "outcome": "passed"}}, {"nodeid": "tests/test_event.py::test_unavailable_value", "lineno": 76, "outcome": "failed", "keywords": ["test_unavailable_value", "test_event.py", "tests", "testbed", ""], "setup": {"duration": 0.0002430359999996412, "outcome": "passed"}, "call": {"duration": 0.00033032799999954676, "outcome": "failed", "crash": {"path": "/testbed/tests/test_event.py", "lineno": 82, "message": "Failed: DID NOT RAISE <class 'AttributeError'>"}, "traceback": [{"path": "tests/test_event.py", "lineno": 82, "message": "Failed"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea4ddcf0>\n\n    def test_unavailable_value(env):\n        \"\"\"If an event has not yet been triggered, its value is not available and\n        trying to access it will result in a AttributeError.\"\"\"\n        event = env.event()\n    \n>       with pytest.raises(AttributeError, match='.* is not yet available$'):\nE       Failed: DID NOT RAISE <class 'AttributeError'>\n\ntests/test_event.py:82: Failed"}, "teardown": {"duration": 0.00021460100000059157, "outcome": "passed"}}, {"nodeid": "tests/test_event.py::test_triggered", "lineno": 85, "outcome": "failed", "keywords": ["test_triggered", "test_event.py", "tests", "testbed", ""], "setup": {"duration": 0.000241157999999686, "outcome": "passed"}, "call": {"duration": 0.00029421799999962417, "outcome": "failed", "crash": {"path": "/testbed/tests/test_event.py", "lineno": 96, "message": "AssertionError: assert None == 'i was already done'"}, "traceback": [{"path": "tests/test_event.py", "lineno": 96, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea5f25f0>\n\n    def test_triggered(env):\n        def pem(env, event):\n            value = yield event\n            return value\n    \n        event = env.event()\n        event.succeed('i was already done')\n    \n        result = env.run(env.process(pem(env, event)))\n    \n>       assert result == 'i was already done'\nE       AssertionError: assert None == 'i was already done'\n\ntests/test_event.py:96: AssertionError"}, "teardown": {"duration": 0.00022635099999934738, "outcome": "passed"}}, {"nodeid": "tests/test_event.py::test_callback_modification", "lineno": 98, "outcome": "passed", "keywords": ["test_callback_modification", "test_event.py", "tests", "testbed", ""], "setup": {"duration": 0.00024109300000052514, "outcome": "passed"}, "call": {"duration": 0.00019110599999994093, "outcome": "passed"}, "teardown": {"duration": 0.00019038499999979308, "outcome": "passed"}}, {"nodeid": "tests/test_event.py::test_condition_callback_removal", "lineno": 111, "outcome": "failed", "keywords": ["test_condition_callback_removal", "test_event.py", "tests", "testbed", ""], "setup": {"duration": 0.0002306789999995118, "outcome": "passed"}, "call": {"duration": 0.0002894690000001532, "outcome": "failed", "crash": {"path": "/testbed/tests/test_event.py", "lineno": 118, "message": "assert not [<bound method Condition._check of <None object at 0x7fabeb5d9540>>]\n +  where [<bound method Condition._check of <None object at 0x7fabeb5d9540>>] = <None object at 0x7fabeb5dbfd0>.callbacks"}, "traceback": [{"path": "tests/test_event.py", "lineno": 118, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb5db370>\n\n    def test_condition_callback_removal(env):\n        \"\"\"A condition will remove all outstanding callbacks from its events.\"\"\"\n        a, b = env.event(), env.event()\n        a.succeed()\n        env.run(until=a | b)\n        # The condition has removed its callback from event b.\n>       assert not a.callbacks\nE       assert not [<bound method Condition._check of <None object at 0x7fabeb5d9540>>]\nE        +  where [<bound method Condition._check of <None object at 0x7fabeb5d9540>>] = <None object at 0x7fabeb5dbfd0>.callbacks\n\ntests/test_event.py:118: AssertionError"}, "teardown": {"duration": 0.00021460800000028257, "outcome": "passed"}}, {"nodeid": "tests/test_event.py::test_condition_nested_callback_removal", "lineno": 121, "outcome": "failed", "keywords": ["test_condition_nested_callback_removal", "test_event.py", "tests", "testbed", ""], "setup": {"duration": 0.00024598700000044715, "outcome": "passed"}, "call": {"duration": 0.00030168800000041074, "outcome": "failed", "crash": {"path": "/testbed/tests/test_event.py", "lineno": 131, "message": "assert not [<bound method Condition._check of <None object at 0x7fabea5f3940>>]\n +  where [<bound method Condition._check of <None object at 0x7fabea5f3940>>] = <None object at 0x7fabea5f1690>.callbacks"}, "traceback": [{"path": "tests/test_event.py", "lineno": 131, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea5f2920>\n\n    def test_condition_nested_callback_removal(env):\n        \"\"\"A condition will remove all outstanding callbacks from its events (even\n        if nested).\"\"\"\n        a, b, c = env.event(), env.event(), env.event()\n        b_and_c = b & c\n        a_or_b_and_c = a | b_and_c\n        a.succeed()\n        env.run(until=a_or_b_and_c)\n        # Callbacks from nested conditions are also removed.\n>       assert not a.callbacks\nE       assert not [<bound method Condition._check of <None object at 0x7fabea5f3940>>]\nE        +  where [<bound method Condition._check of <None object at 0x7fabea5f3940>>] = <None object at 0x7fabea5f1690>.callbacks\n\ntests/test_event.py:131: AssertionError"}, "teardown": {"duration": 0.00023506700000019976, "outcome": "passed"}}, {"nodeid": "tests/test_exceptions.py::test_error_forwarding", "lineno": 12, "outcome": "passed", "keywords": ["test_error_forwarding", "test_exceptions.py", "tests", "testbed", ""], "setup": {"duration": 0.0003256949999999037, "outcome": "passed"}, "call": {"duration": 0.00020178600000075875, "outcome": "passed"}, "teardown": {"duration": 0.00018867900000074656, "outcome": "passed"}}, {"nodeid": "tests/test_exceptions.py::test_no_parent_process", "lineno": 30, "outcome": "failed", "keywords": ["test_no_parent_process", "test_exceptions.py", "tests", "testbed", ""], "setup": {"duration": 0.00024395700000034992, "outcome": "passed"}, "call": {"duration": 0.0002865690000000143, "outcome": "failed", "crash": {"path": "/testbed/tests/test_exceptions.py", "lineno": 49, "message": "Failed: DID NOT RAISE <class 'ValueError'>"}, "traceback": [{"path": "tests/test_exceptions.py", "lineno": 49, "message": "Failed"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb5dac50>\n\n    def test_no_parent_process(env):\n        \"\"\"Exceptions should be normally raised if there are no processes waiting\n        for the one that raises something.\n    \n        \"\"\"\n    \n        def child(env):\n            raise ValueError('Onoes!')\n            yield env.timeout(1)\n    \n        def parent(env):\n            try:\n                env.process(child(env))\n                yield env.timeout(1)\n            except Exception as err:\n                pytest.fail(f'There should be no error ({err}).')\n    \n        env.process(parent(env))\n>       with pytest.raises(ValueError, match='Onoes!'):\nE       Failed: DID NOT RAISE <class 'ValueError'>\n\ntests/test_exceptions.py:49: Failed"}, "teardown": {"duration": 0.00021829599999989568, "outcome": "passed"}}, {"nodeid": "tests/test_exceptions.py::test_crashing_child_traceback", "lineno": 52, "outcome": "passed", "keywords": ["test_crashing_child_traceback", "test_exceptions.py", "tests", "testbed", ""], "setup": {"duration": 0.0002510109999995791, "outcome": "passed"}, "call": {"duration": 0.0001951919999996221, "outcome": "passed"}, "teardown": {"duration": 0.00018799199999985916, "outcome": "passed"}}, {"nodeid": "tests/test_exceptions.py::test_exception_chaining", "lineno": 71, "outcome": "failed", "keywords": ["test_exception_chaining", "test_exceptions.py", "tests", "testbed", ""], "setup": {"duration": 0.0002446349999996045, "outcome": "passed"}, "call": {"duration": 0.0002078059999996995, "outcome": "failed", "crash": {"path": "/testbed/tests/test_exceptions.py", "lineno": 93, "message": "Failed: There should have been an exception"}, "traceback": [{"path": "tests/test_exceptions.py", "lineno": 93, "message": "Failed"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb3444f0>\n\n    def test_exception_chaining(env):\n        \"\"\"Unhandled exceptions pass through the entire event stack. This must be\n        visible in the stacktrace of the exception.\n    \n        \"\"\"\n    \n        def child(env):\n            yield env.timeout(1)\n            raise RuntimeError('foo')\n    \n        def parent(env):\n            child_proc = env.process(child(env))\n            yield child_proc\n    \n        def grandparent(env):\n            parent_proc = env.process(parent(env))\n            yield parent_proc\n    \n        env.process(grandparent(env))\n        try:\n            env.run()\n>           pytest.fail('There should have been an exception')\nE           Failed: There should have been an exception\n\ntests/test_exceptions.py:93: Failed"}, "teardown": {"duration": 0.00021781799999942564, "outcome": "passed"}}, {"nodeid": "tests/test_exceptions.py::test_invalid_event", "lineno": 142, "outcome": "failed", "keywords": ["test_invalid_event", "test_exceptions.py", "tests", "testbed", ""], "setup": {"duration": 0.00024343800000004023, "outcome": "passed"}, "call": {"duration": 0.00031710999999923217, "outcome": "failed", "crash": {"path": "/testbed/tests/test_exceptions.py", "lineno": 150, "message": "Failed: DID NOT RAISE <class 'RuntimeError'>"}, "traceback": [{"path": "tests/test_exceptions.py", "lineno": 150, "message": "Failed"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb1b7b20>\n\n    def test_invalid_event(env):\n        \"\"\"Invalid yield values will cause the simulation to fail.\"\"\"\n    \n        def root(_):\n            yield None\n    \n        env.process(root(env))\n>       with pytest.raises(RuntimeError, match='Invalid yield value \"None\"'):\nE       Failed: DID NOT RAISE <class 'RuntimeError'>\n\ntests/test_exceptions.py:150: Failed"}, "teardown": {"duration": 0.0002454880000000159, "outcome": "passed"}}, {"nodeid": "tests/test_exceptions.py::test_exception_handling", "lineno": 153, "outcome": "failed", "keywords": ["test_exception_handling", "test_exceptions.py", "tests", "testbed", ""], "setup": {"duration": 0.00039318999999959914, "outcome": "passed"}, "call": {"duration": 0.00024293100000072343, "outcome": "failed", "crash": {"path": "/testbed/tests/test_exceptions.py", "lineno": 160, "message": "Failed: DID NOT RAISE <class 'RuntimeError'>"}, "traceback": [{"path": "tests/test_exceptions.py", "lineno": 160, "message": "Failed"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb431300>\n\n    def test_exception_handling(env):\n        \"\"\"If failed events are not defused (which is the default) the simulation\n        crashes.\"\"\"\n    \n        event = env.event()\n        event.fail(RuntimeError())\n>       with pytest.raises(RuntimeError):\nE       Failed: DID NOT RAISE <class 'RuntimeError'>\n\ntests/test_exceptions.py:160: Failed"}, "teardown": {"duration": 0.00022226599999974894, "outcome": "passed"}}, {"nodeid": "tests/test_exceptions.py::test_callback_exception_handling", "lineno": 163, "outcome": "failed", "keywords": ["test_callback_exception_handling", "test_exceptions.py", "tests", "testbed", ""], "setup": {"duration": 0.00025553099999964246, "outcome": "passed"}, "call": {"duration": 0.00026909799999952355, "outcome": "failed", "crash": {"path": "/testbed/tests/test_exceptions.py", "lineno": 176, "message": "AssertionError: Event has not been defused\nassert None\n +  where None = <None object at 0x7fabeb6b2110>.defused"}, "traceback": [{"path": "tests/test_exceptions.py", "lineno": 176, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb6b3790>\n\n    def test_callback_exception_handling(env):\n        \"\"\"Callbacks of events may handle exception by setting the ``defused``\n        attribute of ``event`` to ``True``.\"\"\"\n    \n        def callback(event):\n            event.defused = True\n    \n        event = env.event()\n        event.callbacks.append(callback)\n        event.fail(RuntimeError())\n        assert not event.defused, 'Event has been defused immediately'\n        env.run(until=1)\n>       assert event.defused, 'Event has not been defused'\nE       AssertionError: Event has not been defused\nE       assert None\nE        +  where None = <None object at 0x7fabeb6b2110>.defused\n\ntests/test_exceptions.py:176: AssertionError"}, "teardown": {"duration": 0.00023274199999967493, "outcome": "passed"}}, {"nodeid": "tests/test_exceptions.py::test_process_exception_handling", "lineno": 178, "outcome": "failed", "keywords": ["test_process_exception_handling", "test_exceptions.py", "tests", "testbed", ""], "setup": {"duration": 0.00024555199999998223, "outcome": "passed"}, "call": {"duration": 0.00027035599999969406, "outcome": "failed", "crash": {"path": "/testbed/tests/test_exceptions.py", "lineno": 195, "message": "AssertionError: Event has not been defused\nassert None\n +  where None = <None object at 0x7fabeb431480>.defused"}, "traceback": [{"path": "tests/test_exceptions.py", "lineno": 195, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb4320b0>\n\n    def test_process_exception_handling(env):\n        \"\"\"Processes can't ignore failed events and auto-handle exceptions.\"\"\"\n    \n        def pem(_, event):\n            try:\n                yield event\n                pytest.fail('Hey, the event should fail!')\n            except RuntimeError:\n                pass\n    \n        event = env.event()\n        env.process(pem(env, event))\n        event.fail(RuntimeError())\n    \n        assert not event.defused, 'Event has been defused immediately'\n        env.run(until=1)\n>       assert event.defused, 'Event has not been defused'\nE       AssertionError: Event has not been defused\nE       assert None\nE        +  where None = <None object at 0x7fabeb431480>.defused\n\ntests/test_exceptions.py:195: AssertionError"}, "teardown": {"duration": 0.00022024700000056185, "outcome": "passed"}}, {"nodeid": "tests/test_exceptions.py::test_process_exception_chaining", "lineno": 197, "outcome": "passed", "keywords": ["test_process_exception_chaining", "test_exceptions.py", "tests", "testbed", ""], "setup": {"duration": 0.000253320999999751, "outcome": "passed"}, "call": {"duration": 0.00020752799999979032, "outcome": "passed"}, "teardown": {"duration": 0.0001897980000000743, "outcome": "passed"}}, {"nodeid": "tests/test_exceptions.py::test_sys_excepthook", "lineno": 228, "outcome": "passed", "keywords": ["test_sys_excepthook", "test_exceptions.py", "tests", "testbed", ""], "setup": {"duration": 0.0002482839999995434, "outcome": "passed"}, "call": {"duration": 0.0001995759999999791, "outcome": "passed"}, "teardown": {"duration": 0.0001918129999998186, "outcome": "passed"}}, {"nodeid": "tests/test_interrupts.py::test_interruption", "lineno": 11, "outcome": "passed", "keywords": ["test_interruption", "test_interrupts.py", "tests", "testbed", ""], "setup": {"duration": 0.00025415100000003576, "outcome": "passed"}, "call": {"duration": 0.00019513400000015224, "outcome": "passed"}, "teardown": {"duration": 0.00019899700000003406, "outcome": "passed"}}, {"nodeid": "tests/test_interrupts.py::test_concurrent_interrupts", "lineno": 27, "outcome": "failed", "keywords": ["test_concurrent_interrupts", "test_interrupts.py", "tests", "testbed", ""], "setup": {"duration": 0.00026716400000026397, "outcome": "passed"}, "call": {"duration": 0.00039366099999949, "outcome": "failed", "crash": {"path": "/testbed/tests/test_interrupts.py", "lineno": 50, "message": "AssertionError: assert [] == [(0, 'boggis'... (0, 'beans')]\n  \n  Right contains 3 more items, first extra item: (0, 'boggis')\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_interrupts.py", "lineno": 50, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb6b3820>, log = []\n\n    def test_concurrent_interrupts(env, log):\n        \"\"\"Concurrent interrupts are scheduled in the order in which they\n        occurred.\n    \n        \"\"\"\n    \n        def fox(env, log):\n            while True:\n                try:\n                    yield env.timeout(10)\n                except simpy.Interrupt as interrupt:\n                    log.append((env.now, interrupt.cause))\n    \n        def farmer(env, name, fox):\n            fox.interrupt(name)\n            yield env.timeout(1)\n    \n        fantastic_mr_fox = env.process(fox(env, log))\n        for name in ('boggis', 'bunce', 'beans'):\n            env.process(farmer(env, name, fantastic_mr_fox))\n    \n        env.run(20)\n>       assert log == [(0, 'boggis'), (0, 'bunce'), (0, 'beans')]\nE       AssertionError: assert [] == [(0, 'boggis'... (0, 'beans')]\nE         \nE         Right contains 3 more items, first extra item: (0, 'boggis')\nE         Use -v to get more diff\n\ntests/test_interrupts.py:50: AssertionError"}, "teardown": {"duration": 0.000240134000000225, "outcome": "passed"}}, {"nodeid": "tests/test_interrupts.py::test_concurrent_interrupts_and_events", "lineno": 52, "outcome": "failed", "keywords": ["test_concurrent_interrupts_and_events", "test_interrupts.py", "tests", "testbed", ""], "setup": {"duration": 0.0002723580000001391, "outcome": "passed"}, "call": {"duration": 0.00036285399999957946, "outcome": "failed", "crash": {"path": "/testbed/tests/test_interrupts.py", "lineno": 78, "message": "AssertionError: assert [] == ['coup interr...mpleted at 1']\n  \n  Right contains 2 more items, first extra item: 'coup interrupted at 1'\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_interrupts.py", "lineno": 78, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb644bb0>, log = []\n\n    def test_concurrent_interrupts_and_events(env, log):\n        \"\"\"Interrupts interrupt a process while waiting for an event. Even if the\n        event has happened concurrently with the interrupt.\"\"\"\n    \n        def fox(env, coup, log):\n            while True:\n                try:\n                    yield coup\n                    log.append(f'coup completed at {env.now}')\n                except simpy.Interrupt:\n                    log.append(f'coup interrupted at {env.now}')\n                else:\n                    return\n    \n        def master_plan(env, fox, coup):\n            yield env.timeout(1)\n            # Succeed and interrupt concurrently.\n            coup.succeed()\n            fox.interrupt()\n    \n        coup = env.event()\n        fantastic_mr_fox = env.process(fox(env, coup, log))\n        env.process(master_plan(env, fantastic_mr_fox, coup))\n    \n        env.run(5)\n>       assert log == ['coup interrupted at 1', 'coup completed at 1']\nE       AssertionError: assert [] == ['coup interr...mpleted at 1']\nE         \nE         Right contains 2 more items, first extra item: 'coup interrupted at 1'\nE         Use -v to get more diff\n\ntests/test_interrupts.py:78: AssertionError"}, "teardown": {"duration": 0.0006792150000007879, "outcome": "passed"}}, {"nodeid": "tests/test_interrupts.py::test_init_interrupt", "lineno": 80, "outcome": "passed", "keywords": ["test_init_interrupt", "test_interrupts.py", "tests", "testbed", ""], "setup": {"duration": 0.0003417969999999215, "outcome": "passed"}, "call": {"duration": 0.0002353540000008536, "outcome": "passed"}, "teardown": {"duration": 0.00021920200000025147, "outcome": "passed"}}, {"nodeid": "tests/test_interrupts.py::test_interrupt_terminated_process", "lineno": 101, "outcome": "passed", "keywords": ["test_interrupt_terminated_process", "test_interrupts.py", "tests", "testbed", ""], "setup": {"duration": 0.00023961900000024627, "outcome": "passed"}, "call": {"duration": 0.00019675800000040766, "outcome": "passed"}, "teardown": {"duration": 0.00020295499999978261, "outcome": "passed"}}, {"nodeid": "tests/test_interrupts.py::test_multiple_interrupts", "lineno": 125, "outcome": "passed", "keywords": ["test_multiple_interrupts", "test_interrupts.py", "tests", "testbed", ""], "setup": {"duration": 0.00023917000000039934, "outcome": "passed"}, "call": {"duration": 0.00019326699999933084, "outcome": "passed"}, "teardown": {"duration": 0.000194038000000063, "outcome": "passed"}}, {"nodeid": "tests/test_interrupts.py::test_interrupt_self", "lineno": 151, "outcome": "passed", "keywords": ["test_interrupt_self", "test_interrupts.py", "tests", "testbed", ""], "setup": {"duration": 0.00023703699999977346, "outcome": "passed"}, "call": {"duration": 0.00019373100000041887, "outcome": "passed"}, "teardown": {"duration": 0.00018999699999966424, "outcome": "passed"}}, {"nodeid": "tests/test_interrupts.py::test_immediate_interrupt", "lineno": 162, "outcome": "failed", "keywords": ["test_immediate_interrupt", "test_interrupts.py", "tests", "testbed", ""], "setup": {"duration": 0.00026384099999976485, "outcome": "passed"}, "call": {"duration": 0.0003539569999997383, "outcome": "failed", "crash": {"path": "/testbed/tests/test_interrupts.py", "lineno": 182, "message": "assert [] == [0]\n  \n  Right contains one more item: 0\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_interrupts.py", "lineno": 182, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb6b2710>, log = []\n\n    def test_immediate_interrupt(env, log):\n        \"\"\"Processes are immediately interruptable.\"\"\"\n    \n        def child(env, log):\n            try:\n                yield env.event()\n            except simpy.Interrupt:\n                log.append(env.now)\n    \n        def parent(env, log):\n            child_proc = env.process(child(env, log))\n            child_proc.interrupt()\n            return\n            yield\n    \n        env.process(parent(env, log))\n        env.run()\n    \n        # Confirm that child has been interrupted immediately at timestep 0.\n>       assert log == [0]\nE       assert [] == [0]\nE         \nE         Right contains one more item: 0\nE         Use -v to get more diff\n\ntests/test_interrupts.py:182: AssertionError"}, "teardown": {"duration": 0.00023733700000061475, "outcome": "passed"}}, {"nodeid": "tests/test_interrupts.py::test_interrupt_event", "lineno": 184, "outcome": "passed", "keywords": ["test_interrupt_event", "test_interrupts.py", "tests", "testbed", ""], "setup": {"duration": 0.00024352600000021596, "outcome": "passed"}, "call": {"duration": 0.00019622000000030226, "outcome": "passed"}, "teardown": {"duration": 0.00020133800000010638, "outcome": "passed"}}, {"nodeid": "tests/test_interrupts.py::test_concurrent_behaviour", "lineno": 202, "outcome": "passed", "keywords": ["test_concurrent_behaviour", "test_interrupts.py", "tests", "testbed", ""], "setup": {"duration": 0.00023603500000035638, "outcome": "passed"}, "call": {"duration": 0.00019843499999971925, "outcome": "passed"}, "teardown": {"duration": 0.00019102599999953895, "outcome": "passed"}}, {"nodeid": "tests/test_process.py::test_start_non_process", "lineno": 10, "outcome": "passed", "keywords": ["test_start_non_process", "test_process.py", "tests", "testbed", ""], "setup": {"duration": 0.00025441000000014924, "outcome": "passed"}, "call": {"duration": 0.0004096379999998234, "outcome": "passed"}, "teardown": {"duration": 0.0001943729999993593, "outcome": "passed"}}, {"nodeid": "tests/test_process.py::test_get_state", "lineno": 20, "outcome": "passed", "keywords": ["test_get_state", "test_process.py", "tests", "testbed", ""], "setup": {"duration": 0.00025019699999973, "outcome": "passed"}, "call": {"duration": 0.0001954089999998132, "outcome": "passed"}, "teardown": {"duration": 0.0001931719999994641, "outcome": "passed"}}, {"nodeid": "tests/test_process.py::test_target", "lineno": 38, "outcome": "failed", "keywords": ["test_target", "test_process.py", "tests", "testbed", ""], "setup": {"duration": 0.00025304900000033825, "outcome": "passed"}, "call": {"duration": 0.00021709600000008322, "outcome": "failed", "crash": {"path": "/testbed/tests/test_process.py", "lineno": 47, "message": "TypeError: '<' not supported between instances of 'NoneType' and 'int'"}, "traceback": [{"path": "tests/test_process.py", "lineno": 47, "message": "TypeError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea5f3640>\n\n    def test_target(env):\n        def pem(env, event):\n            yield event\n    \n        event = env.timeout(5)\n        proc = env.process(pem(env, event))\n    \n        # Wait until \"proc\" is initialized and yielded the event\n>       while env.peek() < 5:\nE       TypeError: '<' not supported between instances of 'NoneType' and 'int'\n\ntests/test_process.py:47: TypeError"}, "teardown": {"duration": 0.00021970600000020823, "outcome": "passed"}}, {"nodeid": "tests/test_process.py::test_wait_for_proc", "lineno": 52, "outcome": "passed", "keywords": ["test_wait_for_proc", "test_process.py", "tests", "testbed", ""], "setup": {"duration": 0.00024833000000068495, "outcome": "passed"}, "call": {"duration": 0.00020213499999943707, "outcome": "passed"}, "teardown": {"duration": 0.0001902910000000091, "outcome": "passed"}}, {"nodeid": "tests/test_process.py::test_return_value", "lineno": 68, "outcome": "passed", "keywords": ["test_return_value", "test_process.py", "tests", "testbed", ""], "setup": {"duration": 0.00024251900000038518, "outcome": "passed"}, "call": {"duration": 0.00019431499999988944, "outcome": "passed"}, "teardown": {"duration": 0.00019947600000058685, "outcome": "passed"}}, {"nodeid": "tests/test_process.py::test_child_exception", "lineno": 85, "outcome": "passed", "keywords": ["test_child_exception", "test_process.py", "tests", "testbed", ""], "setup": {"duration": 0.0002372219999999814, "outcome": "passed"}, "call": {"duration": 0.0001943380000000161, "outcome": "passed"}, "teardown": {"duration": 0.00020312099999930666, "outcome": "passed"}}, {"nodeid": "tests/test_process.py::test_interrupted_join", "lineno": 100, "outcome": "passed", "keywords": ["test_interrupted_join", "test_process.py", "tests", "testbed", ""], "setup": {"duration": 0.0002363089999999346, "outcome": "passed"}, "call": {"duration": 0.00019611299999944265, "outcome": "passed"}, "teardown": {"duration": 0.00019098100000025653, "outcome": "passed"}}, {"nodeid": "tests/test_process.py::test_interrupted_join_and_rejoin", "lineno": 128, "outcome": "passed", "keywords": ["test_interrupted_join_and_rejoin", "test_process.py", "tests", "testbed", ""], "setup": {"duration": 0.0002349690000000848, "outcome": "passed"}, "call": {"duration": 0.00019742499999964025, "outcome": "passed"}, "teardown": {"duration": 0.00019097300000048278, "outcome": "passed"}}, {"nodeid": "tests/test_process.py::test_error_and_interrupted_join", "lineno": 158, "outcome": "failed", "keywords": ["test_error_and_interrupted_join", "test_process.py", "tests", "testbed", ""], "setup": {"duration": 0.00023531899999973405, "outcome": "passed"}, "call": {"duration": 0.00022664799999994045, "outcome": "failed", "crash": {"path": "/testbed/tests/test_process.py", "lineno": 183, "message": "Failed: DID NOT RAISE <class 'AttributeError'>"}, "traceback": [{"path": "tests/test_process.py", "lineno": 183, "message": "Failed"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea6c51b0>\n\n    def test_error_and_interrupted_join(env):\n        def child_a(env, process):\n            process.interrupt()\n            return\n            yield  # Dummy yield\n    \n        def child_b(env):\n            raise AttributeError('spam')\n            yield  # Dummy yield\n    \n        def parent(env):\n            env.process(child_a(env, env.active_process))\n            b = env.process(child_b(env))\n    \n            try:\n                yield b\n            # This interrupt unregisters me from b so I won't receive its\n            # AttributeError\n            except Interrupt:\n                pass\n    \n            yield env.timeout(0)\n    \n        env.process(parent(env))\n>       pytest.raises(AttributeError, env.run)\nE       Failed: DID NOT RAISE <class 'AttributeError'>\n\ntests/test_process.py:183: Failed"}, "teardown": {"duration": 0.00023692999999980202, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_resource", "lineno": 15, "outcome": "failed", "keywords": ["test_resource", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0003142489999996556, "outcome": "passed"}, "call": {"duration": 0.0003514369999999545, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 34, "message": "assert None == 1\n +  where None = <simpy.resources.resource.Resource object at 0x7fabea5f2e00>.capacity"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 34, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea5f1930>, log = []\n\n    def test_resource(env, log):\n        \"\"\"A *resource* is something with a limited numer of slots that need\n        to be requested before and released after the usage (e.g., gas pumps\n        at a gas station).\n    \n        \"\"\"\n    \n        def pem(env, name, resource, log):\n            req = resource.request()\n            yield req\n            assert resource.count == 1\n    \n            yield env.timeout(1)\n            resource.release(req)\n    \n            log.append((name, env.now))\n    \n        resource = simpy.Resource(env, capacity=1)\n>       assert resource.capacity == 1\nE       assert None == 1\nE        +  where None = <simpy.resources.resource.Resource object at 0x7fabea5f2e00>.capacity\n\ntests/test_resources.py:34: AssertionError"}, "teardown": {"duration": 0.00023431099999982052, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_resource_capacity", "lineno": 42, "outcome": "passed", "keywords": ["test_resource_capacity", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0002488170000001233, "outcome": "passed"}, "call": {"duration": 0.0003324600000000899, "outcome": "passed"}, "teardown": {"duration": 0.0001998939999996452, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_resource_context_manager", "lineno": 47, "outcome": "failed", "keywords": ["test_resource_context_manager", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00026758599999965327, "outcome": "passed"}, "call": {"duration": 0.0003943399999997155, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 64, "message": "AssertionError: assert [] == [('a', 1), ('b', 2)]\n  \n  Right contains 2 more items, first extra item: ('a', 1)\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 64, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea4db3a0>, log = []\n\n    def test_resource_context_manager(env, log):\n        \"\"\"The event that ``Resource.request()`` returns can be used as\n        Context Manager.\"\"\"\n    \n        def pem(env, name, resource, log):\n            with resource.request() as request:\n                yield request\n                yield env.timeout(1)\n    \n            log.append((name, env.now))\n    \n        resource = simpy.Resource(env, capacity=1)\n        env.process(pem(env, 'a', resource, log))\n        env.process(pem(env, 'b', resource, log))\n        env.run()\n    \n>       assert log == [('a', 1), ('b', 2)]\nE       AssertionError: assert [] == [('a', 1), ('b', 2)]\nE         \nE         Right contains 2 more items, first extra item: ('a', 1)\nE         Use -v to get more diff\n\ntests/test_resources.py:64: AssertionError"}, "teardown": {"duration": 0.0002516350000005829, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_resource_slots", "lineno": 66, "outcome": "failed", "keywords": ["test_resource_slots", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00034528500000075013, "outcome": "passed"}, "call": {"duration": 0.00044284400000016433, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 79, "message": "AssertionError: assert [] == [('0', 0), ('...('5', 1), ...]\n  \n  Right contains 9 more items, first extra item: ('0', 0)\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 79, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea5e7250>, log = []\n\n    def test_resource_slots(env, log):\n        def pem(env, name, resource, log):\n            with resource.request() as req:\n                yield req\n                log.append((name, env.now))\n                yield env.timeout(1)\n    \n        resource = simpy.Resource(env, capacity=3)\n        for i in range(9):\n            env.process(pem(env, str(i), resource, log))\n        env.run()\n    \n>       assert log == [\n            ('0', 0),\n            ('1', 0),\n            ('2', 0),\n            ('3', 1),\n            ('4', 1),\n            ('5', 1),\n            ('6', 2),\n            ('7', 2),\n            ('8', 2),\n        ]\nE       AssertionError: assert [] == [('0', 0), ('...('5', 1), ...]\nE         \nE         Right contains 9 more items, first extra item: ('0', 0)\nE         Use -v to get more diff\n\ntests/test_resources.py:79: AssertionError"}, "teardown": {"duration": 0.00025518700000048966, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_resource_continue_after_interrupt", "lineno": 91, "outcome": "passed", "keywords": ["test_resource_continue_after_interrupt", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00025212099999993853, "outcome": "passed"}, "call": {"duration": 0.0002183059999998349, "outcome": "passed"}, "teardown": {"duration": 0.00019433699999993337, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_resource_release_after_interrupt", "lineno": 122, "outcome": "passed", "keywords": ["test_resource_release_after_interrupt", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00023668499999995873, "outcome": "passed"}, "call": {"duration": 0.00020370000000013988, "outcome": "passed"}, "teardown": {"duration": 0.00018788299999972224, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_resource_immediate_requests", "lineno": 153, "outcome": "passed", "keywords": ["test_resource_immediate_requests", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00023467600000071087, "outcome": "passed"}, "call": {"duration": 0.00019950800000057, "outcome": "passed"}, "teardown": {"duration": 0.00018596000000048463, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_resource_cm_exception", "lineno": 181, "outcome": "failed", "keywords": ["test_resource_cm_exception", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00026566100000025017, "outcome": "passed"}, "call": {"duration": 0.00037669700000009243, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 201, "message": "assert [] == [1, 2]\n  \n  Right contains 2 more items, first extra item: 1\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 201, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea4d99c0>, log = []\n\n    def test_resource_cm_exception(env, log):\n        \"\"\"Resource with context manager receives an exception.\"\"\"\n    \n        def process(env, resource, log, raise_):\n            with resource.request() as req:\n                yield req\n                yield env.timeout(1)\n                log.append(env.now)\n                if raise_:\n                    with pytest.raises(ValueError, match='Foo'):\n                        raise ValueError('Foo')\n    \n        resource = simpy.Resource(env, 1)\n        env.process(process(env, resource, log, True))\n        # The second process is used to check if it was able to access the\n        # resource:\n        env.process(process(env, resource, log, False))\n        env.run()\n    \n>       assert log == [1, 2]\nE       assert [] == [1, 2]\nE         \nE         Right contains 2 more items, first extra item: 1\nE         Use -v to get more diff\n\ntests/test_resources.py:201: AssertionError"}, "teardown": {"duration": 0.00023794300000012925, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_resource_with_condition", "lineno": 203, "outcome": "passed", "keywords": ["test_resource_with_condition", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00025678599999956475, "outcome": "passed"}, "call": {"duration": 0.00021765999999967534, "outcome": "passed"}, "teardown": {"duration": 0.00018797699999950623, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_resource_with_priority_queue", "lineno": 214, "outcome": "passed", "keywords": ["test_resource_with_priority_queue", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00023563600000020557, "outcome": "passed"}, "call": {"duration": 0.00021535499999991714, "outcome": "passed"}, "teardown": {"duration": 0.00018830300000072242, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_sorted_queue_maxlen", "lineno": 231, "outcome": "passed", "keywords": ["test_sorted_queue_maxlen", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0002412259999999833, "outcome": "passed"}, "call": {"duration": 0.000200355000000485, "outcome": "passed"}, "teardown": {"duration": 0.000184239000000197, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_get_users", "lineno": 251, "outcome": "failed", "keywords": ["test_get_users", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00024243800000078863, "outcome": "passed"}, "call": {"duration": 0.00037322700000075315, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 261, "message": "assert [] == [<None object...7fabea6c6c80>]\n  \n  Right contains one more item: <None object at 0x7fabea6c6c80>\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 261, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea6c61d0>\n\n    def test_get_users(env):\n        def process(env, resource):\n            with resource.request() as req:\n                yield req\n                yield env.timeout(1)\n    \n        resource = simpy.Resource(env, 1)\n        procs = [env.process(process(env, resource)) for _ in range(3)]\n        env.run(until=1)\n>       assert [evt.proc for evt in resource.users] == procs[0:1]\nE       assert [] == [<None object...7fabea6c6c80>]\nE         \nE         Right contains one more item: <None object at 0x7fabea6c6c80>\nE         Use -v to get more diff\n\ntests/test_resources.py:261: AssertionError"}, "teardown": {"duration": 0.00022323099999965734, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_preemptive_resource", "lineno": 271, "outcome": "passed", "keywords": ["test_preemptive_resource", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0002420519999999371, "outcome": "passed"}, "call": {"duration": 0.00022060800000023306, "outcome": "passed"}, "teardown": {"duration": 0.0001885880000003226, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_preemptive_resource_timeout_0", "lineno": 295, "outcome": "passed", "keywords": ["test_preemptive_resource_timeout_0", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0002584230000000076, "outcome": "passed"}, "call": {"duration": 0.00020418799999966097, "outcome": "passed"}, "teardown": {"duration": 0.00018745900000016746, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_mixed_preemption", "lineno": 317, "outcome": "failed", "keywords": ["test_mixed_preemption", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00027052300000018903, "outcome": "passed"}, "call": {"duration": 0.0004351400000004446, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 345, "message": "assert [] == [(2, 0), (3, ...7, 1), (9, 4)]\n  \n  Right contains 5 more items, first extra item: (2, 0)\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 345, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb6b2110>, log = []\n\n    def test_mixed_preemption(env, log):\n        def p(id, env, res, delay, prio, preempt, log):\n            yield env.timeout(delay)\n            with res.request(priority=prio, preempt=preempt) as req:\n                try:\n                    yield req\n                    yield env.timeout(2)\n                    log.append((env.now, id))\n                except simpy.Interrupt as ir:\n                    assert ir is not None  # noqa: PT017\n                    assert isinstance(ir.cause, Preempted)  # noqa: PT017\n                    log.append((env.now, id, (ir.cause.by, ir.cause.usage_since)))\n    \n        res = simpy.PreemptiveResource(env, 1)\n        # p0: First user:\n        env.process(p(0, env, res, delay=0, prio=2, preempt=True, log=log))\n        # p1: Waits (cannot preempt):\n        env.process(p(1, env, res, delay=0, prio=2, preempt=True, log=log))\n        # p2: Waits later, but has a higher prio:\n        env.process(p(2, env, res, delay=1, prio=1, preempt=False, log=log))\n        # p3: Preempt the above proc:\n        p3 = env.process(p(3, env, res, delay=3, prio=0, preempt=True, log=log))\n        # p4: Wait again:\n        env.process(p(4, env, res, delay=4, prio=3, preempt=True, log=log))\n    \n        env.run()\n    \n>       assert log == [\n            (2, 0),  # p0 done\n            (3, 2, (p3, 2)),  # p2 got it next, but got interrupted by p3\n            (5, 3),  # p3 done\n            (7, 1),  # p1 done (finally got the resource)\n            (9, 4),  # p4 done\n        ]\nE       assert [] == [(2, 0), (3, ...7, 1), (9, 4)]\nE         \nE         Right contains 5 more items, first extra item: (2, 0)\nE         Use -v to get more diff\n\ntests/test_resources.py:345: AssertionError"}, "teardown": {"duration": 0.0002377999999998437, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_nested_preemption", "lineno": 353, "outcome": "failed", "keywords": ["test_nested_preemption", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0002788979999994723, "outcome": "passed"}, "call": {"duration": 0.0004999009999995252, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 408, "message": "assert [] == [(1, 0, (<Non..., 3), (31, 4)]\n  \n  Right contains 5 more items, first extra item: (1, 0, (<None object at 0x7fabea5e76a0>, 0, <simpy.resources.resource.PreemptiveResource object at 0x7fabea5e47f0>))\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 408, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea5e6fe0>, log = []\n\n    def test_nested_preemption(env, log):\n        def process(id, env, res, delay, prio, preempt, log):\n            yield env.timeout(delay)\n            with res.request(priority=prio, preempt=preempt) as req:\n                try:\n                    yield req\n                    yield env.timeout(5)\n                    log.append((env.now, id))\n                except simpy.Interrupt as ir:\n                    assert isinstance(ir.cause, Preempted)  # noqa: PT017\n                    log.append((env.now, id, (ir.cause.by, ir.cause.usage_since)))\n    \n        def process2(id, env, res0, res1, delay, prio, preempt, log):\n            yield env.timeout(delay)\n            with res0.request(priority=prio, preempt=preempt) as req0:\n                try:\n                    yield req0\n                    with res1.request(priority=prio, preempt=preempt) as req1:\n                        try:\n                            yield req1\n                            yield env.timeout(5)\n                            log.append((env.now, id))\n                        except simpy.Interrupt as ir:\n                            assert isinstance(ir.cause, Preempted)  # noqa: PT017\n                            log.append(\n                                (\n                                    env.now,\n                                    id,\n                                    (ir.cause.by, ir.cause.usage_since, ir.cause.resource),\n                                )\n                            )\n                except simpy.Interrupt as ir:\n                    assert isinstance(ir.cause, Preempted)  # noqa: PT017\n                    log.append(\n                        (\n                            env.now,\n                            id,\n                            (ir.cause.by, ir.cause.usage_since, ir.cause.resource),\n                        )\n                    )\n    \n        res0 = simpy.PreemptiveResource(env, 1)\n        res1 = simpy.PreemptiveResource(env, 1)\n    \n        env.process(process2(0, env, res0, res1, 0, -1, True, log))\n        p1 = env.process(process(1, env, res1, 1, -2, True, log))\n    \n        env.process(process2(2, env, res0, res1, 20, -1, True, log))\n        p3 = env.process(process(3, env, res0, 21, -2, True, log))\n    \n        env.process(process2(4, env, res0, res1, 21, -1, True, log))\n    \n        env.run()\n    \n>       assert log == [\n            (1, 0, (p1, 0, res1)),\n            (6, 1),\n            (21, 2, (p3, 20, res0)),\n            (26, 3),\n            (31, 4),\n        ]\nE       assert [] == [(1, 0, (<Non..., 3), (31, 4)]\nE         \nE         Right contains 5 more items, first extra item: (1, 0, (<None object at 0x7fabea5e76a0>, 0, <simpy.resources.resource.PreemptiveResource object at 0x7fabea5e47f0>))\nE         Use -v to get more diff\n\ntests/test_resources.py:408: AssertionError"}, "teardown": {"duration": 0.00023291900000010912, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_container", "lineno": 421, "outcome": "failed", "keywords": ["test_container", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00027589799999994113, "outcome": "passed"}, "call": {"duration": 0.0004021320000004991, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 452, "message": "AssertionError: assert [] == [('p', 1), ('... 2), ('p', 2)]\n  \n  Right contains 4 more items, first extra item: ('p', 1)\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 452, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea4da590>, log = []\n\n    def test_container(env, log):\n        \"\"\"A *container* is a resource (of optionally limited capacity) where\n        you can put in our take-out a discrete or continuous amount of\n        things (e.g., a box of lump sugar or a can of milk).  The *put* and\n        *get* operations block if the buffer is to full or to empty. If they\n        return, the process knows that the *put* or *get* operation was\n        successful.\n    \n        \"\"\"\n    \n        def putter(env, buf, log):\n            yield env.timeout(1)\n            while True:\n                yield buf.put(2)\n                log.append(('p', env.now))\n                yield env.timeout(1)\n    \n        def getter(env, buf, log):\n            yield buf.get(1)\n            log.append(('g', env.now))\n    \n            yield env.timeout(1)\n            yield buf.get(1)\n            log.append(('g', env.now))\n    \n        buf = simpy.Container(env, init=0, capacity=2)\n        env.process(putter(env, buf, log))\n        env.process(getter(env, buf, log))\n        env.run(until=5)\n    \n>       assert log == [('p', 1), ('g', 1), ('g', 2), ('p', 2)]\nE       AssertionError: assert [] == [('p', 1), ('... 2), ('p', 2)]\nE         \nE         Right contains 4 more items, first extra item: ('p', 1)\nE         Use -v to get more diff\n\ntests/test_resources.py:452: AssertionError"}, "teardown": {"duration": 0.00022916400000028148, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_container_get_queued", "lineno": 454, "outcome": "failed", "keywords": ["test_container_get_queued", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0002442179999997407, "outcome": "passed"}, "call": {"duration": 0.0003727579999992514, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 469, "message": "assert [] == [<None object...7fabea5e4cd0>]\n  \n  Right contains one more item: <None object at 0x7fabea5e4cd0>\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 469, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea5e5b40>\n\n    def test_container_get_queued(env):\n        def proc(env, wait, container, what):\n            yield env.timeout(wait)\n            with getattr(container, what)(1) as req:\n                yield req\n    \n        container = simpy.Container(env, 1)\n        p0 = env.process(proc(env, 0, container, 'get'))\n        env.process(proc(env, 1, container, 'put'))\n        env.process(proc(env, 1, container, 'put'))\n        p3 = env.process(proc(env, 1, container, 'put'))\n    \n        env.run(until=1)\n        assert [ev.proc for ev in container.put_queue] == []\n>       assert [ev.proc for ev in container.get_queue] == [p0]\nE       assert [] == [<None object...7fabea5e4cd0>]\nE         \nE         Right contains one more item: <None object at 0x7fabea5e4cd0>\nE         Use -v to get more diff\n\ntests/test_resources.py:469: AssertionError"}, "teardown": {"duration": 0.00022088399999997677, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_initial_container_capacity", "lineno": 475, "outcome": "failed", "keywords": ["test_initial_container_capacity", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0002470990000000839, "outcome": "passed"}, "call": {"duration": 0.00032197699999958473, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 478, "message": "AssertionError: assert None == inf\n +  where None = <simpy.resources.container.Container object at 0x7fabea4dac50>.capacity\n +  and   inf = float('inf')"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 478, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea4daef0>\n\n    def test_initial_container_capacity(env):\n        container = simpy.Container(env)\n>       assert container.capacity == float('inf')\nE       AssertionError: assert None == inf\nE        +  where None = <simpy.resources.container.Container object at 0x7fabea4dac50>.capacity\nE        +  and   inf = float('inf')\n\ntests/test_resources.py:478: AssertionError"}, "teardown": {"duration": 0.00022153799999991008, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_container_get_put_bounds", "lineno": 480, "outcome": "passed", "keywords": ["test_container_get_put_bounds", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00024368900000037996, "outcome": "passed"}, "call": {"duration": 0.00036880700000008204, "outcome": "passed"}, "teardown": {"duration": 0.0002023859999997768, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_container_init_capacity[None-args0]", "lineno": 488, "outcome": "passed", "keywords": ["test_container_init_capacity[None-args0]", "parametrize", "pytestmark", "None-args0", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0003052730000003834, "outcome": "passed"}, "call": {"duration": 0.0001961360000004575, "outcome": "passed"}, "teardown": {"duration": 0.0002062299999998629, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_container_init_capacity[None-args1]", "lineno": 488, "outcome": "passed", "keywords": ["test_container_init_capacity[None-args1]", "parametrize", "pytestmark", "None-args1", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0002955279999996563, "outcome": "passed"}, "call": {"duration": 0.00020487400000046563, "outcome": "passed"}, "teardown": {"duration": 0.0002006450000004989, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_container_init_capacity[None-args2]", "lineno": 488, "outcome": "passed", "keywords": ["test_container_init_capacity[None-args2]", "parametrize", "pytestmark", "None-args2", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.000295365999999575, "outcome": "passed"}, "call": {"duration": 0.00019471400000004024, "outcome": "passed"}, "teardown": {"duration": 0.00020006599999966568, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_container_init_capacity[ValueError-args3]", "lineno": 488, "outcome": "passed", "keywords": ["test_container_init_capacity[ValueError-args3]", "parametrize", "pytestmark", "ValueError-args3", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0003019870000002811, "outcome": "passed"}, "call": {"duration": 0.00020639000000066687, "outcome": "passed"}, "teardown": {"duration": 0.00019918199999935382, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_container_init_capacity[ValueError-args4]", "lineno": 488, "outcome": "passed", "keywords": ["test_container_init_capacity[ValueError-args4]", "parametrize", "pytestmark", "ValueError-args4", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00030592099999982025, "outcome": "passed"}, "call": {"duration": 0.00020467600000007025, "outcome": "passed"}, "teardown": {"duration": 0.00019900399999972507, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_container_init_capacity[ValueError-args5]", "lineno": 488, "outcome": "passed", "keywords": ["test_container_init_capacity[ValueError-args5]", "parametrize", "pytestmark", "ValueError-args5", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0002967979999999315, "outcome": "passed"}, "call": {"duration": 0.00020065600000052086, "outcome": "passed"}, "teardown": {"duration": 0.00021052499999996144, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_container_init_capacity[ValueError-args6]", "lineno": 488, "outcome": "passed", "keywords": ["test_container_init_capacity[ValueError-args6]", "parametrize", "pytestmark", "ValueError-args6", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0002955550000001139, "outcome": "passed"}, "call": {"duration": 0.0002000860000004323, "outcome": "passed"}, "teardown": {"duration": 0.00020280800000005428, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_store", "lineno": 513, "outcome": "passed", "keywords": ["test_store", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0002350350000002166, "outcome": "passed"}, "call": {"duration": 0.00020013600000012843, "outcome": "passed"}, "teardown": {"duration": 0.00018677000000000277, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_initial_store_capacity[Store]", "lineno": 537, "outcome": "failed", "keywords": ["test_initial_store_capacity[Store]", "parametrize", "pytestmark", "Store", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00026543600000028533, "outcome": "passed"}, "call": {"duration": 0.0003570509999999416, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 547, "message": "AssertionError: assert None == inf\n +  where None = <simpy.resources.store.Store object at 0x7fabea4dd150>.capacity\n +  and   inf = float('inf')"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 547, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea4de4a0>\nstore_type = <class 'simpy.resources.store.Store'>\n\n    @pytest.mark.parametrize(\n        'store_type',\n        [\n            simpy.Store,\n            simpy.FilterStore,\n        ],\n    )\n    def test_initial_store_capacity(env, store_type):\n        store = store_type(env)\n>       assert store.capacity == float('inf')\nE       AssertionError: assert None == inf\nE        +  where None = <simpy.resources.store.Store object at 0x7fabea4dd150>.capacity\nE        +  and   inf = float('inf')\n\ntests/test_resources.py:547: AssertionError"}, "teardown": {"duration": 0.00024931100000014084, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_initial_store_capacity[FilterStore]", "lineno": 537, "outcome": "failed", "keywords": ["test_initial_store_capacity[FilterStore]", "parametrize", "pytestmark", "FilterStore", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00027909100000034215, "outcome": "passed"}, "call": {"duration": 0.00033559899999957565, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 547, "message": "AssertionError: assert None == inf\n +  where None = <simpy.resources.store.FilterStore object at 0x7fabeaf5d570>.capacity\n +  and   inf = float('inf')"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 547, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeaf5d420>\nstore_type = <class 'simpy.resources.store.FilterStore'>\n\n    @pytest.mark.parametrize(\n        'store_type',\n        [\n            simpy.Store,\n            simpy.FilterStore,\n        ],\n    )\n    def test_initial_store_capacity(env, store_type):\n        store = store_type(env)\n>       assert store.capacity == float('inf')\nE       AssertionError: assert None == inf\nE        +  where None = <simpy.resources.store.FilterStore object at 0x7fabeaf5d570>.capacity\nE        +  and   inf = float('inf')\n\ntests/test_resources.py:547: AssertionError"}, "teardown": {"duration": 0.00027859800000040735, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_store_capacity", "lineno": 549, "outcome": "failed", "keywords": ["test_store_capacity", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00025149400000046285, "outcome": "passed"}, "call": {"duration": 0.0005247559999999041, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 562, "message": "assert 0 == 2\n +  where 0 = len([])\n +    where [] = <simpy.resources.store.Store object at 0x7fabea4dfac0>.items"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 562, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea4dc310>\n\n    def test_store_capacity(env):\n        with pytest.raises(ValueError, match='\"capacity\" must be > 0'):\n            simpy.Store(env, 0)\n        with pytest.raises(ValueError, match='\"capacity\" must be > 0'):\n            simpy.Store(env, -1)\n    \n        capacity = 2\n        store = simpy.Store(env, capacity)\n        env.process(store.put(i) for i in range(capacity + 1))\n        env.run()\n    \n        # Ensure store is filled to capacity\n>       assert len(store.items) == capacity\nE       assert 0 == 2\nE        +  where 0 = len([])\nE        +    where [] = <simpy.resources.store.Store object at 0x7fabea4dfac0>.items\n\ntests/test_resources.py:562: AssertionError"}, "teardown": {"duration": 0.00022287999999992536, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_store_cancel", "lineno": 564, "outcome": "passed", "keywords": ["test_store_cancel", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00025173700000014065, "outcome": "passed"}, "call": {"duration": 0.00020361600000029512, "outcome": "passed"}, "teardown": {"duration": 0.00020415800000073148, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_priority_store_item_priority", "lineno": 576, "outcome": "failed", "keywords": ["test_priority_store_item_priority", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00025664500000033286, "outcome": "passed"}, "call": {"duration": 0.0003585430000008216, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 593, "message": "AssertionError: assert [] == ['a', 'b', 'c']\n  \n  Right contains 3 more items, first extra item: 'a'\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 593, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb30d570>\n\n    def test_priority_store_item_priority(env):\n        pstore = simpy.PriorityStore(env, 3)\n        log = []\n    \n        def getter(wait):\n            yield env.timeout(wait)\n            item = yield pstore.get()\n            log.append(item)\n    \n        # Do not specify priority; the items themselves will be compared to\n        # determine priority.\n        env.process(pstore.put(s) for s in 'bcadefg')\n        env.process(getter(1))\n        env.process(getter(2))\n        env.process(getter(3))\n        env.run()\n>       assert log == ['a', 'b', 'c']\nE       AssertionError: assert [] == ['a', 'b', 'c']\nE         \nE         Right contains 3 more items, first extra item: 'a'\nE         Use -v to get more diff\n\ntests/test_resources.py:593: AssertionError"}, "teardown": {"duration": 0.00021985599999929661, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_priority_store_stable_order", "lineno": 595, "outcome": "failed", "keywords": ["test_priority_store_stable_order", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0002528349999995072, "outcome": "passed"}, "call": {"duration": 0.00036885000000008716, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 616, "message": "assert [] == [<object obje...7fabebb8a5c0>]\n  \n  Right contains 3 more items, first extra item: <object object at 0x7fabebb8a1c0>\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 616, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb30d360>\n\n    def test_priority_store_stable_order(env):\n        pstore = simpy.PriorityStore(env, 3)\n        log = []\n    \n        def getter(wait):\n            yield env.timeout(wait)\n            _, item = yield pstore.get()\n            log.append(item)\n    \n        items = [object() for _ in range(3)]\n    \n        # Unorderable items are inserted with same priority.\n        env.process(pstore.put(simpy.PriorityItem(0, item)) for item in items)\n        env.process(getter(1))\n        env.process(getter(2))\n        env.process(getter(3))\n        env.run()\n    \n        # Since the priorities were the same for all items, ensure that items are\n        # retrieved in insertion order.\n>       assert log == items\nE       assert [] == [<object obje...7fabebb8a5c0>]\nE         \nE         Right contains 3 more items, first extra item: <object object at 0x7fabebb8a1c0>\nE         Use -v to get more diff\n\ntests/test_resources.py:616: AssertionError"}, "teardown": {"duration": 0.00023217399999975186, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_filter_store", "lineno": 618, "outcome": "passed", "keywords": ["test_filter_store", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0002444749999996887, "outcome": "passed"}, "call": {"duration": 0.0002207790000001708, "outcome": "passed"}, "teardown": {"duration": 0.00019829299999951644, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_filter_store_get_after_mismatch", "lineno": 632, "outcome": "passed", "keywords": ["test_filter_store_get_after_mismatch", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00023791499999958887, "outcome": "passed"}, "call": {"duration": 0.00021135099999991525, "outcome": "passed"}, "teardown": {"duration": 0.0002018969999992848, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_filter_calls_best_case", "lineno": 665, "outcome": "failed", "keywords": ["test_filter_calls_best_case", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0002341169999997561, "outcome": "passed"}, "call": {"duration": 0.00037086899999927425, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 686, "message": "AssertionError: assert [] == ['check 1', '...k 3', 'get 3']\n  \n  Right contains 6 more items, first extra item: 'check 1'\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 686, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeaf5d060>\n\n    def test_filter_calls_best_case(env):\n        \"\"\"The filter function is called every item in the store until a match is\n        found. In the best case the first item already matches.\"\"\"\n        log = []\n    \n        def log_filter(item):\n            log.append(f'check {item}')\n            return True\n    \n        store = simpy.FilterStore(env)\n        store.items = [1, 2, 3]\n    \n        def getter(store):\n            log.append(f'get {yield store.get(log_filter)}')\n            log.append(f'get {yield store.get(log_filter)}')\n            log.append(f'get {yield store.get(log_filter)}')\n    \n        env.process(getter(store))\n        env.run()\n    \n>       assert log == ['check 1', 'get 1', 'check 2', 'get 2', 'check 3', 'get 3']\nE       AssertionError: assert [] == ['check 1', '...k 3', 'get 3']\nE         \nE         Right contains 6 more items, first extra item: 'check 1'\nE         Use -v to get more diff\n\ntests/test_resources.py:686: AssertionError"}, "teardown": {"duration": 0.0002321179999995593, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_filter_calls_worst_case", "lineno": 688, "outcome": "failed", "keywords": ["test_filter_calls_worst_case", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0002528709999998213, "outcome": "passed"}, "call": {"duration": 0.0003610099999997729, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 715, "message": "AssertionError: assert [] == ['put 0', 'ch... 'put 2', ...]\n  \n  Right contains 15 more items, first extra item: 'put 0'\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 715, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb30d9f0>\n\n    def test_filter_calls_worst_case(env):\n        \"\"\"In the worst case the filter function is being called for items multiple\n        times.\"\"\"\n    \n        log = []\n        store = simpy.FilterStore(env)\n    \n        def putter(store):\n            for i in range(4):\n                log.append(f'put {i}')\n                yield store.put(i)\n    \n        def log_filter(item):\n            log.append(f'check {item}')\n            return item >= 3\n    \n        def getter(store):\n            log.append(f'get {yield store.get(log_filter)}')\n    \n        env.process(getter(store))\n        env.process(putter(store))\n        env.run()\n    \n        # The filter function is repeatedly called for every item in the store\n        # until a match is found.\n        # fmt: off\n>       assert log == [\n            'put 0', 'check 0',\n            'put 1', 'check 0', 'check 1',\n            'put 2', 'check 0', 'check 1', 'check 2',\n            'put 3', 'check 0', 'check 1', 'check 2', 'check 3', 'get 3',\n        ]\nE       AssertionError: assert [] == ['put 0', 'ch... 'put 2', ...]\nE         \nE         Right contains 15 more items, first extra item: 'put 0'\nE         Use -v to get more diff\n\ntests/test_resources.py:715: AssertionError"}, "teardown": {"duration": 0.00022516099999947414, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_immediate_put_request", "lineno": 723, "outcome": "failed", "keywords": ["test_immediate_put_request", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.00024326600000001974, "outcome": "passed"}, "call": {"duration": 0.0002883800000006431, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 734, "message": "assert None\n +  where None = <None object at 0x7fabeaf5f7c0>.triggered"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 734, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeaf5f850>\n\n    def test_immediate_put_request(env):\n        \"\"\"Put requests that can be fulfilled immediately do not enter the put\n        queue.\"\"\"\n        resource = simpy.Resource(env, capacity=1)\n        assert len(resource.users) == 0\n        assert len(resource.queue) == 0\n    \n        # The resource is empty, the first request will succeed immediately without\n        # entering the queue.\n        request = resource.request()\n>       assert request.triggered\nE       assert None\nE        +  where None = <None object at 0x7fabeaf5f7c0>.triggered\n\ntests/test_resources.py:734: AssertionError"}, "teardown": {"duration": 0.00022925800000006546, "outcome": "passed"}}, {"nodeid": "tests/test_resources.py::test_immediate_get_request", "lineno": 744, "outcome": "failed", "keywords": ["test_immediate_get_request", "test_resources.py", "tests", "testbed", ""], "setup": {"duration": 0.0002465379999998518, "outcome": "passed"}, "call": {"duration": 0.0003109270000001274, "outcome": "failed", "crash": {"path": "/testbed/tests/test_resources.py", "lineno": 752, "message": "assert None\n +  where None = <None object at 0x7fabea4dc460>.triggered"}, "traceback": [{"path": "tests/test_resources.py", "lineno": 752, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabea4de170>\n\n    def test_immediate_get_request(env):\n        \"\"\"Get requests that can be fulfilled immediately do not enter the get\n        queue.\"\"\"\n        container = simpy.Container(env)\n        # Put something in the container, this request is triggered immediately\n        # without entering the queue.\n        request = container.put(1)\n>       assert request.triggered\nE       assert None\nE        +  where None = <None object at 0x7fabea4dc460>.triggered\n\ntests/test_resources.py:752: AssertionError"}, "teardown": {"duration": 0.00022174299999999647, "outcome": "passed"}}, {"nodeid": "tests/test_rt.py::test_rt[0.1]", "lineno": 23, "outcome": "failed", "keywords": ["test_rt[0.1]", "parametrize", "pytestmark", "0.1", "test_rt.py", "tests", "testbed", ""], "setup": {"duration": 0.00029123300000044594, "outcome": "passed"}, "call": {"duration": 0.00030431400000008324, "outcome": "failed", "crash": {"path": "/testbed/tests/test_rt.py", "lineno": 35, "message": "assert False\n +  where False = check_duration(1.54759999997367e-05, (2 * 0.1))"}, "traceback": [{"path": "tests/test_rt.py", "lineno": 35, "message": "AssertionError"}], "longrepr": "log = [], factor = 0.1\n\n    @pytest.mark.parametrize('factor', [0.1, 0.05, 0.15])\n    def test_rt(log, factor):\n        \"\"\"Basic tests for run().\"\"\"\n        start = monotonic()\n        env = RealtimeEnvironment(factor=factor)\n        env.process(process(env, log, 0.01, 1))\n        env.process(process(env, log, 0.02, 1))\n    \n        env.run(2)\n        duration = monotonic() - start\n    \n>       assert check_duration(duration, 2 * factor)\nE       assert False\nE        +  where False = check_duration(1.54759999997367e-05, (2 * 0.1))\n\ntests/test_rt.py:35: AssertionError"}, "teardown": {"duration": 0.0002273900000000495, "outcome": "passed"}}, {"nodeid": "tests/test_rt.py::test_rt[0.05]", "lineno": 23, "outcome": "failed", "keywords": ["test_rt[0.05]", "parametrize", "pytestmark", "0.05", "test_rt.py", "tests", "testbed", ""], "setup": {"duration": 0.00027080400000034643, "outcome": "passed"}, "call": {"duration": 0.00029922500000001406, "outcome": "failed", "crash": {"path": "/testbed/tests/test_rt.py", "lineno": 35, "message": "assert False\n +  where False = check_duration(1.136499999976337e-05, (2 * 0.05))"}, "traceback": [{"path": "tests/test_rt.py", "lineno": 35, "message": "AssertionError"}], "longrepr": "log = [], factor = 0.05\n\n    @pytest.mark.parametrize('factor', [0.1, 0.05, 0.15])\n    def test_rt(log, factor):\n        \"\"\"Basic tests for run().\"\"\"\n        start = monotonic()\n        env = RealtimeEnvironment(factor=factor)\n        env.process(process(env, log, 0.01, 1))\n        env.process(process(env, log, 0.02, 1))\n    \n        env.run(2)\n        duration = monotonic() - start\n    \n>       assert check_duration(duration, 2 * factor)\nE       assert False\nE        +  where False = check_duration(1.136499999976337e-05, (2 * 0.05))\n\ntests/test_rt.py:35: AssertionError"}, "teardown": {"duration": 0.00024680499999973904, "outcome": "passed"}}, {"nodeid": "tests/test_rt.py::test_rt[0.15]", "lineno": 23, "outcome": "failed", "keywords": ["test_rt[0.15]", "parametrize", "pytestmark", "0.15", "test_rt.py", "tests", "testbed", ""], "setup": {"duration": 0.00027425900000022096, "outcome": "passed"}, "call": {"duration": 0.0002862199999995596, "outcome": "failed", "crash": {"path": "/testbed/tests/test_rt.py", "lineno": 35, "message": "assert False\n +  where False = check_duration(1.0532000000118558e-05, (2 * 0.15))"}, "traceback": [{"path": "tests/test_rt.py", "lineno": 35, "message": "AssertionError"}], "longrepr": "log = [], factor = 0.15\n\n    @pytest.mark.parametrize('factor', [0.1, 0.05, 0.15])\n    def test_rt(log, factor):\n        \"\"\"Basic tests for run().\"\"\"\n        start = monotonic()\n        env = RealtimeEnvironment(factor=factor)\n        env.process(process(env, log, 0.01, 1))\n        env.process(process(env, log, 0.02, 1))\n    \n        env.run(2)\n        duration = monotonic() - start\n    \n>       assert check_duration(duration, 2 * factor)\nE       assert False\nE        +  where False = check_duration(1.0532000000118558e-05, (2 * 0.15))\n\ntests/test_rt.py:35: AssertionError"}, "teardown": {"duration": 0.00022590499999974867, "outcome": "passed"}}, {"nodeid": "tests/test_rt.py::test_rt_multiple_call", "lineno": 38, "outcome": "failed", "keywords": ["test_rt_multiple_call", "test_rt.py", "tests", "testbed", ""], "setup": {"duration": 0.0002543739999998351, "outcome": "passed"}, "call": {"duration": 0.00028283500000014783, "outcome": "failed", "crash": {"path": "/testbed/tests/test_rt.py", "lineno": 51, "message": "assert False\n +  where False = check_duration(1.095899999992156e-05, (5 * 0.05))"}, "traceback": [{"path": "tests/test_rt.py", "lineno": 51, "message": "AssertionError"}], "longrepr": "log = []\n\n    def test_rt_multiple_call(log):\n        \"\"\"Test multiple calls to run().\"\"\"\n        start = monotonic()\n        env = RealtimeEnvironment(factor=0.05)\n    \n        env.process(process(env, log, 0.01, 2))\n        env.process(process(env, log, 0.01, 3))\n    \n        env.run(5)\n        duration = monotonic() - start\n    \n        # assert almost_equal(duration, 0.2)\n>       assert check_duration(duration, 5 * 0.05)\nE       assert False\nE        +  where False = check_duration(1.095899999992156e-05, (5 * 0.05))\n\ntests/test_rt.py:51: AssertionError"}, "teardown": {"duration": 0.00023131299999956667, "outcome": "passed"}}, {"nodeid": "tests/test_rt.py::test_rt_slow_sim_default_behavior", "lineno": 60, "outcome": "failed", "keywords": ["test_rt_slow_sim_default_behavior", "test_rt.py", "tests", "testbed", ""], "setup": {"duration": 0.00026486299999994856, "outcome": "passed"}, "call": {"duration": 0.0002558339999998438, "outcome": "failed", "crash": {"path": "/testbed/tests/test_rt.py", "lineno": 67, "message": "Failed: DID NOT RAISE <class 'RuntimeError'>"}, "traceback": [{"path": "tests/test_rt.py", "lineno": 67, "message": "Failed"}], "longrepr": "log = []\n\n    def test_rt_slow_sim_default_behavior(log):\n        \"\"\"By default, SimPy should raise an error if a simulation is too\n        slow for the selected real-time factor.\"\"\"\n        env = RealtimeEnvironment(factor=0.05)\n        env.process(process(env, log, 0.1, 1))\n    \n>       err = pytest.raises(RuntimeError, env.run, 3)\nE       Failed: DID NOT RAISE <class 'RuntimeError'>\n\ntests/test_rt.py:67: Failed"}, "teardown": {"duration": 0.0002174400000001242, "outcome": "passed"}}, {"nodeid": "tests/test_rt.py::test_rt_slow_sim_no_error", "lineno": 71, "outcome": "failed", "keywords": ["test_rt_slow_sim_no_error", "test_rt.py", "tests", "testbed", ""], "setup": {"duration": 0.00024313099999950794, "outcome": "passed"}, "call": {"duration": 0.0002839409999992881, "outcome": "failed", "crash": {"path": "/testbed/tests/test_rt.py", "lineno": 81, "message": "assert False\n +  where False = check_duration(9.675000000264333e-06, (2 * 0.1))"}, "traceback": [{"path": "tests/test_rt.py", "lineno": 81, "message": "AssertionError"}], "longrepr": "log = []\n\n    def test_rt_slow_sim_no_error(log):\n        \"\"\"Test ignoring slow simulations.\"\"\"\n        start = monotonic()\n        env = RealtimeEnvironment(factor=0.05, strict=False)\n        env.process(process(env, log, 0.1, 1))\n    \n        env.run(2)\n        duration = monotonic() - start\n    \n>       assert check_duration(duration, 2 * 0.1)\nE       assert False\nE        +  where False = check_duration(9.675000000264333e-06, (2 * 0.1))\n\ntests/test_rt.py:81: AssertionError"}, "teardown": {"duration": 0.0002189189999999286, "outcome": "passed"}}, {"nodeid": "tests/test_rt.py::test_rt_illegal_until", "lineno": 84, "outcome": "failed", "keywords": ["test_rt_illegal_until", "test_rt.py", "tests", "testbed", ""], "setup": {"duration": 0.00018610600000013022, "outcome": "passed"}, "call": {"duration": 0.0003886419999998836, "outcome": "failed", "crash": {"path": "/testbed/tests/test_rt.py", "lineno": 88, "message": "Failed: DID NOT RAISE <class 'ValueError'>"}, "traceback": [{"path": "tests/test_rt.py", "lineno": 88, "message": "Failed"}], "longrepr": "def test_rt_illegal_until():\n        \"\"\"Test illegal value for *until*.\"\"\"\n        env = RealtimeEnvironment()\n>       with pytest.raises(\n            ValueError,\n            match=r'until \\(-1\\) must be greater than the current simulation time',\n        ):\nE       Failed: DID NOT RAISE <class 'ValueError'>\n\ntests/test_rt.py:88: Failed"}, "teardown": {"duration": 0.0002770839999994834, "outcome": "passed"}}, {"nodeid": "tests/test_rt.py::test_rt_sync", "lineno": 94, "outcome": "passed", "keywords": ["test_rt_sync", "test_rt.py", "tests", "testbed", ""], "setup": {"duration": 0.00024195900000023585, "outcome": "passed"}, "call": {"duration": 0.06114917500000061, "outcome": "passed"}, "teardown": {"duration": 0.0002762089999999162, "outcome": "passed"}}, {"nodeid": "tests/test_rt.py::test_run_with_untriggered_event", "lineno": 103, "outcome": "failed", "keywords": ["test_run_with_untriggered_event", "test_rt.py", "tests", "testbed", ""], "setup": {"duration": 0.00032015099999949115, "outcome": "passed"}, "call": {"duration": 0.000264060999999316, "outcome": "failed", "crash": {"path": "/testbed/tests/test_rt.py", "lineno": 106, "message": "Failed: DID NOT RAISE <class 'RuntimeError'>"}, "traceback": [{"path": "tests/test_rt.py", "lineno": 106, "message": "Failed"}], "longrepr": "env = <simpy.rt.RealtimeEnvironment object at 0x7fabeb3f02e0>\n\n    def test_run_with_untriggered_event(env):\n        env = RealtimeEnvironment(factor=0.05)\n>       excinfo = pytest.raises(RuntimeError, env.run, until=env.event())\nE       Failed: DID NOT RAISE <class 'RuntimeError'>\n\ntests/test_rt.py:106: Failed"}, "teardown": {"duration": 0.00023578000000057386, "outcome": "passed"}}, {"nodeid": "tests/test_timeout.py::test_discrete_time_steps", "lineno": 8, "outcome": "failed", "keywords": ["test_discrete_time_steps", "test_timeout.py", "tests", "testbed", ""], "setup": {"duration": 0.00030695700000027415, "outcome": "passed"}, "call": {"duration": 0.0004066549999999225, "outcome": "failed", "crash": {"path": "/testbed/tests/test_timeout.py", "lineno": 20, "message": "assert [] == [0, 1, 2]\n  \n  Right contains 3 more items, first extra item: 0\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_timeout.py", "lineno": 20, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb1b6c20>, log = []\n\n    def test_discrete_time_steps(env, log):\n        \"\"\"envple envulation with discrete time steps.\"\"\"\n    \n        def pem(env, log):\n            while True:\n                log.append(env.now)\n                yield env.timeout(delay=1)\n    \n        env.process(pem(env, log))\n        env.run(until=3)\n    \n>       assert log == [0, 1, 2]\nE       assert [] == [0, 1, 2]\nE         \nE         Right contains 3 more items, first extra item: 0\nE         Use -v to get more diff\n\ntests/test_timeout.py:20: AssertionError"}, "teardown": {"duration": 0.00023506399999995153, "outcome": "passed"}}, {"nodeid": "tests/test_timeout.py::test_negative_timeout", "lineno": 22, "outcome": "failed", "keywords": ["test_negative_timeout", "test_timeout.py", "tests", "testbed", ""], "setup": {"duration": 0.00026272699999996263, "outcome": "passed"}, "call": {"duration": 0.00037393699999999086, "outcome": "failed", "crash": {"path": "/testbed/tests/test_timeout.py", "lineno": 30, "message": "Failed: DID NOT RAISE <class 'ValueError'>"}, "traceback": [{"path": "tests/test_timeout.py", "lineno": 30, "message": "Failed"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb9230d0>\n\n    def test_negative_timeout(env):\n        \"\"\"Don't allow negative timeout times.\"\"\"\n    \n        def pem(env):\n            yield env.timeout(-1)\n    \n        env.process(pem(env))\n>       with pytest.raises(ValueError, match='Negative delay'):\nE       Failed: DID NOT RAISE <class 'ValueError'>\n\ntests/test_timeout.py:30: Failed"}, "teardown": {"duration": 0.0002187539999995991, "outcome": "passed"}}, {"nodeid": "tests/test_timeout.py::test_timeout_value", "lineno": 33, "outcome": "passed", "keywords": ["test_timeout_value", "test_timeout.py", "tests", "testbed", ""], "setup": {"duration": 0.00024952600000016645, "outcome": "passed"}, "call": {"duration": 0.00020449700000035875, "outcome": "passed"}, "teardown": {"duration": 0.00020277499999998838, "outcome": "passed"}}, {"nodeid": "tests/test_timeout.py::test_shared_timeout", "lineno": 50, "outcome": "failed", "keywords": ["test_shared_timeout", "test_timeout.py", "tests", "testbed", ""], "setup": {"duration": 0.00027148099999951825, "outcome": "passed"}, "call": {"duration": 0.00040210000000051593, "outcome": "failed", "crash": {"path": "/testbed/tests/test_timeout.py", "lineno": 61, "message": "assert [] == [(0, 1), (1, 1), (2, 1)]\n  \n  Right contains 3 more items, first extra item: (0, 1)\n  Use -v to get more diff"}, "traceback": [{"path": "tests/test_timeout.py", "lineno": 61, "message": "AssertionError"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb431450>, log = []\n\n    def test_shared_timeout(env, log):\n        def child(env, timeout, id, log):\n            yield timeout\n            log.append((id, env.now))\n    \n        timeout = env.timeout(1)\n        for i in range(3):\n            env.process(child(env, timeout, i, log))\n    \n        env.run()\n>       assert log == [(0, 1), (1, 1), (2, 1)]\nE       assert [] == [(0, 1), (1, 1), (2, 1)]\nE         \nE         Right contains 3 more items, first extra item: (0, 1)\nE         Use -v to get more diff\n\ntests/test_timeout.py:61: AssertionError"}, "teardown": {"duration": 0.00022756799999967825, "outcome": "passed"}}, {"nodeid": "tests/test_timeout.py::test_triggered_timeout", "lineno": 63, "outcome": "passed", "keywords": ["test_triggered_timeout", "test_timeout.py", "tests", "testbed", ""], "setup": {"duration": 0.0002579929999999564, "outcome": "passed"}, "call": {"duration": 0.00020170999999979955, "outcome": "passed"}, "teardown": {"duration": 0.0001926860000001085, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_start_delayed", "lineno": 11, "outcome": "passed", "keywords": ["test_start_delayed", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.0002695949999997893, "outcome": "passed"}, "call": {"duration": 0.00019385500000002054, "outcome": "passed"}, "teardown": {"duration": 0.00019006099999963055, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_start_delayed_error", "lineno": 20, "outcome": "failed", "keywords": ["test_start_delayed_error", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.00024384499999996478, "outcome": "passed"}, "call": {"duration": 0.0003394820000002241, "outcome": "failed", "crash": {"path": "/testbed/tests/test_util.py", "lineno": 27, "message": "Failed: DID NOT RAISE <class 'ValueError'>"}, "traceback": [{"path": "tests/test_util.py", "lineno": 27, "message": "Failed"}], "longrepr": "env = <simpy.core.Environment object at 0x7fabeb9214e0>\n\n    def test_start_delayed_error(env):\n        \"\"\"Check if delayed() raises an error if you pass a negative dt.\"\"\"\n    \n        def pem(env):\n            yield env.timeout(1)\n    \n>       with pytest.raises(ValueError, match='delay.*must be > 0'):\nE       Failed: DID NOT RAISE <class 'ValueError'>\n\ntests/test_util.py:27: Failed"}, "teardown": {"duration": 0.00023425499999962796, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_subscribe", "lineno": 30, "outcome": "passed", "keywords": ["test_subscribe", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.00024849500000012625, "outcome": "passed"}, "call": {"duration": 0.0002026060000002161, "outcome": "passed"}, "teardown": {"duration": 0.00020303000000065907, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_subscribe_terminated_proc", "lineno": 53, "outcome": "passed", "keywords": ["test_subscribe_terminated_proc", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.00023978800000001854, "outcome": "passed"}, "call": {"duration": 0.00019318000000012603, "outcome": "passed"}, "teardown": {"duration": 0.00019037199999960563, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_subscribe_with_join", "lineno": 71, "outcome": "passed", "keywords": ["test_subscribe_with_join", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.00023938699999970225, "outcome": "passed"}, "call": {"duration": 0.00019178999999969193, "outcome": "passed"}, "teardown": {"duration": 0.00018914999999974924, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_subscribe_at_timeout", "lineno": 93, "outcome": "passed", "keywords": ["test_subscribe_at_timeout", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.00023673799999990308, "outcome": "passed"}, "call": {"duration": 0.00020468299999976125, "outcome": "passed"}, "teardown": {"duration": 0.00019150500000009174, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_subscribe_at_timeout_with_value", "lineno": 109, "outcome": "passed", "keywords": ["test_subscribe_at_timeout_with_value", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.000235146000000519, "outcome": "passed"}, "call": {"duration": 0.00020229799999960107, "outcome": "passed"}, "teardown": {"duration": 0.00018820599999980203, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_all_of", "lineno": 126, "outcome": "passed", "keywords": ["test_all_of", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.00023747200000023838, "outcome": "passed"}, "call": {"duration": 0.00020562999999995668, "outcome": "passed"}, "teardown": {"duration": 0.000185676000000079, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_all_of_generator", "lineno": 141, "outcome": "passed", "keywords": ["test_all_of_generator", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.00023701499999972953, "outcome": "passed"}, "call": {"duration": 0.000195957000000746, "outcome": "passed"}, "teardown": {"duration": 0.00019129499999959165, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_wait_for_all_with_errors", "lineno": 156, "outcome": "passed", "keywords": ["test_wait_for_all_with_errors", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.0002672919999993084, "outcome": "passed"}, "call": {"duration": 0.00019330699999997591, "outcome": "passed"}, "teardown": {"duration": 0.00018451299999977522, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_all_of_chaining", "lineno": 185, "outcome": "passed", "keywords": ["test_all_of_chaining", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.00024693300000055984, "outcome": "passed"}, "call": {"duration": 0.00019270000000037868, "outcome": "passed"}, "teardown": {"duration": 0.000188216999999824, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_all_of_chaining_intermediate_results", "lineno": 202, "outcome": "passed", "keywords": ["test_all_of_chaining_intermediate_results", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.00024868100000041693, "outcome": "passed"}, "call": {"duration": 0.00019476200000045907, "outcome": "passed"}, "teardown": {"duration": 0.00018806500000057014, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_all_of_with_triggered_events", "lineno": 225, "outcome": "passed", "keywords": ["test_all_of_with_triggered_events", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.0002496480000004908, "outcome": "passed"}, "call": {"duration": 0.0001919849999998391, "outcome": "passed"}, "teardown": {"duration": 0.00018506600000023354, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_any_of", "lineno": 240, "outcome": "passed", "keywords": ["test_any_of", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.00023607700000027876, "outcome": "passed"}, "call": {"duration": 0.00019236599999938875, "outcome": "passed"}, "teardown": {"duration": 0.00018590899999981758, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_any_of_with_errors", "lineno": 255, "outcome": "passed", "keywords": ["test_any_of_with_errors", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.00023788599999985394, "outcome": "passed"}, "call": {"duration": 0.00019813599999984888, "outcome": "passed"}, "teardown": {"duration": 0.00018815899999946595, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_any_of_chaining", "lineno": 276, "outcome": "passed", "keywords": ["test_any_of_chaining", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.00023951399999955214, "outcome": "passed"}, "call": {"duration": 0.00022051699999980912, "outcome": "passed"}, "teardown": {"duration": 0.0002063410000001653, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_any_of_with_triggered_events", "lineno": 293, "outcome": "passed", "keywords": ["test_any_of_with_triggered_events", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.00023911300000012403, "outcome": "passed"}, "call": {"duration": 0.00019159000000001924, "outcome": "passed"}, "teardown": {"duration": 0.0002027559999993045, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_empty_any_of", "lineno": 308, "outcome": "passed", "keywords": ["test_empty_any_of", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.0002373469999996658, "outcome": "passed"}, "call": {"duration": 0.00019310199999988953, "outcome": "passed"}, "teardown": {"duration": 0.0001899850000004477, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_empty_all_of", "lineno": 319, "outcome": "passed", "keywords": ["test_empty_all_of", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.0002388460000002368, "outcome": "passed"}, "call": {"duration": 0.00019081800000009252, "outcome": "passed"}, "teardown": {"duration": 0.0001908099999994306, "outcome": "passed"}}, {"nodeid": "tests/test_util.py::test_all_of_expansion", "lineno": 330, "outcome": "passed", "keywords": ["test_all_of_expansion", "test_util.py", "tests", "testbed", ""], "setup": {"duration": 0.0002390180000002573, "outcome": "passed"}, "call": {"duration": 0.00020770700000039, "outcome": "passed"}, "teardown": {"duration": 0.00019552599999972387, "outcome": "passed"}}, {"nodeid": "tests/test_version.py::test_simpy_version", "lineno": 8, "outcome": "passed", "keywords": ["test_simpy_version", "test_version.py", "tests", "testbed", ""], "setup": {"duration": 0.00020010999999975354, "outcome": "passed"}, "call": {"duration": 0.00019574999999960596, "outcome": "passed"}, "teardown": {"duration": 0.00017023099999935454, "outcome": "passed"}}]}