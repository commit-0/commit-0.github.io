
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.37">
    
    
      
        <title>Analysis commit0 all plain fillin joblib - Commit-0</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.8c3ca2c6.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#claude-sonnet-35-fill-in-joblib" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Commit-0" class="md-header__button md-logo" aria-label="Commit-0" data-md-component="logo">
      
  <img src="../logo2.webp" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Commit-0
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Analysis commit0 all plain fillin joblib
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Commit-0" class="md-nav__button md-logo" aria-label="Commit-0" data-md-component="logo">
      
  <img src="../logo2.webp" alt="logo">

    </a>
    Commit-0
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../setupdist/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Commit0
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Agent
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Leaderboard
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#failed-to-run-pytests-for-test-test" class="md-nav__link">
    <span class="md-ellipsis">
      Failed to run pytests for test test
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#patch-diff" class="md-nav__link">
    <span class="md-ellipsis">
      Patch diff
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<p><a href="/analysis_commit0-all-plain_fillin">back to Claude Sonnet 3.5 - Fill-in summary</a></p>
<h1 id="claude-sonnet-35-fill-in-joblib"><strong>Claude Sonnet 3.5 - Fill-in</strong>: joblib</h1>
<h2 id="failed-to-run-pytests-for-test-test">Failed to run pytests for test <code>test</code></h2>
<div class="highlight"><pre><span></span><code>ImportError while loading conftest &#39;/testbed/conftest.py&#39;.
conftest.py:9: in &lt;module&gt;
    from joblib.parallel import mp
joblib/__init__.py:114: in &lt;module&gt;
    from .memory import Memory
joblib/memory.py:21: in &lt;module&gt;
    from . import hashing
joblib/hashing.py:34: in &lt;module&gt;
    class Hasher(Pickler):
joblib/hashing.py:45: in Hasher
    dispatch[type(len)] = save_global
E   NameError: name &#39;save_global&#39; is not defined
</code></pre></div>
<h2 id="patch-diff">Patch diff</h2>
<div class="highlight"><pre><span></span><code><span class="gh">diff --git a/joblib/_dask.py b/joblib/_dask.py</span>
<span class="gh">index 726f453..a8b7f08 100644</span>
<span class="gd">--- a/joblib/_dask.py</span>
<span class="gi">+++ b/joblib/_dask.py</span>
<span class="gu">@@ -64,7 +64,15 @@ class _WeakKeyDictionary:</span>

<span class="w"> </span>def _make_tasks_summary(tasks):
<span class="w"> </span>    &quot;&quot;&quot;Summarize of list of (func, args, kwargs) function calls&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    num_tasks = len(tasks)</span>
<span class="gi">+    if num_tasks == 0:</span>
<span class="gi">+        return 0, False, &#39;&#39;</span>
<span class="gi">+    </span>
<span class="gi">+    first_func = tasks[0][0]</span>
<span class="gi">+    mixed = any(task[0] != first_func for task in tasks[1:])</span>
<span class="gi">+    funcname = funcname(first_func)</span>
<span class="gi">+    </span>
<span class="gi">+    return num_tasks, mixed, funcname</span>


<span class="w"> </span>class Batch:
<span class="gu">@@ -143,7 +151,11 @@ or</span>

<span class="w"> </span>        joblib.Parallel will never access those results
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.client.cancel(list(self._results.keys()))</span>
<span class="gi">+        self._results.clear()</span>
<span class="gi">+        self._callbacks.clear()</span>
<span class="gi">+        if ensure_ready:</span>
<span class="gi">+            self.client.restart()</span>

<span class="w"> </span>    @contextlib.contextmanager
<span class="w"> </span>    def retrieval_context(self):
<span class="gu">@@ -152,4 +164,10 @@ or</span>
<span class="w"> </span>        This removes thread from the worker&#39;s thread pool (using &#39;secede&#39;).
<span class="w"> </span>        Seceding avoids deadlock in nested parallelism settings.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if hasattr(thread_state, &#39;on_worker&#39;):</span>
<span class="gi">+            secede()</span>
<span class="gi">+        try:</span>
<span class="gi">+            yield</span>
<span class="gi">+        finally:</span>
<span class="gi">+            if hasattr(thread_state, &#39;on_worker&#39;):</span>
<span class="gi">+                rejoin()</span>
<span class="gh">diff --git a/joblib/_memmapping_reducer.py b/joblib/_memmapping_reducer.py</span>
<span class="gh">index 5012683..2ea8325 100644</span>
<span class="gd">--- a/joblib/_memmapping_reducer.py</span>
<span class="gi">+++ b/joblib/_memmapping_reducer.py</span>
<span class="gu">@@ -45,7 +45,15 @@ def unlink_file(filename):</span>
<span class="w"> </span>    it takes for the last reference of the memmap to be closed, yielding (on
<span class="w"> </span>    Windows) a PermissionError in the resource_tracker loop.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    max_retries = 10</span>
<span class="gi">+    for retry in range(max_retries):</span>
<span class="gi">+        try:</span>
<span class="gi">+            os.unlink(filename)</span>
<span class="gi">+            return</span>
<span class="gi">+        except PermissionError:</span>
<span class="gi">+            if retry == max_retries - 1:</span>
<span class="gi">+                raise</span>
<span class="gi">+            time.sleep(0.1 * (2 ** retry))  # Exponential backoff</span>


<span class="w"> </span>resource_tracker._CLEANUP_FUNCS[&#39;file&#39;] = unlink_file
<span class="gu">@@ -68,7 +76,15 @@ class _WeakArrayKeyMap:</span>

<span class="w"> </span>def _get_backing_memmap(a):
<span class="w"> </span>    &quot;&quot;&quot;Recursively look up the original np.memmap instance base if any.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(a, np.memmap):</span>
<span class="gi">+        return a</span>
<span class="gi">+    elif hasattr(a, &#39;__array_interface__&#39;):</span>
<span class="gi">+        base = a.__array_interface__.get(&#39;data&#39;)[0]</span>
<span class="gi">+        if base is not None:</span>
<span class="gi">+            return _get_backing_memmap(base)</span>
<span class="gi">+    elif hasattr(a, &#39;base&#39;):</span>
<span class="gi">+        return _get_backing_memmap(a.base)</span>
<span class="gi">+    return None</span>


<span class="w"> </span>def _get_temp_dir(pool_folder_name, temp_folder=None):
<span class="gu">@@ -101,18 +117,53 @@ def _get_temp_dir(pool_folder_name, temp_folder=None):</span>
<span class="w"> </span>       whether the temporary folder is written to the system shared memory
<span class="w"> </span>       folder or some other temporary folder.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if temp_folder is None:</span>
<span class="gi">+        temp_folder = os.environ.get(&#39;JOBLIB_TEMP_FOLDER&#39;, None)</span>
<span class="gi">+    </span>
<span class="gi">+    if temp_folder is None:</span>
<span class="gi">+        if os.path.exists(SYSTEM_SHARED_MEM_FS):</span>
<span class="gi">+            try:</span>
<span class="gi">+                temp_folder = SYSTEM_SHARED_MEM_FS</span>
<span class="gi">+                if os.path.getsize(SYSTEM_SHARED_MEM_FS) &lt; SYSTEM_SHARED_MEM_FS_MIN_SIZE:</span>
<span class="gi">+                    warnings.warn(&quot;The filesystem at %s is too small for&quot;</span>
<span class="gi">+                                  &quot; joblib memmapping&quot; % SYSTEM_SHARED_MEM_FS)</span>
<span class="gi">+            except OSError:</span>
<span class="gi">+                temp_folder = None</span>
<span class="gi">+    </span>
<span class="gi">+    if temp_folder is None:</span>
<span class="gi">+        temp_folder = tempfile.gettempdir()</span>
<span class="gi">+    </span>
<span class="gi">+    pool_folder = os.path.join(temp_folder, &#39;joblib_memmapping&#39;, pool_folder_name)</span>
<span class="gi">+    </span>
<span class="gi">+    return pool_folder, temp_folder == SYSTEM_SHARED_MEM_FS</span>


<span class="w"> </span>def has_shareable_memory(a):
<span class="w"> </span>    &quot;&quot;&quot;Return True if a is backed by some mmap buffer directly or not.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(a, np.memmap):</span>
<span class="gi">+        return True</span>
<span class="gi">+    </span>
<span class="gi">+    base = _get_backing_memmap(a)</span>
<span class="gi">+    if base is not None:</span>
<span class="gi">+        return True</span>
<span class="gi">+    </span>
<span class="gi">+    return False</span>


<span class="w"> </span>def _strided_from_memmap(filename, dtype, mode, offset, order, shape,
<span class="w"> </span>    strides, total_buffer_len, unlink_on_gc_collect):
<span class="w"> </span>    &quot;&quot;&quot;Reconstruct an array view on a memory mapped file.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if mode == &#39;w+&#39;:</span>
<span class="gi">+        mode = &#39;r+&#39;</span>
<span class="gi">+</span>
<span class="gi">+    mm = make_memmap(filename, dtype=dtype, shape=(total_buffer_len,),</span>
<span class="gi">+                     mode=mode, offset=offset, order=order)</span>
<span class="gi">+</span>
<span class="gi">+    if unlink_on_gc_collect:</span>
<span class="gi">+        resource_tracker.register(filename, &#39;file&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    array = as_strided(mm, shape=shape, strides=strides)</span>
<span class="gi">+    return array</span>


<span class="w"> </span>def _reduce_memmap_backed(a, m):
<span class="gu">@@ -122,12 +173,34 @@ def _reduce_memmap_backed(a, m):</span>
<span class="w"> </span>    m is expected to be an instance of np.memmap on the top of the ``base``
<span class="w"> </span>    attribute ancestry of a. ``m.base`` should be the real python mmap object.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not isinstance(m, np.memmap):</span>
<span class="gi">+        raise ValueError(&quot;m is not a memmap instance&quot;)</span>
<span class="gi">+    </span>
<span class="gi">+    offset = m.offset</span>
<span class="gi">+    mode = m.mode</span>
<span class="gi">+    </span>
<span class="gi">+    if isinstance(a, np.memmap):</span>
<span class="gi">+        # if a is already a memmap instance, we need to respect its view</span>
<span class="gi">+        # on the original memmap</span>
<span class="gi">+        offset += a.offset</span>
<span class="gi">+        mode = a.mode</span>
<span class="gi">+    </span>
<span class="gi">+    order = &#39;C&#39; if m.flags[&#39;C_CONTIGUOUS&#39;] else &#39;F&#39;</span>
<span class="gi">+    </span>
<span class="gi">+    return (_strided_from_memmap,</span>
<span class="gi">+            (m.filename, a.dtype, mode, offset, order, a.shape, a.strides,</span>
<span class="gi">+             m._mmap.size(), True))</span>


<span class="w"> </span>def reduce_array_memmap_backward(a):
<span class="w"> </span>    &quot;&quot;&quot;reduce a np.array or a np.memmap from a child process&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    m = _get_backing_memmap(a)</span>
<span class="gi">+    if m is not None:</span>
<span class="gi">+        return _reduce_memmap_backed(a, m)</span>
<span class="gi">+    else:</span>
<span class="gi">+        # This is a regular in-memory array that can be pickled without</span>
<span class="gi">+        # problem</span>
<span class="gi">+        return (loads, (dumps(a, protocol=HIGHEST_PROTOCOL),))</span>


<span class="w"> </span>class ArrayMemmapForwardReducer(object):
<span class="gh">diff --git a/joblib/_parallel_backends.py b/joblib/_parallel_backends.py</span>
<span class="gh">index 87fe642..50f5b75 100644</span>
<span class="gd">--- a/joblib/_parallel_backends.py</span>
<span class="gi">+++ b/joblib/_parallel_backends.py</span>
<span class="gu">@@ -51,12 +51,17 @@ class ParallelBackendBase(metaclass=ABCMeta):</span>
<span class="w"> </span>        scheduling overhead and better use of CPU cache prefetching heuristics)
<span class="w"> </span>        as long as all the workers have enough work to do.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if n_jobs == -1:</span>
<span class="gi">+            return cpu_count()</span>
<span class="gi">+        return max(1, min(n_jobs, cpu_count()))</span>

<span class="w"> </span>    @abstractmethod
<span class="w"> </span>    def apply_async(self, func, callback=None):
<span class="w"> </span>        &quot;&quot;&quot;Schedule a func to be run&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        result = func()</span>
<span class="gi">+        if callback is not None:</span>
<span class="gi">+            callback(result)</span>
<span class="gi">+        return result</span>

<span class="w"> </span>    def retrieve_result_callback(self, out):
<span class="w"> </span>        &quot;&quot;&quot;Called within the callback function passed in apply_async.
<span class="gu">@@ -74,7 +79,9 @@ class ParallelBackendBase(metaclass=ABCMeta):</span>
<span class="w"> </span>        This makes it possible to reuse an existing backend instance for
<span class="w"> </span>        successive independent calls to Parallel with different parameters.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.parallel = parallel</span>
<span class="gi">+        self.n_jobs = self.effective_n_jobs(n_jobs)</span>
<span class="gi">+        return self.n_jobs</span>

<span class="w"> </span>    def start_call(self):
<span class="w"> </span>        &quot;&quot;&quot;Call-back method called at the beginning of a Parallel call&quot;&quot;&quot;
<span class="gu">@@ -90,11 +97,30 @@ class ParallelBackendBase(metaclass=ABCMeta):</span>

<span class="w"> </span>    def compute_batch_size(self):
<span class="w"> </span>        &quot;&quot;&quot;Determine the optimal batch size&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self._effective_batch_size == 1:</span>
<span class="gi">+            return 1</span>
<span class="gi">+        if self._smoothed_batch_duration == 0.0:</span>
<span class="gi">+            return self._effective_batch_size</span>
<span class="gi">+        optimal_duration = (self.MIN_IDEAL_BATCH_DURATION +</span>
<span class="gi">+                            self.MAX_IDEAL_BATCH_DURATION) / 2</span>
<span class="gi">+        return int(self._effective_batch_size *</span>
<span class="gi">+                   optimal_duration / self._smoothed_batch_duration)</span>

<span class="w"> </span>    def batch_completed(self, batch_size, duration):
<span class="w"> </span>        &quot;&quot;&quot;Callback indicate how long it took to run a batch&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if (self._smoothed_batch_duration == 0.0 or</span>
<span class="gi">+                duration &lt; self._smoothed_batch_duration):</span>
<span class="gi">+            self._smoothed_batch_duration = duration</span>
<span class="gi">+        else:</span>
<span class="gi">+            sd = self._smoothed_batch_duration</span>
<span class="gi">+            self._smoothed_batch_duration = 0.8 * sd + 0.2 * duration</span>
<span class="gi">+        </span>
<span class="gi">+        ideal_duration = (self.MIN_IDEAL_BATCH_DURATION +</span>
<span class="gi">+                          self.MAX_IDEAL_BATCH_DURATION) / 2</span>
<span class="gi">+        ratio = self._smoothed_batch_duration / ideal_duration</span>
<span class="gi">+        self._effective_batch_size = int(self._effective_batch_size / ratio)</span>
<span class="gi">+        # Clip to avoid crazy sizes</span>
<span class="gi">+        self._effective_batch_size = max(1, min(self._effective_batch_size, 1000))</span>

<span class="w"> </span>    def get_exceptions(self):
<span class="w"> </span>        &quot;&quot;&quot;List of exception types to be captured.&quot;&quot;&quot;
<span class="gu">@@ -172,11 +198,14 @@ class SequentialBackend(ParallelBackendBase):</span>

<span class="w"> </span>    def effective_n_jobs(self, n_jobs):
<span class="w"> </span>        &quot;&quot;&quot;Determine the number of jobs which are going to run in parallel&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return 1  # SequentialBackend always runs 1 job</span>

<span class="w"> </span>    def apply_async(self, func, callback=None):
<span class="w"> </span>        &quot;&quot;&quot;Schedule a func to be run&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        result = func()</span>
<span class="gi">+        if callback is not None:</span>
<span class="gi">+            callback(result)</span>
<span class="gi">+        return result</span>


<span class="w"> </span>class PoolManagerMixin(object):
<span class="gu">@@ -185,11 +214,16 @@ class PoolManagerMixin(object):</span>

<span class="w"> </span>    def effective_n_jobs(self, n_jobs):
<span class="w"> </span>        &quot;&quot;&quot;Determine the number of jobs which are going to run in parallel&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if n_jobs == -1:</span>
<span class="gi">+            n_jobs = cpu_count()</span>
<span class="gi">+        return max(1, min(n_jobs, cpu_count()))</span>

<span class="w"> </span>    def terminate(self):
<span class="w"> </span>        &quot;&quot;&quot;Shutdown the process or thread pool&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self._pool is not None:</span>
<span class="gi">+            self._pool.close()</span>
<span class="gi">+            self._pool.terminate()</span>
<span class="gi">+            self._pool = None</span>

<span class="w"> </span>    def _get_pool(self):
<span class="w"> </span>        &quot;&quot;&quot;Used by apply_async to make it possible to implement lazy init&quot;&quot;&quot;
<span class="gh">diff --git a/joblib/_store_backends.py b/joblib/_store_backends.py</span>
<span class="gh">index 0ce3682..11832d7 100644</span>
<span class="gd">--- a/joblib/_store_backends.py</span>
<span class="gi">+++ b/joblib/_store_backends.py</span>
<span class="gu">@@ -27,7 +27,15 @@ class CacheWarning(Warning):</span>

<span class="w"> </span>def concurrency_safe_write(object_to_write, filename, write_func):
<span class="w"> </span>    &quot;&quot;&quot;Writes an object into a unique file in a concurrency-safe way.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    temporary_filename = f&quot;{filename}.tmp&quot;</span>
<span class="gi">+    try:</span>
<span class="gi">+        with open(temporary_filename, &#39;wb&#39;) as f:</span>
<span class="gi">+            write_func(object_to_write, f)</span>
<span class="gi">+        concurrency_safe_rename(temporary_filename, filename)</span>
<span class="gi">+    except:</span>
<span class="gi">+        if os.path.exists(temporary_filename):</span>
<span class="gi">+            os.unlink(temporary_filename)</span>
<span class="gi">+        raise</span>


<span class="w"> </span>class StoreBackendBase(metaclass=ABCMeta):
<span class="gu">@@ -153,73 +161,177 @@ class StoreBackendMixin(object):</span>

<span class="w"> </span>    def load_item(self, call_id, verbose=1, timestamp=None, metadata=None):
<span class="w"> </span>        &quot;&quot;&quot;Load an item from the store given its id as a list of str.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        path = os.path.join(*call_id)</span>
<span class="gi">+        full_path = os.path.join(self.location, path)</span>
<span class="gi">+        </span>
<span class="gi">+        if not self._item_exists(full_path):</span>
<span class="gi">+            raise KeyError(f&quot;No item with path {path} in the store&quot;)</span>
<span class="gi">+        </span>
<span class="gi">+        with self._open_item(full_path, &#39;rb&#39;) as f:</span>
<span class="gi">+            item = numpy_pickle.load(f)</span>
<span class="gi">+        </span>
<span class="gi">+        if verbose &gt; 1:</span>
<span class="gi">+            print(f&quot;[Memory] Loading {path} from {self.location}&quot;)</span>
<span class="gi">+        </span>
<span class="gi">+        return item</span>

<span class="w"> </span>    def dump_item(self, call_id, item, verbose=1):
<span class="w"> </span>        &quot;&quot;&quot;Dump an item in the store at the id given as a list of str.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        path = os.path.join(*call_id)</span>
<span class="gi">+        full_path = os.path.join(self.location, path)</span>
<span class="gi">+        </span>
<span class="gi">+        try:</span>
<span class="gi">+            mkdirp(os.path.dirname(full_path))</span>
<span class="gi">+            self._concurrency_safe_write(item, full_path, numpy_pickle.dump)</span>
<span class="gi">+            if verbose &gt; 1:</span>
<span class="gi">+                print(f&quot;[Memory] Storing {path} in {self.location}&quot;)</span>
<span class="gi">+        except Exception as e:</span>
<span class="gi">+            raise CacheWarning(f&quot;Error while dumping item: {e}&quot;)</span>

<span class="w"> </span>    def clear_item(self, call_id):
<span class="w"> </span>        &quot;&quot;&quot;Clear the item at the id, given as a list of str.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        path = os.path.join(*call_id)</span>
<span class="gi">+        full_path = os.path.join(self.location, path)</span>
<span class="gi">+        if self._item_exists(full_path):</span>
<span class="gi">+            os.remove(full_path)</span>

<span class="w"> </span>    def contains_item(self, call_id):
<span class="w"> </span>        &quot;&quot;&quot;Check if there is an item at the id, given as a list of str.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        path = os.path.join(*call_id)</span>
<span class="gi">+        full_path = os.path.join(self.location, path)</span>
<span class="gi">+        return self._item_exists(full_path)</span>

<span class="w"> </span>    def get_item_info(self, call_id):
<span class="w"> </span>        &quot;&quot;&quot;Return information about item.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        path = os.path.join(*call_id)</span>
<span class="gi">+        full_path = os.path.join(self.location, path)</span>
<span class="gi">+        if not self._item_exists(full_path):</span>
<span class="gi">+            raise KeyError(f&quot;No item with path {path} in the store&quot;)</span>
<span class="gi">+        </span>
<span class="gi">+        stats = os.stat(full_path)</span>
<span class="gi">+        return CacheItemInfo(path=full_path, </span>
<span class="gi">+                             size=stats.st_size, </span>
<span class="gi">+                             last_access=datetime.datetime.fromtimestamp(stats.st_atime))</span>

<span class="w"> </span>    def get_metadata(self, call_id):
<span class="w"> </span>        &quot;&quot;&quot;Return actual metadata of an item.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        path = os.path.join(*call_id)</span>
<span class="gi">+        metadata_path = os.path.join(self.location, path + &#39;.metadata&#39;)</span>
<span class="gi">+        if not self._item_exists(metadata_path):</span>
<span class="gi">+            return None</span>
<span class="gi">+        with self._open_item(metadata_path, &#39;r&#39;) as f:</span>
<span class="gi">+            return json.load(f)</span>

<span class="w"> </span>    def store_metadata(self, call_id, metadata):
<span class="w"> </span>        &quot;&quot;&quot;Store metadata of a computation.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        path = os.path.join(*call_id)</span>
<span class="gi">+        metadata_path = os.path.join(self.location, path + &#39;.metadata&#39;)</span>
<span class="gi">+        mkdirp(os.path.dirname(metadata_path))</span>
<span class="gi">+        self._concurrency_safe_write(metadata, metadata_path, json.dump)</span>

<span class="w"> </span>    def contains_path(self, call_id):
<span class="w"> </span>        &quot;&quot;&quot;Check cached function is available in store.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        path = os.path.join(*call_id)</span>
<span class="gi">+        full_path = os.path.join(self.location, path)</span>
<span class="gi">+        return os.path.exists(full_path)</span>

<span class="w"> </span>    def clear_path(self, call_id):
<span class="w"> </span>        &quot;&quot;&quot;Clear all items with a common path in the store.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        path = os.path.join(*call_id)</span>
<span class="gi">+        full_path = os.path.join(self.location, path)</span>
<span class="gi">+        if os.path.exists(full_path):</span>
<span class="gi">+            if os.path.isdir(full_path):</span>
<span class="gi">+                shutil.rmtree(full_path)</span>
<span class="gi">+            else:</span>
<span class="gi">+                os.remove(full_path)</span>

<span class="w"> </span>    def store_cached_func_code(self, call_id, func_code=None):
<span class="w"> </span>        &quot;&quot;&quot;Store the code of the cached function.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if func_code is not None:</span>
<span class="gi">+            path = os.path.join(*call_id)</span>
<span class="gi">+            func_code_path = os.path.join(self.location, path + &#39;.py&#39;)</span>
<span class="gi">+            mkdirp(os.path.dirname(func_code_path))</span>
<span class="gi">+            self._concurrency_safe_write(func_code, func_code_path, lambda x, f: f.write(x))</span>

<span class="w"> </span>    def get_cached_func_code(self, call_id):
<span class="gd">-        &quot;&quot;&quot;Store the code of the cached function.&quot;&quot;&quot;</span>
<span class="gd">-        pass</span>
<span class="gi">+        &quot;&quot;&quot;Get the code of the cached function.&quot;&quot;&quot;</span>
<span class="gi">+        path = os.path.join(*call_id)</span>
<span class="gi">+        func_code_path = os.path.join(self.location, path + &#39;.py&#39;)</span>
<span class="gi">+        if not self._item_exists(func_code_path):</span>
<span class="gi">+            return None</span>
<span class="gi">+        with self._open_item(func_code_path, &#39;r&#39;) as f:</span>
<span class="gi">+            return f.read()</span>

<span class="w"> </span>    def get_cached_func_info(self, call_id):
<span class="w"> </span>        &quot;&quot;&quot;Return information related to the cached function if it exists.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        path = os.path.join(*call_id)</span>
<span class="gi">+        full_path = os.path.join(self.location, path)</span>
<span class="gi">+        if not os.path.exists(full_path):</span>
<span class="gi">+            return None</span>
<span class="gi">+        </span>
<span class="gi">+        func_code = self.get_cached_func_code(call_id)</span>
<span class="gi">+        metadata = self.get_metadata(call_id)</span>
<span class="gi">+        </span>
<span class="gi">+        return {</span>
<span class="gi">+            &#39;path&#39;: full_path,</span>
<span class="gi">+            &#39;func_code&#39;: func_code,</span>
<span class="gi">+            &#39;metadata&#39;: metadata</span>
<span class="gi">+        }</span>

<span class="w"> </span>    def clear(self):
<span class="w"> </span>        &quot;&quot;&quot;Clear the whole store content.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if os.path.exists(self.location):</span>
<span class="gi">+            shutil.rmtree(self.location)</span>
<span class="gi">+        self.create_location(self.location)</span>

<span class="gd">-    def enforce_store_limits(self, bytes_limit, items_limit=None, age_limit</span>
<span class="gd">-        =None):</span>
<span class="gi">+    def enforce_store_limits(self, bytes_limit, items_limit=None, age_limit=None):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Remove the store&#39;s oldest files to enforce item, byte, and age limits.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        items_to_delete = self._get_items_to_delete(bytes_limit, items_limit, age_limit)</span>
<span class="gi">+        for item in items_to_delete:</span>
<span class="gi">+            os.remove(item.path)</span>

<span class="gd">-    def _get_items_to_delete(self, bytes_limit, items_limit=None, age_limit</span>
<span class="gd">-        =None):</span>
<span class="gi">+    def _get_items_to_delete(self, bytes_limit, items_limit=None, age_limit=None):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Get items to delete to keep the store under size, file, &amp; age limits.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        items = []</span>
<span class="gi">+        total_size = 0</span>
<span class="gi">+        for dirpath, dirnames, filenames in os.walk(self.location):</span>
<span class="gi">+            for filename in filenames:</span>
<span class="gi">+                full_path = os.path.join(dirpath, filename)</span>
<span class="gi">+                stats = os.stat(full_path)</span>
<span class="gi">+                items.append(CacheItemInfo(path=full_path, </span>
<span class="gi">+                                           size=stats.st_size, </span>
<span class="gi">+                                           last_access=datetime.datetime.fromtimestamp(stats.st_atime)))</span>
<span class="gi">+                total_size += stats.st_size</span>
<span class="gi">+</span>
<span class="gi">+        items.sort(key=lambda x: x.last_access)</span>
<span class="gi">+        items_to_delete = []</span>
<span class="gi">+        </span>
<span class="gi">+        now = datetime.datetime.now()</span>
<span class="gi">+        </span>
<span class="gi">+        while (len(items) &gt; items_limit if items_limit else False) or \</span>
<span class="gi">+              (total_size &gt; bytes_limit if bytes_limit else False) or \</span>
<span class="gi">+              (age_limit and (now - items[0].last_access).total_seconds() &gt; age_limit):</span>
<span class="gi">+            item = items.pop(0)</span>
<span class="gi">+            items_to_delete.append(item)</span>
<span class="gi">+            total_size -= item.size</span>
<span class="gi">+</span>
<span class="gi">+        return items_to_delete</span>

<span class="w"> </span>    def _concurrency_safe_write(self, to_write, filename, write_func):
<span class="w"> </span>        &quot;&quot;&quot;Writes an object into a file in a concurrency-safe way.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        temporary_filename = f&quot;{filename}.tmp&quot;</span>
<span class="gi">+        try:</span>
<span class="gi">+            with open(temporary_filename, &#39;wb&#39;) as f:</span>
<span class="gi">+                write_func(to_write, f)</span>
<span class="gi">+            self._move_item(temporary_filename, filename)</span>
<span class="gi">+        except:</span>
<span class="gi">+            if os.path.exists(temporary_filename):</span>
<span class="gi">+                os.unlink(temporary_filename)</span>
<span class="gi">+            raise</span>

<span class="w"> </span>    def __repr__(self):
<span class="w"> </span>        &quot;&quot;&quot;Printable representation of the store location.&quot;&quot;&quot;
<span class="gh">diff --git a/joblib/_utils.py b/joblib/_utils.py</span>
<span class="gh">index d2feff7..8665df1 100644</span>
<span class="gd">--- a/joblib/_utils.py</span>
<span class="gi">+++ b/joblib/_utils.py</span>
<span class="gu">@@ -18,7 +18,17 @@ def eval_expr(expr):</span>
<span class="w"> </span>    &gt;&gt;&gt; eval_expr(&#39;1 + 2*3**(4) / (6 + -7)&#39;)
<span class="w"> </span>    -161.0
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    def eval_(node):</span>
<span class="gi">+        if isinstance(node, ast.Num):</span>
<span class="gi">+            return node.n</span>
<span class="gi">+        elif isinstance(node, ast.BinOp):</span>
<span class="gi">+            return operators[type(node.op)](eval_(node.left), eval_(node.right))</span>
<span class="gi">+        elif isinstance(node, ast.UnaryOp):</span>
<span class="gi">+            return operators[type(node.op)](eval_(node.operand))</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise TypeError(node)</span>
<span class="gi">+</span>
<span class="gi">+    return eval_(ast.parse(expr, mode=&#39;eval&#39;).body)</span>


<span class="w"> </span>@dataclass(frozen=True)
<span class="gh">diff --git a/joblib/backports.py b/joblib/backports.py</span>
<span class="gh">index b7178c8..458b5a3 100644</span>
<span class="gd">--- a/joblib/backports.py</span>
<span class="gi">+++ b/joblib/backports.py</span>
<span class="gu">@@ -95,7 +95,22 @@ try:</span>
<span class="w"> </span>          newly-created memmap that sends a maybe_unlink request for the
<span class="w"> </span>          memmaped file to resource_tracker.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        mm = np.memmap(filename, dtype=dtype, mode=mode, offset=offset,</span>
<span class="gi">+                       shape=shape, order=order)</span>
<span class="gi">+        </span>
<span class="gi">+        if unlink_on_gc_collect:</span>
<span class="gi">+            from joblib.disk import delete_folder</span>
<span class="gi">+            import weakref</span>
<span class="gi">+            </span>
<span class="gi">+            def cleanup(path):</span>
<span class="gi">+                try:</span>
<span class="gi">+                    delete_folder(path)</span>
<span class="gi">+                except OSError:</span>
<span class="gi">+                    pass</span>
<span class="gi">+</span>
<span class="gi">+            weakref.finalize(mm, cleanup, filename)</span>
<span class="gi">+        </span>
<span class="gi">+        return mm</span>
<span class="w"> </span>except ImportError:
<span class="w"> </span>if os.name == &#39;nt&#39;:
<span class="w"> </span>    access_denied_errors = 5, 13
<span class="gu">@@ -107,6 +122,13 @@ if os.name == &#39;nt&#39;:</span>
<span class="w"> </span>        On Windows os.replace can yield permission errors if executed by two
<span class="w"> </span>        different processes.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        for i in range(10):  # Try up to 10 times</span>
<span class="gi">+            try:</span>
<span class="gi">+                return replace(src, dst)</span>
<span class="gi">+            except PermissionError as e:</span>
<span class="gi">+                if e.winerror not in access_denied_errors:</span>
<span class="gi">+                    raise</span>
<span class="gi">+                time.sleep(0.1 * (2 ** i))  # Exponential backoff</span>
<span class="gi">+        raise PermissionError(f&quot;Failed to rename {src} to {dst} after 10 attempts&quot;)</span>
<span class="w"> </span>else:
<span class="w"> </span>    from os import replace as concurrency_safe_rename
<span class="gh">diff --git a/joblib/compressor.py b/joblib/compressor.py</span>
<span class="gh">index 7a72b91..cd61e06 100644</span>
<span class="gd">--- a/joblib/compressor.py</span>
<span class="gi">+++ b/joblib/compressor.py</span>
<span class="gu">@@ -42,7 +42,10 @@ def register_compressor(compressor_name, compressor, force=False):</span>
<span class="w"> </span>    compressor: CompressorWrapper
<span class="w"> </span>        An instance of a &#39;CompressorWrapper&#39;.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if compressor_name in _COMPRESSORS and not force:</span>
<span class="gi">+        raise ValueError(f&quot;Compressor &#39;{compressor_name}&#39; already registered. &quot;</span>
<span class="gi">+                         &quot;Use force=True to override.&quot;)</span>
<span class="gi">+    _COMPRESSORS[compressor_name] = compressor</span>


<span class="w"> </span>class CompressorWrapper:
<span class="gu">@@ -68,11 +71,17 @@ class CompressorWrapper:</span>

<span class="w"> </span>    def compressor_file(self, fileobj, compresslevel=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns an instance of a compressor file object.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.fileobj_factory is None:</span>
<span class="gi">+            raise ValueError(&quot;bz2 module is not available&quot;)</span>
<span class="gi">+        if compresslevel is None:</span>
<span class="gi">+            compresslevel = 9</span>
<span class="gi">+        return self.fileobj_factory(fileobj, &#39;wb&#39;, compresslevel=compresslevel)</span>

<span class="w"> </span>    def decompressor_file(self, fileobj):
<span class="w"> </span>        &quot;&quot;&quot;Returns an instance of a decompressor file object.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.fileobj_factory is None:</span>
<span class="gi">+            raise ValueError(&quot;bz2 module is not available&quot;)</span>
<span class="gi">+        return self.fileobj_factory(fileobj, &#39;rb&#39;)</span>


<span class="w"> </span>class BZ2CompressorWrapper(CompressorWrapper):
<span class="gu">@@ -87,11 +96,15 @@ class BZ2CompressorWrapper(CompressorWrapper):</span>

<span class="w"> </span>    def compressor_file(self, fileobj, compresslevel=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns an instance of a compressor file object.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.fileobj_factory is None:</span>
<span class="gi">+            raise ValueError(&quot;lzma module is not available&quot;)</span>
<span class="gi">+        return self.fileobj_factory(fileobj, mode=&#39;wb&#39;, format=self._lzma_format)</span>

<span class="w"> </span>    def decompressor_file(self, fileobj):
<span class="w"> </span>        &quot;&quot;&quot;Returns an instance of a decompressor file object.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.fileobj_factory is None:</span>
<span class="gi">+            raise ValueError(&quot;lzma module is not available&quot;)</span>
<span class="gi">+        return self.fileobj_factory(fileobj, mode=&#39;rb&#39;, format=self._lzma_format)</span>


<span class="w"> </span>class LZMACompressorWrapper(CompressorWrapper):
<span class="gu">@@ -108,11 +121,15 @@ class LZMACompressorWrapper(CompressorWrapper):</span>

<span class="w"> </span>    def compressor_file(self, fileobj, compresslevel=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns an instance of a compressor file object.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.fileobj_factory is None:</span>
<span class="gi">+            raise ValueError(LZ4_NOT_INSTALLED_ERROR)</span>
<span class="gi">+        return self.fileobj_factory(fileobj, mode=&#39;wb&#39;, compression_level=compresslevel)</span>

<span class="w"> </span>    def decompressor_file(self, fileobj):
<span class="w"> </span>        &quot;&quot;&quot;Returns an instance of a decompressor file object.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.fileobj_factory is None:</span>
<span class="gi">+            raise ValueError(LZ4_NOT_INSTALLED_ERROR)</span>
<span class="gi">+        return self.fileobj_factory(fileobj, mode=&#39;rb&#39;)</span>


<span class="w"> </span>class XZCompressorWrapper(LZMACompressorWrapper):
<span class="gu">@@ -210,28 +227,47 @@ class BinaryZlibFile(io.BufferedIOBase):</span>
<span class="w"> </span>        May be called more than once without error. Once the file is
<span class="w"> </span>        closed, any other operation on it will raise a ValueError.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with self._lock:</span>
<span class="gi">+            if self._mode == _MODE_CLOSED:</span>
<span class="gi">+                return</span>
<span class="gi">+            try:</span>
<span class="gi">+                if self._mode in (_MODE_READ, _MODE_READ_EOF):</span>
<span class="gi">+                    self._decompressor = None</span>
<span class="gi">+                elif self._mode == _MODE_WRITE:</span>
<span class="gi">+                    self._fp.write(self._compressor.flush())</span>
<span class="gi">+                    self._compressor = None</span>
<span class="gi">+            finally:</span>
<span class="gi">+                try:</span>
<span class="gi">+                    if self._closefp:</span>
<span class="gi">+                        self._fp.close()</span>
<span class="gi">+                finally:</span>
<span class="gi">+                    self._fp = None</span>
<span class="gi">+                    self._closefp = False</span>
<span class="gi">+                    self._mode = _MODE_CLOSED</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def closed(self):
<span class="w"> </span>        &quot;&quot;&quot;True if this file is closed.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._mode == _MODE_CLOSED</span>

<span class="w"> </span>    def fileno(self):
<span class="w"> </span>        &quot;&quot;&quot;Return the file descriptor for the underlying file.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._check_not_closed()</span>
<span class="gi">+        return self._fp.fileno()</span>

<span class="w"> </span>    def seekable(self):
<span class="w"> </span>        &quot;&quot;&quot;Return whether the file supports seeking.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.readable() and self._fp.seekable()</span>

<span class="w"> </span>    def readable(self):
<span class="w"> </span>        &quot;&quot;&quot;Return whether the file was opened for reading.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._check_not_closed()</span>
<span class="gi">+        return self._mode in (_MODE_READ, _MODE_READ_EOF)</span>

<span class="w"> </span>    def writable(self):
<span class="w"> </span>        &quot;&quot;&quot;Return whether the file was opened for writing.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._check_not_closed()</span>
<span class="gi">+        return self._mode == _MODE_WRITE</span>

<span class="w"> </span>    def read(self, size=-1):
<span class="w"> </span>        &quot;&quot;&quot;Read up to size uncompressed bytes from the file.
<span class="gu">@@ -239,14 +275,27 @@ class BinaryZlibFile(io.BufferedIOBase):</span>
<span class="w"> </span>        If size is negative or omitted, read until EOF is reached.
<span class="w"> </span>        Returns b&#39;&#39; if the file is already at EOF.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with self._lock:</span>
<span class="gi">+            self._check_can_read()</span>
<span class="gi">+            if size == 0:</span>
<span class="gi">+                return b&quot;&quot;</span>
<span class="gi">+            </span>
<span class="gi">+            if self._mode == _MODE_READ_EOF or size &lt; 0:</span>
<span class="gi">+                return self._read_all()</span>
<span class="gi">+            </span>
<span class="gi">+            return self._read_limited(size)</span>

<span class="w"> </span>    def readinto(self, b):
<span class="w"> </span>        &quot;&quot;&quot;Read up to len(b) bytes into b.

<span class="w"> </span>        Returns the number of bytes read (0 for EOF).
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with self._lock:</span>
<span class="gi">+            self._check_can_read()</span>
<span class="gi">+            data = self.read(len(b))</span>
<span class="gi">+            n = len(data)</span>
<span class="gi">+            b[:n] = data</span>
<span class="gi">+            return n</span>

<span class="w"> </span>    def write(self, data):
<span class="w"> </span>        &quot;&quot;&quot;Write a byte string to the file.
<span class="gu">@@ -255,7 +304,11 @@ class BinaryZlibFile(io.BufferedIOBase):</span>
<span class="w"> </span>        always len(data). Note that due to buffering, the file on disk
<span class="w"> </span>        may not reflect the data written until close() is called.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with self._lock:</span>
<span class="gi">+            self._check_can_write()</span>
<span class="gi">+            compressed = self._compressor.compress(data)</span>
<span class="gi">+            self._fp.write(compressed)</span>
<span class="gi">+            return len(data)</span>

<span class="w"> </span>    def seek(self, offset, whence=0):
<span class="w"> </span>        &quot;&quot;&quot;Change the file position.
<span class="gu">@@ -272,11 +325,102 @@ class BinaryZlibFile(io.BufferedIOBase):</span>
<span class="w"> </span>        Note that seeking is emulated, so depending on the parameters,
<span class="w"> </span>        this operation may be extremely slow.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with self._lock:</span>
<span class="gi">+            self._check_can_seek()</span>
<span class="gi">+</span>
<span class="gi">+            if whence == 0:</span>
<span class="gi">+                if offset &lt; 0:</span>
<span class="gi">+                    raise ValueError(&quot;Negative seek position {}&quot;.format(offset))</span>
<span class="gi">+                return self._seek_forward(offset)</span>
<span class="gi">+            elif whence == 1:</span>
<span class="gi">+                return self._seek_forward(offset)</span>
<span class="gi">+            elif whence == 2:</span>
<span class="gi">+                if offset &gt; 0:</span>
<span class="gi">+                    raise ValueError(&quot;Positive seek position {}&quot;.format(offset))</span>
<span class="gi">+                return self._seek_backward(offset)</span>
<span class="gi">+            else:</span>
<span class="gi">+                raise ValueError(&quot;Invalid whence value&quot;)</span>

<span class="w"> </span>    def tell(self):
<span class="w"> </span>        &quot;&quot;&quot;Return the current file position.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with self._lock:</span>
<span class="gi">+            self._check_not_closed()</span>
<span class="gi">+            return self._pos</span>
<span class="gi">+</span>
<span class="gi">+    def _check_not_closed(self):</span>
<span class="gi">+        if self.closed:</span>
<span class="gi">+            raise ValueError(&quot;I/O operation on closed file&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def _check_can_read(self):</span>
<span class="gi">+        if self._mode not in (_MODE_READ, _MODE_READ_EOF):</span>
<span class="gi">+            raise io.UnsupportedOperation(&quot;File not open for reading&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def _check_can_write(self):</span>
<span class="gi">+        if self._mode != _MODE_WRITE:</span>
<span class="gi">+            raise io.UnsupportedOperation(&quot;File not open for writing&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def _check_can_seek(self):</span>
<span class="gi">+        if self._mode not in (_MODE_READ, _MODE_READ_EOF):</span>
<span class="gi">+            raise io.UnsupportedOperation(&quot;Seeking is only supported on files open for reading&quot;)</span>
<span class="gi">+        if not self._fp.seekable():</span>
<span class="gi">+            raise io.UnsupportedOperation(&quot;The underlying file object does not support seeking&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def _read_all(self):</span>
<span class="gi">+        chunks = []</span>
<span class="gi">+        while True:</span>
<span class="gi">+            chunk = self._fp.read(_BUFFER_SIZE)</span>
<span class="gi">+            if not chunk:</span>
<span class="gi">+                break</span>
<span class="gi">+            decompressed = self._decompressor.decompress(chunk)</span>
<span class="gi">+            if decompressed:</span>
<span class="gi">+                chunks.append(decompressed)</span>
<span class="gi">+        if self._decompressor.unused_data:</span>
<span class="gi">+            self._fp.seek(-len(self._decompressor.unused_data), 1)</span>
<span class="gi">+        self._mode = _MODE_READ_EOF</span>
<span class="gi">+        self._pos += sum(len(chunk) for chunk in chunks)</span>
<span class="gi">+        return b&quot;&quot;.join(chunks)</span>
<span class="gi">+</span>
<span class="gi">+    def _read_limited(self, size):</span>
<span class="gi">+        chunks = []</span>
<span class="gi">+        while size &gt; 0:</span>
<span class="gi">+            chunk = self._fp.read(min(_BUFFER_SIZE, size))</span>
<span class="gi">+            if not chunk:</span>
<span class="gi">+                break</span>
<span class="gi">+            decompressed = self._decompressor.decompress(chunk)</span>
<span class="gi">+            if decompressed:</span>
<span class="gi">+                chunks.append(decompressed)</span>
<span class="gi">+                size -= len(decompressed)</span>
<span class="gi">+        if self._decompressor.unused_data:</span>
<span class="gi">+            self._fp.seek(-len(self._decompressor.unused_data), 1)</span>
<span class="gi">+        self._pos += sum(len(chunk) for chunk in chunks)</span>
<span class="gi">+        return b&quot;&quot;.join(chunks)</span>
<span class="gi">+</span>
<span class="gi">+    def _seek_forward(self, offset):</span>
<span class="gi">+        if offset &lt; self._pos:</span>
<span class="gi">+            self._fp.seek(0)</span>
<span class="gi">+            self._decompressor = zlib.decompressobj(self.wbits)</span>
<span class="gi">+            self._pos = 0</span>
<span class="gi">+        else:</span>
<span class="gi">+            offset -= self._pos</span>
<span class="gi">+        while offset &gt; 0:</span>
<span class="gi">+            chunk = self.read(min(_BUFFER_SIZE, offset))</span>
<span class="gi">+            if not chunk:</span>
<span class="gi">+                break</span>
<span class="gi">+            offset -= len(chunk)</span>
<span class="gi">+        return self._pos</span>
<span class="gi">+</span>
<span class="gi">+    def _seek_backward(self, offset):</span>
<span class="gi">+        if offset:</span>
<span class="gi">+            self._fp.seek(0)</span>
<span class="gi">+            self._decompressor = zlib.decompressobj(self.wbits)</span>
<span class="gi">+            self._pos = 0</span>
<span class="gi">+            while self._pos &gt; offset:</span>
<span class="gi">+                chunk = self._fp.read(min(_BUFFER_SIZE, self._pos - offset))</span>
<span class="gi">+                if not chunk:</span>
<span class="gi">+                    break</span>
<span class="gi">+                decompressed = self._decompressor.decompress(chunk)</span>
<span class="gi">+                self._pos += len(decompressed)</span>
<span class="gi">+        return self._pos</span>


<span class="w"> </span>class ZlibCompressorWrapper(CompressorWrapper):
<span class="gh">diff --git a/joblib/disk.py b/joblib/disk.py</span>
<span class="gh">index b35e507..707fcbf 100644</span>
<span class="gd">--- a/joblib/disk.py</span>
<span class="gi">+++ b/joblib/disk.py</span>
<span class="gu">@@ -15,20 +15,39 @@ except NameError:</span>

<span class="w"> </span>def disk_used(path):
<span class="w"> </span>    &quot;&quot;&quot; Return the disk usage in a directory.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    total_size = 0</span>
<span class="gi">+    for dirpath, dirnames, filenames in os.walk(path):</span>
<span class="gi">+        for f in filenames:</span>
<span class="gi">+            fp = os.path.join(dirpath, f)</span>
<span class="gi">+            total_size += os.path.getsize(fp)</span>
<span class="gi">+    return total_size</span>


<span class="w"> </span>def memstr_to_bytes(text):
<span class="w"> </span>    &quot;&quot;&quot; Convert a memory text to its value in bytes.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    units = {</span>
<span class="gi">+        &#39;K&#39;: 1024,</span>
<span class="gi">+        &#39;M&#39;: 1024 ** 2,</span>
<span class="gi">+        &#39;G&#39;: 1024 ** 3,</span>
<span class="gi">+        &#39;T&#39;: 1024 ** 4,</span>
<span class="gi">+    }</span>
<span class="gi">+    text = text.upper().strip()</span>
<span class="gi">+    if text[-1] in units:</span>
<span class="gi">+        return int(float(text[:-1]) * units[text[-1]])</span>
<span class="gi">+    else:</span>
<span class="gi">+        return int(float(text))</span>


<span class="w"> </span>def mkdirp(d):
<span class="w"> </span>    &quot;&quot;&quot;Ensure directory d exists (like mkdir -p on Unix)
<span class="w"> </span>    No guarantee that the directory is writable.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        os.makedirs(d)</span>
<span class="gi">+    except OSError as e:</span>
<span class="gi">+        if e.errno != errno.EEXIST:</span>
<span class="gi">+            raise</span>


<span class="w"> </span>RM_SUBDIRS_RETRY_TIME = 0.1
<span class="gu">@@ -47,9 +66,29 @@ def rm_subdirs(path, onerror=None):</span>
<span class="w"> </span>    exc_info is a tuple returned by sys.exc_info().  If onerror is None,
<span class="w"> </span>    an exception is raised.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    for root, dirs, files in os.walk(path, topdown=False):</span>
<span class="gi">+        for name in dirs:</span>
<span class="gi">+            fullname = os.path.join(root, name)</span>
<span class="gi">+            try:</span>
<span class="gi">+                shutil.rmtree(fullname)</span>
<span class="gi">+            except Exception:</span>
<span class="gi">+                if onerror is not None:</span>
<span class="gi">+                    onerror(os.rmdir, fullname, sys.exc_info())</span>
<span class="gi">+                else:</span>
<span class="gi">+                    raise</span>


<span class="w"> </span>def delete_folder(folder_path, onerror=None, allow_non_empty=True):
<span class="w"> </span>    &quot;&quot;&quot;Utility function to cleanup a temporary folder if it still exists.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if os.path.exists(folder_path):</span>
<span class="gi">+        if allow_non_empty:</span>
<span class="gi">+            shutil.rmtree(folder_path, onerror=onerror)</span>
<span class="gi">+        else:</span>
<span class="gi">+            try:</span>
<span class="gi">+                os.rmdir(folder_path)</span>
<span class="gi">+            except OSError as e:</span>
<span class="gi">+                if e.errno != errno.ENOTEMPTY:</span>
<span class="gi">+                    if onerror is not None:</span>
<span class="gi">+                        onerror(os.rmdir, folder_path, sys.exc_info())</span>
<span class="gi">+                    else:</span>
<span class="gi">+                        raise</span>
<span class="gh">diff --git a/joblib/executor.py b/joblib/executor.py</span>
<span class="gh">index 6eea29c..9b822a7 100644</span>
<span class="gd">--- a/joblib/executor.py</span>
<span class="gi">+++ b/joblib/executor.py</span>
<span class="gu">@@ -19,7 +19,22 @@ class MemmappingExecutor(_ReusablePoolExecutor):</span>
<span class="w"> </span>        &quot;&quot;&quot;Factory for ReusableExecutor with automatic memmapping for large
<span class="w"> </span>        numpy arrays.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        global _executor_args</span>
<span class="gi">+        if _executor_args is None:</span>
<span class="gi">+            reducers = get_memmapping_reducers(temp_folder, context_id)</span>
<span class="gi">+            _executor_args = dict(</span>
<span class="gi">+                timeout=timeout,</span>
<span class="gi">+                initializer=initializer,</span>
<span class="gi">+                initargs=initargs,</span>
<span class="gi">+                env=env,</span>
<span class="gi">+                reducers=reducers,</span>
<span class="gi">+                **backend_args</span>
<span class="gi">+            )</span>
<span class="gi">+        </span>
<span class="gi">+        executor = cls(n_jobs, **_executor_args)</span>
<span class="gi">+        executor.reduce_call = _executor_args[&#39;reducers&#39;][&#39;reduce_call&#39;]</span>
<span class="gi">+        executor.temp_folder_manager = TemporaryResourcesManager(temp_folder)</span>
<span class="gi">+        return executor</span>


<span class="w"> </span>class _TestingMemmappingExecutor(MemmappingExecutor):
<span class="gu">@@ -30,4 +45,4 @@ class _TestingMemmappingExecutor(MemmappingExecutor):</span>

<span class="w"> </span>    def apply_async(self, func, args):
<span class="w"> </span>        &quot;&quot;&quot;Schedule a func to be run&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return super().apply_async(self.reduce_call(func), args)</span>
<span class="gh">diff --git a/joblib/externals/cloudpickle/cloudpickle.py b/joblib/externals/cloudpickle/cloudpickle.py</span>
<span class="gh">index 92fb769..24fa2a3 100644</span>
<span class="gd">--- a/joblib/externals/cloudpickle/cloudpickle.py</span>
<span class="gi">+++ b/joblib/externals/cloudpickle/cloudpickle.py</span>
<span class="gu">@@ -104,12 +104,14 @@ def register_pickle_by_value(module):</span>
<span class="w"> </span>    Note: this feature is considered experimental. See the cloudpickle
<span class="w"> </span>    README.md file for more details and limitations.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    global _PICKLE_BY_VALUE_MODULES</span>
<span class="gi">+    _PICKLE_BY_VALUE_MODULES.add(module)</span>


<span class="w"> </span>def unregister_pickle_by_value(module):
<span class="w"> </span>    &quot;&quot;&quot;Unregister that the input module should be pickled by value.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    global _PICKLE_BY_VALUE_MODULES</span>
<span class="gi">+    _PICKLE_BY_VALUE_MODULES.discard(module)</span>


<span class="w"> </span>def _whichmodule(obj, name):
<span class="gu">@@ -121,7 +123,20 @@ def _whichmodule(obj, name):</span>
<span class="w"> </span>    - Errors arising during module introspection are ignored, as those errors
<span class="w"> </span>      are considered unwanted side effects.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(obj, types.ModuleType):</span>
<span class="gi">+        return obj.__name__</span>
<span class="gi">+    module_name = getattr(obj, &#39;__module__&#39;, None)</span>
<span class="gi">+    if module_name is not None:</span>
<span class="gi">+        return module_name</span>
<span class="gi">+    for module_name, module in sys.modules.items():</span>
<span class="gi">+        if module_name == &#39;__main__&#39;:</span>
<span class="gi">+            continue</span>
<span class="gi">+        try:</span>
<span class="gi">+            if getattr(module, name, None) is obj:</span>
<span class="gi">+                return module_name</span>
<span class="gi">+        except Exception:</span>
<span class="gi">+            pass</span>
<span class="gi">+    return None</span>


<span class="w"> </span>def _should_pickle_by_reference(obj, name=None):
<span class="gu">@@ -138,7 +153,19 @@ def _should_pickle_by_reference(obj, name=None):</span>
<span class="w"> </span>    functions and classes or for attributes of modules that have been
<span class="w"> </span>    explicitly registered to be pickled by value.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if name is None:</span>
<span class="gi">+        name = getattr(obj, &#39;__qualname__&#39;, None)</span>
<span class="gi">+    if name is None:</span>
<span class="gi">+        name = getattr(obj, &#39;__name__&#39;, None)</span>
<span class="gi">+    </span>
<span class="gi">+    module = _whichmodule(obj, name)</span>
<span class="gi">+    if module is None:</span>
<span class="gi">+        return False</span>
<span class="gi">+    if module in _PICKLE_BY_VALUE_MODULES:</span>
<span class="gi">+        return False</span>
<span class="gi">+    if module in (&#39;__main__&#39;, &#39;__mp_main__&#39;):</span>
<span class="gi">+        return False</span>
<span class="gi">+    return True</span>


<span class="w"> </span>def _extract_code_globals(co):
<span class="gh">diff --git a/joblib/externals/loky/_base.py b/joblib/externals/loky/_base.py</span>
<span class="gh">index 6d789c8..6400c8c 100644</span>
<span class="gd">--- a/joblib/externals/loky/_base.py</span>
<span class="gi">+++ b/joblib/externals/loky/_base.py</span>
<span class="gu">@@ -1,6 +1,107 @@</span>
<span class="w"> </span>from concurrent.futures import Future as _BaseFuture
<span class="gd">-from concurrent.futures._base import LOGGER</span>
<span class="gi">+from concurrent.futures._base import LOGGER, PENDING, RUNNING, CANCELLED, CANCELLED_AND_NOTIFIED, FINISHED</span>
<span class="gi">+import threading</span>


<span class="w"> </span>class Future(_BaseFuture):
<span class="gd">-    pass</span>
<span class="gi">+    def __init__(self):</span>
<span class="gi">+        self._condition = threading.Condition()</span>
<span class="gi">+        self._state = PENDING</span>
<span class="gi">+        self._result = None</span>
<span class="gi">+        self._exception = None</span>
<span class="gi">+        self._waiters = []</span>
<span class="gi">+        self._done_callbacks = []</span>
<span class="gi">+</span>
<span class="gi">+    def cancel(self):</span>
<span class="gi">+        with self._condition:</span>
<span class="gi">+            if self._state in [RUNNING, FINISHED]:</span>
<span class="gi">+                return False</span>
<span class="gi">+            if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:</span>
<span class="gi">+                return True</span>
<span class="gi">+            self._state = CANCELLED</span>
<span class="gi">+            self._condition.notify_all()</span>
<span class="gi">+        self._invoke_callbacks()</span>
<span class="gi">+        return True</span>
<span class="gi">+</span>
<span class="gi">+    def cancelled(self):</span>
<span class="gi">+        with self._condition:</span>
<span class="gi">+            return self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]</span>
<span class="gi">+</span>
<span class="gi">+    def running(self):</span>
<span class="gi">+        with self._condition:</span>
<span class="gi">+            return self._state == RUNNING</span>
<span class="gi">+</span>
<span class="gi">+    def done(self):</span>
<span class="gi">+        with self._condition:</span>
<span class="gi">+            return self._state in [CANCELLED, CANCELLED_AND_NOTIFIED, FINISHED]</span>
<span class="gi">+</span>
<span class="gi">+    def result(self, timeout=None):</span>
<span class="gi">+        with self._condition:</span>
<span class="gi">+            if self._state == CANCELLED:</span>
<span class="gi">+                raise CancelledError()</span>
<span class="gi">+            elif self._state == FINISHED:</span>
<span class="gi">+                return self._result</span>
<span class="gi">+            self._condition.wait(timeout)</span>
<span class="gi">+            if self._state == CANCELLED:</span>
<span class="gi">+                raise CancelledError()</span>
<span class="gi">+            elif self._state == FINISHED:</span>
<span class="gi">+                return self._result</span>
<span class="gi">+            else:</span>
<span class="gi">+                raise TimeoutError()</span>
<span class="gi">+</span>
<span class="gi">+    def exception(self, timeout=None):</span>
<span class="gi">+        with self._condition:</span>
<span class="gi">+            if self._state == CANCELLED:</span>
<span class="gi">+                raise CancelledError()</span>
<span class="gi">+            elif self._state == FINISHED:</span>
<span class="gi">+                return self._exception</span>
<span class="gi">+            self._condition.wait(timeout)</span>
<span class="gi">+            if self._state == CANCELLED:</span>
<span class="gi">+                raise CancelledError()</span>
<span class="gi">+            elif self._state == FINISHED:</span>
<span class="gi">+                return self._exception</span>
<span class="gi">+            else:</span>
<span class="gi">+                raise TimeoutError()</span>
<span class="gi">+</span>
<span class="gi">+    def add_done_callback(self, fn):</span>
<span class="gi">+        with self._condition:</span>
<span class="gi">+            if self._state not in [CANCELLED, FINISHED]:</span>
<span class="gi">+                self._done_callbacks.append(fn)</span>
<span class="gi">+                return</span>
<span class="gi">+        fn(self)</span>
<span class="gi">+</span>
<span class="gi">+    def _invoke_callbacks(self):</span>
<span class="gi">+        for callback in self._done_callbacks:</span>
<span class="gi">+            try:</span>
<span class="gi">+                callback(self)</span>
<span class="gi">+            except Exception:</span>
<span class="gi">+                LOGGER.exception(&#39;exception calling callback for %r&#39;, self)</span>
<span class="gi">+</span>
<span class="gi">+    def set_running_or_notify_cancel(self):</span>
<span class="gi">+        with self._condition:</span>
<span class="gi">+            if self._state == CANCELLED:</span>
<span class="gi">+                self._state = CANCELLED_AND_NOTIFIED</span>
<span class="gi">+                return False</span>
<span class="gi">+            elif self._state == PENDING:</span>
<span class="gi">+                self._state = RUNNING</span>
<span class="gi">+                return True</span>
<span class="gi">+            else:</span>
<span class="gi">+                raise RuntimeError(&#39;Future in unexpected state&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    def set_result(self, result):</span>
<span class="gi">+        with self._condition:</span>
<span class="gi">+            self._result = result</span>
<span class="gi">+            self._state = FINISHED</span>
<span class="gi">+            for waiter in self._waiters:</span>
<span class="gi">+                waiter.add_result(self)</span>
<span class="gi">+            self._condition.notify_all()</span>
<span class="gi">+        self._invoke_callbacks()</span>
<span class="gi">+</span>
<span class="gi">+    def set_exception(self, exception):</span>
<span class="gi">+        with self._condition:</span>
<span class="gi">+            self._exception = exception</span>
<span class="gi">+            self._state = FINISHED</span>
<span class="gi">+            for waiter in self._waiters:</span>
<span class="gi">+                waiter.add_exception(self)</span>
<span class="gi">+            self._condition.notify_all()</span>
<span class="gi">+        self._invoke_callbacks()</span>
<span class="gh">diff --git a/joblib/externals/loky/backend/_posix_reduction.py b/joblib/externals/loky/backend/_posix_reduction.py</span>
<span class="gh">index c819d41..25abb3b 100644</span>
<span class="gd">--- a/joblib/externals/loky/backend/_posix_reduction.py</span>
<span class="gi">+++ b/joblib/externals/loky/backend/_posix_reduction.py</span>
<span class="gu">@@ -10,7 +10,7 @@ HAVE_SEND_HANDLE = hasattr(socket, &#39;CMSG_LEN&#39;) and hasattr(socket, &#39;SCM_RIGHTS&#39;</span>

<span class="w"> </span>def DupFd(fd):
<span class="w"> </span>    &quot;&quot;&quot;Return a wrapper for an fd.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return os.dup(fd)</span>


<span class="w"> </span>register(socket.socket, _reduce_socket)
<span class="gh">diff --git a/joblib/externals/loky/backend/context.py b/joblib/externals/loky/backend/context.py</span>
<span class="gh">index 1e0d413..1a1925e 100644</span>
<span class="gd">--- a/joblib/externals/loky/backend/context.py</span>
<span class="gi">+++ b/joblib/externals/loky/backend/context.py</span>
<span class="gu">@@ -47,12 +47,41 @@ def cpu_count(only_physical_cores=False):</span>

<span class="w"> </span>    It is also always larger or equal to 1.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    global physical_cores_cache</span>
<span class="gi">+</span>
<span class="gi">+    if only_physical_cores and physical_cores_cache is None:</span>
<span class="gi">+        physical_cores_cache, _ = _count_physical_cores()</span>
<span class="gi">+</span>
<span class="gi">+    if only_physical_cores and physical_cores_cache != &quot;not found&quot;:</span>
<span class="gi">+        return max(1, physical_cores_cache)</span>
<span class="gi">+</span>
<span class="gi">+    os_cpu_count = mp.cpu_count()</span>
<span class="gi">+    cpu_count_user = _cpu_count_user(os_cpu_count)</span>
<span class="gi">+</span>
<span class="gi">+    if sys.platform == &#39;win32&#39;:</span>
<span class="gi">+        cpu_count = min(cpu_count_user, _MAX_WINDOWS_WORKERS)</span>
<span class="gi">+    else:</span>
<span class="gi">+        cpu_count = cpu_count_user</span>
<span class="gi">+</span>
<span class="gi">+    return max(1, cpu_count)</span>


<span class="w"> </span>def _cpu_count_user(os_cpu_count):
<span class="w"> </span>    &quot;&quot;&quot;Number of user defined available CPUs&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    cpu_count_user = os.environ.get(&#39;LOKY_MAX_CPU_COUNT&#39;)</span>
<span class="gi">+    if cpu_count_user is not None:</span>
<span class="gi">+        try:</span>
<span class="gi">+            cpu_count_user = int(cpu_count_user)</span>
<span class="gi">+        except ValueError:</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                f&quot;LOKY_MAX_CPU_COUNT environment variable cannot be parsed as &quot;</span>
<span class="gi">+                f&quot;an integer: {cpu_count_user!r}. Using {os_cpu_count} as the &quot;</span>
<span class="gi">+                f&quot;number of CPUs.&quot;, UserWarning)</span>
<span class="gi">+            cpu_count_user = os_cpu_count</span>
<span class="gi">+    else:</span>
<span class="gi">+        cpu_count_user = os_cpu_count</span>
<span class="gi">+</span>
<span class="gi">+    return min(cpu_count_user, os_cpu_count)</span>


<span class="w"> </span>def _count_physical_cores():
<span class="gu">@@ -63,7 +92,58 @@ def _count_physical_cores():</span>

<span class="w"> </span>    The number of physical cores is cached to avoid repeating subprocess calls.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    global physical_cores_cache</span>
<span class="gi">+</span>
<span class="gi">+    if physical_cores_cache is not None:</span>
<span class="gi">+        return physical_cores_cache, None</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        if sys.platform == &#39;linux&#39;:</span>
<span class="gi">+            cores = subprocess.check_output(</span>
<span class="gi">+                [&#39;lscpu&#39;, &#39;-p=Core,Socket&#39;]).decode(&#39;utf-8&#39;)</span>
<span class="gi">+            cores = {line.split(&#39;,&#39;)[0:2] for line in cores.splitlines()</span>
<span class="gi">+                     if not line.startswith(&#39;#&#39;)}</span>
<span class="gi">+            physical_cores_cache = len(cores)</span>
<span class="gi">+        elif sys.platform == &#39;darwin&#39;:</span>
<span class="gi">+            physical_cores_cache = int(subprocess.check_output(</span>
<span class="gi">+                [&#39;sysctl&#39;, &#39;-n&#39;, &#39;hw.physicalcpu&#39;]).decode(&#39;utf-8&#39;).strip())</span>
<span class="gi">+        elif sys.platform == &#39;win32&#39;:</span>
<span class="gi">+            import ctypes</span>
<span class="gi">+            import ctypes.wintypes</span>
<span class="gi">+</span>
<span class="gi">+            DWORD = ctypes.wintypes.DWORD</span>
<span class="gi">+            WORD = ctypes.wintypes.WORD</span>
<span class="gi">+</span>
<span class="gi">+            class SYSTEM_LOGICAL_PROCESSOR_INFORMATION(ctypes.Structure):</span>
<span class="gi">+                _fields_ = [</span>
<span class="gi">+                    (&#39;ProcessorMask&#39;, ctypes.c_void_p),</span>
<span class="gi">+                    (&#39;Relationship&#39;, DWORD),</span>
<span class="gi">+                    (&#39;_&#39;, ctypes.c_ulonglong)</span>
<span class="gi">+                ]</span>
<span class="gi">+</span>
<span class="gi">+            buffer = ctypes.create_string_buffer(1)</span>
<span class="gi">+            size = DWORD(ctypes.sizeof(buffer))</span>
<span class="gi">+            while True:</span>
<span class="gi">+                if ctypes.windll.kernel32.GetLogicalProcessorInformation(</span>
<span class="gi">+                        ctypes.byref(buffer), ctypes.byref(size)):</span>
<span class="gi">+                    break</span>
<span class="gi">+                buffer = ctypes.create_string_buffer(size.value)</span>
<span class="gi">+</span>
<span class="gi">+            system_info = (SYSTEM_LOGICAL_PROCESSOR_INFORMATION *</span>
<span class="gi">+                           (size.value // ctypes.sizeof(</span>
<span class="gi">+                               SYSTEM_LOGICAL_PROCESSOR_INFORMATION))).\</span>
<span class="gi">+                from_buffer_copy(buffer)</span>
<span class="gi">+            physical_cores_cache = sum(info.Relationship == 1</span>
<span class="gi">+                                       for info in system_info)</span>
<span class="gi">+        else:</span>
<span class="gi">+            physical_cores_cache = &quot;not found&quot;</span>
<span class="gi">+            raise NotImplementedError(</span>
<span class="gi">+                &quot;Counting physical cores not implemented for &quot;</span>
<span class="gi">+                &quot;this platform&quot;)</span>
<span class="gi">+        return physical_cores_cache, None</span>
<span class="gi">+    except Exception as e:</span>
<span class="gi">+        physical_cores_cache = &quot;not found&quot;</span>
<span class="gi">+        return &quot;not found&quot;, e</span>


<span class="w"> </span>class LokyContext(BaseContext):
<span class="gu">@@ -74,11 +154,13 @@ class LokyContext(BaseContext):</span>

<span class="w"> </span>    def Queue(self, maxsize=0, reducers=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a queue object&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from .queues import Queue</span>
<span class="gi">+        return Queue(maxsize, reducers=reducers, ctx=self.get_context())</span>

<span class="w"> </span>    def SimpleQueue(self, reducers=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a queue object&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from .queues import SimpleQueue</span>
<span class="gi">+        return SimpleQueue(reducers=reducers, ctx=self.get_context())</span>
<span class="w"> </span>    if sys.platform != &#39;win32&#39;:
<span class="w"> </span>        &quot;&quot;&quot;For Unix platform, use our custom implementation of synchronize
<span class="w"> </span>        ensuring that we use the loky.backend.resource_tracker to clean-up
<span class="gh">diff --git a/joblib/externals/loky/backend/fork_exec.py b/joblib/externals/loky/backend/fork_exec.py</span>
<span class="gh">index a8af34a..056bec8 100644</span>
<span class="gd">--- a/joblib/externals/loky/backend/fork_exec.py</span>
<span class="gi">+++ b/joblib/externals/loky/backend/fork_exec.py</span>
<span class="gu">@@ -4,4 +4,11 @@ import sys</span>

<span class="w"> </span>def close_fds(keep_fds):
<span class="w"> </span>    &quot;&quot;&quot;Close all the file descriptors except those in keep_fds.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import resource</span>
<span class="gi">+    max_fd = resource.getrlimit(resource.RLIMIT_NOFILE)[0]</span>
<span class="gi">+    for fd in range(3, max_fd):</span>
<span class="gi">+        if fd not in keep_fds:</span>
<span class="gi">+            try:</span>
<span class="gi">+                os.close(fd)</span>
<span class="gi">+            except OSError:</span>
<span class="gi">+                pass</span>
<span class="gh">diff --git a/joblib/externals/loky/backend/popen_loky_win32.py b/joblib/externals/loky/backend/popen_loky_win32.py</span>
<span class="gh">index b174751..fa533f6 100644</span>
<span class="gd">--- a/joblib/externals/loky/backend/popen_loky_win32.py</span>
<span class="gi">+++ b/joblib/externals/loky/backend/popen_loky_win32.py</span>
<span class="gu">@@ -62,14 +62,28 @@ class Popen(_Popen):</span>

<span class="w"> </span>def get_command_line(pipe_handle, parent_pid, **kwds):
<span class="w"> </span>    &quot;&quot;&quot;Returns prefix of command line used for spawning a child process.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    cmd = [sys.executable, &#39;-c&#39;,</span>
<span class="gi">+           &#39;from joblib.externals.loky.backend.popen_loky_win32 import main; &#39;</span>
<span class="gi">+           &#39;main(%r, %r)&#39; % (pipe_handle, parent_pid)]</span>
<span class="gi">+    return cmd</span>


<span class="w"> </span>def is_forking(argv):
<span class="w"> </span>    &quot;&quot;&quot;Return whether commandline indicates we are forking.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return len(argv) &gt;= 2 and argv[1] == &#39;--multiprocessing-fork&#39;</span>


<span class="w"> </span>def main(pipe_handle, parent_pid=None):
<span class="w"> </span>    &quot;&quot;&quot;Run code specified by data received over pipe.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    fd = msvcrt.open_osfhandle(pipe_handle, os.O_RDONLY)</span>
<span class="gi">+    with open(fd, &#39;rb&#39;) as from_parent:</span>
<span class="gi">+        process.current_process()._inheriting = True</span>
<span class="gi">+        try:</span>
<span class="gi">+            preparation_data = load(from_parent)</span>
<span class="gi">+            spawn.prepare(preparation_data)</span>
<span class="gi">+            self = load(from_parent)</span>
<span class="gi">+        finally:</span>
<span class="gi">+            del process.current_process()._inheriting</span>
<span class="gi">+</span>
<span class="gi">+    exitcode = self._bootstrap()</span>
<span class="gi">+    sys.exit(exitcode)</span>
<span class="gh">diff --git a/joblib/externals/loky/backend/queues.py b/joblib/externals/loky/backend/queues.py</span>
<span class="gh">index 704e2a3..7596205 100644</span>
<span class="gd">--- a/joblib/externals/loky/backend/queues.py</span>
<span class="gi">+++ b/joblib/externals/loky/backend/queues.py</span>
<span class="gu">@@ -36,7 +36,12 @@ class Queue(mp_Queue):</span>
<span class="w"> </span>        Private API hook called when feeding data in the background thread
<span class="w"> </span>        raises an exception.  For overriding by concurrent.futures.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(e, OSError) and e.errno == errno.EPIPE:</span>
<span class="gi">+            if self._ignore_epipe:</span>
<span class="gi">+                return</span>
<span class="gi">+        util.debug(&#39;Error in queue feeder thread: %s&#39; % e)</span>
<span class="gi">+        # Notify the queue management thread about the error</span>
<span class="gi">+        self._thread_queue.put(None)</span>


<span class="w"> </span>class SimpleQueue(mp_SimpleQueue):
<span class="gh">diff --git a/joblib/externals/loky/backend/reduction.py b/joblib/externals/loky/backend/reduction.py</span>
<span class="gh">index 6770d67..3e797bb 100644</span>
<span class="gd">--- a/joblib/externals/loky/backend/reduction.py</span>
<span class="gi">+++ b/joblib/externals/loky/backend/reduction.py</span>
<span class="gu">@@ -36,7 +36,20 @@ set_loky_pickler()</span>

<span class="w"> </span>def dump(obj, file, reducers=None, protocol=None):
<span class="w"> </span>    &quot;&quot;&quot;Replacement for pickle.dump() using _LokyPickler.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if protocol is None:</span>
<span class="gi">+        protocol = HIGHEST_PROTOCOL</span>
<span class="gi">+    if reducers is None:</span>
<span class="gi">+        reducers = {}</span>
<span class="gi">+    </span>
<span class="gi">+    if isinstance(file, io.IOBase):</span>
<span class="gi">+        pickler = _LokyPickler(file, protocol=protocol)</span>
<span class="gi">+        pickler.dispatch_table.update(reducers)</span>
<span class="gi">+        pickler.dump(obj)</span>
<span class="gi">+    else:</span>
<span class="gi">+        with open(file, &#39;wb&#39;) as f:</span>
<span class="gi">+            pickler = _LokyPickler(f, protocol=protocol)</span>
<span class="gi">+            pickler.dispatch_table.update(reducers)</span>
<span class="gi">+            pickler.dump(obj)</span>


<span class="w"> </span>__all__ = [&#39;dump&#39;, &#39;dumps&#39;, &#39;loads&#39;, &#39;register&#39;, &#39;set_loky_pickler&#39;]
<span class="gh">diff --git a/joblib/externals/loky/backend/resource_tracker.py b/joblib/externals/loky/backend/resource_tracker.py</span>
<span class="gh">index 3550ef5..f876b9e 100644</span>
<span class="gd">--- a/joblib/externals/loky/backend/resource_tracker.py</span>
<span class="gi">+++ b/joblib/externals/loky/backend/resource_tracker.py</span>
<span class="gu">@@ -32,23 +32,64 @@ class ResourceTracker:</span>

<span class="w"> </span>        This can be run from any process.  Usually a child process will use
<span class="w"> </span>        the resource created by its parent.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with self._lock:</span>
<span class="gi">+            if self._fd is not None:</span>
<span class="gi">+                # resource tracker already started</span>
<span class="gi">+                return</span>
<span class="gi">+            fds_to_pass = []</span>
<span class="gi">+            cmd = [sys.executable, &#39;-c&#39;, &#39;from joblib.externals.loky.backend.resource_tracker import main; main()&#39;]</span>
<span class="gi">+            r, w = os.pipe()</span>
<span class="gi">+            self._fd = r</span>
<span class="gi">+            try:</span>
<span class="gi">+                fds_to_pass.append(w)</span>
<span class="gi">+                # process will out live us, so no need to wait on pid</span>
<span class="gi">+                pid = spawn.spawn_main(cmd, fds_to_pass)</span>
<span class="gi">+                self._pid = pid</span>
<span class="gi">+            except:</span>
<span class="gi">+                os.close(r)</span>
<span class="gi">+                raise</span>
<span class="gi">+            finally:</span>
<span class="gi">+                os.close(w)</span>

<span class="w"> </span>    def _check_alive(self):
<span class="w"> </span>        &quot;&quot;&quot;Check for the existence of the resource tracker process.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self._pid is None:</span>
<span class="gi">+            return False</span>
<span class="gi">+        try:</span>
<span class="gi">+            os.kill(self._pid, 0)</span>
<span class="gi">+        except OSError:</span>
<span class="gi">+            return False</span>
<span class="gi">+        return True</span>

<span class="w"> </span>    def register(self, name, rtype):
<span class="w"> </span>        &quot;&quot;&quot;Register a named resource, and increment its refcount.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.ensure_running()</span>
<span class="gi">+        msg = f&#39;{name}:{rtype}:REGISTER\n&#39;.encode(&#39;ascii&#39;)</span>
<span class="gi">+        if len(name) &gt; 512:</span>
<span class="gi">+            # Prevent overflow on the C side</span>
<span class="gi">+            raise ValueError(&quot;name too long&quot;)</span>
<span class="gi">+        with self._lock:</span>
<span class="gi">+            os.write(self._fd, msg)</span>

<span class="w"> </span>    def unregister(self, name, rtype):
<span class="w"> </span>        &quot;&quot;&quot;Unregister a named resource with resource tracker.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.ensure_running()</span>
<span class="gi">+        msg = f&#39;{name}:{rtype}:UNREGISTER\n&#39;.encode(&#39;ascii&#39;)</span>
<span class="gi">+        if len(name) &gt; 512:</span>
<span class="gi">+            # Prevent overflow on the C side</span>
<span class="gi">+            raise ValueError(&quot;name too long&quot;)</span>
<span class="gi">+        with self._lock:</span>
<span class="gi">+            os.write(self._fd, msg)</span>

<span class="w"> </span>    def maybe_unlink(self, name, rtype):
<span class="w"> </span>        &quot;&quot;&quot;Decrement the refcount of a resource, and delete it if it hits 0&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.ensure_running()</span>
<span class="gi">+        msg = f&#39;{name}:{rtype}:MAYBE_UNLINK\n&#39;.encode(&#39;ascii&#39;)</span>
<span class="gi">+        if len(name) &gt; 512:</span>
<span class="gi">+            # Prevent overflow on the C side</span>
<span class="gi">+            raise ValueError(&quot;name too long&quot;)</span>
<span class="gi">+        with self._lock:</span>
<span class="gi">+            os.write(self._fd, msg)</span>


<span class="w"> </span>_resource_tracker = ResourceTracker()
<span class="gu">@@ -59,6 +100,60 @@ unregister = _resource_tracker.unregister</span>
<span class="w"> </span>getfd = _resource_tracker.getfd


<span class="gd">-def main(fd, verbose=0):</span>
<span class="gi">+def main(fd=None, verbose=0):</span>
<span class="w"> </span>    &quot;&quot;&quot;Run resource tracker.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    global VERBOSE</span>
<span class="gi">+    VERBOSE = verbose</span>
<span class="gi">+</span>
<span class="gi">+    if fd is None:</span>
<span class="gi">+        fd = sys.stdin.fileno()</span>
<span class="gi">+</span>
<span class="gi">+    cache = {}</span>
<span class="gi">+    try:</span>
<span class="gi">+        while True:</span>
<span class="gi">+            msg = os.read(fd, 512)</span>
<span class="gi">+            if not msg:</span>
<span class="gi">+                break</span>
<span class="gi">+            try:</span>
<span class="gi">+                name, rtype, action = msg.decode(&#39;ascii&#39;).strip().split(&#39;:&#39;)</span>
<span class="gi">+            except ValueError:</span>
<span class="gi">+                continue</span>
<span class="gi">+</span>
<span class="gi">+            if action == &#39;REGISTER&#39;:</span>
<span class="gi">+                cache.setdefault(rtype, {}).setdefault(name, 0)</span>
<span class="gi">+                cache[rtype][name] += 1</span>
<span class="gi">+            elif action == &#39;UNREGISTER&#39;:</span>
<span class="gi">+                if name in cache.get(rtype, {}):</span>
<span class="gi">+                    cache[rtype][name] -= 1</span>
<span class="gi">+                    if cache[rtype][name] == 0:</span>
<span class="gi">+                        del cache[rtype][name]</span>
<span class="gi">+                        cleanup = _CLEANUP_FUNCS.get(rtype)</span>
<span class="gi">+                        if cleanup:</span>
<span class="gi">+                            try:</span>
<span class="gi">+                                cleanup(name)</span>
<span class="gi">+                            except Exception as e:</span>
<span class="gi">+                                warnings.warn(f&#39;Error cleaning up {name}: {e}&#39;)</span>
<span class="gi">+            elif action == &#39;MAYBE_UNLINK&#39;:</span>
<span class="gi">+                if name in cache.get(rtype, {}):</span>
<span class="gi">+                    cache[rtype][name] -= 1</span>
<span class="gi">+                    if cache[rtype][name] == 0:</span>
<span class="gi">+                        del cache[rtype][name]</span>
<span class="gi">+                        cleanup = _CLEANUP_FUNCS.get(rtype)</span>
<span class="gi">+                        if cleanup:</span>
<span class="gi">+                            try:</span>
<span class="gi">+                                cleanup(name)</span>
<span class="gi">+                            except Exception as e:</span>
<span class="gi">+                                warnings.warn(f&#39;Error cleaning up {name}: {e}&#39;)</span>
<span class="gi">+            else:</span>
<span class="gi">+                warnings.warn(f&#39;Unrecognized action: {action}&#39;)</span>
<span class="gi">+    finally:</span>
<span class="gi">+        if sys.platform != &#39;win32&#39;:</span>
<span class="gi">+            signal.signal(signal.SIGTERM, signal.SIG_IGN)</span>
<span class="gi">+        for rtype, rdict in cache.items():</span>
<span class="gi">+            for name in rdict:</span>
<span class="gi">+                cleanup = _CLEANUP_FUNCS.get(rtype)</span>
<span class="gi">+                if cleanup:</span>
<span class="gi">+                    try:</span>
<span class="gi">+                        cleanup(name)</span>
<span class="gi">+                    except Exception as e:</span>
<span class="gi">+                        warnings.warn(f&#39;Error cleaning up {name}: {e}&#39;)</span>
<span class="gh">diff --git a/joblib/externals/loky/backend/spawn.py b/joblib/externals/loky/backend/spawn.py</span>
<span class="gh">index aadb9e2..6653777 100644</span>
<span class="gd">--- a/joblib/externals/loky/backend/spawn.py</span>
<span class="gi">+++ b/joblib/externals/loky/backend/spawn.py</span>
<span class="gu">@@ -20,7 +20,29 @@ else:</span>

<span class="w"> </span>def get_preparation_data(name, init_main_module=True):
<span class="w"> </span>    &quot;&quot;&quot;Return info about parent needed by child to unpickle process object.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    d = {}</span>
<span class="gi">+    if init_main_module:</span>
<span class="gi">+        d[&#39;init_main_module&#39;] = True</span>
<span class="gi">+</span>
<span class="gi">+    # Get sys.path and sys.argv</span>
<span class="gi">+    d[&#39;sys_path&#39;] = sys.path</span>
<span class="gi">+    d[&#39;sys_argv&#39;] = sys.argv</span>
<span class="gi">+</span>
<span class="gi">+    # Get the main module&#39;s __spec__</span>
<span class="gi">+    main_module = sys.modules[&#39;__main__&#39;]</span>
<span class="gi">+    if hasattr(main_module, &#39;__spec__&#39;):</span>
<span class="gi">+        d[&#39;main_module_spec&#39;] = main_module.__spec__</span>
<span class="gi">+</span>
<span class="gi">+    # Get the current working directory</span>
<span class="gi">+    d[&#39;cwd&#39;] = os.getcwd()</span>
<span class="gi">+</span>
<span class="gi">+    # Get environment variables</span>
<span class="gi">+    d[&#39;env&#39;] = dict(os.environ)</span>
<span class="gi">+</span>
<span class="gi">+    # Get the process name</span>
<span class="gi">+    d[&#39;name&#39;] = name</span>
<span class="gi">+</span>
<span class="gi">+    return d</span>


<span class="w"> </span>old_main_modules = []
<span class="gu">@@ -28,4 +50,33 @@ old_main_modules = []</span>

<span class="w"> </span>def prepare(data, parent_sentinel=None):
<span class="w"> </span>    &quot;&quot;&quot;Try to get current process ready to unpickle process object.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if &#39;init_main_module&#39; in data and data[&#39;init_main_module&#39;]:</span>
<span class="gi">+        # Set up the main module</span>
<span class="gi">+        runpy.run_module(sys.modules[&#39;__main__&#39;].__spec__.name,</span>
<span class="gi">+                         run_name=&#39;__mp_main__&#39;, alter_sys=True)</span>
<span class="gi">+</span>
<span class="gi">+    # Update sys.path</span>
<span class="gi">+    sys.path = data.get(&#39;sys_path&#39;, sys.path)</span>
<span class="gi">+</span>
<span class="gi">+    # Update sys.argv</span>
<span class="gi">+    sys.argv = data.get(&#39;sys_argv&#39;, sys.argv)</span>
<span class="gi">+</span>
<span class="gi">+    # Change the current working directory</span>
<span class="gi">+    os.chdir(data.get(&#39;cwd&#39;, os.getcwd()))</span>
<span class="gi">+</span>
<span class="gi">+    # Update environment variables</span>
<span class="gi">+    os.environ.update(data.get(&#39;env&#39;, {}))</span>
<span class="gi">+</span>
<span class="gi">+    # Set the process name</span>
<span class="gi">+    util.set_process_name(data.get(&#39;name&#39;, &#39;loky_process&#39;))</span>
<span class="gi">+</span>
<span class="gi">+    # Handle the parent sentinel (Windows-specific)</span>
<span class="gi">+    if parent_sentinel is not None and sys.platform == &#39;win32&#39;:</span>
<span class="gi">+        parent_sentinel = duplicate(parent_sentinel, inheritable=True)</span>
<span class="gi">+        process.current_process()._parent_pid = os.getppid()</span>
<span class="gi">+        process.current_process()._parent_sentinel = parent_sentinel</span>
<span class="gi">+</span>
<span class="gi">+    # Clear and update old_main_modules</span>
<span class="gi">+    global old_main_modules</span>
<span class="gi">+    old_main_modules.clear()</span>
<span class="gi">+    old_main_modules.append(sys.modules[&#39;__main__&#39;])</span>
<span class="gh">diff --git a/joblib/externals/loky/backend/utils.py b/joblib/externals/loky/backend/utils.py</span>
<span class="gh">index 3a17859..89c0054 100644</span>
<span class="gd">--- a/joblib/externals/loky/backend/utils.py</span>
<span class="gi">+++ b/joblib/externals/loky/backend/utils.py</span>
<span class="gu">@@ -14,17 +14,37 @@ except ImportError:</span>

<span class="w"> </span>def kill_process_tree(process, use_psutil=True):
<span class="w"> </span>    &quot;&quot;&quot;Terminate process and its descendants with SIGKILL&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if use_psutil and psutil is not None:</span>
<span class="gi">+        try:</span>
<span class="gi">+            parent = psutil.Process(process.pid)</span>
<span class="gi">+            children = parent.children(recursive=True)</span>
<span class="gi">+            for child in children:</span>
<span class="gi">+                child.kill()</span>
<span class="gi">+            parent.kill()</span>
<span class="gi">+        except psutil.NoSuchProcess:</span>
<span class="gi">+            pass</span>
<span class="gi">+    else:</span>
<span class="gi">+        _kill_process_tree_without_psutil(process)</span>


<span class="w"> </span>def _kill_process_tree_without_psutil(process):
<span class="w"> </span>    &quot;&quot;&quot;Terminate a process and its descendants.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if sys.platform != &#39;win32&#39;:</span>
<span class="gi">+        _posix_recursive_kill(process.pid)</span>
<span class="gi">+    else:</span>
<span class="gi">+        subprocess.call([&#39;taskkill&#39;, &#39;/F&#39;, &#39;/T&#39;, &#39;/PID&#39;, str(process.pid)])</span>


<span class="w"> </span>def _posix_recursive_kill(pid):
<span class="w"> </span>    &quot;&quot;&quot;Recursively kill the descendants of a process before killing it.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        parent = psutil.Process(pid)</span>
<span class="gi">+        children = parent.children(recursive=True)</span>
<span class="gi">+        for child in children:</span>
<span class="gi">+            child.kill()</span>
<span class="gi">+        parent.kill()</span>
<span class="gi">+    except psutil.NoSuchProcess:</span>
<span class="gi">+        pass</span>


<span class="w"> </span>def get_exitcodes_terminated_worker(processes):
<span class="gu">@@ -33,9 +53,33 @@ def get_exitcodes_terminated_worker(processes):</span>
<span class="w"> </span>    If necessary, wait (up to .25s) for the system to correctly set the
<span class="w"> </span>    exitcode of one terminated worker.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    exitcodes = []</span>
<span class="gi">+    for process in processes:</span>
<span class="gi">+        try:</span>
<span class="gi">+            exitcode = process.exitcode</span>
<span class="gi">+            if exitcode is None:</span>
<span class="gi">+                process.join(timeout=0.25)</span>
<span class="gi">+                exitcode = process.exitcode</span>
<span class="gi">+            if exitcode is not None:</span>
<span class="gi">+                exitcodes.append(exitcode)</span>
<span class="gi">+        except Exception:</span>
<span class="gi">+            pass</span>
<span class="gi">+    </span>
<span class="gi">+    if exitcodes:</span>
<span class="gi">+        return _format_exitcodes(exitcodes)</span>
<span class="gi">+    return &quot;&quot;</span>


<span class="w"> </span>def _format_exitcodes(exitcodes):
<span class="w"> </span>    &quot;&quot;&quot;Format a list of exit code with names of the signals if possible&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    formatted_exitcodes = []</span>
<span class="gi">+    for exitcode in exitcodes:</span>
<span class="gi">+        if exitcode &lt; 0:</span>
<span class="gi">+            try:</span>
<span class="gi">+                sig_name = signal.Signals(-exitcode).name</span>
<span class="gi">+                formatted_exitcodes.append(f&quot;{exitcode} ({sig_name})&quot;)</span>
<span class="gi">+            except ValueError:</span>
<span class="gi">+                formatted_exitcodes.append(str(exitcode))</span>
<span class="gi">+        else:</span>
<span class="gi">+            formatted_exitcodes.append(str(exitcode))</span>
<span class="gi">+    return &quot;, &quot;.join(formatted_exitcodes)</span>
<span class="gh">diff --git a/joblib/externals/loky/cloudpickle_wrapper.py b/joblib/externals/loky/cloudpickle_wrapper.py</span>
<span class="gh">index 808ade4..75466fc 100644</span>
<span class="gd">--- a/joblib/externals/loky/cloudpickle_wrapper.py</span>
<span class="gi">+++ b/joblib/externals/loky/cloudpickle_wrapper.py</span>
<span class="gu">@@ -37,4 +37,16 @@ def wrap_non_picklable_objects(obj, keep_wrapper=True):</span>
<span class="w"> </span>    objects in the main scripts and to implement __reduce__ functions for
<span class="w"> </span>    complex classes.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(obj, partial):</span>
<span class="gi">+        # Handle partial functions</span>
<span class="gi">+        return obj</span>
<span class="gi">+    elif callable(obj):</span>
<span class="gi">+        # Handle callable objects</span>
<span class="gi">+        if obj in WRAP_CACHE:</span>
<span class="gi">+            return WRAP_CACHE[obj]</span>
<span class="gi">+        wrapper = CallableObjectWrapper(obj, keep_wrapper=keep_wrapper)</span>
<span class="gi">+        WRAP_CACHE[obj] = wrapper</span>
<span class="gi">+        return wrapper</span>
<span class="gi">+    else:</span>
<span class="gi">+        # Handle non-callable objects</span>
<span class="gi">+        return CloudpickledObjectWrapper(obj, keep_wrapper=keep_wrapper)</span>
<span class="gh">diff --git a/joblib/externals/loky/initializers.py b/joblib/externals/loky/initializers.py</span>
<span class="gh">index 81c0c79..a96110f 100644</span>
<span class="gd">--- a/joblib/externals/loky/initializers.py</span>
<span class="gi">+++ b/joblib/externals/loky/initializers.py</span>
<span class="gu">@@ -3,7 +3,11 @@ import warnings</span>

<span class="w"> </span>def _viztracer_init(init_kwargs):
<span class="w"> </span>    &quot;&quot;&quot;Initialize viztracer&#39;s profiler in worker processes&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        import viztracer</span>
<span class="gi">+        viztracer.set_tracer(**init_kwargs)</span>
<span class="gi">+    except ImportError:</span>
<span class="gi">+        warnings.warn(&quot;viztracer is not installed. Profiling will not be available.&quot;)</span>


<span class="w"> </span>class _ChainedInitializer:
<span class="gu">@@ -26,4 +30,11 @@ def _chain_initializers(initializer_and_args):</span>

<span class="w"> </span>    If some initializers are None, they are filtered out.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    valid_initializers = [</span>
<span class="gi">+        (init, args) for init, args in initializer_and_args</span>
<span class="gi">+        if init is not None</span>
<span class="gi">+    ]</span>
<span class="gi">+    if not valid_initializers:</span>
<span class="gi">+        return None</span>
<span class="gi">+    initializers, args_list = zip(*valid_initializers)</span>
<span class="gi">+    return _ChainedInitializer(initializers), args_list</span>
<span class="gh">diff --git a/joblib/externals/loky/process_executor.py b/joblib/externals/loky/process_executor.py</span>
<span class="gh">index c68582c..2e84f34 100644</span>
<span class="gd">--- a/joblib/externals/loky/process_executor.py</span>
<span class="gi">+++ b/joblib/externals/loky/process_executor.py</span>
<span class="gu">@@ -180,7 +180,12 @@ class _SafeQueue(Queue):</span>

<span class="w"> </span>def _get_chunks(chunksize, *iterables):
<span class="w"> </span>    &quot;&quot;&quot;Iterates over zip()ed iterables in chunks.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    it = zip(*iterables)</span>
<span class="gi">+    while True:</span>
<span class="gi">+        chunk = tuple(itertools.islice(it, chunksize))</span>
<span class="gi">+        if not chunk:</span>
<span class="gi">+            return</span>
<span class="gi">+        yield chunk</span>


<span class="w"> </span>def _process_chunk(fn, chunk):
<span class="gu">@@ -192,12 +197,16 @@ def _process_chunk(fn, chunk):</span>
<span class="w"> </span>    This function is run in a separate process.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return [fn(*args) for args in chunk]</span>


<span class="w"> </span>def _sendback_result(result_queue, work_id, result=None, exception=None):
<span class="w"> </span>    &quot;&quot;&quot;Safely send back the given result or exception&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        result_queue.put(_ResultItem(work_id, exception, result))</span>
<span class="gi">+    except BaseException as e:</span>
<span class="gi">+        exc = _ExceptionWithTraceback(e)</span>
<span class="gi">+        result_queue.put(_ResultItem(work_id, exc))</span>


<span class="w"> </span>def _process_worker(call_queue, result_queue, initializer, initargs,
<span class="gu">@@ -221,7 +230,39 @@ def _process_worker(call_queue, result_queue, initializer, initargs,</span>
<span class="w"> </span>            workers timeout.
<span class="w"> </span>        current_depth: Nested parallelism level, to avoid infinite spawning.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if initializer is not None:</span>
<span class="gi">+        try:</span>
<span class="gi">+            initializer(*initargs)</span>
<span class="gi">+        except BaseException:</span>
<span class="gi">+            _sendback_result(result_queue, None, exception=_ExceptionWithTraceback(sys.exc_info()[1]))</span>
<span class="gi">+            return</span>
<span class="gi">+</span>
<span class="gi">+    watchdog = None</span>
<span class="gi">+    if timeout is not None:</span>
<span class="gi">+        watchdog = threading.Thread(target=_shutdown_worker,</span>
<span class="gi">+                                    args=(call_queue, result_queue, timeout, processes_management_lock, worker_exit_lock))</span>
<span class="gi">+        watchdog.daemon = True</span>
<span class="gi">+        watchdog.start()</span>
<span class="gi">+</span>
<span class="gi">+    while True:</span>
<span class="gi">+        try:</span>
<span class="gi">+            call_item = call_queue.get(block=True, timeout=timeout)</span>
<span class="gi">+        except queue.Empty:</span>
<span class="gi">+            if watchdog is not None:</span>
<span class="gi">+                watchdog.join()</span>
<span class="gi">+            processes_management_lock.acquire()</span>
<span class="gi">+            return</span>
<span class="gi">+        if call_item is None:</span>
<span class="gi">+            processes_management_lock.acquire()</span>
<span class="gi">+            return</span>
<span class="gi">+        try:</span>
<span class="gi">+            r = call_item()</span>
<span class="gi">+        except BaseException as e:</span>
<span class="gi">+            exc = _ExceptionWithTraceback(e)</span>
<span class="gi">+            _sendback_result(result_queue, call_item.work_id, exception=exc)</span>
<span class="gi">+        else:</span>
<span class="gi">+            _sendback_result(result_queue, call_item.work_id, result=r)</span>
<span class="gi">+        del call_item</span>


<span class="w"> </span>class _ExecutorManagerThread(threading.Thread):
<span class="gu">@@ -272,7 +313,8 @@ def _chain_from_iterable_of_lists(iterable):</span>
<span class="w"> </span>    Each item in *iterable* should be a list.  This function is
<span class="w"> </span>    careful not to keep references to yielded objects.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    for element in iterable:</span>
<span class="gi">+        yield from element</span>


<span class="w"> </span>class LokyRecursionError(RuntimeError):
<span class="gu">@@ -375,7 +417,13 @@ class ProcessPoolExecutor(Executor):</span>

<span class="w"> </span>    def _ensure_executor_running(self):
<span class="w"> </span>        &quot;&quot;&quot;ensures all workers and management thread are running&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with self._processes_management_lock:</span>
<span class="gi">+            if len(self._processes) == 0:</span>
<span class="gi">+                self._adjust_process_count()</span>
<span class="gi">+            if self._executor_manager_thread is None:</span>
<span class="gi">+                self._executor_manager_thread = _ExecutorManagerThread(self)</span>
<span class="gi">+                self._executor_manager_thread.start()</span>
<span class="gi">+                _threads_wakeups[self._executor_manager_thread] = self._executor_manager_thread_wakeup</span>
<span class="w"> </span>    submit.__doc__ = Executor.submit.__doc__

<span class="w"> </span>    def map(self, fn, *iterables, **kwargs):
<span class="gu">@@ -400,5 +448,14 @@ class ProcessPoolExecutor(Executor):</span>
<span class="w"> </span>                before the given timeout.
<span class="w"> </span>            Exception: If fn(*args) raises for any values.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        timeout = kwargs.get(&#39;timeout&#39;, None)</span>
<span class="gi">+        chunksize = kwargs.get(&#39;chunksize&#39;, 1)</span>
<span class="gi">+        </span>
<span class="gi">+        if chunksize &lt; 1:</span>
<span class="gi">+            raise ValueError(&quot;chunksize must be &gt;= 1.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        results = super().map(partial(_process_chunk, fn),</span>
<span class="gi">+                              _get_chunks(chunksize, *iterables),</span>
<span class="gi">+                              timeout=timeout)</span>
<span class="gi">+        return _chain_from_iterable_of_lists(results)</span>
<span class="w"> </span>    shutdown.__doc__ = Executor.shutdown.__doc__
<span class="gh">diff --git a/joblib/externals/loky/reusable_executor.py b/joblib/externals/loky/reusable_executor.py</span>
<span class="gh">index 5509ecc..c3469f6 100644</span>
<span class="gd">--- a/joblib/externals/loky/reusable_executor.py</span>
<span class="gi">+++ b/joblib/externals/loky/reusable_executor.py</span>
<span class="gu">@@ -18,7 +18,11 @@ def _get_next_executor_id():</span>
<span class="w"> </span>    The purpose of this monotonic id is to help debug and test automated
<span class="w"> </span>    instance creation.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    global _next_executor_id</span>
<span class="gi">+    with _executor_lock:</span>
<span class="gi">+        executor_id = _next_executor_id</span>
<span class="gi">+        _next_executor_id += 1</span>
<span class="gi">+    return executor_id</span>


<span class="w"> </span>def get_reusable_executor(max_workers=None, context=None, timeout=10,
<span class="gu">@@ -64,7 +68,48 @@ def get_reusable_executor(max_workers=None, context=None, timeout=10,</span>
<span class="w"> </span>    in the children before any module is loaded. This only works with the
<span class="w"> </span>    ``loky`` context.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    global _executor, _executor_kwargs</span>
<span class="gi">+    executor_id = _get_next_executor_id()</span>
<span class="gi">+    </span>
<span class="gi">+    with _executor_lock:</span>
<span class="gi">+        if _executor is None or kill_workers:</span>
<span class="gi">+            if _executor is not None:</span>
<span class="gi">+                _executor.shutdown(wait=True)</span>
<span class="gi">+            </span>
<span class="gi">+            _executor = _ReusablePoolExecutor(</span>
<span class="gi">+                _executor_lock,</span>
<span class="gi">+                max_workers=max_workers,</span>
<span class="gi">+                context=context,</span>
<span class="gi">+                timeout=timeout,</span>
<span class="gi">+                executor_id=executor_id,</span>
<span class="gi">+                job_reducers=job_reducers,</span>
<span class="gi">+                result_reducers=result_reducers,</span>
<span class="gi">+                initializer=initializer,</span>
<span class="gi">+                initargs=initargs,</span>
<span class="gi">+                env=env</span>
<span class="gi">+            )</span>
<span class="gi">+            _executor_kwargs = _executor._kwargs</span>
<span class="gi">+        else:</span>
<span class="gi">+            if max_workers is not None and _executor._max_workers != max_workers:</span>
<span class="gi">+                _executor._wait_job_completion()</span>
<span class="gi">+                _executor._max_workers = max_workers</span>
<span class="gi">+                _executor._adjust_process_count()</span>
<span class="gi">+            if _executor._broken:</span>
<span class="gi">+                _executor = None</span>
<span class="gi">+                return get_reusable_executor(</span>
<span class="gi">+                    max_workers=max_workers,</span>
<span class="gi">+                    context=context,</span>
<span class="gi">+                    timeout=timeout,</span>
<span class="gi">+                    kill_workers=kill_workers,</span>
<span class="gi">+                    reuse=reuse,</span>
<span class="gi">+                    job_reducers=job_reducers,</span>
<span class="gi">+                    result_reducers=result_reducers,</span>
<span class="gi">+                    initializer=initializer,</span>
<span class="gi">+                    initargs=initargs,</span>
<span class="gi">+                    env=env</span>
<span class="gi">+                )</span>
<span class="gi">+    </span>
<span class="gi">+    return _executor</span>


<span class="w"> </span>class _ReusablePoolExecutor(ProcessPoolExecutor):
<span class="gu">@@ -81,4 +126,5 @@ class _ReusablePoolExecutor(ProcessPoolExecutor):</span>

<span class="w"> </span>    def _wait_job_completion(self):
<span class="w"> </span>        &quot;&quot;&quot;Wait for the cache to be empty before resizing the pool.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        while len(self._pending_work_items) &gt; 0:</span>
<span class="gi">+            time.sleep(0.1)</span>
<span class="gh">diff --git a/joblib/func_inspect.py b/joblib/func_inspect.py</span>
<span class="gh">index 5a263a0..7d3f537 100644</span>
<span class="gd">--- a/joblib/func_inspect.py</span>
<span class="gi">+++ b/joblib/func_inspect.py</span>
<span class="gu">@@ -35,12 +35,23 @@ def get_func_code(func):</span>
<span class="w"> </span>        This function does a bit more magic than inspect, and is thus
<span class="w"> </span>        more robust.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        source_file = inspect.getsourcefile(func)</span>
<span class="gi">+        if source_file is None:</span>
<span class="gi">+            raise ValueError(&quot;Unable to find the source file for the function.&quot;)</span>
<span class="gi">+        </span>
<span class="gi">+        lines, first_line = inspect.getsourcelines(func)</span>
<span class="gi">+        func_code = &#39;&#39;.join(lines)</span>
<span class="gi">+        </span>
<span class="gi">+        return func_code, source_file, first_line</span>
<span class="gi">+    except Exception as e:</span>
<span class="gi">+        raise ValueError(f&quot;Unable to retrieve function code: {str(e)}&quot;)</span>


<span class="w"> </span>def _clean_win_chars(string):
<span class="w"> </span>    &quot;&quot;&quot;Windows cannot encode some characters in filename.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import urllib.parse</span>
<span class="gi">+    return urllib.parse.quote(string, safe=&#39;&#39;)</span>


<span class="w"> </span>def get_func_name(func, resolv_alias=True, win_characters=True):
<span class="gu">@@ -57,17 +68,49 @@ def get_func_name(func, resolv_alias=True, win_characters=True):</span>
<span class="w"> </span>            If true, substitute special characters using urllib.quote
<span class="w"> </span>            This is useful in Windows, as it cannot encode some filenames
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    module = inspect.getmodule(func)</span>
<span class="gi">+    if module is None:</span>
<span class="gi">+        return [], func.__name__</span>
<span class="gi">+</span>
<span class="gi">+    module_path = module.__name__.split(&#39;.&#39;)</span>
<span class="gi">+    func_name = func.__name__</span>
<span class="gi">+</span>
<span class="gi">+    if resolv_alias:</span>
<span class="gi">+        if hasattr(module, &#39;__all__&#39;):</span>
<span class="gi">+            if func_name not in module.__all__:</span>
<span class="gi">+                func_name = f&#39;{func_name} (alias)&#39;</span>
<span class="gi">+        elif not func_name.startswith(&#39;_&#39;):</span>
<span class="gi">+            func_name = f&#39;{func_name} (alias)&#39;</span>
<span class="gi">+</span>
<span class="gi">+    if win_characters:</span>
<span class="gi">+        func_name = _clean_win_chars(func_name)</span>
<span class="gi">+</span>
<span class="gi">+    return module_path, func_name</span>


<span class="w"> </span>def _signature_str(function_name, arg_sig):
<span class="w"> </span>    &quot;&quot;&quot;Helper function to output a function signature&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    args = []</span>
<span class="gi">+    for arg in arg_sig.args:</span>
<span class="gi">+        if arg in arg_sig.annotations:</span>
<span class="gi">+            args.append(f&quot;{arg}: {arg_sig.annotations[arg].__name__}&quot;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            args.append(arg)</span>
<span class="gi">+    </span>
<span class="gi">+    if arg_sig.varargs:</span>
<span class="gi">+        args.append(f&quot;*{arg_sig.varargs}&quot;)</span>
<span class="gi">+    if arg_sig.varkw:</span>
<span class="gi">+        args.append(f&quot;**{arg_sig.varkw}&quot;)</span>
<span class="gi">+    </span>
<span class="gi">+    return f&quot;{function_name}({&#39;, &#39;.join(args)})&quot;</span>


<span class="w"> </span>def _function_called_str(function_name, args, kwargs):
<span class="w"> </span>    &quot;&quot;&quot;Helper function to output a function call&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    args_str = [repr(arg) for arg in args]</span>
<span class="gi">+    kwargs_str = [f&quot;{key}={repr(value)}&quot; for key, value in kwargs.items()]</span>
<span class="gi">+    all_args = args_str + kwargs_str</span>
<span class="gi">+    return f&quot;{function_name}({&#39;, &#39;.join(all_args)})&quot;</span>


<span class="w"> </span>def filter_args(func, ignore_lst, args=(), kwargs=dict()):
<span class="gu">@@ -91,11 +134,27 @@ def filter_args(func, ignore_lst, args=(), kwargs=dict()):</span>
<span class="w"> </span>        filtered_args: list
<span class="w"> </span>            List of filtered positional and keyword arguments.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    arg_spec = inspect.getfullargspec(func)</span>
<span class="gi">+    </span>
<span class="gi">+    # Filter positional arguments</span>
<span class="gi">+    filtered_args = [arg for i, arg in enumerate(args) if i &lt; len(arg_spec.args) and arg_spec.args[i] not in ignore_lst]</span>
<span class="gi">+    </span>
<span class="gi">+    # Filter keyword arguments</span>
<span class="gi">+    filtered_kwargs = {k: v for k, v in kwargs.items() if k not in ignore_lst}</span>
<span class="gi">+    </span>
<span class="gi">+    # Handle &#39;*args&#39; and &#39;**kwargs&#39;</span>
<span class="gi">+    if &#39;*&#39; not in ignore_lst and arg_spec.varargs:</span>
<span class="gi">+        filtered_args.extend(args[len(arg_spec.args):])</span>
<span class="gi">+    if &#39;**&#39; not in ignore_lst and arg_spec.varkw:</span>
<span class="gi">+        filtered_kwargs.update({k: v for k, v in kwargs.items() if k not in arg_spec.args})</span>
<span class="gi">+    </span>
<span class="gi">+    return filtered_args + list(filtered_kwargs.items())</span>


<span class="w"> </span>def format_call(func, args, kwargs, object_name=&#39;Memory&#39;):
<span class="w"> </span>    &quot;&quot;&quot; Returns a nicely formatted statement displaying the function
<span class="w"> </span>        call with the given arguments.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    func_name = get_func_name(func)[1]</span>
<span class="gi">+    arg_str = _function_called_str(func_name, args, kwargs)</span>
<span class="gi">+    return f&quot;{object_name}({arg_str})&quot;</span>
<span class="gh">diff --git a/joblib/hashing.py b/joblib/hashing.py</span>
<span class="gh">index 7f57b88..e4e7758 100644</span>
<span class="gd">--- a/joblib/hashing.py</span>
<span class="gi">+++ b/joblib/hashing.py</span>
<span class="gu">@@ -77,7 +77,20 @@ class NumpyHasher(Hasher):</span>
<span class="w"> </span>            than pickling them. Off course, this is a total abuse of
<span class="w"> </span>            the Pickler class.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(obj, self.np.ndarray):</span>
<span class="gi">+            # Check if it&#39;s a memmap</span>
<span class="gi">+            if isinstance(obj, self.np.memmap) and not self.coerce_mmap:</span>
<span class="gi">+                # Memmap detected, handle differently</span>
<span class="gi">+                self._hash.update(obj.filename.encode(&#39;utf-8&#39;))</span>
<span class="gi">+                self._hash.update(str(obj.offset).encode(&#39;utf-8&#39;))</span>
<span class="gi">+                self._hash.update(str(obj.shape).encode(&#39;utf-8&#39;))</span>
<span class="gi">+                self._hash.update(str(obj.dtype).encode(&#39;utf-8&#39;))</span>
<span class="gi">+            else:</span>
<span class="gi">+                # Regular ndarray or coerced memmap</span>
<span class="gi">+                self._hash.update(self._getbuffer(obj))</span>
<span class="gi">+        else:</span>
<span class="gi">+            # For all other objects, use the default pickling behavior</span>
<span class="gi">+            Hasher.save(self, obj)</span>


<span class="w"> </span>def hash(obj, hash_name=&#39;md5&#39;, coerce_mmap=False):
<span class="gu">@@ -92,4 +105,17 @@ def hash(obj, hash_name=&#39;md5&#39;, coerce_mmap=False):</span>
<span class="w"> </span>        coerce_mmap: boolean
<span class="w"> </span>            Make no difference between np.memmap and np.ndarray
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if hash_name not in (&#39;md5&#39;, &#39;sha1&#39;):</span>
<span class="gi">+        raise ValueError(&quot;Valid options for &#39;hash_name&#39; are &#39;md5&#39; or &#39;sha1&#39;&quot;)</span>
<span class="gi">+    try:</span>
<span class="gi">+        import numpy as np</span>
<span class="gi">+        hasher = NumpyHasher(hash_name=hash_name, coerce_mmap=coerce_mmap)</span>
<span class="gi">+    except ImportError:</span>
<span class="gi">+        hasher = Hasher(hash_name=hash_name)</span>
<span class="gi">+    </span>
<span class="gi">+    try:</span>
<span class="gi">+        hasher.save(obj)</span>
<span class="gi">+    except pickle.PicklingError as e:</span>
<span class="gi">+        raise pickle.PicklingError(&#39;PicklingError while hashing %r: %r&#39; %</span>
<span class="gi">+                                   (obj, e))</span>
<span class="gi">+    return hasher._hash.hexdigest()</span>
<span class="gh">diff --git a/joblib/logger.py b/joblib/logger.py</span>
<span class="gh">index 4991108..40ece3d 100644</span>
<span class="gd">--- a/joblib/logger.py</span>
<span class="gi">+++ b/joblib/logger.py</span>
<span class="gu">@@ -18,7 +18,9 @@ def _squeeze_time(t):</span>
<span class="w"> </span>    stat files. This is needed to make results similar to timings under
<span class="w"> </span>    Unix, for tests
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if sys.platform.startswith(&#39;win&#39;):</span>
<span class="gi">+        return max(0, t - 0.1)</span>
<span class="gi">+    return t</span>


<span class="w"> </span>class Logger(object):
<span class="gu">@@ -39,7 +41,7 @@ class Logger(object):</span>

<span class="w"> </span>    def format(self, obj, indent=0):
<span class="w"> </span>        &quot;&quot;&quot;Return the formatted representation of the object.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return pprint.pformat(obj, indent=indent, depth=self.depth)</span>


<span class="w"> </span>class PrintTime(object):
<span class="gh">diff --git a/joblib/memory.py b/joblib/memory.py</span>
<span class="gh">index 14f8456..2db1dcd 100644</span>
<span class="gd">--- a/joblib/memory.py</span>
<span class="gi">+++ b/joblib/memory.py</span>
<span class="gu">@@ -30,7 +30,10 @@ def extract_first_line(func_code):</span>
<span class="w"> </span>    &quot;&quot;&quot; Extract the first line information from the function code
<span class="w"> </span>        text if available.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    lines = func_code.split(&#39;\n&#39;)</span>
<span class="gi">+    if lines:</span>
<span class="gi">+        return lines[0].strip()</span>
<span class="gi">+    return &#39;&#39;</span>


<span class="w"> </span>class JobLibCollisionWarning(UserWarning):
<span class="gu">@@ -59,17 +62,32 @@ def register_store_backend(backend_name, backend):</span>
<span class="w"> </span>        The name of a class that implements the StoreBackendBase interface.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not issubclass(backend, StoreBackendBase):</span>
<span class="gi">+        raise ValueError(&quot;backend must be a subclass of StoreBackendBase&quot;)</span>
<span class="gi">+    _STORE_BACKENDS[backend_name] = backend</span>


<span class="w"> </span>def _store_backend_factory(backend, location, verbose=0, backend_options=None):
<span class="w"> </span>    &quot;&quot;&quot;Return the correct store object for the given location.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if backend not in _STORE_BACKENDS:</span>
<span class="gi">+        raise ValueError(f&quot;Unknown backend: {backend}&quot;)</span>
<span class="gi">+    </span>
<span class="gi">+    backend_options = backend_options or {}</span>
<span class="gi">+    backend_class = _STORE_BACKENDS[backend]</span>
<span class="gi">+    return backend_class(location, verbose=verbose, **backend_options)</span>


<span class="w"> </span>def _build_func_identifier(func):
<span class="w"> </span>    &quot;&quot;&quot;Build a roughly unique identifier for the cached function.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    module = getattr(func, &#39;__module__&#39;, None)</span>
<span class="gi">+    name = getattr(func, &#39;__qualname__&#39;, None) or getattr(func, &#39;__name__&#39;, None)</span>
<span class="gi">+    </span>
<span class="gi">+    if module and name:</span>
<span class="gi">+        return f&quot;{module}.{name}&quot;</span>
<span class="gi">+    elif name:</span>
<span class="gi">+        return name</span>
<span class="gi">+    else:</span>
<span class="gi">+        return str(func)</span>


<span class="w"> </span>_FUNCTION_HASHES = weakref.WeakKeyDictionary()
<span class="gu">@@ -123,11 +141,20 @@ class MemorizedResult(Logger):</span>

<span class="w"> </span>    def get(self):
<span class="w"> </span>        &quot;&quot;&quot;Read value from cache and return it.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.store_backend is None:</span>
<span class="gi">+            raise ValueError(&quot;Cannot get a value from a non-initialized backend&quot;)</span>
<span class="gi">+        </span>
<span class="gi">+        value = self.store_backend.load_item(self._call_id)</span>
<span class="gi">+        </span>
<span class="gi">+        if self.mmap_mode is not None and hasattr(value, &#39;mmap&#39;):</span>
<span class="gi">+            value = value.mmap(mode=self.mmap_mode)</span>
<span class="gi">+        </span>
<span class="gi">+        return value</span>

<span class="w"> </span>    def clear(self):
<span class="w"> </span>        &quot;&quot;&quot;Clear value from cache&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.store_backend is not None:</span>
<span class="gi">+            self.store_backend.clear_item(self._call_id)</span>

<span class="w"> </span>    def __repr__(self):
<span class="w"> </span>        return &#39;{}(location=&quot;{}&quot;, func=&quot;{}&quot;, args_id=&quot;{}&quot;)&#39;.format(self.
<span class="gu">@@ -279,7 +306,22 @@ class MemorizedFunc(Logger):</span>
<span class="w"> </span>        Returns True if the function call is in cache and can be used, and
<span class="w"> </span>        returns False otherwise.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.store_backend is None:</span>
<span class="gi">+            return False</span>
<span class="gi">+</span>
<span class="gi">+        if not self.store_backend.contains_item(call_id):</span>
<span class="gi">+            return False</span>
<span class="gi">+</span>
<span class="gi">+        func_code, _ = get_func_code(self.func)</span>
<span class="gi">+        if self._check_previous_func_code(stacklevel=4):</span>
<span class="gi">+            return False</span>
<span class="gi">+</span>
<span class="gi">+        if self.cache_validation_callback is not None:</span>
<span class="gi">+            metadata = self.store_backend.get_metadata(call_id)</span>
<span class="gi">+            if not self.cache_validation_callback(metadata):</span>
<span class="gi">+                return False</span>
<span class="gi">+</span>
<span class="gi">+        return True</span>

<span class="w"> </span>    def _cached_call(self, args, kwargs, shelving):
<span class="w"> </span>        &quot;&quot;&quot;Call wrapped function and cache result, or read cache if available.
<span class="gu">@@ -303,7 +345,32 @@ class MemorizedFunc(Logger):</span>
<span class="w"> </span>            MemorizedResult reference to the value if shelving is true.
<span class="w"> </span>        metadata: dict containing the metadata associated with the call.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        call_id = self._get_args_id(*args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+        if self._is_in_cache_and_valid(call_id):</span>
<span class="gi">+            return self._load_cached_result(call_id, shelving)</span>
<span class="gi">+</span>
<span class="gi">+        start_time = time.time()</span>
<span class="gi">+        output = self.func(*args, **kwargs)</span>
<span class="gi">+        duration = time.time() - start_time</span>
<span class="gi">+</span>
<span class="gi">+        metadata = {</span>
<span class="gi">+            &#39;duration&#39;: duration,</span>
<span class="gi">+            &#39;timestamp&#39;: time.time(),</span>
<span class="gi">+        }</span>
<span class="gi">+</span>
<span class="gi">+        self._persist_input(duration, call_id, args, kwargs)</span>
<span class="gi">+        self.store_backend.dump_item(call_id, output, metadata)</span>
<span class="gi">+</span>
<span class="gi">+        if shelving:</span>
<span class="gi">+            return MemorizedResult(self.store_backend.location, call_id, </span>
<span class="gi">+                                   backend=self.store_backend.__class__.__name__,</span>
<span class="gi">+                                   mmap_mode=self.mmap_mode,</span>
<span class="gi">+                                   verbose=self._verbose,</span>
<span class="gi">+                                   timestamp=self.timestamp,</span>
<span class="gi">+                                   metadata=metadata), metadata</span>
<span class="gi">+        else:</span>
<span class="gi">+            return output, metadata</span>

<span class="w"> </span>    def call_and_shelve(self, *args, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Call wrapped function, cache result and return a reference.
<span class="gu">@@ -348,27 +415,47 @@ class MemorizedFunc(Logger):</span>

<span class="w"> </span>    def _get_args_id(self, *args, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Return the input parameter hash of a result.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return hashing.hash((args, kwargs), ignore=self.ignore)</span>

<span class="w"> </span>    def _hash_func(self):
<span class="w"> </span>        &quot;&quot;&quot;Hash a function to key the online cache&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        func_code, source_file = get_func_code(self.func)</span>
<span class="gi">+        return hashing.hash((func_code, source_file, self.func_id))</span>

<span class="w"> </span>    def _write_func_code(self, func_code, first_line):
<span class="w"> </span>        &quot;&quot;&quot; Write the function code and the filename to a file.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.store_backend is None:</span>
<span class="gi">+            return</span>
<span class="gi">+</span>
<span class="gi">+        func_code = f&quot;{FIRST_LINE_TEXT} {first_line}\n{func_code}&quot;</span>
<span class="gi">+        self.store_backend.store_cached_func_code([self.func_id], func_code)</span>

<span class="w"> </span>    def _check_previous_func_code(self, stacklevel=2):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>            stacklevel is the depth a which this function is called, to
<span class="w"> </span>            issue useful warnings to the user.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self._func_code_info is None:</span>
<span class="gi">+            return False</span>
<span class="gi">+        </span>
<span class="gi">+        func_code, source_file = get_func_code(self.func)</span>
<span class="gi">+        func_code_id = self._hash_func()</span>
<span class="gi">+        </span>
<span class="gi">+        if func_code_id != self._func_code_id:</span>
<span class="gi">+            warnings.warn(&#39;Function {} has changed.&#39;.format(self.func),</span>
<span class="gi">+                          JobLibCollisionWarning, stacklevel=stacklevel)</span>
<span class="gi">+            return True</span>
<span class="gi">+        return False</span>

<span class="w"> </span>    def clear(self, warn=True):
<span class="w"> </span>        &quot;&quot;&quot;Empty the function&#39;s cache.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.store_backend is not None:</span>
<span class="gi">+            self.store_backend.clear()</span>
<span class="gi">+        </span>
<span class="gi">+        if warn:</span>
<span class="gi">+            warnings.warn(&#39;Clearing {0} cache&#39;.format(self.func.__name__),</span>
<span class="gi">+                          stacklevel=2)</span>

<span class="w"> </span>    def call(self, *args, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Force the execution of the function with the given arguments.
<span class="gu">@@ -410,7 +497,25 @@ class MemorizedFunc(Logger):</span>
<span class="w"> </span>            this_duration_limit: float
<span class="w"> </span>                Max execution time for this function before issuing a warning.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if duration &gt; this_duration_limit:</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                &#39;Persisting input arguments took %.2fs to run.\n&#39;</span>
<span class="gi">+                &#39;If this happens often in your code, it can cause performance problems &#39;</span>
<span class="gi">+                &#39;(results will be correct but it can be slow).\n&#39;</span>
<span class="gi">+                &#39;The reason for this is probably some large input arguments.\n&#39;</span>
<span class="gi">+                &#39;You can try to increase the compression level or cache them separately &#39;</span>
<span class="gi">+                &#39;if possible.&#39; % duration, stacklevel=5)</span>
<span class="gi">+        </span>
<span class="gi">+        input_repr = format_call(self.func, args, kwargs)</span>
<span class="gi">+        input_repr = textwrap.shorten(input_repr, width=300)</span>
<span class="gi">+        </span>
<span class="gi">+        metadata = {</span>
<span class="gi">+            &#39;duration&#39;: duration,</span>
<span class="gi">+            &#39;input_repr&#39;: input_repr,</span>
<span class="gi">+            &#39;timestamp&#39;: time.time(),</span>
<span class="gi">+        }</span>
<span class="gi">+        </span>
<span class="gi">+        self.store_backend.store_metadata(call_id, metadata)</span>

<span class="w"> </span>    def __repr__(self):
<span class="w"> </span>        return &#39;{class_name}(func={func}, location={location})&#39;.format(
<span class="gu">@@ -548,7 +653,11 @@ class Memory(Logger):</span>
<span class="w"> </span>    def clear(self, warn=True):
<span class="w"> </span>        &quot;&quot;&quot; Erase the complete cache directory.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.store_backend is not None:</span>
<span class="gi">+            self.store_backend.clear()</span>
<span class="gi">+        </span>
<span class="gi">+        if warn:</span>
<span class="gi">+            warnings.warn(&#39;Clearing Memory cache&#39;, stacklevel=2)</span>

<span class="w"> </span>    def reduce_size(self, bytes_limit=None, items_limit=None, age_limit=None):
<span class="w"> </span>        &quot;&quot;&quot;Remove cache elements to make the cache fit its limits.
<span class="gu">@@ -576,7 +685,19 @@ class Memory(Logger):</span>
<span class="w"> </span>            of the cache, any items last accessed more than the given length of
<span class="w"> </span>            time ago are deleted.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.store_backend is None:</span>
<span class="gi">+            return</span>
<span class="gi">+</span>
<span class="gi">+        if isinstance(bytes_limit, str):</span>
<span class="gi">+            bytes_limit = self._parse_size(bytes_limit)</span>
<span class="gi">+</span>
<span class="gi">+        self.store_backend.reduce_store(bytes_limit, items_limit, age_limit)</span>
<span class="gi">+</span>
<span class="gi">+    def _parse_size(self, size_str):</span>
<span class="gi">+        units = {&#39;K&#39;: 1024, &#39;M&#39;: 1024**2, &#39;G&#39;: 1024**3}</span>
<span class="gi">+        size = int(size_str[:-1])</span>
<span class="gi">+        unit = size_str[-1].upper()</span>
<span class="gi">+        return size * units.get(unit, 1)</span>

<span class="w"> </span>    def eval(self, func, *args, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot; Eval function func with arguments `*args` and `**kwargs`,
<span class="gu">@@ -587,7 +708,11 @@ class Memory(Logger):</span>
<span class="w"> </span>            up to date.

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.store_backend is None:</span>
<span class="gi">+            return func(*args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+        cached_func = self.cache(func)</span>
<span class="gi">+        return cached_func(*args, **kwargs)</span>

<span class="w"> </span>    def __repr__(self):
<span class="w"> </span>        return &#39;{class_name}(location={location})&#39;.format(class_name=self.
<span class="gu">@@ -612,4 +737,16 @@ def expires_after(days=0, seconds=0, microseconds=0, milliseconds=0,</span>
<span class="w"> </span>    days, seconds, microseconds, milliseconds, minutes, hours, weeks: numbers
<span class="w"> </span>        argument passed to a timedelta.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    duration = datetime.timedelta(</span>
<span class="gi">+        days=days, seconds=seconds, microseconds=microseconds,</span>
<span class="gi">+        milliseconds=milliseconds, minutes=minutes, hours=hours, weeks=weeks</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    def callback(metadata):</span>
<span class="gi">+        timestamp = metadata.get(&#39;timestamp&#39;)</span>
<span class="gi">+        if timestamp is None:</span>
<span class="gi">+            return False</span>
<span class="gi">+        age = datetime.datetime.now() - datetime.datetime.fromtimestamp(timestamp)</span>
<span class="gi">+        return age &lt; duration</span>
<span class="gi">+</span>
<span class="gi">+    return callback</span>
<span class="gh">diff --git a/joblib/numpy_pickle.py b/joblib/numpy_pickle.py</span>
<span class="gh">index 6cc4089..6da27f2 100644</span>
<span class="gd">--- a/joblib/numpy_pickle.py</span>
<span class="gi">+++ b/joblib/numpy_pickle.py</span>
<span class="gu">@@ -70,7 +70,30 @@ class NumpyArrayWrapper(object):</span>
<span class="w"> </span>        This function is an adaptation of the numpy write_array function
<span class="w"> </span>        available in version 1.10.1 in numpy/lib/format.py.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.order not in (&#39;C&#39;, &#39;F&#39;):</span>
<span class="gi">+            raise ValueError(&quot;order must be &#39;C&#39; or &#39;F&#39;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        if array.dtype.hasobject:</span>
<span class="gi">+            # We don&#39;t handle object arrays</span>
<span class="gi">+            raise ValueError(&quot;object arrays cannot be written&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        if pickler.np is None:</span>
<span class="gi">+            # numpy is not available, fallback to pickle</span>
<span class="gi">+            return pickler.save(array)</span>
<span class="gi">+</span>
<span class="gi">+        # Make sure we&#39;re working with a contiguous array</span>
<span class="gi">+        array = pickler.np.ascontiguousarray(array, dtype=self.dtype)</span>
<span class="gi">+        </span>
<span class="gi">+        # Write the array data</span>
<span class="gi">+        if not pickler.buffered:</span>
<span class="gi">+            pickler.file_handle.write(array.data)</span>
<span class="gi">+        else:</span>
<span class="gi">+            # If the file handle is buffered (like with gzip), we need to chunk the write</span>
<span class="gi">+            chunk_size = BUFFER_SIZE</span>
<span class="gi">+            data = array.data</span>
<span class="gi">+            for i in range(0, len(data), chunk_size):</span>
<span class="gi">+                chunk = data[i:i+chunk_size]</span>
<span class="gi">+                pickler.file_handle.write(chunk)</span>

<span class="w"> </span>    def read_array(self, unpickler):
<span class="w"> </span>        &quot;&quot;&quot;Read array from unpickler file handle.
<span class="gu">@@ -78,11 +101,37 @@ class NumpyArrayWrapper(object):</span>
<span class="w"> </span>        This function is an adaptation of the numpy read_array function
<span class="w"> </span>        available in version 1.10.1 in numpy/lib/format.py.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if unpickler.np is None:</span>
<span class="gi">+            raise ImportError(&quot;Numpy is required to unpickle numpy arrays&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        # Read the array data</span>
<span class="gi">+        array = unpickler.np.frombuffer(</span>
<span class="gi">+            _read_bytes(unpickler.file_handle, self.size, &quot;array data&quot;),</span>
<span class="gi">+            dtype=self.dtype</span>
<span class="gi">+        ).reshape(self.shape, order=self.order)</span>
<span class="gi">+</span>
<span class="gi">+        if self.order == &#39;F&#39;:</span>
<span class="gi">+            array = unpickler.np.asfortranarray(array)</span>
<span class="gi">+</span>
<span class="gi">+        return array</span>

<span class="w"> </span>    def read_mmap(self, unpickler):
<span class="w"> </span>        &quot;&quot;&quot;Read an array using numpy memmap.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if unpickler.np is None:</span>
<span class="gi">+            raise ImportError(&quot;Numpy is required to unpickle numpy arrays&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        offset = unpickler.file_handle.tell()</span>
<span class="gi">+        if isinstance(unpickler.file_handle, io.BufferedReader):</span>
<span class="gi">+            # For buffered readers, we need to flush to get the true file position</span>
<span class="gi">+            unpickler.file_handle.flush()</span>
<span class="gi">+</span>
<span class="gi">+        array = unpickler.np.memmap(unpickler.filename, mode=unpickler.mmap_mode,</span>
<span class="gi">+                                    dtype=self.dtype, shape=self.shape,</span>
<span class="gi">+                                    order=self.order, offset=offset)</span>
<span class="gi">+</span>
<span class="gi">+        # Advance file cursor</span>
<span class="gi">+        unpickler.file_handle.seek(self.size, 1)</span>
<span class="gi">+        return array</span>

<span class="w"> </span>    def read(self, unpickler):
<span class="w"> </span>        &quot;&quot;&quot;Read the array corresponding to this wrapper.
<span class="gu">@@ -98,7 +147,16 @@ class NumpyArrayWrapper(object):</span>
<span class="w"> </span>        array: numpy.ndarray

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if unpickler.mmap_mode is not None and self.allow_mmap:</span>
<span class="gi">+            array = self.read_mmap(unpickler)</span>
<span class="gi">+        else:</span>
<span class="gi">+            array = self.read_array(unpickler)</span>
<span class="gi">+</span>
<span class="gi">+        # Handle subclasses</span>
<span class="gi">+        if self.subclass is not unpickler.np.ndarray:</span>
<span class="gi">+            array = array.view(self.subclass)</span>
<span class="gi">+</span>
<span class="gi">+        return array</span>


<span class="w"> </span>class NumpyPickler(Pickler):
<span class="gu">@@ -131,7 +189,22 @@ class NumpyPickler(Pickler):</span>

<span class="w"> </span>    def _create_array_wrapper(self, array):
<span class="w"> </span>        &quot;&quot;&quot;Create and returns a numpy array wrapper from a numpy array.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.np is None:</span>
<span class="gi">+            return array</span>
<span class="gi">+</span>
<span class="gi">+        # Check if the array is a numpy array</span>
<span class="gi">+        if not isinstance(array, self.np.ndarray):</span>
<span class="gi">+            return array</span>
<span class="gi">+</span>
<span class="gi">+        # Create and return the wrapper</span>
<span class="gi">+        return NumpyArrayWrapper(</span>
<span class="gi">+            subclass=array.__class__,</span>
<span class="gi">+            shape=array.shape,</span>
<span class="gi">+            dtype=array.dtype,</span>
<span class="gi">+            order=&#39;F&#39; if array.flags.f_contiguous else &#39;C&#39;,</span>
<span class="gi">+            allow_mmap=not array.dtype.hasobject,</span>
<span class="gi">+            numpy_array_alignment_bytes=self.np.lib.format.ARRAY_ALIGN</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def save(self, obj):
<span class="w"> </span>        &quot;&quot;&quot;Subclass the Pickler `save` method.
<span class="gu">@@ -143,7 +216,14 @@ class NumpyPickler(Pickler):</span>
<span class="w"> </span>        after in the file. Warning: the file produced does not follow the
<span class="w"> </span>        pickle format. As such it can not be read with `pickle.load`.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.np is not None and isinstance(obj, self.np.ndarray):</span>
<span class="gi">+            # Replace the numpy array with our custom wrapper</span>
<span class="gi">+            wrapper = self._create_array_wrapper(obj)</span>
<span class="gi">+            Pickler.save(self, wrapper)</span>
<span class="gi">+            # Write the array data directly to the file</span>
<span class="gi">+            wrapper.write_array(obj, self)</span>
<span class="gi">+        else:</span>
<span class="gi">+            Pickler.save(self, obj)</span>


<span class="w"> </span>class NumpyUnpickler(Unpickler):
<span class="gu">@@ -185,7 +265,13 @@ class NumpyUnpickler(Unpickler):</span>
<span class="w"> </span>        replace them directly in the stack of pickler.
<span class="w"> </span>        NDArrayWrapper is used for backward compatibility with joblib &lt;= 0.9.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        stack = self.stack</span>
<span class="gi">+        if isinstance(stack[-1], (NDArrayWrapper, NumpyArrayWrapper)):</span>
<span class="gi">+            # Replace the wrapper object by the underlying array</span>
<span class="gi">+            array = stack[-1].read(self)</span>
<span class="gi">+            stack[-1] = array</span>
<span class="gi">+        else:</span>
<span class="gi">+            Unpickler.load_build(self)</span>
<span class="w"> </span>    dispatch[pickle.BUILD[0]] = load_build


<span class="gh">diff --git a/joblib/numpy_pickle_compat.py b/joblib/numpy_pickle_compat.py</span>
<span class="gh">index 4ccffb6..700e68d 100644</span>
<span class="gd">--- a/joblib/numpy_pickle_compat.py</span>
<span class="gi">+++ b/joblib/numpy_pickle_compat.py</span>
<span class="gu">@@ -11,7 +11,7 @@ from .numpy_pickle_utils import _ensure_native_byte_order</span>

<span class="w"> </span>def hex_str(an_int):
<span class="w"> </span>    &quot;&quot;&quot;Convert an int to an hexadecimal string.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return f&quot;{an_int:x}&quot;.zfill(_MAX_LEN)</span>


<span class="w"> </span>_MAX_LEN = len(hex_str(2 ** 64))
<span class="gu">@@ -25,7 +25,9 @@ def read_zfile(file_handle):</span>
<span class="w"> </span>    for persistence. Backward compatibility is not guaranteed. Do not
<span class="w"> </span>    use for external purposes.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    file_handle.seek(0)</span>
<span class="gi">+    assert file_handle.read(len(_ZFILE_PREFIX)) == _ZFILE_PREFIX</span>
<span class="gi">+    return zlib.decompress(file_handle.read())</span>


<span class="w"> </span>def write_zfile(file_handle, data, compress=1):
<span class="gu">@@ -35,7 +37,8 @@ def write_zfile(file_handle, data, compress=1):</span>
<span class="w"> </span>    for persistence. Backward compatibility is not guaranteed. Do not
<span class="w"> </span>    use for external purposes.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    file_handle.write(_ZFILE_PREFIX)</span>
<span class="gi">+    file_handle.write(zlib.compress(data, compress))</span>


<span class="w"> </span>class NDArrayWrapper(object):
<span class="gu">@@ -53,7 +56,17 @@ class NDArrayWrapper(object):</span>

<span class="w"> </span>    def read(self, unpickler):
<span class="w"> </span>        &quot;&quot;&quot;Reconstruct the array.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        import numpy as np</span>
<span class="gi">+        filename = os.path.join(unpickler._dirname, self.filename)</span>
<span class="gi">+        if self.allow_mmap and unpickler.mmap_mode is not None:</span>
<span class="gi">+            array = np.load(filename, mmap_mode=unpickler.mmap_mode)</span>
<span class="gi">+        else:</span>
<span class="gi">+            array = np.load(filename, allow_pickle=True)</span>
<span class="gi">+        if self.subclass is not np.ndarray:</span>
<span class="gi">+            # We need to reconstruct another subclass</span>
<span class="gi">+            return self.subclass(array.shape, array.dtype,</span>
<span class="gi">+                                 buffer=array, order=&#39;C&#39;)</span>
<span class="gi">+        return array</span>


<span class="w"> </span>class ZNDArrayWrapper(NDArrayWrapper):
<span class="gu">@@ -79,7 +92,24 @@ class ZNDArrayWrapper(NDArrayWrapper):</span>

<span class="w"> </span>    def read(self, unpickler):
<span class="w"> </span>        &quot;&quot;&quot;Reconstruct the array from the meta-information and the z-file.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        import numpy as np</span>
<span class="gi">+        filename = os.path.join(unpickler._dirname, self.filename)</span>
<span class="gi">+        with open(filename, &#39;rb&#39;) as f:</span>
<span class="gi">+            array = np.frombuffer(read_zfile(f),</span>
<span class="gi">+                                  dtype=self.init_args[&#39;dtype&#39;])</span>
<span class="gi">+        array = array.reshape(self.init_args[&#39;shape&#39;])</span>
<span class="gi">+        if self.init_args.get(&#39;order&#39;) == &#39;F&#39;:</span>
<span class="gi">+            array = array.T</span>
<span class="gi">+        if self.init_args[&#39;dtype&#39;].hasobject:</span>
<span class="gi">+            array = array.copy()</span>
<span class="gi">+        # Reconstruct subclasses</span>
<span class="gi">+        if self.init_args.get(&#39;cls&#39;) is not None:</span>
<span class="gi">+            new_array = self.init_args[&#39;cls&#39;].__new__(</span>
<span class="gi">+                self.init_args[&#39;cls&#39;], self.init_args[&#39;shape&#39;],</span>
<span class="gi">+                self.init_args[&#39;dtype&#39;], buffer=array)</span>
<span class="gi">+            array = new_array</span>
<span class="gi">+        array.__setstate__(self.state)</span>
<span class="gi">+        return array</span>


<span class="w"> </span>class ZipNumpyUnpickler(Unpickler):
<span class="gu">@@ -106,7 +136,32 @@ class ZipNumpyUnpickler(Unpickler):</span>
<span class="w"> </span>        NDArrayWrapper, by the array we are interested in. We
<span class="w"> </span>        replace them directly in the stack of pickler.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        stack = self.stack</span>
<span class="gi">+        state = stack.pop()</span>
<span class="gi">+        instance = stack[-1]</span>
<span class="gi">+        if isinstance(instance, NDArrayWrapper):</span>
<span class="gi">+            # Replace the NDArrayWrapper by the array itself</span>
<span class="gi">+            array = instance.read(self)</span>
<span class="gi">+            # If the array is part of a subclass, we need to preserve it</span>
<span class="gi">+            if (isinstance(array, self.np.ndarray) and</span>
<span class="gi">+                    not type(array) is self.np.ndarray):</span>
<span class="gi">+                self.stack[-1] = array</span>
<span class="gi">+            else:</span>
<span class="gi">+                self.stack[-1] = _ensure_native_byte_order(array)</span>
<span class="gi">+        else:</span>
<span class="gi">+            setstate = getattr(instance, &quot;__setstate__&quot;, None)</span>
<span class="gi">+            if setstate is not None:</span>
<span class="gi">+                setstate(state)</span>
<span class="gi">+            else:</span>
<span class="gi">+                try:</span>
<span class="gi">+                    (slotstate, state) = state</span>
<span class="gi">+                except:</span>
<span class="gi">+                    slotstate = None</span>
<span class="gi">+                if state:</span>
<span class="gi">+                    instance.__dict__.update(state)</span>
<span class="gi">+                if slotstate:</span>
<span class="gi">+                    for key, value in slotstate.items():</span>
<span class="gi">+                        setattr(instance, key, value)</span>
<span class="w"> </span>    dispatch[pickle.BUILD[0]] = load_build


<span class="gu">@@ -136,4 +191,14 @@ def load_compatibility(filename):</span>
<span class="w"> </span>    This function can load numpy array files saved separately during the
<span class="w"> </span>    dump.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    with open(filename, &#39;rb&#39;) as file_handle:</span>
<span class="gi">+        # We are careful to open the file handle early and keep it open to</span>
<span class="gi">+        # avoid race-conditions on renames.</span>
<span class="gi">+        # We use a try/finally block to ensure that file is closed even if</span>
<span class="gi">+        # we raise an exception</span>
<span class="gi">+        try:</span>
<span class="gi">+            unpickler = ZipNumpyUnpickler(filename, file_handle)</span>
<span class="gi">+            obj = unpickler.load()</span>
<span class="gi">+        finally:</span>
<span class="gi">+            file_handle.close()</span>
<span class="gi">+    return obj</span>
<span class="gh">diff --git a/joblib/numpy_pickle_utils.py b/joblib/numpy_pickle_utils.py</span>
<span class="gh">index e79528e..79b048f 100644</span>
<span class="gd">--- a/joblib/numpy_pickle_utils.py</span>
<span class="gi">+++ b/joblib/numpy_pickle_utils.py</span>
<span class="gu">@@ -22,12 +22,15 @@ _IO_BUFFER_SIZE = 1024 ** 2</span>

<span class="w"> </span>def _is_raw_file(fileobj):
<span class="w"> </span>    &quot;&quot;&quot;Check if fileobj is a raw file object, e.g created with open.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return isinstance(fileobj, (io.FileIO, io.BufferedReader, io.BufferedWriter))</span>


<span class="w"> </span>def _is_numpy_array_byte_order_mismatch(array):
<span class="w"> </span>    &quot;&quot;&quot;Check if numpy array is having byte order mismatch&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if np is None:</span>
<span class="gi">+        return False</span>
<span class="gi">+    return (array.dtype.byteorder == &#39;&gt;&#39; and sys.byteorder == &#39;little&#39;) or \</span>
<span class="gi">+           (array.dtype.byteorder == &#39;&lt;&#39; and sys.byteorder == &#39;big&#39;)</span>


<span class="w"> </span>def _ensure_native_byte_order(array):
<span class="gu">@@ -35,7 +38,9 @@ def _ensure_native_byte_order(array):</span>

<span class="w"> </span>    Does nothing if array already uses the system byte order.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if _is_numpy_array_byte_order_mismatch(array):</span>
<span class="gi">+        return array.byteswap().newbyteorder()</span>
<span class="gi">+    return array</span>


<span class="w"> </span>def _detect_compressor(fileobj):
<span class="gu">@@ -49,17 +54,40 @@ def _detect_compressor(fileobj):</span>
<span class="w"> </span>    -------
<span class="w"> </span>    str in {&#39;zlib&#39;, &#39;gzip&#39;, &#39;bz2&#39;, &#39;lzma&#39;, &#39;xz&#39;, &#39;compat&#39;, &#39;not-compressed&#39;}
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not hasattr(fileobj, &#39;read&#39;):</span>
<span class="gi">+        raise ValueError(&quot;Expected file-like object, got %s&quot; % type(fileobj))</span>
<span class="gi">+</span>
<span class="gi">+    magic = fileobj.read(4)</span>
<span class="gi">+    fileobj.seek(0)</span>
<span class="gi">+</span>
<span class="gi">+    if magic.startswith(_ZFILE_PREFIX):</span>
<span class="gi">+        return &#39;zlib&#39;</span>
<span class="gi">+    elif magic.startswith(b&#39;\x1f\x8b&#39;):</span>
<span class="gi">+        return &#39;gzip&#39;</span>
<span class="gi">+    elif magic.startswith(b&#39;BZh&#39;):</span>
<span class="gi">+        return &#39;bz2&#39;</span>
<span class="gi">+    elif magic.startswith(b&#39;\x28\xb5\x2f\xfd&#39;):</span>
<span class="gi">+        return &#39;zstd&#39;</span>
<span class="gi">+    elif magic.startswith(b&#39;\xfd7zXZ\x00&#39;):</span>
<span class="gi">+        return &#39;xz&#39;</span>
<span class="gi">+    elif magic.startswith(b&#39;\x89LZO&#39;):</span>
<span class="gi">+        return &#39;lzo&#39;</span>
<span class="gi">+    else:</span>
<span class="gi">+        return &#39;not-compressed&#39;</span>


<span class="w"> </span>def _buffered_read_file(fobj):
<span class="w"> </span>    &quot;&quot;&quot;Return a buffered version of a read file object.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(fobj, io.BufferedReader):</span>
<span class="gi">+        return fobj</span>
<span class="gi">+    return io.BufferedReader(fobj, buffer_size=_IO_BUFFER_SIZE)</span>


<span class="w"> </span>def _buffered_write_file(fobj):
<span class="w"> </span>    &quot;&quot;&quot;Return a buffered version of a write file object.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(fobj, io.BufferedWriter):</span>
<span class="gi">+        return fobj</span>
<span class="gi">+    return io.BufferedWriter(fobj, buffer_size=_IO_BUFFER_SIZE)</span>


<span class="w"> </span>@contextlib.contextmanager
<span class="gu">@@ -90,12 +118,39 @@ def _read_fileobject(fileobj, filename, mmap_mode=None):</span>
<span class="w"> </span>        a file like object

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    compressor = _detect_compressor(fileobj)</span>
<span class="gi">+    </span>
<span class="gi">+    if compressor == &#39;not-compressed&#39;:</span>
<span class="gi">+        if mmap_mode is not None:</span>
<span class="gi">+            fileobj = np.load(filename, mmap_mode=mmap_mode)</span>
<span class="gi">+        else:</span>
<span class="gi">+            fileobj = _buffered_read_file(fileobj)</span>
<span class="gi">+    elif compressor in _COMPRESSORS:</span>
<span class="gi">+        if mmap_mode is not None:</span>
<span class="gi">+            warnings.warn(&#39;File &quot;%(filename)s&quot; is compressed using %(compressor)s. &#39;</span>
<span class="gi">+                          &#39;Memory mapping mode &quot;%(mmap_mode)s&quot; is not supported.&#39;</span>
<span class="gi">+                          % locals())</span>
<span class="gi">+        fileobj = _COMPRESSORS[compressor][&#39;file_open&#39;](fileobj, mode=&#39;rb&#39;)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(&quot;Unrecognized file type: %s&quot; % compressor)</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        yield fileobj</span>
<span class="gi">+    finally:</span>
<span class="gi">+        fileobj.close()</span>


<span class="w"> </span>def _write_fileobject(filename, compress=(&#39;zlib&#39;, 3)):
<span class="w"> </span>    &quot;&quot;&quot;Return the right compressor file object in write mode.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if compress is None or compress == &#39;not-compressed&#39;:</span>
<span class="gi">+        return _buffered_write_file(open(filename, &#39;wb&#39;))</span>
<span class="gi">+    </span>
<span class="gi">+    compressor, compress_level = compress</span>
<span class="gi">+    if compressor not in _COMPRESSORS:</span>
<span class="gi">+        raise ValueError(&quot;Unrecognized compressor: %s&quot; % compressor)</span>
<span class="gi">+    </span>
<span class="gi">+    return _COMPRESSORS[compressor][&#39;file_open&#39;](filename, &#39;wb&#39;, </span>
<span class="gi">+                                                 compresslevel=compress_level)</span>


<span class="w"> </span>BUFFER_SIZE = 2 ** 18
<span class="gu">@@ -127,4 +182,10 @@ def _read_bytes(fp, size, error_template=&#39;ran out of data&#39;):</span>
<span class="w"> </span>        The data read in bytes.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    data = bytes()</span>
<span class="gi">+    while len(data) &lt; size:</span>
<span class="gi">+        chunk = fp.read(size - len(data))</span>
<span class="gi">+        if not chunk:</span>
<span class="gi">+            raise ValueError(error_template)</span>
<span class="gi">+        data += chunk</span>
<span class="gi">+    return data</span>
<span class="gh">diff --git a/joblib/parallel.py b/joblib/parallel.py</span>
<span class="gh">index f141ee0..d7d863b 100644</span>
<span class="gd">--- a/joblib/parallel.py</span>
<span class="gi">+++ b/joblib/parallel.py</span>
<span class="gu">@@ -904,7 +904,20 @@ class Parallel(Logger):</span>

<span class="w"> </span>    def _initialize_backend(self):
<span class="w"> </span>        &quot;&quot;&quot;Build a process or thread pool and return the number of workers&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        try:</span>
<span class="gi">+            n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self, **self._backend_args)</span>
<span class="gi">+            if self.timeout is not None and not self._backend.supports_timeout:</span>
<span class="gi">+                warnings.warn(</span>
<span class="gi">+                    &#39;The backend class {!r} does not support timeout. &#39;</span>
<span class="gi">+                    &quot;You have set &#39;timeout={}&#39; in Parallel but &quot;</span>
<span class="gi">+                    &quot;the &#39;timeout&#39; parameter will not be used.&quot;.format(</span>
<span class="gi">+                        self._backend.__class__.__name__,</span>
<span class="gi">+                        self.timeout))</span>
<span class="gi">+</span>
<span class="gi">+            return n_jobs</span>
<span class="gi">+        except FallbackToBackend as e:</span>
<span class="gi">+            self._backend = e.backend</span>
<span class="gi">+            return self._initialize_backend()</span>

<span class="w"> </span>    def _dispatch(self, batch):
<span class="w"> </span>        &quot;&quot;&quot;Queue the batch for computing, with or without multiprocessing
<span class="gu">@@ -913,7 +926,15 @@ class Parallel(Logger):</span>
<span class="w"> </span>        indirectly via dispatch_one_batch.

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.timeout is not None:</span>
<span class="gi">+            batch = BatchCompletionCallBack(self._backend, batch, self.timeout)</span>
<span class="gi">+</span>
<span class="gi">+        dispatch_timestamp = time.time()</span>
<span class="gi">+        cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)</span>
<span class="gi">+        with self._lock:</span>
<span class="gi">+            job_id = self._backend.apply_async(batch, callback=cb)</span>
<span class="gi">+            cb.register_job(job_id)</span>
<span class="gi">+            self._jobs.append(job_id)</span>

<span class="w"> </span>    def dispatch_next(self):
<span class="w"> </span>        &quot;&quot;&quot;Dispatch more data for parallel processing
<span class="gu">@@ -923,7 +944,15 @@ class Parallel(Logger):</span>
<span class="w"> </span>        against concurrent consumption of the unprotected iterator.

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.dispatch_one_batch(self._original_iterator):</span>
<span class="gi">+            return True</span>
<span class="gi">+        elif self._original_iterator is not None:</span>
<span class="gi">+            self._iterating = False</span>
<span class="gi">+            self._original_iterator = None</span>
<span class="gi">+            with self._lock:</span>
<span class="gi">+                if not self.return_generator:</span>
<span class="gi">+                    self._ready_batches.put(None)</span>
<span class="gi">+        return False</span>

<span class="w"> </span>    def dispatch_one_batch(self, iterator):
<span class="w"> </span>        &quot;&quot;&quot;Prefetch the tasks for the next batch and dispatch them.
<span class="gu">@@ -935,41 +964,121 @@ class Parallel(Logger):</span>
<span class="w"> </span>        lock so calling this function should be thread safe.

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if iterator is None:</span>
<span class="gi">+            return False</span>
<span class="gi">+</span>
<span class="gi">+        with self._lock:</span>
<span class="gi">+            batch_size = self._get_batch_size()</span>
<span class="gi">+            tasks = []</span>
<span class="gi">+            for _ in range(batch_size):</span>
<span class="gi">+                try:</span>
<span class="gi">+                    tasks.append(next(iterator))</span>
<span class="gi">+                except StopIteration:</span>
<span class="gi">+                    break</span>
<span class="gi">+</span>
<span class="gi">+            if len(tasks) == 0:</span>
<span class="gi">+                return False</span>
<span class="gi">+</span>
<span class="gi">+            self._dispatch(tasks)</span>
<span class="gi">+            return True</span>

<span class="w"> </span>    def _get_batch_size(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns the effective batch size for dispatch&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.batch_size == &#39;auto&#39;:</span>
<span class="gi">+            if self._cached_effective_n_jobs == 1:</span>
<span class="gi">+                return 1</span>
<span class="gi">+            elif self._backend.supports_threading:</span>
<span class="gi">+                return 1</span>
<span class="gi">+            else:</span>
<span class="gi">+                return 2 * self._cached_effective_n_jobs</span>
<span class="gi">+        else:</span>
<span class="gi">+            return self.batch_size</span>

<span class="w"> </span>    def _print(self, msg):
<span class="w"> </span>        &quot;&quot;&quot;Display the message on stout or stderr depending on verbosity&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.verbose &gt; 10:</span>
<span class="gi">+            print(msg)</span>
<span class="gi">+        elif self.verbose &gt; 0:</span>
<span class="gi">+            print(msg, end=&#39;\r&#39;, file=sys.stderr)</span>

<span class="w"> </span>    def _is_completed(self):
<span class="w"> </span>        &quot;&quot;&quot;Check if all tasks have been completed&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._ready_batches.qsize() == 0 and len(self._jobs) == 0</span>

<span class="w"> </span>    def print_progress(self):
<span class="w"> </span>        &quot;&quot;&quot;Display the process of the parallel execution only a fraction
<span class="w"> </span>           of time, controlled by self.verbose.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if not self.verbose:</span>
<span class="gi">+            return</span>
<span class="gi">+        elapsed_time = time.time() - self._start_time</span>
<span class="gi">+</span>
<span class="gi">+        # This is heuristic code to print only &#39;verbose&#39; times a messages</span>
<span class="gi">+        # The challenge is that we may not know the queue length</span>
<span class="gi">+        if self._original_iterator:</span>
<span class="gi">+            if _verbosity_filter(self._completed_tasks, self.verbose):</span>
<span class="gi">+                return</span>
<span class="gi">+            self._print(&#39;Done %3i tasks      | elapsed: %s&#39; %</span>
<span class="gi">+                        (self._completed_tasks,</span>
<span class="gi">+                         short_format_time(elapsed_time)))</span>
<span class="gi">+        else:</span>
<span class="gi">+            index = self._completed_tasks</span>
<span class="gi">+            if _verbosity_filter(index, self.verbose):</span>
<span class="gi">+                return</span>
<span class="gi">+            self._print(&#39;[%s]: Done %3i out of %3i | elapsed: %s&#39; % (</span>
<span class="gi">+                self, index, len(self._jobs),</span>
<span class="gi">+                short_format_time(elapsed_time)))</span>

<span class="w"> </span>    def _get_outputs(self, iterator, pre_dispatch):
<span class="w"> </span>        &quot;&quot;&quot;Iterator returning the tasks&#39; output as soon as they are ready.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._start_time = time.time()</span>
<span class="gi">+        self._iterating = True</span>
<span class="gi">+        self._completed_tasks = 0</span>
<span class="gi">+</span>
<span class="gi">+        while self._iterating or len(self._jobs) &gt; 0:</span>
<span class="gi">+            if self._iterating:</span>
<span class="gi">+                self.dispatch_one_batch(iterator)</span>
<span class="gi">+</span>
<span class="gi">+            if len(self._jobs) == 0:</span>
<span class="gi">+                continue</span>
<span class="gi">+</span>
<span class="gi">+            try:</span>
<span class="gi">+                batch = self._ready_batches.get(timeout=0.1)</span>
<span class="gi">+            except queue.Empty:</span>
<span class="gi">+                self.print_progress()</span>
<span class="gi">+                continue</span>
<span class="gi">+</span>
<span class="gi">+            if batch is None:</span>
<span class="gi">+                self._iterating = False</span>
<span class="gi">+            else:</span>
<span class="gi">+                yield from batch</span>
<span class="gi">+                self._completed_tasks += len(batch)</span>
<span class="gi">+                self.print_progress()</span>
<span class="gi">+</span>
<span class="gi">+            self._raise_error_fast()</span>
<span class="gi">+</span>
<span class="gi">+        if self._aborting:</span>
<span class="gi">+            self._terminate_and_reset()</span>
<span class="gi">+            raise self._exception</span>
<span class="gi">+</span>
<span class="gi">+        self._terminate_and_reset()</span>

<span class="w"> </span>    def _wait_retrieval(self):
<span class="w"> </span>        &quot;&quot;&quot;Return True if we need to continue retrieving some tasks.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return (self._iterating or len(self._jobs) &gt; 0 or</span>
<span class="gi">+                self._ready_batches.qsize() &gt; 0)</span>

<span class="w"> </span>    def _raise_error_fast(self):
<span class="w"> </span>        &quot;&quot;&quot;If we are aborting, raise if a job caused an error.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self._aborting:</span>
<span class="gi">+            raise self._exception</span>

<span class="w"> </span>    def _warn_exit_early(self):
<span class="gd">-        &quot;&quot;&quot;Warn the user if the generator is gc&#39;ed before being consumned.&quot;&quot;&quot;</span>
<span class="gd">-        pass</span>
<span class="gi">+        &quot;&quot;&quot;Warn the user if the generator is gc&#39;ed before being consumed.&quot;&quot;&quot;</span>
<span class="gi">+        if self._iterating:</span>
<span class="gi">+            warnings.warn(&quot;Parallel generator was garbage collected before &quot;</span>
<span class="gi">+                          &quot;being fully consumed. Some jobs may have not been &quot;</span>
<span class="gi">+                          &quot;run.&quot;, UserWarning)</span>

<span class="w"> </span>    def _get_sequential_output(self, iterable):
<span class="w"> </span>        &quot;&quot;&quot;Separate loop for sequential output.
<span class="gu">@@ -977,11 +1086,29 @@ class Parallel(Logger):</span>
<span class="w"> </span>        This simplifies the traceback in case of errors and reduces the
<span class="w"> </span>        overhead of calling sequential tasks with `joblib`.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._start_time = time.time()</span>
<span class="gi">+        output = []</span>
<span class="gi">+        try:</span>
<span class="gi">+            for i, func_args_kwargs in enumerate(iterable):</span>
<span class="gi">+                if self.pre_dispatch == &quot;all&quot; or i &lt; self.pre_dispatch:</span>
<span class="gi">+                    output.append(func_args_kwargs)</span>
<span class="gi">+                else:</span>
<span class="gi">+                    yield func_args_kwargs</span>
<span class="gi">+                self._completed_tasks += 1</span>
<span class="gi">+                if self.timeout is not None and time.time() - self._start_time &gt; self.timeout:</span>
<span class="gi">+                    raise TimeoutError()</span>
<span class="gi">+        except BaseException as e:</span>
<span class="gi">+            self._exception = e</span>
<span class="gi">+            self._aborting = True</span>
<span class="gi">+        finally:</span>
<span class="gi">+            yield from output</span>

<span class="w"> </span>    def _reset_run_tracking(self):
<span class="w"> </span>        &quot;&quot;&quot;Reset the counters and flags used to track the execution.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._aborting = False</span>
<span class="gi">+        self._exception = None</span>
<span class="gi">+        self._iterating = False</span>
<span class="gi">+        self._completed_tasks = 0</span>

<span class="w"> </span>    def __call__(self, iterable):
<span class="w"> </span>        &quot;&quot;&quot;Main function to dispatch parallel tasks.&quot;&quot;&quot;
<span class="gh">diff --git a/joblib/pool.py b/joblib/pool.py</span>
<span class="gh">index a5c2643..71628a3 100644</span>
<span class="gd">--- a/joblib/pool.py</span>
<span class="gi">+++ b/joblib/pool.py</span>
<span class="gu">@@ -61,7 +61,10 @@ class CustomizablePickler(Pickler):</span>

<span class="w"> </span>    def register(self, type, reduce_func):
<span class="w"> </span>        &quot;&quot;&quot;Attach a reducer function to a given type in the dispatch table.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if hasattr(self, &#39;dispatch&#39;):</span>
<span class="gi">+            self.dispatch[type] = reduce_func</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.dispatch_table[type] = reduce_func</span>


<span class="w"> </span>class CustomizablePicklingQueue(object):
<span class="gu">@@ -101,6 +104,46 @@ class CustomizablePicklingQueue(object):</span>
<span class="w"> </span>            ) = state
<span class="w"> </span>        self._make_methods()

<span class="gi">+    def _make_methods(self):</span>
<span class="gi">+        self.put = self._make_put()</span>
<span class="gi">+        self.get = self._make_get()</span>
<span class="gi">+        self.empty = self._make_empty()</span>
<span class="gi">+</span>
<span class="gi">+    def _make_put(self):</span>
<span class="gi">+        def put(obj):</span>
<span class="gi">+            buffer = BytesIO()</span>
<span class="gi">+            CustomizablePickler(buffer, self._reducers).dump(obj)</span>
<span class="gi">+            self._writer.send_bytes(buffer.getvalue())</span>
<span class="gi">+        if self._wlock is None:</span>
<span class="gi">+            return put</span>
<span class="gi">+        else:</span>
<span class="gi">+            def locked_put(obj):</span>
<span class="gi">+                with self._wlock:</span>
<span class="gi">+                    return put(obj)</span>
<span class="gi">+            return locked_put</span>
<span class="gi">+</span>
<span class="gi">+    def _make_get(self):</span>
<span class="gi">+        def get():</span>
<span class="gi">+            return CustomizablePickler.loads(self._reader.recv_bytes())</span>
<span class="gi">+        if self._rlock is None:</span>
<span class="gi">+            return get</span>
<span class="gi">+        else:</span>
<span class="gi">+            def locked_get():</span>
<span class="gi">+                with self._rlock:</span>
<span class="gi">+                    return get()</span>
<span class="gi">+            return locked_get</span>
<span class="gi">+</span>
<span class="gi">+    def _make_empty(self):</span>
<span class="gi">+        def empty():</span>
<span class="gi">+            return not self._reader.poll()</span>
<span class="gi">+        if self._rlock is None:</span>
<span class="gi">+            return empty</span>
<span class="gi">+        else:</span>
<span class="gi">+            def locked_empty():</span>
<span class="gi">+                with self._rlock:</span>
<span class="gi">+                    return empty()</span>
<span class="gi">+            return locked_empty</span>
<span class="gi">+</span>

<span class="w"> </span>class PicklingPool(Pool):
<span class="w"> </span>    &quot;&quot;&quot;Pool implementation with customizable pickling reducers.
<span class="gh">diff --git a/joblib/testing.py b/joblib/testing.py</span>
<span class="gh">index e20431c..af4e267 100644</span>
<span class="gd">--- a/joblib/testing.py</span>
<span class="gi">+++ b/joblib/testing.py</span>
<span class="gu">@@ -23,11 +23,15 @@ param = pytest.param</span>
<span class="w"> </span>def warnings_to_stdout():
<span class="w"> </span>    &quot;&quot;&quot; Redirect all warnings to stdout.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    def custom_formatwarning(message, category, filename, lineno, line=None):</span>
<span class="gi">+        return f&quot;{filename}:{lineno}: {category.__name__}: {message}\n&quot;</span>
<span class="gi">+    </span>
<span class="gi">+    warnings.formatwarning = custom_formatwarning</span>
<span class="gi">+    warnings.simplefilter(&quot;always&quot;)</span>
<span class="gi">+    warnings.showwarning = lambda *args, **kwargs: sys.stdout.write(warnings.formatwarning(*args, **kwargs))</span>


<span class="gd">-def check_subprocess_call(cmd, timeout=5, stdout_regex=None, stderr_regex=None</span>
<span class="gd">-    ):</span>
<span class="gi">+def check_subprocess_call(cmd, timeout=5, stdout_regex=None, stderr_regex=None):</span>
<span class="w"> </span>    &quot;&quot;&quot;Runs a command in a subprocess with timeout in seconds.

<span class="w"> </span>    A SIGTERM is sent after `timeout` and if it does not terminate, a
<span class="gu">@@ -36,4 +40,27 @@ def check_subprocess_call(cmd, timeout=5, stdout_regex=None, stderr_regex=None</span>
<span class="w"> </span>    Also checks returncode is zero, stdout if stdout_regex is set, and
<span class="w"> </span>    stderr if stderr_regex is set.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)</span>
<span class="gi">+    </span>
<span class="gi">+    try:</span>
<span class="gi">+        stdout, stderr = process.communicate(timeout=timeout)</span>
<span class="gi">+    except subprocess.TimeoutExpired:</span>
<span class="gi">+        process.terminate()</span>
<span class="gi">+        try:</span>
<span class="gi">+            stdout, stderr = process.communicate(timeout=timeout)</span>
<span class="gi">+        except subprocess.TimeoutExpired:</span>
<span class="gi">+            process.kill()</span>
<span class="gi">+            stdout, stderr = process.communicate()</span>
<span class="gi">+    </span>
<span class="gi">+    returncode = process.returncode</span>
<span class="gi">+    </span>
<span class="gi">+    if returncode != 0:</span>
<span class="gi">+        raise subprocess.CalledProcessError(returncode, cmd, stdout, stderr)</span>
<span class="gi">+    </span>
<span class="gi">+    if stdout_regex and not re.search(stdout_regex, stdout):</span>
<span class="gi">+        raise AssertionError(f&quot;Stdout did not match regex: {stdout_regex}\nStdout: {stdout}&quot;)</span>
<span class="gi">+    </span>
<span class="gi">+    if stderr_regex and not re.search(stderr_regex, stderr):</span>
<span class="gi">+        raise AssertionError(f&quot;Stderr did not match regex: {stderr_regex}\nStderr: {stderr}&quot;)</span>
<span class="gi">+    </span>
<span class="gi">+    return stdout, stderr</span>
</code></pre></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.d6f25eb3.min.js"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../javascripts/tablesort.js"></script>
      
        <script src="../javascripts/tablesort.number.js"></script>
      
    
  </body>
</html>