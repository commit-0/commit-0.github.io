
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.37">
    
    
      
        <title>Analysis commit0 all reference filesystem spec - Commit-0</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.8c3ca2c6.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#reference-gold-filesystem_spec" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Commit-0" class="md-header__button md-logo" aria-label="Commit-0" data-md-component="logo">
      
  <img src="../logo2.webp" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Commit-0
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Analysis commit0 all reference filesystem spec
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Commit-0" class="md-nav__button md-logo" aria-label="Commit-0" data-md-component="logo">
      
  <img src="../logo2.webp" alt="logo">

    </a>
    Commit-0
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../setupdist/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Commit0
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Agent
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Leaderboard
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pytest-summary-for-test-tests" class="md-nav__link">
    <span class="md-ellipsis">
      Pytest Summary for test tests
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#failed-pytests" class="md-nav__link">
    <span class="md-ellipsis">
      Failed pytests:
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Failed pytests:">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#test_apipytest_multilevel_chained_fs" class="md-nav__link">
    <span class="md-ellipsis">
      test_api.py::test_multilevel_chained_fs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_specpytest_find" class="md-nav__link">
    <span class="md-ellipsis">
      test_spec.py::test_find
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#patch-diff" class="md-nav__link">
    <span class="md-ellipsis">
      Patch diff
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<p><a href="/analysis_commit0_all_reference">back to Reference (Gold) summary</a></p>
<h1 id="reference-gold-filesystem_spec"><strong>Reference (Gold)</strong>: filesystem_spec</h1>
<h2 id="pytest-summary-for-test-tests">Pytest Summary for test <code>tests</code></h2>
<table>
<thead>
<tr>
<th style="text-align: left;">status</th>
<th style="text-align: center;">count</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">passed</td>
<td style="text-align: center;">698</td>
</tr>
<tr>
<td style="text-align: left;">xfailed</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: left;">skipped</td>
<td style="text-align: center;">92</td>
</tr>
<tr>
<td style="text-align: left;">total</td>
<td style="text-align: center;">792</td>
</tr>
<tr>
<td style="text-align: left;">collected</td>
<td style="text-align: center;">792</td>
</tr>
</tbody>
</table>
<h2 id="failed-pytests">Failed pytests:</h2>
<h3 id="test_apipytest_multilevel_chained_fs">test_api.py::test_multilevel_chained_fs</h3>
<details><summary> <pre>test_api.py::test_multilevel_chained_fs</pre></summary><pre>
@pytest.mark.xfail(reason="see issue #334", strict=True)
    def test_multilevel_chained_fs():
        """This test reproduces fsspec/filesystem_spec#334"""
        import zipfile

        d1 = tempfile.mkdtemp()
        f1 = os.path.join(d1, "f1.zip")
        with zipfile.ZipFile(f1, mode="w") as z:
            # filename, content
            z.writestr("foo.txt", "foo.txt")
            z.writestr("bar.txt", "bar.txt")

        # We expected this to be the correct syntax
>       with pytest.raises(IsADirectoryError):
E       Failed: DID NOT RAISE <class 'IsADirectoryError'>

fsspec/tests/test_api.py:252: Failed
</pre>
</details>
<h3 id="test_specpytest_find">test_spec.py::test_find</h3>
<details><summary> <pre>test_spec.py::test_find</pre></summary><pre>
@pytest.mark.xfail
    def test_find():
        """Test .find() method on debian server (ftp, https) with constant folder"""
        filesystem, host, test_path = (
            FTPFileSystem,
            "ftp.fau.de",
            "ftp://ftp.fau.de/debian-cd/current/amd64/log/success",
        )
        test_fs = filesystem(host)
        filenames_ftp = test_fs.find(test_path)
>       assert filenames_ftp
E       assert []

fsspec/tests/test_spec.py:699: AssertionError
</pre>
</details>

<h2 id="patch-diff">Patch diff</h2>
<div class="highlight"><pre><span></span><code><span class="gh">diff --git a/fsspec/archive.py b/fsspec/archive.py</span>
<span class="gh">index 1a4570f..f466780 100644</span>
<span class="gd">--- a/fsspec/archive.py</span>
<span class="gi">+++ b/fsspec/archive.py</span>
<span class="gu">@@ -13,9 +13,13 @@ class AbstractArchiveFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>    &quot;&quot;&quot;

<span class="w"> </span>    def __str__(self):
<span class="gd">-        return f&#39;&lt;Archive-like object {type(self).__name__} at {id(self)}&gt;&#39;</span>
<span class="gi">+        return f&quot;&lt;Archive-like object {type(self).__name__} at {id(self)}&gt;&quot;</span>
<span class="gi">+</span>
<span class="w"> </span>    __repr__ = __str__

<span class="gi">+    def ukey(self, path):</span>
<span class="gi">+        return tokenize(path, self.fo, self.protocol)</span>
<span class="gi">+</span>
<span class="w"> </span>    def _all_dirnames(self, paths):
<span class="w"> </span>        &quot;&quot;&quot;Returns *all* directory names for each path in paths, including intermediate
<span class="w"> </span>        ones.
<span class="gu">@@ -24,4 +28,46 @@ class AbstractArchiveFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        ----------
<span class="w"> </span>        paths: Iterable of path strings
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if len(paths) == 0:</span>
<span class="gi">+            return set()</span>
<span class="gi">+</span>
<span class="gi">+        dirnames = {self._parent(path) for path in paths} - {self.root_marker}</span>
<span class="gi">+        return dirnames | self._all_dirnames(dirnames)</span>
<span class="gi">+</span>
<span class="gi">+    def info(self, path, **kwargs):</span>
<span class="gi">+        self._get_dirs()</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if path in {&quot;&quot;, &quot;/&quot;} and self.dir_cache:</span>
<span class="gi">+            return {&quot;name&quot;: &quot;&quot;, &quot;type&quot;: &quot;directory&quot;, &quot;size&quot;: 0}</span>
<span class="gi">+        if path in self.dir_cache:</span>
<span class="gi">+            return self.dir_cache[path]</span>
<span class="gi">+        elif path + &quot;/&quot; in self.dir_cache:</span>
<span class="gi">+            return self.dir_cache[path + &quot;/&quot;]</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise FileNotFoundError(path)</span>
<span class="gi">+</span>
<span class="gi">+    def ls(self, path, detail=True, **kwargs):</span>
<span class="gi">+        self._get_dirs()</span>
<span class="gi">+        paths = {}</span>
<span class="gi">+        for p, f in self.dir_cache.items():</span>
<span class="gi">+            p = p.rstrip(&quot;/&quot;)</span>
<span class="gi">+            if &quot;/&quot; in p:</span>
<span class="gi">+                root = p.rsplit(&quot;/&quot;, 1)[0]</span>
<span class="gi">+            else:</span>
<span class="gi">+                root = &quot;&quot;</span>
<span class="gi">+            if root == path.rstrip(&quot;/&quot;):</span>
<span class="gi">+                paths[p] = f</span>
<span class="gi">+            elif all(</span>
<span class="gi">+                (a == b)</span>
<span class="gi">+                for a, b in zip(path.split(&quot;/&quot;), [&quot;&quot;] + p.strip(&quot;/&quot;).split(&quot;/&quot;))</span>
<span class="gi">+            ):</span>
<span class="gi">+                # root directory entry</span>
<span class="gi">+                ppath = p.rstrip(&quot;/&quot;).split(&quot;/&quot;, 1)[0]</span>
<span class="gi">+                if ppath not in paths:</span>
<span class="gi">+                    out = {&quot;name&quot;: ppath, &quot;size&quot;: 0, &quot;type&quot;: &quot;directory&quot;}</span>
<span class="gi">+                    paths[ppath] = out</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            out = sorted(paths.values(), key=lambda _: _[&quot;name&quot;])</span>
<span class="gi">+            return out</span>
<span class="gi">+        else:</span>
<span class="gi">+            return sorted(paths)</span>
<span class="gh">diff --git a/fsspec/asyn.py b/fsspec/asyn.py</span>
<span class="gh">index 551290c..a040efc 100644</span>
<span class="gd">--- a/fsspec/asyn.py</span>
<span class="gi">+++ b/fsspec/asyn.py</span>
<span class="gu">@@ -10,15 +10,17 @@ import threading</span>
<span class="w"> </span>from contextlib import contextmanager
<span class="w"> </span>from glob import has_magic
<span class="w"> </span>from typing import TYPE_CHECKING, Iterable
<span class="gi">+</span>
<span class="w"> </span>from .callbacks import DEFAULT_CALLBACK
<span class="w"> </span>from .exceptions import FSTimeoutError
<span class="w"> </span>from .implementations.local import LocalFileSystem, make_path_posix, trailing_sep
<span class="w"> </span>from .spec import AbstractBufferedFile, AbstractFileSystem
<span class="w"> </span>from .utils import glob_translate, is_exception, other_paths
<span class="gd">-private = re.compile(&#39;_[^_]&#39;)</span>
<span class="gd">-iothread = [None]</span>
<span class="gd">-loop = [None]</span>
<span class="gd">-_lock = None</span>
<span class="gi">+</span>
<span class="gi">+private = re.compile(&quot;_[^_]&quot;)</span>
<span class="gi">+iothread = [None]  # dedicated fsspec IO thread</span>
<span class="gi">+loop = [None]  # global event loop for any non-async instance</span>
<span class="gi">+_lock = None  # global lock placeholder</span>
<span class="w"> </span>get_running_loop = asyncio.get_running_loop


<span class="gu">@@ -27,7 +29,10 @@ def get_lock():</span>

<span class="w"> </span>    The lock is allocated on first use to allow setting one lock per forked process.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    global _lock</span>
<span class="gi">+    if not _lock:</span>
<span class="gi">+        _lock = threading.Lock()</span>
<span class="gi">+    return _lock</span>


<span class="w"> </span>def reset_lock():
<span class="gu">@@ -36,7 +41,23 @@ def reset_lock():</span>
<span class="w"> </span>    This should be called only on the init of a forked process to reset the lock to
<span class="w"> </span>    None, enabling the new forked process to get a new lock.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    global _lock</span>
<span class="gi">+</span>
<span class="gi">+    iothread[0] = None</span>
<span class="gi">+    loop[0] = None</span>
<span class="gi">+    _lock = None</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+async def _runner(event, coro, result, timeout=None):</span>
<span class="gi">+    timeout = timeout if timeout else None  # convert 0 or 0.0 to None</span>
<span class="gi">+    if timeout is not None:</span>
<span class="gi">+        coro = asyncio.wait_for(coro, timeout=timeout)</span>
<span class="gi">+    try:</span>
<span class="gi">+        result[0] = await coro</span>
<span class="gi">+    except Exception as ex:</span>
<span class="gi">+        result[0] = ex</span>
<span class="gi">+    finally:</span>
<span class="gi">+        event.set()</span>


<span class="w"> </span>def sync(loop, func, *args, timeout=None, **kwargs):
<span class="gu">@@ -48,7 +69,40 @@ def sync(loop, func, *args, timeout=None, **kwargs):</span>
<span class="w"> </span>    &gt;&gt;&gt; fsspec.asyn.sync(fsspec.asyn.get_loop(), func, *args,
<span class="w"> </span>                         timeout=timeout, **kwargs)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    timeout = timeout if timeout else None  # convert 0 or 0.0 to None</span>
<span class="gi">+    # NB: if the loop is not running *yet*, it is OK to submit work</span>
<span class="gi">+    # and we will wait for it</span>
<span class="gi">+    if loop is None or loop.is_closed():</span>
<span class="gi">+        raise RuntimeError(&quot;Loop is not running&quot;)</span>
<span class="gi">+    try:</span>
<span class="gi">+        loop0 = asyncio.events.get_running_loop()</span>
<span class="gi">+        if loop0 is loop:</span>
<span class="gi">+            raise NotImplementedError(&quot;Calling sync() from within a running loop&quot;)</span>
<span class="gi">+    except NotImplementedError:</span>
<span class="gi">+        raise</span>
<span class="gi">+    except RuntimeError:</span>
<span class="gi">+        pass</span>
<span class="gi">+    coro = func(*args, **kwargs)</span>
<span class="gi">+    result = [None]</span>
<span class="gi">+    event = threading.Event()</span>
<span class="gi">+    asyncio.run_coroutine_threadsafe(_runner(event, coro, result, timeout), loop)</span>
<span class="gi">+    while True:</span>
<span class="gi">+        # this loops allows thread to get interrupted</span>
<span class="gi">+        if event.wait(1):</span>
<span class="gi">+            break</span>
<span class="gi">+        if timeout is not None:</span>
<span class="gi">+            timeout -= 1</span>
<span class="gi">+            if timeout &lt; 0:</span>
<span class="gi">+                raise FSTimeoutError</span>
<span class="gi">+</span>
<span class="gi">+    return_result = result[0]</span>
<span class="gi">+    if isinstance(return_result, asyncio.TimeoutError):</span>
<span class="gi">+        # suppress asyncio.TimeoutError, raise FSTimeoutError</span>
<span class="gi">+        raise FSTimeoutError from return_result</span>
<span class="gi">+    elif isinstance(return_result, BaseException):</span>
<span class="gi">+        raise return_result</span>
<span class="gi">+    else:</span>
<span class="gi">+        return return_result</span>


<span class="w"> </span>def sync_wrapper(func, obj=None):
<span class="gu">@@ -57,7 +111,25 @@ def sync_wrapper(func, obj=None):</span>
<span class="w"> </span>    Leave obj=None if defining within a class. Pass the instance if attaching
<span class="w"> </span>    as an attribute of the instance.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    @functools.wraps(func)</span>
<span class="gi">+    def wrapper(*args, **kwargs):</span>
<span class="gi">+        self = obj or args[0]</span>
<span class="gi">+        return sync(self.loop, func, *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    return wrapper</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@contextmanager</span>
<span class="gi">+def _selector_policy():</span>
<span class="gi">+    original_policy = asyncio.get_event_loop_policy()</span>
<span class="gi">+    try:</span>
<span class="gi">+        if os.name == &quot;nt&quot; and hasattr(asyncio, &quot;WindowsSelectorEventLoopPolicy&quot;):</span>
<span class="gi">+            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())</span>
<span class="gi">+</span>
<span class="gi">+        yield</span>
<span class="gi">+    finally:</span>
<span class="gi">+        asyncio.set_event_loop_policy(original_policy)</span>


<span class="w"> </span>def get_loop():
<span class="gu">@@ -65,11 +137,23 @@ def get_loop():</span>

<span class="w"> </span>    The loop will be running on a separate thread.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if loop[0] is None:</span>
<span class="gi">+        with get_lock():</span>
<span class="gi">+            # repeat the check just in case the loop got filled between the</span>
<span class="gi">+            # previous two calls from another thread</span>
<span class="gi">+            if loop[0] is None:</span>
<span class="gi">+                with _selector_policy():</span>
<span class="gi">+                    loop[0] = asyncio.new_event_loop()</span>
<span class="gi">+                th = threading.Thread(target=loop[0].run_forever, name=&quot;fsspecIO&quot;)</span>
<span class="gi">+                th.daemon = True</span>
<span class="gi">+                th.start()</span>
<span class="gi">+                iothread[0] = th</span>
<span class="gi">+    return loop[0]</span>


<span class="w"> </span>if TYPE_CHECKING:
<span class="w"> </span>    import resource
<span class="gi">+</span>
<span class="w"> </span>    ResourceError = resource.error
<span class="w"> </span>else:
<span class="w"> </span>    try:
<span class="gu">@@ -78,18 +162,54 @@ else:</span>
<span class="w"> </span>        resource = None
<span class="w"> </span>        ResourceError = OSError
<span class="w"> </span>    else:
<span class="gd">-        ResourceError = getattr(resource, &#39;error&#39;, OSError)</span>
<span class="gi">+        ResourceError = getattr(resource, &quot;error&quot;, OSError)</span>
<span class="gi">+</span>
<span class="w"> </span>_DEFAULT_BATCH_SIZE = 128
<span class="w"> </span>_NOFILES_DEFAULT_BATCH_SIZE = 1280


<span class="gd">-def running_async() -&gt;bool:</span>
<span class="gi">+def _get_batch_size(nofiles=False):</span>
<span class="gi">+    from fsspec.config import conf</span>
<span class="gi">+</span>
<span class="gi">+    if nofiles:</span>
<span class="gi">+        if &quot;nofiles_gather_batch_size&quot; in conf:</span>
<span class="gi">+            return conf[&quot;nofiles_gather_batch_size&quot;]</span>
<span class="gi">+    else:</span>
<span class="gi">+        if &quot;gather_batch_size&quot; in conf:</span>
<span class="gi">+            return conf[&quot;gather_batch_size&quot;]</span>
<span class="gi">+    if nofiles:</span>
<span class="gi">+        return _NOFILES_DEFAULT_BATCH_SIZE</span>
<span class="gi">+    if resource is None:</span>
<span class="gi">+        return _DEFAULT_BATCH_SIZE</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        soft_limit, _ = resource.getrlimit(resource.RLIMIT_NOFILE)</span>
<span class="gi">+    except (ImportError, ValueError, ResourceError):</span>
<span class="gi">+        return _DEFAULT_BATCH_SIZE</span>
<span class="gi">+</span>
<span class="gi">+    if soft_limit == resource.RLIM_INFINITY:</span>
<span class="gi">+        return -1</span>
<span class="gi">+    else:</span>
<span class="gi">+        return soft_limit // 8</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def running_async() -&gt; bool:</span>
<span class="w"> </span>    &quot;&quot;&quot;Being executed by an event loop?&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        asyncio.get_running_loop()</span>
<span class="gi">+        return True</span>
<span class="gi">+    except RuntimeError:</span>
<span class="gi">+        return False</span>


<span class="gd">-async def _run_coros_in_chunks(coros, batch_size=None, callback=</span>
<span class="gd">-    DEFAULT_CALLBACK, timeout=None, return_exceptions=False, nofiles=False):</span>
<span class="gi">+async def _run_coros_in_chunks(</span>
<span class="gi">+    coros,</span>
<span class="gi">+    batch_size=None,</span>
<span class="gi">+    callback=DEFAULT_CALLBACK,</span>
<span class="gi">+    timeout=None,</span>
<span class="gi">+    return_exceptions=False,</span>
<span class="gi">+    nofiles=False,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;Run the given coroutines in  chunks.

<span class="w"> </span>    Parameters
<span class="gu">@@ -111,13 +231,68 @@ async def _run_coros_in_chunks(coros, batch_size=None, callback=</span>
<span class="w"> </span>        If inferring the batch_size, does this operation involve local files?
<span class="w"> </span>        If yes, you normally expect smaller batches.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>

<span class="gi">+    if batch_size is None:</span>
<span class="gi">+        batch_size = _get_batch_size(nofiles=nofiles)</span>

<span class="gd">-async_methods = [&#39;_ls&#39;, &#39;_cat_file&#39;, &#39;_get_file&#39;, &#39;_put_file&#39;, &#39;_rm_file&#39;,</span>
<span class="gd">-    &#39;_cp_file&#39;, &#39;_pipe_file&#39;, &#39;_expand_path&#39;, &#39;_info&#39;, &#39;_isfile&#39;, &#39;_isdir&#39;,</span>
<span class="gd">-    &#39;_exists&#39;, &#39;_walk&#39;, &#39;_glob&#39;, &#39;_find&#39;, &#39;_du&#39;, &#39;_size&#39;, &#39;_mkdir&#39;, &#39;_makedirs&#39;</span>
<span class="gd">-    ]</span>
<span class="gi">+    if batch_size == -1:</span>
<span class="gi">+        batch_size = len(coros)</span>
<span class="gi">+</span>
<span class="gi">+    assert batch_size &gt; 0</span>
<span class="gi">+</span>
<span class="gi">+    async def _run_coro(coro, i):</span>
<span class="gi">+        try:</span>
<span class="gi">+            return await asyncio.wait_for(coro, timeout=timeout), i</span>
<span class="gi">+        except Exception as e:</span>
<span class="gi">+            if not return_exceptions:</span>
<span class="gi">+                raise</span>
<span class="gi">+            return e, i</span>
<span class="gi">+        finally:</span>
<span class="gi">+            callback.relative_update(1)</span>
<span class="gi">+</span>
<span class="gi">+    i = 0</span>
<span class="gi">+    n = len(coros)</span>
<span class="gi">+    results = [None] * n</span>
<span class="gi">+    pending = set()</span>
<span class="gi">+</span>
<span class="gi">+    while pending or i &lt; n:</span>
<span class="gi">+        while len(pending) &lt; batch_size and i &lt; n:</span>
<span class="gi">+            pending.add(asyncio.ensure_future(_run_coro(coros[i], i)))</span>
<span class="gi">+            i += 1</span>
<span class="gi">+</span>
<span class="gi">+        if not pending:</span>
<span class="gi">+            break</span>
<span class="gi">+</span>
<span class="gi">+        done, pending = await asyncio.wait(pending, return_when=asyncio.FIRST_COMPLETED)</span>
<span class="gi">+        while done:</span>
<span class="gi">+            result, k = await done.pop()</span>
<span class="gi">+            results[k] = result</span>
<span class="gi">+</span>
<span class="gi">+    return results</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# these methods should be implemented as async by any async-able backend</span>
<span class="gi">+async_methods = [</span>
<span class="gi">+    &quot;_ls&quot;,</span>
<span class="gi">+    &quot;_cat_file&quot;,</span>
<span class="gi">+    &quot;_get_file&quot;,</span>
<span class="gi">+    &quot;_put_file&quot;,</span>
<span class="gi">+    &quot;_rm_file&quot;,</span>
<span class="gi">+    &quot;_cp_file&quot;,</span>
<span class="gi">+    &quot;_pipe_file&quot;,</span>
<span class="gi">+    &quot;_expand_path&quot;,</span>
<span class="gi">+    &quot;_info&quot;,</span>
<span class="gi">+    &quot;_isfile&quot;,</span>
<span class="gi">+    &quot;_isdir&quot;,</span>
<span class="gi">+    &quot;_exists&quot;,</span>
<span class="gi">+    &quot;_walk&quot;,</span>
<span class="gi">+    &quot;_glob&quot;,</span>
<span class="gi">+    &quot;_find&quot;,</span>
<span class="gi">+    &quot;_du&quot;,</span>
<span class="gi">+    &quot;_size&quot;,</span>
<span class="gi">+    &quot;_mkdir&quot;,</span>
<span class="gi">+    &quot;_makedirs&quot;,</span>
<span class="gi">+]</span>


<span class="w"> </span>class AsyncFileSystem(AbstractFileSystem):
<span class="gu">@@ -129,12 +304,15 @@ class AsyncFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>    should inherit from this class instead of AbstractFileSystem. Docstrings are
<span class="w"> </span>    copied from the un-underscored method in AbstractFileSystem, if not given.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gi">+</span>
<span class="gi">+    # note that methods do not have docstring here; they will be copied</span>
<span class="gi">+    # for _* methods and inferred for overridden methods.</span>
<span class="gi">+</span>
<span class="w"> </span>    async_impl = True
<span class="w"> </span>    mirror_sync_methods = True
<span class="w"> </span>    disable_throttling = False

<span class="gd">-    def __init__(self, *args, asynchronous=False, loop=None, batch_size=</span>
<span class="gd">-        None, **kwargs):</span>
<span class="gi">+    def __init__(self, *args, asynchronous=False, loop=None, batch_size=None, **kwargs):</span>
<span class="w"> </span>        self.asynchronous = asynchronous
<span class="w"> </span>        self._pid = os.getpid()
<span class="w"> </span>        if not asynchronous:
<span class="gu">@@ -144,12 +322,166 @@ class AsyncFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        self.batch_size = batch_size
<span class="w"> </span>        super().__init__(*args, **kwargs)

<span class="gi">+    @property</span>
<span class="gi">+    def loop(self):</span>
<span class="gi">+        if self._pid != os.getpid():</span>
<span class="gi">+            raise RuntimeError(&quot;This class is not fork-safe&quot;)</span>
<span class="gi">+        return self._loop</span>
<span class="gi">+</span>
<span class="gi">+    async def _rm_file(self, path, **kwargs):</span>
<span class="gi">+        raise NotImplementedError</span>
<span class="gi">+</span>
<span class="gi">+    async def _rm(self, path, recursive=False, batch_size=None, **kwargs):</span>
<span class="gi">+        # TODO: implement on_error</span>
<span class="gi">+        batch_size = batch_size or self.batch_size</span>
<span class="gi">+        path = await self._expand_path(path, recursive=recursive)</span>
<span class="gi">+        return await _run_coros_in_chunks(</span>
<span class="gi">+            [self._rm_file(p, **kwargs) for p in reversed(path)],</span>
<span class="gi">+            batch_size=batch_size,</span>
<span class="gi">+            nofiles=True,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    async def _cp_file(self, path1, path2, **kwargs):</span>
<span class="gi">+        raise NotImplementedError</span>
<span class="gi">+</span>
<span class="gi">+    async def _copy(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path1,</span>
<span class="gi">+        path2,</span>
<span class="gi">+        recursive=False,</span>
<span class="gi">+        on_error=None,</span>
<span class="gi">+        maxdepth=None,</span>
<span class="gi">+        batch_size=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        if on_error is None and recursive:</span>
<span class="gi">+            on_error = &quot;ignore&quot;</span>
<span class="gi">+        elif on_error is None:</span>
<span class="gi">+            on_error = &quot;raise&quot;</span>
<span class="gi">+</span>
<span class="gi">+        if isinstance(path1, list) and isinstance(path2, list):</span>
<span class="gi">+            # No need to expand paths when both source and destination</span>
<span class="gi">+            # are provided as lists</span>
<span class="gi">+            paths1 = path1</span>
<span class="gi">+            paths2 = path2</span>
<span class="gi">+        else:</span>
<span class="gi">+            source_is_str = isinstance(path1, str)</span>
<span class="gi">+            paths1 = await self._expand_path(</span>
<span class="gi">+                path1, maxdepth=maxdepth, recursive=recursive</span>
<span class="gi">+            )</span>
<span class="gi">+            if source_is_str and (not recursive or maxdepth is not None):</span>
<span class="gi">+                # Non-recursive glob does not copy directories</span>
<span class="gi">+                paths1 = [</span>
<span class="gi">+                    p for p in paths1 if not (trailing_sep(p) or await self._isdir(p))</span>
<span class="gi">+                ]</span>
<span class="gi">+                if not paths1:</span>
<span class="gi">+                    return</span>
<span class="gi">+</span>
<span class="gi">+            source_is_file = len(paths1) == 1</span>
<span class="gi">+            dest_is_dir = isinstance(path2, str) and (</span>
<span class="gi">+                trailing_sep(path2) or await self._isdir(path2)</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            exists = source_is_str and (</span>
<span class="gi">+                (has_magic(path1) and source_is_file)</span>
<span class="gi">+                or (not has_magic(path1) and dest_is_dir and not trailing_sep(path1))</span>
<span class="gi">+            )</span>
<span class="gi">+            paths2 = other_paths(</span>
<span class="gi">+                paths1,</span>
<span class="gi">+                path2,</span>
<span class="gi">+                exists=exists,</span>
<span class="gi">+                flatten=not source_is_str,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        batch_size = batch_size or self.batch_size</span>
<span class="gi">+        coros = [self._cp_file(p1, p2, **kwargs) for p1, p2 in zip(paths1, paths2)]</span>
<span class="gi">+        result = await _run_coros_in_chunks(</span>
<span class="gi">+            coros, batch_size=batch_size, return_exceptions=True, nofiles=True</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        for ex in filter(is_exception, result):</span>
<span class="gi">+            if on_error == &quot;ignore&quot; and isinstance(ex, FileNotFoundError):</span>
<span class="gi">+                continue</span>
<span class="gi">+            raise ex</span>
<span class="gi">+</span>
<span class="gi">+    async def _pipe_file(self, path, value, **kwargs):</span>
<span class="gi">+        raise NotImplementedError</span>
<span class="gi">+</span>
<span class="gi">+    async def _pipe(self, path, value=None, batch_size=None, **kwargs):</span>
<span class="gi">+        if isinstance(path, str):</span>
<span class="gi">+            path = {path: value}</span>
<span class="gi">+        batch_size = batch_size or self.batch_size</span>
<span class="gi">+        return await _run_coros_in_chunks(</span>
<span class="gi">+            [self._pipe_file(k, v, **kwargs) for k, v in path.items()],</span>
<span class="gi">+            batch_size=batch_size,</span>
<span class="gi">+            nofiles=True,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="w"> </span>    async def _process_limits(self, url, start, end):
<span class="w"> </span>        &quot;&quot;&quot;Helper for &quot;Range&quot;-based _cat_file&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        size = None</span>
<span class="gi">+        suff = False</span>
<span class="gi">+        if start is not None and start &lt; 0:</span>
<span class="gi">+            # if start is negative and end None, end is the &quot;suffix length&quot;</span>
<span class="gi">+            if end is None:</span>
<span class="gi">+                end = -start</span>
<span class="gi">+                start = &quot;&quot;</span>
<span class="gi">+                suff = True</span>
<span class="gi">+            else:</span>
<span class="gi">+                size = size or (await self._info(url))[&quot;size&quot;]</span>
<span class="gi">+                start = size + start</span>
<span class="gi">+        elif start is None:</span>
<span class="gi">+            start = 0</span>
<span class="gi">+        if not suff:</span>
<span class="gi">+            if end is not None and end &lt; 0:</span>
<span class="gi">+                if start is not None:</span>
<span class="gi">+                    size = size or (await self._info(url))[&quot;size&quot;]</span>
<span class="gi">+                    end = size + end</span>
<span class="gi">+            elif end is None:</span>
<span class="gi">+                end = &quot;&quot;</span>
<span class="gi">+            if isinstance(end, numbers.Integral):</span>
<span class="gi">+                end -= 1  # bytes range is inclusive</span>
<span class="gi">+        return f&quot;bytes={start}-{end}&quot;</span>
<span class="gi">+</span>
<span class="gi">+    async def _cat_file(self, path, start=None, end=None, **kwargs):</span>
<span class="gi">+        raise NotImplementedError</span>
<span class="gi">+</span>
<span class="gi">+    async def _cat(</span>
<span class="gi">+        self, path, recursive=False, on_error=&quot;raise&quot;, batch_size=None, **kwargs</span>
<span class="gi">+    ):</span>
<span class="gi">+        paths = await self._expand_path(path, recursive=recursive)</span>
<span class="gi">+        coros = [self._cat_file(path, **kwargs) for path in paths]</span>
<span class="gi">+        batch_size = batch_size or self.batch_size</span>
<span class="gi">+        out = await _run_coros_in_chunks(</span>
<span class="gi">+            coros, batch_size=batch_size, nofiles=True, return_exceptions=True</span>
<span class="gi">+        )</span>
<span class="gi">+        if on_error == &quot;raise&quot;:</span>
<span class="gi">+            ex = next(filter(is_exception, out), False)</span>
<span class="gi">+            if ex:</span>
<span class="gi">+                raise ex</span>
<span class="gi">+        if (</span>
<span class="gi">+            len(paths) &gt; 1</span>
<span class="gi">+            or isinstance(path, list)</span>
<span class="gi">+            or paths[0] != self._strip_protocol(path)</span>
<span class="gi">+        ):</span>
<span class="gi">+            return {</span>
<span class="gi">+                k: v</span>
<span class="gi">+                for k, v in zip(paths, out)</span>
<span class="gi">+                if on_error != &quot;omit&quot; or not is_exception(v)</span>
<span class="gi">+            }</span>
<span class="gi">+        else:</span>
<span class="gi">+            return out[0]</span>

<span class="gd">-    async def _cat_ranges(self, paths, starts, ends, max_gap=None,</span>
<span class="gd">-        batch_size=None, on_error=&#39;return&#39;, **kwargs):</span>
<span class="gi">+    async def _cat_ranges(</span>
<span class="gi">+        self,</span>
<span class="gi">+        paths,</span>
<span class="gi">+        starts,</span>
<span class="gi">+        ends,</span>
<span class="gi">+        max_gap=None,</span>
<span class="gi">+        batch_size=None,</span>
<span class="gi">+        on_error=&quot;return&quot;,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Get the contents of byte ranges from one or more files

<span class="w"> </span>        Parameters
<span class="gu">@@ -160,10 +492,40 @@ class AsyncFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>            Bytes limits of the read. If using a single int, the same value will be
<span class="w"> </span>            used to read all the specified files.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # TODO: on_error</span>
<span class="gi">+        if max_gap is not None:</span>
<span class="gi">+            # use utils.merge_offset_ranges</span>
<span class="gi">+            raise NotImplementedError</span>
<span class="gi">+        if not isinstance(paths, list):</span>
<span class="gi">+            raise TypeError</span>
<span class="gi">+        if not isinstance(starts, Iterable):</span>
<span class="gi">+            starts = [starts] * len(paths)</span>
<span class="gi">+        if not isinstance(ends, Iterable):</span>
<span class="gi">+            ends = [ends] * len(paths)</span>
<span class="gi">+        if len(starts) != len(paths) or len(ends) != len(paths):</span>
<span class="gi">+            raise ValueError</span>
<span class="gi">+        coros = [</span>
<span class="gi">+            self._cat_file(p, start=s, end=e, **kwargs)</span>
<span class="gi">+            for p, s, e in zip(paths, starts, ends)</span>
<span class="gi">+        ]</span>
<span class="gi">+        batch_size = batch_size or self.batch_size</span>
<span class="gi">+        return await _run_coros_in_chunks(</span>
<span class="gi">+            coros, batch_size=batch_size, nofiles=True, return_exceptions=True</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    async def _put_file(self, lpath, rpath, **kwargs):</span>
<span class="gi">+        raise NotImplementedError</span>

<span class="gd">-    async def _put(self, lpath, rpath, recursive=False, callback=</span>
<span class="gd">-        DEFAULT_CALLBACK, batch_size=None, maxdepth=None, **kwargs):</span>
<span class="gi">+    async def _put(</span>
<span class="gi">+        self,</span>
<span class="gi">+        lpath,</span>
<span class="gi">+        rpath,</span>
<span class="gi">+        recursive=False,</span>
<span class="gi">+        callback=DEFAULT_CALLBACK,</span>
<span class="gi">+        batch_size=None,</span>
<span class="gi">+        maxdepth=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Copy file(s) from local.

<span class="w"> </span>        Copies a specific file or tree of files (if recursive=True). If rpath
<span class="gu">@@ -177,10 +539,69 @@ class AsyncFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        constructor, or for all instances by setting the &quot;gather_batch_size&quot; key
<span class="w"> </span>        in ``fsspec.config.conf``, falling back to 1/8th of the system limit .
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(lpath, list) and isinstance(rpath, list):</span>
<span class="gi">+            # No need to expand paths when both source and destination</span>
<span class="gi">+            # are provided as lists</span>
<span class="gi">+            rpaths = rpath</span>
<span class="gi">+            lpaths = lpath</span>
<span class="gi">+        else:</span>
<span class="gi">+            source_is_str = isinstance(lpath, str)</span>
<span class="gi">+            if source_is_str:</span>
<span class="gi">+                lpath = make_path_posix(lpath)</span>
<span class="gi">+            fs = LocalFileSystem()</span>
<span class="gi">+            lpaths = fs.expand_path(lpath, recursive=recursive, maxdepth=maxdepth)</span>
<span class="gi">+            if source_is_str and (not recursive or maxdepth is not None):</span>
<span class="gi">+                # Non-recursive glob does not copy directories</span>
<span class="gi">+                lpaths = [p for p in lpaths if not (trailing_sep(p) or fs.isdir(p))]</span>
<span class="gi">+                if not lpaths:</span>
<span class="gi">+                    return</span>
<span class="gi">+</span>
<span class="gi">+            source_is_file = len(lpaths) == 1</span>
<span class="gi">+            dest_is_dir = isinstance(rpath, str) and (</span>
<span class="gi">+                trailing_sep(rpath) or await self._isdir(rpath)</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            rpath = self._strip_protocol(rpath)</span>
<span class="gi">+            exists = source_is_str and (</span>
<span class="gi">+                (has_magic(lpath) and source_is_file)</span>
<span class="gi">+                or (not has_magic(lpath) and dest_is_dir and not trailing_sep(lpath))</span>
<span class="gi">+            )</span>
<span class="gi">+            rpaths = other_paths(</span>
<span class="gi">+                lpaths,</span>
<span class="gi">+                rpath,</span>
<span class="gi">+                exists=exists,</span>
<span class="gi">+                flatten=not source_is_str,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        is_dir = {l: os.path.isdir(l) for l in lpaths}</span>
<span class="gi">+        rdirs = [r for l, r in zip(lpaths, rpaths) if is_dir[l]]</span>
<span class="gi">+        file_pairs = [(l, r) for l, r in zip(lpaths, rpaths) if not is_dir[l]]</span>
<span class="gi">+</span>
<span class="gi">+        await asyncio.gather(*[self._makedirs(d, exist_ok=True) for d in rdirs])</span>
<span class="gi">+        batch_size = batch_size or self.batch_size</span>

<span class="gd">-    async def _get(self, rpath, lpath, recursive=False, callback=</span>
<span class="gd">-        DEFAULT_CALLBACK, maxdepth=None, **kwargs):</span>
<span class="gi">+        coros = []</span>
<span class="gi">+        callback.set_size(len(file_pairs))</span>
<span class="gi">+        for lfile, rfile in file_pairs:</span>
<span class="gi">+            put_file = callback.branch_coro(self._put_file)</span>
<span class="gi">+            coros.append(put_file(lfile, rfile, **kwargs))</span>
<span class="gi">+</span>
<span class="gi">+        return await _run_coros_in_chunks(</span>
<span class="gi">+            coros, batch_size=batch_size, callback=callback</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    async def _get_file(self, rpath, lpath, **kwargs):</span>
<span class="gi">+        raise NotImplementedError</span>
<span class="gi">+</span>
<span class="gi">+    async def _get(</span>
<span class="gi">+        self,</span>
<span class="gi">+        rpath,</span>
<span class="gi">+        lpath,</span>
<span class="gi">+        recursive=False,</span>
<span class="gi">+        callback=DEFAULT_CALLBACK,</span>
<span class="gi">+        maxdepth=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Copy file(s) to local.

<span class="w"> </span>        Copies a specific file or tree of files (if recursive=True). If lpath
<span class="gu">@@ -195,7 +616,298 @@ class AsyncFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        constructor, or for all instances by setting the &quot;gather_batch_size&quot; key
<span class="w"> </span>        in ``fsspec.config.conf``, falling back to 1/8th of the system limit .
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(lpath, list) and isinstance(rpath, list):</span>
<span class="gi">+            # No need to expand paths when both source and destination</span>
<span class="gi">+            # are provided as lists</span>
<span class="gi">+            rpaths = rpath</span>
<span class="gi">+            lpaths = lpath</span>
<span class="gi">+        else:</span>
<span class="gi">+            source_is_str = isinstance(rpath, str)</span>
<span class="gi">+            # First check for rpath trailing slash as _strip_protocol removes it.</span>
<span class="gi">+            source_not_trailing_sep = source_is_str and not trailing_sep(rpath)</span>
<span class="gi">+            rpath = self._strip_protocol(rpath)</span>
<span class="gi">+            rpaths = await self._expand_path(</span>
<span class="gi">+                rpath, recursive=recursive, maxdepth=maxdepth</span>
<span class="gi">+            )</span>
<span class="gi">+            if source_is_str and (not recursive or maxdepth is not None):</span>
<span class="gi">+                # Non-recursive glob does not copy directories</span>
<span class="gi">+                rpaths = [</span>
<span class="gi">+                    p for p in rpaths if not (trailing_sep(p) or await self._isdir(p))</span>
<span class="gi">+                ]</span>
<span class="gi">+                if not rpaths:</span>
<span class="gi">+                    return</span>
<span class="gi">+</span>
<span class="gi">+            lpath = make_path_posix(lpath)</span>
<span class="gi">+            source_is_file = len(rpaths) == 1</span>
<span class="gi">+            dest_is_dir = isinstance(lpath, str) and (</span>
<span class="gi">+                trailing_sep(lpath) or LocalFileSystem().isdir(lpath)</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            exists = source_is_str and (</span>
<span class="gi">+                (has_magic(rpath) and source_is_file)</span>
<span class="gi">+                or (not has_magic(rpath) and dest_is_dir and source_not_trailing_sep)</span>
<span class="gi">+            )</span>
<span class="gi">+            lpaths = other_paths(</span>
<span class="gi">+                rpaths,</span>
<span class="gi">+                lpath,</span>
<span class="gi">+                exists=exists,</span>
<span class="gi">+                flatten=not source_is_str,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        [os.makedirs(os.path.dirname(lp), exist_ok=True) for lp in lpaths]</span>
<span class="gi">+        batch_size = kwargs.pop(&quot;batch_size&quot;, self.batch_size)</span>
<span class="gi">+</span>
<span class="gi">+        coros = []</span>
<span class="gi">+        callback.set_size(len(lpaths))</span>
<span class="gi">+        for lpath, rpath in zip(lpaths, rpaths):</span>
<span class="gi">+            get_file = callback.branch_coro(self._get_file)</span>
<span class="gi">+            coros.append(get_file(rpath, lpath, **kwargs))</span>
<span class="gi">+        return await _run_coros_in_chunks(</span>
<span class="gi">+            coros, batch_size=batch_size, callback=callback</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    async def _isfile(self, path):</span>
<span class="gi">+        try:</span>
<span class="gi">+            return (await self._info(path))[&quot;type&quot;] == &quot;file&quot;</span>
<span class="gi">+        except:  # noqa: E722</span>
<span class="gi">+            return False</span>
<span class="gi">+</span>
<span class="gi">+    async def _isdir(self, path):</span>
<span class="gi">+        try:</span>
<span class="gi">+            return (await self._info(path))[&quot;type&quot;] == &quot;directory&quot;</span>
<span class="gi">+        except OSError:</span>
<span class="gi">+            return False</span>
<span class="gi">+</span>
<span class="gi">+    async def _size(self, path):</span>
<span class="gi">+        return (await self._info(path)).get(&quot;size&quot;, None)</span>
<span class="gi">+</span>
<span class="gi">+    async def _sizes(self, paths, batch_size=None):</span>
<span class="gi">+        batch_size = batch_size or self.batch_size</span>
<span class="gi">+        return await _run_coros_in_chunks(</span>
<span class="gi">+            [self._size(p) for p in paths], batch_size=batch_size</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    async def _exists(self, path, **kwargs):</span>
<span class="gi">+        try:</span>
<span class="gi">+            await self._info(path, **kwargs)</span>
<span class="gi">+            return True</span>
<span class="gi">+        except FileNotFoundError:</span>
<span class="gi">+            return False</span>
<span class="gi">+</span>
<span class="gi">+    async def _info(self, path, **kwargs):</span>
<span class="gi">+        raise NotImplementedError</span>
<span class="gi">+</span>
<span class="gi">+    async def _ls(self, path, detail=True, **kwargs):</span>
<span class="gi">+        raise NotImplementedError</span>
<span class="gi">+</span>
<span class="gi">+    async def _walk(self, path, maxdepth=None, on_error=&quot;omit&quot;, **kwargs):</span>
<span class="gi">+        if maxdepth is not None and maxdepth &lt; 1:</span>
<span class="gi">+            raise ValueError(&quot;maxdepth must be at least 1&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        full_dirs = {}</span>
<span class="gi">+        dirs = {}</span>
<span class="gi">+        files = {}</span>
<span class="gi">+</span>
<span class="gi">+        detail = kwargs.pop(&quot;detail&quot;, False)</span>
<span class="gi">+        try:</span>
<span class="gi">+            listing = await self._ls(path, detail=True, **kwargs)</span>
<span class="gi">+        except (FileNotFoundError, OSError) as e:</span>
<span class="gi">+            if on_error == &quot;raise&quot;:</span>
<span class="gi">+                raise</span>
<span class="gi">+            elif callable(on_error):</span>
<span class="gi">+                on_error(e)</span>
<span class="gi">+            if detail:</span>
<span class="gi">+                yield path, {}, {}</span>
<span class="gi">+            else:</span>
<span class="gi">+                yield path, [], []</span>
<span class="gi">+            return</span>
<span class="gi">+</span>
<span class="gi">+        for info in listing:</span>
<span class="gi">+            # each info name must be at least [path]/part , but here</span>
<span class="gi">+            # we check also for names like [path]/part/</span>
<span class="gi">+            pathname = info[&quot;name&quot;].rstrip(&quot;/&quot;)</span>
<span class="gi">+            name = pathname.rsplit(&quot;/&quot;, 1)[-1]</span>
<span class="gi">+            if info[&quot;type&quot;] == &quot;directory&quot; and pathname != path:</span>
<span class="gi">+                # do not include &quot;self&quot; path</span>
<span class="gi">+                full_dirs[name] = pathname</span>
<span class="gi">+                dirs[name] = info</span>
<span class="gi">+            elif pathname == path:</span>
<span class="gi">+                # file-like with same name as give path</span>
<span class="gi">+                files[&quot;&quot;] = info</span>
<span class="gi">+            else:</span>
<span class="gi">+                files[name] = info</span>
<span class="gi">+</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            yield path, dirs, files</span>
<span class="gi">+        else:</span>
<span class="gi">+            yield path, list(dirs), list(files)</span>
<span class="gi">+</span>
<span class="gi">+        if maxdepth is not None:</span>
<span class="gi">+            maxdepth -= 1</span>
<span class="gi">+            if maxdepth &lt; 1:</span>
<span class="gi">+                return</span>
<span class="gi">+</span>
<span class="gi">+        for d in dirs:</span>
<span class="gi">+            async for _ in self._walk(</span>
<span class="gi">+                full_dirs[d], maxdepth=maxdepth, detail=detail, **kwargs</span>
<span class="gi">+            ):</span>
<span class="gi">+                yield _</span>
<span class="gi">+</span>
<span class="gi">+    async def _glob(self, path, maxdepth=None, **kwargs):</span>
<span class="gi">+        if maxdepth is not None and maxdepth &lt; 1:</span>
<span class="gi">+            raise ValueError(&quot;maxdepth must be at least 1&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        import re</span>
<span class="gi">+</span>
<span class="gi">+        seps = (os.path.sep, os.path.altsep) if os.path.altsep else (os.path.sep,)</span>
<span class="gi">+        ends_with_sep = path.endswith(seps)  # _strip_protocol strips trailing slash</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        append_slash_to_dirname = ends_with_sep or path.endswith(</span>
<span class="gi">+            tuple(sep + &quot;**&quot; for sep in seps)</span>
<span class="gi">+        )</span>
<span class="gi">+        idx_star = path.find(&quot;*&quot;) if path.find(&quot;*&quot;) &gt;= 0 else len(path)</span>
<span class="gi">+        idx_qmark = path.find(&quot;?&quot;) if path.find(&quot;?&quot;) &gt;= 0 else len(path)</span>
<span class="gi">+        idx_brace = path.find(&quot;[&quot;) if path.find(&quot;[&quot;) &gt;= 0 else len(path)</span>
<span class="gi">+</span>
<span class="gi">+        min_idx = min(idx_star, idx_qmark, idx_brace)</span>
<span class="gi">+</span>
<span class="gi">+        detail = kwargs.pop(&quot;detail&quot;, False)</span>
<span class="gi">+</span>
<span class="gi">+        if not has_magic(path):</span>
<span class="gi">+            if await self._exists(path, **kwargs):</span>
<span class="gi">+                if not detail:</span>
<span class="gi">+                    return [path]</span>
<span class="gi">+                else:</span>
<span class="gi">+                    return {path: await self._info(path, **kwargs)}</span>
<span class="gi">+            else:</span>
<span class="gi">+                if not detail:</span>
<span class="gi">+                    return []  # glob of non-existent returns empty</span>
<span class="gi">+                else:</span>
<span class="gi">+                    return {}</span>
<span class="gi">+        elif &quot;/&quot; in path[:min_idx]:</span>
<span class="gi">+            min_idx = path[:min_idx].rindex(&quot;/&quot;)</span>
<span class="gi">+            root = path[: min_idx + 1]</span>
<span class="gi">+            depth = path[min_idx + 1 :].count(&quot;/&quot;) + 1</span>
<span class="gi">+        else:</span>
<span class="gi">+            root = &quot;&quot;</span>
<span class="gi">+            depth = path[min_idx + 1 :].count(&quot;/&quot;) + 1</span>
<span class="gi">+</span>
<span class="gi">+        if &quot;**&quot; in path:</span>
<span class="gi">+            if maxdepth is not None:</span>
<span class="gi">+                idx_double_stars = path.find(&quot;**&quot;)</span>
<span class="gi">+                depth_double_stars = path[idx_double_stars:].count(&quot;/&quot;) + 1</span>
<span class="gi">+                depth = depth - depth_double_stars + maxdepth</span>
<span class="gi">+            else:</span>
<span class="gi">+                depth = None</span>
<span class="gi">+</span>
<span class="gi">+        allpaths = await self._find(</span>
<span class="gi">+            root, maxdepth=depth, withdirs=True, detail=True, **kwargs</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        pattern = glob_translate(path + (&quot;/&quot; if ends_with_sep else &quot;&quot;))</span>
<span class="gi">+        pattern = re.compile(pattern)</span>
<span class="gi">+</span>
<span class="gi">+        out = {</span>
<span class="gi">+            p: info</span>
<span class="gi">+            for p, info in sorted(allpaths.items())</span>
<span class="gi">+            if pattern.match(</span>
<span class="gi">+                (</span>
<span class="gi">+                    p + &quot;/&quot;</span>
<span class="gi">+                    if append_slash_to_dirname and info[&quot;type&quot;] == &quot;directory&quot;</span>
<span class="gi">+                    else p</span>
<span class="gi">+                )</span>
<span class="gi">+            )</span>
<span class="gi">+        }</span>
<span class="gi">+</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return out</span>
<span class="gi">+        else:</span>
<span class="gi">+            return list(out)</span>
<span class="gi">+</span>
<span class="gi">+    async def _du(self, path, total=True, maxdepth=None, **kwargs):</span>
<span class="gi">+        sizes = {}</span>
<span class="gi">+        # async for?</span>
<span class="gi">+        for f in await self._find(path, maxdepth=maxdepth, **kwargs):</span>
<span class="gi">+            info = await self._info(f)</span>
<span class="gi">+            sizes[info[&quot;name&quot;]] = info[&quot;size&quot;]</span>
<span class="gi">+        if total:</span>
<span class="gi">+            return sum(sizes.values())</span>
<span class="gi">+        else:</span>
<span class="gi">+            return sizes</span>
<span class="gi">+</span>
<span class="gi">+    async def _find(self, path, maxdepth=None, withdirs=False, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        out = {}</span>
<span class="gi">+        detail = kwargs.pop(&quot;detail&quot;, False)</span>
<span class="gi">+</span>
<span class="gi">+        # Add the root directory if withdirs is requested</span>
<span class="gi">+        # This is needed for posix glob compliance</span>
<span class="gi">+        if withdirs and path != &quot;&quot; and await self._isdir(path):</span>
<span class="gi">+            out[path] = await self._info(path)</span>
<span class="gi">+</span>
<span class="gi">+        # async for?</span>
<span class="gi">+        async for _, dirs, files in self._walk(path, maxdepth, detail=True, **kwargs):</span>
<span class="gi">+            if withdirs:</span>
<span class="gi">+                files.update(dirs)</span>
<span class="gi">+            out.update({info[&quot;name&quot;]: info for name, info in files.items()})</span>
<span class="gi">+        if not out and (await self._isfile(path)):</span>
<span class="gi">+            # walk works on directories, but find should also return [path]</span>
<span class="gi">+            # when path happens to be a file</span>
<span class="gi">+            out[path] = {}</span>
<span class="gi">+        names = sorted(out)</span>
<span class="gi">+        if not detail:</span>
<span class="gi">+            return names</span>
<span class="gi">+        else:</span>
<span class="gi">+            return {name: out[name] for name in names}</span>
<span class="gi">+</span>
<span class="gi">+    async def _expand_path(self, path, recursive=False, maxdepth=None):</span>
<span class="gi">+        if maxdepth is not None and maxdepth &lt; 1:</span>
<span class="gi">+            raise ValueError(&quot;maxdepth must be at least 1&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        if isinstance(path, str):</span>
<span class="gi">+            out = await self._expand_path([path], recursive, maxdepth)</span>
<span class="gi">+        else:</span>
<span class="gi">+            out = set()</span>
<span class="gi">+            path = [self._strip_protocol(p) for p in path]</span>
<span class="gi">+            for p in path:  # can gather here</span>
<span class="gi">+                if has_magic(p):</span>
<span class="gi">+                    bit = set(await self._glob(p, maxdepth=maxdepth))</span>
<span class="gi">+                    out |= bit</span>
<span class="gi">+                    if recursive:</span>
<span class="gi">+                        # glob call above expanded one depth so if maxdepth is defined</span>
<span class="gi">+                        # then decrement it in expand_path call below. If it is zero</span>
<span class="gi">+                        # after decrementing then avoid expand_path call.</span>
<span class="gi">+                        if maxdepth is not None and maxdepth &lt;= 1:</span>
<span class="gi">+                            continue</span>
<span class="gi">+                        out |= set(</span>
<span class="gi">+                            await self._expand_path(</span>
<span class="gi">+                                list(bit),</span>
<span class="gi">+                                recursive=recursive,</span>
<span class="gi">+                                maxdepth=maxdepth - 1 if maxdepth is not None else None,</span>
<span class="gi">+                            )</span>
<span class="gi">+                        )</span>
<span class="gi">+                    continue</span>
<span class="gi">+                elif recursive:</span>
<span class="gi">+                    rec = set(await self._find(p, maxdepth=maxdepth, withdirs=True))</span>
<span class="gi">+                    out |= rec</span>
<span class="gi">+                if p not in out and (recursive is False or (await self._exists(p))):</span>
<span class="gi">+                    # should only check once, for the root</span>
<span class="gi">+                    out.add(p)</span>
<span class="gi">+        if not out:</span>
<span class="gi">+            raise FileNotFoundError(path)</span>
<span class="gi">+        return sorted(out)</span>
<span class="gi">+</span>
<span class="gi">+    async def _mkdir(self, path, create_parents=True, **kwargs):</span>
<span class="gi">+        pass  # not necessary to implement, may not have directories</span>
<span class="gi">+</span>
<span class="gi">+    async def _makedirs(self, path, exist_ok=False):</span>
<span class="gi">+        pass  # not necessary to implement, may not have directories</span>
<span class="gi">+</span>
<span class="gi">+    async def open_async(self, path, mode=&quot;rb&quot;, **kwargs):</span>
<span class="gi">+        if &quot;b&quot; not in mode or kwargs.get(&quot;compression&quot;):</span>
<span class="gi">+            raise ValueError</span>
<span class="gi">+        raise NotImplementedError</span>


<span class="w"> </span>def mirror_sync_methods(obj):
<span class="gu">@@ -211,14 +923,65 @@ def mirror_sync_methods(obj):</span>
<span class="w"> </span>      AbstractFileSystem
<span class="w"> </span>    - AsyncFileSystem: async-specific default coroutines
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from fsspec import AbstractFileSystem</span>
<span class="gi">+</span>
<span class="gi">+    for method in async_methods + dir(AsyncFileSystem):</span>
<span class="gi">+        if not method.startswith(&quot;_&quot;):</span>
<span class="gi">+            continue</span>
<span class="gi">+        smethod = method[1:]</span>
<span class="gi">+        if private.match(method):</span>
<span class="gi">+            isco = inspect.iscoroutinefunction(getattr(obj, method, None))</span>
<span class="gi">+            unsync = getattr(getattr(obj, smethod, False), &quot;__func__&quot;, None)</span>
<span class="gi">+            is_default = unsync is getattr(AbstractFileSystem, smethod, &quot;&quot;)</span>
<span class="gi">+            if isco and is_default:</span>
<span class="gi">+                mth = sync_wrapper(getattr(obj, method), obj=obj)</span>
<span class="gi">+                setattr(obj, smethod, mth)</span>
<span class="gi">+                if not mth.__doc__:</span>
<span class="gi">+                    mth.__doc__ = getattr(</span>
<span class="gi">+                        getattr(AbstractFileSystem, smethod, None), &quot;__doc__&quot;, &quot;&quot;</span>
<span class="gi">+                    )</span>


<span class="w"> </span>class FSSpecCoroutineCancel(Exception):
<span class="w"> </span>    pass


<span class="gi">+def _dump_running_tasks(</span>
<span class="gi">+    printout=True, cancel=True, exc=FSSpecCoroutineCancel, with_task=False</span>
<span class="gi">+):</span>
<span class="gi">+    import traceback</span>
<span class="gi">+</span>
<span class="gi">+    tasks = [t for t in asyncio.tasks.all_tasks(loop[0]) if not t.done()]</span>
<span class="gi">+    if printout:</span>
<span class="gi">+        [task.print_stack() for task in tasks]</span>
<span class="gi">+    out = [</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;locals&quot;: task._coro.cr_frame.f_locals,</span>
<span class="gi">+            &quot;file&quot;: task._coro.cr_frame.f_code.co_filename,</span>
<span class="gi">+            &quot;firstline&quot;: task._coro.cr_frame.f_code.co_firstlineno,</span>
<span class="gi">+            &quot;linelo&quot;: task._coro.cr_frame.f_lineno,</span>
<span class="gi">+            &quot;stack&quot;: traceback.format_stack(task._coro.cr_frame),</span>
<span class="gi">+            &quot;task&quot;: task if with_task else None,</span>
<span class="gi">+        }</span>
<span class="gi">+        for task in tasks</span>
<span class="gi">+    ]</span>
<span class="gi">+    if cancel:</span>
<span class="gi">+        for t in tasks:</span>
<span class="gi">+            cbs = t._callbacks</span>
<span class="gi">+            t.cancel()</span>
<span class="gi">+            asyncio.futures.Future.set_exception(t, exc)</span>
<span class="gi">+            asyncio.futures.Future.cancel(t)</span>
<span class="gi">+            [cb[0](t) for cb in cbs]  # cancels any dependent concurrent.futures</span>
<span class="gi">+            try:</span>
<span class="gi">+                t._coro.throw(exc)  # exits coro, unless explicitly handled</span>
<span class="gi">+            except exc:</span>
<span class="gi">+                pass</span>
<span class="gi">+    return out</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>class AbstractAsyncStreamedFile(AbstractBufferedFile):
<span class="gi">+    # no read buffering, and always auto-commit</span>
<span class="gi">+    # TODO: readahead might still be useful here, but needs async version</span>

<span class="w"> </span>    async def read(self, length=-1):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -229,7 +992,19 @@ class AbstractAsyncStreamedFile(AbstractBufferedFile):</span>
<span class="w"> </span>        length: int (-1)
<span class="w"> </span>            Number of bytes to read; if &lt;0, all remaining bytes.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        length = -1 if length is None else int(length)</span>
<span class="gi">+        if self.mode != &quot;rb&quot;:</span>
<span class="gi">+            raise ValueError(&quot;File not in read mode&quot;)</span>
<span class="gi">+        if length &lt; 0:</span>
<span class="gi">+            length = self.size - self.loc</span>
<span class="gi">+        if self.closed:</span>
<span class="gi">+            raise ValueError(&quot;I/O operation on closed file.&quot;)</span>
<span class="gi">+        if length == 0:</span>
<span class="gi">+            # don&#39;t even bother calling fetch</span>
<span class="gi">+            return b&quot;&quot;</span>
<span class="gi">+        out = await self._fetch_range(self.loc, self.loc + length)</span>
<span class="gi">+        self.loc += len(out)</span>
<span class="gi">+        return out</span>

<span class="w"> </span>    async def write(self, data):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -243,17 +1018,79 @@ class AbstractAsyncStreamedFile(AbstractBufferedFile):</span>
<span class="w"> </span>        data: bytes
<span class="w"> </span>            Set of bytes to be written.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.mode not in {&quot;wb&quot;, &quot;ab&quot;}:</span>
<span class="gi">+            raise ValueError(&quot;File not in write mode&quot;)</span>
<span class="gi">+        if self.closed:</span>
<span class="gi">+            raise ValueError(&quot;I/O operation on closed file.&quot;)</span>
<span class="gi">+        if self.forced:</span>
<span class="gi">+            raise ValueError(&quot;This file has been force-flushed, can only close&quot;)</span>
<span class="gi">+        out = self.buffer.write(data)</span>
<span class="gi">+        self.loc += out</span>
<span class="gi">+        if self.buffer.tell() &gt;= self.blocksize:</span>
<span class="gi">+            await self.flush()</span>
<span class="gi">+        return out</span>

<span class="w"> </span>    async def close(self):
<span class="w"> </span>        &quot;&quot;&quot;Close file

<span class="w"> </span>        Finalizes writes, discards cache
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if getattr(self, &quot;_unclosable&quot;, False):</span>
<span class="gi">+            return</span>
<span class="gi">+        if self.closed:</span>
<span class="gi">+            return</span>
<span class="gi">+        if self.mode == &quot;rb&quot;:</span>
<span class="gi">+            self.cache = None</span>
<span class="gi">+        else:</span>
<span class="gi">+            if not self.forced:</span>
<span class="gi">+                await self.flush(force=True)</span>
<span class="gi">+</span>
<span class="gi">+            if self.fs is not None:</span>
<span class="gi">+                self.fs.invalidate_cache(self.path)</span>
<span class="gi">+                self.fs.invalidate_cache(self.fs._parent(self.path))</span>
<span class="gi">+</span>
<span class="gi">+        self.closed = True</span>
<span class="gi">+</span>
<span class="gi">+    async def flush(self, force=False):</span>
<span class="gi">+        if self.closed:</span>
<span class="gi">+            raise ValueError(&quot;Flush on closed file&quot;)</span>
<span class="gi">+        if force and self.forced:</span>
<span class="gi">+            raise ValueError(&quot;Force flush cannot be called more than once&quot;)</span>
<span class="gi">+        if force:</span>
<span class="gi">+            self.forced = True</span>
<span class="gi">+</span>
<span class="gi">+        if self.mode not in {&quot;wb&quot;, &quot;ab&quot;}:</span>
<span class="gi">+            # no-op to flush on read-mode</span>
<span class="gi">+            return</span>
<span class="gi">+</span>
<span class="gi">+        if not force and self.buffer.tell() &lt; self.blocksize:</span>
<span class="gi">+            # Defer write on small block</span>
<span class="gi">+            return</span>
<span class="gi">+</span>
<span class="gi">+        if self.offset is None:</span>
<span class="gi">+            # Initialize a multipart upload</span>
<span class="gi">+            self.offset = 0</span>
<span class="gi">+            try:</span>
<span class="gi">+                await self._initiate_upload()</span>
<span class="gi">+            except:  # noqa: E722</span>
<span class="gi">+                self.closed = True</span>
<span class="gi">+                raise</span>
<span class="gi">+</span>
<span class="gi">+        if await self._upload_chunk(final=force) is not False:</span>
<span class="gi">+            self.offset += self.buffer.seek(0, 2)</span>
<span class="gi">+            self.buffer = io.BytesIO()</span>

<span class="w"> </span>    async def __aenter__(self):
<span class="w"> </span>        return self

<span class="w"> </span>    async def __aexit__(self, exc_type, exc_val, exc_tb):
<span class="w"> </span>        await self.close()
<span class="gi">+</span>
<span class="gi">+    async def _fetch_range(self, start, end):</span>
<span class="gi">+        raise NotImplementedError</span>
<span class="gi">+</span>
<span class="gi">+    async def _initiate_upload(self):</span>
<span class="gi">+        pass</span>
<span class="gi">+</span>
<span class="gi">+    async def _upload_chunk(self, final=False):</span>
<span class="gi">+        raise NotImplementedError</span>
<span class="gh">diff --git a/fsspec/caching.py b/fsspec/caching.py</span>
<span class="gh">index c4fc674..a3f7a1c 100644</span>
<span class="gd">--- a/fsspec/caching.py</span>
<span class="gi">+++ b/fsspec/caching.py</span>
<span class="gu">@@ -1,4 +1,5 @@</span>
<span class="w"> </span>from __future__ import annotations
<span class="gi">+</span>
<span class="w"> </span>import collections
<span class="w"> </span>import functools
<span class="w"> </span>import logging
<span class="gu">@@ -7,16 +8,33 @@ import os</span>
<span class="w"> </span>import threading
<span class="w"> </span>import warnings
<span class="w"> </span>from concurrent.futures import Future, ThreadPoolExecutor
<span class="gd">-from typing import TYPE_CHECKING, Any, Callable, ClassVar, Generic, NamedTuple, Optional, OrderedDict, TypeVar</span>
<span class="gi">+from typing import (</span>
<span class="gi">+    TYPE_CHECKING,</span>
<span class="gi">+    Any,</span>
<span class="gi">+    Callable,</span>
<span class="gi">+    ClassVar,</span>
<span class="gi">+    Generic,</span>
<span class="gi">+    NamedTuple,</span>
<span class="gi">+    Optional,</span>
<span class="gi">+    OrderedDict,</span>
<span class="gi">+    TypeVar,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="w"> </span>if TYPE_CHECKING:
<span class="w"> </span>    import mmap
<span class="gi">+</span>
<span class="w"> </span>    from typing_extensions import ParamSpec
<span class="gd">-    P = ParamSpec(&#39;P&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    P = ParamSpec(&quot;P&quot;)</span>
<span class="w"> </span>else:
<span class="gd">-    P = TypeVar(&#39;P&#39;)</span>
<span class="gd">-T = TypeVar(&#39;T&#39;)</span>
<span class="gd">-logger = logging.getLogger(&#39;fsspec&#39;)</span>
<span class="gd">-Fetcher = Callable[[int, int], bytes]</span>
<span class="gi">+    P = TypeVar(&quot;P&quot;)</span>
<span class="gi">+</span>
<span class="gi">+T = TypeVar(&quot;T&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+logger = logging.getLogger(&quot;fsspec&quot;)</span>
<span class="gi">+</span>
<span class="gi">+Fetcher = Callable[[int, int], bytes]  # Maps (start, end) to bytes</span>


<span class="w"> </span>class BaseCache:
<span class="gu">@@ -34,26 +52,48 @@ class BaseCache:</span>
<span class="w"> </span>    size: int
<span class="w"> </span>        How big this file is
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    name: ClassVar[str] = &#39;none&#39;</span>

<span class="gd">-    def __init__(self, blocksize: int, fetcher: Fetcher, size: int) -&gt;None:</span>
<span class="gi">+    name: ClassVar[str] = &quot;none&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(self, blocksize: int, fetcher: Fetcher, size: int) -&gt; None:</span>
<span class="w"> </span>        self.blocksize = blocksize
<span class="w"> </span>        self.nblocks = 0
<span class="w"> </span>        self.fetcher = fetcher
<span class="w"> </span>        self.size = size
<span class="w"> </span>        self.hit_count = 0
<span class="w"> </span>        self.miss_count = 0
<span class="gi">+        # the bytes that we actually requested</span>
<span class="w"> </span>        self.total_requested_bytes = 0

<span class="gd">-    def _reset_stats(self) -&gt;None:</span>
<span class="gi">+    def _fetch(self, start: int | None, stop: int | None) -&gt; bytes:</span>
<span class="gi">+        if start is None:</span>
<span class="gi">+            start = 0</span>
<span class="gi">+        if stop is None:</span>
<span class="gi">+            stop = self.size</span>
<span class="gi">+        if start &gt;= self.size or start &gt;= stop:</span>
<span class="gi">+            return b&quot;&quot;</span>
<span class="gi">+        return self.fetcher(start, stop)</span>
<span class="gi">+</span>
<span class="gi">+    def _reset_stats(self) -&gt; None:</span>
<span class="w"> </span>        &quot;&quot;&quot;Reset hit and miss counts for a more ganular report e.g. by file.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.hit_count = 0</span>
<span class="gi">+        self.miss_count = 0</span>
<span class="gi">+        self.total_requested_bytes = 0</span>

<span class="gd">-    def _log_stats(self) -&gt;str:</span>
<span class="gi">+    def _log_stats(self) -&gt; str:</span>
<span class="w"> </span>        &quot;&quot;&quot;Return a formatted string of the cache statistics.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def __repr__(self) -&gt;str:</span>
<span class="gi">+        if self.hit_count == 0 and self.miss_count == 0:</span>
<span class="gi">+            # a cache that does nothing, this is for logs only</span>
<span class="gi">+            return &quot;&quot;</span>
<span class="gi">+        return &quot; , %s: %d hits, %d misses, %d total requested bytes&quot; % (</span>
<span class="gi">+            self.name,</span>
<span class="gi">+            self.hit_count,</span>
<span class="gi">+            self.miss_count,</span>
<span class="gi">+            self.total_requested_bytes,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def __repr__(self) -&gt; str:</span>
<span class="gi">+        # TODO: use rich for better formatting</span>
<span class="w"> </span>        return f&quot;&quot;&quot;
<span class="w"> </span>        &lt;{self.__class__.__name__}:
<span class="w"> </span>            block size  :   {self.blocksize}
<span class="gu">@@ -73,21 +113,80 @@ class MMapCache(BaseCache):</span>

<span class="w"> </span>    This cache method might only work on posix
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    name = &#39;mmap&#39;</span>

<span class="gd">-    def __init__(self, blocksize: int, fetcher: Fetcher, size: int,</span>
<span class="gd">-        location: (str | None)=None, blocks: (set[int] | None)=None) -&gt;None:</span>
<span class="gi">+    name = &quot;mmap&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        blocksize: int,</span>
<span class="gi">+        fetcher: Fetcher,</span>
<span class="gi">+        size: int,</span>
<span class="gi">+        location: str | None = None,</span>
<span class="gi">+        blocks: set[int] | None = None,</span>
<span class="gi">+    ) -&gt; None:</span>
<span class="w"> </span>        super().__init__(blocksize, fetcher, size)
<span class="w"> </span>        self.blocks = set() if blocks is None else blocks
<span class="w"> </span>        self.location = location
<span class="w"> </span>        self.cache = self._makefile()

<span class="gd">-    def __getstate__(self) -&gt;dict[str, Any]:</span>
<span class="gi">+    def _makefile(self) -&gt; mmap.mmap | bytearray:</span>
<span class="gi">+        import mmap</span>
<span class="gi">+        import tempfile</span>
<span class="gi">+</span>
<span class="gi">+        if self.size == 0:</span>
<span class="gi">+            return bytearray()</span>
<span class="gi">+</span>
<span class="gi">+        # posix version</span>
<span class="gi">+        if self.location is None or not os.path.exists(self.location):</span>
<span class="gi">+            if self.location is None:</span>
<span class="gi">+                fd = tempfile.TemporaryFile()</span>
<span class="gi">+                self.blocks = set()</span>
<span class="gi">+            else:</span>
<span class="gi">+                fd = open(self.location, &quot;wb+&quot;)</span>
<span class="gi">+            fd.seek(self.size - 1)</span>
<span class="gi">+            fd.write(b&quot;1&quot;)</span>
<span class="gi">+            fd.flush()</span>
<span class="gi">+        else:</span>
<span class="gi">+            fd = open(self.location, &quot;r+b&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        return mmap.mmap(fd.fileno(), self.size)</span>
<span class="gi">+</span>
<span class="gi">+    def _fetch(self, start: int | None, end: int | None) -&gt; bytes:</span>
<span class="gi">+        logger.debug(f&quot;MMap cache fetching {start}-{end}&quot;)</span>
<span class="gi">+        if start is None:</span>
<span class="gi">+            start = 0</span>
<span class="gi">+        if end is None:</span>
<span class="gi">+            end = self.size</span>
<span class="gi">+        if start &gt;= self.size or start &gt;= end:</span>
<span class="gi">+            return b&quot;&quot;</span>
<span class="gi">+        start_block = start // self.blocksize</span>
<span class="gi">+        end_block = end // self.blocksize</span>
<span class="gi">+        need = [i for i in range(start_block, end_block + 1) if i not in self.blocks]</span>
<span class="gi">+        hits = [i for i in range(start_block, end_block + 1) if i in self.blocks]</span>
<span class="gi">+        self.miss_count += len(need)</span>
<span class="gi">+        self.hit_count += len(hits)</span>
<span class="gi">+        while need:</span>
<span class="gi">+            # TODO: not a for loop so we can consolidate blocks later to</span>
<span class="gi">+            # make fewer fetch calls; this could be parallel</span>
<span class="gi">+            i = need.pop(0)</span>
<span class="gi">+</span>
<span class="gi">+            sstart = i * self.blocksize</span>
<span class="gi">+            send = min(sstart + self.blocksize, self.size)</span>
<span class="gi">+            self.total_requested_bytes += send - sstart</span>
<span class="gi">+            logger.debug(f&quot;MMap get block #{i} ({sstart}-{send})&quot;)</span>
<span class="gi">+            self.cache[sstart:send] = self.fetcher(sstart, send)</span>
<span class="gi">+            self.blocks.add(i)</span>
<span class="gi">+</span>
<span class="gi">+        return self.cache[start:end]</span>
<span class="gi">+</span>
<span class="gi">+    def __getstate__(self) -&gt; dict[str, Any]:</span>
<span class="w"> </span>        state = self.__dict__.copy()
<span class="gd">-        del state[&#39;cache&#39;]</span>
<span class="gi">+        # Remove the unpicklable entries.</span>
<span class="gi">+        del state[&quot;cache&quot;]</span>
<span class="w"> </span>        return state

<span class="gd">-    def __setstate__(self, state: dict[str, Any]) -&gt;None:</span>
<span class="gi">+    def __setstate__(self, state: dict[str, Any]) -&gt; None:</span>
<span class="gi">+        # Restore instance attributes</span>
<span class="w"> </span>        self.__dict__.update(state)
<span class="w"> </span>        self.cache = self._makefile()

<span class="gu">@@ -99,14 +198,44 @@ class ReadAheadCache(BaseCache):</span>
<span class="w"> </span>    fill holes in the cache or keep fragments alive. It is best suited to
<span class="w"> </span>    many small reads in a sequential order (e.g., reading lines from a file).
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    name = &#39;readahead&#39;</span>

<span class="gd">-    def __init__(self, blocksize: int, fetcher: Fetcher, size: int) -&gt;None:</span>
<span class="gi">+    name = &quot;readahead&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(self, blocksize: int, fetcher: Fetcher, size: int) -&gt; None:</span>
<span class="w"> </span>        super().__init__(blocksize, fetcher, size)
<span class="gd">-        self.cache = b&#39;&#39;</span>
<span class="gi">+        self.cache = b&quot;&quot;</span>
<span class="w"> </span>        self.start = 0
<span class="w"> </span>        self.end = 0

<span class="gi">+    def _fetch(self, start: int | None, end: int | None) -&gt; bytes:</span>
<span class="gi">+        if start is None:</span>
<span class="gi">+            start = 0</span>
<span class="gi">+        if end is None or end &gt; self.size:</span>
<span class="gi">+            end = self.size</span>
<span class="gi">+        if start &gt;= self.size or start &gt;= end:</span>
<span class="gi">+            return b&quot;&quot;</span>
<span class="gi">+        l = end - start</span>
<span class="gi">+        if start &gt;= self.start and end &lt;= self.end:</span>
<span class="gi">+            # cache hit</span>
<span class="gi">+            self.hit_count += 1</span>
<span class="gi">+            return self.cache[start - self.start : end - self.start]</span>
<span class="gi">+        elif self.start &lt;= start &lt; self.end:</span>
<span class="gi">+            # partial hit</span>
<span class="gi">+            self.miss_count += 1</span>
<span class="gi">+            part = self.cache[start - self.start :]</span>
<span class="gi">+            l -= len(part)</span>
<span class="gi">+            start = self.end</span>
<span class="gi">+        else:</span>
<span class="gi">+            # miss</span>
<span class="gi">+            self.miss_count += 1</span>
<span class="gi">+            part = b&quot;&quot;</span>
<span class="gi">+        end = min(self.size, end + self.blocksize)</span>
<span class="gi">+        self.total_requested_bytes += end - start</span>
<span class="gi">+        self.cache = self.fetcher(start, end)  # new block replaces old</span>
<span class="gi">+        self.start = start</span>
<span class="gi">+        self.end = self.start + len(self.cache)</span>
<span class="gi">+        return part + self.cache[:l]</span>
<span class="gi">+</span>

<span class="w"> </span>class FirstChunkCache(BaseCache):
<span class="w"> </span>    &quot;&quot;&quot;Caches the first block of a file only
<span class="gu">@@ -114,14 +243,45 @@ class FirstChunkCache(BaseCache):</span>
<span class="w"> </span>    This may be useful for file types where the metadata is stored in the header,
<span class="w"> </span>    but is randomly accessed.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    name = &#39;first&#39;</span>

<span class="gd">-    def __init__(self, blocksize: int, fetcher: Fetcher, size: int) -&gt;None:</span>
<span class="gi">+    name = &quot;first&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(self, blocksize: int, fetcher: Fetcher, size: int) -&gt; None:</span>
<span class="w"> </span>        if blocksize &gt; size:
<span class="gi">+            # this will buffer the whole thing</span>
<span class="w"> </span>            blocksize = size
<span class="w"> </span>        super().__init__(blocksize, fetcher, size)
<span class="w"> </span>        self.cache: bytes | None = None

<span class="gi">+    def _fetch(self, start: int | None, end: int | None) -&gt; bytes:</span>
<span class="gi">+        start = start or 0</span>
<span class="gi">+        if start &gt; self.size:</span>
<span class="gi">+            logger.debug(&quot;FirstChunkCache: requested start &gt; file size&quot;)</span>
<span class="gi">+            return b&quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+        end = min(end, self.size)</span>
<span class="gi">+</span>
<span class="gi">+        if start &lt; self.blocksize:</span>
<span class="gi">+            if self.cache is None:</span>
<span class="gi">+                self.miss_count += 1</span>
<span class="gi">+                if end &gt; self.blocksize:</span>
<span class="gi">+                    self.total_requested_bytes += end</span>
<span class="gi">+                    data = self.fetcher(0, end)</span>
<span class="gi">+                    self.cache = data[: self.blocksize]</span>
<span class="gi">+                    return data[start:]</span>
<span class="gi">+                self.cache = self.fetcher(0, self.blocksize)</span>
<span class="gi">+                self.total_requested_bytes += self.blocksize</span>
<span class="gi">+            part = self.cache[start:end]</span>
<span class="gi">+            if end &gt; self.blocksize:</span>
<span class="gi">+                self.total_requested_bytes += end - self.blocksize</span>
<span class="gi">+                part += self.fetcher(self.blocksize, end)</span>
<span class="gi">+            self.hit_count += 1</span>
<span class="gi">+            return part</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.miss_count += 1</span>
<span class="gi">+            self.total_requested_bytes += end - start</span>
<span class="gi">+            return self.fetcher(start, end)</span>
<span class="gi">+</span>

<span class="w"> </span>class BlockCache(BaseCache):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gu">@@ -145,15 +305,16 @@ class BlockCache(BaseCache):</span>
<span class="w"> </span>        The maximum number of blocks to cache for. The maximum memory
<span class="w"> </span>        use for this cache is then ``blocksize * maxblocks``.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    name = &#39;blockcache&#39;</span>

<span class="gd">-    def __init__(self, blocksize: int, fetcher: Fetcher, size: int,</span>
<span class="gd">-        maxblocks: int=32) -&gt;None:</span>
<span class="gi">+    name = &quot;blockcache&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self, blocksize: int, fetcher: Fetcher, size: int, maxblocks: int = 32</span>
<span class="gi">+    ) -&gt; None:</span>
<span class="w"> </span>        super().__init__(blocksize, fetcher, size)
<span class="w"> </span>        self.nblocks = math.ceil(size / blocksize)
<span class="w"> </span>        self.maxblocks = maxblocks
<span class="gd">-        self._fetch_block_cached = functools.lru_cache(maxblocks)(self.</span>
<span class="gd">-            _fetch_block)</span>
<span class="gi">+        self._fetch_block_cached = functools.lru_cache(maxblocks)(self._fetch_block)</span>

<span class="w"> </span>    def cache_info(self):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -164,26 +325,63 @@ class BlockCache(BaseCache):</span>
<span class="w"> </span>        NamedTuple
<span class="w"> </span>            Returned directly from the LRU Cache used internally.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._fetch_block_cached.cache_info()</span>

<span class="gd">-    def __getstate__(self) -&gt;dict[str, Any]:</span>
<span class="gi">+    def __getstate__(self) -&gt; dict[str, Any]:</span>
<span class="w"> </span>        state = self.__dict__
<span class="gd">-        del state[&#39;_fetch_block_cached&#39;]</span>
<span class="gi">+        del state[&quot;_fetch_block_cached&quot;]</span>
<span class="w"> </span>        return state

<span class="gd">-    def __setstate__(self, state: dict[str, Any]) -&gt;None:</span>
<span class="gi">+    def __setstate__(self, state: dict[str, Any]) -&gt; None:</span>
<span class="w"> </span>        self.__dict__.update(state)
<span class="gd">-        self._fetch_block_cached = functools.lru_cache(state[&#39;maxblocks&#39;])(self</span>
<span class="gd">-            ._fetch_block)</span>
<span class="gd">-</span>
<span class="gd">-    def _fetch_block(self, block_number: int) -&gt;bytes:</span>
<span class="gi">+        self._fetch_block_cached = functools.lru_cache(state[&quot;maxblocks&quot;])(</span>
<span class="gi">+            self._fetch_block</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def _fetch(self, start: int | None, end: int | None) -&gt; bytes:</span>
<span class="gi">+        if start is None:</span>
<span class="gi">+            start = 0</span>
<span class="gi">+        if end is None:</span>
<span class="gi">+            end = self.size</span>
<span class="gi">+        if start &gt;= self.size or start &gt;= end:</span>
<span class="gi">+            return b&quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+        # byte position -&gt; block numbers</span>
<span class="gi">+        start_block_number = start // self.blocksize</span>
<span class="gi">+        end_block_number = end // self.blocksize</span>
<span class="gi">+</span>
<span class="gi">+        # these are cached, so safe to do multiple calls for the same start and end.</span>
<span class="gi">+        for block_number in range(start_block_number, end_block_number + 1):</span>
<span class="gi">+            self._fetch_block_cached(block_number)</span>
<span class="gi">+</span>
<span class="gi">+        return self._read_cache(</span>
<span class="gi">+            start,</span>
<span class="gi">+            end,</span>
<span class="gi">+            start_block_number=start_block_number,</span>
<span class="gi">+            end_block_number=end_block_number,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def _fetch_block(self, block_number: int) -&gt; bytes:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Fetch the block of data for `block_number`.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def _read_cache(self, start: int, end: int, start_block_number: int,</span>
<span class="gd">-        end_block_number: int) -&gt;bytes:</span>
<span class="gi">+        if block_number &gt; self.nblocks:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                f&quot;&#39;block_number={block_number}&#39; is greater than &quot;</span>
<span class="gi">+                f&quot;the number of blocks ({self.nblocks})&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        start = block_number * self.blocksize</span>
<span class="gi">+        end = start + self.blocksize</span>
<span class="gi">+        self.total_requested_bytes += end - start</span>
<span class="gi">+        self.miss_count += 1</span>
<span class="gi">+        logger.info(&quot;BlockCache fetching block %d&quot;, block_number)</span>
<span class="gi">+        block_contents = super()._fetch(start, end)</span>
<span class="gi">+        return block_contents</span>
<span class="gi">+</span>
<span class="gi">+    def _read_cache(</span>
<span class="gi">+        self, start: int, end: int, start_block_number: int, end_block_number: int</span>
<span class="gi">+    ) -&gt; bytes:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Read from our block cache.

<span class="gu">@@ -194,7 +392,32 @@ class BlockCache(BaseCache):</span>
<span class="w"> </span>        start_block_number, end_block_number : int
<span class="w"> </span>            The start and end block numbers.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        start_pos = start % self.blocksize</span>
<span class="gi">+        end_pos = end % self.blocksize</span>
<span class="gi">+</span>
<span class="gi">+        self.hit_count += 1</span>
<span class="gi">+        if start_block_number == end_block_number:</span>
<span class="gi">+            block: bytes = self._fetch_block_cached(start_block_number)</span>
<span class="gi">+            return block[start_pos:end_pos]</span>
<span class="gi">+</span>
<span class="gi">+        else:</span>
<span class="gi">+            # read from the initial</span>
<span class="gi">+            out = [self._fetch_block_cached(start_block_number)[start_pos:]]</span>
<span class="gi">+</span>
<span class="gi">+            # intermediate blocks</span>
<span class="gi">+            # Note: it&#39;d be nice to combine these into one big request. However</span>
<span class="gi">+            # that doesn&#39;t play nicely with our LRU cache.</span>
<span class="gi">+            out.extend(</span>
<span class="gi">+                map(</span>
<span class="gi">+                    self._fetch_block_cached,</span>
<span class="gi">+                    range(start_block_number + 1, end_block_number),</span>
<span class="gi">+                )</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            # final block</span>
<span class="gi">+            out.append(self._fetch_block_cached(end_block_number)[:end_pos])</span>
<span class="gi">+</span>
<span class="gi">+            return b&quot;&quot;.join(out)</span>


<span class="w"> </span>class BytesCache(BaseCache):
<span class="gu">@@ -209,33 +432,118 @@ class BytesCache(BaseCache):</span>
<span class="w"> </span>        As we read more data, whether to discard the start of the buffer when
<span class="w"> </span>        we are more than a blocksize ahead of it.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    name: ClassVar[str] = &#39;bytes&#39;</span>

<span class="gd">-    def __init__(self, blocksize: int, fetcher: Fetcher, size: int, trim:</span>
<span class="gd">-        bool=True) -&gt;None:</span>
<span class="gi">+    name: ClassVar[str] = &quot;bytes&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self, blocksize: int, fetcher: Fetcher, size: int, trim: bool = True</span>
<span class="gi">+    ) -&gt; None:</span>
<span class="w"> </span>        super().__init__(blocksize, fetcher, size)
<span class="gd">-        self.cache = b&#39;&#39;</span>
<span class="gi">+        self.cache = b&quot;&quot;</span>
<span class="w"> </span>        self.start: int | None = None
<span class="w"> </span>        self.end: int | None = None
<span class="w"> </span>        self.trim = trim

<span class="gd">-    def __len__(self) -&gt;int:</span>
<span class="gi">+    def _fetch(self, start: int | None, end: int | None) -&gt; bytes:</span>
<span class="gi">+        # TODO: only set start/end after fetch, in case it fails?</span>
<span class="gi">+        # is this where retry logic might go?</span>
<span class="gi">+        if start is None:</span>
<span class="gi">+            start = 0</span>
<span class="gi">+        if end is None:</span>
<span class="gi">+            end = self.size</span>
<span class="gi">+        if start &gt;= self.size or start &gt;= end:</span>
<span class="gi">+            return b&quot;&quot;</span>
<span class="gi">+        if (</span>
<span class="gi">+            self.start is not None</span>
<span class="gi">+            and start &gt;= self.start</span>
<span class="gi">+            and self.end is not None</span>
<span class="gi">+            and end &lt; self.end</span>
<span class="gi">+        ):</span>
<span class="gi">+            # cache hit: we have all the required data</span>
<span class="gi">+            offset = start - self.start</span>
<span class="gi">+            self.hit_count += 1</span>
<span class="gi">+            return self.cache[offset : offset + end - start]</span>
<span class="gi">+</span>
<span class="gi">+        if self.blocksize:</span>
<span class="gi">+            bend = min(self.size, end + self.blocksize)</span>
<span class="gi">+        else:</span>
<span class="gi">+            bend = end</span>
<span class="gi">+</span>
<span class="gi">+        if bend == start or start &gt; self.size:</span>
<span class="gi">+            return b&quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+        if (self.start is None or start &lt; self.start) and (</span>
<span class="gi">+            self.end is None or end &gt; self.end</span>
<span class="gi">+        ):</span>
<span class="gi">+            # First read, or extending both before and after</span>
<span class="gi">+            self.total_requested_bytes += bend - start</span>
<span class="gi">+            self.miss_count += 1</span>
<span class="gi">+            self.cache = self.fetcher(start, bend)</span>
<span class="gi">+            self.start = start</span>
<span class="gi">+        else:</span>
<span class="gi">+            assert self.start is not None</span>
<span class="gi">+            assert self.end is not None</span>
<span class="gi">+            self.miss_count += 1</span>
<span class="gi">+</span>
<span class="gi">+            if start &lt; self.start:</span>
<span class="gi">+                if self.end is None or self.end - end &gt; self.blocksize:</span>
<span class="gi">+                    self.total_requested_bytes += bend - start</span>
<span class="gi">+                    self.cache = self.fetcher(start, bend)</span>
<span class="gi">+                    self.start = start</span>
<span class="gi">+                else:</span>
<span class="gi">+                    self.total_requested_bytes += self.start - start</span>
<span class="gi">+                    new = self.fetcher(start, self.start)</span>
<span class="gi">+                    self.start = start</span>
<span class="gi">+                    self.cache = new + self.cache</span>
<span class="gi">+            elif self.end is not None and bend &gt; self.end:</span>
<span class="gi">+                if self.end &gt; self.size:</span>
<span class="gi">+                    pass</span>
<span class="gi">+                elif end - self.end &gt; self.blocksize:</span>
<span class="gi">+                    self.total_requested_bytes += bend - start</span>
<span class="gi">+                    self.cache = self.fetcher(start, bend)</span>
<span class="gi">+                    self.start = start</span>
<span class="gi">+                else:</span>
<span class="gi">+                    self.total_requested_bytes += bend - self.end</span>
<span class="gi">+                    new = self.fetcher(self.end, bend)</span>
<span class="gi">+                    self.cache = self.cache + new</span>
<span class="gi">+</span>
<span class="gi">+        self.end = self.start + len(self.cache)</span>
<span class="gi">+        offset = start - self.start</span>
<span class="gi">+        out = self.cache[offset : offset + end - start]</span>
<span class="gi">+        if self.trim:</span>
<span class="gi">+            num = (self.end - self.start) // (self.blocksize + 1)</span>
<span class="gi">+            if num &gt; 1:</span>
<span class="gi">+                self.start += self.blocksize * num</span>
<span class="gi">+                self.cache = self.cache[self.blocksize * num :]</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    def __len__(self) -&gt; int:</span>
<span class="w"> </span>        return len(self.cache)


<span class="w"> </span>class AllBytes(BaseCache):
<span class="w"> </span>    &quot;&quot;&quot;Cache entire contents of the file&quot;&quot;&quot;
<span class="gd">-    name: ClassVar[str] = &#39;all&#39;</span>

<span class="gd">-    def __init__(self, blocksize: (int | None)=None, fetcher: (Fetcher |</span>
<span class="gd">-        None)=None, size: (int | None)=None, data: (bytes | None)=None) -&gt;None:</span>
<span class="gd">-        super().__init__(blocksize, fetcher, size)</span>
<span class="gi">+    name: ClassVar[str] = &quot;all&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        blocksize: int | None = None,</span>
<span class="gi">+        fetcher: Fetcher | None = None,</span>
<span class="gi">+        size: int | None = None,</span>
<span class="gi">+        data: bytes | None = None,</span>
<span class="gi">+    ) -&gt; None:</span>
<span class="gi">+        super().__init__(blocksize, fetcher, size)  # type: ignore[arg-type]</span>
<span class="w"> </span>        if data is None:
<span class="w"> </span>            self.miss_count += 1
<span class="w"> </span>            self.total_requested_bytes += self.size
<span class="w"> </span>            data = self.fetcher(0, self.size)
<span class="w"> </span>        self.data = data

<span class="gi">+    def _fetch(self, start: int | None, stop: int | None) -&gt; bytes:</span>
<span class="gi">+        self.hit_count += 1</span>
<span class="gi">+        return self.data[start:stop]</span>
<span class="gi">+</span>

<span class="w"> </span>class KnownPartsOfAFile(BaseCache):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gu">@@ -259,13 +567,22 @@ class KnownPartsOfAFile(BaseCache):</span>
<span class="w"> </span>        padded. Note that zero padding will not be used for reads that
<span class="w"> </span>        begin outside a known byte-range.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    name: ClassVar[str] = &#39;parts&#39;</span>

<span class="gd">-    def __init__(self, blocksize: int, fetcher: Fetcher, size: int, data:</span>
<span class="gd">-        Optional[dict[tuple[int, int], bytes]]=None, strict: bool=True, **_:</span>
<span class="gd">-        Any):</span>
<span class="gi">+    name: ClassVar[str] = &quot;parts&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        blocksize: int,</span>
<span class="gi">+        fetcher: Fetcher,</span>
<span class="gi">+        size: int,</span>
<span class="gi">+        data: Optional[dict[tuple[int, int], bytes]] = None,</span>
<span class="gi">+        strict: bool = True,</span>
<span class="gi">+        **_: Any,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        super().__init__(blocksize, fetcher, size)
<span class="w"> </span>        self.strict = strict
<span class="gi">+</span>
<span class="gi">+        # simple consolidation of contiguous blocks</span>
<span class="w"> </span>        if data:
<span class="w"> </span>            old_offsets = sorted(data.keys())
<span class="w"> </span>            offsets = [old_offsets[0]]
<span class="gu">@@ -273,15 +590,61 @@ class KnownPartsOfAFile(BaseCache):</span>
<span class="w"> </span>            for start, stop in old_offsets[1:]:
<span class="w"> </span>                start0, stop0 = offsets[-1]
<span class="w"> </span>                if start == stop0:
<span class="gd">-                    offsets[-1] = start0, stop</span>
<span class="gi">+                    offsets[-1] = (start0, stop)</span>
<span class="w"> </span>                    blocks[-1] += data.pop((start, stop))
<span class="w"> </span>                else:
<span class="w"> </span>                    offsets.append((start, stop))
<span class="w"> </span>                    blocks.append(data.pop((start, stop)))
<span class="gi">+</span>
<span class="w"> </span>            self.data = dict(zip(offsets, blocks))
<span class="w"> </span>        else:
<span class="w"> </span>            self.data = {}

<span class="gi">+    def _fetch(self, start: int | None, stop: int | None) -&gt; bytes:</span>
<span class="gi">+        if start is None:</span>
<span class="gi">+            start = 0</span>
<span class="gi">+        if stop is None:</span>
<span class="gi">+            stop = self.size</span>
<span class="gi">+</span>
<span class="gi">+        out = b&quot;&quot;</span>
<span class="gi">+        for (loc0, loc1), data in self.data.items():</span>
<span class="gi">+            # If self.strict=False, use zero-padded data</span>
<span class="gi">+            # for reads beyond the end of a &quot;known&quot; buffer</span>
<span class="gi">+            if loc0 &lt;= start &lt; loc1:</span>
<span class="gi">+                off = start - loc0</span>
<span class="gi">+                out = data[off : off + stop - start]</span>
<span class="gi">+                if not self.strict or loc0 &lt;= stop &lt;= loc1:</span>
<span class="gi">+                    # The request is within a known range, or</span>
<span class="gi">+                    # it begins within a known range, and we</span>
<span class="gi">+                    # are allowed to pad reads beyond the</span>
<span class="gi">+                    # buffer with zero</span>
<span class="gi">+                    out += b&quot;\x00&quot; * (stop - start - len(out))</span>
<span class="gi">+                    self.hit_count += 1</span>
<span class="gi">+                    return out</span>
<span class="gi">+                else:</span>
<span class="gi">+                    # The request ends outside a known range,</span>
<span class="gi">+                    # and we are being &quot;strict&quot; about reads</span>
<span class="gi">+                    # beyond the buffer</span>
<span class="gi">+                    start = loc1</span>
<span class="gi">+                    break</span>
<span class="gi">+</span>
<span class="gi">+        # We only get here if there is a request outside the</span>
<span class="gi">+        # known parts of the file. In an ideal world, this</span>
<span class="gi">+        # should never happen</span>
<span class="gi">+        if self.fetcher is None:</span>
<span class="gi">+            # We cannot fetch the data, so raise an error</span>
<span class="gi">+            raise ValueError(f&quot;Read is outside the known file parts: {(start, stop)}. &quot;)</span>
<span class="gi">+        # We can fetch the data, but should warn the user</span>
<span class="gi">+        # that this may be slow</span>
<span class="gi">+        warnings.warn(</span>
<span class="gi">+            f&quot;Read is outside the known file parts: {(start, stop)}. &quot;</span>
<span class="gi">+            f&quot;IO/caching performance may be poor!&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+        logger.debug(f&quot;KnownPartsOfAFile cache fetching {start}-{stop}&quot;)</span>
<span class="gi">+        self.total_requested_bytes += stop - start</span>
<span class="gi">+        self.miss_count += 1</span>
<span class="gi">+        return out + super()._fetch(start, stop)</span>
<span class="gi">+</span>

<span class="w"> </span>class UpdatableLRU(Generic[P, T]):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gu">@@ -290,14 +653,13 @@ class UpdatableLRU(Generic[P, T]):</span>
<span class="w"> </span>    Used by BackgroudBlockCache
<span class="w"> </span>    &quot;&quot;&quot;

<span class="gd">-</span>
<span class="w"> </span>    class CacheInfo(NamedTuple):
<span class="w"> </span>        hits: int
<span class="w"> </span>        misses: int
<span class="w"> </span>        maxsize: int
<span class="w"> </span>        currsize: int

<span class="gd">-    def __init__(self, func: Callable[P, T], max_size: int=128) -&gt;None:</span>
<span class="gi">+    def __init__(self, func: Callable[P, T], max_size: int = 128) -&gt; None:</span>
<span class="w"> </span>        self._cache: OrderedDict[Any, T] = collections.OrderedDict()
<span class="w"> </span>        self._func = func
<span class="w"> </span>        self._max_size = max_size
<span class="gu">@@ -305,22 +667,44 @@ class UpdatableLRU(Generic[P, T]):</span>
<span class="w"> </span>        self._misses = 0
<span class="w"> </span>        self._lock = threading.Lock()

<span class="gd">-    def __call__(self, *args: P.args, **kwargs: P.kwargs) -&gt;T:</span>
<span class="gi">+    def __call__(self, *args: P.args, **kwargs: P.kwargs) -&gt; T:</span>
<span class="w"> </span>        if kwargs:
<span class="gd">-            raise TypeError(f&#39;Got unexpected keyword argument {kwargs.keys()}&#39;)</span>
<span class="gi">+            raise TypeError(f&quot;Got unexpected keyword argument {kwargs.keys()}&quot;)</span>
<span class="w"> </span>        with self._lock:
<span class="w"> </span>            if args in self._cache:
<span class="w"> </span>                self._cache.move_to_end(args)
<span class="w"> </span>                self._hits += 1
<span class="w"> </span>                return self._cache[args]
<span class="gi">+</span>
<span class="w"> </span>        result = self._func(*args, **kwargs)
<span class="gi">+</span>
<span class="w"> </span>        with self._lock:
<span class="w"> </span>            self._cache[args] = result
<span class="w"> </span>            self._misses += 1
<span class="w"> </span>            if len(self._cache) &gt; self._max_size:
<span class="w"> </span>                self._cache.popitem(last=False)
<span class="gi">+</span>
<span class="w"> </span>        return result

<span class="gi">+    def is_key_cached(self, *args: Any) -&gt; bool:</span>
<span class="gi">+        with self._lock:</span>
<span class="gi">+            return args in self._cache</span>
<span class="gi">+</span>
<span class="gi">+    def add_key(self, result: T, *args: Any) -&gt; None:</span>
<span class="gi">+        with self._lock:</span>
<span class="gi">+            self._cache[args] = result</span>
<span class="gi">+            if len(self._cache) &gt; self._max_size:</span>
<span class="gi">+                self._cache.popitem(last=False)</span>
<span class="gi">+</span>
<span class="gi">+    def cache_info(self) -&gt; UpdatableLRU.CacheInfo:</span>
<span class="gi">+        with self._lock:</span>
<span class="gi">+            return self.CacheInfo(</span>
<span class="gi">+                maxsize=self._max_size,</span>
<span class="gi">+                currsize=len(self._cache),</span>
<span class="gi">+                hits=self._hits,</span>
<span class="gi">+                misses=self._misses,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>

<span class="w"> </span>class BackgroundBlockCache(BaseCache):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gu">@@ -347,20 +731,23 @@ class BackgroundBlockCache(BaseCache):</span>
<span class="w"> </span>        The maximum number of blocks to cache for. The maximum memory
<span class="w"> </span>        use for this cache is then ``blocksize * maxblocks``.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    name: ClassVar[str] = &#39;background&#39;</span>

<span class="gd">-    def __init__(self, blocksize: int, fetcher: Fetcher, size: int,</span>
<span class="gd">-        maxblocks: int=32) -&gt;None:</span>
<span class="gi">+    name: ClassVar[str] = &quot;background&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self, blocksize: int, fetcher: Fetcher, size: int, maxblocks: int = 32</span>
<span class="gi">+    ) -&gt; None:</span>
<span class="w"> </span>        super().__init__(blocksize, fetcher, size)
<span class="w"> </span>        self.nblocks = math.ceil(size / blocksize)
<span class="w"> </span>        self.maxblocks = maxblocks
<span class="w"> </span>        self._fetch_block_cached = UpdatableLRU(self._fetch_block, maxblocks)
<span class="gi">+</span>
<span class="w"> </span>        self._thread_executor = ThreadPoolExecutor(max_workers=1)
<span class="w"> </span>        self._fetch_future_block_number: int | None = None
<span class="w"> </span>        self._fetch_future: Future[bytes] | None = None
<span class="w"> </span>        self._fetch_future_lock = threading.Lock()

<span class="gd">-    def cache_info(self) -&gt;UpdatableLRU.CacheInfo:</span>
<span class="gi">+    def cache_info(self) -&gt; UpdatableLRU.CacheInfo:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        The statistics on the block cache.

<span class="gu">@@ -369,34 +756,122 @@ class BackgroundBlockCache(BaseCache):</span>
<span class="w"> </span>        NamedTuple
<span class="w"> </span>            Returned directly from the LRU Cache used internally.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._fetch_block_cached.cache_info()</span>

<span class="gd">-    def __getstate__(self) -&gt;dict[str, Any]:</span>
<span class="gi">+    def __getstate__(self) -&gt; dict[str, Any]:</span>
<span class="w"> </span>        state = self.__dict__
<span class="gd">-        del state[&#39;_fetch_block_cached&#39;]</span>
<span class="gd">-        del state[&#39;_thread_executor&#39;]</span>
<span class="gd">-        del state[&#39;_fetch_future_block_number&#39;]</span>
<span class="gd">-        del state[&#39;_fetch_future&#39;]</span>
<span class="gd">-        del state[&#39;_fetch_future_lock&#39;]</span>
<span class="gi">+        del state[&quot;_fetch_block_cached&quot;]</span>
<span class="gi">+        del state[&quot;_thread_executor&quot;]</span>
<span class="gi">+        del state[&quot;_fetch_future_block_number&quot;]</span>
<span class="gi">+        del state[&quot;_fetch_future&quot;]</span>
<span class="gi">+        del state[&quot;_fetch_future_lock&quot;]</span>
<span class="w"> </span>        return state

<span class="gd">-    def __setstate__(self, state) -&gt;None:</span>
<span class="gi">+    def __setstate__(self, state) -&gt; None:</span>
<span class="w"> </span>        self.__dict__.update(state)
<span class="gd">-        self._fetch_block_cached = UpdatableLRU(self._fetch_block, state[</span>
<span class="gd">-            &#39;maxblocks&#39;])</span>
<span class="gi">+        self._fetch_block_cached = UpdatableLRU(self._fetch_block, state[&quot;maxblocks&quot;])</span>
<span class="w"> </span>        self._thread_executor = ThreadPoolExecutor(max_workers=1)
<span class="w"> </span>        self._fetch_future_block_number = None
<span class="w"> </span>        self._fetch_future = None
<span class="w"> </span>        self._fetch_future_lock = threading.Lock()

<span class="gd">-    def _fetch_block(self, block_number: int, log_info: str=&#39;sync&#39;) -&gt;bytes:</span>
<span class="gi">+    def _fetch(self, start: int | None, end: int | None) -&gt; bytes:</span>
<span class="gi">+        if start is None:</span>
<span class="gi">+            start = 0</span>
<span class="gi">+        if end is None:</span>
<span class="gi">+            end = self.size</span>
<span class="gi">+        if start &gt;= self.size or start &gt;= end:</span>
<span class="gi">+            return b&quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+        # byte position -&gt; block numbers</span>
<span class="gi">+        start_block_number = start // self.blocksize</span>
<span class="gi">+        end_block_number = end // self.blocksize</span>
<span class="gi">+</span>
<span class="gi">+        fetch_future_block_number = None</span>
<span class="gi">+        fetch_future = None</span>
<span class="gi">+        with self._fetch_future_lock:</span>
<span class="gi">+            # Background thread is running. Check we we can or must join it.</span>
<span class="gi">+            if self._fetch_future is not None:</span>
<span class="gi">+                assert self._fetch_future_block_number is not None</span>
<span class="gi">+                if self._fetch_future.done():</span>
<span class="gi">+                    logger.info(&quot;BlockCache joined background fetch without waiting.&quot;)</span>
<span class="gi">+                    self._fetch_block_cached.add_key(</span>
<span class="gi">+                        self._fetch_future.result(), self._fetch_future_block_number</span>
<span class="gi">+                    )</span>
<span class="gi">+                    # Cleanup the fetch variables. Done with fetching the block.</span>
<span class="gi">+                    self._fetch_future_block_number = None</span>
<span class="gi">+                    self._fetch_future = None</span>
<span class="gi">+                else:</span>
<span class="gi">+                    # Must join if we need the block for the current fetch</span>
<span class="gi">+                    must_join = bool(</span>
<span class="gi">+                        start_block_number</span>
<span class="gi">+                        &lt;= self._fetch_future_block_number</span>
<span class="gi">+                        &lt;= end_block_number</span>
<span class="gi">+                    )</span>
<span class="gi">+                    if must_join:</span>
<span class="gi">+                        # Copy to the local variables to release lock</span>
<span class="gi">+                        # before waiting for result</span>
<span class="gi">+                        fetch_future_block_number = self._fetch_future_block_number</span>
<span class="gi">+                        fetch_future = self._fetch_future</span>
<span class="gi">+</span>
<span class="gi">+                        # Cleanup the fetch variables. Have a local copy.</span>
<span class="gi">+                        self._fetch_future_block_number = None</span>
<span class="gi">+                        self._fetch_future = None</span>
<span class="gi">+</span>
<span class="gi">+        # Need to wait for the future for the current read</span>
<span class="gi">+        if fetch_future is not None:</span>
<span class="gi">+            logger.info(&quot;BlockCache waiting for background fetch.&quot;)</span>
<span class="gi">+            # Wait until result and put it in cache</span>
<span class="gi">+            self._fetch_block_cached.add_key(</span>
<span class="gi">+                fetch_future.result(), fetch_future_block_number</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        # these are cached, so safe to do multiple calls for the same start and end.</span>
<span class="gi">+        for block_number in range(start_block_number, end_block_number + 1):</span>
<span class="gi">+            self._fetch_block_cached(block_number)</span>
<span class="gi">+</span>
<span class="gi">+        # fetch next block in the background if nothing is running in the background,</span>
<span class="gi">+        # the block is within file and it is not already cached</span>
<span class="gi">+        end_block_plus_1 = end_block_number + 1</span>
<span class="gi">+        with self._fetch_future_lock:</span>
<span class="gi">+            if (</span>
<span class="gi">+                self._fetch_future is None</span>
<span class="gi">+                and end_block_plus_1 &lt;= self.nblocks</span>
<span class="gi">+                and not self._fetch_block_cached.is_key_cached(end_block_plus_1)</span>
<span class="gi">+            ):</span>
<span class="gi">+                self._fetch_future_block_number = end_block_plus_1</span>
<span class="gi">+                self._fetch_future = self._thread_executor.submit(</span>
<span class="gi">+                    self._fetch_block, end_block_plus_1, &quot;async&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+</span>
<span class="gi">+        return self._read_cache(</span>
<span class="gi">+            start,</span>
<span class="gi">+            end,</span>
<span class="gi">+            start_block_number=start_block_number,</span>
<span class="gi">+            end_block_number=end_block_number,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def _fetch_block(self, block_number: int, log_info: str = &quot;sync&quot;) -&gt; bytes:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Fetch the block of data for `block_number`.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def _read_cache(self, start: int, end: int, start_block_number: int,</span>
<span class="gd">-        end_block_number: int) -&gt;bytes:</span>
<span class="gi">+        if block_number &gt; self.nblocks:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                f&quot;&#39;block_number={block_number}&#39; is greater than &quot;</span>
<span class="gi">+                f&quot;the number of blocks ({self.nblocks})&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        start = block_number * self.blocksize</span>
<span class="gi">+        end = start + self.blocksize</span>
<span class="gi">+        logger.info(&quot;BlockCache fetching block (%s) %d&quot;, log_info, block_number)</span>
<span class="gi">+        self.total_requested_bytes += end - start</span>
<span class="gi">+        self.miss_count += 1</span>
<span class="gi">+        block_contents = super()._fetch(start, end)</span>
<span class="gi">+        return block_contents</span>
<span class="gi">+</span>
<span class="gi">+    def _read_cache(</span>
<span class="gi">+        self, start: int, end: int, start_block_number: int, end_block_number: int</span>
<span class="gi">+    ) -&gt; bytes:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Read from our block cache.

<span class="gu">@@ -407,13 +882,43 @@ class BackgroundBlockCache(BaseCache):</span>
<span class="w"> </span>        start_block_number, end_block_number : int
<span class="w"> </span>            The start and end block numbers.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        start_pos = start % self.blocksize</span>
<span class="gi">+        end_pos = end % self.blocksize</span>

<span class="gi">+        # kind of pointless to count this as a hit, but it is</span>
<span class="gi">+        self.hit_count += 1</span>

<span class="gd">-caches: dict[str | None, type[BaseCache]] = {None: BaseCache}</span>
<span class="gi">+        if start_block_number == end_block_number:</span>
<span class="gi">+            block = self._fetch_block_cached(start_block_number)</span>
<span class="gi">+            return block[start_pos:end_pos]</span>
<span class="gi">+</span>
<span class="gi">+        else:</span>
<span class="gi">+            # read from the initial</span>
<span class="gi">+            out = [self._fetch_block_cached(start_block_number)[start_pos:]]</span>
<span class="gi">+</span>
<span class="gi">+            # intermediate blocks</span>
<span class="gi">+            # Note: it&#39;d be nice to combine these into one big request. However</span>
<span class="gi">+            # that doesn&#39;t play nicely with our LRU cache.</span>
<span class="gi">+            out.extend(</span>
<span class="gi">+                map(</span>
<span class="gi">+                    self._fetch_block_cached,</span>
<span class="gi">+                    range(start_block_number + 1, end_block_number),</span>
<span class="gi">+                )</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            # final block</span>
<span class="gi">+            out.append(self._fetch_block_cached(end_block_number)[:end_pos])</span>
<span class="gi">+</span>
<span class="gi">+            return b&quot;&quot;.join(out)</span>


<span class="gd">-def register_cache(cls: type[BaseCache], clobber: bool=False) -&gt;None:</span>
<span class="gi">+caches: dict[str | None, type[BaseCache]] = {</span>
<span class="gi">+    # one custom case</span>
<span class="gi">+    None: BaseCache,</span>
<span class="gi">+}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def register_cache(cls: type[BaseCache], clobber: bool = False) -&gt; None:</span>
<span class="w"> </span>    &quot;&quot;&quot;&#39;Register&#39; cache implementation.

<span class="w"> </span>    Parameters
<span class="gu">@@ -426,9 +931,21 @@ def register_cache(cls: type[BaseCache], clobber: bool=False) -&gt;None:</span>
<span class="w"> </span>    ------
<span class="w"> </span>    ValueError
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-for c in (BaseCache, MMapCache, BytesCache, ReadAheadCache, BlockCache,</span>
<span class="gd">-    FirstChunkCache, AllBytes, KnownPartsOfAFile, BackgroundBlockCache):</span>
<span class="gi">+    name = cls.name</span>
<span class="gi">+    if not clobber and name in caches:</span>
<span class="gi">+        raise ValueError(f&quot;Cache with name {name!r} is already known: {caches[name]}&quot;)</span>
<span class="gi">+    caches[name] = cls</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+for c in (</span>
<span class="gi">+    BaseCache,</span>
<span class="gi">+    MMapCache,</span>
<span class="gi">+    BytesCache,</span>
<span class="gi">+    ReadAheadCache,</span>
<span class="gi">+    BlockCache,</span>
<span class="gi">+    FirstChunkCache,</span>
<span class="gi">+    AllBytes,</span>
<span class="gi">+    KnownPartsOfAFile,</span>
<span class="gi">+    BackgroundBlockCache,</span>
<span class="gi">+):</span>
<span class="w"> </span>    register_cache(c)
<span class="gh">diff --git a/fsspec/callbacks.py b/fsspec/callbacks.py</span>
<span class="gh">index fd7312d..7ca99ca 100644</span>
<span class="gd">--- a/fsspec/callbacks.py</span>
<span class="gi">+++ b/fsspec/callbacks.py</span>
<span class="gu">@@ -36,7 +36,6 @@ class Callback:</span>

<span class="w"> </span>    def close(self):
<span class="w"> </span>        &quot;&quot;&quot;Close callback.&quot;&quot;&quot;
<span class="gd">-        pass</span>

<span class="w"> </span>    def branched(self, path_1, path_2, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -67,13 +66,21 @@ class Callback:</span>
<span class="w"> </span>        callback: Callback
<span class="w"> </span>            A callback instance to be passed to the child method
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.branch(path_1, path_2, kwargs)</span>
<span class="gi">+        # mutate kwargs so that we can force the caller to pass &quot;callback=&quot; explicitly</span>
<span class="gi">+        return kwargs.pop(&quot;callback&quot;, DEFAULT_CALLBACK)</span>

<span class="w"> </span>    def branch_coro(self, fn):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Wraps a coroutine, and pass a new child callback to it.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+</span>
<span class="gi">+        @wraps(fn)</span>
<span class="gi">+        async def func(path1, path2: str, **kwargs):</span>
<span class="gi">+            with self.branched(path1, path2, **kwargs) as child:</span>
<span class="gi">+                return await fn(path1, path2, callback=child, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+        return func</span>

<span class="w"> </span>    def set_size(self, size):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -86,7 +93,8 @@ class Callback:</span>
<span class="w"> </span>        ----------
<span class="w"> </span>        size: int
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.size = size</span>
<span class="gi">+        self.call()</span>

<span class="w"> </span>    def absolute_update(self, value):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -98,7 +106,8 @@ class Callback:</span>
<span class="w"> </span>        ----------
<span class="w"> </span>        value: int
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.value = value</span>
<span class="gi">+        self.call()</span>

<span class="w"> </span>    def relative_update(self, inc=1):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -110,7 +119,8 @@ class Callback:</span>
<span class="w"> </span>        ----------
<span class="w"> </span>        inc: int
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.value += inc</span>
<span class="gi">+        self.call()</span>

<span class="w"> </span>    def call(self, hook_name=None, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -124,7 +134,16 @@ class Callback:</span>
<span class="w"> </span>            If given, execute on this hook
<span class="w"> </span>        kwargs: passed on to (all) hook(s)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if not self.hooks:</span>
<span class="gi">+            return</span>
<span class="gi">+        kw = self.kw.copy()</span>
<span class="gi">+        kw.update(kwargs)</span>
<span class="gi">+        if hook_name:</span>
<span class="gi">+            if hook_name not in self.hooks:</span>
<span class="gi">+                return</span>
<span class="gi">+            return self.hooks[hook_name](self.size, self.value, **kw)</span>
<span class="gi">+        for hook in self.hooks.values() or []:</span>
<span class="gi">+            hook(self.size, self.value, **kw)</span>

<span class="w"> </span>    def wrap(self, iterable):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -135,7 +154,9 @@ class Callback:</span>
<span class="w"> </span>        iterable: Iterable
<span class="w"> </span>            The iterable that is being wrapped
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        for item in iterable:</span>
<span class="gi">+            self.relative_update()</span>
<span class="gi">+            yield item</span>

<span class="w"> </span>    def branch(self, path_1, path_2, kwargs):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -159,6 +180,9 @@ class Callback:</span>
<span class="w"> </span>        -------

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gi">+        return None</span>
<span class="gi">+</span>
<span class="gi">+    def no_op(self, *_, **__):</span>
<span class="w"> </span>        pass

<span class="w"> </span>    def __getattr__(self, item):
<span class="gu">@@ -175,7 +199,9 @@ class Callback:</span>
<span class="w"> </span>        ``NoOpCallback``. This is an alternative to including
<span class="w"> </span>        ``callback=DEFAULT_CALLBACK`` directly in a method signature.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if maybe_callback is None:</span>
<span class="gi">+            return DEFAULT_CALLBACK</span>
<span class="gi">+        return maybe_callback</span>


<span class="w"> </span>class NoOpCallback(Callback):
<span class="gu">@@ -183,6 +209,9 @@ class NoOpCallback(Callback):</span>
<span class="w"> </span>    This implementation of Callback does exactly nothing
<span class="w"> </span>    &quot;&quot;&quot;

<span class="gi">+    def call(self, *args, **kwargs):</span>
<span class="gi">+        return None</span>
<span class="gi">+</span>

<span class="w"> </span>class DotPrinterCallback(Callback):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gu">@@ -192,17 +221,17 @@ class DotPrinterCallback(Callback):</span>
<span class="w"> </span>    demonstrate how the outer layer may print &quot;#&quot; and the inner layer &quot;.&quot;
<span class="w"> </span>    &quot;&quot;&quot;

<span class="gd">-    def __init__(self, chr_to_print=&#39;#&#39;, **kwargs):</span>
<span class="gi">+    def __init__(self, chr_to_print=&quot;#&quot;, **kwargs):</span>
<span class="w"> </span>        self.chr = chr_to_print
<span class="w"> </span>        super().__init__(**kwargs)

<span class="w"> </span>    def branch(self, path_1, path_2, kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Mutate kwargs to add new instance with different print char&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        kwargs[&quot;callback&quot;] = DotPrinterCallback(&quot;.&quot;)</span>

<span class="w"> </span>    def call(self, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Just outputs a character&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        print(self.chr, end=&quot;&quot;)</span>


<span class="w"> </span>class TqdmCallback(Callback):
<span class="gu">@@ -266,14 +295,28 @@ class TqdmCallback(Callback):</span>
<span class="w"> </span>    def __init__(self, tqdm_kwargs=None, *args, **kwargs):
<span class="w"> </span>        try:
<span class="w"> </span>            from tqdm import tqdm
<span class="gi">+</span>
<span class="w"> </span>        except ImportError as exce:
<span class="w"> </span>            raise ImportError(
<span class="gd">-                &#39;Using TqdmCallback requires tqdm to be installed&#39;) from exce</span>
<span class="gd">-        self._tqdm_cls = kwargs.pop(&#39;tqdm_cls&#39;, tqdm)</span>
<span class="gi">+                &quot;Using TqdmCallback requires tqdm to be installed&quot;</span>
<span class="gi">+            ) from exce</span>
<span class="gi">+</span>
<span class="gi">+        self._tqdm_cls = kwargs.pop(&quot;tqdm_cls&quot;, tqdm)</span>
<span class="w"> </span>        self._tqdm_kwargs = tqdm_kwargs or {}
<span class="w"> </span>        self.tqdm = None
<span class="w"> </span>        super().__init__(*args, **kwargs)

<span class="gi">+    def call(self, *args, **kwargs):</span>
<span class="gi">+        if self.tqdm is None:</span>
<span class="gi">+            self.tqdm = self._tqdm_cls(total=self.size, **self._tqdm_kwargs)</span>
<span class="gi">+        self.tqdm.total = self.size</span>
<span class="gi">+        self.tqdm.update(self.value - self.tqdm.n)</span>
<span class="gi">+</span>
<span class="gi">+    def close(self):</span>
<span class="gi">+        if self.tqdm is not None:</span>
<span class="gi">+            self.tqdm.close()</span>
<span class="gi">+            self.tqdm = None</span>
<span class="gi">+</span>
<span class="w"> </span>    def __del__(self):
<span class="w"> </span>        return self.close()

<span class="gh">diff --git a/fsspec/compression.py b/fsspec/compression.py</span>
<span class="gh">index 9562369..fc519c2 100644</span>
<span class="gd">--- a/fsspec/compression.py</span>
<span class="gi">+++ b/fsspec/compression.py</span>
<span class="gu">@@ -1,7 +1,17 @@</span>
<span class="w"> </span>&quot;&quot;&quot;Helper functions for a standard streaming compression API&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>from zipfile import ZipFile
<span class="gi">+</span>
<span class="w"> </span>import fsspec.utils
<span class="w"> </span>from fsspec.spec import AbstractBufferedFile
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def noop_file(file, mode, **kwargs):</span>
<span class="gi">+    return file</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# TODO: files should also be available as contexts</span>
<span class="gi">+# should be functions of the form func(infile, mode=, **kwargs) -&gt; file-like</span>
<span class="w"> </span>compr = {None: noop_file}


<span class="gu">@@ -25,72 +35,141 @@ def register_compression(name, callback, extensions, force=False):</span>
<span class="w"> </span>        ValueError: If name or extensions already registered, and not force.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(extensions, str):</span>
<span class="gi">+        extensions = [extensions]</span>
<span class="gi">+</span>
<span class="gi">+    # Validate registration</span>
<span class="gi">+    if name in compr and not force:</span>
<span class="gi">+        raise ValueError(f&quot;Duplicate compression registration: {name}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    for ext in extensions:</span>
<span class="gi">+        if ext in fsspec.utils.compressions and not force:</span>
<span class="gi">+            raise ValueError(f&quot;Duplicate compression file extension: {ext} ({name})&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    compr[name] = callback</span>

<span class="gi">+    for ext in extensions:</span>
<span class="gi">+        fsspec.utils.compressions[ext] = name</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def unzip(infile, mode=&quot;rb&quot;, filename=None, **kwargs):</span>
<span class="gi">+    if &quot;r&quot; not in mode:</span>
<span class="gi">+        filename = filename or &quot;file&quot;</span>
<span class="gi">+        z = ZipFile(infile, mode=&quot;w&quot;, **kwargs)</span>
<span class="gi">+        fo = z.open(filename, mode=&quot;w&quot;)</span>
<span class="gi">+        fo.close = lambda closer=fo.close: closer() or z.close()</span>
<span class="gi">+        return fo</span>
<span class="gi">+    z = ZipFile(infile)</span>
<span class="gi">+    if filename is None:</span>
<span class="gi">+        filename = z.namelist()[0]</span>
<span class="gi">+    return z.open(filename, mode=&quot;r&quot;, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+register_compression(&quot;zip&quot;, unzip, &quot;zip&quot;)</span>

<span class="gd">-register_compression(&#39;zip&#39;, unzip, &#39;zip&#39;)</span>
<span class="w"> </span>try:
<span class="w"> </span>    from bz2 import BZ2File
<span class="w"> </span>except ImportError:
<span class="w"> </span>    pass
<span class="w"> </span>else:
<span class="gd">-    register_compression(&#39;bz2&#39;, BZ2File, &#39;bz2&#39;)</span>
<span class="gd">-try:</span>
<span class="gi">+    register_compression(&quot;bz2&quot;, BZ2File, &quot;bz2&quot;)</span>
<span class="gi">+</span>
<span class="gi">+try:  # pragma: no cover</span>
<span class="w"> </span>    from isal import igzip
<span class="gd">-    register_compression(&#39;gzip&#39;, isal, &#39;gz&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    def isal(infile, mode=&quot;rb&quot;, **kwargs):</span>
<span class="gi">+        return igzip.IGzipFile(fileobj=infile, mode=mode, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    register_compression(&quot;gzip&quot;, isal, &quot;gz&quot;)</span>
<span class="w"> </span>except ImportError:
<span class="w"> </span>    from gzip import GzipFile
<span class="gd">-    register_compression(&#39;gzip&#39;, lambda f, **kwargs: GzipFile(fileobj=f, **</span>
<span class="gd">-        kwargs), &#39;gz&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    register_compression(</span>
<span class="gi">+        &quot;gzip&quot;, lambda f, **kwargs: GzipFile(fileobj=f, **kwargs), &quot;gz&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="w"> </span>try:
<span class="w"> </span>    from lzma import LZMAFile
<span class="gd">-    register_compression(&#39;lzma&#39;, LZMAFile, &#39;lzma&#39;)</span>
<span class="gd">-    register_compression(&#39;xz&#39;, LZMAFile, &#39;xz&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    register_compression(&quot;lzma&quot;, LZMAFile, &quot;lzma&quot;)</span>
<span class="gi">+    register_compression(&quot;xz&quot;, LZMAFile, &quot;xz&quot;)</span>
<span class="w"> </span>except ImportError:
<span class="w"> </span>    pass
<span class="gi">+</span>
<span class="w"> </span>try:
<span class="w"> </span>    import lzmaffi
<span class="gd">-    register_compression(&#39;lzma&#39;, lzmaffi.LZMAFile, &#39;lzma&#39;, force=True)</span>
<span class="gd">-    register_compression(&#39;xz&#39;, lzmaffi.LZMAFile, &#39;xz&#39;, force=True)</span>
<span class="gi">+</span>
<span class="gi">+    register_compression(&quot;lzma&quot;, lzmaffi.LZMAFile, &quot;lzma&quot;, force=True)</span>
<span class="gi">+    register_compression(&quot;xz&quot;, lzmaffi.LZMAFile, &quot;xz&quot;, force=True)</span>
<span class="w"> </span>except ImportError:
<span class="w"> </span>    pass


<span class="w"> </span>class SnappyFile(AbstractBufferedFile):
<span class="gd">-</span>
<span class="w"> </span>    def __init__(self, infile, mode, **kwargs):
<span class="w"> </span>        import snappy
<span class="gd">-        super().__init__(fs=None, path=&#39;snappy&#39;, mode=mode.strip(&#39;b&#39;) + &#39;b&#39;,</span>
<span class="gd">-            size=999999999, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+        super().__init__(</span>
<span class="gi">+            fs=None, path=&quot;snappy&quot;, mode=mode.strip(&quot;b&quot;) + &quot;b&quot;, size=999999999, **kwargs</span>
<span class="gi">+        )</span>
<span class="w"> </span>        self.infile = infile
<span class="gd">-        if &#39;r&#39; in mode:</span>
<span class="gi">+        if &quot;r&quot; in mode:</span>
<span class="w"> </span>            self.codec = snappy.StreamDecompressor()
<span class="w"> </span>        else:
<span class="w"> </span>            self.codec = snappy.StreamCompressor()

<span class="gi">+    def _upload_chunk(self, final=False):</span>
<span class="gi">+        self.buffer.seek(0)</span>
<span class="gi">+        out = self.codec.add_chunk(self.buffer.read())</span>
<span class="gi">+        self.infile.write(out)</span>
<span class="gi">+        return True</span>
<span class="gi">+</span>
<span class="gi">+    def seek(self, loc, whence=0):</span>
<span class="gi">+        raise NotImplementedError(&quot;SnappyFile is not seekable&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def seekable(self):</span>
<span class="gi">+        return False</span>
<span class="gi">+</span>
<span class="w"> </span>    def _fetch_range(self, start, end):
<span class="w"> </span>        &quot;&quot;&quot;Get the specified set of bytes from remote&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        data = self.infile.read(end - start)</span>
<span class="gi">+        return self.codec.decompress(data)</span>


<span class="w"> </span>try:
<span class="w"> </span>    import snappy
<span class="gd">-    snappy.compress(b&#39;&#39;)</span>
<span class="gd">-    register_compression(&#39;snappy&#39;, SnappyFile, [])</span>
<span class="gi">+</span>
<span class="gi">+    snappy.compress(b&quot;&quot;)</span>
<span class="gi">+    # Snappy may use the .sz file extension, but this is not part of the</span>
<span class="gi">+    # standard implementation.</span>
<span class="gi">+    register_compression(&quot;snappy&quot;, SnappyFile, [])</span>
<span class="gi">+</span>
<span class="w"> </span>except (ImportError, NameError, AttributeError):
<span class="w"> </span>    pass
<span class="gi">+</span>
<span class="w"> </span>try:
<span class="w"> </span>    import lz4.frame
<span class="gd">-    register_compression(&#39;lz4&#39;, lz4.frame.open, &#39;lz4&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    register_compression(&quot;lz4&quot;, lz4.frame.open, &quot;lz4&quot;)</span>
<span class="w"> </span>except ImportError:
<span class="w"> </span>    pass
<span class="gi">+</span>
<span class="w"> </span>try:
<span class="w"> </span>    import zstandard as zstd
<span class="gd">-    register_compression(&#39;zstd&#39;, zstandard_file, &#39;zst&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    def zstandard_file(infile, mode=&quot;rb&quot;):</span>
<span class="gi">+        if &quot;r&quot; in mode:</span>
<span class="gi">+            cctx = zstd.ZstdDecompressor()</span>
<span class="gi">+            return cctx.stream_reader(infile)</span>
<span class="gi">+        else:</span>
<span class="gi">+            cctx = zstd.ZstdCompressor(level=10)</span>
<span class="gi">+            return cctx.stream_writer(infile)</span>
<span class="gi">+</span>
<span class="gi">+    register_compression(&quot;zstd&quot;, zstandard_file, &quot;zst&quot;)</span>
<span class="w"> </span>except ImportError:
<span class="w"> </span>    pass


<span class="w"> </span>def available_compressions():
<span class="w"> </span>    &quot;&quot;&quot;Return a list of the implemented compressions.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return list(compr)</span>
<span class="gh">diff --git a/fsspec/config.py b/fsspec/config.py</span>
<span class="gh">index 00a7d90..76d9af1 100644</span>
<span class="gd">--- a/fsspec/config.py</span>
<span class="gi">+++ b/fsspec/config.py</span>
<span class="gu">@@ -1,12 +1,14 @@</span>
<span class="w"> </span>from __future__ import annotations
<span class="gi">+</span>
<span class="w"> </span>import configparser
<span class="w"> </span>import json
<span class="w"> </span>import os
<span class="w"> </span>import warnings
<span class="w"> </span>from typing import Any
<span class="gi">+</span>
<span class="w"> </span>conf: dict[str, dict[str, Any]] = {}
<span class="gd">-default_conf_dir = os.path.join(os.path.expanduser(&#39;~&#39;), &#39;.config/fsspec&#39;)</span>
<span class="gd">-conf_dir = os.environ.get(&#39;FSSPEC_CONFIG_DIR&#39;, default_conf_dir)</span>
<span class="gi">+default_conf_dir = os.path.join(os.path.expanduser(&quot;~&quot;), &quot;.config/fsspec&quot;)</span>
<span class="gi">+conf_dir = os.environ.get(&quot;FSSPEC_CONFIG_DIR&quot;, default_conf_dir)</span>


<span class="w"> </span>def set_conf_env(conf_dict, envdict=os.environ):
<span class="gu">@@ -28,7 +30,35 @@ def set_conf_env(conf_dict, envdict=os.environ):</span>
<span class="w"> </span>    envdict : dict-like(str, str)
<span class="w"> </span>        Source for the values - usually the real environment
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    kwarg_keys = []</span>
<span class="gi">+    for key in envdict:</span>
<span class="gi">+        if key.startswith(&quot;FSSPEC_&quot;) and len(key) &gt; 7 and key[7] != &quot;_&quot;:</span>
<span class="gi">+            if key.count(&quot;_&quot;) &gt; 1:</span>
<span class="gi">+                kwarg_keys.append(key)</span>
<span class="gi">+                continue</span>
<span class="gi">+            try:</span>
<span class="gi">+                value = json.loads(envdict[key])</span>
<span class="gi">+            except json.decoder.JSONDecodeError as ex:</span>
<span class="gi">+                warnings.warn(</span>
<span class="gi">+                    f&quot;Ignoring environment variable {key} due to a parse failure: {ex}&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+            else:</span>
<span class="gi">+                if isinstance(value, dict):</span>
<span class="gi">+                    _, proto = key.split(&quot;_&quot;, 1)</span>
<span class="gi">+                    conf_dict.setdefault(proto.lower(), {}).update(value)</span>
<span class="gi">+                else:</span>
<span class="gi">+                    warnings.warn(</span>
<span class="gi">+                        f&quot;Ignoring environment variable {key} due to not being a dict:&quot;</span>
<span class="gi">+                        f&quot; {type(value)}&quot;</span>
<span class="gi">+                    )</span>
<span class="gi">+        elif key.startswith(&quot;FSSPEC&quot;):</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                f&quot;Ignoring environment variable {key} due to having an unexpected name&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    for key in kwarg_keys:</span>
<span class="gi">+        _, proto, kwarg = key.split(&quot;_&quot;, 2)</span>
<span class="gi">+        conf_dict.setdefault(proto.lower(), {})[kwarg.lower()] = envdict[key]</span>


<span class="w"> </span>def set_conf_files(cdir, conf_dict):
<span class="gu">@@ -48,7 +78,22 @@ def set_conf_files(cdir, conf_dict):</span>
<span class="w"> </span>    conf_dict : dict(str, dict)
<span class="w"> </span>        This dict will be mutated
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not os.path.isdir(cdir):</span>
<span class="gi">+        return</span>
<span class="gi">+    allfiles = sorted(os.listdir(cdir))</span>
<span class="gi">+    for fn in allfiles:</span>
<span class="gi">+        if fn.endswith(&quot;.ini&quot;):</span>
<span class="gi">+            ini = configparser.ConfigParser()</span>
<span class="gi">+            ini.read(os.path.join(cdir, fn))</span>
<span class="gi">+            for key in ini:</span>
<span class="gi">+                if key == &quot;DEFAULT&quot;:</span>
<span class="gi">+                    continue</span>
<span class="gi">+                conf_dict.setdefault(key, {}).update(dict(ini[key]))</span>
<span class="gi">+        if fn.endswith(&quot;.json&quot;):</span>
<span class="gi">+            with open(os.path.join(cdir, fn)) as f:</span>
<span class="gi">+                js = json.load(f)</span>
<span class="gi">+            for key in js:</span>
<span class="gi">+                conf_dict.setdefault(key, {}).update(dict(js[key]))</span>


<span class="w"> </span>def apply_config(cls, kwargs, conf_dict=None):
<span class="gu">@@ -68,7 +113,18 @@ def apply_config(cls, kwargs, conf_dict=None):</span>
<span class="w"> </span>    -------
<span class="w"> </span>    dict : the modified set of kwargs
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if conf_dict is None:</span>
<span class="gi">+        conf_dict = conf</span>
<span class="gi">+    protos = cls.protocol if isinstance(cls.protocol, (tuple, list)) else [cls.protocol]</span>
<span class="gi">+    kw = {}</span>
<span class="gi">+    for proto in protos:</span>
<span class="gi">+        # default kwargs from the current state of the config</span>
<span class="gi">+        if proto in conf_dict:</span>
<span class="gi">+            kw.update(conf_dict[proto])</span>
<span class="gi">+    # explicit kwargs always win</span>
<span class="gi">+    kw.update(**kwargs)</span>
<span class="gi">+    kwargs = kw</span>
<span class="gi">+    return kwargs</span>


<span class="w"> </span>set_conf_files(conf_dir, conf)
<span class="gh">diff --git a/fsspec/core.py b/fsspec/core.py</span>
<span class="gh">index 0ba5d69..bd4f98d 100644</span>
<span class="gd">--- a/fsspec/core.py</span>
<span class="gi">+++ b/fsspec/core.py</span>
<span class="gu">@@ -1,16 +1,32 @@</span>
<span class="w"> </span>from __future__ import annotations
<span class="gi">+</span>
<span class="w"> </span>import io
<span class="w"> </span>import logging
<span class="w"> </span>import os
<span class="w"> </span>import re
<span class="w"> </span>from glob import has_magic
<span class="w"> </span>from pathlib import Path
<span class="gd">-from fsspec.caching import BaseCache, BlockCache, BytesCache, MMapCache, ReadAheadCache, caches</span>
<span class="gi">+</span>
<span class="gi">+# for backwards compat, we export cache things from here too</span>
<span class="gi">+from fsspec.caching import (  # noqa: F401</span>
<span class="gi">+    BaseCache,</span>
<span class="gi">+    BlockCache,</span>
<span class="gi">+    BytesCache,</span>
<span class="gi">+    MMapCache,</span>
<span class="gi">+    ReadAheadCache,</span>
<span class="gi">+    caches,</span>
<span class="gi">+)</span>
<span class="w"> </span>from fsspec.compression import compr
<span class="w"> </span>from fsspec.config import conf
<span class="w"> </span>from fsspec.registry import filesystem, get_filesystem_class
<span class="gd">-from fsspec.utils import _unstrip_protocol, build_name_function, infer_compression, stringify_path</span>
<span class="gd">-logger = logging.getLogger(&#39;fsspec&#39;)</span>
<span class="gi">+from fsspec.utils import (</span>
<span class="gi">+    _unstrip_protocol,</span>
<span class="gi">+    build_name_function,</span>
<span class="gi">+    infer_compression,</span>
<span class="gi">+    stringify_path,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="gi">+logger = logging.getLogger(&quot;fsspec&quot;)</span>


<span class="w"> </span>class OpenFile:
<span class="gu">@@ -46,8 +62,16 @@ class OpenFile:</span>
<span class="w"> </span>        If given and autoopen is True, seek to this location immediately
<span class="w"> </span>    &quot;&quot;&quot;

<span class="gd">-    def __init__(self, fs, path, mode=&#39;rb&#39;, compression=None, encoding=None,</span>
<span class="gd">-        errors=None, newline=None):</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        fs,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        compression=None,</span>
<span class="gi">+        encoding=None,</span>
<span class="gi">+        errors=None,</span>
<span class="gi">+        newline=None,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        self.fs = fs
<span class="w"> </span>        self.path = path
<span class="w"> </span>        self.mode = mode
<span class="gu">@@ -58,39 +82,61 @@ class OpenFile:</span>
<span class="w"> </span>        self.fobjects = []

<span class="w"> </span>    def __reduce__(self):
<span class="gd">-        return OpenFile, (self.fs, self.path, self.mode, self.compression,</span>
<span class="gd">-            self.encoding, self.errors, self.newline)</span>
<span class="gi">+        return (</span>
<span class="gi">+            OpenFile,</span>
<span class="gi">+            (</span>
<span class="gi">+                self.fs,</span>
<span class="gi">+                self.path,</span>
<span class="gi">+                self.mode,</span>
<span class="gi">+                self.compression,</span>
<span class="gi">+                self.encoding,</span>
<span class="gi">+                self.errors,</span>
<span class="gi">+                self.newline,</span>
<span class="gi">+            ),</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def __repr__(self):
<span class="w"> </span>        return f&quot;&lt;OpenFile &#39;{self.path}&#39;&gt;&quot;

<span class="w"> </span>    def __enter__(self):
<span class="gd">-        mode = self.mode.replace(&#39;t&#39;, &#39;&#39;).replace(&#39;b&#39;, &#39;&#39;) + &#39;b&#39;</span>
<span class="gi">+        mode = self.mode.replace(&quot;t&quot;, &quot;&quot;).replace(&quot;b&quot;, &quot;&quot;) + &quot;b&quot;</span>
<span class="gi">+</span>
<span class="w"> </span>        try:
<span class="w"> </span>            f = self.fs.open(self.path, mode=mode)
<span class="w"> </span>        except FileNotFoundError as e:
<span class="w"> </span>            if has_magic(self.path):
<span class="w"> </span>                raise FileNotFoundError(
<span class="gd">-                    &quot;&quot;&quot;%s not found. The URL contains glob characters: you maybe needed</span>
<span class="gd">-to pass expand=True in fsspec.open() or the storage_options of </span>
<span class="gd">-your library. You can also set the config value &#39;open_expand&#39;</span>
<span class="gd">-before import, or fsspec.core.DEFAULT_EXPAND at runtime, to True.&quot;&quot;&quot;</span>
<span class="gd">-                    , self.path) from e</span>
<span class="gi">+                    &quot;%s not found. The URL contains glob characters: you maybe needed\n&quot;</span>
<span class="gi">+                    &quot;to pass expand=True in fsspec.open() or the storage_options of \n&quot;</span>
<span class="gi">+                    &quot;your library. You can also set the config value &#39;open_expand&#39;\n&quot;</span>
<span class="gi">+                    &quot;before import, or fsspec.core.DEFAULT_EXPAND at runtime, to True.&quot;,</span>
<span class="gi">+                    self.path,</span>
<span class="gi">+                ) from e</span>
<span class="w"> </span>            raise
<span class="gi">+</span>
<span class="w"> </span>        self.fobjects = [f]
<span class="gi">+</span>
<span class="w"> </span>        if self.compression is not None:
<span class="w"> </span>            compress = compr[self.compression]
<span class="w"> </span>            f = compress(f, mode=mode[0])
<span class="w"> </span>            self.fobjects.append(f)
<span class="gd">-        if &#39;b&#39; not in self.mode:</span>
<span class="gd">-            f = PickleableTextIOWrapper(f, encoding=self.encoding, errors=</span>
<span class="gd">-                self.errors, newline=self.newline)</span>
<span class="gi">+</span>
<span class="gi">+        if &quot;b&quot; not in self.mode:</span>
<span class="gi">+            # assume, for example, that &#39;r&#39; is equivalent to &#39;rt&#39; as in builtin</span>
<span class="gi">+            f = PickleableTextIOWrapper(</span>
<span class="gi">+                f, encoding=self.encoding, errors=self.errors, newline=self.newline</span>
<span class="gi">+            )</span>
<span class="w"> </span>            self.fobjects.append(f)
<span class="gi">+</span>
<span class="w"> </span>        return self.fobjects[-1]

<span class="w"> </span>    def __exit__(self, *args):
<span class="w"> </span>        self.close()

<span class="gi">+    @property</span>
<span class="gi">+    def full_name(self):</span>
<span class="gi">+        return _unstrip_protocol(self.path, self.fs)</span>
<span class="gi">+</span>
<span class="w"> </span>    def open(self):
<span class="w"> </span>        &quot;&quot;&quot;Materialise this as a real open file without context

<span class="gu">@@ -98,11 +144,15 @@ before import, or fsspec.core.DEFAULT_EXPAND at runtime, to True.&quot;&quot;&quot;</span>
<span class="w"> </span>        instances persisting. You must, therefore, keep a reference to the OpenFile
<span class="w"> </span>        during the life of the file-like it generates.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.__enter__()</span>

<span class="w"> </span>    def close(self):
<span class="w"> </span>        &quot;&quot;&quot;Close all encapsulated file objects&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        for f in reversed(self.fobjects):</span>
<span class="gi">+            if &quot;r&quot; not in self.mode and not f.closed:</span>
<span class="gi">+                f.flush()</span>
<span class="gi">+            f.close()</span>
<span class="gi">+        self.fobjects.clear()</span>


<span class="w"> </span>class OpenFiles(list):
<span class="gu">@@ -117,7 +167,7 @@ class OpenFiles(list):</span>
<span class="w"> </span>    this may happen concurrently, if the target filesystem supports it.
<span class="w"> </span>    &quot;&quot;&quot;

<span class="gd">-    def __init__(self, *args, mode=&#39;rb&#39;, fs=None):</span>
<span class="gi">+    def __init__(self, *args, mode=&quot;rb&quot;, fs=None):</span>
<span class="w"> </span>        self.mode = mode
<span class="w"> </span>        self.fs = fs
<span class="w"> </span>        self.files = []
<span class="gu">@@ -125,13 +175,15 @@ class OpenFiles(list):</span>

<span class="w"> </span>    def __enter__(self):
<span class="w"> </span>        if self.fs is None:
<span class="gd">-            raise ValueError(&#39;Context has already been used&#39;)</span>
<span class="gi">+            raise ValueError(&quot;Context has already been used&quot;)</span>
<span class="gi">+</span>
<span class="w"> </span>        fs = self.fs
<span class="w"> </span>        while True:
<span class="gd">-            if hasattr(fs, &#39;open_many&#39;):</span>
<span class="gi">+            if hasattr(fs, &quot;open_many&quot;):</span>
<span class="gi">+                # check for concurrent cache download; or set up for upload</span>
<span class="w"> </span>                self.files = fs.open_many(self)
<span class="w"> </span>                return self.files
<span class="gd">-            if hasattr(fs, &#39;fs&#39;) and fs.fs is not None:</span>
<span class="gi">+            if hasattr(fs, &quot;fs&quot;) and fs.fs is not None:</span>
<span class="w"> </span>                fs = fs.fs
<span class="w"> </span>            else:
<span class="w"> </span>                break
<span class="gu">@@ -140,12 +192,13 @@ class OpenFiles(list):</span>
<span class="w"> </span>    def __exit__(self, *args):
<span class="w"> </span>        fs = self.fs
<span class="w"> </span>        [s.__exit__(*args) for s in self]
<span class="gd">-        if &#39;r&#39; not in self.mode:</span>
<span class="gi">+        if &quot;r&quot; not in self.mode:</span>
<span class="w"> </span>            while True:
<span class="gd">-                if hasattr(fs, &#39;open_many&#39;):</span>
<span class="gi">+                if hasattr(fs, &quot;open_many&quot;):</span>
<span class="gi">+                    # check for concurrent cache upload</span>
<span class="w"> </span>                    fs.commit_many(self.files)
<span class="w"> </span>                    return
<span class="gd">-                if hasattr(fs, &#39;fs&#39;) and fs.fs is not None:</span>
<span class="gi">+                if hasattr(fs, &quot;fs&quot;) and fs.fs is not None:</span>
<span class="w"> </span>                    fs = fs.fs
<span class="w"> </span>                else:
<span class="w"> </span>                    break
<span class="gu">@@ -157,12 +210,23 @@ class OpenFiles(list):</span>
<span class="w"> </span>        return out

<span class="w"> </span>    def __repr__(self):
<span class="gd">-        return f&#39;&lt;List of {len(self)} OpenFile instances&gt;&#39;</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def open_files(urlpath, mode=&#39;rb&#39;, compression=None, encoding=&#39;utf8&#39;,</span>
<span class="gd">-    errors=None, name_function=None, num=1, protocol=None, newline=None,</span>
<span class="gd">-    auto_mkdir=True, expand=True, **kwargs):</span>
<span class="gi">+        return f&quot;&lt;List of {len(self)} OpenFile instances&gt;&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def open_files(</span>
<span class="gi">+    urlpath,</span>
<span class="gi">+    mode=&quot;rb&quot;,</span>
<span class="gi">+    compression=None,</span>
<span class="gi">+    encoding=&quot;utf8&quot;,</span>
<span class="gi">+    errors=None,</span>
<span class="gi">+    name_function=None,</span>
<span class="gi">+    num=1,</span>
<span class="gi">+    protocol=None,</span>
<span class="gi">+    newline=None,</span>
<span class="gi">+    auto_mkdir=True,</span>
<span class="gi">+    expand=True,</span>
<span class="gi">+    **kwargs,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;Given a path or paths, return a list of ``OpenFile`` objects.

<span class="w"> </span>    For writing, a str path must contain the &quot;*&quot; character, which will be filled
<span class="gu">@@ -228,7 +292,71 @@ def open_files(urlpath, mode=&#39;rb&#39;, compression=None, encoding=&#39;utf8&#39;,</span>
<span class="w"> </span>    - For implementations in separate packages see
<span class="w"> </span>      https://filesystem-spec.readthedocs.io/en/latest/api.html#other-known-implementations
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    fs, fs_token, paths = get_fs_token_paths(</span>
<span class="gi">+        urlpath,</span>
<span class="gi">+        mode,</span>
<span class="gi">+        num=num,</span>
<span class="gi">+        name_function=name_function,</span>
<span class="gi">+        storage_options=kwargs,</span>
<span class="gi">+        protocol=protocol,</span>
<span class="gi">+        expand=expand,</span>
<span class="gi">+    )</span>
<span class="gi">+    if fs.protocol == &quot;file&quot;:</span>
<span class="gi">+        fs.auto_mkdir = auto_mkdir</span>
<span class="gi">+    elif &quot;r&quot; not in mode and auto_mkdir:</span>
<span class="gi">+        parents = {fs._parent(path) for path in paths}</span>
<span class="gi">+        for parent in parents:</span>
<span class="gi">+            try:</span>
<span class="gi">+                fs.makedirs(parent, exist_ok=True)</span>
<span class="gi">+            except PermissionError:</span>
<span class="gi">+                pass</span>
<span class="gi">+    return OpenFiles(</span>
<span class="gi">+        [</span>
<span class="gi">+            OpenFile(</span>
<span class="gi">+                fs,</span>
<span class="gi">+                path,</span>
<span class="gi">+                mode=mode,</span>
<span class="gi">+                compression=compression,</span>
<span class="gi">+                encoding=encoding,</span>
<span class="gi">+                errors=errors,</span>
<span class="gi">+                newline=newline,</span>
<span class="gi">+            )</span>
<span class="gi">+            for path in paths</span>
<span class="gi">+        ],</span>
<span class="gi">+        mode=mode,</span>
<span class="gi">+        fs=fs,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _un_chain(path, kwargs):</span>
<span class="gi">+    x = re.compile(&quot;.*[^a-z]+.*&quot;)  # test for non protocol-like single word</span>
<span class="gi">+    bits = (</span>
<span class="gi">+        [p if &quot;://&quot; in p or x.match(p) else p + &quot;://&quot; for p in path.split(&quot;::&quot;)]</span>
<span class="gi">+        if &quot;::&quot; in path</span>
<span class="gi">+        else [path]</span>
<span class="gi">+    )</span>
<span class="gi">+    # [[url, protocol, kwargs], ...]</span>
<span class="gi">+    out = []</span>
<span class="gi">+    previous_bit = None</span>
<span class="gi">+    kwargs = kwargs.copy()</span>
<span class="gi">+    for bit in reversed(bits):</span>
<span class="gi">+        protocol = kwargs.pop(&quot;protocol&quot;, None) or split_protocol(bit)[0] or &quot;file&quot;</span>
<span class="gi">+        cls = get_filesystem_class(protocol)</span>
<span class="gi">+        extra_kwargs = cls._get_kwargs_from_urls(bit)</span>
<span class="gi">+        kws = kwargs.pop(protocol, {})</span>
<span class="gi">+        if bit is bits[0]:</span>
<span class="gi">+            kws.update(kwargs)</span>
<span class="gi">+        kw = dict(**extra_kwargs, **kws)</span>
<span class="gi">+        bit = cls._strip_protocol(bit)</span>
<span class="gi">+        if (</span>
<span class="gi">+            protocol in {&quot;blockcache&quot;, &quot;filecache&quot;, &quot;simplecache&quot;}</span>
<span class="gi">+            and &quot;target_protocol&quot; not in kw</span>
<span class="gi">+        ):</span>
<span class="gi">+            bit = previous_bit</span>
<span class="gi">+        out.append((bit, protocol, kw))</span>
<span class="gi">+        previous_bit = bit</span>
<span class="gi">+    out.reverse()</span>
<span class="gi">+    return out</span>


<span class="w"> </span>def url_to_fs(url, **kwargs):
<span class="gu">@@ -251,14 +379,50 @@ def url_to_fs(url, **kwargs):</span>
<span class="w"> </span>    urlpath : str
<span class="w"> </span>        The file-systems-specific URL for ``url``.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-DEFAULT_EXPAND = conf.get(&#39;open_expand&#39;, False)</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def open(urlpath, mode=&#39;rb&#39;, compression=None, encoding=&#39;utf8&#39;, errors=None,</span>
<span class="gd">-    protocol=None, newline=None, expand=None, **kwargs):</span>
<span class="gi">+    url = stringify_path(url)</span>
<span class="gi">+    # non-FS arguments that appear in fsspec.open()</span>
<span class="gi">+    # inspect could keep this in sync with open()&#39;s signature</span>
<span class="gi">+    known_kwargs = {</span>
<span class="gi">+        &quot;compression&quot;,</span>
<span class="gi">+        &quot;encoding&quot;,</span>
<span class="gi">+        &quot;errors&quot;,</span>
<span class="gi">+        &quot;expand&quot;,</span>
<span class="gi">+        &quot;mode&quot;,</span>
<span class="gi">+        &quot;name_function&quot;,</span>
<span class="gi">+        &quot;newline&quot;,</span>
<span class="gi">+        &quot;num&quot;,</span>
<span class="gi">+    }</span>
<span class="gi">+    kwargs = {k: v for k, v in kwargs.items() if k not in known_kwargs}</span>
<span class="gi">+    chain = _un_chain(url, kwargs)</span>
<span class="gi">+    inkwargs = {}</span>
<span class="gi">+    # Reverse iterate the chain, creating a nested target_* structure</span>
<span class="gi">+    for i, ch in enumerate(reversed(chain)):</span>
<span class="gi">+        urls, protocol, kw = ch</span>
<span class="gi">+        if i == len(chain) - 1:</span>
<span class="gi">+            inkwargs = dict(**kw, **inkwargs)</span>
<span class="gi">+            continue</span>
<span class="gi">+        inkwargs[&quot;target_options&quot;] = dict(**kw, **inkwargs)</span>
<span class="gi">+        inkwargs[&quot;target_protocol&quot;] = protocol</span>
<span class="gi">+        inkwargs[&quot;fo&quot;] = urls</span>
<span class="gi">+    urlpath, protocol, _ = chain[0]</span>
<span class="gi">+    fs = filesystem(protocol, **inkwargs)</span>
<span class="gi">+    return fs, urlpath</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+DEFAULT_EXPAND = conf.get(&quot;open_expand&quot;, False)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def open(</span>
<span class="gi">+    urlpath,</span>
<span class="gi">+    mode=&quot;rb&quot;,</span>
<span class="gi">+    compression=None,</span>
<span class="gi">+    encoding=&quot;utf8&quot;,</span>
<span class="gi">+    errors=None,</span>
<span class="gi">+    protocol=None,</span>
<span class="gi">+    newline=None,</span>
<span class="gi">+    expand=None,</span>
<span class="gi">+    **kwargs,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;Given a path or paths, return one ``OpenFile`` object.

<span class="w"> </span>    Parameters
<span class="gu">@@ -316,11 +480,28 @@ def open(urlpath, mode=&#39;rb&#39;, compression=None, encoding=&#39;utf8&#39;, errors=None,</span>
<span class="w"> </span>    - For implementations in separate packages see
<span class="w"> </span>      https://filesystem-spec.readthedocs.io/en/latest/api.html#other-known-implementations
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def open_local(url: (str | list[str] | Path | list[Path]), mode: str=&#39;rb&#39;,</span>
<span class="gd">-    **storage_options: dict) -&gt;(str | list[str]):</span>
<span class="gi">+    expand = DEFAULT_EXPAND if expand is None else expand</span>
<span class="gi">+    out = open_files(</span>
<span class="gi">+        urlpath=[urlpath],</span>
<span class="gi">+        mode=mode,</span>
<span class="gi">+        compression=compression,</span>
<span class="gi">+        encoding=encoding,</span>
<span class="gi">+        errors=errors,</span>
<span class="gi">+        protocol=protocol,</span>
<span class="gi">+        newline=newline,</span>
<span class="gi">+        expand=expand,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    )</span>
<span class="gi">+    if not out:</span>
<span class="gi">+        raise FileNotFoundError(urlpath)</span>
<span class="gi">+    return out[0]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def open_local(</span>
<span class="gi">+    url: str | list[str] | Path | list[Path],</span>
<span class="gi">+    mode: str = &quot;rb&quot;,</span>
<span class="gi">+    **storage_options: dict,</span>
<span class="gi">+) -&gt; str | list[str]:</span>
<span class="w"> </span>    &quot;&quot;&quot;Open file(s) which can be resolved to local

<span class="w"> </span>    For files which either are local, or get downloaded upon open
<span class="gu">@@ -334,17 +515,47 @@ def open_local(url: (str | list[str] | Path | list[Path]), mode: str=&#39;rb&#39;,</span>
<span class="w"> </span>    storage_options:
<span class="w"> </span>        passed on to FS for or used by open_files (e.g., compression)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if &quot;r&quot; not in mode:</span>
<span class="gi">+        raise ValueError(&quot;Can only ensure local files when reading&quot;)</span>
<span class="gi">+    of = open_files(url, mode=mode, **storage_options)</span>
<span class="gi">+    if not getattr(of[0].fs, &quot;local_file&quot;, False):</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &quot;open_local can only be used on a filesystem which&quot;</span>
<span class="gi">+            &quot; has attribute local_file=True&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+    with of as files:</span>
<span class="gi">+        paths = [f.name for f in files]</span>
<span class="gi">+    if (isinstance(url, str) and not has_magic(url)) or isinstance(url, Path):</span>
<span class="gi">+        return paths[0]</span>
<span class="gi">+    return paths</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def get_compression(urlpath, compression):</span>
<span class="gi">+    if compression == &quot;infer&quot;:</span>
<span class="gi">+        compression = infer_compression(urlpath)</span>
<span class="gi">+    if compression is not None and compression not in compr:</span>
<span class="gi">+        raise ValueError(f&quot;Compression type {compression} not supported&quot;)</span>
<span class="gi">+    return compression</span>


<span class="w"> </span>def split_protocol(urlpath):
<span class="w"> </span>    &quot;&quot;&quot;Return protocol, path pair&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    urlpath = stringify_path(urlpath)</span>
<span class="gi">+    if &quot;://&quot; in urlpath:</span>
<span class="gi">+        protocol, path = urlpath.split(&quot;://&quot;, 1)</span>
<span class="gi">+        if len(protocol) &gt; 1:</span>
<span class="gi">+            # excludes Windows paths</span>
<span class="gi">+            return protocol, path</span>
<span class="gi">+    if urlpath.startswith(&quot;data:&quot;):</span>
<span class="gi">+        return urlpath.split(&quot;:&quot;, 1)</span>
<span class="gi">+    return None, urlpath</span>


<span class="w"> </span>def strip_protocol(urlpath):
<span class="w"> </span>    &quot;&quot;&quot;Return only path part of full URL, according to appropriate backend&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    protocol, _ = split_protocol(urlpath)</span>
<span class="gi">+    cls = get_filesystem_class(protocol)</span>
<span class="gi">+    return cls._strip_protocol(urlpath)</span>


<span class="w"> </span>def expand_paths_if_needed(paths, mode, num, fs, name_function):
<span class="gu">@@ -363,11 +574,46 @@ def expand_paths_if_needed(paths, mode, num, fs, name_function):</span>
<span class="w"> </span>        ``urlpath.replace(&#39;*&#39;, name_function(partition_index))``.
<span class="w"> </span>    :return: list of paths
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    expanded_paths = []</span>
<span class="gi">+    paths = list(paths)</span>
<span class="gi">+</span>
<span class="gi">+    if &quot;w&quot; in mode:  # read mode</span>
<span class="gi">+        if sum([1 for p in paths if &quot;*&quot; in p]) &gt; 1:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;When writing data, only one filename mask can be specified.&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        num = max(num, len(paths))</span>
<span class="gi">+</span>
<span class="gi">+        for curr_path in paths:</span>
<span class="gi">+            if &quot;*&quot; in curr_path:</span>
<span class="gi">+                # expand using name_function</span>
<span class="gi">+                expanded_paths.extend(_expand_paths(curr_path, name_function, num))</span>
<span class="gi">+            else:</span>
<span class="gi">+                expanded_paths.append(curr_path)</span>
<span class="gi">+        # if we generated more paths that asked for, trim the list</span>
<span class="gi">+        if len(expanded_paths) &gt; num:</span>
<span class="gi">+            expanded_paths = expanded_paths[:num]</span>
<span class="gi">+</span>
<span class="gi">+    else:  # read mode</span>
<span class="gi">+        for curr_path in paths:</span>
<span class="gi">+            if has_magic(curr_path):</span>
<span class="gi">+                # expand using glob</span>
<span class="gi">+                expanded_paths.extend(fs.glob(curr_path))</span>
<span class="gi">+            else:</span>
<span class="gi">+                expanded_paths.append(curr_path)</span>
<span class="gi">+</span>
<span class="gi">+    return expanded_paths</span>


<span class="gd">-def get_fs_token_paths(urlpath, mode=&#39;rb&#39;, num=1, name_function=None,</span>
<span class="gd">-    storage_options=None, protocol=None, expand=True):</span>
<span class="gi">+def get_fs_token_paths(</span>
<span class="gi">+    urlpath,</span>
<span class="gi">+    mode=&quot;rb&quot;,</span>
<span class="gi">+    num=1,</span>
<span class="gi">+    name_function=None,</span>
<span class="gi">+    storage_options=None,</span>
<span class="gi">+    protocol=None,</span>
<span class="gi">+    expand=True,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;Filesystem, deterministic token, and paths from a urlpath and options.

<span class="w"> </span>    Parameters
<span class="gu">@@ -390,7 +636,83 @@ def get_fs_token_paths(urlpath, mode=&#39;rb&#39;, num=1, name_function=None,</span>
<span class="w"> </span>    expand: bool
<span class="w"> </span>        Expand string paths for writing, assuming the path is a directory
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(urlpath, (list, tuple, set)):</span>
<span class="gi">+        if not urlpath:</span>
<span class="gi">+            raise ValueError(&quot;empty urlpath sequence&quot;)</span>
<span class="gi">+        urlpath0 = stringify_path(list(urlpath)[0])</span>
<span class="gi">+    else:</span>
<span class="gi">+        urlpath0 = stringify_path(urlpath)</span>
<span class="gi">+    storage_options = storage_options or {}</span>
<span class="gi">+    if protocol:</span>
<span class="gi">+        storage_options[&quot;protocol&quot;] = protocol</span>
<span class="gi">+    chain = _un_chain(urlpath0, storage_options or {})</span>
<span class="gi">+    inkwargs = {}</span>
<span class="gi">+    # Reverse iterate the chain, creating a nested target_* structure</span>
<span class="gi">+    for i, ch in enumerate(reversed(chain)):</span>
<span class="gi">+        urls, nested_protocol, kw = ch</span>
<span class="gi">+        if i == len(chain) - 1:</span>
<span class="gi">+            inkwargs = dict(**kw, **inkwargs)</span>
<span class="gi">+            continue</span>
<span class="gi">+        inkwargs[&quot;target_options&quot;] = dict(**kw, **inkwargs)</span>
<span class="gi">+        inkwargs[&quot;target_protocol&quot;] = nested_protocol</span>
<span class="gi">+        inkwargs[&quot;fo&quot;] = urls</span>
<span class="gi">+    paths, protocol, _ = chain[0]</span>
<span class="gi">+    fs = filesystem(protocol, **inkwargs)</span>
<span class="gi">+    if isinstance(urlpath, (list, tuple, set)):</span>
<span class="gi">+        pchains = [</span>
<span class="gi">+            _un_chain(stringify_path(u), storage_options or {})[0] for u in urlpath</span>
<span class="gi">+        ]</span>
<span class="gi">+        if len({pc[1] for pc in pchains}) &gt; 1:</span>
<span class="gi">+            raise ValueError(&quot;Protocol mismatch getting fs from %s&quot;, urlpath)</span>
<span class="gi">+        paths = [pc[0] for pc in pchains]</span>
<span class="gi">+    else:</span>
<span class="gi">+        paths = fs._strip_protocol(paths)</span>
<span class="gi">+    if isinstance(paths, (list, tuple, set)):</span>
<span class="gi">+        if expand:</span>
<span class="gi">+            paths = expand_paths_if_needed(paths, mode, num, fs, name_function)</span>
<span class="gi">+        elif not isinstance(paths, list):</span>
<span class="gi">+            paths = list(paths)</span>
<span class="gi">+    else:</span>
<span class="gi">+        if &quot;w&quot; in mode and expand:</span>
<span class="gi">+            paths = _expand_paths(paths, name_function, num)</span>
<span class="gi">+        elif &quot;x&quot; in mode and expand:</span>
<span class="gi">+            paths = _expand_paths(paths, name_function, num)</span>
<span class="gi">+        elif &quot;*&quot; in paths:</span>
<span class="gi">+            paths = [f for f in sorted(fs.glob(paths)) if not fs.isdir(f)]</span>
<span class="gi">+        else:</span>
<span class="gi">+            paths = [paths]</span>
<span class="gi">+</span>
<span class="gi">+    return fs, fs._fs_token, paths</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _expand_paths(path, name_function, num):</span>
<span class="gi">+    if isinstance(path, str):</span>
<span class="gi">+        if path.count(&quot;*&quot;) &gt; 1:</span>
<span class="gi">+            raise ValueError(&quot;Output path spec must contain exactly one &#39;*&#39;.&quot;)</span>
<span class="gi">+        elif &quot;*&quot; not in path:</span>
<span class="gi">+            path = os.path.join(path, &quot;*.part&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        if name_function is None:</span>
<span class="gi">+            name_function = build_name_function(num - 1)</span>
<span class="gi">+</span>
<span class="gi">+        paths = [path.replace(&quot;*&quot;, name_function(i)) for i in range(num)]</span>
<span class="gi">+        if paths != sorted(paths):</span>
<span class="gi">+            logger.warning(</span>
<span class="gi">+                &quot;In order to preserve order between partitions&quot;</span>
<span class="gi">+                &quot; paths created with ``name_function`` should &quot;</span>
<span class="gi">+                &quot;sort to partition order&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+    elif isinstance(path, (tuple, list)):</span>
<span class="gi">+        assert len(path) == num</span>
<span class="gi">+        paths = list(path)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &quot;Path should be either\n&quot;</span>
<span class="gi">+            &quot;1. A list of paths: [&#39;foo.json&#39;, &#39;bar.json&#39;, ...]\n&quot;</span>
<span class="gi">+            &quot;2. A directory: &#39;foo/\n&quot;</span>
<span class="gi">+            &quot;3. A path with a &#39;*&#39; in it: &#39;foo.*.json&#39;&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+    return paths</span>


<span class="w"> </span>class PickleableTextIOWrapper(io.TextIOWrapper):
<span class="gu">@@ -400,10 +722,16 @@ class PickleableTextIOWrapper(io.TextIOWrapper):</span>
<span class="w"> </span>    AbstractBufferedFile are.
<span class="w"> </span>    &quot;&quot;&quot;

<span class="gd">-    def __init__(self, buffer, encoding=None, errors=None, newline=None,</span>
<span class="gd">-        line_buffering=False, write_through=False):</span>
<span class="gd">-        self.args = (buffer, encoding, errors, newline, line_buffering,</span>
<span class="gd">-            write_through)</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        buffer,</span>
<span class="gi">+        encoding=None,</span>
<span class="gi">+        errors=None,</span>
<span class="gi">+        newline=None,</span>
<span class="gi">+        line_buffering=False,</span>
<span class="gi">+        write_through=False,</span>
<span class="gi">+    ):</span>
<span class="gi">+        self.args = buffer, encoding, errors, newline, line_buffering, write_through</span>
<span class="w"> </span>        super().__init__(*self.args)

<span class="w"> </span>    def __reduce__(self):
<span class="gh">diff --git a/fsspec/dircache.py b/fsspec/dircache.py</span>
<span class="gh">index b6c92be..eca1956 100644</span>
<span class="gd">--- a/fsspec/dircache.py</span>
<span class="gi">+++ b/fsspec/dircache.py</span>
<span class="gu">@@ -24,8 +24,13 @@ class DirCache(MutableMapping):</span>
<span class="w"> </span>    caching off
<span class="w"> </span>    &quot;&quot;&quot;

<span class="gd">-    def __init__(self, use_listings_cache=True, listings_expiry_time=None,</span>
<span class="gd">-        max_paths=None, **kwargs):</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        use_listings_cache=True,</span>
<span class="gi">+        listings_expiry_time=None,</span>
<span class="gi">+        max_paths=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;

<span class="w"> </span>        Parameters
<span class="gu">@@ -43,20 +48,21 @@ class DirCache(MutableMapping):</span>
<span class="w"> </span>        self._cache = {}
<span class="w"> </span>        self._times = {}
<span class="w"> </span>        if max_paths:
<span class="gd">-            self._q = lru_cache(max_paths + 1)(lambda key: self._cache.pop(</span>
<span class="gd">-                key, None))</span>
<span class="gi">+            self._q = lru_cache(max_paths + 1)(lambda key: self._cache.pop(key, None))</span>
<span class="w"> </span>        self.use_listings_cache = use_listings_cache
<span class="w"> </span>        self.listings_expiry_time = listings_expiry_time
<span class="w"> </span>        self.max_paths = max_paths

<span class="w"> </span>    def __getitem__(self, item):
<span class="w"> </span>        if self.listings_expiry_time is not None:
<span class="gd">-            if self._times.get(item, 0) - time.time(</span>
<span class="gd">-                ) &lt; -self.listings_expiry_time:</span>
<span class="gi">+            if self._times.get(item, 0) - time.time() &lt; -self.listings_expiry_time:</span>
<span class="w"> </span>                del self._cache[item]
<span class="w"> </span>        if self.max_paths:
<span class="w"> </span>            self._q(item)
<span class="gd">-        return self._cache[item]</span>
<span class="gi">+        return self._cache[item]  # maybe raises KeyError</span>
<span class="gi">+</span>
<span class="gi">+    def clear(self):</span>
<span class="gi">+        self._cache.clear()</span>

<span class="w"> </span>    def __len__(self):
<span class="w"> </span>        return len(self._cache)
<span class="gu">@@ -82,8 +88,11 @@ class DirCache(MutableMapping):</span>

<span class="w"> </span>    def __iter__(self):
<span class="w"> </span>        entries = list(self._cache)
<span class="gi">+</span>
<span class="w"> </span>        return (k for k in entries if k in self)

<span class="w"> </span>    def __reduce__(self):
<span class="gd">-        return DirCache, (self.use_listings_cache, self.</span>
<span class="gd">-            listings_expiry_time, self.max_paths)</span>
<span class="gi">+        return (</span>
<span class="gi">+            DirCache,</span>
<span class="gi">+            (self.use_listings_cache, self.listings_expiry_time, self.max_paths),</span>
<span class="gi">+        )</span>
<span class="gh">diff --git a/fsspec/exceptions.py b/fsspec/exceptions.py</span>
<span class="gh">index 0593f0e..ae89054 100644</span>
<span class="gd">--- a/fsspec/exceptions.py</span>
<span class="gi">+++ b/fsspec/exceptions.py</span>
<span class="gu">@@ -1,6 +1,7 @@</span>
<span class="w"> </span>&quot;&quot;&quot;
<span class="w"> </span>fsspec user-defined exception classes
<span class="w"> </span>&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>import asyncio


<span class="gh">diff --git a/fsspec/fuse.py b/fsspec/fuse.py</span>
<span class="gh">index de1075f..6ca8c97 100644</span>
<span class="gd">--- a/fsspec/fuse.py</span>
<span class="gi">+++ b/fsspec/fuse.py</span>
<span class="gu">@@ -5,25 +5,149 @@ import stat</span>
<span class="w"> </span>import threading
<span class="w"> </span>import time
<span class="w"> </span>from errno import EIO, ENOENT
<span class="gi">+</span>
<span class="w"> </span>from fuse import FUSE, FuseOSError, LoggingMixIn, Operations
<span class="gi">+</span>
<span class="w"> </span>from fsspec import __version__
<span class="w"> </span>from fsspec.core import url_to_fs
<span class="gd">-logger = logging.getLogger(&#39;fsspec.fuse&#39;)</span>

<span class="gi">+logger = logging.getLogger(&quot;fsspec.fuse&quot;)</span>

<span class="gd">-class FUSEr(Operations):</span>

<span class="gi">+class FUSEr(Operations):</span>
<span class="w"> </span>    def __init__(self, fs, path, ready_file=False):
<span class="w"> </span>        self.fs = fs
<span class="w"> </span>        self.cache = {}
<span class="gd">-        self.root = path.rstrip(&#39;/&#39;) + &#39;/&#39;</span>
<span class="gi">+        self.root = path.rstrip(&quot;/&quot;) + &quot;/&quot;</span>
<span class="w"> </span>        self.counter = 0
<span class="gd">-        logger.info(&#39;Starting FUSE at %s&#39;, path)</span>
<span class="gi">+        logger.info(&quot;Starting FUSE at %s&quot;, path)</span>
<span class="w"> </span>        self._ready_file = ready_file

<span class="gi">+    def getattr(self, path, fh=None):</span>
<span class="gi">+        logger.debug(&quot;getattr %s&quot;, path)</span>
<span class="gi">+        if self._ready_file and path in [&quot;/.fuse_ready&quot;, &quot;.fuse_ready&quot;]:</span>
<span class="gi">+            return {&quot;type&quot;: &quot;file&quot;, &quot;st_size&quot;: 5}</span>
<span class="gi">+</span>
<span class="gi">+        path = &quot;&quot;.join([self.root, path.lstrip(&quot;/&quot;)]).rstrip(&quot;/&quot;)</span>
<span class="gi">+        try:</span>
<span class="gi">+            info = self.fs.info(path)</span>
<span class="gi">+        except FileNotFoundError:</span>
<span class="gi">+            raise FuseOSError(ENOENT)</span>
<span class="gi">+</span>
<span class="gi">+        data = {&quot;st_uid&quot;: info.get(&quot;uid&quot;, 1000), &quot;st_gid&quot;: info.get(&quot;gid&quot;, 1000)}</span>
<span class="gi">+        perm = info.get(&quot;mode&quot;, 0o777)</span>
<span class="gi">+</span>
<span class="gi">+        if info[&quot;type&quot;] != &quot;file&quot;:</span>
<span class="gi">+            data[&quot;st_mode&quot;] = stat.S_IFDIR | perm</span>
<span class="gi">+            data[&quot;st_size&quot;] = 0</span>
<span class="gi">+            data[&quot;st_blksize&quot;] = 0</span>
<span class="gi">+        else:</span>
<span class="gi">+            data[&quot;st_mode&quot;] = stat.S_IFREG | perm</span>
<span class="gi">+            data[&quot;st_size&quot;] = info[&quot;size&quot;]</span>
<span class="gi">+            data[&quot;st_blksize&quot;] = 5 * 2**20</span>
<span class="gi">+            data[&quot;st_nlink&quot;] = 1</span>
<span class="gi">+        data[&quot;st_atime&quot;] = info[&quot;atime&quot;] if &quot;atime&quot; in info else time.time()</span>
<span class="gi">+        data[&quot;st_ctime&quot;] = info[&quot;ctime&quot;] if &quot;ctime&quot; in info else time.time()</span>
<span class="gi">+        data[&quot;st_mtime&quot;] = info[&quot;mtime&quot;] if &quot;mtime&quot; in info else time.time()</span>
<span class="gi">+        return data</span>
<span class="gi">+</span>
<span class="gi">+    def readdir(self, path, fh):</span>
<span class="gi">+        logger.debug(&quot;readdir %s&quot;, path)</span>
<span class="gi">+        path = &quot;&quot;.join([self.root, path.lstrip(&quot;/&quot;)])</span>
<span class="gi">+        files = self.fs.ls(path, False)</span>
<span class="gi">+        files = [os.path.basename(f.rstrip(&quot;/&quot;)) for f in files]</span>
<span class="gi">+        return [&quot;.&quot;, &quot;..&quot;] + files</span>
<span class="gi">+</span>
<span class="gi">+    def mkdir(self, path, mode):</span>
<span class="gi">+        path = &quot;&quot;.join([self.root, path.lstrip(&quot;/&quot;)])</span>
<span class="gi">+        self.fs.mkdir(path)</span>
<span class="gi">+        return 0</span>
<span class="gi">+</span>
<span class="gi">+    def rmdir(self, path):</span>
<span class="gi">+        path = &quot;&quot;.join([self.root, path.lstrip(&quot;/&quot;)])</span>
<span class="gi">+        self.fs.rmdir(path)</span>
<span class="gi">+        return 0</span>
<span class="gi">+</span>
<span class="gi">+    def read(self, path, size, offset, fh):</span>
<span class="gi">+        logger.debug(&quot;read %s&quot;, (path, size, offset))</span>
<span class="gi">+        if self._ready_file and path in [&quot;/.fuse_ready&quot;, &quot;.fuse_ready&quot;]:</span>
<span class="gi">+            # status indicator</span>
<span class="gi">+            return b&quot;ready&quot;</span>
<span class="gi">+</span>
<span class="gi">+        f = self.cache[fh]</span>
<span class="gi">+        f.seek(offset)</span>
<span class="gi">+        out = f.read(size)</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    def write(self, path, data, offset, fh):</span>
<span class="gi">+        logger.debug(&quot;write %s&quot;, (path, offset))</span>
<span class="gi">+        f = self.cache[fh]</span>
<span class="gi">+        f.seek(offset)</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+        return len(data)</span>
<span class="gi">+</span>
<span class="gi">+    def create(self, path, flags, fi=None):</span>
<span class="gi">+        logger.debug(&quot;create %s&quot;, (path, flags))</span>
<span class="gi">+        fn = &quot;&quot;.join([self.root, path.lstrip(&quot;/&quot;)])</span>
<span class="gi">+        self.fs.touch(fn)  # OS will want to get attributes immediately</span>
<span class="gi">+        f = self.fs.open(fn, &quot;wb&quot;)</span>
<span class="gi">+        self.cache[self.counter] = f</span>
<span class="gi">+        self.counter += 1</span>
<span class="gi">+        return self.counter - 1</span>
<span class="gi">+</span>
<span class="gi">+    def open(self, path, flags):</span>
<span class="gi">+        logger.debug(&quot;open %s&quot;, (path, flags))</span>
<span class="gi">+        fn = &quot;&quot;.join([self.root, path.lstrip(&quot;/&quot;)])</span>
<span class="gi">+        if flags % 2 == 0:</span>
<span class="gi">+            # read</span>
<span class="gi">+            mode = &quot;rb&quot;</span>
<span class="gi">+        else:</span>
<span class="gi">+            # write/create</span>
<span class="gi">+            mode = &quot;wb&quot;</span>
<span class="gi">+        self.cache[self.counter] = self.fs.open(fn, mode)</span>
<span class="gi">+        self.counter += 1</span>
<span class="gi">+        return self.counter - 1</span>

<span class="gd">-def run(fs, path, mount_point, foreground=True, threads=False, ready_file=</span>
<span class="gd">-    False, ops_class=FUSEr):</span>
<span class="gi">+    def truncate(self, path, length, fh=None):</span>
<span class="gi">+        fn = &quot;&quot;.join([self.root, path.lstrip(&quot;/&quot;)])</span>
<span class="gi">+        if length != 0:</span>
<span class="gi">+            raise NotImplementedError</span>
<span class="gi">+        # maybe should be no-op since open with write sets size to zero anyway</span>
<span class="gi">+        self.fs.touch(fn)</span>
<span class="gi">+</span>
<span class="gi">+    def unlink(self, path):</span>
<span class="gi">+        fn = &quot;&quot;.join([self.root, path.lstrip(&quot;/&quot;)])</span>
<span class="gi">+        try:</span>
<span class="gi">+            self.fs.rm(fn, False)</span>
<span class="gi">+        except (OSError, FileNotFoundError):</span>
<span class="gi">+            raise FuseOSError(EIO)</span>
<span class="gi">+</span>
<span class="gi">+    def release(self, path, fh):</span>
<span class="gi">+        try:</span>
<span class="gi">+            if fh in self.cache:</span>
<span class="gi">+                f = self.cache[fh]</span>
<span class="gi">+                f.close()</span>
<span class="gi">+                self.cache.pop(fh)</span>
<span class="gi">+        except Exception as e:</span>
<span class="gi">+            print(e)</span>
<span class="gi">+        return 0</span>
<span class="gi">+</span>
<span class="gi">+    def chmod(self, path, mode):</span>
<span class="gi">+        if hasattr(self.fs, &quot;chmod&quot;):</span>
<span class="gi">+            path = &quot;&quot;.join([self.root, path.lstrip(&quot;/&quot;)])</span>
<span class="gi">+            return self.fs.chmod(path, mode)</span>
<span class="gi">+        raise NotImplementedError</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def run(</span>
<span class="gi">+    fs,</span>
<span class="gi">+    path,</span>
<span class="gi">+    mount_point,</span>
<span class="gi">+    foreground=True,</span>
<span class="gi">+    threads=False,</span>
<span class="gi">+    ready_file=False,</span>
<span class="gi">+    ops_class=FUSEr,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;Mount stuff in a local directory

<span class="w"> </span>    This uses fusepy to make it appear as if a given path on an fsspec
<span class="gu">@@ -59,7 +183,22 @@ def run(fs, path, mount_point, foreground=True, threads=False, ready_file=</span>
<span class="w"> </span>        to file.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    func = lambda: FUSE(</span>
<span class="gi">+        ops_class(fs, path, ready_file=ready_file),</span>
<span class="gi">+        mount_point,</span>
<span class="gi">+        nothreads=not threads,</span>
<span class="gi">+        foreground=foreground,</span>
<span class="gi">+    )</span>
<span class="gi">+    if not foreground:</span>
<span class="gi">+        th = threading.Thread(target=func)</span>
<span class="gi">+        th.daemon = True</span>
<span class="gi">+        th.start()</span>
<span class="gi">+        return th</span>
<span class="gi">+    else:  # pragma: no cover</span>
<span class="gi">+        try:</span>
<span class="gi">+            func()</span>
<span class="gi">+        except KeyboardInterrupt:</span>
<span class="gi">+            pass</span>


<span class="w"> </span>def main(args):
<span class="gu">@@ -89,9 +228,97 @@ def main(args):</span>
<span class="w"> </span>            -o &#39;ftp-username=anonymous&#39; \\
<span class="w"> </span>            -o &#39;ftp-password=xieyanbo&#39;
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>

<span class="gi">+    class RawDescriptionArgumentParser(argparse.ArgumentParser):</span>
<span class="gi">+        def format_help(self):</span>
<span class="gi">+            usage = super().format_help()</span>
<span class="gi">+            parts = usage.split(&quot;\n\n&quot;)</span>
<span class="gi">+            parts[1] = self.description.rstrip()</span>
<span class="gi">+            return &quot;\n\n&quot;.join(parts)</span>
<span class="gi">+</span>
<span class="gi">+    parser = RawDescriptionArgumentParser(prog=&quot;fsspec.fuse&quot;, description=main.__doc__)</span>
<span class="gi">+    parser.add_argument(&quot;--version&quot;, action=&quot;version&quot;, version=__version__)</span>
<span class="gi">+    parser.add_argument(&quot;url&quot;, type=str, help=&quot;fs url&quot;)</span>
<span class="gi">+    parser.add_argument(&quot;source_path&quot;, type=str, help=&quot;source directory in fs&quot;)</span>
<span class="gi">+    parser.add_argument(&quot;mount_point&quot;, type=str, help=&quot;local directory&quot;)</span>
<span class="gi">+    parser.add_argument(</span>
<span class="gi">+        &quot;-o&quot;,</span>
<span class="gi">+        &quot;--option&quot;,</span>
<span class="gi">+        action=&quot;append&quot;,</span>
<span class="gi">+        help=&quot;Any options of protocol included in the chained URL&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+    parser.add_argument(</span>
<span class="gi">+        &quot;-l&quot;, &quot;--log-file&quot;, type=str, help=&quot;Logging FUSE debug info (Default: &#39;&#39;)&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    parser.add_argument(</span>
<span class="gi">+        &quot;-f&quot;,</span>
<span class="gi">+        &quot;--foreground&quot;,</span>
<span class="gi">+        action=&quot;store_false&quot;,</span>
<span class="gi">+        help=&quot;Running in foreground or not (Default: False)&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+    parser.add_argument(</span>
<span class="gi">+        &quot;-t&quot;,</span>
<span class="gi">+        &quot;--threads&quot;,</span>
<span class="gi">+        action=&quot;store_false&quot;,</span>
<span class="gi">+        help=&quot;Running with threads support (Default: False)&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+    parser.add_argument(</span>
<span class="gi">+        &quot;-r&quot;,</span>
<span class="gi">+        &quot;--ready-file&quot;,</span>
<span class="gi">+        action=&quot;store_false&quot;,</span>
<span class="gi">+        help=&quot;The `.fuse_ready` file will exist after FUSE is ready. &quot;</span>
<span class="gi">+        &quot;(Debugging purpose, Default: False)&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+    args = parser.parse_args(args)</span>
<span class="gi">+</span>
<span class="gi">+    kwargs = {}</span>
<span class="gi">+    for item in args.option or []:</span>
<span class="gi">+        key, sep, value = item.partition(&quot;=&quot;)</span>
<span class="gi">+        if not sep:</span>
<span class="gi">+            parser.error(message=f&quot;Wrong option: {item!r}&quot;)</span>
<span class="gi">+        val = value.lower()</span>
<span class="gi">+        if val.endswith(&quot;[int]&quot;):</span>
<span class="gi">+            value = int(value[: -len(&quot;[int]&quot;)])</span>
<span class="gi">+        elif val.endswith(&quot;[bool]&quot;):</span>
<span class="gi">+            value = val[: -len(&quot;[bool]&quot;)] in [&quot;1&quot;, &quot;yes&quot;, &quot;true&quot;]</span>

<span class="gd">-if __name__ == &#39;__main__&#39;:</span>
<span class="gi">+        if &quot;-&quot; in key:</span>
<span class="gi">+            fs_name, setting_name = key.split(&quot;-&quot;, 1)</span>
<span class="gi">+            if fs_name in kwargs:</span>
<span class="gi">+                kwargs[fs_name][setting_name] = value</span>
<span class="gi">+            else:</span>
<span class="gi">+                kwargs[fs_name] = {setting_name: value}</span>
<span class="gi">+        else:</span>
<span class="gi">+            kwargs[key] = value</span>
<span class="gi">+</span>
<span class="gi">+    if args.log_file:</span>
<span class="gi">+        logging.basicConfig(</span>
<span class="gi">+            level=logging.DEBUG,</span>
<span class="gi">+            filename=args.log_file,</span>
<span class="gi">+            format=&quot;%(asctime)s %(message)s&quot;,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        class LoggingFUSEr(FUSEr, LoggingMixIn):</span>
<span class="gi">+            pass</span>
<span class="gi">+</span>
<span class="gi">+        fuser = LoggingFUSEr</span>
<span class="gi">+    else:</span>
<span class="gi">+        fuser = FUSEr</span>
<span class="gi">+</span>
<span class="gi">+    fs, url_path = url_to_fs(args.url, **kwargs)</span>
<span class="gi">+    logger.debug(&quot;Mounting %s to %s&quot;, url_path, str(args.mount_point))</span>
<span class="gi">+    run(</span>
<span class="gi">+        fs,</span>
<span class="gi">+        args.source_path,</span>
<span class="gi">+        args.mount_point,</span>
<span class="gi">+        foreground=args.foreground,</span>
<span class="gi">+        threads=args.threads,</span>
<span class="gi">+        ready_file=args.ready_file,</span>
<span class="gi">+        ops_class=fuser,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+if __name__ == &quot;__main__&quot;:</span>
<span class="w"> </span>    import sys
<span class="gi">+</span>
<span class="w"> </span>    main(sys.argv[1:])
<span class="gh">diff --git a/fsspec/generic.py b/fsspec/generic.py</span>
<span class="gh">index 48ba37c..9bad0f0 100644</span>
<span class="gd">--- a/fsspec/generic.py</span>
<span class="gi">+++ b/fsspec/generic.py</span>
<span class="gu">@@ -1,26 +1,56 @@</span>
<span class="w"> </span>from __future__ import annotations
<span class="gi">+</span>
<span class="w"> </span>import inspect
<span class="w"> </span>import logging
<span class="w"> </span>import os
<span class="w"> </span>import shutil
<span class="w"> </span>import uuid
<span class="w"> </span>from typing import Optional
<span class="gi">+</span>
<span class="w"> </span>from .asyn import AsyncFileSystem, _run_coros_in_chunks, sync_wrapper
<span class="w"> </span>from .callbacks import DEFAULT_CALLBACK
<span class="w"> </span>from .core import filesystem, get_filesystem_class, split_protocol, url_to_fs
<span class="gi">+</span>
<span class="w"> </span>_generic_fs = {}
<span class="gd">-logger = logging.getLogger(&#39;fsspec.generic&#39;)</span>
<span class="gd">-default_method = &#39;default&#39;</span>
<span class="gi">+logger = logging.getLogger(&quot;fsspec.generic&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def set_generic_fs(protocol, **storage_options):</span>
<span class="gi">+    _generic_fs[protocol] = filesystem(protocol, **storage_options)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+default_method = &quot;default&quot;</span>


<span class="w"> </span>def _resolve_fs(url, method=None, protocol=None, storage_options=None):
<span class="w"> </span>    &quot;&quot;&quot;Pick instance of backend FS&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    method = method or default_method</span>
<span class="gi">+    protocol = protocol or split_protocol(url)[0]</span>
<span class="gi">+    storage_options = storage_options or {}</span>
<span class="gi">+    if method == &quot;default&quot;:</span>
<span class="gi">+        return filesystem(protocol)</span>
<span class="gi">+    if method == &quot;generic&quot;:</span>
<span class="gi">+        return _generic_fs[protocol]</span>
<span class="gi">+    if method == &quot;current&quot;:</span>
<span class="gi">+        cls = get_filesystem_class(protocol)</span>
<span class="gi">+        return cls.current()</span>
<span class="gi">+    if method == &quot;options&quot;:</span>
<span class="gi">+        fs, _ = url_to_fs(url, **storage_options.get(protocol, {}))</span>
<span class="gi">+        return fs</span>
<span class="gi">+    raise ValueError(f&quot;Unknown FS resolution method: {method}&quot;)</span>


<span class="gd">-def rsync(source, destination, delete_missing=False, source_field=&#39;size&#39;,</span>
<span class="gd">-    dest_field=&#39;size&#39;, update_cond=&#39;different&#39;, inst_kwargs=None, fs=None,</span>
<span class="gd">-    **kwargs):</span>
<span class="gi">+def rsync(</span>
<span class="gi">+    source,</span>
<span class="gi">+    destination,</span>
<span class="gi">+    delete_missing=False,</span>
<span class="gi">+    source_field=&quot;size&quot;,</span>
<span class="gi">+    dest_field=&quot;size&quot;,</span>
<span class="gi">+    update_cond=&quot;different&quot;,</span>
<span class="gi">+    inst_kwargs=None,</span>
<span class="gi">+    fs=None,</span>
<span class="gi">+    **kwargs,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;Sync files between two directory trees

<span class="w"> </span>    (experimental)
<span class="gu">@@ -62,7 +92,56 @@ def rsync(source, destination, delete_missing=False, source_field=&#39;size&#39;,</span>
<span class="w"> </span>    -------
<span class="w"> </span>    dict of the copy operations that were performed, {source: destination}
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    fs = fs or GenericFileSystem(**(inst_kwargs or {}))</span>
<span class="gi">+    source = fs._strip_protocol(source)</span>
<span class="gi">+    destination = fs._strip_protocol(destination)</span>
<span class="gi">+    allfiles = fs.find(source, withdirs=True, detail=True)</span>
<span class="gi">+    if not fs.isdir(source):</span>
<span class="gi">+        raise ValueError(&quot;Can only rsync on a directory&quot;)</span>
<span class="gi">+    otherfiles = fs.find(destination, withdirs=True, detail=True)</span>
<span class="gi">+    dirs = [</span>
<span class="gi">+        a</span>
<span class="gi">+        for a, v in allfiles.items()</span>
<span class="gi">+        if v[&quot;type&quot;] == &quot;directory&quot; and a.replace(source, destination) not in otherfiles</span>
<span class="gi">+    ]</span>
<span class="gi">+    logger.debug(f&quot;{len(dirs)} directories to create&quot;)</span>
<span class="gi">+    if dirs:</span>
<span class="gi">+        fs.make_many_dirs(</span>
<span class="gi">+            [dirn.replace(source, destination) for dirn in dirs], exist_ok=True</span>
<span class="gi">+        )</span>
<span class="gi">+    allfiles = {a: v for a, v in allfiles.items() if v[&quot;type&quot;] == &quot;file&quot;}</span>
<span class="gi">+    logger.debug(f&quot;{len(allfiles)} files to consider for copy&quot;)</span>
<span class="gi">+    to_delete = [</span>
<span class="gi">+        o</span>
<span class="gi">+        for o, v in otherfiles.items()</span>
<span class="gi">+        if o.replace(destination, source) not in allfiles and v[&quot;type&quot;] == &quot;file&quot;</span>
<span class="gi">+    ]</span>
<span class="gi">+    for k, v in allfiles.copy().items():</span>
<span class="gi">+        otherfile = k.replace(source, destination)</span>
<span class="gi">+        if otherfile in otherfiles:</span>
<span class="gi">+            if update_cond == &quot;always&quot;:</span>
<span class="gi">+                allfiles[k] = otherfile</span>
<span class="gi">+            elif update_cond == &quot;different&quot;:</span>
<span class="gi">+                inf1 = source_field(v) if callable(source_field) else v[source_field]</span>
<span class="gi">+                v2 = otherfiles[otherfile]</span>
<span class="gi">+                inf2 = dest_field(v2) if callable(dest_field) else v2[dest_field]</span>
<span class="gi">+                if inf1 != inf2:</span>
<span class="gi">+                    # details mismatch, make copy</span>
<span class="gi">+                    allfiles[k] = otherfile</span>
<span class="gi">+                else:</span>
<span class="gi">+                    # details match, don&#39;t copy</span>
<span class="gi">+                    allfiles.pop(k)</span>
<span class="gi">+        else:</span>
<span class="gi">+            # file not in target yet</span>
<span class="gi">+            allfiles[k] = otherfile</span>
<span class="gi">+    logger.debug(f&quot;{len(allfiles)} files to copy&quot;)</span>
<span class="gi">+    if allfiles:</span>
<span class="gi">+        source_files, target_files = zip(*allfiles.items())</span>
<span class="gi">+        fs.cp(source_files, target_files, **kwargs)</span>
<span class="gi">+    logger.debug(f&quot;{len(to_delete)} files to delete&quot;)</span>
<span class="gi">+    if delete_missing and to_delete:</span>
<span class="gi">+        fs.rm(to_delete)</span>
<span class="gi">+    return allfiles</span>


<span class="w"> </span>class GenericFileSystem(AsyncFileSystem):
<span class="gu">@@ -77,9 +156,10 @@ class GenericFileSystem(AsyncFileSystem):</span>
<span class="w"> </span>    Note: instances of this FS are always async, even if you never use it with any async
<span class="w"> </span>    backend.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    protocol = &#39;generic&#39;</span>

<span class="gd">-    def __init__(self, default_method=&#39;default&#39;, **kwargs):</span>
<span class="gi">+    protocol = &quot;generic&quot;  # there is no real reason to ever use a protocol with this FS</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(self, default_method=&quot;default&quot;, **kwargs):</span>
<span class="w"> </span>        &quot;&quot;&quot;

<span class="w"> </span>        Parameters
<span class="gu">@@ -96,10 +176,236 @@ class GenericFileSystem(AsyncFileSystem):</span>
<span class="w"> </span>        self.method = default_method
<span class="w"> </span>        super().__init__(**kwargs)

<span class="gi">+    def _parent(self, path):</span>
<span class="gi">+        fs = _resolve_fs(path, self.method)</span>
<span class="gi">+        return fs.unstrip_protocol(fs._parent(path))</span>
<span class="gi">+</span>
<span class="gi">+    def _strip_protocol(self, path):</span>
<span class="gi">+        # normalization only</span>
<span class="gi">+        fs = _resolve_fs(path, self.method)</span>
<span class="gi">+        return fs.unstrip_protocol(fs._strip_protocol(path))</span>
<span class="gi">+</span>
<span class="gi">+    async def _find(self, path, maxdepth=None, withdirs=False, detail=False, **kwargs):</span>
<span class="gi">+        fs = _resolve_fs(path, self.method)</span>
<span class="gi">+        if fs.async_impl:</span>
<span class="gi">+            out = await fs._find(</span>
<span class="gi">+                path, maxdepth=maxdepth, withdirs=withdirs, detail=True, **kwargs</span>
<span class="gi">+            )</span>
<span class="gi">+        else:</span>
<span class="gi">+            out = fs.find(</span>
<span class="gi">+                path, maxdepth=maxdepth, withdirs=withdirs, detail=True, **kwargs</span>
<span class="gi">+            )</span>
<span class="gi">+        result = {}</span>
<span class="gi">+        for k, v in out.items():</span>
<span class="gi">+            v = v.copy()  # don&#39;t corrupt target FS dircache</span>
<span class="gi">+            name = fs.unstrip_protocol(k)</span>
<span class="gi">+            v[&quot;name&quot;] = name</span>
<span class="gi">+            result[name] = v</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return result</span>
<span class="gi">+        return list(result)</span>
<span class="gi">+</span>
<span class="gi">+    async def _info(self, url, **kwargs):</span>
<span class="gi">+        fs = _resolve_fs(url, self.method)</span>
<span class="gi">+        if fs.async_impl:</span>
<span class="gi">+            out = await fs._info(url, **kwargs)</span>
<span class="gi">+        else:</span>
<span class="gi">+            out = fs.info(url, **kwargs)</span>
<span class="gi">+        out = out.copy()  # don&#39;t edit originals</span>
<span class="gi">+        out[&quot;name&quot;] = fs.unstrip_protocol(out[&quot;name&quot;])</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    async def _ls(</span>
<span class="gi">+        self,</span>
<span class="gi">+        url,</span>
<span class="gi">+        detail=True,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        fs = _resolve_fs(url, self.method)</span>
<span class="gi">+        if fs.async_impl:</span>
<span class="gi">+            out = await fs._ls(url, detail=True, **kwargs)</span>
<span class="gi">+        else:</span>
<span class="gi">+            out = fs.ls(url, detail=True, **kwargs)</span>
<span class="gi">+        out = [o.copy() for o in out]  # don&#39;t edit originals</span>
<span class="gi">+        for o in out:</span>
<span class="gi">+            o[&quot;name&quot;] = fs.unstrip_protocol(o[&quot;name&quot;])</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return out</span>
<span class="gi">+        else:</span>
<span class="gi">+            return [o[&quot;name&quot;] for o in out]</span>
<span class="gi">+</span>
<span class="gi">+    async def _cat_file(</span>
<span class="gi">+        self,</span>
<span class="gi">+        url,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        fs = _resolve_fs(url, self.method)</span>
<span class="gi">+        if fs.async_impl:</span>
<span class="gi">+            return await fs._cat_file(url, **kwargs)</span>
<span class="gi">+        else:</span>
<span class="gi">+            return fs.cat_file(url, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    async def _pipe_file(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        value,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        fs = _resolve_fs(path, self.method)</span>
<span class="gi">+        if fs.async_impl:</span>
<span class="gi">+            return await fs._pipe_file(path, value, **kwargs)</span>
<span class="gi">+        else:</span>
<span class="gi">+            return fs.pipe_file(path, value, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    async def _rm(self, url, **kwargs):</span>
<span class="gi">+        urls = url</span>
<span class="gi">+        if isinstance(urls, str):</span>
<span class="gi">+            urls = [urls]</span>
<span class="gi">+        fs = _resolve_fs(urls[0], self.method)</span>
<span class="gi">+        if fs.async_impl:</span>
<span class="gi">+            await fs._rm(urls, **kwargs)</span>
<span class="gi">+        else:</span>
<span class="gi">+            fs.rm(url, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    async def _makedirs(self, path, exist_ok=False):</span>
<span class="gi">+        logger.debug(&quot;Make dir %s&quot;, path)</span>
<span class="gi">+        fs = _resolve_fs(path, self.method)</span>
<span class="gi">+        if fs.async_impl:</span>
<span class="gi">+            await fs._makedirs(path, exist_ok=exist_ok)</span>
<span class="gi">+        else:</span>
<span class="gi">+            fs.makedirs(path, exist_ok=exist_ok)</span>
<span class="gi">+</span>
<span class="w"> </span>    def rsync(self, source, destination, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Sync files between two directory trees

<span class="w"> </span>        See `func:rsync` for more details.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        rsync(source, destination, fs=self, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    async def _cp_file(</span>
<span class="gi">+        self,</span>
<span class="gi">+        url,</span>
<span class="gi">+        url2,</span>
<span class="gi">+        blocksize=2**20,</span>
<span class="gi">+        callback=DEFAULT_CALLBACK,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        fs = _resolve_fs(url, self.method)</span>
<span class="gi">+        fs2 = _resolve_fs(url2, self.method)</span>
<span class="gi">+        if fs is fs2:</span>
<span class="gi">+            # pure remote</span>
<span class="gi">+            if fs.async_impl:</span>
<span class="gi">+                return await fs._cp_file(url, url2, **kwargs)</span>
<span class="gi">+            else:</span>
<span class="gi">+                return fs.cp_file(url, url2, **kwargs)</span>
<span class="gi">+        kw = {&quot;blocksize&quot;: 0, &quot;cache_type&quot;: &quot;none&quot;}</span>
<span class="gi">+        try:</span>
<span class="gi">+            f1 = (</span>
<span class="gi">+                await fs.open_async(url, &quot;rb&quot;)</span>
<span class="gi">+                if hasattr(fs, &quot;open_async&quot;)</span>
<span class="gi">+                else fs.open(url, &quot;rb&quot;, **kw)</span>
<span class="gi">+            )</span>
<span class="gi">+            callback.set_size(await maybe_await(f1.size))</span>
<span class="gi">+            f2 = (</span>
<span class="gi">+                await fs2.open_async(url2, &quot;wb&quot;)</span>
<span class="gi">+                if hasattr(fs2, &quot;open_async&quot;)</span>
<span class="gi">+                else fs2.open(url2, &quot;wb&quot;, **kw)</span>
<span class="gi">+            )</span>
<span class="gi">+            while f1.size is None or f2.tell() &lt; f1.size:</span>
<span class="gi">+                data = await maybe_await(f1.read(blocksize))</span>
<span class="gi">+                if f1.size is None and not data:</span>
<span class="gi">+                    break</span>
<span class="gi">+                await maybe_await(f2.write(data))</span>
<span class="gi">+                callback.absolute_update(f2.tell())</span>
<span class="gi">+        finally:</span>
<span class="gi">+            try:</span>
<span class="gi">+                await maybe_await(f2.close())</span>
<span class="gi">+                await maybe_await(f1.close())</span>
<span class="gi">+            except NameError:</span>
<span class="gi">+                # fail while opening f1 or f2</span>
<span class="gi">+                pass</span>
<span class="gi">+</span>
<span class="gi">+    async def _make_many_dirs(self, urls, exist_ok=True):</span>
<span class="gi">+        fs = _resolve_fs(urls[0], self.method)</span>
<span class="gi">+        if fs.async_impl:</span>
<span class="gi">+            coros = [fs._makedirs(u, exist_ok=exist_ok) for u in urls]</span>
<span class="gi">+            await _run_coros_in_chunks(coros)</span>
<span class="gi">+        else:</span>
<span class="gi">+            for u in urls:</span>
<span class="gi">+                fs.makedirs(u, exist_ok=exist_ok)</span>
<span class="gi">+</span>
<span class="w"> </span>    make_many_dirs = sync_wrapper(_make_many_dirs)
<span class="gi">+</span>
<span class="gi">+    async def _copy(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path1: list[str],</span>
<span class="gi">+        path2: list[str],</span>
<span class="gi">+        recursive: bool = False,</span>
<span class="gi">+        on_error: str = &quot;ignore&quot;,</span>
<span class="gi">+        maxdepth: Optional[int] = None,</span>
<span class="gi">+        batch_size: Optional[int] = None,</span>
<span class="gi">+        tempdir: Optional[str] = None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        if recursive:</span>
<span class="gi">+            raise NotImplementedError</span>
<span class="gi">+        fs = _resolve_fs(path1[0], self.method)</span>
<span class="gi">+        fs2 = _resolve_fs(path2[0], self.method)</span>
<span class="gi">+        # not expanding paths atm., assume call is from rsync()</span>
<span class="gi">+        if fs is fs2:</span>
<span class="gi">+            # pure remote</span>
<span class="gi">+            if fs.async_impl:</span>
<span class="gi">+                return await fs._copy(path1, path2, **kwargs)</span>
<span class="gi">+            else:</span>
<span class="gi">+                return fs.copy(path1, path2, **kwargs)</span>
<span class="gi">+        await copy_file_op(</span>
<span class="gi">+            fs, path1, fs2, path2, tempdir, batch_size, on_error=on_error</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+async def copy_file_op(</span>
<span class="gi">+    fs1, url1, fs2, url2, tempdir=None, batch_size=20, on_error=&quot;ignore&quot;</span>
<span class="gi">+):</span>
<span class="gi">+    import tempfile</span>
<span class="gi">+</span>
<span class="gi">+    tempdir = tempdir or tempfile.mkdtemp()</span>
<span class="gi">+    try:</span>
<span class="gi">+        coros = [</span>
<span class="gi">+            _copy_file_op(</span>
<span class="gi">+                fs1,</span>
<span class="gi">+                u1,</span>
<span class="gi">+                fs2,</span>
<span class="gi">+                u2,</span>
<span class="gi">+                os.path.join(tempdir, uuid.uuid4().hex),</span>
<span class="gi">+                on_error=on_error,</span>
<span class="gi">+            )</span>
<span class="gi">+            for u1, u2 in zip(url1, url2)</span>
<span class="gi">+        ]</span>
<span class="gi">+        await _run_coros_in_chunks(coros, batch_size=batch_size)</span>
<span class="gi">+    finally:</span>
<span class="gi">+        shutil.rmtree(tempdir)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+async def _copy_file_op(fs1, url1, fs2, url2, local, on_error=&quot;ignore&quot;):</span>
<span class="gi">+    ex = () if on_error == &quot;raise&quot; else Exception</span>
<span class="gi">+    logger.debug(&quot;Copy %s -&gt; %s&quot;, url1, url2)</span>
<span class="gi">+    try:</span>
<span class="gi">+        if fs1.async_impl:</span>
<span class="gi">+            await fs1._get_file(url1, local)</span>
<span class="gi">+        else:</span>
<span class="gi">+            fs1.get_file(url1, local)</span>
<span class="gi">+        if fs2.async_impl:</span>
<span class="gi">+            await fs2._put_file(local, url2)</span>
<span class="gi">+        else:</span>
<span class="gi">+            fs2.put_file(local, url2)</span>
<span class="gi">+        os.unlink(local)</span>
<span class="gi">+        logger.debug(&quot;Copy %s -&gt; %s; done&quot;, url1, url2)</span>
<span class="gi">+    except ex as e:</span>
<span class="gi">+        logger.debug(&quot;ignoring cp exception for %s: %s&quot;, url1, e)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+async def maybe_await(cor):</span>
<span class="gi">+    if inspect.iscoroutine(cor):</span>
<span class="gi">+        return await cor</span>
<span class="gi">+    else:</span>
<span class="gi">+        return cor</span>
<span class="gh">diff --git a/fsspec/gui.py b/fsspec/gui.py</span>
<span class="gh">index ad74c4c..113317e 100644</span>
<span class="gd">--- a/fsspec/gui.py</span>
<span class="gi">+++ b/fsspec/gui.py</span>
<span class="gu">@@ -4,11 +4,14 @@ import logging</span>
<span class="w"> </span>import os
<span class="w"> </span>import re
<span class="w"> </span>from typing import ClassVar, Sequence
<span class="gi">+</span>
<span class="w"> </span>import panel as pn
<span class="gi">+</span>
<span class="w"> </span>from .core import OpenFile, get_filesystem_class, split_protocol
<span class="w"> </span>from .registry import known_implementations
<span class="gi">+</span>
<span class="w"> </span>pn.extension()
<span class="gd">-logger = logging.getLogger(&#39;fsspec.gui&#39;)</span>
<span class="gi">+logger = logging.getLogger(&quot;fsspec.gui&quot;)</span>


<span class="w"> </span>class SigSlot:
<span class="gu">@@ -22,9 +25,15 @@ class SigSlot:</span>

<span class="w"> </span>    By default, all signals emit a DEBUG logging statement.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gi">+</span>
<span class="gi">+    # names of signals that this class may emit each of which must be</span>
<span class="gi">+    # set by _register for any new instance</span>
<span class="w"> </span>    signals: ClassVar[Sequence[str]] = []
<span class="gi">+    # names of actions that this class may respond to</span>
<span class="w"> </span>    slots: ClassVar[Sequence[str]] = []

<span class="gi">+    # each of which must be a method name</span>
<span class="gi">+</span>
<span class="w"> </span>    def __init__(self):
<span class="w"> </span>        self._ignoring_events = False
<span class="w"> </span>        self._sigs = {}
<span class="gu">@@ -33,10 +42,12 @@ class SigSlot:</span>

<span class="w"> </span>    def _setup(self):
<span class="w"> </span>        &quot;&quot;&quot;Create GUI elements and register signals&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.panel = pn.pane.PaneBase()</span>
<span class="gi">+        # no signals to set up in the base class</span>

<span class="gd">-    def _register(self, widget, name, thing=&#39;value&#39;, log_level=logging.</span>
<span class="gd">-        DEBUG, auto=False):</span>
<span class="gi">+    def _register(</span>
<span class="gi">+        self, widget, name, thing=&quot;value&quot;, log_level=logging.DEBUG, auto=False</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Watch the given attribute of a widget and assign it a named event

<span class="w"> </span>        This is normally called at the time a widget is instantiated, in the
<span class="gu">@@ -58,11 +69,32 @@ class SigSlot:</span>
<span class="w"> </span>            If True, automatically connects with a method in this class of the
<span class="w"> </span>            same name.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if name not in self.signals:</span>
<span class="gi">+            raise ValueError(f&quot;Attempt to assign an undeclared signal: {name}&quot;)</span>
<span class="gi">+        self._sigs[name] = {</span>
<span class="gi">+            &quot;widget&quot;: widget,</span>
<span class="gi">+            &quot;callbacks&quot;: [],</span>
<span class="gi">+            &quot;thing&quot;: thing,</span>
<span class="gi">+            &quot;log&quot;: log_level,</span>
<span class="gi">+        }</span>
<span class="gi">+        wn = &quot;-&quot;.join(</span>
<span class="gi">+            [</span>
<span class="gi">+                getattr(widget, &quot;name&quot;, str(widget)) if widget is not None else &quot;none&quot;,</span>
<span class="gi">+                thing,</span>
<span class="gi">+            ]</span>
<span class="gi">+        )</span>
<span class="gi">+        self._map[wn] = name</span>
<span class="gi">+        if widget is not None:</span>
<span class="gi">+            widget.param.watch(self._signal, thing, onlychanged=True)</span>
<span class="gi">+        if auto and hasattr(self, name):</span>
<span class="gi">+            self.connect(name, getattr(self, name))</span>

<span class="w"> </span>    def _repr_mimebundle_(self, *args, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Display in a notebook or a server&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        try:</span>
<span class="gi">+            return self.panel._repr_mimebundle_(*args, **kwargs)</span>
<span class="gi">+        except (ValueError, AttributeError):</span>
<span class="gi">+            raise NotImplementedError(&quot;Panel does not seem to be set up properly&quot;)</span>

<span class="w"> </span>    def connect(self, signal, slot):
<span class="w"> </span>        &quot;&quot;&quot;Associate call back with given event
<span class="gu">@@ -74,7 +106,7 @@ class SigSlot:</span>
<span class="w"> </span>        Alternatively, the callback can be a string, in which case it means
<span class="w"> </span>        emitting the correspondingly-named event (i.e., connect to self)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._sigs[signal][&quot;callbacks&quot;].append(slot)</span>

<span class="w"> </span>    def _signal(self, event):
<span class="w"> </span>        &quot;&quot;&quot;This is called by a an action on a widget
<span class="gu">@@ -84,7 +116,10 @@ class SigSlot:</span>
<span class="w"> </span>        Tests can execute this method by directly changing the values of
<span class="w"> </span>        widget components.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if not self._ignoring_events:</span>
<span class="gi">+            wn = &quot;-&quot;.join([event.obj.name, event.name])</span>
<span class="gi">+            if wn in self._map and self._map[wn] in self._sigs:</span>
<span class="gi">+                self._emit(self._map[wn], event.new)</span>

<span class="w"> </span>    @contextlib.contextmanager
<span class="w"> </span>    def ignore_events(self):
<span class="gu">@@ -92,7 +127,11 @@ class SigSlot:</span>

<span class="w"> </span>        (does not propagate to children)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._ignoring_events = True</span>
<span class="gi">+        try:</span>
<span class="gi">+            yield</span>
<span class="gi">+        finally:</span>
<span class="gi">+            self._ignoring_events = False</span>

<span class="w"> </span>    def _emit(self, sig, value=None):
<span class="w"> </span>        &quot;&quot;&quot;An event happened, call its callbacks
<span class="gu">@@ -102,22 +141,67 @@ class SigSlot:</span>

<span class="w"> </span>        Calling of callbacks will halt whenever one returns False.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        logger.log(self._sigs[sig][&quot;log&quot;], f&quot;{sig}: {value}&quot;)</span>
<span class="gi">+        for callback in self._sigs[sig][&quot;callbacks&quot;]:</span>
<span class="gi">+            if isinstance(callback, str):</span>
<span class="gi">+                self._emit(callback)</span>
<span class="gi">+            else:</span>
<span class="gi">+                try:</span>
<span class="gi">+                    # running callbacks should not break the interface</span>
<span class="gi">+                    ret = callback(value)</span>
<span class="gi">+                    if ret is False:</span>
<span class="gi">+                        break</span>
<span class="gi">+                except Exception as e:</span>
<span class="gi">+                    logger.exception(</span>
<span class="gi">+                        &quot;Exception (%s) while executing callback for signal: %s&quot;,</span>
<span class="gi">+                        e,</span>
<span class="gi">+                        sig,</span>
<span class="gi">+                    )</span>

<span class="w"> </span>    def show(self, threads=False):
<span class="w"> </span>        &quot;&quot;&quot;Open a new browser tab and display this instance&#39;s interface&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.panel.show(threads=threads, verbose=False)</span>
<span class="gi">+        return self</span>


<span class="w"> </span>class SingleSelect(SigSlot):
<span class="w"> </span>    &quot;&quot;&quot;A multiselect which only allows you to select one item for an event&quot;&quot;&quot;
<span class="gd">-    signals = [&#39;_selected&#39;, &#39;selected&#39;]</span>
<span class="gd">-    slots = [&#39;set_options&#39;, &#39;set_selection&#39;, &#39;add&#39;, &#39;clear&#39;, &#39;select&#39;]</span>
<span class="gi">+</span>
<span class="gi">+    signals = [&quot;_selected&quot;, &quot;selected&quot;]  # the first is internal</span>
<span class="gi">+    slots = [&quot;set_options&quot;, &quot;set_selection&quot;, &quot;add&quot;, &quot;clear&quot;, &quot;select&quot;]</span>

<span class="w"> </span>    def __init__(self, **kwargs):
<span class="w"> </span>        self.kwargs = kwargs
<span class="w"> </span>        super().__init__()

<span class="gi">+    def _setup(self):</span>
<span class="gi">+        self.panel = pn.widgets.MultiSelect(**self.kwargs)</span>
<span class="gi">+        self._register(self.panel, &quot;_selected&quot;, &quot;value&quot;)</span>
<span class="gi">+        self._register(None, &quot;selected&quot;)</span>
<span class="gi">+        self.connect(&quot;_selected&quot;, self.select_one)</span>
<span class="gi">+</span>
<span class="gi">+    def _signal(self, *args, **kwargs):</span>
<span class="gi">+        super()._signal(*args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def select_one(self, *_):</span>
<span class="gi">+        with self.ignore_events():</span>
<span class="gi">+            val = [self.panel.value[-1]] if self.panel.value else []</span>
<span class="gi">+            self.panel.value = val</span>
<span class="gi">+        self._emit(&quot;selected&quot;, self.panel.value)</span>
<span class="gi">+</span>
<span class="gi">+    def set_options(self, options):</span>
<span class="gi">+        self.panel.options = options</span>
<span class="gi">+</span>
<span class="gi">+    def clear(self):</span>
<span class="gi">+        self.panel.options = []</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def value(self):</span>
<span class="gi">+        return self.panel.value</span>
<span class="gi">+</span>
<span class="gi">+    def set_selection(self, selection):</span>
<span class="gi">+        self.panel.value = [selection]</span>
<span class="gi">+</span>

<span class="w"> </span>class FileSelector(SigSlot):
<span class="w"> </span>    &quot;&quot;&quot;Panel-based graphical file selector widget
<span class="gu">@@ -125,9 +209,17 @@ class FileSelector(SigSlot):</span>
<span class="w"> </span>    Instances of this widget are interactive and can be displayed in jupyter by having
<span class="w"> </span>    them as the output of a cell,  or in a separate browser tab using ``.show()``.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    signals = [&#39;protocol_changed&#39;, &#39;selection_changed&#39;, &#39;directory_entered&#39;,</span>
<span class="gd">-        &#39;home_clicked&#39;, &#39;up_clicked&#39;, &#39;go_clicked&#39;, &#39;filters_changed&#39;]</span>
<span class="gd">-    slots = [&#39;set_filters&#39;, &#39;go_home&#39;]</span>
<span class="gi">+</span>
<span class="gi">+    signals = [</span>
<span class="gi">+        &quot;protocol_changed&quot;,</span>
<span class="gi">+        &quot;selection_changed&quot;,</span>
<span class="gi">+        &quot;directory_entered&quot;,</span>
<span class="gi">+        &quot;home_clicked&quot;,</span>
<span class="gi">+        &quot;up_clicked&quot;,</span>
<span class="gi">+        &quot;go_clicked&quot;,</span>
<span class="gi">+        &quot;filters_changed&quot;,</span>
<span class="gi">+    ]</span>
<span class="gi">+    slots = [&quot;set_filters&quot;, &quot;go_home&quot;]</span>

<span class="w"> </span>    def __init__(self, url=None, filters=None, ignore=None, kwargs=None):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -149,31 +241,91 @@ class FileSelector(SigSlot):</span>
<span class="w"> </span>        if url:
<span class="w"> </span>            self.init_protocol, url = split_protocol(url)
<span class="w"> </span>        else:
<span class="gd">-            self.init_protocol, url = &#39;file&#39;, os.getcwd()</span>
<span class="gi">+            self.init_protocol, url = &quot;file&quot;, os.getcwd()</span>
<span class="w"> </span>        self.init_url = url
<span class="gd">-        self.init_kwargs = (kwargs if isinstance(kwargs, str) else str(kwargs)</span>
<span class="gd">-            ) or &#39;{}&#39;</span>
<span class="gi">+        self.init_kwargs = (kwargs if isinstance(kwargs, str) else str(kwargs)) or &quot;{}&quot;</span>
<span class="w"> </span>        self.filters = filters
<span class="w"> </span>        self.ignore = [re.compile(i) for i in ignore or []]
<span class="w"> </span>        self._fs = None
<span class="w"> </span>        super().__init__()

<span class="gi">+    def _setup(self):</span>
<span class="gi">+        self.url = pn.widgets.TextInput(</span>
<span class="gi">+            name=&quot;url&quot;,</span>
<span class="gi">+            value=self.init_url,</span>
<span class="gi">+            align=&quot;end&quot;,</span>
<span class="gi">+            sizing_mode=&quot;stretch_width&quot;,</span>
<span class="gi">+            width_policy=&quot;max&quot;,</span>
<span class="gi">+        )</span>
<span class="gi">+        self.protocol = pn.widgets.Select(</span>
<span class="gi">+            options=sorted(known_implementations),</span>
<span class="gi">+            value=self.init_protocol,</span>
<span class="gi">+            name=&quot;protocol&quot;,</span>
<span class="gi">+            align=&quot;center&quot;,</span>
<span class="gi">+        )</span>
<span class="gi">+        self.kwargs = pn.widgets.TextInput(</span>
<span class="gi">+            name=&quot;kwargs&quot;, value=self.init_kwargs, align=&quot;center&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+        self.go = pn.widgets.Button(name=&quot;⇨&quot;, align=&quot;end&quot;, width=45)</span>
<span class="gi">+        self.main = SingleSelect(size=10)</span>
<span class="gi">+        self.home = pn.widgets.Button(name=&quot;🏠&quot;, width=40, height=30, align=&quot;end&quot;)</span>
<span class="gi">+        self.up = pn.widgets.Button(name=&quot;‹&quot;, width=30, height=30, align=&quot;end&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        self._register(self.protocol, &quot;protocol_changed&quot;, auto=True)</span>
<span class="gi">+        self._register(self.go, &quot;go_clicked&quot;, &quot;clicks&quot;, auto=True)</span>
<span class="gi">+        self._register(self.up, &quot;up_clicked&quot;, &quot;clicks&quot;, auto=True)</span>
<span class="gi">+        self._register(self.home, &quot;home_clicked&quot;, &quot;clicks&quot;, auto=True)</span>
<span class="gi">+        self._register(None, &quot;selection_changed&quot;)</span>
<span class="gi">+        self.main.connect(&quot;selected&quot;, self.selection_changed)</span>
<span class="gi">+        self._register(None, &quot;directory_entered&quot;)</span>
<span class="gi">+        self.prev_protocol = self.protocol.value</span>
<span class="gi">+        self.prev_kwargs = self.storage_options</span>
<span class="gi">+</span>
<span class="gi">+        self.filter_sel = pn.widgets.CheckBoxGroup(</span>
<span class="gi">+            value=[], options=[], inline=False, align=&quot;end&quot;, width_policy=&quot;min&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+        self._register(self.filter_sel, &quot;filters_changed&quot;, auto=True)</span>
<span class="gi">+</span>
<span class="gi">+        self.panel = pn.Column(</span>
<span class="gi">+            pn.Row(self.protocol, self.kwargs),</span>
<span class="gi">+            pn.Row(self.home, self.up, self.url, self.go, self.filter_sel),</span>
<span class="gi">+            self.main.panel,</span>
<span class="gi">+        )</span>
<span class="gi">+        self.set_filters(self.filters)</span>
<span class="gi">+        self.go_clicked()</span>
<span class="gi">+</span>
<span class="gi">+    def set_filters(self, filters=None):</span>
<span class="gi">+        self.filters = filters</span>
<span class="gi">+        if filters:</span>
<span class="gi">+            self.filter_sel.options = filters</span>
<span class="gi">+            self.filter_sel.value = filters</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.filter_sel.options = []</span>
<span class="gi">+            self.filter_sel.value = []</span>
<span class="gi">+</span>
<span class="w"> </span>    @property
<span class="w"> </span>    def storage_options(self):
<span class="w"> </span>        &quot;&quot;&quot;Value of the kwargs box as a dictionary&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return ast.literal_eval(self.kwargs.value) or {}</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def fs(self):
<span class="w"> </span>        &quot;&quot;&quot;Current filesystem instance&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self._fs is None:</span>
<span class="gi">+            cls = get_filesystem_class(self.protocol.value)</span>
<span class="gi">+            self._fs = cls(**self.storage_options)</span>
<span class="gi">+        return self._fs</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def urlpath(self):
<span class="w"> </span>        &quot;&quot;&quot;URL of currently selected item&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return (</span>
<span class="gi">+            (f&quot;{self.protocol.value}://{self.main.value[0]}&quot;)</span>
<span class="gi">+            if self.main.value</span>
<span class="gi">+            else None</span>
<span class="gi">+        )</span>

<span class="gd">-    def open_file(self, mode=&#39;rb&#39;, compression=None, encoding=None):</span>
<span class="gi">+    def open_file(self, mode=&quot;rb&quot;, compression=None, encoding=None):</span>
<span class="w"> </span>        &quot;&quot;&quot;Create OpenFile instance for the currently selected item

<span class="w"> </span>        For example, in a notebook you might do something like
<span class="gu">@@ -197,4 +349,66 @@ class FileSelector(SigSlot):</span>
<span class="w"> </span>        encoding: str (optional)
<span class="w"> </span>            If using text mode, use this encoding; defaults to UTF8.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.urlpath is None:</span>
<span class="gi">+            raise ValueError(&quot;No file selected&quot;)</span>
<span class="gi">+        return OpenFile(self.fs, self.urlpath, mode, compression, encoding)</span>
<span class="gi">+</span>
<span class="gi">+    def filters_changed(self, values):</span>
<span class="gi">+        self.filters = values</span>
<span class="gi">+        self.go_clicked()</span>
<span class="gi">+</span>
<span class="gi">+    def selection_changed(self, *_):</span>
<span class="gi">+        if self.urlpath is None:</span>
<span class="gi">+            return</span>
<span class="gi">+        if self.fs.isdir(self.urlpath):</span>
<span class="gi">+            self.url.value = self.fs._strip_protocol(self.urlpath)</span>
<span class="gi">+        self.go_clicked()</span>
<span class="gi">+</span>
<span class="gi">+    def go_clicked(self, *_):</span>
<span class="gi">+        if (</span>
<span class="gi">+            self.prev_protocol != self.protocol.value</span>
<span class="gi">+            or self.prev_kwargs != self.storage_options</span>
<span class="gi">+        ):</span>
<span class="gi">+            self._fs = None  # causes fs to be recreated</span>
<span class="gi">+            self.prev_protocol = self.protocol.value</span>
<span class="gi">+            self.prev_kwargs = self.storage_options</span>
<span class="gi">+        listing = sorted(</span>
<span class="gi">+            self.fs.ls(self.url.value, detail=True), key=lambda x: x[&quot;name&quot;]</span>
<span class="gi">+        )</span>
<span class="gi">+        listing = [</span>
<span class="gi">+            l</span>
<span class="gi">+            for l in listing</span>
<span class="gi">+            if not any(i.match(l[&quot;name&quot;].rsplit(&quot;/&quot;, 1)[-1]) for i in self.ignore)</span>
<span class="gi">+        ]</span>
<span class="gi">+        folders = {</span>
<span class="gi">+            &quot;📁 &quot; + o[&quot;name&quot;].rsplit(&quot;/&quot;, 1)[-1]: o[&quot;name&quot;]</span>
<span class="gi">+            for o in listing</span>
<span class="gi">+            if o[&quot;type&quot;] == &quot;directory&quot;</span>
<span class="gi">+        }</span>
<span class="gi">+        files = {</span>
<span class="gi">+            &quot;📄 &quot; + o[&quot;name&quot;].rsplit(&quot;/&quot;, 1)[-1]: o[&quot;name&quot;]</span>
<span class="gi">+            for o in listing</span>
<span class="gi">+            if o[&quot;type&quot;] == &quot;file&quot;</span>
<span class="gi">+        }</span>
<span class="gi">+        if self.filters:</span>
<span class="gi">+            files = {</span>
<span class="gi">+                k: v</span>
<span class="gi">+                for k, v in files.items()</span>
<span class="gi">+                if any(v.endswith(ext) for ext in self.filters)</span>
<span class="gi">+            }</span>
<span class="gi">+        self.main.set_options(dict(**folders, **files))</span>
<span class="gi">+</span>
<span class="gi">+    def protocol_changed(self, *_):</span>
<span class="gi">+        self._fs = None</span>
<span class="gi">+        self.main.options = []</span>
<span class="gi">+        self.url.value = &quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def home_clicked(self, *_):</span>
<span class="gi">+        self.protocol.value = self.init_protocol</span>
<span class="gi">+        self.kwargs.value = self.init_kwargs</span>
<span class="gi">+        self.url.value = self.init_url</span>
<span class="gi">+        self.go_clicked()</span>
<span class="gi">+</span>
<span class="gi">+    def up_clicked(self, *_):</span>
<span class="gi">+        self.url.value = self.fs._parent(self.url.value)</span>
<span class="gi">+        self.go_clicked()</span>
<span class="gh">diff --git a/fsspec/implementations/arrow.py b/fsspec/implementations/arrow.py</span>
<span class="gh">index e065995..f9fea70 100644</span>
<span class="gd">--- a/fsspec/implementations/arrow.py</span>
<span class="gi">+++ b/fsspec/implementations/arrow.py</span>
<span class="gu">@@ -6,8 +6,34 @@ import shutil</span>
<span class="w"> </span>from contextlib import suppress
<span class="w"> </span>from functools import cached_property, wraps
<span class="w"> </span>from urllib.parse import parse_qs
<span class="gi">+</span>
<span class="w"> </span>from fsspec.spec import AbstractFileSystem
<span class="gd">-from fsspec.utils import get_package_version_without_import, infer_storage_options, mirror_from, tokenize</span>
<span class="gi">+from fsspec.utils import (</span>
<span class="gi">+    get_package_version_without_import,</span>
<span class="gi">+    infer_storage_options,</span>
<span class="gi">+    mirror_from,</span>
<span class="gi">+    tokenize,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def wrap_exceptions(func):</span>
<span class="gi">+    @wraps(func)</span>
<span class="gi">+    def wrapper(*args, **kwargs):</span>
<span class="gi">+        try:</span>
<span class="gi">+            return func(*args, **kwargs)</span>
<span class="gi">+        except OSError as exception:</span>
<span class="gi">+            if not exception.args:</span>
<span class="gi">+                raise</span>
<span class="gi">+</span>
<span class="gi">+            message, *args = exception.args</span>
<span class="gi">+            if isinstance(message, str) and &quot;does not exist&quot; in message:</span>
<span class="gi">+                raise FileNotFoundError(errno.ENOENT, message) from exception</span>
<span class="gi">+            else:</span>
<span class="gi">+                raise</span>
<span class="gi">+</span>
<span class="gi">+    return wrapper</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>PYARROW_VERSION = None


<span class="gu">@@ -19,24 +45,193 @@ class ArrowFSWrapper(AbstractFileSystem):</span>
<span class="w"> </span>    fs : pyarrow.fs.FileSystem

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    root_marker = &#39;/&#39;</span>
<span class="gi">+</span>
<span class="gi">+    root_marker = &quot;/&quot;</span>

<span class="w"> </span>    def __init__(self, fs, **kwargs):
<span class="w"> </span>        global PYARROW_VERSION
<span class="gd">-        PYARROW_VERSION = get_package_version_without_import(&#39;pyarrow&#39;)</span>
<span class="gi">+        PYARROW_VERSION = get_package_version_without_import(&quot;pyarrow&quot;)</span>
<span class="w"> </span>        self.fs = fs
<span class="w"> </span>        super().__init__(**kwargs)

<span class="gi">+    @property</span>
<span class="gi">+    def protocol(self):</span>
<span class="gi">+        return self.fs.type_name</span>

<span class="gd">-@mirror_from(&#39;stream&#39;, [&#39;read&#39;, &#39;seek&#39;, &#39;tell&#39;, &#39;write&#39;, &#39;readable&#39;,</span>
<span class="gd">-    &#39;writable&#39;, &#39;close&#39;, &#39;size&#39;, &#39;seekable&#39;])</span>
<span class="gd">-class ArrowFile(io.IOBase):</span>
<span class="gi">+    @cached_property</span>
<span class="gi">+    def fsid(self):</span>
<span class="gi">+        return &quot;hdfs_&quot; + tokenize(self.fs.host, self.fs.port)</span>
<span class="gi">+</span>
<span class="gi">+    @classmethod</span>
<span class="gi">+    def _strip_protocol(cls, path):</span>
<span class="gi">+        ops = infer_storage_options(path)</span>
<span class="gi">+        path = ops[&quot;path&quot;]</span>
<span class="gi">+        if path.startswith(&quot;//&quot;):</span>
<span class="gi">+            # special case for &quot;hdfs://path&quot; (without the triple slash)</span>
<span class="gi">+            path = path[1:]</span>
<span class="gi">+        return path</span>
<span class="gi">+</span>
<span class="gi">+    def ls(self, path, detail=False, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        from pyarrow.fs import FileSelector</span>
<span class="gi">+</span>
<span class="gi">+        entries = [</span>
<span class="gi">+            self._make_entry(entry)</span>
<span class="gi">+            for entry in self.fs.get_file_info(FileSelector(path))</span>
<span class="gi">+        ]</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return entries</span>
<span class="gi">+        else:</span>
<span class="gi">+            return [entry[&quot;name&quot;] for entry in entries]</span>
<span class="gi">+</span>
<span class="gi">+    def info(self, path, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        [info] = self.fs.get_file_info([path])</span>
<span class="gi">+        return self._make_entry(info)</span>
<span class="gi">+</span>
<span class="gi">+    def exists(self, path):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        try:</span>
<span class="gi">+            self.info(path)</span>
<span class="gi">+        except FileNotFoundError:</span>
<span class="gi">+            return False</span>
<span class="gi">+        else:</span>
<span class="gi">+            return True</span>
<span class="gi">+</span>
<span class="gi">+    def _make_entry(self, info):</span>
<span class="gi">+        from pyarrow.fs import FileType</span>
<span class="gi">+</span>
<span class="gi">+        if info.type is FileType.Directory:</span>
<span class="gi">+            kind = &quot;directory&quot;</span>
<span class="gi">+        elif info.type is FileType.File:</span>
<span class="gi">+            kind = &quot;file&quot;</span>
<span class="gi">+        elif info.type is FileType.NotFound:</span>
<span class="gi">+            raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), info.path)</span>
<span class="gi">+        else:</span>
<span class="gi">+            kind = &quot;other&quot;</span>
<span class="gi">+</span>
<span class="gi">+        return {</span>
<span class="gi">+            &quot;name&quot;: info.path,</span>
<span class="gi">+            &quot;size&quot;: info.size,</span>
<span class="gi">+            &quot;type&quot;: kind,</span>
<span class="gi">+            &quot;mtime&quot;: info.mtime,</span>
<span class="gi">+        }</span>
<span class="gi">+</span>
<span class="gi">+    @wrap_exceptions</span>
<span class="gi">+    def cp_file(self, path1, path2, **kwargs):</span>
<span class="gi">+        path1 = self._strip_protocol(path1).rstrip(&quot;/&quot;)</span>
<span class="gi">+        path2 = self._strip_protocol(path2).rstrip(&quot;/&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        with self._open(path1, &quot;rb&quot;) as lstream:</span>
<span class="gi">+            tmp_fname = f&quot;{path2}.tmp.{secrets.token_hex(6)}&quot;</span>
<span class="gi">+            try:</span>
<span class="gi">+                with self.open(tmp_fname, &quot;wb&quot;) as rstream:</span>
<span class="gi">+                    shutil.copyfileobj(lstream, rstream)</span>
<span class="gi">+                self.fs.move(tmp_fname, path2)</span>
<span class="gi">+            except BaseException:  # noqa</span>
<span class="gi">+                with suppress(FileNotFoundError):</span>
<span class="gi">+                    self.fs.delete_file(tmp_fname)</span>
<span class="gi">+                raise</span>

<span class="gi">+    @wrap_exceptions</span>
<span class="gi">+    def mv(self, path1, path2, **kwargs):</span>
<span class="gi">+        path1 = self._strip_protocol(path1).rstrip(&quot;/&quot;)</span>
<span class="gi">+        path2 = self._strip_protocol(path2).rstrip(&quot;/&quot;)</span>
<span class="gi">+        self.fs.move(path1, path2)</span>
<span class="gi">+</span>
<span class="gi">+    @wrap_exceptions</span>
<span class="gi">+    def rm_file(self, path):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        self.fs.delete_file(path)</span>
<span class="gi">+</span>
<span class="gi">+    @wrap_exceptions</span>
<span class="gi">+    def rm(self, path, recursive=False, maxdepth=None):</span>
<span class="gi">+        path = self._strip_protocol(path).rstrip(&quot;/&quot;)</span>
<span class="gi">+        if self.isdir(path):</span>
<span class="gi">+            if recursive:</span>
<span class="gi">+                self.fs.delete_dir(path)</span>
<span class="gi">+            else:</span>
<span class="gi">+                raise ValueError(&quot;Can&#39;t delete directories without recursive=False&quot;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.fs.delete_file(path)</span>
<span class="gi">+</span>
<span class="gi">+    @wrap_exceptions</span>
<span class="gi">+    def _open(self, path, mode=&quot;rb&quot;, block_size=None, seekable=True, **kwargs):</span>
<span class="gi">+        if mode == &quot;rb&quot;:</span>
<span class="gi">+            if seekable:</span>
<span class="gi">+                method = self.fs.open_input_file</span>
<span class="gi">+            else:</span>
<span class="gi">+                method = self.fs.open_input_stream</span>
<span class="gi">+        elif mode == &quot;wb&quot;:</span>
<span class="gi">+            method = self.fs.open_output_stream</span>
<span class="gi">+        elif mode == &quot;ab&quot;:</span>
<span class="gi">+            method = self.fs.open_append_stream</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise ValueError(f&quot;unsupported mode for Arrow filesystem: {mode!r}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        _kwargs = {}</span>
<span class="gi">+        if mode != &quot;rb&quot; or not seekable:</span>
<span class="gi">+            if int(PYARROW_VERSION.split(&quot;.&quot;)[0]) &gt;= 4:</span>
<span class="gi">+                # disable compression auto-detection</span>
<span class="gi">+                _kwargs[&quot;compression&quot;] = None</span>
<span class="gi">+        stream = method(path, **_kwargs)</span>
<span class="gi">+</span>
<span class="gi">+        return ArrowFile(self, stream, path, mode, block_size, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    @wrap_exceptions</span>
<span class="gi">+    def mkdir(self, path, create_parents=True, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if create_parents:</span>
<span class="gi">+            self.makedirs(path, exist_ok=True)</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.fs.create_dir(path, recursive=False)</span>
<span class="gi">+</span>
<span class="gi">+    @wrap_exceptions</span>
<span class="gi">+    def makedirs(self, path, exist_ok=False):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        self.fs.create_dir(path, recursive=True)</span>
<span class="gi">+</span>
<span class="gi">+    @wrap_exceptions</span>
<span class="gi">+    def rmdir(self, path):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        self.fs.delete_dir(path)</span>
<span class="gi">+</span>
<span class="gi">+    @wrap_exceptions</span>
<span class="gi">+    def modified(self, path):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        return self.fs.get_file_info(path).mtime</span>
<span class="gi">+</span>
<span class="gi">+    def cat_file(self, path, start=None, end=None, **kwargs):</span>
<span class="gi">+        kwargs[&quot;seekable&quot;] = start not in [None, 0]</span>
<span class="gi">+        return super().cat_file(path, start=None, end=None, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def get_file(self, rpath, lpath, **kwargs):</span>
<span class="gi">+        kwargs[&quot;seekable&quot;] = False</span>
<span class="gi">+        super().get_file(rpath, lpath, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@mirror_from(</span>
<span class="gi">+    &quot;stream&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        &quot;read&quot;,</span>
<span class="gi">+        &quot;seek&quot;,</span>
<span class="gi">+        &quot;tell&quot;,</span>
<span class="gi">+        &quot;write&quot;,</span>
<span class="gi">+        &quot;readable&quot;,</span>
<span class="gi">+        &quot;writable&quot;,</span>
<span class="gi">+        &quot;close&quot;,</span>
<span class="gi">+        &quot;size&quot;,</span>
<span class="gi">+        &quot;seekable&quot;,</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+class ArrowFile(io.IOBase):</span>
<span class="w"> </span>    def __init__(self, fs, stream, path, mode, block_size=None, **kwargs):
<span class="w"> </span>        self.path = path
<span class="w"> </span>        self.mode = mode
<span class="gi">+</span>
<span class="w"> </span>        self.fs = fs
<span class="w"> </span>        self.stream = stream
<span class="gi">+</span>
<span class="w"> </span>        self.blocksize = self.block_size = block_size
<span class="w"> </span>        self.kwargs = kwargs

<span class="gu">@@ -50,10 +245,19 @@ class ArrowFile(io.IOBase):</span>
<span class="w"> </span>class HadoopFileSystem(ArrowFSWrapper):
<span class="w"> </span>    &quot;&quot;&quot;A wrapper on top of the pyarrow.fs.HadoopFileSystem
<span class="w"> </span>    to connect it&#39;s interface with fsspec&quot;&quot;&quot;
<span class="gd">-    protocol = &#39;hdfs&#39;</span>

<span class="gd">-    def __init__(self, host=&#39;default&#39;, port=0, user=None, kerb_ticket=None,</span>
<span class="gd">-        replication=3, extra_conf=None, **kwargs):</span>
<span class="gi">+    protocol = &quot;hdfs&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        host=&quot;default&quot;,</span>
<span class="gi">+        port=0,</span>
<span class="gi">+        user=None,</span>
<span class="gi">+        kerb_ticket=None,</span>
<span class="gi">+        replication=3,</span>
<span class="gi">+        extra_conf=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;

<span class="w"> </span>        Parameters
<span class="gu">@@ -72,6 +276,29 @@ class HadoopFileSystem(ArrowFSWrapper):</span>
<span class="w"> </span>            Passed on to HadoopFileSystem
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        from pyarrow.fs import HadoopFileSystem
<span class="gd">-        fs = HadoopFileSystem(host=host, port=port, user=user, kerb_ticket=</span>
<span class="gd">-            kerb_ticket, replication=replication, extra_conf=extra_conf)</span>
<span class="gi">+</span>
<span class="gi">+        fs = HadoopFileSystem(</span>
<span class="gi">+            host=host,</span>
<span class="gi">+            port=port,</span>
<span class="gi">+            user=user,</span>
<span class="gi">+            kerb_ticket=kerb_ticket,</span>
<span class="gi">+            replication=replication,</span>
<span class="gi">+            extra_conf=extra_conf,</span>
<span class="gi">+        )</span>
<span class="w"> </span>        super().__init__(fs=fs, **kwargs)
<span class="gi">+</span>
<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _get_kwargs_from_urls(path):</span>
<span class="gi">+        ops = infer_storage_options(path)</span>
<span class="gi">+        out = {}</span>
<span class="gi">+        if ops.get(&quot;host&quot;, None):</span>
<span class="gi">+            out[&quot;host&quot;] = ops[&quot;host&quot;]</span>
<span class="gi">+        if ops.get(&quot;username&quot;, None):</span>
<span class="gi">+            out[&quot;user&quot;] = ops[&quot;username&quot;]</span>
<span class="gi">+        if ops.get(&quot;port&quot;, None):</span>
<span class="gi">+            out[&quot;port&quot;] = ops[&quot;port&quot;]</span>
<span class="gi">+        if ops.get(&quot;url_query&quot;, None):</span>
<span class="gi">+            queries = parse_qs(ops[&quot;url_query&quot;])</span>
<span class="gi">+            if queries.get(&quot;replication&quot;, None):</span>
<span class="gi">+                out[&quot;replication&quot;] = int(queries[&quot;replication&quot;][0])</span>
<span class="gi">+        return out</span>
<span class="gh">diff --git a/fsspec/implementations/cache_mapper.py b/fsspec/implementations/cache_mapper.py</span>
<span class="gh">index 3294867..6e7c7d8 100644</span>
<span class="gd">--- a/fsspec/implementations/cache_mapper.py</span>
<span class="gi">+++ b/fsspec/implementations/cache_mapper.py</span>
<span class="gu">@@ -1,6 +1,8 @@</span>
<span class="w"> </span>from __future__ import annotations
<span class="gi">+</span>
<span class="w"> </span>import abc
<span class="w"> </span>import hashlib
<span class="gi">+</span>
<span class="w"> </span>from fsspec.implementations.local import make_path_posix


<span class="gu">@@ -10,13 +12,16 @@ class AbstractCacheMapper(abc.ABC):</span>
<span class="w"> </span>    &quot;&quot;&quot;

<span class="w"> </span>    @abc.abstractmethod
<span class="gd">-    def __call__(self, path: str) -&gt;str:</span>
<span class="gd">-        ...</span>
<span class="gi">+    def __call__(self, path: str) -&gt; str: ...</span>

<span class="gd">-    def __eq__(self, other: object) -&gt;bool:</span>
<span class="gi">+    def __eq__(self, other: object) -&gt; bool:</span>
<span class="gi">+        # Identity only depends on class. When derived classes have attributes</span>
<span class="gi">+        # they will need to be included.</span>
<span class="w"> </span>        return isinstance(other, type(self))

<span class="gd">-    def __hash__(self) -&gt;int:</span>
<span class="gi">+    def __hash__(self) -&gt; int:</span>
<span class="gi">+        # Identity only depends on class. When derived classes have attributes</span>
<span class="gi">+        # they will need to be included.</span>
<span class="w"> </span>        return hash(type(self))


<span class="gu">@@ -28,39 +33,43 @@ class BasenameCacheMapper(AbstractCacheMapper):</span>
<span class="w"> </span>    basename will have the same cached basename.
<span class="w"> </span>    &quot;&quot;&quot;

<span class="gd">-    def __init__(self, directory_levels: int=0):</span>
<span class="gi">+    def __init__(self, directory_levels: int = 0):</span>
<span class="w"> </span>        if directory_levels &lt; 0:
<span class="w"> </span>            raise ValueError(
<span class="gd">-                &#39;BasenameCacheMapper requires zero or positive directory_levels&#39;</span>
<span class="gd">-                )</span>
<span class="gi">+                &quot;BasenameCacheMapper requires zero or positive directory_levels&quot;</span>
<span class="gi">+            )</span>
<span class="w"> </span>        self.directory_levels = directory_levels
<span class="gd">-        self._separator = &#39;_@_&#39;</span>

<span class="gd">-    def __call__(self, path: str) -&gt;str:</span>
<span class="gi">+        # Separator for directories when encoded as strings.</span>
<span class="gi">+        self._separator = &quot;_@_&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def __call__(self, path: str) -&gt; str:</span>
<span class="w"> </span>        path = make_path_posix(path)
<span class="gd">-        prefix, *bits = path.rsplit(&#39;/&#39;, self.directory_levels + 1)</span>
<span class="gi">+        prefix, *bits = path.rsplit(&quot;/&quot;, self.directory_levels + 1)</span>
<span class="w"> </span>        if bits:
<span class="w"> </span>            return self._separator.join(bits)
<span class="w"> </span>        else:
<span class="gd">-            return prefix</span>
<span class="gi">+            return prefix  # No separator found, simple filename</span>

<span class="gd">-    def __eq__(self, other: object) -&gt;bool:</span>
<span class="gd">-        return super().__eq__(other</span>
<span class="gd">-            ) and self.directory_levels == other.directory_levels</span>
<span class="gi">+    def __eq__(self, other: object) -&gt; bool:</span>
<span class="gi">+        return super().__eq__(other) and self.directory_levels == other.directory_levels</span>

<span class="gd">-    def __hash__(self) -&gt;int:</span>
<span class="gi">+    def __hash__(self) -&gt; int:</span>
<span class="w"> </span>        return super().__hash__() ^ hash(self.directory_levels)


<span class="w"> </span>class HashCacheMapper(AbstractCacheMapper):
<span class="w"> </span>    &quot;&quot;&quot;Cache mapper that uses a hash of the remote URL.&quot;&quot;&quot;

<span class="gd">-    def __call__(self, path: str) -&gt;str:</span>
<span class="gi">+    def __call__(self, path: str) -&gt; str:</span>
<span class="w"> </span>        return hashlib.sha256(path.encode()).hexdigest()


<span class="gd">-def create_cache_mapper(same_names: bool) -&gt;AbstractCacheMapper:</span>
<span class="gi">+def create_cache_mapper(same_names: bool) -&gt; AbstractCacheMapper:</span>
<span class="w"> </span>    &quot;&quot;&quot;Factory method to create cache mapper for backward compatibility with
<span class="w"> </span>    ``CachingFileSystem`` constructor using ``same_names`` kwarg.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if same_names:</span>
<span class="gi">+        return BasenameCacheMapper()</span>
<span class="gi">+    else:</span>
<span class="gi">+        return HashCacheMapper()</span>
<span class="gh">diff --git a/fsspec/implementations/cache_metadata.py b/fsspec/implementations/cache_metadata.py</span>
<span class="gh">index 9a2c33e..bd9b5cd 100644</span>
<span class="gd">--- a/fsspec/implementations/cache_metadata.py</span>
<span class="gi">+++ b/fsspec/implementations/cache_metadata.py</span>
<span class="gu">@@ -1,18 +1,25 @@</span>
<span class="w"> </span>from __future__ import annotations
<span class="gi">+</span>
<span class="w"> </span>import os
<span class="w"> </span>import pickle
<span class="w"> </span>import time
<span class="w"> </span>from typing import TYPE_CHECKING
<span class="gi">+</span>
<span class="w"> </span>from fsspec.utils import atomic_write
<span class="gi">+</span>
<span class="w"> </span>try:
<span class="w"> </span>    import ujson as json
<span class="w"> </span>except ImportError:
<span class="w"> </span>    if not TYPE_CHECKING:
<span class="w"> </span>        import json
<span class="gi">+</span>
<span class="w"> </span>if TYPE_CHECKING:
<span class="w"> </span>    from typing import Any, Dict, Iterator, Literal
<span class="gi">+</span>
<span class="w"> </span>    from typing_extensions import TypeAlias
<span class="gi">+</span>
<span class="w"> </span>    from .cached import CachingFileSystem
<span class="gi">+</span>
<span class="w"> </span>    Detail: TypeAlias = Dict[str, Any]


<span class="gu">@@ -37,22 +44,40 @@ class CacheMetadata:</span>
<span class="w"> </span>            is stored in the last of these directories by convention.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        if not storage:
<span class="gd">-            raise ValueError(</span>
<span class="gd">-                &#39;CacheMetadata expects at least one storage location&#39;)</span>
<span class="gi">+            raise ValueError(&quot;CacheMetadata expects at least one storage location&quot;)</span>
<span class="gi">+</span>
<span class="w"> </span>        self._storage = storage
<span class="w"> </span>        self.cached_files: list[Detail] = [{}]
<span class="gi">+</span>
<span class="gi">+        # Private attribute to force saving of metadata in pickle format rather than</span>
<span class="gi">+        # JSON for use in tests to confirm can read both pickle and JSON formats.</span>
<span class="w"> </span>        self._force_save_pickle = False

<span class="gd">-    def _load(self, fn: str) -&gt;Detail:</span>
<span class="gi">+    def _load(self, fn: str) -&gt; Detail:</span>
<span class="w"> </span>        &quot;&quot;&quot;Low-level function to load metadata from specific file&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def _save(self, metadata_to_save: Detail, fn: str) -&gt;None:</span>
<span class="gi">+        try:</span>
<span class="gi">+            with open(fn, &quot;r&quot;) as f:</span>
<span class="gi">+                loaded = json.load(f)</span>
<span class="gi">+        except ValueError:</span>
<span class="gi">+            with open(fn, &quot;rb&quot;) as f:</span>
<span class="gi">+                loaded = pickle.load(f)</span>
<span class="gi">+        for c in loaded.values():</span>
<span class="gi">+            if isinstance(c.get(&quot;blocks&quot;), list):</span>
<span class="gi">+                c[&quot;blocks&quot;] = set(c[&quot;blocks&quot;])</span>
<span class="gi">+        return loaded</span>
<span class="gi">+</span>
<span class="gi">+    def _save(self, metadata_to_save: Detail, fn: str) -&gt; None:</span>
<span class="w"> </span>        &quot;&quot;&quot;Low-level function to save metadata to specific file&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def _scan_locations(self, writable_only: bool=False) -&gt;Iterator[tuple[</span>
<span class="gd">-        str, str, bool]]:</span>
<span class="gi">+        if self._force_save_pickle:</span>
<span class="gi">+            with atomic_write(fn) as f:</span>
<span class="gi">+                pickle.dump(metadata_to_save, f)</span>
<span class="gi">+        else:</span>
<span class="gi">+            with atomic_write(fn, mode=&quot;w&quot;) as f:</span>
<span class="gi">+                json.dump(metadata_to_save, f)</span>
<span class="gi">+</span>
<span class="gi">+    def _scan_locations(</span>
<span class="gi">+        self, writable_only: bool = False</span>
<span class="gi">+    ) -&gt; Iterator[tuple[str, str, bool]]:</span>
<span class="w"> </span>        &quot;&quot;&quot;Yield locations (filenames) where metadata is stored, and whether
<span class="w"> </span>        writable or not.

<span class="gu">@@ -65,51 +90,143 @@ class CacheMetadata:</span>
<span class="w"> </span>        -------
<span class="w"> </span>        Yields (str, str, bool)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def check_file(self, path: str, cfs: (CachingFileSystem | None)) -&gt;(Literal</span>
<span class="gd">-        [False] | tuple[Detail, str]):</span>
<span class="gi">+        n = len(self._storage)</span>
<span class="gi">+        for i, storage in enumerate(self._storage):</span>
<span class="gi">+            writable = i == n - 1</span>
<span class="gi">+            if writable_only and not writable:</span>
<span class="gi">+                continue</span>
<span class="gi">+            yield os.path.join(storage, &quot;cache&quot;), storage, writable</span>
<span class="gi">+</span>
<span class="gi">+    def check_file(</span>
<span class="gi">+        self, path: str, cfs: CachingFileSystem | None</span>
<span class="gi">+    ) -&gt; Literal[False] | tuple[Detail, str]:</span>
<span class="w"> </span>        &quot;&quot;&quot;If path is in cache return its details, otherwise return ``False``.

<span class="w"> </span>        If the optional CachingFileSystem is specified then it is used to
<span class="w"> </span>        perform extra checks to reject possible matches, such as if they are
<span class="w"> </span>        too old.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def clear_expired(self, expiry_time: int) -&gt;tuple[list[str], bool]:</span>
<span class="gi">+        for (fn, base, _), cache in zip(self._scan_locations(), self.cached_files):</span>
<span class="gi">+            if path not in cache:</span>
<span class="gi">+                continue</span>
<span class="gi">+            detail = cache[path].copy()</span>
<span class="gi">+</span>
<span class="gi">+            if cfs is not None:</span>
<span class="gi">+                if cfs.check_files and detail[&quot;uid&quot;] != cfs.fs.ukey(path):</span>
<span class="gi">+                    # Wrong file as determined by hash of file properties</span>
<span class="gi">+                    continue</span>
<span class="gi">+                if cfs.expiry and time.time() - detail[&quot;time&quot;] &gt; cfs.expiry:</span>
<span class="gi">+                    # Cached file has expired</span>
<span class="gi">+                    continue</span>
<span class="gi">+</span>
<span class="gi">+            fn = os.path.join(base, detail[&quot;fn&quot;])</span>
<span class="gi">+            if os.path.exists(fn):</span>
<span class="gi">+                return detail, fn</span>
<span class="gi">+        return False</span>
<span class="gi">+</span>
<span class="gi">+    def clear_expired(self, expiry_time: int) -&gt; tuple[list[str], bool]:</span>
<span class="w"> </span>        &quot;&quot;&quot;Remove expired metadata from the cache.

<span class="w"> </span>        Returns names of files corresponding to expired metadata and a boolean
<span class="w"> </span>        flag indicating whether the writable cache is empty. Caller is
<span class="w"> </span>        responsible for deleting the expired files.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def load(self) -&gt;None:</span>
<span class="gi">+        expired_files = []</span>
<span class="gi">+        for path, detail in self.cached_files[-1].copy().items():</span>
<span class="gi">+            if time.time() - detail[&quot;time&quot;] &gt; expiry_time:</span>
<span class="gi">+                fn = detail.get(&quot;fn&quot;, &quot;&quot;)</span>
<span class="gi">+                if not fn:</span>
<span class="gi">+                    raise RuntimeError(</span>
<span class="gi">+                        f&quot;Cache metadata does not contain &#39;fn&#39; for {path}&quot;</span>
<span class="gi">+                    )</span>
<span class="gi">+                fn = os.path.join(self._storage[-1], fn)</span>
<span class="gi">+                expired_files.append(fn)</span>
<span class="gi">+                self.cached_files[-1].pop(path)</span>
<span class="gi">+</span>
<span class="gi">+        if self.cached_files[-1]:</span>
<span class="gi">+            cache_path = os.path.join(self._storage[-1], &quot;cache&quot;)</span>
<span class="gi">+            self._save(self.cached_files[-1], cache_path)</span>
<span class="gi">+</span>
<span class="gi">+        writable_cache_empty = not self.cached_files[-1]</span>
<span class="gi">+        return expired_files, writable_cache_empty</span>
<span class="gi">+</span>
<span class="gi">+    def load(self) -&gt; None:</span>
<span class="w"> </span>        &quot;&quot;&quot;Load all metadata from disk and store in ``self.cached_files``&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def on_close_cached_file(self, f: Any, path: str) -&gt;None:</span>
<span class="gi">+        cached_files = []</span>
<span class="gi">+        for fn, _, _ in self._scan_locations():</span>
<span class="gi">+            if os.path.exists(fn):</span>
<span class="gi">+                # TODO: consolidate blocks here</span>
<span class="gi">+                cached_files.append(self._load(fn))</span>
<span class="gi">+            else:</span>
<span class="gi">+                cached_files.append({})</span>
<span class="gi">+        self.cached_files = cached_files or [{}]</span>
<span class="gi">+</span>
<span class="gi">+    def on_close_cached_file(self, f: Any, path: str) -&gt; None:</span>
<span class="w"> </span>        &quot;&quot;&quot;Perform side-effect actions on closing a cached file.

<span class="w"> </span>        The actual closing of the file is the responsibility of the caller.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # File must be writeble, so in self.cached_files[-1]</span>
<span class="gi">+        c = self.cached_files[-1][path]</span>
<span class="gi">+        if c[&quot;blocks&quot;] is not True and len(c[&quot;blocks&quot;]) * f.blocksize &gt;= f.size:</span>
<span class="gi">+            c[&quot;blocks&quot;] = True</span>

<span class="gd">-    def pop_file(self, path: str) -&gt;(str | None):</span>
<span class="gi">+    def pop_file(self, path: str) -&gt; str | None:</span>
<span class="w"> </span>        &quot;&quot;&quot;Remove metadata of cached file.

<span class="w"> </span>        If path is in the cache, return the filename of the cached file,
<span class="w"> </span>        otherwise return ``None``.  Caller is responsible for deleting the
<span class="w"> </span>        cached file.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def save(self) -&gt;None:</span>
<span class="gi">+        details = self.check_file(path, None)</span>
<span class="gi">+        if not details:</span>
<span class="gi">+            return None</span>
<span class="gi">+        _, fn = details</span>
<span class="gi">+        if fn.startswith(self._storage[-1]):</span>
<span class="gi">+            self.cached_files[-1].pop(path)</span>
<span class="gi">+            self.save()</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise PermissionError(</span>
<span class="gi">+                &quot;Can only delete cached file in last, writable cache location&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        return fn</span>
<span class="gi">+</span>
<span class="gi">+    def save(self) -&gt; None:</span>
<span class="w"> </span>        &quot;&quot;&quot;Save metadata to disk&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def update_file(self, path: str, detail: Detail) -&gt;None:</span>
<span class="gi">+        for (fn, _, writable), cache in zip(self._scan_locations(), self.cached_files):</span>
<span class="gi">+            if not writable:</span>
<span class="gi">+                continue</span>
<span class="gi">+</span>
<span class="gi">+            if os.path.exists(fn):</span>
<span class="gi">+                cached_files = self._load(fn)</span>
<span class="gi">+                for k, c in cached_files.items():</span>
<span class="gi">+                    if k in cache:</span>
<span class="gi">+                        if c[&quot;blocks&quot;] is True or cache[k][&quot;blocks&quot;] is True:</span>
<span class="gi">+                            c[&quot;blocks&quot;] = True</span>
<span class="gi">+                        else:</span>
<span class="gi">+                            # self.cached_files[*][*][&quot;blocks&quot;] must continue to</span>
<span class="gi">+                            # point to the same set object so that updates</span>
<span class="gi">+                            # performed by MMapCache are propagated back to</span>
<span class="gi">+                            # self.cached_files.</span>
<span class="gi">+                            blocks = cache[k][&quot;blocks&quot;]</span>
<span class="gi">+                            blocks.update(c[&quot;blocks&quot;])</span>
<span class="gi">+                            c[&quot;blocks&quot;] = blocks</span>
<span class="gi">+                        c[&quot;time&quot;] = max(c[&quot;time&quot;], cache[k][&quot;time&quot;])</span>
<span class="gi">+                        c[&quot;uid&quot;] = cache[k][&quot;uid&quot;]</span>
<span class="gi">+</span>
<span class="gi">+                # Files can be added to cache after it was written once</span>
<span class="gi">+                for k, c in cache.items():</span>
<span class="gi">+                    if k not in cached_files:</span>
<span class="gi">+                        cached_files[k] = c</span>
<span class="gi">+            else:</span>
<span class="gi">+                cached_files = cache</span>
<span class="gi">+            cache = {k: v.copy() for k, v in cached_files.items()}</span>
<span class="gi">+            for c in cache.values():</span>
<span class="gi">+                if isinstance(c[&quot;blocks&quot;], set):</span>
<span class="gi">+                    c[&quot;blocks&quot;] = list(c[&quot;blocks&quot;])</span>
<span class="gi">+            self._save(cache, fn)</span>
<span class="gi">+            self.cached_files[-1] = cached_files</span>
<span class="gi">+</span>
<span class="gi">+    def update_file(self, path: str, detail: Detail) -&gt; None:</span>
<span class="w"> </span>        &quot;&quot;&quot;Update metadata for specific file in memory, do not save&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.cached_files[-1][path] = detail</span>
<span class="gh">diff --git a/fsspec/implementations/cached.py b/fsspec/implementations/cached.py</span>
<span class="gh">index bd56e3c..447e4f2 100644</span>
<span class="gd">--- a/fsspec/implementations/cached.py</span>
<span class="gi">+++ b/fsspec/implementations/cached.py</span>
<span class="gu">@@ -1,4 +1,5 @@</span>
<span class="w"> </span>from __future__ import annotations
<span class="gi">+</span>
<span class="w"> </span>import inspect
<span class="w"> </span>import logging
<span class="w"> </span>import os
<span class="gu">@@ -7,6 +8,7 @@ import time</span>
<span class="w"> </span>import weakref
<span class="w"> </span>from shutil import rmtree
<span class="w"> </span>from typing import TYPE_CHECKING, Any, Callable, ClassVar
<span class="gi">+</span>
<span class="w"> </span>from fsspec import AbstractFileSystem, filesystem
<span class="w"> </span>from fsspec.callbacks import DEFAULT_CALLBACK
<span class="w"> </span>from fsspec.compression import compr
<span class="gu">@@ -17,13 +19,23 @@ from fsspec.implementations.cache_metadata import CacheMetadata</span>
<span class="w"> </span>from fsspec.spec import AbstractBufferedFile
<span class="w"> </span>from fsspec.transaction import Transaction
<span class="w"> </span>from fsspec.utils import infer_compression
<span class="gi">+</span>
<span class="w"> </span>if TYPE_CHECKING:
<span class="w"> </span>    from fsspec.implementations.cache_mapper import AbstractCacheMapper
<span class="gd">-logger = logging.getLogger(&#39;fsspec.cached&#39;)</span>
<span class="gi">+</span>
<span class="gi">+logger = logging.getLogger(&quot;fsspec.cached&quot;)</span>


<span class="w"> </span>class WriteCachedTransaction(Transaction):
<span class="gd">-    pass</span>
<span class="gi">+    def complete(self, commit=True):</span>
<span class="gi">+        rpaths = [f.path for f in self.files]</span>
<span class="gi">+        lpaths = [f.fn for f in self.files]</span>
<span class="gi">+        if commit:</span>
<span class="gi">+            self.fs.put(lpaths, rpaths)</span>
<span class="gi">+        self.files.clear()</span>
<span class="gi">+        self.fs._intrans = False</span>
<span class="gi">+        self.fs._transaction = None</span>
<span class="gi">+        self.fs = None  # break cycle</span>


<span class="w"> </span>class CachingFileSystem(AbstractFileSystem):
<span class="gu">@@ -45,13 +57,23 @@ class CachingFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>      derived from fsspec.spec.AbstractBufferedFile ; LocalFileSystem is also
<span class="w"> </span>      allowed, for testing
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    protocol: ClassVar[str | tuple[str, ...]] = (&#39;blockcache&#39;, &#39;cached&#39;)</span>

<span class="gd">-    def __init__(self, target_protocol=None, cache_storage=&#39;TMP&#39;,</span>
<span class="gd">-        cache_check=10, check_files=False, expiry_time=604800,</span>
<span class="gd">-        target_options=None, fs=None, same_names: (bool | None)=None,</span>
<span class="gd">-        compression=None, cache_mapper: (AbstractCacheMapper | None)=None,</span>
<span class="gd">-        **kwargs):</span>
<span class="gi">+    protocol: ClassVar[str | tuple[str, ...]] = (&quot;blockcache&quot;, &quot;cached&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        target_protocol=None,</span>
<span class="gi">+        cache_storage=&quot;TMP&quot;,</span>
<span class="gi">+        cache_check=10,</span>
<span class="gi">+        check_files=False,</span>
<span class="gi">+        expiry_time=604800,</span>
<span class="gi">+        target_options=None,</span>
<span class="gi">+        fs=None,</span>
<span class="gi">+        same_names: bool | None = None,</span>
<span class="gi">+        compression=None,</span>
<span class="gi">+        cache_mapper: AbstractCacheMapper | None = None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;

<span class="w"> </span>        Parameters
<span class="gu">@@ -96,19 +118,21 @@ class CachingFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        super().__init__(**kwargs)
<span class="w"> </span>        if fs is None and target_protocol is None:
<span class="w"> </span>            raise ValueError(
<span class="gd">-                &#39;Please provide filesystem instance(fs) or target_protocol&#39;)</span>
<span class="gi">+                &quot;Please provide filesystem instance(fs) or target_protocol&quot;</span>
<span class="gi">+            )</span>
<span class="w"> </span>        if not (fs is None) ^ (target_protocol is None):
<span class="w"> </span>            raise ValueError(
<span class="gd">-                &#39;Both filesystems (fs) and target_protocol may not be both given.&#39;</span>
<span class="gd">-                )</span>
<span class="gd">-        if cache_storage == &#39;TMP&#39;:</span>
<span class="gi">+                &quot;Both filesystems (fs) and target_protocol may not be both given.&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        if cache_storage == &quot;TMP&quot;:</span>
<span class="w"> </span>            tempdir = tempfile.mkdtemp()
<span class="w"> </span>            storage = [tempdir]
<span class="w"> </span>            weakref.finalize(self, self._remove_tempdir, tempdir)
<span class="gd">-        elif isinstance(cache_storage, str):</span>
<span class="gd">-            storage = [cache_storage]</span>
<span class="w"> </span>        else:
<span class="gd">-            storage = cache_storage</span>
<span class="gi">+            if isinstance(cache_storage, str):</span>
<span class="gi">+                storage = [cache_storage]</span>
<span class="gi">+            else:</span>
<span class="gi">+                storage = cache_storage</span>
<span class="w"> </span>        os.makedirs(storage[-1], exist_ok=True)
<span class="w"> </span>        self.storage = storage
<span class="w"> </span>        self.kwargs = target_options or {}
<span class="gu">@@ -116,51 +140,89 @@ class CachingFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        self.check_files = check_files
<span class="w"> </span>        self.expiry = expiry_time
<span class="w"> </span>        self.compression = compression
<span class="gi">+</span>
<span class="gi">+        # Size of cache in bytes. If None then the size is unknown and will be</span>
<span class="gi">+        # recalculated the next time cache_size() is called. On writes to the</span>
<span class="gi">+        # cache this is reset to None.</span>
<span class="w"> </span>        self._cache_size = None
<span class="gi">+</span>
<span class="w"> </span>        if same_names is not None and cache_mapper is not None:
<span class="w"> </span>            raise ValueError(
<span class="gd">-                &#39;Cannot specify both same_names and cache_mapper in CachingFileSystem.__init__&#39;</span>
<span class="gd">-                )</span>
<span class="gi">+                &quot;Cannot specify both same_names and cache_mapper in &quot;</span>
<span class="gi">+                &quot;CachingFileSystem.__init__&quot;</span>
<span class="gi">+            )</span>
<span class="w"> </span>        if cache_mapper is not None:
<span class="w"> </span>            self._mapper = cache_mapper
<span class="w"> </span>        else:
<span class="gd">-            self._mapper = create_cache_mapper(same_names if same_names is not</span>
<span class="gd">-                None else False)</span>
<span class="gd">-        self.target_protocol = target_protocol if isinstance(target_protocol,</span>
<span class="gd">-            str) else fs.protocol if isinstance(fs.protocol, str</span>
<span class="gd">-            ) else fs.protocol[0]</span>
<span class="gi">+            self._mapper = create_cache_mapper(</span>
<span class="gi">+                same_names if same_names is not None else False</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        self.target_protocol = (</span>
<span class="gi">+            target_protocol</span>
<span class="gi">+            if isinstance(target_protocol, str)</span>
<span class="gi">+            else (fs.protocol if isinstance(fs.protocol, str) else fs.protocol[0])</span>
<span class="gi">+        )</span>
<span class="w"> </span>        self._metadata = CacheMetadata(self.storage)
<span class="w"> </span>        self.load_cache()
<span class="gd">-        self.fs = fs if fs is not None else filesystem(target_protocol, **</span>
<span class="gd">-            self.kwargs)</span>
<span class="gi">+        self.fs = fs if fs is not None else filesystem(target_protocol, **self.kwargs)</span>

<span class="w"> </span>        def _strip_protocol(path):
<span class="gi">+            # acts as a method, since each instance has a difference target</span>
<span class="w"> </span>            return self.fs._strip_protocol(type(self)._strip_protocol(path))
<span class="gi">+</span>
<span class="w"> </span>        self._strip_protocol: Callable = _strip_protocol

<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _remove_tempdir(tempdir):</span>
<span class="gi">+        try:</span>
<span class="gi">+            rmtree(tempdir)</span>
<span class="gi">+        except Exception:</span>
<span class="gi">+            pass</span>
<span class="gi">+</span>
<span class="gi">+    def _mkcache(self):</span>
<span class="gi">+        os.makedirs(self.storage[-1], exist_ok=True)</span>
<span class="gi">+</span>
<span class="w"> </span>    def cache_size(self):
<span class="w"> </span>        &quot;&quot;&quot;Return size of cache in bytes.

<span class="w"> </span>        If more than one cache directory is in use, only the size of the last
<span class="w"> </span>        one (the writable cache directory) is returned.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self._cache_size is None:</span>
<span class="gi">+            cache_dir = self.storage[-1]</span>
<span class="gi">+            self._cache_size = filesystem(&quot;file&quot;).du(cache_dir, withdirs=True)</span>
<span class="gi">+        return self._cache_size</span>

<span class="w"> </span>    def load_cache(self):
<span class="w"> </span>        &quot;&quot;&quot;Read set of stored blocks from file&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._metadata.load()</span>
<span class="gi">+        self._mkcache()</span>
<span class="gi">+        self.last_cache = time.time()</span>

<span class="w"> </span>    def save_cache(self):
<span class="w"> </span>        &quot;&quot;&quot;Save set of stored blocks from file&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._mkcache()</span>
<span class="gi">+        self._metadata.save()</span>
<span class="gi">+        self.last_cache = time.time()</span>
<span class="gi">+        self._cache_size = None</span>

<span class="w"> </span>    def _check_cache(self):
<span class="w"> </span>        &quot;&quot;&quot;Reload caches if time elapsed or any disappeared&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._mkcache()</span>
<span class="gi">+        if not self.cache_check:</span>
<span class="gi">+            # explicitly told not to bother checking</span>
<span class="gi">+            return</span>
<span class="gi">+        timecond = time.time() - self.last_cache &gt; self.cache_check</span>
<span class="gi">+        existcond = all(os.path.exists(storage) for storage in self.storage)</span>
<span class="gi">+        if timecond or not existcond:</span>
<span class="gi">+            self.load_cache()</span>

<span class="w"> </span>    def _check_file(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Is path in cache and still valid&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        self._check_cache()</span>
<span class="gi">+        return self._metadata.check_file(path, self)</span>

<span class="w"> </span>    def clear_cache(self):
<span class="w"> </span>        &quot;&quot;&quot;Remove all files and metadata from the cache
<span class="gu">@@ -168,7 +230,9 @@ class CachingFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        In the case of multiple cache locations, this clears only the last one,
<span class="w"> </span>        which is assumed to be the read/write one.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        rmtree(self.storage[-1])</span>
<span class="gi">+        self.load_cache()</span>
<span class="gi">+        self._cache_size = None</span>

<span class="w"> </span>    def clear_expired_cache(self, expiry_time=None):
<span class="w"> </span>        &quot;&quot;&quot;Remove all expired files and metadata from the cache
<span class="gu">@@ -183,7 +247,22 @@ class CachingFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>            If not defined the default is equivalent to the attribute from the
<span class="w"> </span>            file caching instantiation.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+</span>
<span class="gi">+        if not expiry_time:</span>
<span class="gi">+            expiry_time = self.expiry</span>
<span class="gi">+</span>
<span class="gi">+        self._check_cache()</span>
<span class="gi">+</span>
<span class="gi">+        expired_files, writable_cache_empty = self._metadata.clear_expired(expiry_time)</span>
<span class="gi">+        for fn in expired_files:</span>
<span class="gi">+            if os.path.exists(fn):</span>
<span class="gi">+                os.remove(fn)</span>
<span class="gi">+</span>
<span class="gi">+        if writable_cache_empty:</span>
<span class="gi">+            rmtree(self.storage[-1])</span>
<span class="gi">+            self.load_cache()</span>
<span class="gi">+</span>
<span class="gi">+        self._cache_size = None</span>

<span class="w"> </span>    def pop_from_cache(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Remove cached version of given file
<span class="gu">@@ -192,10 +271,21 @@ class CachingFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        location which is not the last, it is assumed to be read-only, and
<span class="w"> </span>        raises PermissionError
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        fn = self._metadata.pop_file(path)</span>
<span class="gi">+        if fn is not None:</span>
<span class="gi">+            os.remove(fn)</span>
<span class="gi">+        self._cache_size = None</span>

<span class="gd">-    def _open(self, path, mode=&#39;rb&#39;, block_size=None, autocommit=True,</span>
<span class="gd">-        cache_options=None, **kwargs):</span>
<span class="gi">+    def _open(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=None,</span>
<span class="gi">+        autocommit=True,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Wrap the target _open

<span class="w"> </span>        If the whole file exists in the cache, just open it locally and
<span class="gu">@@ -208,47 +298,183 @@ class CachingFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        We monkey-patch this file, so that when it closes, we call
<span class="w"> </span>        ``close_and_update`` to save the state of the blocks.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+</span>
<span class="gi">+        path = self.fs._strip_protocol(path)</span>
<span class="gi">+        if &quot;r&quot; not in mode:</span>
<span class="gi">+            return self.fs._open(</span>
<span class="gi">+                path,</span>
<span class="gi">+                mode=mode,</span>
<span class="gi">+                block_size=block_size,</span>
<span class="gi">+                autocommit=autocommit,</span>
<span class="gi">+                cache_options=cache_options,</span>
<span class="gi">+                **kwargs,</span>
<span class="gi">+            )</span>
<span class="gi">+        detail = self._check_file(path)</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            # file is in cache</span>
<span class="gi">+            detail, fn = detail</span>
<span class="gi">+            hash, blocks = detail[&quot;fn&quot;], detail[&quot;blocks&quot;]</span>
<span class="gi">+            if blocks is True:</span>
<span class="gi">+                # stored file is complete</span>
<span class="gi">+                logger.debug(&quot;Opening local copy of %s&quot;, path)</span>
<span class="gi">+                return open(fn, mode)</span>
<span class="gi">+            # TODO: action where partial file exists in read-only cache</span>
<span class="gi">+            logger.debug(&quot;Opening partially cached copy of %s&quot;, path)</span>
<span class="gi">+        else:</span>
<span class="gi">+            hash = self._mapper(path)</span>
<span class="gi">+            fn = os.path.join(self.storage[-1], hash)</span>
<span class="gi">+            blocks = set()</span>
<span class="gi">+            detail = {</span>
<span class="gi">+                &quot;original&quot;: path,</span>
<span class="gi">+                &quot;fn&quot;: hash,</span>
<span class="gi">+                &quot;blocks&quot;: blocks,</span>
<span class="gi">+                &quot;time&quot;: time.time(),</span>
<span class="gi">+                &quot;uid&quot;: self.fs.ukey(path),</span>
<span class="gi">+            }</span>
<span class="gi">+            self._metadata.update_file(path, detail)</span>
<span class="gi">+            logger.debug(&quot;Creating local sparse file for %s&quot;, path)</span>
<span class="gi">+</span>
<span class="gi">+        # call target filesystems open</span>
<span class="gi">+        self._mkcache()</span>
<span class="gi">+        f = self.fs._open(</span>
<span class="gi">+            path,</span>
<span class="gi">+            mode=mode,</span>
<span class="gi">+            block_size=block_size,</span>
<span class="gi">+            autocommit=autocommit,</span>
<span class="gi">+            cache_options=cache_options,</span>
<span class="gi">+            cache_type=&quot;none&quot;,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>
<span class="gi">+        if self.compression:</span>
<span class="gi">+            comp = (</span>
<span class="gi">+                infer_compression(path)</span>
<span class="gi">+                if self.compression == &quot;infer&quot;</span>
<span class="gi">+                else self.compression</span>
<span class="gi">+            )</span>
<span class="gi">+            f = compr[comp](f, mode=&quot;rb&quot;)</span>
<span class="gi">+        if &quot;blocksize&quot; in detail:</span>
<span class="gi">+            if detail[&quot;blocksize&quot;] != f.blocksize:</span>
<span class="gi">+                raise BlocksizeMismatchError(</span>
<span class="gi">+                    f&quot;Cached file must be reopened with same block&quot;</span>
<span class="gi">+                    f&quot; size as original (old: {detail[&#39;blocksize&#39;]},&quot;</span>
<span class="gi">+                    f&quot; new {f.blocksize})&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+        else:</span>
<span class="gi">+            detail[&quot;blocksize&quot;] = f.blocksize</span>
<span class="gi">+        f.cache = MMapCache(f.blocksize, f._fetch_range, f.size, fn, blocks)</span>
<span class="gi">+        close = f.close</span>
<span class="gi">+        f.close = lambda: self.close_and_update(f, close)</span>
<span class="gi">+        self.save_cache()</span>
<span class="gi">+        return f</span>
<span class="gi">+</span>
<span class="gi">+    def _parent(self, path):</span>
<span class="gi">+        return self.fs._parent(path)</span>
<span class="gi">+</span>
<span class="gi">+    def hash_name(self, path: str, *args: Any) -&gt; str:</span>
<span class="gi">+        # Kept for backward compatibility with downstream libraries.</span>
<span class="gi">+        # Ignores extra arguments, previously same_name boolean.</span>
<span class="gi">+        return self._mapper(path)</span>

<span class="w"> </span>    def close_and_update(self, f, close):
<span class="w"> </span>        &quot;&quot;&quot;Called when a file is closing, so store the set of blocks&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if f.closed:</span>
<span class="gi">+            return</span>
<span class="gi">+        path = self._strip_protocol(f.path)</span>
<span class="gi">+        self._metadata.on_close_cached_file(f, path)</span>
<span class="gi">+        try:</span>
<span class="gi">+            logger.debug(&quot;going to save&quot;)</span>
<span class="gi">+            self.save_cache()</span>
<span class="gi">+            logger.debug(&quot;saved&quot;)</span>
<span class="gi">+        except OSError:</span>
<span class="gi">+            logger.debug(&quot;Cache saving failed while closing file&quot;)</span>
<span class="gi">+        except NameError:</span>
<span class="gi">+            logger.debug(&quot;Cache save failed due to interpreter shutdown&quot;)</span>
<span class="gi">+        close()</span>
<span class="gi">+        f.closed = True</span>
<span class="gi">+</span>
<span class="gi">+    def ls(self, path, detail=True):</span>
<span class="gi">+        return self.fs.ls(path, detail)</span>

<span class="w"> </span>    def __getattribute__(self, item):
<span class="gd">-        if item in {&#39;load_cache&#39;, &#39;_open&#39;, &#39;save_cache&#39;, &#39;close_and_update&#39;,</span>
<span class="gd">-            &#39;__init__&#39;, &#39;__getattribute__&#39;, &#39;__reduce__&#39;,</span>
<span class="gd">-            &#39;_make_local_details&#39;, &#39;open&#39;, &#39;cat&#39;, &#39;cat_file&#39;, &#39;cat_ranges&#39;,</span>
<span class="gd">-            &#39;get&#39;, &#39;read_block&#39;, &#39;tail&#39;, &#39;head&#39;, &#39;info&#39;, &#39;ls&#39;, &#39;exists&#39;,</span>
<span class="gd">-            &#39;isfile&#39;, &#39;isdir&#39;, &#39;_check_file&#39;, &#39;_check_cache&#39;, &#39;_mkcache&#39;,</span>
<span class="gd">-            &#39;clear_cache&#39;, &#39;clear_expired_cache&#39;, &#39;pop_from_cache&#39;,</span>
<span class="gd">-            &#39;local_file&#39;, &#39;_paths_from_path&#39;, &#39;get_mapper&#39;, &#39;open_many&#39;,</span>
<span class="gd">-            &#39;commit_many&#39;, &#39;hash_name&#39;, &#39;__hash__&#39;, &#39;__eq__&#39;, &#39;to_json&#39;,</span>
<span class="gd">-            &#39;to_dict&#39;, &#39;cache_size&#39;, &#39;pipe_file&#39;, &#39;pipe&#39;,</span>
<span class="gd">-            &#39;start_transaction&#39;, &#39;end_transaction&#39;}:</span>
<span class="gi">+        if item in {</span>
<span class="gi">+            &quot;load_cache&quot;,</span>
<span class="gi">+            &quot;_open&quot;,</span>
<span class="gi">+            &quot;save_cache&quot;,</span>
<span class="gi">+            &quot;close_and_update&quot;,</span>
<span class="gi">+            &quot;__init__&quot;,</span>
<span class="gi">+            &quot;__getattribute__&quot;,</span>
<span class="gi">+            &quot;__reduce__&quot;,</span>
<span class="gi">+            &quot;_make_local_details&quot;,</span>
<span class="gi">+            &quot;open&quot;,</span>
<span class="gi">+            &quot;cat&quot;,</span>
<span class="gi">+            &quot;cat_file&quot;,</span>
<span class="gi">+            &quot;cat_ranges&quot;,</span>
<span class="gi">+            &quot;get&quot;,</span>
<span class="gi">+            &quot;read_block&quot;,</span>
<span class="gi">+            &quot;tail&quot;,</span>
<span class="gi">+            &quot;head&quot;,</span>
<span class="gi">+            &quot;info&quot;,</span>
<span class="gi">+            &quot;ls&quot;,</span>
<span class="gi">+            &quot;exists&quot;,</span>
<span class="gi">+            &quot;isfile&quot;,</span>
<span class="gi">+            &quot;isdir&quot;,</span>
<span class="gi">+            &quot;_check_file&quot;,</span>
<span class="gi">+            &quot;_check_cache&quot;,</span>
<span class="gi">+            &quot;_mkcache&quot;,</span>
<span class="gi">+            &quot;clear_cache&quot;,</span>
<span class="gi">+            &quot;clear_expired_cache&quot;,</span>
<span class="gi">+            &quot;pop_from_cache&quot;,</span>
<span class="gi">+            &quot;local_file&quot;,</span>
<span class="gi">+            &quot;_paths_from_path&quot;,</span>
<span class="gi">+            &quot;get_mapper&quot;,</span>
<span class="gi">+            &quot;open_many&quot;,</span>
<span class="gi">+            &quot;commit_many&quot;,</span>
<span class="gi">+            &quot;hash_name&quot;,</span>
<span class="gi">+            &quot;__hash__&quot;,</span>
<span class="gi">+            &quot;__eq__&quot;,</span>
<span class="gi">+            &quot;to_json&quot;,</span>
<span class="gi">+            &quot;to_dict&quot;,</span>
<span class="gi">+            &quot;cache_size&quot;,</span>
<span class="gi">+            &quot;pipe_file&quot;,</span>
<span class="gi">+            &quot;pipe&quot;,</span>
<span class="gi">+            &quot;start_transaction&quot;,</span>
<span class="gi">+            &quot;end_transaction&quot;,</span>
<span class="gi">+        }:</span>
<span class="gi">+            # all the methods defined in this class. Note `open` here, since</span>
<span class="gi">+            # it calls `_open`, but is actually in superclass</span>
<span class="w"> </span>            return lambda *args, **kw: getattr(type(self), item).__get__(self)(
<span class="gd">-                *args, **kw)</span>
<span class="gd">-        if item in [&#39;__reduce_ex__&#39;]:</span>
<span class="gi">+                *args, **kw</span>
<span class="gi">+            )</span>
<span class="gi">+        if item in [&quot;__reduce_ex__&quot;]:</span>
<span class="w"> </span>            raise AttributeError
<span class="gd">-        if item in [&#39;transaction&#39;]:</span>
<span class="gi">+        if item in [&quot;transaction&quot;]:</span>
<span class="gi">+            # property</span>
<span class="w"> </span>            return type(self).transaction.__get__(self)
<span class="gd">-        if item in [&#39;_cache&#39;, &#39;transaction_type&#39;]:</span>
<span class="gi">+        if item in [&quot;_cache&quot;, &quot;transaction_type&quot;]:</span>
<span class="gi">+            # class attributes</span>
<span class="w"> </span>            return getattr(type(self), item)
<span class="gd">-        if item == &#39;__class__&#39;:</span>
<span class="gi">+        if item == &quot;__class__&quot;:</span>
<span class="w"> </span>            return type(self)
<span class="gd">-        d = object.__getattribute__(self, &#39;__dict__&#39;)</span>
<span class="gd">-        fs = d.get(&#39;fs&#39;, None)</span>
<span class="gi">+        d = object.__getattribute__(self, &quot;__dict__&quot;)</span>
<span class="gi">+        fs = d.get(&quot;fs&quot;, None)  # fs is not immediately defined</span>
<span class="w"> </span>        if item in d:
<span class="w"> </span>            return d[item]
<span class="w"> </span>        elif fs is not None:
<span class="w"> </span>            if item in fs.__dict__:
<span class="gi">+                # attribute of instance</span>
<span class="w"> </span>                return fs.__dict__[item]
<span class="gi">+            # attributed belonging to the target filesystem</span>
<span class="w"> </span>            cls = type(fs)
<span class="w"> </span>            m = getattr(cls, item)
<span class="w"> </span>            if (inspect.isfunction(m) or inspect.isdatadescriptor(m)) and (
<span class="gd">-                not hasattr(m, &#39;__self__&#39;) or m.__self__ is None):</span>
<span class="gi">+                not hasattr(m, &quot;__self__&quot;) or m.__self__ is None</span>
<span class="gi">+            ):</span>
<span class="gi">+                # instance method</span>
<span class="w"> </span>                return m.__get__(fs, cls)
<span class="gd">-            return m</span>
<span class="gi">+            return m  # class method or attribute</span>
<span class="w"> </span>        else:
<span class="gi">+            # attributes of the superclass, while target is being set up</span>
<span class="w"> </span>            return super().__getattribute__(item)

<span class="w"> </span>    def __eq__(self, other):
<span class="gu">@@ -257,18 +483,29 @@ class CachingFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>            return True
<span class="w"> </span>        if not isinstance(other, type(self)):
<span class="w"> </span>            return False
<span class="gd">-        return (self.storage == other.storage and self.kwargs == other.</span>
<span class="gd">-            kwargs and self.cache_check == other.cache_check and self.</span>
<span class="gd">-            check_files == other.check_files and self.expiry == other.</span>
<span class="gd">-            expiry and self.compression == other.compression and self.</span>
<span class="gd">-            _mapper == other._mapper and self.target_protocol == other.</span>
<span class="gd">-            target_protocol)</span>
<span class="gi">+        return (</span>
<span class="gi">+            self.storage == other.storage</span>
<span class="gi">+            and self.kwargs == other.kwargs</span>
<span class="gi">+            and self.cache_check == other.cache_check</span>
<span class="gi">+            and self.check_files == other.check_files</span>
<span class="gi">+            and self.expiry == other.expiry</span>
<span class="gi">+            and self.compression == other.compression</span>
<span class="gi">+            and self._mapper == other._mapper</span>
<span class="gi">+            and self.target_protocol == other.target_protocol</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def __hash__(self):
<span class="w"> </span>        &quot;&quot;&quot;Calculate hash.&quot;&quot;&quot;
<span class="gd">-        return hash(tuple(self.storage)) ^ hash(str(self.kwargs)) ^ hash(self</span>
<span class="gd">-            .cache_check) ^ hash(self.check_files) ^ hash(self.expiry) ^ hash(</span>
<span class="gd">-            self.compression) ^ hash(self._mapper) ^ hash(self.target_protocol)</span>
<span class="gi">+        return (</span>
<span class="gi">+            hash(tuple(self.storage))</span>
<span class="gi">+            ^ hash(str(self.kwargs))</span>
<span class="gi">+            ^ hash(self.cache_check)</span>
<span class="gi">+            ^ hash(self.check_files)</span>
<span class="gi">+            ^ hash(self.expiry)</span>
<span class="gi">+            ^ hash(self.compression)</span>
<span class="gi">+            ^ hash(self._mapper)</span>
<span class="gi">+            ^ hash(self.target_protocol)</span>
<span class="gi">+        )</span>


<span class="w"> </span>class WholeFileCacheFileSystem(CachingFileSystem):
<span class="gu">@@ -284,9 +521,192 @@ class WholeFileCacheFileSystem(CachingFileSystem):</span>
<span class="w"> </span>    The class still needs access to the remote store for listing files,
<span class="w"> </span>    and may refresh cached files.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    protocol = &#39;filecache&#39;</span>
<span class="gi">+</span>
<span class="gi">+    protocol = &quot;filecache&quot;</span>
<span class="w"> </span>    local_file = True

<span class="gi">+    def open_many(self, open_files, **kwargs):</span>
<span class="gi">+        paths = [of.path for of in open_files]</span>
<span class="gi">+        if &quot;r&quot; in open_files.mode:</span>
<span class="gi">+            self._mkcache()</span>
<span class="gi">+        else:</span>
<span class="gi">+            return [</span>
<span class="gi">+                LocalTempFile(</span>
<span class="gi">+                    self.fs,</span>
<span class="gi">+                    path,</span>
<span class="gi">+                    mode=open_files.mode,</span>
<span class="gi">+                    fn=os.path.join(self.storage[-1], self._mapper(path)),</span>
<span class="gi">+                    **kwargs,</span>
<span class="gi">+                )</span>
<span class="gi">+                for path in paths</span>
<span class="gi">+            ]</span>
<span class="gi">+</span>
<span class="gi">+        if self.compression:</span>
<span class="gi">+            raise NotImplementedError</span>
<span class="gi">+        details = [self._check_file(sp) for sp in paths]</span>
<span class="gi">+        downpath = [p for p, d in zip(paths, details) if not d]</span>
<span class="gi">+        downfn0 = [</span>
<span class="gi">+            os.path.join(self.storage[-1], self._mapper(p))</span>
<span class="gi">+            for p, d in zip(paths, details)</span>
<span class="gi">+        ]  # keep these path names for opening later</span>
<span class="gi">+        downfn = [fn for fn, d in zip(downfn0, details) if not d]</span>
<span class="gi">+        if downpath:</span>
<span class="gi">+            # skip if all files are already cached and up to date</span>
<span class="gi">+            self.fs.get(downpath, downfn)</span>
<span class="gi">+</span>
<span class="gi">+            # update metadata - only happens when downloads are successful</span>
<span class="gi">+            newdetail = [</span>
<span class="gi">+                {</span>
<span class="gi">+                    &quot;original&quot;: path,</span>
<span class="gi">+                    &quot;fn&quot;: self._mapper(path),</span>
<span class="gi">+                    &quot;blocks&quot;: True,</span>
<span class="gi">+                    &quot;time&quot;: time.time(),</span>
<span class="gi">+                    &quot;uid&quot;: self.fs.ukey(path),</span>
<span class="gi">+                }</span>
<span class="gi">+                for path in downpath</span>
<span class="gi">+            ]</span>
<span class="gi">+            for path, detail in zip(downpath, newdetail):</span>
<span class="gi">+                self._metadata.update_file(path, detail)</span>
<span class="gi">+            self.save_cache()</span>
<span class="gi">+</span>
<span class="gi">+        def firstpart(fn):</span>
<span class="gi">+            # helper to adapt both whole-file and simple-cache</span>
<span class="gi">+            return fn[1] if isinstance(fn, tuple) else fn</span>
<span class="gi">+</span>
<span class="gi">+        return [</span>
<span class="gi">+            open(firstpart(fn0) if fn0 else fn1, mode=open_files.mode)</span>
<span class="gi">+            for fn0, fn1 in zip(details, downfn0)</span>
<span class="gi">+        ]</span>
<span class="gi">+</span>
<span class="gi">+    def commit_many(self, open_files):</span>
<span class="gi">+        self.fs.put([f.fn for f in open_files], [f.path for f in open_files])</span>
<span class="gi">+        [f.close() for f in open_files]</span>
<span class="gi">+        for f in open_files:</span>
<span class="gi">+            # in case autocommit is off, and so close did not already delete</span>
<span class="gi">+            try:</span>
<span class="gi">+                os.remove(f.name)</span>
<span class="gi">+            except FileNotFoundError:</span>
<span class="gi">+                pass</span>
<span class="gi">+        self._cache_size = None</span>
<span class="gi">+</span>
<span class="gi">+    def _make_local_details(self, path):</span>
<span class="gi">+        hash = self._mapper(path)</span>
<span class="gi">+        fn = os.path.join(self.storage[-1], hash)</span>
<span class="gi">+        detail = {</span>
<span class="gi">+            &quot;original&quot;: path,</span>
<span class="gi">+            &quot;fn&quot;: hash,</span>
<span class="gi">+            &quot;blocks&quot;: True,</span>
<span class="gi">+            &quot;time&quot;: time.time(),</span>
<span class="gi">+            &quot;uid&quot;: self.fs.ukey(path),</span>
<span class="gi">+        }</span>
<span class="gi">+        self._metadata.update_file(path, detail)</span>
<span class="gi">+        logger.debug(&quot;Copying %s to local cache&quot;, path)</span>
<span class="gi">+        return fn</span>
<span class="gi">+</span>
<span class="gi">+    def cat(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        recursive=False,</span>
<span class="gi">+        on_error=&quot;raise&quot;,</span>
<span class="gi">+        callback=DEFAULT_CALLBACK,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        paths = self.expand_path(</span>
<span class="gi">+            path, recursive=recursive, maxdepth=kwargs.get(&quot;maxdepth&quot;, None)</span>
<span class="gi">+        )</span>
<span class="gi">+        getpaths = []</span>
<span class="gi">+        storepaths = []</span>
<span class="gi">+        fns = []</span>
<span class="gi">+        out = {}</span>
<span class="gi">+        for p in paths.copy():</span>
<span class="gi">+            try:</span>
<span class="gi">+                detail = self._check_file(p)</span>
<span class="gi">+                if not detail:</span>
<span class="gi">+                    fn = self._make_local_details(p)</span>
<span class="gi">+                    getpaths.append(p)</span>
<span class="gi">+                    storepaths.append(fn)</span>
<span class="gi">+                else:</span>
<span class="gi">+                    detail, fn = detail if isinstance(detail, tuple) else (None, detail)</span>
<span class="gi">+                fns.append(fn)</span>
<span class="gi">+            except Exception as e:</span>
<span class="gi">+                if on_error == &quot;raise&quot;:</span>
<span class="gi">+                    raise</span>
<span class="gi">+                if on_error == &quot;return&quot;:</span>
<span class="gi">+                    out[p] = e</span>
<span class="gi">+                paths.remove(p)</span>
<span class="gi">+</span>
<span class="gi">+        if getpaths:</span>
<span class="gi">+            self.fs.get(getpaths, storepaths)</span>
<span class="gi">+            self.save_cache()</span>
<span class="gi">+</span>
<span class="gi">+        callback.set_size(len(paths))</span>
<span class="gi">+        for p, fn in zip(paths, fns):</span>
<span class="gi">+            with open(fn, &quot;rb&quot;) as f:</span>
<span class="gi">+                out[p] = f.read()</span>
<span class="gi">+            callback.relative_update(1)</span>
<span class="gi">+        if isinstance(path, str) and len(paths) == 1 and recursive is False:</span>
<span class="gi">+            out = out[paths[0]]</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    def _open(self, path, mode=&quot;rb&quot;, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if &quot;r&quot; not in mode:</span>
<span class="gi">+            hash = self._mapper(path)</span>
<span class="gi">+            fn = os.path.join(self.storage[-1], hash)</span>
<span class="gi">+            user_specified_kwargs = {</span>
<span class="gi">+                k: v</span>
<span class="gi">+                for k, v in kwargs.items()</span>
<span class="gi">+                # those kwargs were added by open(), we don&#39;t want them</span>
<span class="gi">+                if k not in [&quot;autocommit&quot;, &quot;block_size&quot;, &quot;cache_options&quot;]</span>
<span class="gi">+            }</span>
<span class="gi">+            return LocalTempFile(self, path, mode=mode, fn=fn, **user_specified_kwargs)</span>
<span class="gi">+        detail = self._check_file(path)</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            detail, fn = detail</span>
<span class="gi">+            _, blocks = detail[&quot;fn&quot;], detail[&quot;blocks&quot;]</span>
<span class="gi">+            if blocks is True:</span>
<span class="gi">+                logger.debug(&quot;Opening local copy of %s&quot;, path)</span>
<span class="gi">+</span>
<span class="gi">+                # In order to support downstream filesystems to be able to</span>
<span class="gi">+                # infer the compression from the original filename, like</span>
<span class="gi">+                # the `TarFileSystem`, let&#39;s extend the `io.BufferedReader`</span>
<span class="gi">+                # fileobject protocol by adding a dedicated attribute</span>
<span class="gi">+                # `original`.</span>
<span class="gi">+                f = open(fn, mode)</span>
<span class="gi">+                f.original = detail.get(&quot;original&quot;)</span>
<span class="gi">+                return f</span>
<span class="gi">+            else:</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    f&quot;Attempt to open partially cached file {path}&quot;</span>
<span class="gi">+                    f&quot; as a wholly cached file&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+        else:</span>
<span class="gi">+            fn = self._make_local_details(path)</span>
<span class="gi">+        kwargs[&quot;mode&quot;] = mode</span>
<span class="gi">+</span>
<span class="gi">+        # call target filesystems open</span>
<span class="gi">+        self._mkcache()</span>
<span class="gi">+        if self.compression:</span>
<span class="gi">+            with self.fs._open(path, **kwargs) as f, open(fn, &quot;wb&quot;) as f2:</span>
<span class="gi">+                if isinstance(f, AbstractBufferedFile):</span>
<span class="gi">+                    # want no type of caching if just downloading whole thing</span>
<span class="gi">+                    f.cache = BaseCache(0, f.cache.fetcher, f.size)</span>
<span class="gi">+                comp = (</span>
<span class="gi">+                    infer_compression(path)</span>
<span class="gi">+                    if self.compression == &quot;infer&quot;</span>
<span class="gi">+                    else self.compression</span>
<span class="gi">+                )</span>
<span class="gi">+                f = compr[comp](f, mode=&quot;rb&quot;)</span>
<span class="gi">+                data = True</span>
<span class="gi">+                while data:</span>
<span class="gi">+                    block = getattr(f, &quot;blocksize&quot;, 5 * 2**20)</span>
<span class="gi">+                    data = f.read(block)</span>
<span class="gi">+                    f2.write(data)</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.fs.get_file(path, fn)</span>
<span class="gi">+        self.save_cache()</span>
<span class="gi">+        return self._open(path, mode)</span>
<span class="gi">+</span>

<span class="w"> </span>class SimpleCacheFileSystem(WholeFileCacheFileSystem):
<span class="w"> </span>    &quot;&quot;&quot;Caches whole remote files on first access
<span class="gu">@@ -303,25 +723,159 @@ class SimpleCacheFileSystem(WholeFileCacheFileSystem):</span>
<span class="w"> </span>    not checked until that time.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    protocol = &#39;simplecache&#39;</span>
<span class="gi">+</span>
<span class="gi">+    protocol = &quot;simplecache&quot;</span>
<span class="w"> </span>    local_file = True
<span class="w"> </span>    transaction_type = WriteCachedTransaction

<span class="w"> </span>    def __init__(self, **kwargs):
<span class="w"> </span>        kw = kwargs.copy()
<span class="gd">-        for key in [&#39;cache_check&#39;, &#39;expiry_time&#39;, &#39;check_files&#39;]:</span>
<span class="gi">+        for key in [&quot;cache_check&quot;, &quot;expiry_time&quot;, &quot;check_files&quot;]:</span>
<span class="w"> </span>            kw[key] = False
<span class="w"> </span>        super().__init__(**kw)
<span class="w"> </span>        for storage in self.storage:
<span class="w"> </span>            if not os.path.exists(storage):
<span class="w"> </span>                os.makedirs(storage, exist_ok=True)

<span class="gi">+    def _check_file(self, path):</span>
<span class="gi">+        self._check_cache()</span>
<span class="gi">+        sha = self._mapper(path)</span>
<span class="gi">+        for storage in self.storage:</span>
<span class="gi">+            fn = os.path.join(storage, sha)</span>
<span class="gi">+            if os.path.exists(fn):</span>
<span class="gi">+                return fn</span>
<span class="gi">+</span>
<span class="gi">+    def save_cache(self):</span>
<span class="gi">+        pass</span>
<span class="gi">+</span>
<span class="gi">+    def load_cache(self):</span>
<span class="gi">+        pass</span>
<span class="gi">+</span>
<span class="gi">+    def pipe_file(self, path, value=None, **kwargs):</span>
<span class="gi">+        if self._intrans:</span>
<span class="gi">+            with self.open(path, &quot;wb&quot;) as f:</span>
<span class="gi">+                f.write(value)</span>
<span class="gi">+        else:</span>
<span class="gi">+            super().pipe_file(path, value)</span>
<span class="gi">+</span>
<span class="gi">+    def ls(self, path, detail=True, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        details = []</span>
<span class="gi">+        try:</span>
<span class="gi">+            details = self.fs.ls(</span>
<span class="gi">+                path, detail=True, **kwargs</span>
<span class="gi">+            ).copy()  # don&#39;t edit original!</span>
<span class="gi">+        except FileNotFoundError as e:</span>
<span class="gi">+            ex = e</span>
<span class="gi">+        else:</span>
<span class="gi">+            ex = None</span>
<span class="gi">+        if self._intrans:</span>
<span class="gi">+            path1 = path.rstrip(&quot;/&quot;) + &quot;/&quot;</span>
<span class="gi">+            for f in self.transaction.files:</span>
<span class="gi">+                if f.path == path:</span>
<span class="gi">+                    details.append(</span>
<span class="gi">+                        {&quot;name&quot;: path, &quot;size&quot;: f.size or f.tell(), &quot;type&quot;: &quot;file&quot;}</span>
<span class="gi">+                    )</span>
<span class="gi">+                elif f.path.startswith(path1):</span>
<span class="gi">+                    if f.path.count(&quot;/&quot;) == path1.count(&quot;/&quot;):</span>
<span class="gi">+                        details.append(</span>
<span class="gi">+                            {&quot;name&quot;: f.path, &quot;size&quot;: f.size or f.tell(), &quot;type&quot;: &quot;file&quot;}</span>
<span class="gi">+                        )</span>
<span class="gi">+                    else:</span>
<span class="gi">+                        dname = &quot;/&quot;.join(f.path.split(&quot;/&quot;)[: path1.count(&quot;/&quot;) + 1])</span>
<span class="gi">+                        details.append({&quot;name&quot;: dname, &quot;size&quot;: 0, &quot;type&quot;: &quot;directory&quot;})</span>
<span class="gi">+        if ex is not None and not details:</span>
<span class="gi">+            raise ex</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return details</span>
<span class="gi">+        return sorted(_[&quot;name&quot;] for _ in details)</span>
<span class="gi">+</span>
<span class="gi">+    def info(self, path, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if self._intrans:</span>
<span class="gi">+            f = [_ for _ in self.transaction.files if _.path == path]</span>
<span class="gi">+            if f:</span>
<span class="gi">+                size = os.path.getsize(f[0].fn) if f[0].closed else f[0].tell()</span>
<span class="gi">+                return {&quot;name&quot;: path, &quot;size&quot;: size, &quot;type&quot;: &quot;file&quot;}</span>
<span class="gi">+            f = any(_.path.startswith(path + &quot;/&quot;) for _ in self.transaction.files)</span>
<span class="gi">+            if f:</span>
<span class="gi">+                return {&quot;name&quot;: path, &quot;size&quot;: 0, &quot;type&quot;: &quot;directory&quot;}</span>
<span class="gi">+        return self.fs.info(path, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def pipe(self, path, value=None, **kwargs):</span>
<span class="gi">+        if isinstance(path, str):</span>
<span class="gi">+            self.pipe_file(self._strip_protocol(path), value, **kwargs)</span>
<span class="gi">+        elif isinstance(path, dict):</span>
<span class="gi">+            for k, v in path.items():</span>
<span class="gi">+                self.pipe_file(self._strip_protocol(k), v, **kwargs)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise ValueError(&quot;path must be str or dict&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def cat_ranges(</span>
<span class="gi">+        self, paths, starts, ends, max_gap=None, on_error=&quot;return&quot;, **kwargs</span>
<span class="gi">+    ):</span>
<span class="gi">+        lpaths = [self._check_file(p) for p in paths]</span>
<span class="gi">+        rpaths = [p for l, p in zip(lpaths, paths) if l is False]</span>
<span class="gi">+        lpaths = [l for l, p in zip(lpaths, paths) if l is False]</span>
<span class="gi">+        self.fs.get(rpaths, lpaths)</span>
<span class="gi">+        return super().cat_ranges(</span>
<span class="gi">+            paths, starts, ends, max_gap=max_gap, on_error=on_error, **kwargs</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def _open(self, path, mode=&quot;rb&quot;, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        sha = self._mapper(path)</span>
<span class="gi">+</span>
<span class="gi">+        if &quot;r&quot; not in mode:</span>
<span class="gi">+            fn = os.path.join(self.storage[-1], sha)</span>
<span class="gi">+            user_specified_kwargs = {</span>
<span class="gi">+                k: v</span>
<span class="gi">+                for k, v in kwargs.items()</span>
<span class="gi">+                if k not in [&quot;autocommit&quot;, &quot;block_size&quot;, &quot;cache_options&quot;]</span>
<span class="gi">+            }  # those were added by open()</span>
<span class="gi">+            return LocalTempFile(</span>
<span class="gi">+                self,</span>
<span class="gi">+                path,</span>
<span class="gi">+                mode=mode,</span>
<span class="gi">+                autocommit=not self._intrans,</span>
<span class="gi">+                fn=fn,</span>
<span class="gi">+                **user_specified_kwargs,</span>
<span class="gi">+            )</span>
<span class="gi">+        fn = self._check_file(path)</span>
<span class="gi">+        if fn:</span>
<span class="gi">+            return open(fn, mode)</span>
<span class="gi">+</span>
<span class="gi">+        fn = os.path.join(self.storage[-1], sha)</span>
<span class="gi">+        logger.debug(&quot;Copying %s to local cache&quot;, path)</span>
<span class="gi">+        kwargs[&quot;mode&quot;] = mode</span>
<span class="gi">+</span>
<span class="gi">+        self._mkcache()</span>
<span class="gi">+        self._cache_size = None</span>
<span class="gi">+        if self.compression:</span>
<span class="gi">+            with self.fs._open(path, **kwargs) as f, open(fn, &quot;wb&quot;) as f2:</span>
<span class="gi">+                if isinstance(f, AbstractBufferedFile):</span>
<span class="gi">+                    # want no type of caching if just downloading whole thing</span>
<span class="gi">+                    f.cache = BaseCache(0, f.cache.fetcher, f.size)</span>
<span class="gi">+                comp = (</span>
<span class="gi">+                    infer_compression(path)</span>
<span class="gi">+                    if self.compression == &quot;infer&quot;</span>
<span class="gi">+                    else self.compression</span>
<span class="gi">+                )</span>
<span class="gi">+                f = compr[comp](f, mode=&quot;rb&quot;)</span>
<span class="gi">+                data = True</span>
<span class="gi">+                while data:</span>
<span class="gi">+                    block = getattr(f, &quot;blocksize&quot;, 5 * 2**20)</span>
<span class="gi">+                    data = f.read(block)</span>
<span class="gi">+                    f2.write(data)</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.fs.get_file(path, fn)</span>
<span class="gi">+        return self._open(path, mode)</span>
<span class="gi">+</span>

<span class="w"> </span>class LocalTempFile:
<span class="w"> </span>    &quot;&quot;&quot;A temporary local file, which will be uploaded on commit&quot;&quot;&quot;

<span class="gd">-    def __init__(self, fs, path, fn, mode=&#39;wb&#39;, autocommit=True, seek=0, **</span>
<span class="gd">-        kwargs):</span>
<span class="gi">+    def __init__(self, fs, path, fn, mode=&quot;wb&quot;, autocommit=True, seek=0, **kwargs):</span>
<span class="w"> </span>        self.fn = fn
<span class="w"> </span>        self.fh = open(fn, mode)
<span class="w"> </span>        self.mode = mode
<span class="gu">@@ -335,8 +889,11 @@ class LocalTempFile:</span>
<span class="w"> </span>        self.kwargs = kwargs

<span class="w"> </span>    def __reduce__(self):
<span class="gd">-        return LocalTempFile, (self.fs, self.path, self.fn, &#39;r+b&#39;, self.</span>
<span class="gd">-            autocommit, self.tell())</span>
<span class="gi">+        # always open in r+b to allow continuing writing at a location</span>
<span class="gi">+        return (</span>
<span class="gi">+            LocalTempFile,</span>
<span class="gi">+            (self.fs, self.path, self.fn, &quot;r+b&quot;, self.autocommit, self.tell()),</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def __enter__(self):
<span class="w"> </span>        return self.fh
<span class="gu">@@ -344,8 +901,29 @@ class LocalTempFile:</span>
<span class="w"> </span>    def __exit__(self, exc_type, exc_val, exc_tb):
<span class="w"> </span>        self.close()

<span class="gd">-    def __repr__(self) -&gt;str:</span>
<span class="gd">-        return f&#39;LocalTempFile: {self.path}&#39;</span>
<span class="gi">+    def close(self):</span>
<span class="gi">+        # self.size = self.fh.tell()</span>
<span class="gi">+        if self.closed:</span>
<span class="gi">+            return</span>
<span class="gi">+        self.fh.close()</span>
<span class="gi">+        self.closed = True</span>
<span class="gi">+        if self.autocommit:</span>
<span class="gi">+            self.commit()</span>
<span class="gi">+</span>
<span class="gi">+    def discard(self):</span>
<span class="gi">+        self.fh.close()</span>
<span class="gi">+        os.remove(self.fn)</span>
<span class="gi">+</span>
<span class="gi">+    def commit(self):</span>
<span class="gi">+        self.fs.put(self.fn, self.path, **self.kwargs)</span>
<span class="gi">+        # we do not delete local copy - it&#39;s still in the cache</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def name(self):</span>
<span class="gi">+        return self.fn</span>
<span class="gi">+</span>
<span class="gi">+    def __repr__(self) -&gt; str:</span>
<span class="gi">+        return f&quot;LocalTempFile: {self.path}&quot;</span>

<span class="w"> </span>    def __getattr__(self, item):
<span class="w"> </span>        return getattr(self.fh, item)
<span class="gh">diff --git a/fsspec/implementations/dask.py b/fsspec/implementations/dask.py</span>
<span class="gh">index ead2260..3e12764 100644</span>
<span class="gd">--- a/fsspec/implementations/dask.py</span>
<span class="gi">+++ b/fsspec/implementations/dask.py</span>
<span class="gu">@@ -1,11 +1,26 @@</span>
<span class="w"> </span>import dask
<span class="w"> </span>from distributed.client import Client, _get_global_client
<span class="w"> </span>from distributed.worker import Worker
<span class="gi">+</span>
<span class="w"> </span>from fsspec import filesystem
<span class="w"> </span>from fsspec.spec import AbstractBufferedFile, AbstractFileSystem
<span class="w"> </span>from fsspec.utils import infer_storage_options


<span class="gi">+def _get_client(client):</span>
<span class="gi">+    if client is None:</span>
<span class="gi">+        return _get_global_client()</span>
<span class="gi">+    elif isinstance(client, Client):</span>
<span class="gi">+        return client</span>
<span class="gi">+    else:</span>
<span class="gi">+        # e.g., connection string</span>
<span class="gi">+        return Client(client)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _in_worker():</span>
<span class="gi">+    return bool(Worker._instances)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>class DaskWorkerFileSystem(AbstractFileSystem):
<span class="w"> </span>    &quot;&quot;&quot;View files accessible to a worker as any other remote file-system

<span class="gu">@@ -15,13 +30,15 @@ class DaskWorkerFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>    **Warning** this implementation is experimental, and read-only for now.
<span class="w"> </span>    &quot;&quot;&quot;

<span class="gd">-    def __init__(self, target_protocol=None, target_options=None, fs=None,</span>
<span class="gd">-        client=None, **kwargs):</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self, target_protocol=None, target_options=None, fs=None, client=None, **kwargs</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        super().__init__(**kwargs)
<span class="w"> </span>        if not (fs is None) ^ (target_protocol is None):
<span class="w"> </span>            raise ValueError(
<span class="gd">-                &#39;Please provide one of filesystem instance (fs) or target_protocol, not both&#39;</span>
<span class="gd">-                )</span>
<span class="gi">+                &quot;Please provide one of filesystem instance (fs) or&quot;</span>
<span class="gi">+                &quot; target_protocol, not both&quot;</span>
<span class="gi">+            )</span>
<span class="w"> </span>        self.target_protocol = target_protocol
<span class="w"> </span>        self.target_options = target_options
<span class="w"> </span>        self.worker = None
<span class="gu">@@ -29,19 +46,107 @@ class DaskWorkerFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        self.fs = fs
<span class="w"> </span>        self._determine_worker()

<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _get_kwargs_from_urls(path):</span>
<span class="gi">+        so = infer_storage_options(path)</span>
<span class="gi">+        if &quot;host&quot; in so and &quot;port&quot; in so:</span>
<span class="gi">+            return {&quot;client&quot;: f&quot;{so[&#39;host&#39;]}:{so[&#39;port&#39;]}&quot;}</span>
<span class="gi">+        else:</span>
<span class="gi">+            return {}</span>

<span class="gd">-class DaskFile(AbstractBufferedFile):</span>
<span class="gi">+    def _determine_worker(self):</span>
<span class="gi">+        if _in_worker():</span>
<span class="gi">+            self.worker = True</span>
<span class="gi">+            if self.fs is None:</span>
<span class="gi">+                self.fs = filesystem(</span>
<span class="gi">+                    self.target_protocol, **(self.target_options or {})</span>
<span class="gi">+                )</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.worker = False</span>
<span class="gi">+            self.client = _get_client(self.client)</span>
<span class="gi">+            self.rfs = dask.delayed(self)</span>

<span class="gd">-    def __init__(self, mode=&#39;rb&#39;, **kwargs):</span>
<span class="gd">-        if mode != &#39;rb&#39;:</span>
<span class="gd">-            raise ValueError(</span>
<span class="gd">-                &#39;Remote dask files can only be opened in &quot;rb&quot; mode&#39;)</span>
<span class="gi">+    def mkdir(self, *args, **kwargs):</span>
<span class="gi">+        if self.worker:</span>
<span class="gi">+            self.fs.mkdir(*args, **kwargs)</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.rfs.mkdir(*args, **kwargs).compute()</span>
<span class="gi">+</span>
<span class="gi">+    def rm(self, *args, **kwargs):</span>
<span class="gi">+        if self.worker:</span>
<span class="gi">+            self.fs.rm(*args, **kwargs)</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.rfs.rm(*args, **kwargs).compute()</span>
<span class="gi">+</span>
<span class="gi">+    def copy(self, *args, **kwargs):</span>
<span class="gi">+        if self.worker:</span>
<span class="gi">+            self.fs.copy(*args, **kwargs)</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.rfs.copy(*args, **kwargs).compute()</span>
<span class="gi">+</span>
<span class="gi">+    def mv(self, *args, **kwargs):</span>
<span class="gi">+        if self.worker:</span>
<span class="gi">+            self.fs.mv(*args, **kwargs)</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.rfs.mv(*args, **kwargs).compute()</span>
<span class="gi">+</span>
<span class="gi">+    def ls(self, *args, **kwargs):</span>
<span class="gi">+        if self.worker:</span>
<span class="gi">+            return self.fs.ls(*args, **kwargs)</span>
<span class="gi">+        else:</span>
<span class="gi">+            return self.rfs.ls(*args, **kwargs).compute()</span>
<span class="gi">+</span>
<span class="gi">+    def _open(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=None,</span>
<span class="gi">+        autocommit=True,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        if self.worker:</span>
<span class="gi">+            return self.fs._open(</span>
<span class="gi">+                path,</span>
<span class="gi">+                mode=mode,</span>
<span class="gi">+                block_size=block_size,</span>
<span class="gi">+                autocommit=autocommit,</span>
<span class="gi">+                cache_options=cache_options,</span>
<span class="gi">+                **kwargs,</span>
<span class="gi">+            )</span>
<span class="gi">+        else:</span>
<span class="gi">+            return DaskFile(</span>
<span class="gi">+                fs=self,</span>
<span class="gi">+                path=path,</span>
<span class="gi">+                mode=mode,</span>
<span class="gi">+                block_size=block_size,</span>
<span class="gi">+                autocommit=autocommit,</span>
<span class="gi">+                cache_options=cache_options,</span>
<span class="gi">+                **kwargs,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    def fetch_range(self, path, mode, start, end):</span>
<span class="gi">+        if self.worker:</span>
<span class="gi">+            with self._open(path, mode) as f:</span>
<span class="gi">+                f.seek(start)</span>
<span class="gi">+                return f.read(end - start)</span>
<span class="gi">+        else:</span>
<span class="gi">+            return self.rfs.fetch_range(path, mode, start, end).compute()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+class DaskFile(AbstractBufferedFile):</span>
<span class="gi">+    def __init__(self, mode=&quot;rb&quot;, **kwargs):</span>
<span class="gi">+        if mode != &quot;rb&quot;:</span>
<span class="gi">+            raise ValueError(&#39;Remote dask files can only be opened in &quot;rb&quot; mode&#39;)</span>
<span class="w"> </span>        super().__init__(**kwargs)

<span class="gi">+    def _upload_chunk(self, final=False):</span>
<span class="gi">+        pass</span>
<span class="gi">+</span>
<span class="w"> </span>    def _initiate_upload(self):
<span class="w"> </span>        &quot;&quot;&quot;Create remote file/upload&quot;&quot;&quot;
<span class="w"> </span>        pass

<span class="w"> </span>    def _fetch_range(self, start, end):
<span class="w"> </span>        &quot;&quot;&quot;Get the specified set of bytes from remote&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.fs.fetch_range(self.path, self.mode, start, end)</span>
<span class="gh">diff --git a/fsspec/implementations/data.py b/fsspec/implementations/data.py</span>
<span class="gh">index 77435f6..5190323 100644</span>
<span class="gd">--- a/fsspec/implementations/data.py</span>
<span class="gi">+++ b/fsspec/implementations/data.py</span>
<span class="gu">@@ -2,6 +2,7 @@ import base64</span>
<span class="w"> </span>import io
<span class="w"> </span>from typing import Optional
<span class="w"> </span>from urllib.parse import unquote
<span class="gi">+</span>
<span class="w"> </span>from fsspec import AbstractFileSystem


<span class="gu">@@ -16,16 +17,42 @@ class DataFileSystem(AbstractFileSystem):</span>

<span class="w"> </span>    See https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/Data_URLs
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    protocol = &#39;data&#39;</span>
<span class="gi">+</span>
<span class="gi">+    protocol = &quot;data&quot;</span>

<span class="w"> </span>    def __init__(self, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;No parameters for this filesystem&quot;&quot;&quot;
<span class="w"> </span>        super().__init__(**kwargs)

<span class="gi">+    def cat_file(self, path, start=None, end=None, **kwargs):</span>
<span class="gi">+        pref, data = path.split(&quot;,&quot;, 1)</span>
<span class="gi">+        if pref.endswith(&quot;base64&quot;):</span>
<span class="gi">+            return base64.b64decode(data)[start:end]</span>
<span class="gi">+        return unquote(data).encode()[start:end]</span>
<span class="gi">+</span>
<span class="gi">+    def info(self, path, **kwargs):</span>
<span class="gi">+        pref, name = path.split(&quot;,&quot;, 1)</span>
<span class="gi">+        data = self.cat_file(path)</span>
<span class="gi">+        mime = pref.split(&quot;:&quot;, 1)[1].split(&quot;;&quot;, 1)[0]</span>
<span class="gi">+        return {&quot;name&quot;: name, &quot;size&quot;: len(data), &quot;type&quot;: &quot;file&quot;, &quot;mimetype&quot;: mime}</span>
<span class="gi">+</span>
<span class="gi">+    def _open(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=None,</span>
<span class="gi">+        autocommit=True,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        if &quot;r&quot; not in mode:</span>
<span class="gi">+            raise ValueError(&quot;Read only filesystem&quot;)</span>
<span class="gi">+        return io.BytesIO(self.cat_file(path))</span>
<span class="gi">+</span>
<span class="w"> </span>    @staticmethod
<span class="gd">-    def encode(data: bytes, mime: Optional[str]=None):</span>
<span class="gi">+    def encode(data: bytes, mime: Optional[str] = None):</span>
<span class="w"> </span>        &quot;&quot;&quot;Format the given data into data-URL syntax

<span class="w"> </span>        This version always base64 encodes, even when the data is ascii/url-safe.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return f&quot;data:{mime or &#39;&#39;};base64,{base64.b64encode(data).decode()}&quot;</span>
<span class="gh">diff --git a/fsspec/implementations/dbfs.py b/fsspec/implementations/dbfs.py</span>
<span class="gh">index bbf4358..ce9f9ea 100644</span>
<span class="gd">--- a/fsspec/implementations/dbfs.py</span>
<span class="gi">+++ b/fsspec/implementations/dbfs.py</span>
<span class="gu">@@ -1,8 +1,10 @@</span>
<span class="w"> </span>import base64
<span class="w"> </span>import urllib
<span class="gi">+</span>
<span class="w"> </span>import requests
<span class="w"> </span>import requests.exceptions
<span class="w"> </span>from requests.adapters import HTTPAdapter, Retry
<span class="gi">+</span>
<span class="w"> </span>from fsspec import AbstractFileSystem
<span class="w"> </span>from fsspec.spec import AbstractBufferedFile

<span class="gu">@@ -15,6 +17,7 @@ class DatabricksException(Exception):</span>
<span class="w"> </span>    def __init__(self, error_code, message):
<span class="w"> </span>        &quot;&quot;&quot;Create a new DatabricksException&quot;&quot;&quot;
<span class="w"> </span>        super().__init__(message)
<span class="gi">+</span>
<span class="w"> </span>        self.error_code = error_code
<span class="w"> </span>        self.message = message

<span class="gu">@@ -42,10 +45,15 @@ class DatabricksFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        self.instance = instance
<span class="w"> </span>        self.token = token
<span class="w"> </span>        self.session = requests.Session()
<span class="gd">-        self.retries = Retry(total=10, backoff_factor=0.05,</span>
<span class="gd">-            status_forcelist=[408, 429, 500, 502, 503, 504])</span>
<span class="gd">-        self.session.mount(&#39;https://&#39;, HTTPAdapter(max_retries=self.retries))</span>
<span class="gd">-        self.session.headers.update({&#39;Authorization&#39;: f&#39;Bearer {self.token}&#39;})</span>
<span class="gi">+        self.retries = Retry(</span>
<span class="gi">+            total=10,</span>
<span class="gi">+            backoff_factor=0.05,</span>
<span class="gi">+            status_forcelist=[408, 429, 500, 502, 503, 504],</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        self.session.mount(&quot;https://&quot;, HTTPAdapter(max_retries=self.retries))</span>
<span class="gi">+        self.session.headers.update({&quot;Authorization&quot;: f&quot;Bearer {self.token}&quot;})</span>
<span class="gi">+</span>
<span class="w"> </span>        super().__init__(**kwargs)

<span class="w"> </span>    def ls(self, path, detail=True, **kwargs):
<span class="gu">@@ -61,7 +69,31 @@ class DatabricksFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>            but also additional information on file sizes
<span class="w"> </span>            and types.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        out = self._ls_from_cache(path)</span>
<span class="gi">+        if not out:</span>
<span class="gi">+            try:</span>
<span class="gi">+                r = self._send_to_api(</span>
<span class="gi">+                    method=&quot;get&quot;, endpoint=&quot;list&quot;, json={&quot;path&quot;: path}</span>
<span class="gi">+                )</span>
<span class="gi">+            except DatabricksException as e:</span>
<span class="gi">+                if e.error_code == &quot;RESOURCE_DOES_NOT_EXIST&quot;:</span>
<span class="gi">+                    raise FileNotFoundError(e.message)</span>
<span class="gi">+</span>
<span class="gi">+                raise e</span>
<span class="gi">+            files = r[&quot;files&quot;]</span>
<span class="gi">+            out = [</span>
<span class="gi">+                {</span>
<span class="gi">+                    &quot;name&quot;: o[&quot;path&quot;],</span>
<span class="gi">+                    &quot;type&quot;: &quot;directory&quot; if o[&quot;is_dir&quot;] else &quot;file&quot;,</span>
<span class="gi">+                    &quot;size&quot;: o[&quot;file_size&quot;],</span>
<span class="gi">+                }</span>
<span class="gi">+                for o in files</span>
<span class="gi">+            ]</span>
<span class="gi">+            self.dircache[path] = out</span>
<span class="gi">+</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return out</span>
<span class="gi">+        return [o[&quot;name&quot;] for o in out]</span>

<span class="w"> </span>    def makedirs(self, path, exist_ok=True):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -76,7 +108,25 @@ class DatabricksFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>            exists before creating it (and raises an
<span class="w"> </span>            Exception if this is the case)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if not exist_ok:</span>
<span class="gi">+            try:</span>
<span class="gi">+                # If the following succeeds, the path is already present</span>
<span class="gi">+                self._send_to_api(</span>
<span class="gi">+                    method=&quot;get&quot;, endpoint=&quot;get-status&quot;, json={&quot;path&quot;: path}</span>
<span class="gi">+                )</span>
<span class="gi">+                raise FileExistsError(f&quot;Path {path} already exists&quot;)</span>
<span class="gi">+            except DatabricksException as e:</span>
<span class="gi">+                if e.error_code == &quot;RESOURCE_DOES_NOT_EXIST&quot;:</span>
<span class="gi">+                    pass</span>
<span class="gi">+</span>
<span class="gi">+        try:</span>
<span class="gi">+            self._send_to_api(method=&quot;post&quot;, endpoint=&quot;mkdirs&quot;, json={&quot;path&quot;: path})</span>
<span class="gi">+        except DatabricksException as e:</span>
<span class="gi">+            if e.error_code == &quot;RESOURCE_ALREADY_EXISTS&quot;:</span>
<span class="gi">+                raise FileExistsError(e.message)</span>
<span class="gi">+</span>
<span class="gi">+            raise e</span>
<span class="gi">+        self.invalidate_cache(self._parent(path))</span>

<span class="w"> </span>    def mkdir(self, path, create_parents=True, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -90,7 +140,10 @@ class DatabricksFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>            Whether to create all parents or not.
<span class="w"> </span>            &quot;False&quot; is not implemented so far.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if not create_parents:</span>
<span class="gi">+            raise NotImplementedError</span>
<span class="gi">+</span>
<span class="gi">+        self.mkdirs(path, **kwargs)</span>

<span class="w"> </span>    def rm(self, path, recursive=False, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -103,10 +156,27 @@ class DatabricksFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        recursive: bool
<span class="w"> </span>            Recursively delete all files in a folder.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def mv(self, source_path, destination_path, recursive=False, maxdepth=</span>
<span class="gd">-        None, **kwargs):</span>
<span class="gi">+        try:</span>
<span class="gi">+            self._send_to_api(</span>
<span class="gi">+                method=&quot;post&quot;,</span>
<span class="gi">+                endpoint=&quot;delete&quot;,</span>
<span class="gi">+                json={&quot;path&quot;: path, &quot;recursive&quot;: recursive},</span>
<span class="gi">+            )</span>
<span class="gi">+        except DatabricksException as e:</span>
<span class="gi">+            # This is not really an exception, it just means</span>
<span class="gi">+            # not everything was deleted so far</span>
<span class="gi">+            if e.error_code == &quot;PARTIAL_DELETE&quot;:</span>
<span class="gi">+                self.rm(path=path, recursive=recursive)</span>
<span class="gi">+            elif e.error_code == &quot;IO_ERROR&quot;:</span>
<span class="gi">+                # Using the same exception as the os module would use here</span>
<span class="gi">+                raise OSError(e.message)</span>
<span class="gi">+</span>
<span class="gi">+            raise e</span>
<span class="gi">+        self.invalidate_cache(self._parent(path))</span>
<span class="gi">+</span>
<span class="gi">+    def mv(</span>
<span class="gi">+        self, source_path, destination_path, recursive=False, maxdepth=None, **kwargs</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Move a source to a destination path.

<span class="gu">@@ -129,16 +199,35 @@ class DatabricksFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        maxdepth:
<span class="w"> </span>            Not implemented to far.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def _open(self, path, mode=&#39;rb&#39;, block_size=&#39;default&#39;, **kwargs):</span>
<span class="gi">+        if recursive:</span>
<span class="gi">+            raise NotImplementedError</span>
<span class="gi">+        if maxdepth:</span>
<span class="gi">+            raise NotImplementedError</span>
<span class="gi">+</span>
<span class="gi">+        try:</span>
<span class="gi">+            self._send_to_api(</span>
<span class="gi">+                method=&quot;post&quot;,</span>
<span class="gi">+                endpoint=&quot;move&quot;,</span>
<span class="gi">+                json={&quot;source_path&quot;: source_path, &quot;destination_path&quot;: destination_path},</span>
<span class="gi">+            )</span>
<span class="gi">+        except DatabricksException as e:</span>
<span class="gi">+            if e.error_code == &quot;RESOURCE_DOES_NOT_EXIST&quot;:</span>
<span class="gi">+                raise FileNotFoundError(e.message)</span>
<span class="gi">+            elif e.error_code == &quot;RESOURCE_ALREADY_EXISTS&quot;:</span>
<span class="gi">+                raise FileExistsError(e.message)</span>
<span class="gi">+</span>
<span class="gi">+            raise e</span>
<span class="gi">+        self.invalidate_cache(self._parent(source_path))</span>
<span class="gi">+        self.invalidate_cache(self._parent(destination_path))</span>
<span class="gi">+</span>
<span class="gi">+    def _open(self, path, mode=&quot;rb&quot;, block_size=&quot;default&quot;, **kwargs):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Overwrite the base class method to make sure to create a DBFile.
<span class="w"> </span>        All arguments are copied from the base method.

<span class="w"> </span>        Only the default blocksize is allowed.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return DatabricksFile(self, path, mode=mode, block_size=block_size, **kwargs)</span>

<span class="w"> </span>    def _send_to_api(self, method, endpoint, json):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -154,7 +243,32 @@ class DatabricksFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        json: dict
<span class="w"> </span>            Dictionary of information to send
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if method == &quot;post&quot;:</span>
<span class="gi">+            session_call = self.session.post</span>
<span class="gi">+        elif method == &quot;get&quot;:</span>
<span class="gi">+            session_call = self.session.get</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise ValueError(f&quot;Do not understand method {method}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        url = urllib.parse.urljoin(f&quot;https://{self.instance}/api/2.0/dbfs/&quot;, endpoint)</span>
<span class="gi">+</span>
<span class="gi">+        r = session_call(url, json=json)</span>
<span class="gi">+</span>
<span class="gi">+        # The DBFS API will return a json, also in case of an exception.</span>
<span class="gi">+        # We want to preserve this information as good as possible.</span>
<span class="gi">+        try:</span>
<span class="gi">+            r.raise_for_status()</span>
<span class="gi">+        except requests.HTTPError as e:</span>
<span class="gi">+            # try to extract json error message</span>
<span class="gi">+            # if that fails, fall back to the original exception</span>
<span class="gi">+            try:</span>
<span class="gi">+                exception_json = e.response.json()</span>
<span class="gi">+            except Exception:</span>
<span class="gi">+                raise e</span>
<span class="gi">+</span>
<span class="gi">+            raise DatabricksException(**exception_json)</span>
<span class="gi">+</span>
<span class="gi">+        return r.json()</span>

<span class="w"> </span>    def _create_handle(self, path, overwrite=True):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -174,7 +288,18 @@ class DatabricksFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>            If a file already exist at this location, either overwrite
<span class="w"> </span>            it or raise an exception.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        try:</span>
<span class="gi">+            r = self._send_to_api(</span>
<span class="gi">+                method=&quot;post&quot;,</span>
<span class="gi">+                endpoint=&quot;create&quot;,</span>
<span class="gi">+                json={&quot;path&quot;: path, &quot;overwrite&quot;: overwrite},</span>
<span class="gi">+            )</span>
<span class="gi">+            return r[&quot;handle&quot;]</span>
<span class="gi">+        except DatabricksException as e:</span>
<span class="gi">+            if e.error_code == &quot;RESOURCE_ALREADY_EXISTS&quot;:</span>
<span class="gi">+                raise FileExistsError(e.message)</span>
<span class="gi">+</span>
<span class="gi">+            raise e</span>

<span class="w"> </span>    def _close_handle(self, handle):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -185,7 +310,13 @@ class DatabricksFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        handle: str
<span class="w"> </span>            Which handle to close.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        try:</span>
<span class="gi">+            self._send_to_api(method=&quot;post&quot;, endpoint=&quot;close&quot;, json={&quot;handle&quot;: handle})</span>
<span class="gi">+        except DatabricksException as e:</span>
<span class="gi">+            if e.error_code == &quot;RESOURCE_DOES_NOT_EXIST&quot;:</span>
<span class="gi">+                raise FileNotFoundError(e.message)</span>
<span class="gi">+</span>
<span class="gi">+            raise e</span>

<span class="w"> </span>    def _add_data(self, handle, data):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -202,7 +333,20 @@ class DatabricksFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        data: bytes
<span class="w"> </span>            Block of data to add to the handle.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        data = base64.b64encode(data).decode()</span>
<span class="gi">+        try:</span>
<span class="gi">+            self._send_to_api(</span>
<span class="gi">+                method=&quot;post&quot;,</span>
<span class="gi">+                endpoint=&quot;add-block&quot;,</span>
<span class="gi">+                json={&quot;handle&quot;: handle, &quot;data&quot;: data},</span>
<span class="gi">+            )</span>
<span class="gi">+        except DatabricksException as e:</span>
<span class="gi">+            if e.error_code == &quot;RESOURCE_DOES_NOT_EXIST&quot;:</span>
<span class="gi">+                raise FileNotFoundError(e.message)</span>
<span class="gi">+            elif e.error_code == &quot;MAX_BLOCK_SIZE_EXCEEDED&quot;:</span>
<span class="gi">+                raise ValueError(e.message)</span>
<span class="gi">+</span>
<span class="gi">+            raise e</span>

<span class="w"> </span>    def _get_data(self, path, start, end):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -219,41 +363,105 @@ class DatabricksFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        end: int
<span class="w"> </span>            End position of the block
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        try:</span>
<span class="gi">+            r = self._send_to_api(</span>
<span class="gi">+                method=&quot;get&quot;,</span>
<span class="gi">+                endpoint=&quot;read&quot;,</span>
<span class="gi">+                json={&quot;path&quot;: path, &quot;offset&quot;: start, &quot;length&quot;: end - start},</span>
<span class="gi">+            )</span>
<span class="gi">+            return base64.b64decode(r[&quot;data&quot;])</span>
<span class="gi">+        except DatabricksException as e:</span>
<span class="gi">+            if e.error_code == &quot;RESOURCE_DOES_NOT_EXIST&quot;:</span>
<span class="gi">+                raise FileNotFoundError(e.message)</span>
<span class="gi">+            elif e.error_code in [&quot;INVALID_PARAMETER_VALUE&quot;, &quot;MAX_READ_SIZE_EXCEEDED&quot;]:</span>
<span class="gi">+                raise ValueError(e.message)</span>
<span class="gi">+</span>
<span class="gi">+            raise e</span>
<span class="gi">+</span>
<span class="gi">+    def invalidate_cache(self, path=None):</span>
<span class="gi">+        if path is None:</span>
<span class="gi">+            self.dircache.clear()</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.dircache.pop(path, None)</span>
<span class="gi">+        super().invalidate_cache(path)</span>


<span class="w"> </span>class DatabricksFile(AbstractBufferedFile):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Helper class for files referenced in the DatabricksFileSystem.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    DEFAULT_BLOCK_SIZE = 1 * 2 ** 20</span>

<span class="gd">-    def __init__(self, fs, path, mode=&#39;rb&#39;, block_size=&#39;default&#39;,</span>
<span class="gd">-        autocommit=True, cache_type=&#39;readahead&#39;, cache_options=None, **kwargs):</span>
<span class="gi">+    DEFAULT_BLOCK_SIZE = 1 * 2**20  # only allowed block size</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        fs,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=&quot;default&quot;,</span>
<span class="gi">+        autocommit=True,</span>
<span class="gi">+        cache_type=&quot;readahead&quot;,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Create a new instance of the DatabricksFile.

<span class="w"> </span>        The blocksize needs to be the default one.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        if block_size is None or block_size == &#39;default&#39;:</span>
<span class="gi">+        if block_size is None or block_size == &quot;default&quot;:</span>
<span class="w"> </span>            block_size = self.DEFAULT_BLOCK_SIZE
<span class="gd">-        assert block_size == self.DEFAULT_BLOCK_SIZE, f&#39;Only the default block size is allowed, not {block_size}&#39;</span>
<span class="gd">-        super().__init__(fs, path, mode=mode, block_size=block_size,</span>
<span class="gd">-            autocommit=autocommit, cache_type=cache_type, cache_options=</span>
<span class="gd">-            cache_options or {}, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+        assert (</span>
<span class="gi">+            block_size == self.DEFAULT_BLOCK_SIZE</span>
<span class="gi">+        ), f&quot;Only the default block size is allowed, not {block_size}&quot;</span>
<span class="gi">+</span>
<span class="gi">+        super().__init__(</span>
<span class="gi">+            fs,</span>
<span class="gi">+            path,</span>
<span class="gi">+            mode=mode,</span>
<span class="gi">+            block_size=block_size,</span>
<span class="gi">+            autocommit=autocommit,</span>
<span class="gi">+            cache_type=cache_type,</span>
<span class="gi">+            cache_options=cache_options or {},</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def _initiate_upload(self):
<span class="w"> </span>        &quot;&quot;&quot;Internal function to start a file upload&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.handle = self.fs._create_handle(self.path)</span>

<span class="w"> </span>    def _upload_chunk(self, final=False):
<span class="w"> </span>        &quot;&quot;&quot;Internal function to add a chunk of data to a started upload&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.buffer.seek(0)</span>
<span class="gi">+        data = self.buffer.getvalue()</span>
<span class="gi">+</span>
<span class="gi">+        data_chunks = [</span>
<span class="gi">+            data[start:end] for start, end in self._to_sized_blocks(len(data))</span>
<span class="gi">+        ]</span>
<span class="gi">+</span>
<span class="gi">+        for data_chunk in data_chunks:</span>
<span class="gi">+            self.fs._add_data(handle=self.handle, data=data_chunk)</span>
<span class="gi">+</span>
<span class="gi">+        if final:</span>
<span class="gi">+            self.fs._close_handle(handle=self.handle)</span>
<span class="gi">+            return True</span>

<span class="w"> </span>    def _fetch_range(self, start, end):
<span class="w"> </span>        &quot;&quot;&quot;Internal function to download a block of data&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return_buffer = b&quot;&quot;</span>
<span class="gi">+        length = end - start</span>
<span class="gi">+        for chunk_start, chunk_end in self._to_sized_blocks(length, start):</span>
<span class="gi">+            return_buffer += self.fs._get_data(</span>
<span class="gi">+                path=self.path, start=chunk_start, end=chunk_end</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        return return_buffer</span>

<span class="w"> </span>    def _to_sized_blocks(self, length, start=0):
<span class="w"> </span>        &quot;&quot;&quot;Helper function to split a range from 0 to total_length into bloksizes&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        end = start + length</span>
<span class="gi">+        for data_chunk in range(start, end, self.blocksize):</span>
<span class="gi">+            data_start = data_chunk</span>
<span class="gi">+            data_end = min(end, data_chunk + self.blocksize)</span>
<span class="gi">+            yield data_start, data_end</span>
<span class="gh">diff --git a/fsspec/implementations/dirfs.py b/fsspec/implementations/dirfs.py</span>
<span class="gh">index 08a20a1..04f7479 100644</span>
<span class="gd">--- a/fsspec/implementations/dirfs.py</span>
<span class="gi">+++ b/fsspec/implementations/dirfs.py</span>
<span class="gu">@@ -9,10 +9,18 @@ class DirFileSystem(AsyncFileSystem):</span>
<span class="w"> </span>    is relative to the `path`. After performing the necessary paths operation it
<span class="w"> </span>    delegates everything to the wrapped filesystem.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    protocol = &#39;dir&#39;</span>

<span class="gd">-    def __init__(self, path=None, fs=None, fo=None, target_protocol=None,</span>
<span class="gd">-        target_options=None, **storage_options):</span>
<span class="gi">+    protocol = &quot;dir&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path=None,</span>
<span class="gi">+        fs=None,</span>
<span class="gi">+        fo=None,</span>
<span class="gi">+        target_protocol=None,</span>
<span class="gi">+        target_options=None,</span>
<span class="gi">+        **storage_options,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Parameters
<span class="w"> </span>        ----------
<span class="gu">@@ -27,18 +35,332 @@ class DirFileSystem(AsyncFileSystem):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        super().__init__(**storage_options)
<span class="w"> </span>        if fs is None:
<span class="gd">-            fs = filesystem(protocol=target_protocol, **target_options or {})</span>
<span class="gi">+            fs = filesystem(protocol=target_protocol, **(target_options or {}))</span>
<span class="w"> </span>        if (path is not None) ^ (fo is not None) is False:
<span class="gd">-            raise ValueError(&#39;Provide path or fo, not both&#39;)</span>
<span class="gi">+            raise ValueError(&quot;Provide path or fo, not both&quot;)</span>
<span class="w"> </span>        path = path or fo
<span class="gi">+</span>
<span class="w"> </span>        if self.asynchronous and not fs.async_impl:
<span class="w"> </span>            raise ValueError(&quot;can&#39;t use asynchronous with non-async fs&quot;)
<span class="gi">+</span>
<span class="w"> </span>        if fs.async_impl and self.asynchronous != fs.asynchronous:
<span class="gd">-            raise ValueError(</span>
<span class="gd">-                &#39;both dirfs and fs should be in the same sync/async mode&#39;)</span>
<span class="gi">+            raise ValueError(&quot;both dirfs and fs should be in the same sync/async mode&quot;)</span>
<span class="gi">+</span>
<span class="w"> </span>        self.path = fs._strip_protocol(path)
<span class="w"> </span>        self.fs = fs

<span class="gi">+    def _join(self, path):</span>
<span class="gi">+        if isinstance(path, str):</span>
<span class="gi">+            if not self.path:</span>
<span class="gi">+                return path</span>
<span class="gi">+            if not path:</span>
<span class="gi">+                return self.path</span>
<span class="gi">+            return self.fs.sep.join((self.path, self._strip_protocol(path)))</span>
<span class="gi">+        if isinstance(path, dict):</span>
<span class="gi">+            return {self._join(_path): value for _path, value in path.items()}</span>
<span class="gi">+        return [self._join(_path) for _path in path]</span>
<span class="gi">+</span>
<span class="gi">+    def _relpath(self, path):</span>
<span class="gi">+        if isinstance(path, str):</span>
<span class="gi">+            if not self.path:</span>
<span class="gi">+                return path</span>
<span class="gi">+            if path == self.path:</span>
<span class="gi">+                return &quot;&quot;</span>
<span class="gi">+            prefix = self.path + self.fs.sep</span>
<span class="gi">+            assert path.startswith(prefix)</span>
<span class="gi">+            return path[len(prefix) :]</span>
<span class="gi">+        return [self._relpath(_path) for _path in path]</span>
<span class="gi">+</span>
<span class="gi">+    # Wrappers below</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def sep(self):</span>
<span class="gi">+        return self.fs.sep</span>
<span class="gi">+</span>
<span class="gi">+    async def set_session(self, *args, **kwargs):</span>
<span class="gi">+        return await self.fs.set_session(*args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    async def _rm_file(self, path, **kwargs):</span>
<span class="gi">+        return await self.fs._rm_file(self._join(path), **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def rm_file(self, path, **kwargs):</span>
<span class="gi">+        return self.fs.rm_file(self._join(path), **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    async def _rm(self, path, *args, **kwargs):</span>
<span class="gi">+        return await self.fs._rm(self._join(path), *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def rm(self, path, *args, **kwargs):</span>
<span class="gi">+        return self.fs.rm(self._join(path), *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    async def _cp_file(self, path1, path2, **kwargs):</span>
<span class="gi">+        return await self.fs._cp_file(self._join(path1), self._join(path2), **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def cp_file(self, path1, path2, **kwargs):</span>
<span class="gi">+        return self.fs.cp_file(self._join(path1), self._join(path2), **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    async def _copy(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path1,</span>
<span class="gi">+        path2,</span>
<span class="gi">+        *args,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        return await self.fs._copy(</span>
<span class="gi">+            self._join(path1),</span>
<span class="gi">+            self._join(path2),</span>
<span class="gi">+            *args,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def copy(self, path1, path2, *args, **kwargs):</span>
<span class="gi">+        return self.fs.copy(</span>
<span class="gi">+            self._join(path1),</span>
<span class="gi">+            self._join(path2),</span>
<span class="gi">+            *args,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    async def _pipe(self, path, *args, **kwargs):</span>
<span class="gi">+        return await self.fs._pipe(self._join(path), *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def pipe(self, path, *args, **kwargs):</span>
<span class="gi">+        return self.fs.pipe(self._join(path), *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    async def _pipe_file(self, path, *args, **kwargs):</span>
<span class="gi">+        return await self.fs._pipe_file(self._join(path), *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def pipe_file(self, path, *args, **kwargs):</span>
<span class="gi">+        return self.fs.pipe_file(self._join(path), *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    async def _cat_file(self, path, *args, **kwargs):</span>
<span class="gi">+        return await self.fs._cat_file(self._join(path), *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def cat_file(self, path, *args, **kwargs):</span>
<span class="gi">+        return self.fs.cat_file(self._join(path), *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    async def _cat(self, path, *args, **kwargs):</span>
<span class="gi">+        ret = await self.fs._cat(</span>
<span class="gi">+            self._join(path),</span>
<span class="gi">+            *args,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        if isinstance(ret, dict):</span>
<span class="gi">+            return {self._relpath(key): value for key, value in ret.items()}</span>
<span class="gi">+</span>
<span class="gi">+        return ret</span>
<span class="gi">+</span>
<span class="gi">+    def cat(self, path, *args, **kwargs):</span>
<span class="gi">+        ret = self.fs.cat(</span>
<span class="gi">+            self._join(path),</span>
<span class="gi">+            *args,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        if isinstance(ret, dict):</span>
<span class="gi">+            return {self._relpath(key): value for key, value in ret.items()}</span>
<span class="gi">+</span>
<span class="gi">+        return ret</span>
<span class="gi">+</span>
<span class="gi">+    async def _put_file(self, lpath, rpath, **kwargs):</span>
<span class="gi">+        return await self.fs._put_file(lpath, self._join(rpath), **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def put_file(self, lpath, rpath, **kwargs):</span>
<span class="gi">+        return self.fs.put_file(lpath, self._join(rpath), **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    async def _put(</span>
<span class="gi">+        self,</span>
<span class="gi">+        lpath,</span>
<span class="gi">+        rpath,</span>
<span class="gi">+        *args,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        return await self.fs._put(</span>
<span class="gi">+            lpath,</span>
<span class="gi">+            self._join(rpath),</span>
<span class="gi">+            *args,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def put(self, lpath, rpath, *args, **kwargs):</span>
<span class="gi">+        return self.fs.put(</span>
<span class="gi">+            lpath,</span>
<span class="gi">+            self._join(rpath),</span>
<span class="gi">+            *args,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    async def _get_file(self, rpath, lpath, **kwargs):</span>
<span class="gi">+        return await self.fs._get_file(self._join(rpath), lpath, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def get_file(self, rpath, lpath, **kwargs):</span>
<span class="gi">+        return self.fs.get_file(self._join(rpath), lpath, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    async def _get(self, rpath, *args, **kwargs):</span>
<span class="gi">+        return await self.fs._get(self._join(rpath), *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def get(self, rpath, *args, **kwargs):</span>
<span class="gi">+        return self.fs.get(self._join(rpath), *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    async def _isfile(self, path):</span>
<span class="gi">+        return await self.fs._isfile(self._join(path))</span>
<span class="gi">+</span>
<span class="gi">+    def isfile(self, path):</span>
<span class="gi">+        return self.fs.isfile(self._join(path))</span>
<span class="gi">+</span>
<span class="gi">+    async def _isdir(self, path):</span>
<span class="gi">+        return await self.fs._isdir(self._join(path))</span>
<span class="gi">+</span>
<span class="gi">+    def isdir(self, path):</span>
<span class="gi">+        return self.fs.isdir(self._join(path))</span>
<span class="gi">+</span>
<span class="gi">+    async def _size(self, path):</span>
<span class="gi">+        return await self.fs._size(self._join(path))</span>
<span class="gi">+</span>
<span class="gi">+    def size(self, path):</span>
<span class="gi">+        return self.fs.size(self._join(path))</span>
<span class="gi">+</span>
<span class="gi">+    async def _exists(self, path):</span>
<span class="gi">+        return await self.fs._exists(self._join(path))</span>
<span class="gi">+</span>
<span class="gi">+    def exists(self, path):</span>
<span class="gi">+        return self.fs.exists(self._join(path))</span>
<span class="gi">+</span>
<span class="gi">+    async def _info(self, path, **kwargs):</span>
<span class="gi">+        return await self.fs._info(self._join(path), **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def info(self, path, **kwargs):</span>
<span class="gi">+        return self.fs.info(self._join(path), **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    async def _ls(self, path, detail=True, **kwargs):</span>
<span class="gi">+        ret = (await self.fs._ls(self._join(path), detail=detail, **kwargs)).copy()</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            out = []</span>
<span class="gi">+            for entry in ret:</span>
<span class="gi">+                entry = entry.copy()</span>
<span class="gi">+                entry[&quot;name&quot;] = self._relpath(entry[&quot;name&quot;])</span>
<span class="gi">+                out.append(entry)</span>
<span class="gi">+            return out</span>
<span class="gi">+</span>
<span class="gi">+        return self._relpath(ret)</span>
<span class="gi">+</span>
<span class="gi">+    def ls(self, path, detail=True, **kwargs):</span>
<span class="gi">+        ret = self.fs.ls(self._join(path), detail=detail, **kwargs).copy()</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            out = []</span>
<span class="gi">+            for entry in ret:</span>
<span class="gi">+                entry = entry.copy()</span>
<span class="gi">+                entry[&quot;name&quot;] = self._relpath(entry[&quot;name&quot;])</span>
<span class="gi">+                out.append(entry)</span>
<span class="gi">+            return out</span>
<span class="gi">+</span>
<span class="gi">+        return self._relpath(ret)</span>
<span class="gi">+</span>
<span class="gi">+    async def _walk(self, path, *args, **kwargs):</span>
<span class="gi">+        async for root, dirs, files in self.fs._walk(self._join(path), *args, **kwargs):</span>
<span class="gi">+            yield self._relpath(root), dirs, files</span>
<span class="gi">+</span>
<span class="gi">+    def walk(self, path, *args, **kwargs):</span>
<span class="gi">+        for root, dirs, files in self.fs.walk(self._join(path), *args, **kwargs):</span>
<span class="gi">+            yield self._relpath(root), dirs, files</span>
<span class="gi">+</span>
<span class="gi">+    async def _glob(self, path, **kwargs):</span>
<span class="gi">+        detail = kwargs.get(&quot;detail&quot;, False)</span>
<span class="gi">+        ret = await self.fs._glob(self._join(path), **kwargs)</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return {self._relpath(path): info for path, info in ret.items()}</span>
<span class="gi">+        return self._relpath(ret)</span>
<span class="gi">+</span>
<span class="gi">+    def glob(self, path, **kwargs):</span>
<span class="gi">+        detail = kwargs.get(&quot;detail&quot;, False)</span>
<span class="gi">+        ret = self.fs.glob(self._join(path), **kwargs)</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return {self._relpath(path): info for path, info in ret.items()}</span>
<span class="gi">+        return self._relpath(ret)</span>
<span class="gi">+</span>
<span class="gi">+    async def _du(self, path, *args, **kwargs):</span>
<span class="gi">+        total = kwargs.get(&quot;total&quot;, True)</span>
<span class="gi">+        ret = await self.fs._du(self._join(path), *args, **kwargs)</span>
<span class="gi">+        if total:</span>
<span class="gi">+            return ret</span>
<span class="gi">+</span>
<span class="gi">+        return {self._relpath(path): size for path, size in ret.items()}</span>
<span class="gi">+</span>
<span class="gi">+    def du(self, path, *args, **kwargs):</span>
<span class="gi">+        total = kwargs.get(&quot;total&quot;, True)</span>
<span class="gi">+        ret = self.fs.du(self._join(path), *args, **kwargs)</span>
<span class="gi">+        if total:</span>
<span class="gi">+            return ret</span>
<span class="gi">+</span>
<span class="gi">+        return {self._relpath(path): size for path, size in ret.items()}</span>
<span class="gi">+</span>
<span class="gi">+    async def _find(self, path, *args, **kwargs):</span>
<span class="gi">+        detail = kwargs.get(&quot;detail&quot;, False)</span>
<span class="gi">+        ret = await self.fs._find(self._join(path), *args, **kwargs)</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return {self._relpath(path): info for path, info in ret.items()}</span>
<span class="gi">+        return self._relpath(ret)</span>
<span class="gi">+</span>
<span class="gi">+    def find(self, path, *args, **kwargs):</span>
<span class="gi">+        detail = kwargs.get(&quot;detail&quot;, False)</span>
<span class="gi">+        ret = self.fs.find(self._join(path), *args, **kwargs)</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return {self._relpath(path): info for path, info in ret.items()}</span>
<span class="gi">+        return self._relpath(ret)</span>
<span class="gi">+</span>
<span class="gi">+    async def _expand_path(self, path, *args, **kwargs):</span>
<span class="gi">+        return self._relpath(</span>
<span class="gi">+            await self.fs._expand_path(self._join(path), *args, **kwargs)</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def expand_path(self, path, *args, **kwargs):</span>
<span class="gi">+        return self._relpath(self.fs.expand_path(self._join(path), *args, **kwargs))</span>
<span class="gi">+</span>
<span class="gi">+    async def _mkdir(self, path, *args, **kwargs):</span>
<span class="gi">+        return await self.fs._mkdir(self._join(path), *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def mkdir(self, path, *args, **kwargs):</span>
<span class="gi">+        return self.fs.mkdir(self._join(path), *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    async def _makedirs(self, path, *args, **kwargs):</span>
<span class="gi">+        return await self.fs._makedirs(self._join(path), *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def makedirs(self, path, *args, **kwargs):</span>
<span class="gi">+        return self.fs.makedirs(self._join(path), *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def rmdir(self, path):</span>
<span class="gi">+        return self.fs.rmdir(self._join(path))</span>
<span class="gi">+</span>
<span class="gi">+    def mv(self, path1, path2, **kwargs):</span>
<span class="gi">+        return self.fs.mv(</span>
<span class="gi">+            self._join(path1),</span>
<span class="gi">+            self._join(path2),</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def touch(self, path, **kwargs):</span>
<span class="gi">+        return self.fs.touch(self._join(path), **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def created(self, path):</span>
<span class="gi">+        return self.fs.created(self._join(path))</span>
<span class="gi">+</span>
<span class="gi">+    def modified(self, path):</span>
<span class="gi">+        return self.fs.modified(self._join(path))</span>
<span class="gi">+</span>
<span class="gi">+    def sign(self, path, *args, **kwargs):</span>
<span class="gi">+        return self.fs.sign(self._join(path), *args, **kwargs)</span>
<span class="gi">+</span>
<span class="w"> </span>    def __repr__(self):
<span class="gd">-        return (</span>
<span class="gd">-            f&quot;{self.__class__.__qualname__}(path=&#39;{self.path}&#39;, fs={self.fs})&quot;)</span>
<span class="gi">+        return f&quot;{self.__class__.__qualname__}(path=&#39;{self.path}&#39;, fs={self.fs})&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def open(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        *args,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        return self.fs.open(</span>
<span class="gi">+            self._join(path),</span>
<span class="gi">+            *args,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>
<span class="gh">diff --git a/fsspec/implementations/ftp.py b/fsspec/implementations/ftp.py</span>
<span class="gh">index 0658887..415f484 100644</span>
<span class="gd">--- a/fsspec/implementations/ftp.py</span>
<span class="gi">+++ b/fsspec/implementations/ftp.py</span>
<span class="gu">@@ -4,19 +4,31 @@ import uuid</span>
<span class="w"> </span>import warnings
<span class="w"> </span>from ftplib import FTP, Error, error_perm
<span class="w"> </span>from typing import Any
<span class="gi">+</span>
<span class="w"> </span>from ..spec import AbstractBufferedFile, AbstractFileSystem
<span class="w"> </span>from ..utils import infer_storage_options, isfilelike


<span class="w"> </span>class FTPFileSystem(AbstractFileSystem):
<span class="w"> </span>    &quot;&quot;&quot;A filesystem over classic FTP&quot;&quot;&quot;
<span class="gd">-    root_marker = &#39;/&#39;</span>
<span class="gi">+</span>
<span class="gi">+    root_marker = &quot;/&quot;</span>
<span class="w"> </span>    cachable = False
<span class="gd">-    protocol = &#39;ftp&#39;</span>
<span class="gi">+    protocol = &quot;ftp&quot;</span>

<span class="gd">-    def __init__(self, host, port=21, username=None, password=None, acct=</span>
<span class="gd">-        None, block_size=None, tempdir=None, timeout=30, encoding=&#39;utf-8&#39;,</span>
<span class="gd">-        **kwargs):</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        host,</span>
<span class="gi">+        port=21,</span>
<span class="gi">+        username=None,</span>
<span class="gi">+        password=None,</span>
<span class="gi">+        acct=None,</span>
<span class="gi">+        block_size=None,</span>
<span class="gi">+        tempdir=None,</span>
<span class="gi">+        timeout=30,</span>
<span class="gi">+        encoding=&quot;utf-8&quot;,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        You can use _get_kwargs_from_urls to get some kwargs from
<span class="w"> </span>        a reasonable FTP url.
<span class="gu">@@ -48,36 +60,243 @@ class FTPFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        super().__init__(**kwargs)
<span class="w"> </span>        self.host = host
<span class="w"> </span>        self.port = port
<span class="gd">-        self.tempdir = tempdir or &#39;/tmp&#39;</span>
<span class="gi">+        self.tempdir = tempdir or &quot;/tmp&quot;</span>
<span class="w"> </span>        self.cred = username, password, acct
<span class="w"> </span>        self.timeout = timeout
<span class="w"> </span>        self.encoding = encoding
<span class="w"> </span>        if block_size is not None:
<span class="w"> </span>            self.blocksize = block_size
<span class="w"> </span>        else:
<span class="gd">-            self.blocksize = 2 ** 16</span>
<span class="gi">+            self.blocksize = 2**16</span>
<span class="w"> </span>        self._connect()

<span class="gi">+    def _connect(self):</span>
<span class="gi">+        if sys.version_info &gt;= (3, 9):</span>
<span class="gi">+            self.ftp = FTP(timeout=self.timeout, encoding=self.encoding)</span>
<span class="gi">+        elif self.encoding:</span>
<span class="gi">+            warnings.warn(&quot;`encoding` not supported for python&lt;3.9, ignoring&quot;)</span>
<span class="gi">+            self.ftp = FTP(timeout=self.timeout)</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.ftp = FTP(timeout=self.timeout)</span>
<span class="gi">+        self.ftp.connect(self.host, self.port)</span>
<span class="gi">+        self.ftp.login(*self.cred)</span>
<span class="gi">+</span>
<span class="gi">+    @classmethod</span>
<span class="gi">+    def _strip_protocol(cls, path):</span>
<span class="gi">+        return &quot;/&quot; + infer_storage_options(path)[&quot;path&quot;].lstrip(&quot;/&quot;).rstrip(&quot;/&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _get_kwargs_from_urls(urlpath):</span>
<span class="gi">+        out = infer_storage_options(urlpath)</span>
<span class="gi">+        out.pop(&quot;path&quot;, None)</span>
<span class="gi">+        out.pop(&quot;protocol&quot;, None)</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    def ls(self, path, detail=True, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        out = []</span>
<span class="gi">+        if path not in self.dircache:</span>
<span class="gi">+            try:</span>
<span class="gi">+                try:</span>
<span class="gi">+                    out = [</span>
<span class="gi">+                        (fn, details)</span>
<span class="gi">+                        for (fn, details) in self.ftp.mlsd(path)</span>
<span class="gi">+                        if fn not in [&quot;.&quot;, &quot;..&quot;]</span>
<span class="gi">+                        and details[&quot;type&quot;] not in [&quot;pdir&quot;, &quot;cdir&quot;]</span>
<span class="gi">+                    ]</span>
<span class="gi">+                except error_perm:</span>
<span class="gi">+                    out = _mlsd2(self.ftp, path)  # Not platform independent</span>
<span class="gi">+                for fn, details in out:</span>
<span class="gi">+                    if path == &quot;/&quot;:</span>
<span class="gi">+                        path = &quot;&quot;  # just for forming the names, below</span>
<span class="gi">+                    details[&quot;name&quot;] = &quot;/&quot;.join([path, fn.lstrip(&quot;/&quot;)])</span>
<span class="gi">+                    if details[&quot;type&quot;] == &quot;file&quot;:</span>
<span class="gi">+                        details[&quot;size&quot;] = int(details[&quot;size&quot;])</span>
<span class="gi">+                    else:</span>
<span class="gi">+                        details[&quot;size&quot;] = 0</span>
<span class="gi">+                    if details[&quot;type&quot;] == &quot;dir&quot;:</span>
<span class="gi">+                        details[&quot;type&quot;] = &quot;directory&quot;</span>
<span class="gi">+                self.dircache[path] = out</span>
<span class="gi">+            except Error:</span>
<span class="gi">+                try:</span>
<span class="gi">+                    info = self.info(path)</span>
<span class="gi">+                    if info[&quot;type&quot;] == &quot;file&quot;:</span>
<span class="gi">+                        out = [(path, info)]</span>
<span class="gi">+                except (Error, IndexError):</span>
<span class="gi">+                    raise FileNotFoundError(path)</span>
<span class="gi">+        files = self.dircache.get(path, out)</span>
<span class="gi">+        if not detail:</span>
<span class="gi">+            return sorted([fn for fn, details in files])</span>
<span class="gi">+        return [details for fn, details in files]</span>
<span class="gi">+</span>
<span class="gi">+    def info(self, path, **kwargs):</span>
<span class="gi">+        # implement with direct method</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if path == &quot;/&quot;:</span>
<span class="gi">+            # special case, since this dir has no real entry</span>
<span class="gi">+            return {&quot;name&quot;: &quot;/&quot;, &quot;size&quot;: 0, &quot;type&quot;: &quot;directory&quot;}</span>
<span class="gi">+        files = self.ls(self._parent(path).lstrip(&quot;/&quot;), True)</span>
<span class="gi">+        try:</span>
<span class="gi">+            out = [f for f in files if f[&quot;name&quot;] == path][0]</span>
<span class="gi">+        except IndexError:</span>
<span class="gi">+            raise FileNotFoundError(path)</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    def get_file(self, rpath, lpath, **kwargs):</span>
<span class="gi">+        if self.isdir(rpath):</span>
<span class="gi">+            if not os.path.exists(lpath):</span>
<span class="gi">+                os.mkdir(lpath)</span>
<span class="gi">+            return</span>
<span class="gi">+        if isfilelike(lpath):</span>
<span class="gi">+            outfile = lpath</span>
<span class="gi">+        else:</span>
<span class="gi">+            outfile = open(lpath, &quot;wb&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        def cb(x):</span>
<span class="gi">+            outfile.write(x)</span>
<span class="gi">+</span>
<span class="gi">+        self.ftp.retrbinary(</span>
<span class="gi">+            f&quot;RETR {rpath}&quot;,</span>
<span class="gi">+            blocksize=self.blocksize,</span>
<span class="gi">+            callback=cb,</span>
<span class="gi">+        )</span>
<span class="gi">+        if not isfilelike(lpath):</span>
<span class="gi">+            outfile.close()</span>
<span class="gi">+</span>
<span class="gi">+    def cat_file(self, path, start=None, end=None, **kwargs):</span>
<span class="gi">+        if end is not None:</span>
<span class="gi">+            return super().cat_file(path, start, end, **kwargs)</span>
<span class="gi">+        out = []</span>
<span class="gi">+</span>
<span class="gi">+        def cb(x):</span>
<span class="gi">+            out.append(x)</span>
<span class="gi">+</span>
<span class="gi">+        try:</span>
<span class="gi">+            self.ftp.retrbinary(</span>
<span class="gi">+                f&quot;RETR {path}&quot;,</span>
<span class="gi">+                blocksize=self.blocksize,</span>
<span class="gi">+                rest=start,</span>
<span class="gi">+                callback=cb,</span>
<span class="gi">+            )</span>
<span class="gi">+        except (Error, error_perm) as orig_exc:</span>
<span class="gi">+            raise FileNotFoundError(path) from orig_exc</span>
<span class="gi">+        return b&quot;&quot;.join(out)</span>
<span class="gi">+</span>
<span class="gi">+    def _open(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=None,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        autocommit=True,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        block_size = block_size or self.blocksize</span>
<span class="gi">+        return FTPFile(</span>
<span class="gi">+            self,</span>
<span class="gi">+            path,</span>
<span class="gi">+            mode=mode,</span>
<span class="gi">+            block_size=block_size,</span>
<span class="gi">+            tempdir=self.tempdir,</span>
<span class="gi">+            autocommit=autocommit,</span>
<span class="gi">+            cache_options=cache_options,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def _rm(self, path):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        self.ftp.delete(path)</span>
<span class="gi">+        self.invalidate_cache(self._parent(path))</span>
<span class="gi">+</span>
<span class="gi">+    def rm(self, path, recursive=False, maxdepth=None):</span>
<span class="gi">+        paths = self.expand_path(path, recursive=recursive, maxdepth=maxdepth)</span>
<span class="gi">+        for p in reversed(paths):</span>
<span class="gi">+            if self.isfile(p):</span>
<span class="gi">+                self.rm_file(p)</span>
<span class="gi">+            else:</span>
<span class="gi">+                self.rmdir(p)</span>
<span class="gi">+</span>
<span class="gi">+    def mkdir(self, path: str, create_parents: bool = True, **kwargs: Any) -&gt; None:</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        parent = self._parent(path)</span>
<span class="gi">+        if parent != self.root_marker and not self.exists(parent) and create_parents:</span>
<span class="gi">+            self.mkdir(parent, create_parents=create_parents)</span>
<span class="gi">+</span>
<span class="gi">+        self.ftp.mkd(path)</span>
<span class="gi">+        self.invalidate_cache(self._parent(path))</span>
<span class="gi">+</span>
<span class="gi">+    def makedirs(self, path: str, exist_ok: bool = False) -&gt; None:</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if self.exists(path):</span>
<span class="gi">+            # NB: &quot;/&quot; does not &quot;exist&quot; as it has no directory entry</span>
<span class="gi">+            if not exist_ok:</span>
<span class="gi">+                raise FileExistsError(f&quot;{path} exists without `exist_ok`&quot;)</span>
<span class="gi">+            # exists_ok=True -&gt; no-op</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.mkdir(path, create_parents=True)</span>
<span class="gi">+</span>
<span class="gi">+    def rmdir(self, path):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        self.ftp.rmd(path)</span>
<span class="gi">+        self.invalidate_cache(self._parent(path))</span>
<span class="gi">+</span>
<span class="gi">+    def mv(self, path1, path2, **kwargs):</span>
<span class="gi">+        path1 = self._strip_protocol(path1)</span>
<span class="gi">+        path2 = self._strip_protocol(path2)</span>
<span class="gi">+        self.ftp.rename(path1, path2)</span>
<span class="gi">+        self.invalidate_cache(self._parent(path1))</span>
<span class="gi">+        self.invalidate_cache(self._parent(path2))</span>
<span class="gi">+</span>
<span class="w"> </span>    def __del__(self):
<span class="w"> </span>        self.ftp.close()

<span class="gi">+    def invalidate_cache(self, path=None):</span>
<span class="gi">+        if path is None:</span>
<span class="gi">+            self.dircache.clear()</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.dircache.pop(path, None)</span>
<span class="gi">+        super().invalidate_cache(path)</span>
<span class="gi">+</span>

<span class="w"> </span>class TransferDone(Exception):
<span class="w"> </span>    &quot;&quot;&quot;Internal exception to break out of transfer&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>    pass


<span class="w"> </span>class FTPFile(AbstractBufferedFile):
<span class="w"> </span>    &quot;&quot;&quot;Interact with a remote FTP file with read/write buffering&quot;&quot;&quot;

<span class="gd">-    def __init__(self, fs, path, mode=&#39;rb&#39;, block_size=&#39;default&#39;,</span>
<span class="gd">-        autocommit=True, cache_type=&#39;readahead&#39;, cache_options=None, **kwargs):</span>
<span class="gd">-        super().__init__(fs, path, mode=mode, block_size=block_size,</span>
<span class="gd">-            autocommit=autocommit, cache_type=cache_type, cache_options=</span>
<span class="gd">-            cache_options, **kwargs)</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        fs,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=&quot;default&quot;,</span>
<span class="gi">+        autocommit=True,</span>
<span class="gi">+        cache_type=&quot;readahead&quot;,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        super().__init__(</span>
<span class="gi">+            fs,</span>
<span class="gi">+            path,</span>
<span class="gi">+            mode=mode,</span>
<span class="gi">+            block_size=block_size,</span>
<span class="gi">+            autocommit=autocommit,</span>
<span class="gi">+            cache_type=cache_type,</span>
<span class="gi">+            cache_options=cache_options,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>
<span class="w"> </span>        if not autocommit:
<span class="w"> </span>            self.target = self.path
<span class="gd">-            self.path = &#39;/&#39;.join([kwargs[&#39;tempdir&#39;], str(uuid.uuid4())])</span>
<span class="gi">+            self.path = &quot;/&quot;.join([kwargs[&quot;tempdir&quot;], str(uuid.uuid4())])</span>
<span class="gi">+</span>
<span class="gi">+    def commit(self):</span>
<span class="gi">+        self.fs.mv(self.path, self.target)</span>
<span class="gi">+</span>
<span class="gi">+    def discard(self):</span>
<span class="gi">+        self.fs.rm(self.path)</span>

<span class="w"> </span>    def _fetch_range(self, start, end):
<span class="w"> </span>        &quot;&quot;&quot;Get bytes between given byte limits
<span class="gu">@@ -88,10 +307,47 @@ class FTPFile(AbstractBufferedFile):</span>
<span class="w"> </span>        Will fail if the server does not respect the REST command on
<span class="w"> </span>        retrieve requests.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        out = []</span>
<span class="gi">+        total = [0]</span>
<span class="gi">+</span>
<span class="gi">+        def callback(x):</span>
<span class="gi">+            total[0] += len(x)</span>
<span class="gi">+            if total[0] &gt; end - start:</span>
<span class="gi">+                out.append(x[: (end - start) - total[0]])</span>
<span class="gi">+                if end &lt; self.size:</span>
<span class="gi">+                    raise TransferDone</span>
<span class="gi">+            else:</span>
<span class="gi">+                out.append(x)</span>
<span class="gi">+</span>
<span class="gi">+            if total[0] == end - start and end &lt; self.size:</span>
<span class="gi">+                raise TransferDone</span>
<span class="gi">+</span>
<span class="gi">+        try:</span>
<span class="gi">+            self.fs.ftp.retrbinary(</span>
<span class="gi">+                f&quot;RETR {self.path}&quot;,</span>
<span class="gi">+                blocksize=self.blocksize,</span>
<span class="gi">+                rest=start,</span>
<span class="gi">+                callback=callback,</span>
<span class="gi">+            )</span>
<span class="gi">+        except TransferDone:</span>
<span class="gi">+            try:</span>
<span class="gi">+                # stop transfer, we got enough bytes for this block</span>
<span class="gi">+                self.fs.ftp.abort()</span>
<span class="gi">+                self.fs.ftp.getmultiline()</span>
<span class="gi">+            except Error:</span>
<span class="gi">+                self.fs._connect()</span>

<span class="gi">+        return b&quot;&quot;.join(out)</span>

<span class="gd">-def _mlsd2(ftp, path=&#39;.&#39;):</span>
<span class="gi">+    def _upload_chunk(self, final=False):</span>
<span class="gi">+        self.buffer.seek(0)</span>
<span class="gi">+        self.fs.ftp.storbinary(</span>
<span class="gi">+            f&quot;STOR {self.path}&quot;, self.buffer, blocksize=self.blocksize, rest=self.offset</span>
<span class="gi">+        )</span>
<span class="gi">+        return True</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _mlsd2(ftp, path=&quot;.&quot;):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Fall back to using `dir` instead of `mlsd` if not supported.

<span class="gu">@@ -104,4 +360,26 @@ def _mlsd2(ftp, path=&#39;.&#39;):</span>
<span class="w"> </span>    path: str
<span class="w"> </span>        Expects to be given path, but defaults to &quot;.&quot;.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    lines = []</span>
<span class="gi">+    minfo = []</span>
<span class="gi">+    ftp.dir(path, lines.append)</span>
<span class="gi">+    for line in lines:</span>
<span class="gi">+        split_line = line.split()</span>
<span class="gi">+        if len(split_line) &lt; 9:</span>
<span class="gi">+            continue</span>
<span class="gi">+        this = (</span>
<span class="gi">+            split_line[-1],</span>
<span class="gi">+            {</span>
<span class="gi">+                &quot;modify&quot;: &quot; &quot;.join(split_line[5:8]),</span>
<span class="gi">+                &quot;unix.owner&quot;: split_line[2],</span>
<span class="gi">+                &quot;unix.group&quot;: split_line[3],</span>
<span class="gi">+                &quot;unix.mode&quot;: split_line[0],</span>
<span class="gi">+                &quot;size&quot;: split_line[4],</span>
<span class="gi">+            },</span>
<span class="gi">+        )</span>
<span class="gi">+        if &quot;d&quot; == this[1][&quot;unix.mode&quot;][0]:</span>
<span class="gi">+            this[1][&quot;type&quot;] = &quot;dir&quot;</span>
<span class="gi">+        else:</span>
<span class="gi">+            this[1][&quot;type&quot;] = &quot;file&quot;</span>
<span class="gi">+        minfo.append(this)</span>
<span class="gi">+    return minfo</span>
<span class="gh">diff --git a/fsspec/implementations/git.py b/fsspec/implementations/git.py</span>
<span class="gh">index 760da5b..7c34d93 100644</span>
<span class="gd">--- a/fsspec/implementations/git.py</span>
<span class="gi">+++ b/fsspec/implementations/git.py</span>
<span class="gu">@@ -1,6 +1,9 @@</span>
<span class="w"> </span>import os
<span class="gi">+</span>
<span class="w"> </span>import pygit2
<span class="gi">+</span>
<span class="w"> </span>from fsspec.spec import AbstractFileSystem
<span class="gi">+</span>
<span class="w"> </span>from .memory import MemoryFile


<span class="gu">@@ -9,7 +12,8 @@ class GitFileSystem(AbstractFileSystem):</span>

<span class="w"> </span>    (experimental backend)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    root_marker = &#39;&#39;</span>
<span class="gi">+</span>
<span class="gi">+    root_marker = &quot;&quot;</span>
<span class="w"> </span>    cachable = True

<span class="w"> </span>    def __init__(self, path=None, fo=None, ref=None, **kwargs):
<span class="gu">@@ -34,4 +38,90 @@ class GitFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        super().__init__(**kwargs)
<span class="w"> </span>        self.repo = pygit2.Repository(fo or path or os.getcwd())
<span class="gd">-        self.ref = ref or &#39;master&#39;</span>
<span class="gi">+        self.ref = ref or &quot;master&quot;</span>
<span class="gi">+</span>
<span class="gi">+    @classmethod</span>
<span class="gi">+    def _strip_protocol(cls, path):</span>
<span class="gi">+        path = super()._strip_protocol(path).lstrip(&quot;/&quot;)</span>
<span class="gi">+        if &quot;:&quot; in path:</span>
<span class="gi">+            path = path.split(&quot;:&quot;, 1)[1]</span>
<span class="gi">+        if &quot;@&quot; in path:</span>
<span class="gi">+            path = path.split(&quot;@&quot;, 1)[1]</span>
<span class="gi">+        return path.lstrip(&quot;/&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def _path_to_object(self, path, ref):</span>
<span class="gi">+        comm, ref = self.repo.resolve_refish(ref or self.ref)</span>
<span class="gi">+        parts = path.split(&quot;/&quot;)</span>
<span class="gi">+        tree = comm.tree</span>
<span class="gi">+        for part in parts:</span>
<span class="gi">+            if part and isinstance(tree, pygit2.Tree):</span>
<span class="gi">+                tree = tree[part]</span>
<span class="gi">+        return tree</span>
<span class="gi">+</span>
<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _get_kwargs_from_urls(path):</span>
<span class="gi">+        if path.startswith(&quot;git://&quot;):</span>
<span class="gi">+            path = path[6:]</span>
<span class="gi">+        out = {}</span>
<span class="gi">+        if &quot;:&quot; in path:</span>
<span class="gi">+            out[&quot;path&quot;], path = path.split(&quot;:&quot;, 1)</span>
<span class="gi">+        if &quot;@&quot; in path:</span>
<span class="gi">+            out[&quot;ref&quot;], path = path.split(&quot;@&quot;, 1)</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    def ls(self, path, detail=True, ref=None, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        tree = self._path_to_object(path, ref)</span>
<span class="gi">+        if isinstance(tree, pygit2.Tree):</span>
<span class="gi">+            out = []</span>
<span class="gi">+            for obj in tree:</span>
<span class="gi">+                if isinstance(obj, pygit2.Tree):</span>
<span class="gi">+                    out.append(</span>
<span class="gi">+                        {</span>
<span class="gi">+                            &quot;type&quot;: &quot;directory&quot;,</span>
<span class="gi">+                            &quot;name&quot;: &quot;/&quot;.join([path, obj.name]).lstrip(&quot;/&quot;),</span>
<span class="gi">+                            &quot;hex&quot;: obj.hex,</span>
<span class="gi">+                            &quot;mode&quot;: f&quot;{obj.filemode:o}&quot;,</span>
<span class="gi">+                            &quot;size&quot;: 0,</span>
<span class="gi">+                        }</span>
<span class="gi">+                    )</span>
<span class="gi">+                else:</span>
<span class="gi">+                    out.append(</span>
<span class="gi">+                        {</span>
<span class="gi">+                            &quot;type&quot;: &quot;file&quot;,</span>
<span class="gi">+                            &quot;name&quot;: &quot;/&quot;.join([path, obj.name]).lstrip(&quot;/&quot;),</span>
<span class="gi">+                            &quot;hex&quot;: obj.hex,</span>
<span class="gi">+                            &quot;mode&quot;: f&quot;{obj.filemode:o}&quot;,</span>
<span class="gi">+                            &quot;size&quot;: obj.size,</span>
<span class="gi">+                        }</span>
<span class="gi">+                    )</span>
<span class="gi">+        else:</span>
<span class="gi">+            obj = tree</span>
<span class="gi">+            out = [</span>
<span class="gi">+                {</span>
<span class="gi">+                    &quot;type&quot;: &quot;file&quot;,</span>
<span class="gi">+                    &quot;name&quot;: obj.name,</span>
<span class="gi">+                    &quot;hex&quot;: obj.hex,</span>
<span class="gi">+                    &quot;mode&quot;: f&quot;{obj.filemode:o}&quot;,</span>
<span class="gi">+                    &quot;size&quot;: obj.size,</span>
<span class="gi">+                }</span>
<span class="gi">+            ]</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return out</span>
<span class="gi">+        return [o[&quot;name&quot;] for o in out]</span>
<span class="gi">+</span>
<span class="gi">+    def ukey(self, path, ref=None):</span>
<span class="gi">+        return self.info(path, ref=ref)[&quot;hex&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    def _open(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=None,</span>
<span class="gi">+        autocommit=True,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        ref=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        obj = self._path_to_object(path, ref or self.ref)</span>
<span class="gi">+        return MemoryFile(data=obj.data)</span>
<span class="gh">diff --git a/fsspec/implementations/github.py b/fsspec/implementations/github.py</span>
<span class="gh">index 27f9ccd..3650b8e 100644</span>
<span class="gd">--- a/fsspec/implementations/github.py</span>
<span class="gi">+++ b/fsspec/implementations/github.py</span>
<span class="gu">@@ -1,9 +1,13 @@</span>
<span class="w"> </span>import requests
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="gi">+</span>
<span class="w"> </span>from ..spec import AbstractFileSystem
<span class="w"> </span>from ..utils import infer_storage_options
<span class="w"> </span>from .memory import MemoryFile

<span class="gi">+# TODO: add GIST backend, would be very similar</span>
<span class="gi">+</span>

<span class="w"> </span>class GithubFileSystem(AbstractFileSystem):
<span class="w"> </span>    &quot;&quot;&quot;Interface to files in github
<span class="gu">@@ -30,30 +34,41 @@ class GithubFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>    For authorised access, you must provide username and token, which can be made
<span class="w"> </span>    at https://github.com/settings/tokens
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    url = &#39;https://api.github.com/repos/{org}/{repo}/git/trees/{sha}&#39;</span>
<span class="gd">-    rurl = &#39;https://raw.githubusercontent.com/{org}/{repo}/{sha}/{path}&#39;</span>
<span class="gd">-    protocol = &#39;github&#39;</span>
<span class="gd">-    timeout = 60, 60</span>

<span class="gd">-    def __init__(self, org, repo, sha=None, username=None, token=None,</span>
<span class="gd">-        timeout=None, **kwargs):</span>
<span class="gi">+    url = &quot;https://api.github.com/repos/{org}/{repo}/git/trees/{sha}&quot;</span>
<span class="gi">+    rurl = &quot;https://raw.githubusercontent.com/{org}/{repo}/{sha}/{path}&quot;</span>
<span class="gi">+    protocol = &quot;github&quot;</span>
<span class="gi">+    timeout = (60, 60)  # connect, read timeouts</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self, org, repo, sha=None, username=None, token=None, timeout=None, **kwargs</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        super().__init__(**kwargs)
<span class="w"> </span>        self.org = org
<span class="w"> </span>        self.repo = repo
<span class="w"> </span>        if (username is None) ^ (token is None):
<span class="gd">-            raise ValueError(&#39;Auth required both username and token&#39;)</span>
<span class="gi">+            raise ValueError(&quot;Auth required both username and token&quot;)</span>
<span class="w"> </span>        self.username = username
<span class="w"> </span>        self.token = token
<span class="w"> </span>        if timeout is not None:
<span class="w"> </span>            self.timeout = timeout
<span class="w"> </span>        if sha is None:
<span class="gd">-            u = &#39;https://api.github.com/repos/{org}/{repo}&#39;</span>
<span class="gd">-            r = requests.get(u.format(org=org, repo=repo), timeout=self.</span>
<span class="gd">-                timeout, **self.kw)</span>
<span class="gi">+            # look up default branch (not necessarily &quot;master&quot;)</span>
<span class="gi">+            u = &quot;https://api.github.com/repos/{org}/{repo}&quot;</span>
<span class="gi">+            r = requests.get(</span>
<span class="gi">+                u.format(org=org, repo=repo), timeout=self.timeout, **self.kw</span>
<span class="gi">+            )</span>
<span class="w"> </span>            r.raise_for_status()
<span class="gd">-            sha = r.json()[&#39;default_branch&#39;]</span>
<span class="gi">+            sha = r.json()[&quot;default_branch&quot;]</span>
<span class="gi">+</span>
<span class="w"> </span>        self.root = sha
<span class="gd">-        self.ls(&#39;&#39;)</span>
<span class="gi">+        self.ls(&quot;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def kw(self):</span>
<span class="gi">+        if self.username:</span>
<span class="gi">+            return {&quot;auth&quot;: (self.username, self.token)}</span>
<span class="gi">+        return {}</span>

<span class="w"> </span>    @classmethod
<span class="w"> </span>    def repos(cls, org_or_user, is_org=True):
<span class="gu">@@ -72,22 +87,39 @@ class GithubFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        -------
<span class="w"> </span>        List of string
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        r = requests.get(</span>
<span class="gi">+            f&quot;https://api.github.com/{[&#39;users&#39;, &#39;orgs&#39;][is_org]}/{org_or_user}/repos&quot;,</span>
<span class="gi">+            timeout=cls.timeout,</span>
<span class="gi">+        )</span>
<span class="gi">+        r.raise_for_status()</span>
<span class="gi">+        return [repo[&quot;name&quot;] for repo in r.json()]</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def tags(self):
<span class="w"> </span>        &quot;&quot;&quot;Names of tags in the repo&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        r = requests.get(</span>
<span class="gi">+            f&quot;https://api.github.com/repos/{self.org}/{self.repo}/tags&quot;,</span>
<span class="gi">+            timeout=self.timeout,</span>
<span class="gi">+            **self.kw,</span>
<span class="gi">+        )</span>
<span class="gi">+        r.raise_for_status()</span>
<span class="gi">+        return [t[&quot;name&quot;] for t in r.json()]</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def branches(self):
<span class="w"> </span>        &quot;&quot;&quot;Names of branches in the repo&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        r = requests.get(</span>
<span class="gi">+            f&quot;https://api.github.com/repos/{self.org}/{self.repo}/branches&quot;,</span>
<span class="gi">+            timeout=self.timeout,</span>
<span class="gi">+            **self.kw,</span>
<span class="gi">+        )</span>
<span class="gi">+        r.raise_for_status()</span>
<span class="gi">+        return [t[&quot;name&quot;] for t in r.json()]</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def refs(self):
<span class="w"> </span>        &quot;&quot;&quot;Named references, tags and branches&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return {&quot;tags&quot;: self.tags, &quot;branches&quot;: self.branches}</span>

<span class="w"> </span>    def ls(self, path, detail=False, sha=None, _sha=None, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;List files at given path
<span class="gu">@@ -105,4 +137,103 @@ class GithubFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        _sha: str (optional)
<span class="w"> </span>            List this specific tree object (used internally to descend into trees)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if path == &quot;&quot;:</span>
<span class="gi">+            _sha = sha or self.root</span>
<span class="gi">+        if _sha is None:</span>
<span class="gi">+            parts = path.rstrip(&quot;/&quot;).split(&quot;/&quot;)</span>
<span class="gi">+            so_far = &quot;&quot;</span>
<span class="gi">+            _sha = sha or self.root</span>
<span class="gi">+            for part in parts:</span>
<span class="gi">+                out = self.ls(so_far, True, sha=sha, _sha=_sha)</span>
<span class="gi">+                so_far += &quot;/&quot; + part if so_far else part</span>
<span class="gi">+                out = [o for o in out if o[&quot;name&quot;] == so_far]</span>
<span class="gi">+                if not out:</span>
<span class="gi">+                    raise FileNotFoundError(path)</span>
<span class="gi">+                out = out[0]</span>
<span class="gi">+                if out[&quot;type&quot;] == &quot;file&quot;:</span>
<span class="gi">+                    if detail:</span>
<span class="gi">+                        return [out]</span>
<span class="gi">+                    else:</span>
<span class="gi">+                        return path</span>
<span class="gi">+                _sha = out[&quot;sha&quot;]</span>
<span class="gi">+        if path not in self.dircache or sha not in [self.root, None]:</span>
<span class="gi">+            r = requests.get(</span>
<span class="gi">+                self.url.format(org=self.org, repo=self.repo, sha=_sha),</span>
<span class="gi">+                timeout=self.timeout,</span>
<span class="gi">+                **self.kw,</span>
<span class="gi">+            )</span>
<span class="gi">+            if r.status_code == 404:</span>
<span class="gi">+                raise FileNotFoundError(path)</span>
<span class="gi">+            r.raise_for_status()</span>
<span class="gi">+            types = {&quot;blob&quot;: &quot;file&quot;, &quot;tree&quot;: &quot;directory&quot;}</span>
<span class="gi">+            out = [</span>
<span class="gi">+                {</span>
<span class="gi">+                    &quot;name&quot;: path + &quot;/&quot; + f[&quot;path&quot;] if path else f[&quot;path&quot;],</span>
<span class="gi">+                    &quot;mode&quot;: f[&quot;mode&quot;],</span>
<span class="gi">+                    &quot;type&quot;: types[f[&quot;type&quot;]],</span>
<span class="gi">+                    &quot;size&quot;: f.get(&quot;size&quot;, 0),</span>
<span class="gi">+                    &quot;sha&quot;: f[&quot;sha&quot;],</span>
<span class="gi">+                }</span>
<span class="gi">+                for f in r.json()[&quot;tree&quot;]</span>
<span class="gi">+                if f[&quot;type&quot;] in types</span>
<span class="gi">+            ]</span>
<span class="gi">+            if sha in [self.root, None]:</span>
<span class="gi">+                self.dircache[path] = out</span>
<span class="gi">+        else:</span>
<span class="gi">+            out = self.dircache[path]</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return out</span>
<span class="gi">+        else:</span>
<span class="gi">+            return sorted([f[&quot;name&quot;] for f in out])</span>
<span class="gi">+</span>
<span class="gi">+    def invalidate_cache(self, path=None):</span>
<span class="gi">+        self.dircache.clear()</span>
<span class="gi">+</span>
<span class="gi">+    @classmethod</span>
<span class="gi">+    def _strip_protocol(cls, path):</span>
<span class="gi">+        opts = infer_storage_options(path)</span>
<span class="gi">+        if &quot;username&quot; not in opts:</span>
<span class="gi">+            return super()._strip_protocol(path)</span>
<span class="gi">+        return opts[&quot;path&quot;].lstrip(&quot;/&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _get_kwargs_from_urls(path):</span>
<span class="gi">+        opts = infer_storage_options(path)</span>
<span class="gi">+        if &quot;username&quot; not in opts:</span>
<span class="gi">+            return {}</span>
<span class="gi">+        out = {&quot;org&quot;: opts[&quot;username&quot;], &quot;repo&quot;: opts[&quot;password&quot;]}</span>
<span class="gi">+        if opts[&quot;host&quot;]:</span>
<span class="gi">+            out[&quot;sha&quot;] = opts[&quot;host&quot;]</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    def _open(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=None,</span>
<span class="gi">+        autocommit=True,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        sha=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        if mode != &quot;rb&quot;:</span>
<span class="gi">+            raise NotImplementedError</span>
<span class="gi">+        url = self.rurl.format(</span>
<span class="gi">+            org=self.org, repo=self.repo, path=path, sha=sha or self.root</span>
<span class="gi">+        )</span>
<span class="gi">+        r = requests.get(url, timeout=self.timeout, **self.kw)</span>
<span class="gi">+        if r.status_code == 404:</span>
<span class="gi">+            raise FileNotFoundError(path)</span>
<span class="gi">+        r.raise_for_status()</span>
<span class="gi">+        return MemoryFile(None, None, r.content)</span>
<span class="gi">+</span>
<span class="gi">+    def cat(self, path, recursive=False, on_error=&quot;raise&quot;, **kwargs):</span>
<span class="gi">+        paths = self.expand_path(path, recursive=recursive)</span>
<span class="gi">+        urls = [</span>
<span class="gi">+            self.rurl.format(org=self.org, repo=self.repo, path=u, sha=self.root)</span>
<span class="gi">+            for u, sh in paths</span>
<span class="gi">+        ]</span>
<span class="gi">+        fs = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+        data = fs.cat(urls, on_error=&quot;return&quot;)</span>
<span class="gi">+        return {u: v for ((k, v), u) in zip(data.items(), urls)}</span>
<span class="gh">diff --git a/fsspec/implementations/http.py b/fsspec/implementations/http.py</span>
<span class="gh">index 94a6f71..c9ab177 100644</span>
<span class="gd">--- a/fsspec/implementations/http.py</span>
<span class="gi">+++ b/fsspec/implementations/http.py</span>
<span class="gu">@@ -5,17 +5,32 @@ import re</span>
<span class="w"> </span>import weakref
<span class="w"> </span>from copy import copy
<span class="w"> </span>from urllib.parse import urlparse
<span class="gi">+</span>
<span class="w"> </span>import aiohttp
<span class="w"> </span>import yarl
<span class="gi">+</span>
<span class="w"> </span>from fsspec.asyn import AbstractAsyncStreamedFile, AsyncFileSystem, sync, sync_wrapper
<span class="w"> </span>from fsspec.callbacks import DEFAULT_CALLBACK
<span class="w"> </span>from fsspec.exceptions import FSTimeoutError
<span class="w"> </span>from fsspec.spec import AbstractBufferedFile
<span class="gd">-from fsspec.utils import DEFAULT_BLOCK_SIZE, glob_translate, isfilelike, nullcontext, tokenize</span>
<span class="gi">+from fsspec.utils import (</span>
<span class="gi">+    DEFAULT_BLOCK_SIZE,</span>
<span class="gi">+    glob_translate,</span>
<span class="gi">+    isfilelike,</span>
<span class="gi">+    nullcontext,</span>
<span class="gi">+    tokenize,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="w"> </span>from ..caching import AllBytes
<span class="gd">-ex = re.compile(&#39;&lt;(a|A)\\s+(?:[^&gt;]*?\\s+)?(href|HREF)=[&quot;\&#39;](?P&lt;url&gt;[^&quot;\&#39;]+)&#39;)</span>
<span class="gd">-ex2 = re.compile(&#39;(?P&lt;url&gt;http[s]?://[-a-zA-Z0-9@:%_+.~#?&amp;/=]+)&#39;)</span>
<span class="gd">-logger = logging.getLogger(&#39;fsspec.http&#39;)</span>
<span class="gi">+</span>
<span class="gi">+# https://stackoverflow.com/a/15926317/3821154</span>
<span class="gi">+ex = re.compile(r&quot;&quot;&quot;&lt;(a|A)\s+(?:[^&gt;]*?\s+)?(href|HREF)=[&quot;&#39;](?P&lt;url&gt;[^&quot;&#39;]+)&quot;&quot;&quot;)</span>
<span class="gi">+ex2 = re.compile(r&quot;&quot;&quot;(?P&lt;url&gt;http[s]?://[-a-zA-Z0-9@:%_+.~#?&amp;/=]+)&quot;&quot;&quot;)</span>
<span class="gi">+logger = logging.getLogger(&quot;fsspec.http&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+async def get_client(**kwargs):</span>
<span class="gi">+    return aiohttp.ClientSession(**kwargs)</span>


<span class="w"> </span>class HTTPFileSystem(AsyncFileSystem):
<span class="gu">@@ -27,12 +42,24 @@ class HTTPFileSystem(AsyncFileSystem):</span>
<span class="w"> </span>    &quot;http(s)://server.com/stuff?thing=other&quot;; otherwise only links within
<span class="w"> </span>    HTML href tags will be used.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    sep = &#39;/&#39;</span>

<span class="gd">-    def __init__(self, simple_links=True, block_size=None, same_scheme=True,</span>
<span class="gd">-        size_policy=None, cache_type=&#39;bytes&#39;, cache_options=None,</span>
<span class="gd">-        asynchronous=False, loop=None, client_kwargs=None, get_client=</span>
<span class="gd">-        get_client, encoded=False, **storage_options):</span>
<span class="gi">+    sep = &quot;/&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        simple_links=True,</span>
<span class="gi">+        block_size=None,</span>
<span class="gi">+        same_scheme=True,</span>
<span class="gi">+        size_policy=None,</span>
<span class="gi">+        cache_type=&quot;bytes&quot;,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        asynchronous=False,</span>
<span class="gi">+        loop=None,</span>
<span class="gi">+        client_kwargs=None,</span>
<span class="gi">+        get_client=get_client,</span>
<span class="gi">+        encoded=False,</span>
<span class="gi">+        **storage_options,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        NB: if this is called async, you must await set_client

<span class="gu">@@ -60,10 +87,8 @@ class HTTPFileSystem(AsyncFileSystem):</span>
<span class="w"> </span>            Any other parameters passed on to requests
<span class="w"> </span>        cache_type, cache_options: defaults used in open
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        super().__init__(self, asynchronous=asynchronous, loop=loop, **</span>
<span class="gd">-            storage_options)</span>
<span class="gd">-        self.block_size = (block_size if block_size is not None else</span>
<span class="gd">-            DEFAULT_BLOCK_SIZE)</span>
<span class="gi">+        super().__init__(self, asynchronous=asynchronous, loop=loop, **storage_options)</span>
<span class="gi">+        self.block_size = block_size if block_size is not None else DEFAULT_BLOCK_SIZE</span>
<span class="w"> </span>        self.simple_links = simple_links
<span class="w"> </span>        self.same_schema = same_scheme
<span class="w"> </span>        self.cache_type = cache_type
<span class="gu">@@ -73,28 +98,246 @@ class HTTPFileSystem(AsyncFileSystem):</span>
<span class="w"> </span>        self.encoded = encoded
<span class="w"> </span>        self.kwargs = storage_options
<span class="w"> </span>        self._session = None
<span class="gi">+</span>
<span class="gi">+        # Clean caching-related parameters from `storage_options`</span>
<span class="gi">+        # before propagating them as `request_options` through `self.kwargs`.</span>
<span class="gi">+        # TODO: Maybe rename `self.kwargs` to `self.request_options` to make</span>
<span class="gi">+        #       it clearer.</span>
<span class="w"> </span>        request_options = copy(storage_options)
<span class="gd">-        self.use_listings_cache = request_options.pop(&#39;use_listings_cache&#39;,</span>
<span class="gd">-            False)</span>
<span class="gd">-        request_options.pop(&#39;listings_expiry_time&#39;, None)</span>
<span class="gd">-        request_options.pop(&#39;max_paths&#39;, None)</span>
<span class="gd">-        request_options.pop(&#39;skip_instance_cache&#39;, None)</span>
<span class="gi">+        self.use_listings_cache = request_options.pop(&quot;use_listings_cache&quot;, False)</span>
<span class="gi">+        request_options.pop(&quot;listings_expiry_time&quot;, None)</span>
<span class="gi">+        request_options.pop(&quot;max_paths&quot;, None)</span>
<span class="gi">+        request_options.pop(&quot;skip_instance_cache&quot;, None)</span>
<span class="w"> </span>        self.kwargs = request_options

<span class="gi">+    @property</span>
<span class="gi">+    def fsid(self):</span>
<span class="gi">+        return &quot;http&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def encode_url(self, url):</span>
<span class="gi">+        return yarl.URL(url, encoded=self.encoded)</span>
<span class="gi">+</span>
<span class="gi">+    @staticmethod</span>
<span class="gi">+    def close_session(loop, session):</span>
<span class="gi">+        if loop is not None and loop.is_running():</span>
<span class="gi">+            try:</span>
<span class="gi">+                sync(loop, session.close, timeout=0.1)</span>
<span class="gi">+                return</span>
<span class="gi">+            except (TimeoutError, FSTimeoutError, NotImplementedError):</span>
<span class="gi">+                pass</span>
<span class="gi">+        connector = getattr(session, &quot;_connector&quot;, None)</span>
<span class="gi">+        if connector is not None:</span>
<span class="gi">+            # close after loop is dead</span>
<span class="gi">+            connector._close()</span>
<span class="gi">+</span>
<span class="gi">+    async def set_session(self):</span>
<span class="gi">+        if self._session is None:</span>
<span class="gi">+            self._session = await self.get_client(loop=self.loop, **self.client_kwargs)</span>
<span class="gi">+            if not self.asynchronous:</span>
<span class="gi">+                weakref.finalize(self, self.close_session, self.loop, self._session)</span>
<span class="gi">+        return self._session</span>
<span class="gi">+</span>
<span class="w"> </span>    @classmethod
<span class="w"> </span>    def _strip_protocol(cls, path):
<span class="w"> </span>        &quot;&quot;&quot;For HTTP, we always want to keep the full URL&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return path</span>
<span class="gi">+</span>
<span class="gi">+    @classmethod</span>
<span class="gi">+    def _parent(cls, path):</span>
<span class="gi">+        # override, since _strip_protocol is different for URLs</span>
<span class="gi">+        par = super()._parent(path)</span>
<span class="gi">+        if len(par) &gt; 7:  # &quot;http://...&quot;</span>
<span class="gi">+            return par</span>
<span class="gi">+        return &quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+    async def _ls_real(self, url, detail=True, **kwargs):</span>
<span class="gi">+        # ignoring URL-encoded arguments</span>
<span class="gi">+        kw = self.kwargs.copy()</span>
<span class="gi">+        kw.update(kwargs)</span>
<span class="gi">+        logger.debug(url)</span>
<span class="gi">+        session = await self.set_session()</span>
<span class="gi">+        async with session.get(self.encode_url(url), **self.kwargs) as r:</span>
<span class="gi">+            self._raise_not_found_for_status(r, url)</span>
<span class="gi">+            try:</span>
<span class="gi">+                text = await r.text()</span>
<span class="gi">+                if self.simple_links:</span>
<span class="gi">+                    links = ex2.findall(text) + [u[2] for u in ex.findall(text)]</span>
<span class="gi">+                else:</span>
<span class="gi">+                    links = [u[2] for u in ex.findall(text)]</span>
<span class="gi">+            except UnicodeDecodeError:</span>
<span class="gi">+                links = []  # binary, not HTML</span>
<span class="gi">+        out = set()</span>
<span class="gi">+        parts = urlparse(url)</span>
<span class="gi">+        for l in links:</span>
<span class="gi">+            if isinstance(l, tuple):</span>
<span class="gi">+                l = l[1]</span>
<span class="gi">+            if l.startswith(&quot;/&quot;) and len(l) &gt; 1:</span>
<span class="gi">+                # absolute URL on this server</span>
<span class="gi">+                l = f&quot;{parts.scheme}://{parts.netloc}{l}&quot;</span>
<span class="gi">+            if l.startswith(&quot;http&quot;):</span>
<span class="gi">+                if self.same_schema and l.startswith(url.rstrip(&quot;/&quot;) + &quot;/&quot;):</span>
<span class="gi">+                    out.add(l)</span>
<span class="gi">+                elif l.replace(&quot;https&quot;, &quot;http&quot;).startswith(</span>
<span class="gi">+                    url.replace(&quot;https&quot;, &quot;http&quot;).rstrip(&quot;/&quot;) + &quot;/&quot;</span>
<span class="gi">+                ):</span>
<span class="gi">+                    # allowed to cross http &lt;-&gt; https</span>
<span class="gi">+                    out.add(l)</span>
<span class="gi">+            else:</span>
<span class="gi">+                if l not in [&quot;..&quot;, &quot;../&quot;]:</span>
<span class="gi">+                    # Ignore FTP-like &quot;parent&quot;</span>
<span class="gi">+                    out.add(&quot;/&quot;.join([url.rstrip(&quot;/&quot;), l.lstrip(&quot;/&quot;)]))</span>
<span class="gi">+        if not out and url.endswith(&quot;/&quot;):</span>
<span class="gi">+            out = await self._ls_real(url.rstrip(&quot;/&quot;), detail=False)</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return [</span>
<span class="gi">+                {</span>
<span class="gi">+                    &quot;name&quot;: u,</span>
<span class="gi">+                    &quot;size&quot;: None,</span>
<span class="gi">+                    &quot;type&quot;: &quot;directory&quot; if u.endswith(&quot;/&quot;) else &quot;file&quot;,</span>
<span class="gi">+                }</span>
<span class="gi">+                for u in out</span>
<span class="gi">+            ]</span>
<span class="gi">+        else:</span>
<span class="gi">+            return sorted(out)</span>
<span class="gi">+</span>
<span class="gi">+    async def _ls(self, url, detail=True, **kwargs):</span>
<span class="gi">+        if self.use_listings_cache and url in self.dircache:</span>
<span class="gi">+            out = self.dircache[url]</span>
<span class="gi">+        else:</span>
<span class="gi">+            out = await self._ls_real(url, detail=detail, **kwargs)</span>
<span class="gi">+            self.dircache[url] = out</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="w"> </span>    ls = sync_wrapper(_ls)

<span class="w"> </span>    def _raise_not_found_for_status(self, response, url):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Raises FileNotFoundError for 404s, otherwise uses raise_for_status.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def _open(self, path, mode=&#39;rb&#39;, block_size=None, autocommit=None,</span>
<span class="gd">-        cache_type=None, cache_options=None, size=None, **kwargs):</span>
<span class="gi">+        if response.status == 404:</span>
<span class="gi">+            raise FileNotFoundError(url)</span>
<span class="gi">+        response.raise_for_status()</span>
<span class="gi">+</span>
<span class="gi">+    async def _cat_file(self, url, start=None, end=None, **kwargs):</span>
<span class="gi">+        kw = self.kwargs.copy()</span>
<span class="gi">+        kw.update(kwargs)</span>
<span class="gi">+        logger.debug(url)</span>
<span class="gi">+</span>
<span class="gi">+        if start is not None or end is not None:</span>
<span class="gi">+            if start == end:</span>
<span class="gi">+                return b&quot;&quot;</span>
<span class="gi">+            headers = kw.pop(&quot;headers&quot;, {}).copy()</span>
<span class="gi">+</span>
<span class="gi">+            headers[&quot;Range&quot;] = await self._process_limits(url, start, end)</span>
<span class="gi">+            kw[&quot;headers&quot;] = headers</span>
<span class="gi">+        session = await self.set_session()</span>
<span class="gi">+        async with session.get(self.encode_url(url), **kw) as r:</span>
<span class="gi">+            out = await r.read()</span>
<span class="gi">+            self._raise_not_found_for_status(r, url)</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    async def _get_file(</span>
<span class="gi">+        self, rpath, lpath, chunk_size=5 * 2**20, callback=DEFAULT_CALLBACK, **kwargs</span>
<span class="gi">+    ):</span>
<span class="gi">+        kw = self.kwargs.copy()</span>
<span class="gi">+        kw.update(kwargs)</span>
<span class="gi">+        logger.debug(rpath)</span>
<span class="gi">+        session = await self.set_session()</span>
<span class="gi">+        async with session.get(self.encode_url(rpath), **kw) as r:</span>
<span class="gi">+            try:</span>
<span class="gi">+                size = int(r.headers[&quot;content-length&quot;])</span>
<span class="gi">+            except (ValueError, KeyError):</span>
<span class="gi">+                size = None</span>
<span class="gi">+</span>
<span class="gi">+            callback.set_size(size)</span>
<span class="gi">+            self._raise_not_found_for_status(r, rpath)</span>
<span class="gi">+            if isfilelike(lpath):</span>
<span class="gi">+                outfile = lpath</span>
<span class="gi">+            else:</span>
<span class="gi">+                outfile = open(lpath, &quot;wb&quot;)  # noqa: ASYNC101</span>
<span class="gi">+</span>
<span class="gi">+            try:</span>
<span class="gi">+                chunk = True</span>
<span class="gi">+                while chunk:</span>
<span class="gi">+                    chunk = await r.content.read(chunk_size)</span>
<span class="gi">+                    outfile.write(chunk)</span>
<span class="gi">+                    callback.relative_update(len(chunk))</span>
<span class="gi">+            finally:</span>
<span class="gi">+                if not isfilelike(lpath):</span>
<span class="gi">+                    outfile.close()</span>
<span class="gi">+</span>
<span class="gi">+    async def _put_file(</span>
<span class="gi">+        self,</span>
<span class="gi">+        lpath,</span>
<span class="gi">+        rpath,</span>
<span class="gi">+        chunk_size=5 * 2**20,</span>
<span class="gi">+        callback=DEFAULT_CALLBACK,</span>
<span class="gi">+        method=&quot;post&quot;,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        async def gen_chunks():</span>
<span class="gi">+            # Support passing arbitrary file-like objects</span>
<span class="gi">+            # and use them instead of streams.</span>
<span class="gi">+            if isinstance(lpath, io.IOBase):</span>
<span class="gi">+                context = nullcontext(lpath)</span>
<span class="gi">+                use_seek = False  # might not support seeking</span>
<span class="gi">+            else:</span>
<span class="gi">+                context = open(lpath, &quot;rb&quot;)  # noqa: ASYNC101</span>
<span class="gi">+                use_seek = True</span>
<span class="gi">+</span>
<span class="gi">+            with context as f:</span>
<span class="gi">+                if use_seek:</span>
<span class="gi">+                    callback.set_size(f.seek(0, 2))</span>
<span class="gi">+                    f.seek(0)</span>
<span class="gi">+                else:</span>
<span class="gi">+                    callback.set_size(getattr(f, &quot;size&quot;, None))</span>
<span class="gi">+</span>
<span class="gi">+                chunk = f.read(chunk_size)</span>
<span class="gi">+                while chunk:</span>
<span class="gi">+                    yield chunk</span>
<span class="gi">+                    callback.relative_update(len(chunk))</span>
<span class="gi">+                    chunk = f.read(chunk_size)</span>
<span class="gi">+</span>
<span class="gi">+        kw = self.kwargs.copy()</span>
<span class="gi">+        kw.update(kwargs)</span>
<span class="gi">+        session = await self.set_session()</span>
<span class="gi">+</span>
<span class="gi">+        method = method.lower()</span>
<span class="gi">+        if method not in (&quot;post&quot;, &quot;put&quot;):</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                f&quot;method has to be either &#39;post&#39; or &#39;put&#39;, not: {method!r}&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        meth = getattr(session, method)</span>
<span class="gi">+        async with meth(self.encode_url(rpath), data=gen_chunks(), **kw) as resp:</span>
<span class="gi">+            self._raise_not_found_for_status(resp, rpath)</span>
<span class="gi">+</span>
<span class="gi">+    async def _exists(self, path, **kwargs):</span>
<span class="gi">+        kw = self.kwargs.copy()</span>
<span class="gi">+        kw.update(kwargs)</span>
<span class="gi">+        try:</span>
<span class="gi">+            logger.debug(path)</span>
<span class="gi">+            session = await self.set_session()</span>
<span class="gi">+            r = await session.get(self.encode_url(path), **kw)</span>
<span class="gi">+            async with r:</span>
<span class="gi">+                return r.status &lt; 400</span>
<span class="gi">+        except aiohttp.ClientError:</span>
<span class="gi">+            return False</span>
<span class="gi">+</span>
<span class="gi">+    async def _isfile(self, path, **kwargs):</span>
<span class="gi">+        return await self._exists(path, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def _open(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=None,</span>
<span class="gi">+        autocommit=None,  # XXX: This differs from the base class.</span>
<span class="gi">+        cache_type=None,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        size=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Make a file-like object

<span class="w"> </span>        Parameters
<span class="gu">@@ -109,11 +352,56 @@ class HTTPFileSystem(AsyncFileSystem):</span>
<span class="w"> </span>        kwargs: key-value
<span class="w"> </span>            Any other parameters, passed to requests calls
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if mode != &quot;rb&quot;:</span>
<span class="gi">+            raise NotImplementedError</span>
<span class="gi">+        block_size = block_size if block_size is not None else self.block_size</span>
<span class="gi">+        kw = self.kwargs.copy()</span>
<span class="gi">+        kw[&quot;asynchronous&quot;] = self.asynchronous</span>
<span class="gi">+        kw.update(kwargs)</span>
<span class="gi">+        size = size or self.info(path, **kwargs)[&quot;size&quot;]</span>
<span class="gi">+        session = sync(self.loop, self.set_session)</span>
<span class="gi">+        if block_size and size:</span>
<span class="gi">+            return HTTPFile(</span>
<span class="gi">+                self,</span>
<span class="gi">+                path,</span>
<span class="gi">+                session=session,</span>
<span class="gi">+                block_size=block_size,</span>
<span class="gi">+                mode=mode,</span>
<span class="gi">+                size=size,</span>
<span class="gi">+                cache_type=cache_type or self.cache_type,</span>
<span class="gi">+                cache_options=cache_options or self.cache_options,</span>
<span class="gi">+                loop=self.loop,</span>
<span class="gi">+                **kw,</span>
<span class="gi">+            )</span>
<span class="gi">+        else:</span>
<span class="gi">+            return HTTPStreamFile(</span>
<span class="gi">+                self,</span>
<span class="gi">+                path,</span>
<span class="gi">+                mode=mode,</span>
<span class="gi">+                loop=self.loop,</span>
<span class="gi">+                session=session,</span>
<span class="gi">+                **kw,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    async def open_async(self, path, mode=&quot;rb&quot;, size=None, **kwargs):</span>
<span class="gi">+        session = await self.set_session()</span>
<span class="gi">+        if size is None:</span>
<span class="gi">+            try:</span>
<span class="gi">+                size = (await self._info(path, **kwargs))[&quot;size&quot;]</span>
<span class="gi">+            except FileNotFoundError:</span>
<span class="gi">+                pass</span>
<span class="gi">+        return AsyncStreamFile(</span>
<span class="gi">+            self,</span>
<span class="gi">+            path,</span>
<span class="gi">+            loop=self.loop,</span>
<span class="gi">+            session=session,</span>
<span class="gi">+            size=size,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def ukey(self, url):
<span class="w"> </span>        &quot;&quot;&quot;Unique identifier; assume HTTP files are static, unchanging&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return tokenize(url, self.kwargs, self.protocol)</span>

<span class="w"> </span>    async def _info(self, url, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Get info of URL
<span class="gu">@@ -125,7 +413,29 @@ class HTTPFileSystem(AsyncFileSystem):</span>
<span class="w"> </span>        which case size will be given as None (and certain operations on the
<span class="w"> </span>        corresponding file will not work).
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        info = {}</span>
<span class="gi">+        session = await self.set_session()</span>
<span class="gi">+</span>
<span class="gi">+        for policy in [&quot;head&quot;, &quot;get&quot;]:</span>
<span class="gi">+            try:</span>
<span class="gi">+                info.update(</span>
<span class="gi">+                    await _file_info(</span>
<span class="gi">+                        self.encode_url(url),</span>
<span class="gi">+                        size_policy=policy,</span>
<span class="gi">+                        session=session,</span>
<span class="gi">+                        **self.kwargs,</span>
<span class="gi">+                        **kwargs,</span>
<span class="gi">+                    )</span>
<span class="gi">+                )</span>
<span class="gi">+                if info.get(&quot;size&quot;) is not None:</span>
<span class="gi">+                    break</span>
<span class="gi">+            except Exception as exc:</span>
<span class="gi">+                if policy == &quot;get&quot;:</span>
<span class="gi">+                    # If get failed, then raise a FileNotFoundError</span>
<span class="gi">+                    raise FileNotFoundError(url) from exc</span>
<span class="gi">+                logger.debug(&quot;&quot;, exc_info=exc)</span>
<span class="gi">+</span>
<span class="gi">+        return {&quot;name&quot;: url, &quot;size&quot;: None, **info, &quot;type&quot;: &quot;file&quot;}</span>

<span class="w"> </span>    async def _glob(self, path, maxdepth=None, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -135,7 +445,77 @@ class HTTPFileSystem(AsyncFileSystem):</span>
<span class="w"> </span>        but &quot;?&quot; is not considered as a character for globbing, because it is
<span class="w"> </span>        so common in URLs, often identifying the &quot;query&quot; part.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if maxdepth is not None and maxdepth &lt; 1:</span>
<span class="gi">+            raise ValueError(&quot;maxdepth must be at least 1&quot;)</span>
<span class="gi">+        import re</span>
<span class="gi">+</span>
<span class="gi">+        ends_with_slash = path.endswith(&quot;/&quot;)  # _strip_protocol strips trailing slash</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        append_slash_to_dirname = ends_with_slash or path.endswith((&quot;/**&quot;, &quot;/*&quot;))</span>
<span class="gi">+        idx_star = path.find(&quot;*&quot;) if path.find(&quot;*&quot;) &gt;= 0 else len(path)</span>
<span class="gi">+        idx_brace = path.find(&quot;[&quot;) if path.find(&quot;[&quot;) &gt;= 0 else len(path)</span>
<span class="gi">+</span>
<span class="gi">+        min_idx = min(idx_star, idx_brace)</span>
<span class="gi">+</span>
<span class="gi">+        detail = kwargs.pop(&quot;detail&quot;, False)</span>
<span class="gi">+</span>
<span class="gi">+        if not has_magic(path):</span>
<span class="gi">+            if await self._exists(path, **kwargs):</span>
<span class="gi">+                if not detail:</span>
<span class="gi">+                    return [path]</span>
<span class="gi">+                else:</span>
<span class="gi">+                    return {path: await self._info(path, **kwargs)}</span>
<span class="gi">+            else:</span>
<span class="gi">+                if not detail:</span>
<span class="gi">+                    return []  # glob of non-existent returns empty</span>
<span class="gi">+                else:</span>
<span class="gi">+                    return {}</span>
<span class="gi">+        elif &quot;/&quot; in path[:min_idx]:</span>
<span class="gi">+            min_idx = path[:min_idx].rindex(&quot;/&quot;)</span>
<span class="gi">+            root = path[: min_idx + 1]</span>
<span class="gi">+            depth = path[min_idx + 1 :].count(&quot;/&quot;) + 1</span>
<span class="gi">+        else:</span>
<span class="gi">+            root = &quot;&quot;</span>
<span class="gi">+            depth = path[min_idx + 1 :].count(&quot;/&quot;) + 1</span>
<span class="gi">+</span>
<span class="gi">+        if &quot;**&quot; in path:</span>
<span class="gi">+            if maxdepth is not None:</span>
<span class="gi">+                idx_double_stars = path.find(&quot;**&quot;)</span>
<span class="gi">+                depth_double_stars = path[idx_double_stars:].count(&quot;/&quot;) + 1</span>
<span class="gi">+                depth = depth - depth_double_stars + maxdepth</span>
<span class="gi">+            else:</span>
<span class="gi">+                depth = None</span>
<span class="gi">+</span>
<span class="gi">+        allpaths = await self._find(</span>
<span class="gi">+            root, maxdepth=depth, withdirs=True, detail=True, **kwargs</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        pattern = glob_translate(path + (&quot;/&quot; if ends_with_slash else &quot;&quot;))</span>
<span class="gi">+        pattern = re.compile(pattern)</span>
<span class="gi">+</span>
<span class="gi">+        out = {</span>
<span class="gi">+            (</span>
<span class="gi">+                p.rstrip(&quot;/&quot;)</span>
<span class="gi">+                if not append_slash_to_dirname</span>
<span class="gi">+                and info[&quot;type&quot;] == &quot;directory&quot;</span>
<span class="gi">+                and p.endswith(&quot;/&quot;)</span>
<span class="gi">+                else p</span>
<span class="gi">+            ): info</span>
<span class="gi">+            for p, info in sorted(allpaths.items())</span>
<span class="gi">+            if pattern.match(p.rstrip(&quot;/&quot;))</span>
<span class="gi">+        }</span>
<span class="gi">+</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return out</span>
<span class="gi">+        else:</span>
<span class="gi">+            return list(out)</span>
<span class="gi">+</span>
<span class="gi">+    async def _isdir(self, path):</span>
<span class="gi">+        # override, since all URLs are (also) files</span>
<span class="gi">+        try:</span>
<span class="gi">+            return bool(await self._ls(path))</span>
<span class="gi">+        except (FileNotFoundError, ValueError):</span>
<span class="gi">+            return False</span>


<span class="w"> </span>class HTTPFile(AbstractBufferedFile):
<span class="gu">@@ -163,18 +543,36 @@ class HTTPFile(AbstractBufferedFile):</span>
<span class="w"> </span>    kwargs: all other key-values are passed to requests calls.
<span class="w"> </span>    &quot;&quot;&quot;

<span class="gd">-    def __init__(self, fs, url, session=None, block_size=None, mode=&#39;rb&#39;,</span>
<span class="gd">-        cache_type=&#39;bytes&#39;, cache_options=None, size=None, loop=None,</span>
<span class="gd">-        asynchronous=False, **kwargs):</span>
<span class="gd">-        if mode != &#39;rb&#39;:</span>
<span class="gd">-            raise NotImplementedError(&#39;File mode not supported&#39;)</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        fs,</span>
<span class="gi">+        url,</span>
<span class="gi">+        session=None,</span>
<span class="gi">+        block_size=None,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        cache_type=&quot;bytes&quot;,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        size=None,</span>
<span class="gi">+        loop=None,</span>
<span class="gi">+        asynchronous=False,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        if mode != &quot;rb&quot;:</span>
<span class="gi">+            raise NotImplementedError(&quot;File mode not supported&quot;)</span>
<span class="w"> </span>        self.asynchronous = asynchronous
<span class="w"> </span>        self.loop = loop
<span class="w"> </span>        self.url = url
<span class="w"> </span>        self.session = session
<span class="gd">-        self.details = {&#39;name&#39;: url, &#39;size&#39;: size, &#39;type&#39;: &#39;file&#39;}</span>
<span class="gd">-        super().__init__(fs=fs, path=url, mode=mode, block_size=block_size,</span>
<span class="gd">-            cache_type=cache_type, cache_options=cache_options, **kwargs)</span>
<span class="gi">+        self.details = {&quot;name&quot;: url, &quot;size&quot;: size, &quot;type&quot;: &quot;file&quot;}</span>
<span class="gi">+        super().__init__(</span>
<span class="gi">+            fs=fs,</span>
<span class="gi">+            path=url,</span>
<span class="gi">+            mode=mode,</span>
<span class="gi">+            block_size=block_size,</span>
<span class="gi">+            cache_type=cache_type,</span>
<span class="gi">+            cache_options=cache_options,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def read(self, length=-1):
<span class="w"> </span>        &quot;&quot;&quot;Read bytes from file
<span class="gu">@@ -186,7 +584,18 @@ class HTTPFile(AbstractBufferedFile):</span>
<span class="w"> </span>            file. If the server has not supplied the filesize, attempting to
<span class="w"> </span>            read only part of the data will raise a ValueError.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if (</span>
<span class="gi">+            (length &lt; 0 and self.loc == 0)  # explicit read all</span>
<span class="gi">+            # but not when the size is known and fits into a block anyways</span>
<span class="gi">+            and not (self.size is not None and self.size &lt;= self.blocksize)</span>
<span class="gi">+        ):</span>
<span class="gi">+            self._fetch_all()</span>
<span class="gi">+        if self.size is None:</span>
<span class="gi">+            if length &lt; 0:</span>
<span class="gi">+                self._fetch_all()</span>
<span class="gi">+        else:</span>
<span class="gi">+            length = min(self.size - self.loc, length)</span>
<span class="gi">+        return super().read(length)</span>

<span class="w"> </span>    async def async_fetch_all(self):
<span class="w"> </span>        &quot;&quot;&quot;Read whole file in one shot, without caching
<span class="gu">@@ -194,12 +603,32 @@ class HTTPFile(AbstractBufferedFile):</span>
<span class="w"> </span>        This is only called when position is still at zero,
<span class="w"> </span>        and read() is called without a byte-count.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        logger.debug(f&quot;Fetch all for {self}&quot;)</span>
<span class="gi">+        if not isinstance(self.cache, AllBytes):</span>
<span class="gi">+            r = await self.session.get(self.fs.encode_url(self.url), **self.kwargs)</span>
<span class="gi">+            async with r:</span>
<span class="gi">+                r.raise_for_status()</span>
<span class="gi">+                out = await r.read()</span>
<span class="gi">+                self.cache = AllBytes(</span>
<span class="gi">+                    size=len(out), fetcher=None, blocksize=None, data=out</span>
<span class="gi">+                )</span>
<span class="gi">+                self.size = len(out)</span>
<span class="gi">+</span>
<span class="w"> </span>    _fetch_all = sync_wrapper(async_fetch_all)

<span class="w"> </span>    def _parse_content_range(self, headers):
<span class="w"> </span>        &quot;&quot;&quot;Parse the Content-Range header&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        s = headers.get(&quot;Content-Range&quot;, &quot;&quot;)</span>
<span class="gi">+        m = re.match(r&quot;bytes (\d+-\d+|\*)/(\d+|\*)&quot;, s)</span>
<span class="gi">+        if not m:</span>
<span class="gi">+            return None, None, None</span>
<span class="gi">+</span>
<span class="gi">+        if m[1] == &quot;*&quot;:</span>
<span class="gi">+            start = end = None</span>
<span class="gi">+        else:</span>
<span class="gi">+            start, end = [int(x) for x in m[1].split(&quot;-&quot;)]</span>
<span class="gi">+        total = None if m[2] == &quot;*&quot; else int(m[2])</span>
<span class="gi">+        return start, end, total</span>

<span class="w"> </span>    async def async_fetch_range(self, start, end):
<span class="w"> </span>        &quot;&quot;&quot;Download a block of data
<span class="gu">@@ -209,66 +638,235 @@ class HTTPFile(AbstractBufferedFile):</span>
<span class="w"> </span>        and then stream the output - if the data size is bigger than we
<span class="w"> </span>        requested, an exception is raised.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        logger.debug(f&quot;Fetch range for {self}: {start}-{end}&quot;)</span>
<span class="gi">+        kwargs = self.kwargs.copy()</span>
<span class="gi">+        headers = kwargs.pop(&quot;headers&quot;, {}).copy()</span>
<span class="gi">+        headers[&quot;Range&quot;] = f&quot;bytes={start}-{end - 1}&quot;</span>
<span class="gi">+        logger.debug(f&quot;{self.url} : {headers[&#39;Range&#39;]}&quot;)</span>
<span class="gi">+        r = await self.session.get(</span>
<span class="gi">+            self.fs.encode_url(self.url), headers=headers, **kwargs</span>
<span class="gi">+        )</span>
<span class="gi">+        async with r:</span>
<span class="gi">+            if r.status == 416:</span>
<span class="gi">+                # range request outside file</span>
<span class="gi">+                return b&quot;&quot;</span>
<span class="gi">+            r.raise_for_status()</span>
<span class="gi">+</span>
<span class="gi">+            # If the server has handled the range request, it should reply</span>
<span class="gi">+            # with status 206 (partial content). But we&#39;ll guess that a suitable</span>
<span class="gi">+            # Content-Range header or a Content-Length no more than the</span>
<span class="gi">+            # requested range also mean we have got the desired range.</span>
<span class="gi">+            response_is_range = (</span>
<span class="gi">+                r.status == 206</span>
<span class="gi">+                or self._parse_content_range(r.headers)[0] == start</span>
<span class="gi">+                or int(r.headers.get(&quot;Content-Length&quot;, end + 1)) &lt;= end - start</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            if response_is_range:</span>
<span class="gi">+                # partial content, as expected</span>
<span class="gi">+                out = await r.read()</span>
<span class="gi">+            elif start &gt; 0:</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    &quot;The HTTP server doesn&#39;t appear to support range requests. &quot;</span>
<span class="gi">+                    &quot;Only reading this file from the beginning is supported. &quot;</span>
<span class="gi">+                    &quot;Open with block_size=0 for a streaming file interface.&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+            else:</span>
<span class="gi">+                # Response is not a range, but we want the start of the file,</span>
<span class="gi">+                # so we can read the required amount anyway.</span>
<span class="gi">+                cl = 0</span>
<span class="gi">+                out = []</span>
<span class="gi">+                while True:</span>
<span class="gi">+                    chunk = await r.content.read(2**20)</span>
<span class="gi">+                    # data size unknown, let&#39;s read until we have enough</span>
<span class="gi">+                    if chunk:</span>
<span class="gi">+                        out.append(chunk)</span>
<span class="gi">+                        cl += len(chunk)</span>
<span class="gi">+                        if cl &gt; end - start:</span>
<span class="gi">+                            break</span>
<span class="gi">+                    else:</span>
<span class="gi">+                        break</span>
<span class="gi">+                out = b&quot;&quot;.join(out)[: end - start]</span>
<span class="gi">+            return out</span>
<span class="gi">+</span>
<span class="w"> </span>    _fetch_range = sync_wrapper(async_fetch_range)

<span class="w"> </span>    def __reduce__(self):
<span class="gd">-        return reopen, (self.fs, self.url, self.mode, self.blocksize, self.</span>
<span class="gd">-            cache.name if self.cache else &#39;none&#39;, self.size)</span>
<span class="gi">+        return (</span>
<span class="gi">+            reopen,</span>
<span class="gi">+            (</span>
<span class="gi">+                self.fs,</span>
<span class="gi">+                self.url,</span>
<span class="gi">+                self.mode,</span>
<span class="gi">+                self.blocksize,</span>
<span class="gi">+                self.cache.name if self.cache else &quot;none&quot;,</span>
<span class="gi">+                self.size,</span>
<span class="gi">+            ),</span>
<span class="gi">+        )</span>


<span class="gd">-magic_check = re.compile(&#39;([*[])&#39;)</span>
<span class="gi">+def reopen(fs, url, mode, blocksize, cache_type, size=None):</span>
<span class="gi">+    return fs.open(</span>
<span class="gi">+        url, mode=mode, block_size=blocksize, cache_type=cache_type, size=size</span>
<span class="gi">+    )</span>


<span class="gd">-class HTTPStreamFile(AbstractBufferedFile):</span>
<span class="gi">+magic_check = re.compile(&quot;([*[])&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def has_magic(s):</span>
<span class="gi">+    match = magic_check.search(s)</span>
<span class="gi">+    return match is not None</span>
<span class="gi">+</span>

<span class="gd">-    def __init__(self, fs, url, mode=&#39;rb&#39;, loop=None, session=None, **kwargs):</span>
<span class="gd">-        self.asynchronous = kwargs.pop(&#39;asynchronous&#39;, False)</span>
<span class="gi">+class HTTPStreamFile(AbstractBufferedFile):</span>
<span class="gi">+    def __init__(self, fs, url, mode=&quot;rb&quot;, loop=None, session=None, **kwargs):</span>
<span class="gi">+        self.asynchronous = kwargs.pop(&quot;asynchronous&quot;, False)</span>
<span class="w"> </span>        self.url = url
<span class="w"> </span>        self.loop = loop
<span class="w"> </span>        self.session = session
<span class="gd">-        if mode != &#39;rb&#39;:</span>
<span class="gi">+        if mode != &quot;rb&quot;:</span>
<span class="w"> </span>            raise ValueError
<span class="gd">-        self.details = {&#39;name&#39;: url, &#39;size&#39;: None}</span>
<span class="gd">-        super().__init__(fs=fs, path=url, mode=mode, cache_type=&#39;none&#39;, **</span>
<span class="gd">-            kwargs)</span>
<span class="gi">+        self.details = {&quot;name&quot;: url, &quot;size&quot;: None}</span>
<span class="gi">+        super().__init__(fs=fs, path=url, mode=mode, cache_type=&quot;none&quot;, **kwargs)</span>

<span class="w"> </span>        async def cor():
<span class="gd">-            r = await self.session.get(self.fs.encode_url(url), **kwargs</span>
<span class="gd">-                ).__aenter__()</span>
<span class="gi">+            r = await self.session.get(self.fs.encode_url(url), **kwargs).__aenter__()</span>
<span class="w"> </span>            self.fs._raise_not_found_for_status(r, url)
<span class="w"> </span>            return r
<span class="gi">+</span>
<span class="w"> </span>        self.r = sync(self.loop, cor)
<span class="w"> </span>        self.loop = fs.loop
<span class="gi">+</span>
<span class="gi">+    def seek(self, loc, whence=0):</span>
<span class="gi">+        if loc == 0 and whence == 1:</span>
<span class="gi">+            return</span>
<span class="gi">+        if loc == self.loc and whence == 0:</span>
<span class="gi">+            return</span>
<span class="gi">+        raise ValueError(&quot;Cannot seek streaming HTTP file&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    async def _read(self, num=-1):</span>
<span class="gi">+        out = await self.r.content.read(num)</span>
<span class="gi">+        self.loc += len(out)</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="w"> </span>    read = sync_wrapper(_read)

<span class="gi">+    async def _close(self):</span>
<span class="gi">+        self.r.close()</span>
<span class="gi">+</span>
<span class="gi">+    def close(self):</span>
<span class="gi">+        asyncio.run_coroutine_threadsafe(self._close(), self.loop)</span>
<span class="gi">+        super().close()</span>
<span class="gi">+</span>
<span class="w"> </span>    def __reduce__(self):
<span class="gd">-        return reopen, (self.fs, self.url, self.mode, self.blocksize, self.</span>
<span class="gd">-            cache.name)</span>
<span class="gi">+        return reopen, (self.fs, self.url, self.mode, self.blocksize, self.cache.name)</span>


<span class="w"> </span>class AsyncStreamFile(AbstractAsyncStreamedFile):
<span class="gd">-</span>
<span class="gd">-    def __init__(self, fs, url, mode=&#39;rb&#39;, loop=None, session=None, size=</span>
<span class="gd">-        None, **kwargs):</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self, fs, url, mode=&quot;rb&quot;, loop=None, session=None, size=None, **kwargs</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        self.url = url
<span class="w"> </span>        self.session = session
<span class="w"> </span>        self.r = None
<span class="gd">-        if mode != &#39;rb&#39;:</span>
<span class="gi">+        if mode != &quot;rb&quot;:</span>
<span class="w"> </span>            raise ValueError
<span class="gd">-        self.details = {&#39;name&#39;: url, &#39;size&#39;: None}</span>
<span class="gi">+        self.details = {&quot;name&quot;: url, &quot;size&quot;: None}</span>
<span class="w"> </span>        self.kwargs = kwargs
<span class="gd">-        super().__init__(fs=fs, path=url, mode=mode, cache_type=&#39;none&#39;)</span>
<span class="gi">+        super().__init__(fs=fs, path=url, mode=mode, cache_type=&quot;none&quot;)</span>
<span class="w"> </span>        self.size = size

<span class="gd">-</span>
<span class="gd">-async def _file_info(url, session, size_policy=&#39;head&#39;, **kwargs):</span>
<span class="gi">+    async def read(self, num=-1):</span>
<span class="gi">+        if self.r is None:</span>
<span class="gi">+            r = await self.session.get(</span>
<span class="gi">+                self.fs.encode_url(self.url), **self.kwargs</span>
<span class="gi">+            ).__aenter__()</span>
<span class="gi">+            self.fs._raise_not_found_for_status(r, self.url)</span>
<span class="gi">+            self.r = r</span>
<span class="gi">+        out = await self.r.content.read(num)</span>
<span class="gi">+        self.loc += len(out)</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    async def close(self):</span>
<span class="gi">+        if self.r is not None:</span>
<span class="gi">+            self.r.close()</span>
<span class="gi">+            self.r = None</span>
<span class="gi">+        await super().close()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+async def get_range(session, url, start, end, file=None, **kwargs):</span>
<span class="gi">+    # explicit get a range when we know it must be safe</span>
<span class="gi">+    kwargs = kwargs.copy()</span>
<span class="gi">+    headers = kwargs.pop(&quot;headers&quot;, {}).copy()</span>
<span class="gi">+    headers[&quot;Range&quot;] = f&quot;bytes={start}-{end - 1}&quot;</span>
<span class="gi">+    r = await session.get(url, headers=headers, **kwargs)</span>
<span class="gi">+    r.raise_for_status()</span>
<span class="gi">+    async with r:</span>
<span class="gi">+        out = await r.read()</span>
<span class="gi">+    if file:</span>
<span class="gi">+        with open(file, &quot;r+b&quot;) as f:  # noqa: ASYNC101</span>
<span class="gi">+            f.seek(start)</span>
<span class="gi">+            f.write(out)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+async def _file_info(url, session, size_policy=&quot;head&quot;, **kwargs):</span>
<span class="w"> </span>    &quot;&quot;&quot;Call HEAD on the server to get details about the file (size/checksum etc.)

<span class="w"> </span>    Default operation is to explicitly allow redirects and use encoding
<span class="w"> </span>    &#39;identity&#39; (no compression) to get the true size of the target.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    logger.debug(&quot;Retrieve file size for %s&quot;, url)</span>
<span class="gi">+    kwargs = kwargs.copy()</span>
<span class="gi">+    ar = kwargs.pop(&quot;allow_redirects&quot;, True)</span>
<span class="gi">+    head = kwargs.get(&quot;headers&quot;, {}).copy()</span>
<span class="gi">+    head[&quot;Accept-Encoding&quot;] = &quot;identity&quot;</span>
<span class="gi">+    kwargs[&quot;headers&quot;] = head</span>
<span class="gi">+</span>
<span class="gi">+    info = {}</span>
<span class="gi">+    if size_policy == &quot;head&quot;:</span>
<span class="gi">+        r = await session.head(url, allow_redirects=ar, **kwargs)</span>
<span class="gi">+    elif size_policy == &quot;get&quot;:</span>
<span class="gi">+        r = await session.get(url, allow_redirects=ar, **kwargs)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(f&#39;size_policy must be &quot;head&quot; or &quot;get&quot;, got {size_policy}&#39;)</span>
<span class="gi">+    async with r:</span>
<span class="gi">+        r.raise_for_status()</span>
<span class="gi">+</span>
<span class="gi">+        # TODO:</span>
<span class="gi">+        #  recognise lack of &#39;Accept-Ranges&#39;,</span>
<span class="gi">+        #                 or &#39;Accept-Ranges&#39;: &#39;none&#39; (not &#39;bytes&#39;)</span>
<span class="gi">+        #  to mean streaming only, no random access =&gt; return None</span>
<span class="gi">+        if &quot;Content-Length&quot; in r.headers:</span>
<span class="gi">+            # Some servers may choose to ignore Accept-Encoding and return</span>
<span class="gi">+            # compressed content, in which case the returned size is unreliable.</span>
<span class="gi">+            if &quot;Content-Encoding&quot; not in r.headers or r.headers[&quot;Content-Encoding&quot;] in [</span>
<span class="gi">+                &quot;identity&quot;,</span>
<span class="gi">+                &quot;&quot;,</span>
<span class="gi">+            ]:</span>
<span class="gi">+                info[&quot;size&quot;] = int(r.headers[&quot;Content-Length&quot;])</span>
<span class="gi">+        elif &quot;Content-Range&quot; in r.headers:</span>
<span class="gi">+            info[&quot;size&quot;] = int(r.headers[&quot;Content-Range&quot;].split(&quot;/&quot;)[1])</span>
<span class="gi">+</span>
<span class="gi">+        if &quot;Content-Type&quot; in r.headers:</span>
<span class="gi">+            info[&quot;mimetype&quot;] = r.headers[&quot;Content-Type&quot;].partition(&quot;;&quot;)[0]</span>
<span class="gi">+</span>
<span class="gi">+        info[&quot;url&quot;] = str(r.url)</span>
<span class="gi">+</span>
<span class="gi">+        for checksum_field in [&quot;ETag&quot;, &quot;Content-MD5&quot;, &quot;Digest&quot;]:</span>
<span class="gi">+            if r.headers.get(checksum_field):</span>
<span class="gi">+                info[checksum_field] = r.headers[checksum_field]</span>
<span class="gi">+</span>
<span class="gi">+    return info</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+async def _file_size(url, session=None, *args, **kwargs):</span>
<span class="gi">+    if session is None:</span>
<span class="gi">+        session = await get_client()</span>
<span class="gi">+    info = await _file_info(url, session=session, *args, **kwargs)</span>
<span class="gi">+    return info.get(&quot;size&quot;)</span>


<span class="w"> </span>file_size = sync_wrapper(_file_size)
<span class="gh">diff --git a/fsspec/implementations/jupyter.py b/fsspec/implementations/jupyter.py</span>
<span class="gh">index 7da1be6..2839f4c 100644</span>
<span class="gd">--- a/fsspec/implementations/jupyter.py</span>
<span class="gi">+++ b/fsspec/implementations/jupyter.py</span>
<span class="gu">@@ -1,13 +1,16 @@</span>
<span class="w"> </span>import base64
<span class="w"> </span>import io
<span class="w"> </span>import re
<span class="gi">+</span>
<span class="w"> </span>import requests
<span class="gi">+</span>
<span class="w"> </span>import fsspec


<span class="w"> </span>class JupyterFileSystem(fsspec.AbstractFileSystem):
<span class="w"> </span>    &quot;&quot;&quot;View of the files as seen by a Jupyter server (notebook or lab)&quot;&quot;&quot;
<span class="gd">-    protocol = &#39;jupyter&#39;, &#39;jlab&#39;</span>
<span class="gi">+</span>
<span class="gi">+    protocol = (&quot;jupyter&quot;, &quot;jlab&quot;)</span>

<span class="w"> </span>    def __init__(self, url, tok=None, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -21,25 +24,101 @@ class JupyterFileSystem(fsspec.AbstractFileSystem):</span>
<span class="w"> </span>            If the token is obtained separately, can be given here
<span class="w"> </span>        kwargs
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        if &#39;?&#39; in url:</span>
<span class="gi">+        if &quot;?&quot; in url:</span>
<span class="w"> </span>            if tok is None:
<span class="w"> </span>                try:
<span class="gd">-                    tok = re.findall(&#39;token=([a-z0-9]+)&#39;, url)[0]</span>
<span class="gi">+                    tok = re.findall(&quot;token=([a-z0-9]+)&quot;, url)[0]</span>
<span class="w"> </span>                except IndexError as e:
<span class="gd">-                    raise ValueError(&#39;Could not determine token&#39;) from e</span>
<span class="gd">-            url = url.split(&#39;?&#39;, 1)[0]</span>
<span class="gd">-        self.url = url.rstrip(&#39;/&#39;) + &#39;/api/contents&#39;</span>
<span class="gi">+                    raise ValueError(&quot;Could not determine token&quot;) from e</span>
<span class="gi">+            url = url.split(&quot;?&quot;, 1)[0]</span>
<span class="gi">+        self.url = url.rstrip(&quot;/&quot;) + &quot;/api/contents&quot;</span>
<span class="w"> </span>        self.session = requests.Session()
<span class="w"> </span>        if tok:
<span class="gd">-            self.session.headers[&#39;Authorization&#39;] = f&#39;token {tok}&#39;</span>
<span class="gi">+            self.session.headers[&quot;Authorization&quot;] = f&quot;token {tok}&quot;</span>
<span class="gi">+</span>
<span class="w"> </span>        super().__init__(**kwargs)

<span class="gi">+    def ls(self, path, detail=True, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        r = self.session.get(f&quot;{self.url}/{path}&quot;)</span>
<span class="gi">+        if r.status_code == 404:</span>
<span class="gi">+            return FileNotFoundError(path)</span>
<span class="gi">+        r.raise_for_status()</span>
<span class="gi">+        out = r.json()</span>

<span class="gd">-class SimpleFileWriter(fsspec.spec.AbstractBufferedFile):</span>
<span class="gi">+        if out[&quot;type&quot;] == &quot;directory&quot;:</span>
<span class="gi">+            out = out[&quot;content&quot;]</span>
<span class="gi">+        else:</span>
<span class="gi">+            out = [out]</span>
<span class="gi">+        for o in out:</span>
<span class="gi">+            o[&quot;name&quot;] = o.pop(&quot;path&quot;)</span>
<span class="gi">+            o.pop(&quot;content&quot;)</span>
<span class="gi">+            if o[&quot;type&quot;] == &quot;notebook&quot;:</span>
<span class="gi">+                o[&quot;type&quot;] = &quot;file&quot;</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return out</span>
<span class="gi">+        return [o[&quot;name&quot;] for o in out]</span>
<span class="gi">+</span>
<span class="gi">+    def cat_file(self, path, start=None, end=None, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        r = self.session.get(f&quot;{self.url}/{path}&quot;)</span>
<span class="gi">+        if r.status_code == 404:</span>
<span class="gi">+            return FileNotFoundError(path)</span>
<span class="gi">+        r.raise_for_status()</span>
<span class="gi">+        out = r.json()</span>
<span class="gi">+        if out[&quot;format&quot;] == &quot;text&quot;:</span>
<span class="gi">+            # data should be binary</span>
<span class="gi">+            b = out[&quot;content&quot;].encode()</span>
<span class="gi">+        else:</span>
<span class="gi">+            b = base64.b64decode(out[&quot;content&quot;])</span>
<span class="gi">+        return b[start:end]</span>

<span class="gi">+    def pipe_file(self, path, value, **_):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        json = {</span>
<span class="gi">+            &quot;name&quot;: path.rsplit(&quot;/&quot;, 1)[-1],</span>
<span class="gi">+            &quot;path&quot;: path,</span>
<span class="gi">+            &quot;size&quot;: len(value),</span>
<span class="gi">+            &quot;content&quot;: base64.b64encode(value).decode(),</span>
<span class="gi">+            &quot;format&quot;: &quot;base64&quot;,</span>
<span class="gi">+            &quot;type&quot;: &quot;file&quot;,</span>
<span class="gi">+        }</span>
<span class="gi">+        self.session.put(f&quot;{self.url}/{path}&quot;, json=json)</span>
<span class="gi">+</span>
<span class="gi">+    def mkdir(self, path, create_parents=True, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if create_parents and &quot;/&quot; in path:</span>
<span class="gi">+            self.mkdir(path.rsplit(&quot;/&quot;, 1)[0], True)</span>
<span class="gi">+        json = {</span>
<span class="gi">+            &quot;name&quot;: path.rsplit(&quot;/&quot;, 1)[-1],</span>
<span class="gi">+            &quot;path&quot;: path,</span>
<span class="gi">+            &quot;size&quot;: None,</span>
<span class="gi">+            &quot;content&quot;: None,</span>
<span class="gi">+            &quot;type&quot;: &quot;directory&quot;,</span>
<span class="gi">+        }</span>
<span class="gi">+        self.session.put(f&quot;{self.url}/{path}&quot;, json=json)</span>
<span class="gi">+</span>
<span class="gi">+    def _rm(self, path):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        self.session.delete(f&quot;{self.url}/{path}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def _open(self, path, mode=&quot;rb&quot;, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if mode == &quot;rb&quot;:</span>
<span class="gi">+            data = self.cat_file(path)</span>
<span class="gi">+            return io.BytesIO(data)</span>
<span class="gi">+        else:</span>
<span class="gi">+            return SimpleFileWriter(self, path, mode=&quot;wb&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+class SimpleFileWriter(fsspec.spec.AbstractBufferedFile):</span>
<span class="w"> </span>    def _upload_chunk(self, final=False):
<span class="w"> </span>        &quot;&quot;&quot;Never uploads a chunk until file is done

<span class="w"> </span>        Not suitable for large files
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if final is False:</span>
<span class="gi">+            return False</span>
<span class="gi">+        self.buffer.seek(0)</span>
<span class="gi">+        data = self.buffer.read()</span>
<span class="gi">+        self.fs.pipe_file(self.path, data)</span>
<span class="gh">diff --git a/fsspec/implementations/libarchive.py b/fsspec/implementations/libarchive.py</span>
<span class="gh">index c2101dc..eb6f145 100644</span>
<span class="gd">--- a/fsspec/implementations/libarchive.py</span>
<span class="gi">+++ b/fsspec/implementations/libarchive.py</span>
<span class="gu">@@ -1,25 +1,72 @@</span>
<span class="w"> </span>from contextlib import contextmanager
<span class="gd">-from ctypes import CFUNCTYPE, POINTER, c_int, c_longlong, c_void_p, cast, create_string_buffer</span>
<span class="gi">+from ctypes import (</span>
<span class="gi">+    CFUNCTYPE,</span>
<span class="gi">+    POINTER,</span>
<span class="gi">+    c_int,</span>
<span class="gi">+    c_longlong,</span>
<span class="gi">+    c_void_p,</span>
<span class="gi">+    cast,</span>
<span class="gi">+    create_string_buffer,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="w"> </span>import libarchive
<span class="w"> </span>import libarchive.ffi as ffi
<span class="gi">+</span>
<span class="w"> </span>from fsspec import open_files
<span class="w"> </span>from fsspec.archive import AbstractArchiveFileSystem
<span class="w"> </span>from fsspec.implementations.memory import MemoryFile
<span class="w"> </span>from fsspec.utils import DEFAULT_BLOCK_SIZE
<span class="gi">+</span>
<span class="gi">+# Libarchive requires seekable files or memory only for certain archive</span>
<span class="gi">+# types. However, since we read the directory first to cache the contents</span>
<span class="gi">+# and also allow random access to any file, the file-like object needs</span>
<span class="gi">+# to be seekable no matter what.</span>
<span class="gi">+</span>
<span class="gi">+# Seek call-backs (not provided in the libarchive python wrapper)</span>
<span class="w"> </span>SEEK_CALLBACK = CFUNCTYPE(c_longlong, c_int, c_void_p, c_longlong, c_int)
<span class="gd">-read_set_seek_callback = ffi.ffi(&#39;read_set_seek_callback&#39;, [ffi.c_archive_p,</span>
<span class="gd">-    SEEK_CALLBACK], c_int, ffi.check_int)</span>
<span class="gd">-new_api = hasattr(ffi, &#39;NO_OPEN_CB&#39;)</span>
<span class="gi">+read_set_seek_callback = ffi.ffi(</span>
<span class="gi">+    &quot;read_set_seek_callback&quot;, [ffi.c_archive_p, SEEK_CALLBACK], c_int, ffi.check_int</span>
<span class="gi">+)</span>
<span class="gi">+new_api = hasattr(ffi, &quot;NO_OPEN_CB&quot;)</span>


<span class="w"> </span>@contextmanager
<span class="gd">-def custom_reader(file, format_name=&#39;all&#39;, filter_name=&#39;all&#39;, block_size=</span>
<span class="gd">-    ffi.page_size):</span>
<span class="gi">+def custom_reader(file, format_name=&quot;all&quot;, filter_name=&quot;all&quot;, block_size=ffi.page_size):</span>
<span class="w"> </span>    &quot;&quot;&quot;Read an archive from a seekable file-like object.

<span class="w"> </span>    The `file` object must support the standard `readinto` and &#39;seek&#39; methods.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    buf = create_string_buffer(block_size)</span>
<span class="gi">+    buf_p = cast(buf, c_void_p)</span>
<span class="gi">+</span>
<span class="gi">+    def read_func(archive_p, context, ptrptr):</span>
<span class="gi">+        # readinto the buffer, returns number of bytes read</span>
<span class="gi">+        length = file.readinto(buf)</span>
<span class="gi">+        # write the address of the buffer into the pointer</span>
<span class="gi">+        ptrptr = cast(ptrptr, POINTER(c_void_p))</span>
<span class="gi">+        ptrptr[0] = buf_p</span>
<span class="gi">+        # tell libarchive how much data was written into the buffer</span>
<span class="gi">+        return length</span>
<span class="gi">+</span>
<span class="gi">+    def seek_func(archive_p, context, offset, whence):</span>
<span class="gi">+        file.seek(offset, whence)</span>
<span class="gi">+        # tell libarchvie the current position</span>
<span class="gi">+        return file.tell()</span>
<span class="gi">+</span>
<span class="gi">+    read_cb = ffi.READ_CALLBACK(read_func)</span>
<span class="gi">+    seek_cb = SEEK_CALLBACK(seek_func)</span>
<span class="gi">+</span>
<span class="gi">+    if new_api:</span>
<span class="gi">+        open_cb = ffi.NO_OPEN_CB</span>
<span class="gi">+        close_cb = ffi.NO_CLOSE_CB</span>
<span class="gi">+    else:</span>
<span class="gi">+        open_cb = libarchive.read.OPEN_CALLBACK(ffi.VOID_CB)</span>
<span class="gi">+        close_cb = libarchive.read.CLOSE_CALLBACK(ffi.VOID_CB)</span>
<span class="gi">+</span>
<span class="gi">+    with libarchive.read.new_archive_read(format_name, filter_name) as archive_p:</span>
<span class="gi">+        read_set_seek_callback(archive_p, seek_cb)</span>
<span class="gi">+        ffi.read_open(archive_p, None, open_cb, read_cb, close_cb)</span>
<span class="gi">+        yield libarchive.read.ArchiveRead(archive_p)</span>


<span class="w"> </span>class LibArchiveFileSystem(AbstractArchiveFileSystem):
<span class="gu">@@ -39,12 +86,20 @@ class LibArchiveFileSystem(AbstractArchiveFileSystem):</span>
<span class="w"> </span>    This class is pickleable, but not necessarily thread-safe (depends on the
<span class="w"> </span>    platform). See libarchive documentation for details.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    root_marker = &#39;&#39;</span>
<span class="gd">-    protocol = &#39;libarchive&#39;</span>
<span class="gi">+</span>
<span class="gi">+    root_marker = &quot;&quot;</span>
<span class="gi">+    protocol = &quot;libarchive&quot;</span>
<span class="w"> </span>    cachable = False

<span class="gd">-    def __init__(self, fo=&#39;&#39;, mode=&#39;r&#39;, target_protocol=None,</span>
<span class="gd">-        target_options=None, block_size=DEFAULT_BLOCK_SIZE, **kwargs):</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        fo=&quot;&quot;,</span>
<span class="gi">+        mode=&quot;r&quot;,</span>
<span class="gi">+        target_protocol=None,</span>
<span class="gi">+        target_options=None,</span>
<span class="gi">+        block_size=DEFAULT_BLOCK_SIZE,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Parameters
<span class="w"> </span>        ----------
<span class="gu">@@ -61,17 +116,98 @@ class LibArchiveFileSystem(AbstractArchiveFileSystem):</span>
<span class="w"> </span>            a string.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        super().__init__(self, **kwargs)
<span class="gd">-        if mode != &#39;r&#39;:</span>
<span class="gd">-            raise ValueError(&#39;Only read from archive files accepted&#39;)</span>
<span class="gi">+        if mode != &quot;r&quot;:</span>
<span class="gi">+            raise ValueError(&quot;Only read from archive files accepted&quot;)</span>
<span class="w"> </span>        if isinstance(fo, str):
<span class="gd">-            files = open_files(fo, protocol=target_protocol, **</span>
<span class="gd">-                target_options or {})</span>
<span class="gi">+            files = open_files(fo, protocol=target_protocol, **(target_options or {}))</span>
<span class="w"> </span>            if len(files) != 1:
<span class="w"> </span>                raise ValueError(
<span class="w"> </span>                    f&#39;Path &quot;{fo}&quot; did not resolve to exactly one file: &quot;{files}&quot;&#39;
<span class="gd">-                    )</span>
<span class="gi">+                )</span>
<span class="w"> </span>            fo = files[0]
<span class="w"> </span>        self.of = fo
<span class="gd">-        self.fo = fo.__enter__()</span>
<span class="gi">+        self.fo = fo.__enter__()  # the whole instance is a context</span>
<span class="w"> </span>        self.block_size = block_size
<span class="w"> </span>        self.dir_cache = None
<span class="gi">+</span>
<span class="gi">+    @contextmanager</span>
<span class="gi">+    def _open_archive(self):</span>
<span class="gi">+        self.fo.seek(0)</span>
<span class="gi">+        with custom_reader(self.fo, block_size=self.block_size) as arc:</span>
<span class="gi">+            yield arc</span>
<span class="gi">+</span>
<span class="gi">+    @classmethod</span>
<span class="gi">+    def _strip_protocol(cls, path):</span>
<span class="gi">+        # file paths are always relative to the archive root</span>
<span class="gi">+        return super()._strip_protocol(path).lstrip(&quot;/&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def _get_dirs(self):</span>
<span class="gi">+        fields = {</span>
<span class="gi">+            &quot;name&quot;: &quot;pathname&quot;,</span>
<span class="gi">+            &quot;size&quot;: &quot;size&quot;,</span>
<span class="gi">+            &quot;created&quot;: &quot;ctime&quot;,</span>
<span class="gi">+            &quot;mode&quot;: &quot;mode&quot;,</span>
<span class="gi">+            &quot;uid&quot;: &quot;uid&quot;,</span>
<span class="gi">+            &quot;gid&quot;: &quot;gid&quot;,</span>
<span class="gi">+            &quot;mtime&quot;: &quot;mtime&quot;,</span>
<span class="gi">+        }</span>
<span class="gi">+</span>
<span class="gi">+        if self.dir_cache is not None:</span>
<span class="gi">+            return</span>
<span class="gi">+</span>
<span class="gi">+        self.dir_cache = {}</span>
<span class="gi">+        list_names = []</span>
<span class="gi">+        with self._open_archive() as arc:</span>
<span class="gi">+            for entry in arc:</span>
<span class="gi">+                if not entry.isdir and not entry.isfile:</span>
<span class="gi">+                    # Skip symbolic links, fifo entries, etc.</span>
<span class="gi">+                    continue</span>
<span class="gi">+                self.dir_cache.update(</span>
<span class="gi">+                    {</span>
<span class="gi">+                        dirname: {&quot;name&quot;: dirname, &quot;size&quot;: 0, &quot;type&quot;: &quot;directory&quot;}</span>
<span class="gi">+                        for dirname in self._all_dirnames(set(entry.name))</span>
<span class="gi">+                    }</span>
<span class="gi">+                )</span>
<span class="gi">+                f = {key: getattr(entry, fields[key]) for key in fields}</span>
<span class="gi">+                f[&quot;type&quot;] = &quot;directory&quot; if entry.isdir else &quot;file&quot;</span>
<span class="gi">+                list_names.append(entry.name)</span>
<span class="gi">+</span>
<span class="gi">+                self.dir_cache[f[&quot;name&quot;]] = f</span>
<span class="gi">+        # libarchive does not seem to return an entry for the directories (at least</span>
<span class="gi">+        # not in all formats), so get the directories names from the files names</span>
<span class="gi">+        self.dir_cache.update(</span>
<span class="gi">+            {</span>
<span class="gi">+                dirname: {&quot;name&quot;: dirname, &quot;size&quot;: 0, &quot;type&quot;: &quot;directory&quot;}</span>
<span class="gi">+                for dirname in self._all_dirnames(list_names)</span>
<span class="gi">+            }</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def _open(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=None,</span>
<span class="gi">+        autocommit=True,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if mode != &quot;rb&quot;:</span>
<span class="gi">+            raise NotImplementedError</span>
<span class="gi">+</span>
<span class="gi">+        data = bytes()</span>
<span class="gi">+        with self._open_archive() as arc:</span>
<span class="gi">+            for entry in arc:</span>
<span class="gi">+                if entry.pathname != path:</span>
<span class="gi">+                    continue</span>
<span class="gi">+</span>
<span class="gi">+                if entry.size == 0:</span>
<span class="gi">+                    # empty file, so there are no blocks</span>
<span class="gi">+                    break</span>
<span class="gi">+</span>
<span class="gi">+                for block in entry.get_blocks(entry.size):</span>
<span class="gi">+                    data = block</span>
<span class="gi">+                    break</span>
<span class="gi">+                else:</span>
<span class="gi">+                    raise ValueError</span>
<span class="gi">+        return MemoryFile(fs=self, path=path, data=data)</span>
<span class="gh">diff --git a/fsspec/implementations/local.py b/fsspec/implementations/local.py</span>
<span class="gh">index af01bea..9881606 100644</span>
<span class="gd">--- a/fsspec/implementations/local.py</span>
<span class="gi">+++ b/fsspec/implementations/local.py</span>
<span class="gu">@@ -6,11 +6,13 @@ import os.path as osp</span>
<span class="w"> </span>import shutil
<span class="w"> </span>import stat
<span class="w"> </span>import tempfile
<span class="gi">+</span>
<span class="w"> </span>from fsspec import AbstractFileSystem
<span class="w"> </span>from fsspec.compression import compr
<span class="w"> </span>from fsspec.core import get_compression
<span class="w"> </span>from fsspec.utils import isfilelike, stringify_path
<span class="gd">-logger = logging.getLogger(&#39;fsspec.local&#39;)</span>
<span class="gi">+</span>
<span class="gi">+logger = logging.getLogger(&quot;fsspec.local&quot;)</span>


<span class="w"> </span>class LocalFileSystem(AbstractFileSystem):
<span class="gu">@@ -23,18 +25,307 @@ class LocalFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        be created (if it doesn&#39;t already exist). This is assumed by pyarrow
<span class="w"> </span>        code.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    root_marker = &#39;/&#39;</span>
<span class="gd">-    protocol = &#39;file&#39;, &#39;local&#39;</span>
<span class="gi">+</span>
<span class="gi">+    root_marker = &quot;/&quot;</span>
<span class="gi">+    protocol = &quot;file&quot;, &quot;local&quot;</span>
<span class="w"> </span>    local_file = True

<span class="w"> </span>    def __init__(self, auto_mkdir=False, **kwargs):
<span class="w"> </span>        super().__init__(**kwargs)
<span class="w"> </span>        self.auto_mkdir = auto_mkdir

<span class="gi">+    @property</span>
<span class="gi">+    def fsid(self):</span>
<span class="gi">+        return &quot;local&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def mkdir(self, path, create_parents=True, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if self.exists(path):</span>
<span class="gi">+            raise FileExistsError(path)</span>
<span class="gi">+        if create_parents:</span>
<span class="gi">+            self.makedirs(path, exist_ok=True)</span>
<span class="gi">+        else:</span>
<span class="gi">+            os.mkdir(path, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def makedirs(self, path, exist_ok=False):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        os.makedirs(path, exist_ok=exist_ok)</span>
<span class="gi">+</span>
<span class="gi">+    def rmdir(self, path):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        os.rmdir(path)</span>
<span class="gi">+</span>
<span class="gi">+    def ls(self, path, detail=False, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        info = self.info(path)</span>
<span class="gi">+        if info[&quot;type&quot;] == &quot;directory&quot;:</span>
<span class="gi">+            with os.scandir(path) as it:</span>
<span class="gi">+                infos = [self.info(f) for f in it]</span>
<span class="gi">+        else:</span>
<span class="gi">+            infos = [info]</span>
<span class="gi">+</span>
<span class="gi">+        if not detail:</span>
<span class="gi">+            return [i[&quot;name&quot;] for i in infos]</span>
<span class="gi">+        return infos</span>
<span class="gi">+</span>
<span class="gi">+    def info(self, path, **kwargs):</span>
<span class="gi">+        if isinstance(path, os.DirEntry):</span>
<span class="gi">+            # scandir DirEntry</span>
<span class="gi">+            out = path.stat(follow_symlinks=False)</span>
<span class="gi">+            link = path.is_symlink()</span>
<span class="gi">+            if path.is_dir(follow_symlinks=False):</span>
<span class="gi">+                t = &quot;directory&quot;</span>
<span class="gi">+            elif path.is_file(follow_symlinks=False):</span>
<span class="gi">+                t = &quot;file&quot;</span>
<span class="gi">+            else:</span>
<span class="gi">+                t = &quot;other&quot;</span>
<span class="gi">+            path = self._strip_protocol(path.path)</span>
<span class="gi">+        else:</span>
<span class="gi">+            # str or path-like</span>
<span class="gi">+            path = self._strip_protocol(path)</span>
<span class="gi">+            out = os.stat(path, follow_symlinks=False)</span>
<span class="gi">+            link = stat.S_ISLNK(out.st_mode)</span>
<span class="gi">+            if link:</span>
<span class="gi">+                out = os.stat(path, follow_symlinks=True)</span>
<span class="gi">+            if stat.S_ISDIR(out.st_mode):</span>
<span class="gi">+                t = &quot;directory&quot;</span>
<span class="gi">+            elif stat.S_ISREG(out.st_mode):</span>
<span class="gi">+                t = &quot;file&quot;</span>
<span class="gi">+            else:</span>
<span class="gi">+                t = &quot;other&quot;</span>
<span class="gi">+        result = {</span>
<span class="gi">+            &quot;name&quot;: path,</span>
<span class="gi">+            &quot;size&quot;: out.st_size,</span>
<span class="gi">+            &quot;type&quot;: t,</span>
<span class="gi">+            &quot;created&quot;: out.st_ctime,</span>
<span class="gi">+            &quot;islink&quot;: link,</span>
<span class="gi">+        }</span>
<span class="gi">+        for field in [&quot;mode&quot;, &quot;uid&quot;, &quot;gid&quot;, &quot;mtime&quot;, &quot;ino&quot;, &quot;nlink&quot;]:</span>
<span class="gi">+            result[field] = getattr(out, f&quot;st_{field}&quot;)</span>
<span class="gi">+        if result[&quot;islink&quot;]:</span>
<span class="gi">+            result[&quot;destination&quot;] = os.readlink(path)</span>
<span class="gi">+            try:</span>
<span class="gi">+                out2 = os.stat(path, follow_symlinks=True)</span>
<span class="gi">+                result[&quot;size&quot;] = out2.st_size</span>
<span class="gi">+            except OSError:</span>
<span class="gi">+                result[&quot;size&quot;] = 0</span>
<span class="gi">+        return result</span>
<span class="gi">+</span>
<span class="gi">+    def lexists(self, path, **kwargs):</span>
<span class="gi">+        return osp.lexists(path)</span>
<span class="gi">+</span>
<span class="gi">+    def cp_file(self, path1, path2, **kwargs):</span>
<span class="gi">+        path1 = self._strip_protocol(path1)</span>
<span class="gi">+        path2 = self._strip_protocol(path2)</span>
<span class="gi">+        if self.auto_mkdir:</span>
<span class="gi">+            self.makedirs(self._parent(path2), exist_ok=True)</span>
<span class="gi">+        if self.isfile(path1):</span>
<span class="gi">+            shutil.copyfile(path1, path2)</span>
<span class="gi">+        elif self.isdir(path1):</span>
<span class="gi">+            self.mkdirs(path2, exist_ok=True)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise FileNotFoundError(path1)</span>
<span class="gi">+</span>
<span class="gi">+    def isfile(self, path):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        return os.path.isfile(path)</span>
<span class="gi">+</span>
<span class="gi">+    def isdir(self, path):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        return os.path.isdir(path)</span>
<span class="gi">+</span>
<span class="gi">+    def get_file(self, path1, path2, callback=None, **kwargs):</span>
<span class="gi">+        if isfilelike(path2):</span>
<span class="gi">+            with open(path1, &quot;rb&quot;) as f:</span>
<span class="gi">+                shutil.copyfileobj(f, path2)</span>
<span class="gi">+        else:</span>
<span class="gi">+            return self.cp_file(path1, path2, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def put_file(self, path1, path2, callback=None, **kwargs):</span>
<span class="gi">+        return self.cp_file(path1, path2, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def mv(self, path1, path2, **kwargs):</span>
<span class="gi">+        path1 = self._strip_protocol(path1)</span>
<span class="gi">+        path2 = self._strip_protocol(path2)</span>
<span class="gi">+        shutil.move(path1, path2)</span>
<span class="gi">+</span>
<span class="gi">+    def link(self, src, dst, **kwargs):</span>
<span class="gi">+        src = self._strip_protocol(src)</span>
<span class="gi">+        dst = self._strip_protocol(dst)</span>
<span class="gi">+        os.link(src, dst, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def symlink(self, src, dst, **kwargs):</span>
<span class="gi">+        src = self._strip_protocol(src)</span>
<span class="gi">+        dst = self._strip_protocol(dst)</span>
<span class="gi">+        os.symlink(src, dst, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def islink(self, path) -&gt; bool:</span>
<span class="gi">+        return os.path.islink(self._strip_protocol(path))</span>
<span class="gi">+</span>
<span class="gi">+    def rm_file(self, path):</span>
<span class="gi">+        os.remove(self._strip_protocol(path))</span>
<span class="gi">+</span>
<span class="gi">+    def rm(self, path, recursive=False, maxdepth=None):</span>
<span class="gi">+        if not isinstance(path, list):</span>
<span class="gi">+            path = [path]</span>
<span class="gi">+</span>
<span class="gi">+        for p in path:</span>
<span class="gi">+            p = self._strip_protocol(p)</span>
<span class="gi">+            if self.isdir(p):</span>
<span class="gi">+                if not recursive:</span>
<span class="gi">+                    raise ValueError(&quot;Cannot delete directory, set recursive=True&quot;)</span>
<span class="gi">+                if osp.abspath(p) == os.getcwd():</span>
<span class="gi">+                    raise ValueError(&quot;Cannot delete current working directory&quot;)</span>
<span class="gi">+                shutil.rmtree(p)</span>
<span class="gi">+            else:</span>
<span class="gi">+                os.remove(p)</span>
<span class="gi">+</span>
<span class="gi">+    def unstrip_protocol(self, name):</span>
<span class="gi">+        name = self._strip_protocol(name)  # normalise for local/win/...</span>
<span class="gi">+        return f&quot;file://{name}&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def _open(self, path, mode=&quot;rb&quot;, block_size=None, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if self.auto_mkdir and &quot;w&quot; in mode:</span>
<span class="gi">+            self.makedirs(self._parent(path), exist_ok=True)</span>
<span class="gi">+        return LocalFileOpener(path, mode, fs=self, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def touch(self, path, truncate=True, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if self.auto_mkdir:</span>
<span class="gi">+            self.makedirs(self._parent(path), exist_ok=True)</span>
<span class="gi">+        if self.exists(path):</span>
<span class="gi">+            os.utime(path, None)</span>
<span class="gi">+        else:</span>
<span class="gi">+            open(path, &quot;a&quot;).close()</span>
<span class="gi">+        if truncate:</span>
<span class="gi">+            os.truncate(path, 0)</span>
<span class="gi">+</span>
<span class="gi">+    def created(self, path):</span>
<span class="gi">+        info = self.info(path=path)</span>
<span class="gi">+        return datetime.datetime.fromtimestamp(</span>
<span class="gi">+            info[&quot;created&quot;], tz=datetime.timezone.utc</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def modified(self, path):</span>
<span class="gi">+        info = self.info(path=path)</span>
<span class="gi">+        return datetime.datetime.fromtimestamp(info[&quot;mtime&quot;], tz=datetime.timezone.utc)</span>
<span class="gi">+</span>
<span class="gi">+    @classmethod</span>
<span class="gi">+    def _parent(cls, path):</span>
<span class="gi">+        path = cls._strip_protocol(path)</span>
<span class="gi">+        if os.sep == &quot;/&quot;:</span>
<span class="gi">+            # posix native</span>
<span class="gi">+            return path.rsplit(&quot;/&quot;, 1)[0] or &quot;/&quot;</span>
<span class="gi">+        else:</span>
<span class="gi">+            # NT</span>
<span class="gi">+            path_ = path.rsplit(&quot;/&quot;, 1)[0]</span>
<span class="gi">+            if len(path_) &lt;= 3:</span>
<span class="gi">+                if path_[1:2] == &quot;:&quot;:</span>
<span class="gi">+                    # nt root (something like c:/)</span>
<span class="gi">+                    return path_[0] + &quot;:/&quot;</span>
<span class="gi">+            # More cases may be required here</span>
<span class="gi">+            return path_</span>
<span class="gi">+</span>
<span class="gi">+    @classmethod</span>
<span class="gi">+    def _strip_protocol(cls, path):</span>
<span class="gi">+        path = stringify_path(path)</span>
<span class="gi">+        if path.startswith(&quot;file://&quot;):</span>
<span class="gi">+            path = path[7:]</span>
<span class="gi">+        elif path.startswith(&quot;file:&quot;):</span>
<span class="gi">+            path = path[5:]</span>
<span class="gi">+        elif path.startswith(&quot;local://&quot;):</span>
<span class="gi">+            path = path[8:]</span>
<span class="gi">+        elif path.startswith(&quot;local:&quot;):</span>
<span class="gi">+            path = path[6:]</span>
<span class="gi">+</span>
<span class="gi">+        path = make_path_posix(path)</span>
<span class="gi">+        if os.sep != &quot;/&quot;:</span>
<span class="gi">+            # This code-path is a stripped down version of</span>
<span class="gi">+            # &gt; drive, path = ntpath.splitdrive(path)</span>
<span class="gi">+            if path[1:2] == &quot;:&quot;:</span>
<span class="gi">+                # Absolute drive-letter path, e.g. X:\Windows</span>
<span class="gi">+                # Relative path with drive, e.g. X:Windows</span>
<span class="gi">+                drive, path = path[:2], path[2:]</span>
<span class="gi">+            elif path[:2] == &quot;//&quot;:</span>
<span class="gi">+                # UNC drives, e.g. \\server\share or \\?\UNC\server\share</span>
<span class="gi">+                # Device drives, e.g. \\.\device or \\?\device</span>
<span class="gi">+                if (index1 := path.find(&quot;/&quot;, 2)) == -1 or (</span>
<span class="gi">+                    index2 := path.find(&quot;/&quot;, index1 + 1)</span>
<span class="gi">+                ) == -1:</span>
<span class="gi">+                    drive, path = path, &quot;&quot;</span>
<span class="gi">+                else:</span>
<span class="gi">+                    drive, path = path[:index2], path[index2:]</span>
<span class="gi">+            else:</span>
<span class="gi">+                # Relative path, e.g. Windows</span>
<span class="gi">+                drive = &quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+            path = path.rstrip(&quot;/&quot;) or cls.root_marker</span>
<span class="gi">+            return drive + path</span>
<span class="gi">+</span>
<span class="gi">+        else:</span>
<span class="gi">+            return path.rstrip(&quot;/&quot;) or cls.root_marker</span>
<span class="gi">+</span>
<span class="gi">+    def _isfilestore(self):</span>
<span class="gi">+        # Inheriting from DaskFileSystem makes this False (S3, etc. were)</span>
<span class="gi">+        # the original motivation. But we are a posix-like file system.</span>
<span class="gi">+        # See https://github.com/dask/dask/issues/5526</span>
<span class="gi">+        return True</span>
<span class="gi">+</span>
<span class="gi">+    def chmod(self, path, mode):</span>
<span class="gi">+        path = stringify_path(path)</span>
<span class="gi">+        return os.chmod(path, mode)</span>
<span class="gi">+</span>

<span class="w"> </span>def make_path_posix(path):
<span class="w"> </span>    &quot;&quot;&quot;Make path generic and absolute for current OS&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not isinstance(path, str):</span>
<span class="gi">+        if isinstance(path, (list, set, tuple)):</span>
<span class="gi">+            return type(path)(make_path_posix(p) for p in path)</span>
<span class="gi">+        else:</span>
<span class="gi">+            path = stringify_path(path)</span>
<span class="gi">+            if not isinstance(path, str):</span>
<span class="gi">+                raise TypeError(f&quot;could not convert {path!r} to string&quot;)</span>
<span class="gi">+    if os.sep == &quot;/&quot;:</span>
<span class="gi">+        # Native posix</span>
<span class="gi">+        if path.startswith(&quot;/&quot;):</span>
<span class="gi">+            # most common fast case for posix</span>
<span class="gi">+            return path</span>
<span class="gi">+        elif path.startswith(&quot;~&quot;):</span>
<span class="gi">+            return osp.expanduser(path)</span>
<span class="gi">+        elif path.startswith(&quot;./&quot;):</span>
<span class="gi">+            path = path[2:]</span>
<span class="gi">+        elif path == &quot;.&quot;:</span>
<span class="gi">+            path = &quot;&quot;</span>
<span class="gi">+        return f&quot;{os.getcwd()}/{path}&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        # NT handling</span>
<span class="gi">+        if path[0:1] == &quot;/&quot; and path[2:3] == &quot;:&quot;:</span>
<span class="gi">+            # path is like &quot;/c:/local/path&quot;</span>
<span class="gi">+            path = path[1:]</span>
<span class="gi">+        if path[1:2] == &quot;:&quot;:</span>
<span class="gi">+            # windows full path like &quot;C:\\local\\path&quot;</span>
<span class="gi">+            if len(path) &lt;= 3:</span>
<span class="gi">+                # nt root (something like c:/)</span>
<span class="gi">+                return path[0] + &quot;:/&quot;</span>
<span class="gi">+            path = path.replace(&quot;\\&quot;, &quot;/&quot;)</span>
<span class="gi">+            return path</span>
<span class="gi">+        elif path[0:1] == &quot;~&quot;:</span>
<span class="gi">+            return make_path_posix(osp.expanduser(path))</span>
<span class="gi">+        elif path.startswith((&quot;\\\\&quot;, &quot;//&quot;)):</span>
<span class="gi">+            # windows UNC/DFS-style paths</span>
<span class="gi">+            return &quot;//&quot; + path[2:].replace(&quot;\\&quot;, &quot;/&quot;)</span>
<span class="gi">+        elif path.startswith((&quot;\\&quot;, &quot;/&quot;)):</span>
<span class="gi">+            # windows relative path with root</span>
<span class="gi">+            path = path.replace(&quot;\\&quot;, &quot;/&quot;)</span>
<span class="gi">+            return f&quot;{osp.splitdrive(os.getcwd())[0]}{path}&quot;</span>
<span class="gi">+        else:</span>
<span class="gi">+            path = path.replace(&quot;\\&quot;, &quot;/&quot;)</span>
<span class="gi">+            if path.startswith(&quot;./&quot;):</span>
<span class="gi">+                path = path[2:]</span>
<span class="gi">+            elif path == &quot;.&quot;:</span>
<span class="gi">+                path = &quot;&quot;</span>
<span class="gi">+            return f&quot;{make_path_posix(os.getcwd())}/{path}&quot;</span>


<span class="w"> </span>def trailing_sep(path):
<span class="gu">@@ -43,14 +334,17 @@ def trailing_sep(path):</span>
<span class="w"> </span>    A forward slash is always considered a path separator, even on Operating
<span class="w"> </span>    Systems that normally use a backslash.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # TODO: if all incoming paths were posix-compliant then separator would</span>
<span class="gi">+    # always be a forward slash, simplifying this function.</span>
<span class="gi">+    # See https://github.com/fsspec/filesystem_spec/pull/1250</span>
<span class="gi">+    return path.endswith(os.sep) or (os.altsep is not None and path.endswith(os.altsep))</span>


<span class="w"> </span>class LocalFileOpener(io.IOBase):
<span class="gd">-</span>
<span class="gd">-    def __init__(self, path, mode, autocommit=True, fs=None, compression=</span>
<span class="gd">-        None, **kwargs):</span>
<span class="gd">-        logger.debug(&#39;open file: %s&#39;, path)</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self, path, mode, autocommit=True, fs=None, compression=None, **kwargs</span>
<span class="gi">+    ):</span>
<span class="gi">+        logger.debug(&quot;open file: %s&quot;, path)</span>
<span class="w"> </span>        self.path = path
<span class="w"> </span>        self.mode = mode
<span class="w"> </span>        self.fs = fs
<span class="gu">@@ -60,24 +354,104 @@ class LocalFileOpener(io.IOBase):</span>
<span class="w"> </span>        self.blocksize = io.DEFAULT_BUFFER_SIZE
<span class="w"> </span>        self._open()

<span class="gi">+    def _open(self):</span>
<span class="gi">+        if self.f is None or self.f.closed:</span>
<span class="gi">+            if self.autocommit or &quot;w&quot; not in self.mode:</span>
<span class="gi">+                self.f = open(self.path, mode=self.mode)</span>
<span class="gi">+                if self.compression:</span>
<span class="gi">+                    compress = compr[self.compression]</span>
<span class="gi">+                    self.f = compress(self.f, mode=self.mode)</span>
<span class="gi">+            else:</span>
<span class="gi">+                # TODO: check if path is writable?</span>
<span class="gi">+                i, name = tempfile.mkstemp()</span>
<span class="gi">+                os.close(i)  # we want normal open and normal buffered file</span>
<span class="gi">+                self.temp = name</span>
<span class="gi">+                self.f = open(name, mode=self.mode)</span>
<span class="gi">+            if &quot;w&quot; not in self.mode:</span>
<span class="gi">+                self.size = self.f.seek(0, 2)</span>
<span class="gi">+                self.f.seek(0)</span>
<span class="gi">+                self.f.size = self.size</span>
<span class="gi">+</span>
<span class="gi">+    def _fetch_range(self, start, end):</span>
<span class="gi">+        # probably only used by cached FS</span>
<span class="gi">+        if &quot;r&quot; not in self.mode:</span>
<span class="gi">+            raise ValueError</span>
<span class="gi">+        self._open()</span>
<span class="gi">+        self.f.seek(start)</span>
<span class="gi">+        return self.f.read(end - start)</span>
<span class="gi">+</span>
<span class="w"> </span>    def __setstate__(self, state):
<span class="w"> </span>        self.f = None
<span class="gd">-        loc = state.pop(&#39;loc&#39;, None)</span>
<span class="gi">+        loc = state.pop(&quot;loc&quot;, None)</span>
<span class="w"> </span>        self.__dict__.update(state)
<span class="gd">-        if &#39;r&#39; in state[&#39;mode&#39;]:</span>
<span class="gi">+        if &quot;r&quot; in state[&quot;mode&quot;]:</span>
<span class="w"> </span>            self.f = None
<span class="w"> </span>            self._open()
<span class="w"> </span>            self.f.seek(loc)

<span class="w"> </span>    def __getstate__(self):
<span class="w"> </span>        d = self.__dict__.copy()
<span class="gd">-        d.pop(&#39;f&#39;)</span>
<span class="gd">-        if &#39;r&#39; in self.mode:</span>
<span class="gd">-            d[&#39;loc&#39;] = self.f.tell()</span>
<span class="gd">-        elif not self.f.closed:</span>
<span class="gd">-            raise ValueError(&#39;Cannot serialise open write-mode local file&#39;)</span>
<span class="gi">+        d.pop(&quot;f&quot;)</span>
<span class="gi">+        if &quot;r&quot; in self.mode:</span>
<span class="gi">+            d[&quot;loc&quot;] = self.f.tell()</span>
<span class="gi">+        else:</span>
<span class="gi">+            if not self.f.closed:</span>
<span class="gi">+                raise ValueError(&quot;Cannot serialise open write-mode local file&quot;)</span>
<span class="w"> </span>        return d

<span class="gi">+    def commit(self):</span>
<span class="gi">+        if self.autocommit:</span>
<span class="gi">+            raise RuntimeError(&quot;Can only commit if not already set to autocommit&quot;)</span>
<span class="gi">+        shutil.move(self.temp, self.path)</span>
<span class="gi">+</span>
<span class="gi">+    def discard(self):</span>
<span class="gi">+        if self.autocommit:</span>
<span class="gi">+            raise RuntimeError(&quot;Cannot discard if set to autocommit&quot;)</span>
<span class="gi">+        os.remove(self.temp)</span>
<span class="gi">+</span>
<span class="gi">+    def readable(self) -&gt; bool:</span>
<span class="gi">+        return True</span>
<span class="gi">+</span>
<span class="gi">+    def writable(self) -&gt; bool:</span>
<span class="gi">+        return &quot;r&quot; not in self.mode</span>
<span class="gi">+</span>
<span class="gi">+    def read(self, *args, **kwargs):</span>
<span class="gi">+        return self.f.read(*args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def write(self, *args, **kwargs):</span>
<span class="gi">+        return self.f.write(*args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def tell(self, *args, **kwargs):</span>
<span class="gi">+        return self.f.tell(*args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def seek(self, *args, **kwargs):</span>
<span class="gi">+        return self.f.seek(*args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def seekable(self, *args, **kwargs):</span>
<span class="gi">+        return self.f.seekable(*args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def readline(self, *args, **kwargs):</span>
<span class="gi">+        return self.f.readline(*args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def readlines(self, *args, **kwargs):</span>
<span class="gi">+        return self.f.readlines(*args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def close(self):</span>
<span class="gi">+        return self.f.close()</span>
<span class="gi">+</span>
<span class="gi">+    def truncate(self, size=None) -&gt; int:</span>
<span class="gi">+        return self.f.truncate(size)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def closed(self):</span>
<span class="gi">+        return self.f.closed</span>
<span class="gi">+</span>
<span class="gi">+    def fileno(self):</span>
<span class="gi">+        return self.raw.fileno()</span>
<span class="gi">+</span>
<span class="gi">+    def flush(self) -&gt; None:</span>
<span class="gi">+        self.f.flush()</span>
<span class="gi">+</span>
<span class="w"> </span>    def __iter__(self):
<span class="w"> </span>        return self.f.__iter__()

<span class="gh">diff --git a/fsspec/implementations/memory.py b/fsspec/implementations/memory.py</span>
<span class="gh">index e1fdbd3..83e7e74 100644</span>
<span class="gd">--- a/fsspec/implementations/memory.py</span>
<span class="gi">+++ b/fsspec/implementations/memory.py</span>
<span class="gu">@@ -1,14 +1,17 @@</span>
<span class="w"> </span>from __future__ import annotations
<span class="gi">+</span>
<span class="w"> </span>import logging
<span class="w"> </span>from datetime import datetime, timezone
<span class="w"> </span>from errno import ENOTEMPTY
<span class="w"> </span>from io import BytesIO
<span class="w"> </span>from pathlib import PurePath, PureWindowsPath
<span class="w"> </span>from typing import Any, ClassVar
<span class="gi">+</span>
<span class="w"> </span>from fsspec import AbstractFileSystem
<span class="w"> </span>from fsspec.implementations.local import LocalFileSystem
<span class="w"> </span>from fsspec.utils import stringify_path
<span class="gd">-logger = logging.getLogger(&#39;fsspec.memoryfs&#39;)</span>
<span class="gi">+</span>
<span class="gi">+logger = logging.getLogger(&quot;fsspec.memoryfs&quot;)</span>


<span class="w"> </span>class MemoryFileSystem(AbstractFileSystem):
<span class="gu">@@ -17,17 +20,251 @@ class MemoryFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>    This is a global filesystem so instances of this class all point to the same
<span class="w"> </span>    in memory filesystem.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    store: ClassVar[dict[str, Any]] = {}</span>
<span class="gd">-    pseudo_dirs = [&#39;&#39;]</span>
<span class="gd">-    protocol = &#39;memory&#39;</span>
<span class="gd">-    root_marker = &#39;/&#39;</span>
<span class="gi">+</span>
<span class="gi">+    store: ClassVar[dict[str, Any]] = {}  # global, do not overwrite!</span>
<span class="gi">+    pseudo_dirs = [&quot;&quot;]  # global, do not overwrite!</span>
<span class="gi">+    protocol = &quot;memory&quot;</span>
<span class="gi">+    root_marker = &quot;/&quot;</span>
<span class="gi">+</span>
<span class="gi">+    @classmethod</span>
<span class="gi">+    def _strip_protocol(cls, path):</span>
<span class="gi">+        if isinstance(path, PurePath):</span>
<span class="gi">+            if isinstance(path, PureWindowsPath):</span>
<span class="gi">+                return LocalFileSystem._strip_protocol(path)</span>
<span class="gi">+            else:</span>
<span class="gi">+                path = stringify_path(path)</span>
<span class="gi">+</span>
<span class="gi">+        if path.startswith(&quot;memory://&quot;):</span>
<span class="gi">+            path = path[len(&quot;memory://&quot;) :]</span>
<span class="gi">+        if &quot;::&quot; in path or &quot;://&quot; in path:</span>
<span class="gi">+            return path.rstrip(&quot;/&quot;)</span>
<span class="gi">+        path = path.lstrip(&quot;/&quot;).rstrip(&quot;/&quot;)</span>
<span class="gi">+        return &quot;/&quot; + path if path else &quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def ls(self, path, detail=True, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if path in self.store:</span>
<span class="gi">+            # there is a key with this exact name</span>
<span class="gi">+            if not detail:</span>
<span class="gi">+                return [path]</span>
<span class="gi">+            return [</span>
<span class="gi">+                {</span>
<span class="gi">+                    &quot;name&quot;: path,</span>
<span class="gi">+                    &quot;size&quot;: self.store[path].size,</span>
<span class="gi">+                    &quot;type&quot;: &quot;file&quot;,</span>
<span class="gi">+                    &quot;created&quot;: self.store[path].created.timestamp(),</span>
<span class="gi">+                }</span>
<span class="gi">+            ]</span>
<span class="gi">+        paths = set()</span>
<span class="gi">+        starter = path + &quot;/&quot;</span>
<span class="gi">+        out = []</span>
<span class="gi">+        for p2 in tuple(self.store):</span>
<span class="gi">+            if p2.startswith(starter):</span>
<span class="gi">+                if &quot;/&quot; not in p2[len(starter) :]:</span>
<span class="gi">+                    # exact child</span>
<span class="gi">+                    out.append(</span>
<span class="gi">+                        {</span>
<span class="gi">+                            &quot;name&quot;: p2,</span>
<span class="gi">+                            &quot;size&quot;: self.store[p2].size,</span>
<span class="gi">+                            &quot;type&quot;: &quot;file&quot;,</span>
<span class="gi">+                            &quot;created&quot;: self.store[p2].created.timestamp(),</span>
<span class="gi">+                        }</span>
<span class="gi">+                    )</span>
<span class="gi">+                elif len(p2) &gt; len(starter):</span>
<span class="gi">+                    # implied child directory</span>
<span class="gi">+                    ppath = starter + p2[len(starter) :].split(&quot;/&quot;, 1)[0]</span>
<span class="gi">+                    if ppath not in paths:</span>
<span class="gi">+                        out = out or []</span>
<span class="gi">+                        out.append(</span>
<span class="gi">+                            {</span>
<span class="gi">+                                &quot;name&quot;: ppath,</span>
<span class="gi">+                                &quot;size&quot;: 0,</span>
<span class="gi">+                                &quot;type&quot;: &quot;directory&quot;,</span>
<span class="gi">+                            }</span>
<span class="gi">+                        )</span>
<span class="gi">+                        paths.add(ppath)</span>
<span class="gi">+        for p2 in self.pseudo_dirs:</span>
<span class="gi">+            if p2.startswith(starter):</span>
<span class="gi">+                if &quot;/&quot; not in p2[len(starter) :]:</span>
<span class="gi">+                    # exact child pdir</span>
<span class="gi">+                    if p2 not in paths:</span>
<span class="gi">+                        out.append({&quot;name&quot;: p2, &quot;size&quot;: 0, &quot;type&quot;: &quot;directory&quot;})</span>
<span class="gi">+                        paths.add(p2)</span>
<span class="gi">+                else:</span>
<span class="gi">+                    # directory implied by deeper pdir</span>
<span class="gi">+                    ppath = starter + p2[len(starter) :].split(&quot;/&quot;, 1)[0]</span>
<span class="gi">+                    if ppath not in paths:</span>
<span class="gi">+                        out.append({&quot;name&quot;: ppath, &quot;size&quot;: 0, &quot;type&quot;: &quot;directory&quot;})</span>
<span class="gi">+                        paths.add(ppath)</span>
<span class="gi">+        if not out:</span>
<span class="gi">+            if path in self.pseudo_dirs:</span>
<span class="gi">+                # empty dir</span>
<span class="gi">+                return []</span>
<span class="gi">+            raise FileNotFoundError(path)</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return out</span>
<span class="gi">+        return sorted([f[&quot;name&quot;] for f in out])</span>
<span class="gi">+</span>
<span class="gi">+    def mkdir(self, path, create_parents=True, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if path in self.store or path in self.pseudo_dirs:</span>
<span class="gi">+            raise FileExistsError(path)</span>
<span class="gi">+        if self._parent(path).strip(&quot;/&quot;) and self.isfile(self._parent(path)):</span>
<span class="gi">+            raise NotADirectoryError(self._parent(path))</span>
<span class="gi">+        if create_parents and self._parent(path).strip(&quot;/&quot;):</span>
<span class="gi">+            try:</span>
<span class="gi">+                self.mkdir(self._parent(path), create_parents, **kwargs)</span>
<span class="gi">+            except FileExistsError:</span>
<span class="gi">+                pass</span>
<span class="gi">+        if path and path not in self.pseudo_dirs:</span>
<span class="gi">+            self.pseudo_dirs.append(path)</span>
<span class="gi">+</span>
<span class="gi">+    def makedirs(self, path, exist_ok=False):</span>
<span class="gi">+        try:</span>
<span class="gi">+            self.mkdir(path, create_parents=True)</span>
<span class="gi">+        except FileExistsError:</span>
<span class="gi">+            if not exist_ok:</span>
<span class="gi">+                raise</span>

<span class="w"> </span>    def pipe_file(self, path, value, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Set the bytes of given file

<span class="w"> </span>        Avoids copies of the data if possible
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.open(path, &quot;wb&quot;, data=value)</span>
<span class="gi">+</span>
<span class="gi">+    def rmdir(self, path):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if path == &quot;&quot;:</span>
<span class="gi">+            # silently avoid deleting FS root</span>
<span class="gi">+            return</span>
<span class="gi">+        if path in self.pseudo_dirs:</span>
<span class="gi">+            if not self.ls(path):</span>
<span class="gi">+                self.pseudo_dirs.remove(path)</span>
<span class="gi">+            else:</span>
<span class="gi">+                raise OSError(ENOTEMPTY, &quot;Directory not empty&quot;, path)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise FileNotFoundError(path)</span>
<span class="gi">+</span>
<span class="gi">+    def info(self, path, **kwargs):</span>
<span class="gi">+        logger.debug(&quot;info: %s&quot;, path)</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if path in self.pseudo_dirs or any(</span>
<span class="gi">+            p.startswith(path + &quot;/&quot;) for p in list(self.store) + self.pseudo_dirs</span>
<span class="gi">+        ):</span>
<span class="gi">+            return {</span>
<span class="gi">+                &quot;name&quot;: path,</span>
<span class="gi">+                &quot;size&quot;: 0,</span>
<span class="gi">+                &quot;type&quot;: &quot;directory&quot;,</span>
<span class="gi">+            }</span>
<span class="gi">+        elif path in self.store:</span>
<span class="gi">+            filelike = self.store[path]</span>
<span class="gi">+            return {</span>
<span class="gi">+                &quot;name&quot;: path,</span>
<span class="gi">+                &quot;size&quot;: filelike.size,</span>
<span class="gi">+                &quot;type&quot;: &quot;file&quot;,</span>
<span class="gi">+                &quot;created&quot;: getattr(filelike, &quot;created&quot;, None),</span>
<span class="gi">+            }</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise FileNotFoundError(path)</span>
<span class="gi">+</span>
<span class="gi">+    def _open(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=None,</span>
<span class="gi">+        autocommit=True,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if path in self.pseudo_dirs:</span>
<span class="gi">+            raise IsADirectoryError(path)</span>
<span class="gi">+        parent = path</span>
<span class="gi">+        while len(parent) &gt; 1:</span>
<span class="gi">+            parent = self._parent(parent)</span>
<span class="gi">+            if self.isfile(parent):</span>
<span class="gi">+                raise FileExistsError(parent)</span>
<span class="gi">+        if mode in [&quot;rb&quot;, &quot;ab&quot;, &quot;r+b&quot;]:</span>
<span class="gi">+            if path in self.store:</span>
<span class="gi">+                f = self.store[path]</span>
<span class="gi">+                if mode == &quot;ab&quot;:</span>
<span class="gi">+                    # position at the end of file</span>
<span class="gi">+                    f.seek(0, 2)</span>
<span class="gi">+                else:</span>
<span class="gi">+                    # position at the beginning of file</span>
<span class="gi">+                    f.seek(0)</span>
<span class="gi">+                return f</span>
<span class="gi">+            else:</span>
<span class="gi">+                raise FileNotFoundError(path)</span>
<span class="gi">+        elif mode == &quot;wb&quot;:</span>
<span class="gi">+            m = MemoryFile(self, path, kwargs.get(&quot;data&quot;))</span>
<span class="gi">+            if not self._intrans:</span>
<span class="gi">+                m.commit()</span>
<span class="gi">+            return m</span>
<span class="gi">+        else:</span>
<span class="gi">+            name = self.__class__.__name__</span>
<span class="gi">+            raise ValueError(f&quot;unsupported file mode for {name}: {mode!r}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def cp_file(self, path1, path2, **kwargs):</span>
<span class="gi">+        path1 = self._strip_protocol(path1)</span>
<span class="gi">+        path2 = self._strip_protocol(path2)</span>
<span class="gi">+        if self.isfile(path1):</span>
<span class="gi">+            self.store[path2] = MemoryFile(</span>
<span class="gi">+                self, path2, self.store[path1].getvalue()</span>
<span class="gi">+            )  # implicit copy</span>
<span class="gi">+        elif self.isdir(path1):</span>
<span class="gi">+            if path2 not in self.pseudo_dirs:</span>
<span class="gi">+                self.pseudo_dirs.append(path2)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise FileNotFoundError(path1)</span>
<span class="gi">+</span>
<span class="gi">+    def cat_file(self, path, start=None, end=None, **kwargs):</span>
<span class="gi">+        logger.debug(&quot;cat: %s&quot;, path)</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        try:</span>
<span class="gi">+            return bytes(self.store[path].getbuffer()[start:end])</span>
<span class="gi">+        except KeyError:</span>
<span class="gi">+            raise FileNotFoundError(path)</span>
<span class="gi">+</span>
<span class="gi">+    def _rm(self, path):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        try:</span>
<span class="gi">+            del self.store[path]</span>
<span class="gi">+        except KeyError as e:</span>
<span class="gi">+            raise FileNotFoundError(path) from e</span>
<span class="gi">+</span>
<span class="gi">+    def modified(self, path):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        try:</span>
<span class="gi">+            return self.store[path].modified</span>
<span class="gi">+        except KeyError:</span>
<span class="gi">+            raise FileNotFoundError(path)</span>
<span class="gi">+</span>
<span class="gi">+    def created(self, path):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        try:</span>
<span class="gi">+            return self.store[path].created</span>
<span class="gi">+        except KeyError:</span>
<span class="gi">+            raise FileNotFoundError(path)</span>
<span class="gi">+</span>
<span class="gi">+    def rm(self, path, recursive=False, maxdepth=None):</span>
<span class="gi">+        if isinstance(path, str):</span>
<span class="gi">+            path = self._strip_protocol(path)</span>
<span class="gi">+        else:</span>
<span class="gi">+            path = [self._strip_protocol(p) for p in path]</span>
<span class="gi">+        paths = self.expand_path(path, recursive=recursive, maxdepth=maxdepth)</span>
<span class="gi">+        for p in reversed(paths):</span>
<span class="gi">+            # If the expanded path doesn&#39;t exist, it is only because the expanded</span>
<span class="gi">+            # path was a directory that does not exist in self.pseudo_dirs. This</span>
<span class="gi">+            # is possible if you directly create files without making the</span>
<span class="gi">+            # directories first.</span>
<span class="gi">+            if not self.exists(p):</span>
<span class="gi">+                continue</span>
<span class="gi">+            if self.isfile(p):</span>
<span class="gi">+                self.rm_file(p)</span>
<span class="gi">+            else:</span>
<span class="gi">+                self.rmdir(p)</span>


<span class="w"> </span>class MemoryFile(BytesIO):
<span class="gu">@@ -39,7 +276,7 @@ class MemoryFile(BytesIO):</span>
<span class="w"> </span>    &quot;&quot;&quot;

<span class="w"> </span>    def __init__(self, fs=None, path=None, data=None):
<span class="gd">-        logger.debug(&#39;open file %s&#39;, path)</span>
<span class="gi">+        logger.debug(&quot;open file %s&quot;, path)</span>
<span class="w"> </span>        self.fs = fs
<span class="w"> </span>        self.path = path
<span class="w"> </span>        self.created = datetime.now(tz=timezone.utc)
<span class="gu">@@ -48,5 +285,19 @@ class MemoryFile(BytesIO):</span>
<span class="w"> </span>            super().__init__(data)
<span class="w"> </span>            self.seek(0)

<span class="gi">+    @property</span>
<span class="gi">+    def size(self):</span>
<span class="gi">+        return self.getbuffer().nbytes</span>
<span class="gi">+</span>
<span class="w"> </span>    def __enter__(self):
<span class="w"> </span>        return self
<span class="gi">+</span>
<span class="gi">+    def close(self):</span>
<span class="gi">+        pass</span>
<span class="gi">+</span>
<span class="gi">+    def discard(self):</span>
<span class="gi">+        pass</span>
<span class="gi">+</span>
<span class="gi">+    def commit(self):</span>
<span class="gi">+        self.fs.store[self.path] = self</span>
<span class="gi">+        self.modified = datetime.now(tz=timezone.utc)</span>
<span class="gh">diff --git a/fsspec/implementations/reference.py b/fsspec/implementations/reference.py</span>
<span class="gh">index 608bb67..981e698 100644</span>
<span class="gd">--- a/fsspec/implementations/reference.py</span>
<span class="gi">+++ b/fsspec/implementations/reference.py</span>
<span class="gu">@@ -7,34 +7,54 @@ import math</span>
<span class="w"> </span>import os
<span class="w"> </span>from functools import lru_cache
<span class="w"> </span>from typing import TYPE_CHECKING
<span class="gi">+</span>
<span class="w"> </span>import fsspec.core
<span class="gi">+</span>
<span class="w"> </span>try:
<span class="w"> </span>    import ujson as json
<span class="w"> </span>except ImportError:
<span class="w"> </span>    if not TYPE_CHECKING:
<span class="w"> </span>        import json
<span class="gi">+</span>
<span class="w"> </span>from ..asyn import AsyncFileSystem
<span class="w"> </span>from ..callbacks import DEFAULT_CALLBACK
<span class="w"> </span>from ..core import filesystem, open, split_protocol
<span class="w"> </span>from ..utils import isfilelike, merge_offset_ranges, other_paths
<span class="gd">-logger = logging.getLogger(&#39;fsspec.reference&#39;)</span>

<span class="gi">+logger = logging.getLogger(&quot;fsspec.reference&quot;)</span>

<span class="gd">-class ReferenceNotReachable(RuntimeError):</span>

<span class="gi">+class ReferenceNotReachable(RuntimeError):</span>
<span class="w"> </span>    def __init__(self, reference, target, *args):
<span class="w"> </span>        super().__init__(*args)
<span class="w"> </span>        self.reference = reference
<span class="w"> </span>        self.target = target

<span class="w"> </span>    def __str__(self):
<span class="gd">-        return (</span>
<span class="gd">-            f&#39;Reference &quot;{self.reference}&quot; failed to fetch target {self.target}&#39;</span>
<span class="gd">-            )</span>
<span class="gi">+        return f&#39;Reference &quot;{self.reference}&quot; failed to fetch target {self.target}&#39;</span>


<span class="gd">-class RefsValuesView(collections.abc.ValuesView):</span>
<span class="gi">+def _first(d):</span>
<span class="gi">+    return list(d.values())[0]</span>
<span class="gi">+</span>

<span class="gi">+def _prot_in_references(path, references):</span>
<span class="gi">+    ref = references.get(path)</span>
<span class="gi">+    if isinstance(ref, (list, tuple)):</span>
<span class="gi">+        return split_protocol(ref[0])[0] if ref[0] else ref[0]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _protocol_groups(paths, references):</span>
<span class="gi">+    if isinstance(paths, str):</span>
<span class="gi">+        return {_prot_in_references(paths, references): [paths]}</span>
<span class="gi">+    out = {}</span>
<span class="gi">+    for path in paths:</span>
<span class="gi">+        protocol = _prot_in_references(path, references)</span>
<span class="gi">+        out.setdefault(protocol, []).append(path)</span>
<span class="gi">+    return out</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+class RefsValuesView(collections.abc.ValuesView):</span>
<span class="w"> </span>    def __iter__(self):
<span class="w"> </span>        for val in self._mapping.zmetadata.values():
<span class="w"> </span>            yield json.dumps(val).encode()
<span class="gu">@@ -42,17 +62,25 @@ class RefsValuesView(collections.abc.ValuesView):</span>
<span class="w"> </span>        for field in self._mapping.listdir():
<span class="w"> </span>            chunk_sizes = self._mapping._get_chunk_sizes(field)
<span class="w"> </span>            if len(chunk_sizes) == 0:
<span class="gd">-                yield self._mapping[field + &#39;/0&#39;]</span>
<span class="gi">+                yield self._mapping[field + &quot;/0&quot;]</span>
<span class="w"> </span>                continue
<span class="w"> </span>            yield from self._mapping._generate_all_records(field)


<span class="w"> </span>class RefsItemsView(collections.abc.ItemsView):
<span class="gd">-</span>
<span class="w"> </span>    def __iter__(self):
<span class="w"> </span>        return zip(self._mapping.keys(), self._mapping.values())


<span class="gi">+def ravel_multi_index(idx, sizes):</span>
<span class="gi">+    val = 0</span>
<span class="gi">+    mult = 1</span>
<span class="gi">+    for i, s in zip(idx[::-1], sizes[::-1]):</span>
<span class="gi">+        val += i * mult</span>
<span class="gi">+        mult *= s</span>
<span class="gi">+    return val</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>class LazyReferenceMapper(collections.abc.MutableMapping):
<span class="w"> </span>    &quot;&quot;&quot;This interface can be used to read/write references from Parquet stores.
<span class="w"> </span>    It is not intended for other types of references.
<span class="gu">@@ -61,8 +89,22 @@ class LazyReferenceMapper(collections.abc.MutableMapping):</span>
<span class="w"> </span>    Examples of this use-case can be found here:
<span class="w"> </span>    https://fsspec.github.io/kerchunk/advanced.html?highlight=parquet#parquet-storage&quot;&quot;&quot;

<span class="gd">-    def __init__(self, root, fs=None, out_root=None, cache_size=128,</span>
<span class="gd">-        categorical_threshold=10):</span>
<span class="gi">+    # import is class level to prevent numpy dep requirement for fsspec</span>
<span class="gi">+    @property</span>
<span class="gi">+    def np(self):</span>
<span class="gi">+        import numpy as np</span>
<span class="gi">+</span>
<span class="gi">+        return np</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def pd(self):</span>
<span class="gi">+        import pandas as pd</span>
<span class="gi">+</span>
<span class="gi">+        return pd</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self, root, fs=None, out_root=None, cache_size=128, categorical_threshold=10</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;

<span class="w"> </span>        This instance will be writable, storing changes in memory until full partitions
<span class="gu">@@ -90,18 +132,40 @@ class LazyReferenceMapper(collections.abc.MutableMapping):</span>
<span class="w"> </span>        self.cat_thresh = categorical_threshold
<span class="w"> </span>        self.cache_size = cache_size
<span class="w"> </span>        self.dirs = None
<span class="gd">-        self.url = self.root + &#39;/{field}/refs.{record}.parq&#39;</span>
<span class="gd">-        self.fs = fsspec.filesystem(&#39;file&#39;) if fs is None else fs</span>
<span class="gi">+        self.url = self.root + &quot;/{field}/refs.{record}.parq&quot;</span>
<span class="gi">+        # TODO: derive fs from `root`</span>
<span class="gi">+        self.fs = fsspec.filesystem(&quot;file&quot;) if fs is None else fs</span>

<span class="w"> </span>    def __getattr__(self, item):
<span class="gd">-        if item in (&#39;_items&#39;, &#39;record_size&#39;, &#39;zmetadata&#39;):</span>
<span class="gi">+        if item in (&quot;_items&quot;, &quot;record_size&quot;, &quot;zmetadata&quot;):</span>
<span class="w"> </span>            self.setup()
<span class="gi">+            # avoid possible recursion if setup fails somehow</span>
<span class="w"> </span>            return self.__dict__[item]
<span class="w"> </span>        raise AttributeError(item)

<span class="gi">+    def setup(self):</span>
<span class="gi">+        self._items = {}</span>
<span class="gi">+        self._items[&quot;.zmetadata&quot;] = self.fs.cat_file(</span>
<span class="gi">+            &quot;/&quot;.join([self.root, &quot;.zmetadata&quot;])</span>
<span class="gi">+        )</span>
<span class="gi">+        met = json.loads(self._items[&quot;.zmetadata&quot;])</span>
<span class="gi">+        self.record_size = met[&quot;record_size&quot;]</span>
<span class="gi">+        self.zmetadata = met[&quot;metadata&quot;]</span>
<span class="gi">+</span>
<span class="gi">+        # Define function to open and decompress refs</span>
<span class="gi">+        @lru_cache(maxsize=self.cache_size)</span>
<span class="gi">+        def open_refs(field, record):</span>
<span class="gi">+            &quot;&quot;&quot;cached parquet file loader&quot;&quot;&quot;</span>
<span class="gi">+            path = self.url.format(field=field, record=record)</span>
<span class="gi">+            data = io.BytesIO(self.fs.cat_file(path))</span>
<span class="gi">+            df = self.pd.read_parquet(data, engine=&quot;fastparquet&quot;)</span>
<span class="gi">+            refs = {c: df[c].values for c in df.columns}</span>
<span class="gi">+            return refs</span>
<span class="gi">+</span>
<span class="gi">+        self.open_refs = open_refs</span>
<span class="gi">+</span>
<span class="w"> </span>    @staticmethod
<span class="gd">-    def create(root, storage_options=None, fs=None, record_size=10000, **kwargs</span>
<span class="gd">-        ):</span>
<span class="gi">+    def create(root, storage_options=None, fs=None, record_size=10000, **kwargs):</span>
<span class="w"> </span>        &quot;&quot;&quot;Make empty parquet reference set

<span class="w"> </span>        First deletes the contents of the given directory, if it exists.
<span class="gu">@@ -122,39 +186,177 @@ class LazyReferenceMapper(collections.abc.MutableMapping):</span>
<span class="w"> </span>        -------
<span class="w"> </span>        LazyReferenceMapper instance
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        met = {&quot;metadata&quot;: {}, &quot;record_size&quot;: record_size}</span>
<span class="gi">+        if fs is None:</span>
<span class="gi">+            fs, root = fsspec.core.url_to_fs(root, **(storage_options or {}))</span>
<span class="gi">+        if fs.exists(root):</span>
<span class="gi">+            fs.rm(root, recursive=True)</span>
<span class="gi">+        fs.makedirs(root, exist_ok=True)</span>
<span class="gi">+        fs.pipe(&quot;/&quot;.join([root, &quot;.zmetadata&quot;]), json.dumps(met).encode())</span>
<span class="gi">+        return LazyReferenceMapper(root, fs, **kwargs)</span>

<span class="w"> </span>    def listdir(self, basename=True):
<span class="w"> </span>        &quot;&quot;&quot;List top-level directories&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # cache me?</span>
<span class="gi">+        if self.dirs is None:</span>
<span class="gi">+            dirs = [p.split(&quot;/&quot;, 1)[0] for p in self.zmetadata]</span>
<span class="gi">+            self.dirs = {p for p in dirs if p and not p.startswith(&quot;.&quot;)}</span>
<span class="gi">+        listing = self.dirs</span>
<span class="gi">+        if basename:</span>
<span class="gi">+            listing = [os.path.basename(path) for path in listing]</span>
<span class="gi">+        return listing</span>

<span class="gd">-    def ls(self, path=&#39;&#39;, detail=True):</span>
<span class="gi">+    def ls(self, path=&quot;&quot;, detail=True):</span>
<span class="w"> </span>        &quot;&quot;&quot;Shortcut file listings&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if not path:</span>
<span class="gi">+            dirnames = self.listdir()</span>
<span class="gi">+            others = set(</span>
<span class="gi">+                [&quot;.zmetadata&quot;]</span>
<span class="gi">+                + [name for name in self.zmetadata if &quot;/&quot; not in name]</span>
<span class="gi">+                + [name for name in self._items if &quot;/&quot; not in name]</span>
<span class="gi">+            )</span>
<span class="gi">+            if detail is False:</span>
<span class="gi">+                others.update(dirnames)</span>
<span class="gi">+                return sorted(others)</span>
<span class="gi">+            dirinfo = [</span>
<span class="gi">+                {&quot;name&quot;: name, &quot;type&quot;: &quot;directory&quot;, &quot;size&quot;: 0} for name in dirnames</span>
<span class="gi">+            ]</span>
<span class="gi">+            fileinfo = [</span>
<span class="gi">+                {</span>
<span class="gi">+                    &quot;name&quot;: name,</span>
<span class="gi">+                    &quot;type&quot;: &quot;file&quot;,</span>
<span class="gi">+                    &quot;size&quot;: len(</span>
<span class="gi">+                        json.dumps(self.zmetadata[name])</span>
<span class="gi">+                        if name in self.zmetadata</span>
<span class="gi">+                        else self._items[name]</span>
<span class="gi">+                    ),</span>
<span class="gi">+                }</span>
<span class="gi">+                for name in others</span>
<span class="gi">+            ]</span>
<span class="gi">+            return sorted(dirinfo + fileinfo, key=lambda s: s[&quot;name&quot;])</span>
<span class="gi">+        parts = path.split(&quot;/&quot;, 1)</span>
<span class="gi">+        if len(parts) &gt; 1:</span>
<span class="gi">+            raise FileNotFoundError(&quot;Cannot list within directories right now&quot;)</span>
<span class="gi">+        field = parts[0]</span>
<span class="gi">+        others = set(</span>
<span class="gi">+            [name for name in self.zmetadata if name.startswith(f&quot;{path}/&quot;)]</span>
<span class="gi">+            + [name for name in self._items if name.startswith(f&quot;{path}/&quot;)]</span>
<span class="gi">+        )</span>
<span class="gi">+        fileinfo = [</span>
<span class="gi">+            {</span>
<span class="gi">+                &quot;name&quot;: name,</span>
<span class="gi">+                &quot;type&quot;: &quot;file&quot;,</span>
<span class="gi">+                &quot;size&quot;: len(</span>
<span class="gi">+                    json.dumps(self.zmetadata[name])</span>
<span class="gi">+                    if name in self.zmetadata</span>
<span class="gi">+                    else self._items[name]</span>
<span class="gi">+                ),</span>
<span class="gi">+            }</span>
<span class="gi">+            for name in others</span>
<span class="gi">+        ]</span>
<span class="gi">+        keys = self._keys_in_field(field)</span>
<span class="gi">+</span>
<span class="gi">+        if detail is False:</span>
<span class="gi">+            return list(others) + list(keys)</span>
<span class="gi">+        recs = self._generate_all_records(field)</span>
<span class="gi">+        recinfo = [</span>
<span class="gi">+            {&quot;name&quot;: name, &quot;type&quot;: &quot;file&quot;, &quot;size&quot;: rec[-1]}</span>
<span class="gi">+            for name, rec in zip(keys, recs)</span>
<span class="gi">+            if rec[0]  # filters out path==None, deleted/missing</span>
<span class="gi">+        ]</span>
<span class="gi">+        return fileinfo + recinfo</span>

<span class="w"> </span>    def _load_one_key(self, key):
<span class="w"> </span>        &quot;&quot;&quot;Get the reference for one key

<span class="w"> </span>        Returns bytes, one-element list or three-element list.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if key in self._items:</span>
<span class="gi">+            return self._items[key]</span>
<span class="gi">+        elif key in self.zmetadata:</span>
<span class="gi">+            return json.dumps(self.zmetadata[key]).encode()</span>
<span class="gi">+        elif &quot;/&quot; not in key or self._is_meta(key):</span>
<span class="gi">+            raise KeyError(key)</span>
<span class="gi">+        field, _ = key.rsplit(&quot;/&quot;, 1)</span>
<span class="gi">+        record, ri, chunk_size = self._key_to_record(key)</span>
<span class="gi">+        maybe = self._items.get((field, record), {}).get(ri, False)</span>
<span class="gi">+        if maybe is None:</span>
<span class="gi">+            # explicitly deleted</span>
<span class="gi">+            raise KeyError</span>
<span class="gi">+        elif maybe:</span>
<span class="gi">+            return maybe</span>
<span class="gi">+        elif chunk_size == 0:</span>
<span class="gi">+            return b&quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+        # Chunk keys can be loaded from row group and cached in LRU cache</span>
<span class="gi">+        try:</span>
<span class="gi">+            refs = self.open_refs(field, record)</span>
<span class="gi">+        except (ValueError, TypeError, FileNotFoundError):</span>
<span class="gi">+            raise KeyError(key)</span>
<span class="gi">+        columns = [&quot;path&quot;, &quot;offset&quot;, &quot;size&quot;, &quot;raw&quot;]</span>
<span class="gi">+        selection = [refs[c][ri] if c in refs else None for c in columns]</span>
<span class="gi">+        raw = selection[-1]</span>
<span class="gi">+        if raw is not None:</span>
<span class="gi">+            return raw</span>
<span class="gi">+        if selection[0] is None:</span>
<span class="gi">+            raise KeyError(&quot;This reference does not exist or has been deleted&quot;)</span>
<span class="gi">+        if selection[1:3] == [0, 0]:</span>
<span class="gi">+            # URL only</span>
<span class="gi">+            return selection[:1]</span>
<span class="gi">+        # URL, offset, size</span>
<span class="gi">+        return selection[:3]</span>

<span class="w"> </span>    @lru_cache(4096)
<span class="w"> </span>    def _key_to_record(self, key):
<span class="w"> </span>        &quot;&quot;&quot;Details needed to construct a reference for one key&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        field, chunk = key.rsplit(&quot;/&quot;, 1)</span>
<span class="gi">+        chunk_sizes = self._get_chunk_sizes(field)</span>
<span class="gi">+        if len(chunk_sizes) == 0:</span>
<span class="gi">+            return 0, 0, 0</span>
<span class="gi">+        chunk_idx = [int(c) for c in chunk.split(&quot;.&quot;)]</span>
<span class="gi">+        chunk_number = ravel_multi_index(chunk_idx, chunk_sizes)</span>
<span class="gi">+        record = chunk_number // self.record_size</span>
<span class="gi">+        ri = chunk_number % self.record_size</span>
<span class="gi">+        return record, ri, len(chunk_sizes)</span>

<span class="w"> </span>    def _get_chunk_sizes(self, field):
<span class="w"> </span>        &quot;&quot;&quot;The number of chunks along each axis for a given field&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if field not in self.chunk_sizes:</span>
<span class="gi">+            zarray = self.zmetadata[f&quot;{field}/.zarray&quot;]</span>
<span class="gi">+            size_ratio = [</span>
<span class="gi">+                math.ceil(s / c) for s, c in zip(zarray[&quot;shape&quot;], zarray[&quot;chunks&quot;])</span>
<span class="gi">+            ]</span>
<span class="gi">+            self.chunk_sizes[field] = size_ratio or [1]</span>
<span class="gi">+        return self.chunk_sizes[field]</span>

<span class="w"> </span>    def _generate_record(self, field, record):
<span class="w"> </span>        &quot;&quot;&quot;The references for a given parquet file of a given field&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        refs = self.open_refs(field, record)</span>
<span class="gi">+        it = iter(zip(*refs.values()))</span>
<span class="gi">+        if len(refs) == 3:</span>
<span class="gi">+            # All urls</span>
<span class="gi">+            return (list(t) for t in it)</span>
<span class="gi">+        elif len(refs) == 1:</span>
<span class="gi">+            # All raws</span>
<span class="gi">+            return refs[&quot;raw&quot;]</span>
<span class="gi">+        else:</span>
<span class="gi">+            # Mix of urls and raws</span>
<span class="gi">+            return (list(t[:3]) if not t[3] else t[3] for t in it)</span>

<span class="w"> </span>    def _generate_all_records(self, field):
<span class="w"> </span>        &quot;&quot;&quot;Load all the references within a field by iterating over the parquet files&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        nrec = 1</span>
<span class="gi">+        for ch in self._get_chunk_sizes(field):</span>
<span class="gi">+            nrec *= ch</span>
<span class="gi">+        nrec = math.ceil(nrec / self.record_size)</span>
<span class="gi">+        for record in range(nrec):</span>
<span class="gi">+            yield from self._generate_record(field, record)</span>
<span class="gi">+</span>
<span class="gi">+    def values(self):</span>
<span class="gi">+        return RefsValuesView(self)</span>
<span class="gi">+</span>
<span class="gi">+    def items(self):</span>
<span class="gi">+        return RefsItemsView(self)</span>

<span class="w"> </span>    def __hash__(self):
<span class="w"> </span>        return id(self)
<span class="gu">@@ -163,33 +365,117 @@ class LazyReferenceMapper(collections.abc.MutableMapping):</span>
<span class="w"> </span>        return self._load_one_key(key)

<span class="w"> </span>    def __setitem__(self, key, value):
<span class="gd">-        if &#39;/&#39; in key and not self._is_meta(key):</span>
<span class="gd">-            field, chunk = key.rsplit(&#39;/&#39;, 1)</span>
<span class="gi">+        if &quot;/&quot; in key and not self._is_meta(key):</span>
<span class="gi">+            field, chunk = key.rsplit(&quot;/&quot;, 1)</span>
<span class="w"> </span>            record, i, _ = self._key_to_record(key)
<span class="w"> </span>            subdict = self._items.setdefault((field, record), {})
<span class="w"> </span>            subdict[i] = value
<span class="w"> </span>            if len(subdict) == self.record_size:
<span class="w"> </span>                self.write(field, record)
<span class="w"> </span>        else:
<span class="gi">+            # metadata or top-level</span>
<span class="w"> </span>            self._items[key] = value
<span class="gd">-            new_value = json.loads(value.decode() if isinstance(value,</span>
<span class="gd">-                bytes) else value)</span>
<span class="gi">+            new_value = json.loads(</span>
<span class="gi">+                value.decode() if isinstance(value, bytes) else value</span>
<span class="gi">+            )</span>
<span class="w"> </span>            self.zmetadata[key] = {**self.zmetadata.get(key, {}), **new_value}

<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _is_meta(key):</span>
<span class="gi">+        return key.startswith(&quot;.z&quot;) or &quot;/.z&quot; in key</span>
<span class="gi">+</span>
<span class="w"> </span>    def __delitem__(self, key):
<span class="w"> </span>        if key in self._items:
<span class="w"> </span>            del self._items[key]
<span class="w"> </span>        elif key in self.zmetadata:
<span class="w"> </span>            del self.zmetadata[key]
<span class="gd">-        elif &#39;/&#39; in key and not self._is_meta(key):</span>
<span class="gd">-            field, _ = key.rsplit(&#39;/&#39;, 1)</span>
<span class="gd">-            record, i, _ = self._key_to_record(key)</span>
<span class="gd">-            subdict = self._items.setdefault((field, record), {})</span>
<span class="gd">-            subdict[i] = None</span>
<span class="gd">-            if len(subdict) == self.record_size:</span>
<span class="gd">-                self.write(field, record)</span>
<span class="w"> </span>        else:
<span class="gd">-            self._items[key] = None</span>
<span class="gi">+            if &quot;/&quot; in key and not self._is_meta(key):</span>
<span class="gi">+                field, _ = key.rsplit(&quot;/&quot;, 1)</span>
<span class="gi">+                record, i, _ = self._key_to_record(key)</span>
<span class="gi">+                subdict = self._items.setdefault((field, record), {})</span>
<span class="gi">+                subdict[i] = None</span>
<span class="gi">+                if len(subdict) == self.record_size:</span>
<span class="gi">+                    self.write(field, record)</span>
<span class="gi">+            else:</span>
<span class="gi">+                # metadata or top-level</span>
<span class="gi">+                self._items[key] = None</span>
<span class="gi">+</span>
<span class="gi">+    def write(self, field, record, base_url=None, storage_options=None):</span>
<span class="gi">+        # extra requirements if writing</span>
<span class="gi">+        import kerchunk.df</span>
<span class="gi">+        import numpy as np</span>
<span class="gi">+        import pandas as pd</span>
<span class="gi">+</span>
<span class="gi">+        partition = self._items[(field, record)]</span>
<span class="gi">+        original = False</span>
<span class="gi">+        if len(partition) &lt; self.record_size:</span>
<span class="gi">+            try:</span>
<span class="gi">+                original = self.open_refs(field, record)</span>
<span class="gi">+            except IOError:</span>
<span class="gi">+                pass</span>
<span class="gi">+</span>
<span class="gi">+        if original:</span>
<span class="gi">+            paths = original[&quot;path&quot;]</span>
<span class="gi">+            offsets = original[&quot;offset&quot;]</span>
<span class="gi">+            sizes = original[&quot;size&quot;]</span>
<span class="gi">+            raws = original[&quot;raw&quot;]</span>
<span class="gi">+        else:</span>
<span class="gi">+            paths = np.full(self.record_size, np.nan, dtype=&quot;O&quot;)</span>
<span class="gi">+            offsets = np.zeros(self.record_size, dtype=&quot;int64&quot;)</span>
<span class="gi">+            sizes = np.zeros(self.record_size, dtype=&quot;int64&quot;)</span>
<span class="gi">+            raws = np.full(self.record_size, np.nan, dtype=&quot;O&quot;)</span>
<span class="gi">+        for j, data in partition.items():</span>
<span class="gi">+            if isinstance(data, list):</span>
<span class="gi">+                if (</span>
<span class="gi">+                    str(paths.dtype) == &quot;category&quot;</span>
<span class="gi">+                    and data[0] not in paths.dtype.categories</span>
<span class="gi">+                ):</span>
<span class="gi">+                    paths = paths.add_categories(data[0])</span>
<span class="gi">+                paths[j] = data[0]</span>
<span class="gi">+                if len(data) &gt; 1:</span>
<span class="gi">+                    offsets[j] = data[1]</span>
<span class="gi">+                    sizes[j] = data[2]</span>
<span class="gi">+            elif data is None:</span>
<span class="gi">+                # delete</span>
<span class="gi">+                paths[j] = None</span>
<span class="gi">+                offsets[j] = 0</span>
<span class="gi">+                sizes[j] = 0</span>
<span class="gi">+                raws[j] = None</span>
<span class="gi">+            else:</span>
<span class="gi">+                # this is the only call into kerchunk, could remove</span>
<span class="gi">+                raws[j] = kerchunk.df._proc_raw(data)</span>
<span class="gi">+        # TODO: only save needed columns</span>
<span class="gi">+        df = pd.DataFrame(</span>
<span class="gi">+            {</span>
<span class="gi">+                &quot;path&quot;: paths,</span>
<span class="gi">+                &quot;offset&quot;: offsets,</span>
<span class="gi">+                &quot;size&quot;: sizes,</span>
<span class="gi">+                &quot;raw&quot;: raws,</span>
<span class="gi">+            },</span>
<span class="gi">+            copy=False,</span>
<span class="gi">+        )</span>
<span class="gi">+        if df.path.count() / (df.path.nunique() or 1) &gt; self.cat_thresh:</span>
<span class="gi">+            df[&quot;path&quot;] = df[&quot;path&quot;].astype(&quot;category&quot;)</span>
<span class="gi">+        object_encoding = {&quot;raw&quot;: &quot;bytes&quot;, &quot;path&quot;: &quot;utf8&quot;}</span>
<span class="gi">+        has_nulls = [&quot;path&quot;, &quot;raw&quot;]</span>
<span class="gi">+</span>
<span class="gi">+        fn = f&quot;{base_url or self.out_root}/{field}/refs.{record}.parq&quot;</span>
<span class="gi">+        self.fs.mkdirs(f&quot;{base_url or self.out_root}/{field}&quot;, exist_ok=True)</span>
<span class="gi">+        df.to_parquet(</span>
<span class="gi">+            fn,</span>
<span class="gi">+            engine=&quot;fastparquet&quot;,</span>
<span class="gi">+            storage_options=storage_options</span>
<span class="gi">+            or getattr(self.fs, &quot;storage_options&quot;, None),</span>
<span class="gi">+            compression=&quot;zstd&quot;,</span>
<span class="gi">+            index=False,</span>
<span class="gi">+            stats=False,</span>
<span class="gi">+            object_encoding=object_encoding,</span>
<span class="gi">+            has_nulls=has_nulls,</span>
<span class="gi">+            # **kwargs,</span>
<span class="gi">+        )</span>
<span class="gi">+        partition.clear()</span>
<span class="gi">+        self._items.pop((field, record))</span>

<span class="w"> </span>    def flush(self, base_url=None, storage_options=None):
<span class="w"> </span>        &quot;&quot;&quot;Output any modified or deleted keys
<span class="gu">@@ -199,20 +485,47 @@ class LazyReferenceMapper(collections.abc.MutableMapping):</span>
<span class="w"> </span>        base_url: str
<span class="w"> </span>            Location of the output
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # write what we have so far and clear sub chunks</span>
<span class="gi">+        for thing in list(self._items):</span>
<span class="gi">+            if isinstance(thing, tuple):</span>
<span class="gi">+                field, record = thing</span>
<span class="gi">+                self.write(</span>
<span class="gi">+                    field,</span>
<span class="gi">+                    record,</span>
<span class="gi">+                    base_url=base_url,</span>
<span class="gi">+                    storage_options=storage_options,</span>
<span class="gi">+                )</span>
<span class="gi">+</span>
<span class="gi">+        # gather .zmetadata from self._items and write that too</span>
<span class="gi">+        for k in list(self._items):</span>
<span class="gi">+            if k != &quot;.zmetadata&quot; and &quot;.z&quot; in k:</span>
<span class="gi">+                self.zmetadata[k] = json.loads(self._items.pop(k))</span>
<span class="gi">+        met = {&quot;metadata&quot;: self.zmetadata, &quot;record_size&quot;: self.record_size}</span>
<span class="gi">+        self._items[&quot;.zmetadata&quot;] = json.dumps(met).encode()</span>
<span class="gi">+        self.fs.pipe(</span>
<span class="gi">+            &quot;/&quot;.join([base_url or self.out_root, &quot;.zmetadata&quot;]),</span>
<span class="gi">+            self._items[&quot;.zmetadata&quot;],</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        # TODO: only clear those that we wrote to?</span>
<span class="gi">+        self.open_refs.cache_clear()</span>

<span class="w"> </span>    def __len__(self):
<span class="gi">+        # Caveat: This counts expected references, not actual - but is fast</span>
<span class="w"> </span>        count = 0
<span class="w"> </span>        for field in self.listdir():
<span class="gd">-            if field.startswith(&#39;.&#39;):</span>
<span class="gi">+            if field.startswith(&quot;.&quot;):</span>
<span class="w"> </span>                count += 1
<span class="w"> </span>            else:
<span class="w"> </span>                count += math.prod(self._get_chunk_sizes(field))
<span class="gd">-        count += len(self.zmetadata)</span>
<span class="gi">+        count += len(self.zmetadata)  # all metadata keys</span>
<span class="gi">+        # any other files not in reference partitions</span>
<span class="w"> </span>        count += sum(1 for _ in self._items if not isinstance(_, tuple))
<span class="w"> </span>        return count

<span class="w"> </span>    def __iter__(self):
<span class="gi">+        # Caveat: returns only existing keys, so the number of these does not</span>
<span class="gi">+        #  match len(self)</span>
<span class="w"> </span>        metas = set(self.zmetadata)
<span class="w"> </span>        metas.update(self._items)
<span class="w"> </span>        for bit in metas:
<span class="gu">@@ -235,7 +548,13 @@ class LazyReferenceMapper(collections.abc.MutableMapping):</span>

<span class="w"> </span>        Produces strings like &quot;field/x.y&quot; appropriate from the chunking of the array
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        chunk_sizes = self._get_chunk_sizes(field)</span>
<span class="gi">+        if len(chunk_sizes) == 0:</span>
<span class="gi">+            yield field + &quot;/0&quot;</span>
<span class="gi">+            return</span>
<span class="gi">+        inds = itertools.product(*(range(i) for i in chunk_sizes))</span>
<span class="gi">+        for ind in inds:</span>
<span class="gi">+            yield field + &quot;/&quot; + &quot;.&quot;.join([str(c) for c in ind])</span>


<span class="w"> </span>class ReferenceFileSystem(AsyncFileSystem):
<span class="gu">@@ -253,13 +572,26 @@ class ReferenceFileSystem(AsyncFileSystem):</span>
<span class="w"> </span>    {path0: bytes_data, path1: (target_url, offset, size)}
<span class="w"> </span>    https://github.com/fsspec/kerchunk/blob/main/README.md
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    protocol = &#39;reference&#39;</span>

<span class="gd">-    def __init__(self, fo, target=None, ref_storage_args=None,</span>
<span class="gd">-        target_protocol=None, target_options=None, remote_protocol=None,</span>
<span class="gd">-        remote_options=None, fs=None, template_overrides=None,</span>
<span class="gd">-        simple_templates=True, max_gap=64000, max_block=256000000,</span>
<span class="gd">-        cache_size=128, **kwargs):</span>
<span class="gi">+    protocol = &quot;reference&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        fo,</span>
<span class="gi">+        target=None,</span>
<span class="gi">+        ref_storage_args=None,</span>
<span class="gi">+        target_protocol=None,</span>
<span class="gi">+        target_options=None,</span>
<span class="gi">+        remote_protocol=None,</span>
<span class="gi">+        remote_options=None,</span>
<span class="gi">+        fs=None,</span>
<span class="gi">+        template_overrides=None,</span>
<span class="gi">+        simple_templates=True,</span>
<span class="gi">+        max_gap=64_000,</span>
<span class="gi">+        max_block=256_000_000,</span>
<span class="gi">+        cache_size=128,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Parameters
<span class="w"> </span>        ----------
<span class="gu">@@ -326,61 +658,512 @@ class ReferenceFileSystem(AsyncFileSystem):</span>
<span class="w"> </span>        self.max_gap = max_gap
<span class="w"> </span>        self.max_block = max_block
<span class="w"> </span>        if isinstance(fo, str):
<span class="gd">-            dic = dict(**ref_storage_args or target_options or {}, protocol</span>
<span class="gd">-                =target_protocol)</span>
<span class="gi">+            dic = dict(</span>
<span class="gi">+                **(ref_storage_args or target_options or {}), protocol=target_protocol</span>
<span class="gi">+            )</span>
<span class="w"> </span>            ref_fs, fo2 = fsspec.core.url_to_fs(fo, **dic)
<span class="w"> </span>            if ref_fs.isfile(fo2):
<span class="gd">-                with fsspec.open(fo, &#39;rb&#39;, **dic) as f:</span>
<span class="gd">-                    logger.info(&#39;Read reference from URL %s&#39;, fo)</span>
<span class="gi">+                # text JSON</span>
<span class="gi">+                with fsspec.open(fo, &quot;rb&quot;, **dic) as f:</span>
<span class="gi">+                    logger.info(&quot;Read reference from URL %s&quot;, fo)</span>
<span class="w"> </span>                    text = json.load(f)
<span class="w"> </span>                self._process_references(text, template_overrides)
<span class="w"> </span>            else:
<span class="gd">-                logger.info(&#39;Open lazy reference dict from URL %s&#39;, fo)</span>
<span class="gd">-                self.references = LazyReferenceMapper(fo2, fs=ref_fs,</span>
<span class="gd">-                    cache_size=cache_size)</span>
<span class="gi">+                # Lazy parquet refs</span>
<span class="gi">+                logger.info(&quot;Open lazy reference dict from URL %s&quot;, fo)</span>
<span class="gi">+                self.references = LazyReferenceMapper(</span>
<span class="gi">+                    fo2,</span>
<span class="gi">+                    fs=ref_fs,</span>
<span class="gi">+                    cache_size=cache_size,</span>
<span class="gi">+                )</span>
<span class="w"> </span>        else:
<span class="gi">+            # dictionaries</span>
<span class="w"> </span>            self._process_references(fo, template_overrides)
<span class="w"> </span>        if isinstance(fs, dict):
<span class="gd">-            self.fss = {k: (fsspec.filesystem(k.split(&#39;:&#39;, 1)[0], **opts) if</span>
<span class="gd">-                isinstance(opts, dict) else opts) for k, opts in fs.items()}</span>
<span class="gi">+            self.fss = {</span>
<span class="gi">+                k: (</span>
<span class="gi">+                    fsspec.filesystem(k.split(&quot;:&quot;, 1)[0], **opts)</span>
<span class="gi">+                    if isinstance(opts, dict)</span>
<span class="gi">+                    else opts</span>
<span class="gi">+                )</span>
<span class="gi">+                for k, opts in fs.items()</span>
<span class="gi">+            }</span>
<span class="w"> </span>            if None not in self.fss:
<span class="gd">-                self.fss[None] = filesystem(&#39;file&#39;)</span>
<span class="gi">+                self.fss[None] = filesystem(&quot;file&quot;)</span>
<span class="w"> </span>            return
<span class="w"> </span>        if fs is not None:
<span class="gd">-            remote_protocol = fs.protocol[0] if isinstance(fs.protocol, tuple</span>
<span class="gd">-                ) else fs.protocol</span>
<span class="gi">+            # single remote FS</span>
<span class="gi">+            remote_protocol = (</span>
<span class="gi">+                fs.protocol[0] if isinstance(fs.protocol, tuple) else fs.protocol</span>
<span class="gi">+            )</span>
<span class="w"> </span>            self.fss[remote_protocol] = fs
<span class="gi">+</span>
<span class="w"> </span>        if remote_protocol is None:
<span class="gi">+            # get single protocol from any templates</span>
<span class="w"> </span>            for ref in self.templates.values():
<span class="w"> </span>                if callable(ref):
<span class="w"> </span>                    ref = ref()
<span class="w"> </span>                protocol, _ = fsspec.core.split_protocol(ref)
<span class="w"> </span>                if protocol and protocol not in self.fss:
<span class="gd">-                    fs = filesystem(protocol, **remote_options or {})</span>
<span class="gi">+                    fs = filesystem(protocol, **(remote_options or {}))</span>
<span class="w"> </span>                    self.fss[protocol] = fs
<span class="w"> </span>        if remote_protocol is None:
<span class="gi">+            # get single protocol from references</span>
<span class="gi">+            # TODO: warning here, since this can be very expensive?</span>
<span class="w"> </span>            for ref in self.references.values():
<span class="w"> </span>                if callable(ref):
<span class="w"> </span>                    ref = ref()
<span class="w"> </span>                if isinstance(ref, list) and ref[0]:
<span class="w"> </span>                    protocol, _ = fsspec.core.split_protocol(ref[0])
<span class="w"> </span>                    if protocol not in self.fss:
<span class="gd">-                        fs = filesystem(protocol, **remote_options or {})</span>
<span class="gi">+                        fs = filesystem(protocol, **(remote_options or {}))</span>
<span class="w"> </span>                        self.fss[protocol] = fs
<span class="gi">+                        # only use first remote URL</span>
<span class="w"> </span>                        break
<span class="gi">+</span>
<span class="w"> </span>        if remote_protocol and remote_protocol not in self.fss:
<span class="gd">-            fs = filesystem(remote_protocol, **remote_options or {})</span>
<span class="gi">+            fs = filesystem(remote_protocol, **(remote_options or {}))</span>
<span class="w"> </span>            self.fss[remote_protocol] = fs
<span class="gd">-        self.fss[None] = fs or filesystem(&#39;file&#39;)</span>
<span class="gi">+</span>
<span class="gi">+        self.fss[None] = fs or filesystem(&quot;file&quot;)  # default one</span>
<span class="gi">+</span>
<span class="gi">+    def _cat_common(self, path, start=None, end=None):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        logger.debug(f&quot;cat: {path}&quot;)</span>
<span class="gi">+        try:</span>
<span class="gi">+            part = self.references[path]</span>
<span class="gi">+        except KeyError:</span>
<span class="gi">+            raise FileNotFoundError(path)</span>
<span class="gi">+        if isinstance(part, str):</span>
<span class="gi">+            part = part.encode()</span>
<span class="gi">+        if isinstance(part, bytes):</span>
<span class="gi">+            logger.debug(f&quot;Reference: {path}, type bytes&quot;)</span>
<span class="gi">+            if part.startswith(b&quot;base64:&quot;):</span>
<span class="gi">+                part = base64.b64decode(part[7:])</span>
<span class="gi">+            return part, None, None</span>
<span class="gi">+</span>
<span class="gi">+        if len(part) == 1:</span>
<span class="gi">+            logger.debug(f&quot;Reference: {path}, whole file =&gt; {part}&quot;)</span>
<span class="gi">+            url = part[0]</span>
<span class="gi">+            start1, end1 = start, end</span>
<span class="gi">+        else:</span>
<span class="gi">+            url, start0, size = part</span>
<span class="gi">+            logger.debug(f&quot;Reference: {path} =&gt; {url}, offset {start0}, size {size}&quot;)</span>
<span class="gi">+            end0 = start0 + size</span>
<span class="gi">+</span>
<span class="gi">+            if start is not None:</span>
<span class="gi">+                if start &gt;= 0:</span>
<span class="gi">+                    start1 = start0 + start</span>
<span class="gi">+                else:</span>
<span class="gi">+                    start1 = end0 + start</span>
<span class="gi">+            else:</span>
<span class="gi">+                start1 = start0</span>
<span class="gi">+            if end is not None:</span>
<span class="gi">+                if end &gt;= 0:</span>
<span class="gi">+                    end1 = start0 + end</span>
<span class="gi">+                else:</span>
<span class="gi">+                    end1 = end0 + end</span>
<span class="gi">+            else:</span>
<span class="gi">+                end1 = end0</span>
<span class="gi">+        if url is None:</span>
<span class="gi">+            url = self.target</span>
<span class="gi">+        return url, start1, end1</span>
<span class="gi">+</span>
<span class="gi">+    async def _cat_file(self, path, start=None, end=None, **kwargs):</span>
<span class="gi">+        part_or_url, start0, end0 = self._cat_common(path, start=start, end=end)</span>
<span class="gi">+        if isinstance(part_or_url, bytes):</span>
<span class="gi">+            return part_or_url[start:end]</span>
<span class="gi">+        protocol, _ = split_protocol(part_or_url)</span>
<span class="gi">+        try:</span>
<span class="gi">+            await self.fss[protocol]._cat_file(part_or_url, start=start, end=end)</span>
<span class="gi">+        except Exception as e:</span>
<span class="gi">+            raise ReferenceNotReachable(path, part_or_url) from e</span>
<span class="gi">+</span>
<span class="gi">+    def cat_file(self, path, start=None, end=None, **kwargs):</span>
<span class="gi">+        part_or_url, start0, end0 = self._cat_common(path, start=start, end=end)</span>
<span class="gi">+        if isinstance(part_or_url, bytes):</span>
<span class="gi">+            return part_or_url[start:end]</span>
<span class="gi">+        protocol, _ = split_protocol(part_or_url)</span>
<span class="gi">+        try:</span>
<span class="gi">+            return self.fss[protocol].cat_file(part_or_url, start=start0, end=end0)</span>
<span class="gi">+        except Exception as e:</span>
<span class="gi">+            raise ReferenceNotReachable(path, part_or_url) from e</span>

<span class="w"> </span>    def pipe_file(self, path, value, **_):
<span class="w"> </span>        &quot;&quot;&quot;Temporarily add binary data or reference as a file&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.references[path] = value</span>
<span class="gi">+</span>
<span class="gi">+    async def _get_file(self, rpath, lpath, **kwargs):</span>
<span class="gi">+        if self.isdir(rpath):</span>
<span class="gi">+            return os.makedirs(lpath, exist_ok=True)</span>
<span class="gi">+        data = await self._cat_file(rpath)</span>
<span class="gi">+        with open(lpath, &quot;wb&quot;) as f:</span>
<span class="gi">+            f.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    def get_file(self, rpath, lpath, callback=DEFAULT_CALLBACK, **kwargs):</span>
<span class="gi">+        if self.isdir(rpath):</span>
<span class="gi">+            return os.makedirs(lpath, exist_ok=True)</span>
<span class="gi">+        data = self.cat_file(rpath, **kwargs)</span>
<span class="gi">+        callback.set_size(len(data))</span>
<span class="gi">+        if isfilelike(lpath):</span>
<span class="gi">+            lpath.write(data)</span>
<span class="gi">+        else:</span>
<span class="gi">+            with open(lpath, &quot;wb&quot;) as f:</span>
<span class="gi">+                f.write(data)</span>
<span class="gi">+        callback.absolute_update(len(data))</span>
<span class="gi">+</span>
<span class="gi">+    def get(self, rpath, lpath, recursive=False, **kwargs):</span>
<span class="gi">+        if recursive:</span>
<span class="gi">+            # trigger directory build</span>
<span class="gi">+            self.ls(&quot;&quot;)</span>
<span class="gi">+        rpath = self.expand_path(rpath, recursive=recursive)</span>
<span class="gi">+        fs = fsspec.filesystem(&quot;file&quot;, auto_mkdir=True)</span>
<span class="gi">+        targets = other_paths(rpath, lpath)</span>
<span class="gi">+        if recursive:</span>
<span class="gi">+            data = self.cat([r for r in rpath if not self.isdir(r)])</span>
<span class="gi">+        else:</span>
<span class="gi">+            data = self.cat(rpath)</span>
<span class="gi">+        for remote, local in zip(rpath, targets):</span>
<span class="gi">+            if remote in data:</span>
<span class="gi">+                fs.pipe_file(local, data[remote])</span>
<span class="gi">+</span>
<span class="gi">+    def cat(self, path, recursive=False, on_error=&quot;raise&quot;, **kwargs):</span>
<span class="gi">+        if isinstance(path, str) and recursive:</span>
<span class="gi">+            raise NotImplementedError</span>
<span class="gi">+        if isinstance(path, list) and (recursive or any(&quot;*&quot; in p for p in path)):</span>
<span class="gi">+            raise NotImplementedError</span>
<span class="gi">+        # TODO: if references is lazy, pre-fetch all paths in batch before access</span>
<span class="gi">+        proto_dict = _protocol_groups(path, self.references)</span>
<span class="gi">+        out = {}</span>
<span class="gi">+        for proto, paths in proto_dict.items():</span>
<span class="gi">+            fs = self.fss[proto]</span>
<span class="gi">+            urls, starts, ends, valid_paths = [], [], [], []</span>
<span class="gi">+            for p in paths:</span>
<span class="gi">+                # find references or label not-found. Early exit if any not</span>
<span class="gi">+                # found and on_error is &quot;raise&quot;</span>
<span class="gi">+                try:</span>
<span class="gi">+                    u, s, e = self._cat_common(p)</span>
<span class="gi">+                except FileNotFoundError as err:</span>
<span class="gi">+                    if on_error == &quot;raise&quot;:</span>
<span class="gi">+                        raise</span>
<span class="gi">+                    if on_error != &quot;omit&quot;:</span>
<span class="gi">+                        out[p] = err</span>
<span class="gi">+                else:</span>
<span class="gi">+                    urls.append(u)</span>
<span class="gi">+                    starts.append(s)</span>
<span class="gi">+                    ends.append(e)</span>
<span class="gi">+                    valid_paths.append(p)</span>
<span class="gi">+</span>
<span class="gi">+            # process references into form for merging</span>
<span class="gi">+            urls2 = []</span>
<span class="gi">+            starts2 = []</span>
<span class="gi">+            ends2 = []</span>
<span class="gi">+            paths2 = []</span>
<span class="gi">+            whole_files = set()</span>
<span class="gi">+            for u, s, e, p in zip(urls, starts, ends, valid_paths):</span>
<span class="gi">+                if isinstance(u, bytes):</span>
<span class="gi">+                    # data</span>
<span class="gi">+                    out[p] = u</span>
<span class="gi">+                elif s is None:</span>
<span class="gi">+                    # whole file - limits are None, None, but no further</span>
<span class="gi">+                    # entries take for this file</span>
<span class="gi">+                    whole_files.add(u)</span>
<span class="gi">+                    urls2.append(u)</span>
<span class="gi">+                    starts2.append(s)</span>
<span class="gi">+                    ends2.append(e)</span>
<span class="gi">+                    paths2.append(p)</span>
<span class="gi">+            for u, s, e, p in zip(urls, starts, ends, valid_paths):</span>
<span class="gi">+                # second run to account for files that are to be loaded whole</span>
<span class="gi">+                if s is not None and u not in whole_files:</span>
<span class="gi">+                    urls2.append(u)</span>
<span class="gi">+                    starts2.append(s)</span>
<span class="gi">+                    ends2.append(e)</span>
<span class="gi">+                    paths2.append(p)</span>
<span class="gi">+</span>
<span class="gi">+            # merge and fetch consolidated ranges</span>
<span class="gi">+            new_paths, new_starts, new_ends = merge_offset_ranges(</span>
<span class="gi">+                list(urls2),</span>
<span class="gi">+                list(starts2),</span>
<span class="gi">+                list(ends2),</span>
<span class="gi">+                sort=True,</span>
<span class="gi">+                max_gap=self.max_gap,</span>
<span class="gi">+                max_block=self.max_block,</span>
<span class="gi">+            )</span>
<span class="gi">+            bytes_out = fs.cat_ranges(new_paths, new_starts, new_ends)</span>
<span class="gi">+</span>
<span class="gi">+            # unbundle from merged bytes - simple approach</span>
<span class="gi">+            for u, s, e, p in zip(urls, starts, ends, valid_paths):</span>
<span class="gi">+                if p in out:</span>
<span class="gi">+                    continue  # was bytes, already handled</span>
<span class="gi">+                for np, ns, ne, b in zip(new_paths, new_starts, new_ends, bytes_out):</span>
<span class="gi">+                    if np == u and (ns is None or ne is None):</span>
<span class="gi">+                        if isinstance(b, Exception):</span>
<span class="gi">+                            out[p] = b</span>
<span class="gi">+                        else:</span>
<span class="gi">+                            out[p] = b[s:e]</span>
<span class="gi">+                    elif np == u and s &gt;= ns and e &lt;= ne:</span>
<span class="gi">+                        if isinstance(b, Exception):</span>
<span class="gi">+                            out[p] = b</span>
<span class="gi">+                        else:</span>
<span class="gi">+                            out[p] = b[s - ns : (e - ne) or None]</span>
<span class="gi">+</span>
<span class="gi">+        for k, v in out.copy().items():</span>
<span class="gi">+            # these were valid references, but fetch failed, so transform exc</span>
<span class="gi">+            if isinstance(v, Exception) and k in self.references:</span>
<span class="gi">+                ex = out[k]</span>
<span class="gi">+                new_ex = ReferenceNotReachable(k, self.references[k])</span>
<span class="gi">+                new_ex.__cause__ = ex</span>
<span class="gi">+                if on_error == &quot;raise&quot;:</span>
<span class="gi">+                    raise new_ex</span>
<span class="gi">+                elif on_error != &quot;omit&quot;:</span>
<span class="gi">+                    out[k] = new_ex</span>
<span class="gi">+</span>
<span class="gi">+        if len(out) == 1 and isinstance(path, str) and &quot;*&quot; not in path:</span>
<span class="gi">+            return _first(out)</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    def _process_references(self, references, template_overrides=None):</span>
<span class="gi">+        vers = references.get(&quot;version&quot;, None)</span>
<span class="gi">+        if vers is None:</span>
<span class="gi">+            self._process_references0(references)</span>
<span class="gi">+        elif vers == 1:</span>
<span class="gi">+            self._process_references1(references, template_overrides=template_overrides)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise ValueError(f&quot;Unknown reference spec version: {vers}&quot;)</span>
<span class="gi">+        # TODO: we make dircache by iterating over all entries, but for Spec &gt;= 1,</span>
<span class="gi">+        #  can replace with programmatic. Is it even needed for mapper interface?</span>

<span class="w"> </span>    def _process_references0(self, references):
<span class="w"> </span>        &quot;&quot;&quot;Make reference dict for Spec Version 0&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(references, dict):</span>
<span class="gi">+            # do not do this for lazy/parquet backend, which will not make dicts,</span>
<span class="gi">+            # but must remain writable in the original object</span>
<span class="gi">+            references = {</span>
<span class="gi">+                key: json.dumps(val) if isinstance(val, dict) else val</span>
<span class="gi">+                for key, val in references.items()</span>
<span class="gi">+            }</span>
<span class="gi">+        self.references = references</span>
<span class="gi">+</span>
<span class="gi">+    def _process_references1(self, references, template_overrides=None):</span>
<span class="gi">+        if not self.simple_templates or self.templates:</span>
<span class="gi">+            import jinja2</span>
<span class="gi">+        self.references = {}</span>
<span class="gi">+        self._process_templates(references.get(&quot;templates&quot;, {}))</span>
<span class="gi">+</span>
<span class="gi">+        @lru_cache(1000)</span>
<span class="gi">+        def _render_jinja(u):</span>
<span class="gi">+            return jinja2.Template(u).render(**self.templates)</span>
<span class="gi">+</span>
<span class="gi">+        for k, v in references.get(&quot;refs&quot;, {}).items():</span>
<span class="gi">+            if isinstance(v, str):</span>
<span class="gi">+                if v.startswith(&quot;base64:&quot;):</span>
<span class="gi">+                    self.references[k] = base64.b64decode(v[7:])</span>
<span class="gi">+                self.references[k] = v</span>
<span class="gi">+            elif isinstance(v, dict):</span>
<span class="gi">+                self.references[k] = json.dumps(v)</span>
<span class="gi">+            elif self.templates:</span>
<span class="gi">+                u = v[0]</span>
<span class="gi">+                if &quot;{{&quot; in u:</span>
<span class="gi">+                    if self.simple_templates:</span>
<span class="gi">+                        u = (</span>
<span class="gi">+                            u.replace(&quot;{{&quot;, &quot;{&quot;)</span>
<span class="gi">+                            .replace(&quot;}}&quot;, &quot;}&quot;)</span>
<span class="gi">+                            .format(**self.templates)</span>
<span class="gi">+                        )</span>
<span class="gi">+                    else:</span>
<span class="gi">+                        u = _render_jinja(u)</span>
<span class="gi">+                self.references[k] = [u] if len(v) == 1 else [u, v[1], v[2]]</span>
<span class="gi">+            else:</span>
<span class="gi">+                self.references[k] = v</span>
<span class="gi">+        self.references.update(self._process_gen(references.get(&quot;gen&quot;, [])))</span>
<span class="gi">+</span>
<span class="gi">+    def _process_templates(self, tmp):</span>
<span class="gi">+        self.templates = {}</span>
<span class="gi">+        if self.template_overrides is not None:</span>
<span class="gi">+            tmp.update(self.template_overrides)</span>
<span class="gi">+        for k, v in tmp.items():</span>
<span class="gi">+            if &quot;{{&quot; in v:</span>
<span class="gi">+                import jinja2</span>
<span class="gi">+</span>
<span class="gi">+                self.templates[k] = lambda temp=v, **kwargs: jinja2.Template(</span>
<span class="gi">+                    temp</span>
<span class="gi">+                ).render(**kwargs)</span>
<span class="gi">+            else:</span>
<span class="gi">+                self.templates[k] = v</span>
<span class="gi">+</span>
<span class="gi">+    def _process_gen(self, gens):</span>
<span class="gi">+        out = {}</span>
<span class="gi">+        for gen in gens:</span>
<span class="gi">+            dimension = {</span>
<span class="gi">+                k: v</span>
<span class="gi">+                if isinstance(v, list)</span>
<span class="gi">+                else range(v.get(&quot;start&quot;, 0), v[&quot;stop&quot;], v.get(&quot;step&quot;, 1))</span>
<span class="gi">+                for k, v in gen[&quot;dimensions&quot;].items()</span>
<span class="gi">+            }</span>
<span class="gi">+            products = (</span>
<span class="gi">+                dict(zip(dimension.keys(), values))</span>
<span class="gi">+                for values in itertools.product(*dimension.values())</span>
<span class="gi">+            )</span>
<span class="gi">+            for pr in products:</span>
<span class="gi">+                import jinja2</span>
<span class="gi">+</span>
<span class="gi">+                key = jinja2.Template(gen[&quot;key&quot;]).render(**pr, **self.templates)</span>
<span class="gi">+                url = jinja2.Template(gen[&quot;url&quot;]).render(**pr, **self.templates)</span>
<span class="gi">+                if (&quot;offset&quot; in gen) and (&quot;length&quot; in gen):</span>
<span class="gi">+                    offset = int(</span>
<span class="gi">+                        jinja2.Template(gen[&quot;offset&quot;]).render(**pr, **self.templates)</span>
<span class="gi">+                    )</span>
<span class="gi">+                    length = int(</span>
<span class="gi">+                        jinja2.Template(gen[&quot;length&quot;]).render(**pr, **self.templates)</span>
<span class="gi">+                    )</span>
<span class="gi">+                    out[key] = [url, offset, length]</span>
<span class="gi">+                elif (&quot;offset&quot; in gen) ^ (&quot;length&quot; in gen):</span>
<span class="gi">+                    raise ValueError(</span>
<span class="gi">+                        &quot;Both &#39;offset&#39; and &#39;length&#39; are required for a &quot;</span>
<span class="gi">+                        &quot;reference generator entry if either is provided.&quot;</span>
<span class="gi">+                    )</span>
<span class="gi">+                else:</span>
<span class="gi">+                    out[key] = [url]</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    def _dircache_from_items(self):</span>
<span class="gi">+        self.dircache = {&quot;&quot;: []}</span>
<span class="gi">+        it = self.references.items()</span>
<span class="gi">+        for path, part in it:</span>
<span class="gi">+            if isinstance(part, (bytes, str)):</span>
<span class="gi">+                size = len(part)</span>
<span class="gi">+            elif len(part) == 1:</span>
<span class="gi">+                size = None</span>
<span class="gi">+            else:</span>
<span class="gi">+                _, _, size = part</span>
<span class="gi">+            par = path.rsplit(&quot;/&quot;, 1)[0] if &quot;/&quot; in path else &quot;&quot;</span>
<span class="gi">+            par0 = par</span>
<span class="gi">+            subdirs = [par0]</span>
<span class="gi">+            while par0 and par0 not in self.dircache:</span>
<span class="gi">+                # collect parent directories</span>
<span class="gi">+                par0 = self._parent(par0)</span>
<span class="gi">+                subdirs.append(par0)</span>
<span class="gi">+</span>
<span class="gi">+            subdirs.reverse()</span>
<span class="gi">+            for parent, child in zip(subdirs, subdirs[1:]):</span>
<span class="gi">+                # register newly discovered directories</span>
<span class="gi">+                assert child not in self.dircache</span>
<span class="gi">+                assert parent in self.dircache</span>
<span class="gi">+                self.dircache[parent].append(</span>
<span class="gi">+                    {&quot;name&quot;: child, &quot;type&quot;: &quot;directory&quot;, &quot;size&quot;: 0}</span>
<span class="gi">+                )</span>
<span class="gi">+                self.dircache[child] = []</span>
<span class="gi">+</span>
<span class="gi">+            self.dircache[par].append({&quot;name&quot;: path, &quot;type&quot;: &quot;file&quot;, &quot;size&quot;: size})</span>
<span class="gi">+</span>
<span class="gi">+    def _open(self, path, mode=&quot;rb&quot;, block_size=None, cache_options=None, **kwargs):</span>
<span class="gi">+        data = self.cat_file(path)  # load whole chunk into memory</span>
<span class="gi">+        return io.BytesIO(data)</span>
<span class="gi">+</span>
<span class="gi">+    def ls(self, path, detail=True, **kwargs):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if isinstance(self.references, LazyReferenceMapper):</span>
<span class="gi">+            try:</span>
<span class="gi">+                return self.references.ls(path, detail)</span>
<span class="gi">+            except KeyError:</span>
<span class="gi">+                pass</span>
<span class="gi">+            raise FileNotFoundError(f&quot;&#39;{path}&#39; is not a known key&quot;)</span>
<span class="gi">+        if not self.dircache:</span>
<span class="gi">+            self._dircache_from_items()</span>
<span class="gi">+        out = self._ls_from_cache(path)</span>
<span class="gi">+        if out is None:</span>
<span class="gi">+            raise FileNotFoundError(path)</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return out</span>
<span class="gi">+        return [o[&quot;name&quot;] for o in out]</span>
<span class="gi">+</span>
<span class="gi">+    def exists(self, path, **kwargs):  # overwrite auto-sync version</span>
<span class="gi">+        return self.isdir(path) or self.isfile(path)</span>
<span class="gi">+</span>
<span class="gi">+    def isdir(self, path):  # overwrite auto-sync version</span>
<span class="gi">+        if self.dircache:</span>
<span class="gi">+            return path in self.dircache</span>
<span class="gi">+        elif isinstance(self.references, LazyReferenceMapper):</span>
<span class="gi">+            return path in self.references.listdir(&quot;&quot;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            # this may be faster than building dircache for single calls, but</span>
<span class="gi">+            # by looping will be slow for many calls; could cache it?</span>
<span class="gi">+            return any(_.startswith(f&quot;{path}/&quot;) for _ in self.references)</span>
<span class="gi">+</span>
<span class="gi">+    def isfile(self, path):  # overwrite auto-sync version</span>
<span class="gi">+        return path in self.references</span>
<span class="gi">+</span>
<span class="gi">+    async def _ls(self, path, detail=True, **kwargs):  # calls fast sync code</span>
<span class="gi">+        return self.ls(path, detail, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def find(self, path, maxdepth=None, withdirs=False, detail=False, **kwargs):</span>
<span class="gi">+        if withdirs:</span>
<span class="gi">+            return super().find(</span>
<span class="gi">+                path, maxdepth=maxdepth, withdirs=withdirs, detail=detail, **kwargs</span>
<span class="gi">+            )</span>
<span class="gi">+        if path:</span>
<span class="gi">+            path = self._strip_protocol(path)</span>
<span class="gi">+            r = sorted(k for k in self.references if k.startswith(path))</span>
<span class="gi">+        else:</span>
<span class="gi">+            r = sorted(self.references)</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            if not self.dircache:</span>
<span class="gi">+                self._dircache_from_items()</span>
<span class="gi">+            return {k: self._ls_from_cache(k)[0] for k in r}</span>
<span class="gi">+        else:</span>
<span class="gi">+            return r</span>
<span class="gi">+</span>
<span class="gi">+    def info(self, path, **kwargs):</span>
<span class="gi">+        out = self.references.get(path)</span>
<span class="gi">+        if out is not None:</span>
<span class="gi">+            if isinstance(out, (str, bytes)):</span>
<span class="gi">+                # decode base64 here</span>
<span class="gi">+                return {&quot;name&quot;: path, &quot;type&quot;: &quot;file&quot;, &quot;size&quot;: len(out)}</span>
<span class="gi">+            elif len(out) &gt; 1:</span>
<span class="gi">+                return {&quot;name&quot;: path, &quot;type&quot;: &quot;file&quot;, &quot;size&quot;: out[2]}</span>
<span class="gi">+            else:</span>
<span class="gi">+                out0 = [{&quot;name&quot;: path, &quot;type&quot;: &quot;file&quot;, &quot;size&quot;: None}]</span>
<span class="gi">+        else:</span>
<span class="gi">+            out = self.ls(path, True)</span>
<span class="gi">+            out0 = [o for o in out if o[&quot;name&quot;] == path]</span>
<span class="gi">+            if not out0:</span>
<span class="gi">+                return {&quot;name&quot;: path, &quot;type&quot;: &quot;directory&quot;, &quot;size&quot;: 0}</span>
<span class="gi">+        if out0[0][&quot;size&quot;] is None:</span>
<span class="gi">+            # if this is a whole remote file, update size using remote FS</span>
<span class="gi">+            prot, _ = split_protocol(self.references[path][0])</span>
<span class="gi">+            out0[0][&quot;size&quot;] = self.fss[prot].size(self.references[path][0])</span>
<span class="gi">+        return out0[0]</span>
<span class="gi">+</span>
<span class="gi">+    async def _info(self, path, **kwargs):  # calls fast sync code</span>
<span class="gi">+        return self.info(path)</span>
<span class="gi">+</span>
<span class="gi">+    async def _rm_file(self, path, **kwargs):</span>
<span class="gi">+        self.references.pop(</span>
<span class="gi">+            path, None</span>
<span class="gi">+        )  # ignores FileNotFound, just as well for directories</span>
<span class="gi">+        self.dircache.clear()  # this is a bit heavy handed</span>
<span class="gi">+</span>
<span class="gi">+    async def _pipe_file(self, path, data):</span>
<span class="gi">+        # can be str or bytes</span>
<span class="gi">+        self.references[path] = data</span>
<span class="gi">+        self.dircache.clear()  # this is a bit heavy handed</span>
<span class="gi">+</span>
<span class="gi">+    async def _put_file(self, lpath, rpath, **kwargs):</span>
<span class="gi">+        # puts binary</span>
<span class="gi">+        with open(lpath, &quot;rb&quot;) as f:</span>
<span class="gi">+            self.references[rpath] = f.read()</span>
<span class="gi">+        self.dircache.clear()  # this is a bit heavy handed</span>

<span class="w"> </span>    def save_json(self, url, **storage_options):
<span class="w"> </span>        &quot;&quot;&quot;Write modified references into new location&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        out = {}</span>
<span class="gi">+        for k, v in self.references.items():</span>
<span class="gi">+            if isinstance(v, bytes):</span>
<span class="gi">+                try:</span>
<span class="gi">+                    out[k] = v.decode(&quot;ascii&quot;)</span>
<span class="gi">+                except UnicodeDecodeError:</span>
<span class="gi">+                    out[k] = (b&quot;base64:&quot; + base64.b64encode(v)).decode()</span>
<span class="gi">+            else:</span>
<span class="gi">+                out[k] = v</span>
<span class="gi">+        with fsspec.open(url, &quot;wb&quot;, **storage_options) as f:</span>
<span class="gi">+            f.write(json.dumps({&quot;version&quot;: 1, &quot;refs&quot;: out}).encode())</span>
<span class="gh">diff --git a/fsspec/implementations/sftp.py b/fsspec/implementations/sftp.py</span>
<span class="gh">index 95b7f25..77f7b37 100644</span>
<span class="gd">--- a/fsspec/implementations/sftp.py</span>
<span class="gi">+++ b/fsspec/implementations/sftp.py</span>
<span class="gu">@@ -4,10 +4,13 @@ import os</span>
<span class="w"> </span>import types
<span class="w"> </span>import uuid
<span class="w"> </span>from stat import S_ISDIR, S_ISLNK
<span class="gi">+</span>
<span class="w"> </span>import paramiko
<span class="gi">+</span>
<span class="w"> </span>from .. import AbstractFileSystem
<span class="w"> </span>from ..utils import infer_storage_options
<span class="gd">-logger = logging.getLogger(&#39;fsspec.sftp&#39;)</span>
<span class="gi">+</span>
<span class="gi">+logger = logging.getLogger(&quot;fsspec.sftp&quot;)</span>


<span class="w"> </span>class SFTPFileSystem(AbstractFileSystem):
<span class="gu">@@ -19,7 +22,8 @@ class SFTPFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>    there is no way to tell if a path is relative, so all paths are assumed
<span class="w"> </span>    to be absolute.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    protocol = &#39;sftp&#39;, &#39;ssh&#39;</span>
<span class="gi">+</span>
<span class="gi">+    protocol = &quot;sftp&quot;, &quot;ssh&quot;</span>

<span class="w"> </span>    def __init__(self, host, **ssh_kwargs):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -38,15 +42,139 @@ class SFTPFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        if self._cached:
<span class="w"> </span>            return
<span class="w"> </span>        super().__init__(**ssh_kwargs)
<span class="gd">-        self.temppath = ssh_kwargs.pop(&#39;temppath&#39;, &#39;/tmp&#39;)</span>
<span class="gi">+        self.temppath = ssh_kwargs.pop(&quot;temppath&quot;, &quot;/tmp&quot;)  # remote temp directory</span>
<span class="w"> </span>        self.host = host
<span class="w"> </span>        self.ssh_kwargs = ssh_kwargs
<span class="w"> </span>        self._connect()

<span class="gd">-    def _open(self, path, mode=&#39;rb&#39;, block_size=None, **kwargs):</span>
<span class="gi">+    def _connect(self):</span>
<span class="gi">+        logger.debug(&quot;Connecting to SFTP server %s&quot;, self.host)</span>
<span class="gi">+        self.client = paramiko.SSHClient()</span>
<span class="gi">+        self.client.set_missing_host_key_policy(paramiko.AutoAddPolicy())</span>
<span class="gi">+        self.client.connect(self.host, **self.ssh_kwargs)</span>
<span class="gi">+        self.ftp = self.client.open_sftp()</span>
<span class="gi">+</span>
<span class="gi">+    @classmethod</span>
<span class="gi">+    def _strip_protocol(cls, path):</span>
<span class="gi">+        return infer_storage_options(path)[&quot;path&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _get_kwargs_from_urls(urlpath):</span>
<span class="gi">+        out = infer_storage_options(urlpath)</span>
<span class="gi">+        out.pop(&quot;path&quot;, None)</span>
<span class="gi">+        out.pop(&quot;protocol&quot;, None)</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    def mkdir(self, path, create_parents=True, mode=511):</span>
<span class="gi">+        logger.debug(&quot;Creating folder %s&quot;, path)</span>
<span class="gi">+        if self.exists(path):</span>
<span class="gi">+            raise FileExistsError(f&quot;File exists: {path}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        if create_parents:</span>
<span class="gi">+            self.makedirs(path)</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.ftp.mkdir(path, mode)</span>
<span class="gi">+</span>
<span class="gi">+    def makedirs(self, path, exist_ok=False, mode=511):</span>
<span class="gi">+        if self.exists(path) and not exist_ok:</span>
<span class="gi">+            raise FileExistsError(f&quot;File exists: {path}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        parts = path.split(&quot;/&quot;)</span>
<span class="gi">+        new_path = &quot;/&quot; if path[:1] == &quot;/&quot; else &quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+        for part in parts:</span>
<span class="gi">+            if part:</span>
<span class="gi">+                new_path = f&quot;{new_path}/{part}&quot; if new_path else part</span>
<span class="gi">+                if not self.exists(new_path):</span>
<span class="gi">+                    self.ftp.mkdir(new_path, mode)</span>
<span class="gi">+</span>
<span class="gi">+    def rmdir(self, path):</span>
<span class="gi">+        logger.debug(&quot;Removing folder %s&quot;, path)</span>
<span class="gi">+        self.ftp.rmdir(path)</span>
<span class="gi">+</span>
<span class="gi">+    def info(self, path):</span>
<span class="gi">+        stat = self._decode_stat(self.ftp.stat(path))</span>
<span class="gi">+        stat[&quot;name&quot;] = path</span>
<span class="gi">+        return stat</span>
<span class="gi">+</span>
<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _decode_stat(stat, parent_path=None):</span>
<span class="gi">+        if S_ISDIR(stat.st_mode):</span>
<span class="gi">+            t = &quot;directory&quot;</span>
<span class="gi">+        elif S_ISLNK(stat.st_mode):</span>
<span class="gi">+            t = &quot;link&quot;</span>
<span class="gi">+        else:</span>
<span class="gi">+            t = &quot;file&quot;</span>
<span class="gi">+        out = {</span>
<span class="gi">+            &quot;name&quot;: &quot;&quot;,</span>
<span class="gi">+            &quot;size&quot;: stat.st_size,</span>
<span class="gi">+            &quot;type&quot;: t,</span>
<span class="gi">+            &quot;uid&quot;: stat.st_uid,</span>
<span class="gi">+            &quot;gid&quot;: stat.st_gid,</span>
<span class="gi">+            &quot;time&quot;: datetime.datetime.fromtimestamp(</span>
<span class="gi">+                stat.st_atime, tz=datetime.timezone.utc</span>
<span class="gi">+            ),</span>
<span class="gi">+            &quot;mtime&quot;: datetime.datetime.fromtimestamp(</span>
<span class="gi">+                stat.st_mtime, tz=datetime.timezone.utc</span>
<span class="gi">+            ),</span>
<span class="gi">+        }</span>
<span class="gi">+        if parent_path:</span>
<span class="gi">+            out[&quot;name&quot;] = &quot;/&quot;.join([parent_path.rstrip(&quot;/&quot;), stat.filename])</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    def ls(self, path, detail=False):</span>
<span class="gi">+        logger.debug(&quot;Listing folder %s&quot;, path)</span>
<span class="gi">+        stats = [self._decode_stat(stat, path) for stat in self.ftp.listdir_iter(path)]</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return stats</span>
<span class="gi">+        else:</span>
<span class="gi">+            paths = [stat[&quot;name&quot;] for stat in stats]</span>
<span class="gi">+            return sorted(paths)</span>
<span class="gi">+</span>
<span class="gi">+    def put(self, lpath, rpath, callback=None, **kwargs):</span>
<span class="gi">+        logger.debug(&quot;Put file %s into %s&quot;, lpath, rpath)</span>
<span class="gi">+        self.ftp.put(lpath, rpath)</span>
<span class="gi">+</span>
<span class="gi">+    def get_file(self, rpath, lpath, **kwargs):</span>
<span class="gi">+        if self.isdir(rpath):</span>
<span class="gi">+            os.makedirs(lpath, exist_ok=True)</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.ftp.get(self._strip_protocol(rpath), lpath)</span>
<span class="gi">+</span>
<span class="gi">+    def _open(self, path, mode=&quot;rb&quot;, block_size=None, **kwargs):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        block_size: int or None
<span class="w"> </span>            If 0, no buffering, if 1, line buffering, if &gt;1, buffer that many
<span class="w"> </span>            bytes, if None use default from paramiko.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        logger.debug(&quot;Opening file %s&quot;, path)</span>
<span class="gi">+        if kwargs.get(&quot;autocommit&quot;, True) is False:</span>
<span class="gi">+            # writes to temporary file, move on commit</span>
<span class="gi">+            path2 = &quot;/&quot;.join([self.temppath, str(uuid.uuid4())])</span>
<span class="gi">+            f = self.ftp.open(path2, mode, bufsize=block_size if block_size else -1)</span>
<span class="gi">+            f.temppath = path2</span>
<span class="gi">+            f.targetpath = path</span>
<span class="gi">+            f.fs = self</span>
<span class="gi">+            f.commit = types.MethodType(commit_a_file, f)</span>
<span class="gi">+            f.discard = types.MethodType(discard_a_file, f)</span>
<span class="gi">+        else:</span>
<span class="gi">+            f = self.ftp.open(path, mode, bufsize=block_size if block_size else -1)</span>
<span class="gi">+        return f</span>
<span class="gi">+</span>
<span class="gi">+    def _rm(self, path):</span>
<span class="gi">+        if self.isdir(path):</span>
<span class="gi">+            self.ftp.rmdir(path)</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.ftp.remove(path)</span>
<span class="gi">+</span>
<span class="gi">+    def mv(self, old, new):</span>
<span class="gi">+        logger.debug(&quot;Renaming %s into %s&quot;, old, new)</span>
<span class="gi">+        self.ftp.posix_rename(old, new)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def commit_a_file(self):</span>
<span class="gi">+    self.fs.mv(self.temppath, self.targetpath)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def discard_a_file(self):</span>
<span class="gi">+    self.fs._rm(self.temppath)</span>
<span class="gh">diff --git a/fsspec/implementations/smb.py b/fsspec/implementations/smb.py</span>
<span class="gh">index a4da1d4..bcd13a6 100644</span>
<span class="gd">--- a/fsspec/implementations/smb.py</span>
<span class="gi">+++ b/fsspec/implementations/smb.py</span>
<span class="gu">@@ -2,13 +2,18 @@</span>
<span class="w"> </span>This module contains SMBFileSystem class responsible for handling access to
<span class="w"> </span>Windows Samba network shares by using package smbprotocol
<span class="w"> </span>&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>import datetime
<span class="w"> </span>import uuid
<span class="w"> </span>from stat import S_ISDIR, S_ISLNK
<span class="gi">+</span>
<span class="w"> </span>import smbclient
<span class="gi">+</span>
<span class="w"> </span>from .. import AbstractFileSystem
<span class="w"> </span>from ..utils import infer_storage_options

<span class="gi">+# ! pylint: disable=bad-continuation</span>
<span class="gi">+</span>

<span class="w"> </span>class SMBFileSystem(AbstractFileSystem):
<span class="w"> </span>    &quot;&quot;&quot;Allow reading and writing to Windows and Samba network shares.
<span class="gu">@@ -49,11 +54,23 @@ class SMBFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>    there is no way to tell if a path is relative, so all paths are assumed
<span class="w"> </span>    to be absolute.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    protocol = &#39;smb&#39;</span>

<span class="gd">-    def __init__(self, host, port=None, username=None, password=None,</span>
<span class="gd">-        timeout=60, encrypt=None, share_access=None,</span>
<span class="gd">-        register_session_retries=5, auto_mkdir=False, **kwargs):</span>
<span class="gi">+    protocol = &quot;smb&quot;</span>
<span class="gi">+</span>
<span class="gi">+    # pylint: disable=too-many-arguments</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        host,</span>
<span class="gi">+        port=None,</span>
<span class="gi">+        username=None,</span>
<span class="gi">+        password=None,</span>
<span class="gi">+        timeout=60,</span>
<span class="gi">+        encrypt=None,</span>
<span class="gi">+        share_access=None,</span>
<span class="gi">+        register_session_retries=5,</span>
<span class="gi">+        auto_mkdir=False,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        You can use _get_kwargs_from_urls to get some kwargs from
<span class="w"> </span>        a reasonable SMB url.
<span class="gu">@@ -98,22 +115,112 @@ class SMBFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        self.password = password
<span class="w"> </span>        self.timeout = timeout
<span class="w"> </span>        self.encrypt = encrypt
<span class="gd">-        self.temppath = kwargs.pop(&#39;temppath&#39;, &#39;&#39;)</span>
<span class="gi">+        self.temppath = kwargs.pop(&quot;temppath&quot;, &quot;&quot;)</span>
<span class="w"> </span>        self.share_access = share_access
<span class="w"> </span>        self.register_session_retries = register_session_retries
<span class="w"> </span>        self.auto_mkdir = auto_mkdir
<span class="w"> </span>        self._connect()

<span class="gi">+    @property</span>
<span class="gi">+    def _port(self):</span>
<span class="gi">+        return 445 if self.port is None else self.port</span>
<span class="gi">+</span>
<span class="gi">+    def _connect(self):</span>
<span class="gi">+        import time</span>
<span class="gi">+</span>
<span class="gi">+        for _ in range(self.register_session_retries):</span>
<span class="gi">+            try:</span>
<span class="gi">+                smbclient.register_session(</span>
<span class="gi">+                    self.host,</span>
<span class="gi">+                    username=self.username,</span>
<span class="gi">+                    password=self.password,</span>
<span class="gi">+                    port=self._port,</span>
<span class="gi">+                    encrypt=self.encrypt,</span>
<span class="gi">+                    connection_timeout=self.timeout,</span>
<span class="gi">+                )</span>
<span class="gi">+                break</span>
<span class="gi">+            except Exception:</span>
<span class="gi">+                time.sleep(0.1)</span>
<span class="gi">+</span>
<span class="gi">+    @classmethod</span>
<span class="gi">+    def _strip_protocol(cls, path):</span>
<span class="gi">+        return infer_storage_options(path)[&quot;path&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _get_kwargs_from_urls(path):</span>
<span class="gi">+        # smb://workgroup;user:password@host:port/share/folder/file.csv</span>
<span class="gi">+        out = infer_storage_options(path)</span>
<span class="gi">+        out.pop(&quot;path&quot;, None)</span>
<span class="gi">+        out.pop(&quot;protocol&quot;, None)</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    def mkdir(self, path, create_parents=True, **kwargs):</span>
<span class="gi">+        wpath = _as_unc_path(self.host, path)</span>
<span class="gi">+        if create_parents:</span>
<span class="gi">+            smbclient.makedirs(wpath, exist_ok=False, port=self._port, **kwargs)</span>
<span class="gi">+        else:</span>
<span class="gi">+            smbclient.mkdir(wpath, port=self._port, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def makedirs(self, path, exist_ok=False):</span>
<span class="gi">+        if _share_has_path(path):</span>
<span class="gi">+            wpath = _as_unc_path(self.host, path)</span>
<span class="gi">+            smbclient.makedirs(wpath, exist_ok=exist_ok, port=self._port)</span>
<span class="gi">+</span>
<span class="gi">+    def rmdir(self, path):</span>
<span class="gi">+        if _share_has_path(path):</span>
<span class="gi">+            wpath = _as_unc_path(self.host, path)</span>
<span class="gi">+            smbclient.rmdir(wpath, port=self._port)</span>
<span class="gi">+</span>
<span class="gi">+    def info(self, path, **kwargs):</span>
<span class="gi">+        wpath = _as_unc_path(self.host, path)</span>
<span class="gi">+        stats = smbclient.stat(wpath, port=self._port, **kwargs)</span>
<span class="gi">+        if S_ISDIR(stats.st_mode):</span>
<span class="gi">+            stype = &quot;directory&quot;</span>
<span class="gi">+        elif S_ISLNK(stats.st_mode):</span>
<span class="gi">+            stype = &quot;link&quot;</span>
<span class="gi">+        else:</span>
<span class="gi">+            stype = &quot;file&quot;</span>
<span class="gi">+        res = {</span>
<span class="gi">+            &quot;name&quot;: path + &quot;/&quot; if stype == &quot;directory&quot; else path,</span>
<span class="gi">+            &quot;size&quot;: stats.st_size,</span>
<span class="gi">+            &quot;type&quot;: stype,</span>
<span class="gi">+            &quot;uid&quot;: stats.st_uid,</span>
<span class="gi">+            &quot;gid&quot;: stats.st_gid,</span>
<span class="gi">+            &quot;time&quot;: stats.st_atime,</span>
<span class="gi">+            &quot;mtime&quot;: stats.st_mtime,</span>
<span class="gi">+        }</span>
<span class="gi">+        return res</span>
<span class="gi">+</span>
<span class="w"> </span>    def created(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Return the created timestamp of a file as a datetime.datetime&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        wpath = _as_unc_path(self.host, path)</span>
<span class="gi">+        stats = smbclient.stat(wpath, port=self._port)</span>
<span class="gi">+        return datetime.datetime.fromtimestamp(stats.st_ctime, tz=datetime.timezone.utc)</span>

<span class="w"> </span>    def modified(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Return the modified timestamp of a file as a datetime.datetime&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def _open(self, path, mode=&#39;rb&#39;, block_size=-1, autocommit=True,</span>
<span class="gd">-        cache_options=None, **kwargs):</span>
<span class="gi">+        wpath = _as_unc_path(self.host, path)</span>
<span class="gi">+        stats = smbclient.stat(wpath, port=self._port)</span>
<span class="gi">+        return datetime.datetime.fromtimestamp(stats.st_mtime, tz=datetime.timezone.utc)</span>
<span class="gi">+</span>
<span class="gi">+    def ls(self, path, detail=True, **kwargs):</span>
<span class="gi">+        unc = _as_unc_path(self.host, path)</span>
<span class="gi">+        listed = smbclient.listdir(unc, port=self._port, **kwargs)</span>
<span class="gi">+        dirs = [&quot;/&quot;.join([path.rstrip(&quot;/&quot;), p]) for p in listed]</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            dirs = [self.info(d) for d in dirs]</span>
<span class="gi">+        return dirs</span>
<span class="gi">+</span>
<span class="gi">+    # pylint: disable=too-many-arguments</span>
<span class="gi">+    def _open(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=-1,</span>
<span class="gi">+        autocommit=True,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        block_size: int or None
<span class="w"> </span>            If 0, no buffering, 1, line buffering, &gt;1, buffer that many bytes
<span class="gu">@@ -123,11 +230,66 @@ class SMBFileSystem(AbstractFileSystem):</span>
<span class="w"> </span>        By specifying &#39;share_access&#39; in &#39;kwargs&#39; it is possible to override the
<span class="w"> </span>        default shared access setting applied in the constructor of this object.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.auto_mkdir and &quot;w&quot; in mode:</span>
<span class="gi">+            self.makedirs(self._parent(path), exist_ok=True)</span>
<span class="gi">+        bls = block_size if block_size is not None and block_size &gt;= 0 else -1</span>
<span class="gi">+        wpath = _as_unc_path(self.host, path)</span>
<span class="gi">+        share_access = kwargs.pop(&quot;share_access&quot;, self.share_access)</span>
<span class="gi">+        if &quot;w&quot; in mode and autocommit is False:</span>
<span class="gi">+            temp = _as_temp_path(self.host, path, self.temppath)</span>
<span class="gi">+            return SMBFileOpener(</span>
<span class="gi">+                wpath, temp, mode, port=self._port, block_size=bls, **kwargs</span>
<span class="gi">+            )</span>
<span class="gi">+        return smbclient.open_file(</span>
<span class="gi">+            wpath,</span>
<span class="gi">+            mode,</span>
<span class="gi">+            buffering=bls,</span>
<span class="gi">+            share_access=share_access,</span>
<span class="gi">+            port=self._port,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def copy(self, path1, path2, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Copy within two locations in the same filesystem&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        wpath1 = _as_unc_path(self.host, path1)</span>
<span class="gi">+        wpath2 = _as_unc_path(self.host, path2)</span>
<span class="gi">+        if self.auto_mkdir:</span>
<span class="gi">+            self.makedirs(self._parent(path2), exist_ok=True)</span>
<span class="gi">+        smbclient.copyfile(wpath1, wpath2, port=self._port, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def _rm(self, path):</span>
<span class="gi">+        if _share_has_path(path):</span>
<span class="gi">+            wpath = _as_unc_path(self.host, path)</span>
<span class="gi">+            stats = smbclient.stat(wpath, port=self._port)</span>
<span class="gi">+            if S_ISDIR(stats.st_mode):</span>
<span class="gi">+                smbclient.rmdir(wpath, port=self._port)</span>
<span class="gi">+            else:</span>
<span class="gi">+                smbclient.remove(wpath, port=self._port)</span>
<span class="gi">+</span>
<span class="gi">+    def mv(self, path1, path2, recursive=None, maxdepth=None, **kwargs):</span>
<span class="gi">+        wpath1 = _as_unc_path(self.host, path1)</span>
<span class="gi">+        wpath2 = _as_unc_path(self.host, path2)</span>
<span class="gi">+        smbclient.rename(wpath1, wpath2, port=self._port, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _as_unc_path(host, path):</span>
<span class="gi">+    rpath = path.replace(&quot;/&quot;, &quot;\\&quot;)</span>
<span class="gi">+    unc = f&quot;\\\\{host}{rpath}&quot;</span>
<span class="gi">+    return unc</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _as_temp_path(host, path, temppath):</span>
<span class="gi">+    share = path.split(&quot;/&quot;)[1]</span>
<span class="gi">+    temp_file = f&quot;/{share}{temppath}/{uuid.uuid4()}&quot;</span>
<span class="gi">+    unc = _as_unc_path(host, temp_file)</span>
<span class="gi">+    return unc</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _share_has_path(path):</span>
<span class="gi">+    parts = path.count(&quot;/&quot;)</span>
<span class="gi">+    if path.endswith(&quot;/&quot;):</span>
<span class="gi">+        return parts &gt; 2</span>
<span class="gi">+    return parts &gt; 1</span>


<span class="w"> </span>class SMBFileOpener:
<span class="gu">@@ -144,13 +306,24 @@ class SMBFileOpener:</span>
<span class="w"> </span>        self.port = port
<span class="w"> </span>        self._open()

<span class="gi">+    def _open(self):</span>
<span class="gi">+        if self.smbfile is None or self.smbfile.closed:</span>
<span class="gi">+            self.smbfile = smbclient.open_file(</span>
<span class="gi">+                self.temp,</span>
<span class="gi">+                self.mode,</span>
<span class="gi">+                port=self.port,</span>
<span class="gi">+                buffering=self.block_size,</span>
<span class="gi">+                **self.kwargs,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="w"> </span>    def commit(self):
<span class="w"> </span>        &quot;&quot;&quot;Move temp file to definitive on success.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # TODO: use transaction support in SMB protocol</span>
<span class="gi">+        smbclient.replace(self.temp, self.path, port=self.port)</span>

<span class="w"> </span>    def discard(self):
<span class="w"> </span>        &quot;&quot;&quot;Remove the temp file on failure.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        smbclient.remove(self.temp, port=self.port)</span>

<span class="w"> </span>    def __fspath__(self):
<span class="w"> </span>        return self.path
<span class="gh">diff --git a/fsspec/implementations/tar.py b/fsspec/implementations/tar.py</span>
<span class="gh">index acb812a..412e5ba 100644</span>
<span class="gd">--- a/fsspec/implementations/tar.py</span>
<span class="gi">+++ b/fsspec/implementations/tar.py</span>
<span class="gu">@@ -1,11 +1,14 @@</span>
<span class="w"> </span>import logging
<span class="w"> </span>import tarfile
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="w"> </span>from fsspec.archive import AbstractArchiveFileSystem
<span class="w"> </span>from fsspec.compression import compr
<span class="w"> </span>from fsspec.utils import infer_compression
<span class="gd">-typemap = {b&#39;0&#39;: &#39;file&#39;, b&#39;5&#39;: &#39;directory&#39;}</span>
<span class="gd">-logger = logging.getLogger(&#39;tar&#39;)</span>
<span class="gi">+</span>
<span class="gi">+typemap = {b&quot;0&quot;: &quot;file&quot;, b&quot;5&quot;: &quot;directory&quot;}</span>
<span class="gi">+</span>
<span class="gi">+logger = logging.getLogger(&quot;tar&quot;)</span>


<span class="w"> </span>class TarFileSystem(AbstractArchiveFileSystem):
<span class="gu">@@ -14,44 +17,108 @@ class TarFileSystem(AbstractArchiveFileSystem):</span>
<span class="w"> </span>    Supports the following formats:
<span class="w"> </span>    tar.gz, tar.bz2, tar.xz
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    root_marker = &#39;&#39;</span>
<span class="gd">-    protocol = &#39;tar&#39;</span>
<span class="gi">+</span>
<span class="gi">+    root_marker = &quot;&quot;</span>
<span class="gi">+    protocol = &quot;tar&quot;</span>
<span class="w"> </span>    cachable = False

<span class="gd">-    def __init__(self, fo=&#39;&#39;, index_store=None, target_options=None,</span>
<span class="gd">-        target_protocol=None, compression=None, **kwargs):</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        fo=&quot;&quot;,</span>
<span class="gi">+        index_store=None,</span>
<span class="gi">+        target_options=None,</span>
<span class="gi">+        target_protocol=None,</span>
<span class="gi">+        compression=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        super().__init__(**kwargs)
<span class="w"> </span>        target_options = target_options or {}
<span class="gi">+</span>
<span class="w"> </span>        if isinstance(fo, str):
<span class="gd">-            self.of = fsspec.open(fo, protocol=target_protocol, **</span>
<span class="gd">-                target_options)</span>
<span class="gd">-            fo = self.of.open()</span>
<span class="gi">+            self.of = fsspec.open(fo, protocol=target_protocol, **target_options)</span>
<span class="gi">+            fo = self.of.open()  # keep the reference</span>
<span class="gi">+</span>
<span class="gi">+        # Try to infer compression.</span>
<span class="w"> </span>        if compression is None:
<span class="w"> </span>            name = None
<span class="gi">+</span>
<span class="gi">+            # Try different ways to get hold of the filename. `fo` might either</span>
<span class="gi">+            # be a `fsspec.LocalFileOpener`, an `io.BufferedReader` or an</span>
<span class="gi">+            # `fsspec.AbstractFileSystem` instance.</span>
<span class="w"> </span>            try:
<span class="gd">-                if hasattr(fo, &#39;original&#39;):</span>
<span class="gi">+                # Amended io.BufferedReader or similar.</span>
<span class="gi">+                # This uses a &quot;protocol extension&quot; where original filenames are</span>
<span class="gi">+                # propagated to archive-like filesystems in order to let them</span>
<span class="gi">+                # infer the right compression appropriately.</span>
<span class="gi">+                if hasattr(fo, &quot;original&quot;):</span>
<span class="w"> </span>                    name = fo.original
<span class="gd">-                elif hasattr(fo, &#39;path&#39;):</span>
<span class="gi">+</span>
<span class="gi">+                # fsspec.LocalFileOpener</span>
<span class="gi">+                elif hasattr(fo, &quot;path&quot;):</span>
<span class="w"> </span>                    name = fo.path
<span class="gd">-                elif hasattr(fo, &#39;name&#39;):</span>
<span class="gi">+</span>
<span class="gi">+                # io.BufferedReader</span>
<span class="gi">+                elif hasattr(fo, &quot;name&quot;):</span>
<span class="w"> </span>                    name = fo.name
<span class="gd">-                elif hasattr(fo, &#39;info&#39;):</span>
<span class="gd">-                    name = fo.info()[&#39;name&#39;]</span>
<span class="gi">+</span>
<span class="gi">+                # fsspec.AbstractFileSystem</span>
<span class="gi">+                elif hasattr(fo, &quot;info&quot;):</span>
<span class="gi">+                    name = fo.info()[&quot;name&quot;]</span>
<span class="gi">+</span>
<span class="w"> </span>            except Exception as ex:
<span class="w"> </span>                logger.warning(
<span class="gd">-                    f&#39;Unable to determine file name, not inferring compression: {ex}&#39;</span>
<span class="gd">-                    )</span>
<span class="gi">+                    f&quot;Unable to determine file name, not inferring compression: {ex}&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+</span>
<span class="w"> </span>            if name is not None:
<span class="w"> </span>                compression = infer_compression(name)
<span class="gd">-                logger.info(</span>
<span class="gd">-                    f&#39;Inferred compression {compression} from file name {name}&#39;</span>
<span class="gd">-                    )</span>
<span class="gi">+                logger.info(f&quot;Inferred compression {compression} from file name {name}&quot;)</span>
<span class="gi">+</span>
<span class="w"> </span>        if compression is not None:
<span class="gi">+            # TODO: tarfile already implements compression with modes like &quot;&#39;r:gz&#39;&quot;,</span>
<span class="gi">+            #  but then would seek to offset in the file work?</span>
<span class="w"> </span>            fo = compr[compression](fo)
<span class="gi">+</span>
<span class="w"> </span>        self._fo_ref = fo
<span class="gd">-        self.fo = fo</span>
<span class="gi">+        self.fo = fo  # the whole instance is a context</span>
<span class="w"> </span>        self.tar = tarfile.TarFile(fileobj=self.fo)
<span class="w"> </span>        self.dir_cache = None
<span class="gi">+</span>
<span class="w"> </span>        self.index_store = index_store
<span class="w"> </span>        self.index = None
<span class="w"> </span>        self._index()
<span class="gi">+</span>
<span class="gi">+    def _index(self):</span>
<span class="gi">+        # TODO: load and set saved index, if exists</span>
<span class="gi">+        out = {}</span>
<span class="gi">+        for ti in self.tar:</span>
<span class="gi">+            info = ti.get_info()</span>
<span class="gi">+            info[&quot;type&quot;] = typemap.get(info[&quot;type&quot;], &quot;file&quot;)</span>
<span class="gi">+            name = ti.get_info()[&quot;name&quot;].rstrip(&quot;/&quot;)</span>
<span class="gi">+            out[name] = (info, ti.offset_data)</span>
<span class="gi">+</span>
<span class="gi">+        self.index = out</span>
<span class="gi">+        # TODO: save index to self.index_store here, if set</span>
<span class="gi">+</span>
<span class="gi">+    def _get_dirs(self):</span>
<span class="gi">+        if self.dir_cache is not None:</span>
<span class="gi">+            return</span>
<span class="gi">+</span>
<span class="gi">+        # This enables ls to get directories as children as well as files</span>
<span class="gi">+        self.dir_cache = {</span>
<span class="gi">+            dirname: {&quot;name&quot;: dirname, &quot;size&quot;: 0, &quot;type&quot;: &quot;directory&quot;}</span>
<span class="gi">+            for dirname in self._all_dirnames(self.tar.getnames())</span>
<span class="gi">+        }</span>
<span class="gi">+        for member in self.tar.getmembers():</span>
<span class="gi">+            info = member.get_info()</span>
<span class="gi">+            info[&quot;name&quot;] = info[&quot;name&quot;].rstrip(&quot;/&quot;)</span>
<span class="gi">+            info[&quot;type&quot;] = typemap.get(info[&quot;type&quot;], &quot;file&quot;)</span>
<span class="gi">+            self.dir_cache[info[&quot;name&quot;]] = info</span>
<span class="gi">+</span>
<span class="gi">+    def _open(self, path, mode=&quot;rb&quot;, **kwargs):</span>
<span class="gi">+        if mode != &quot;rb&quot;:</span>
<span class="gi">+            raise ValueError(&quot;Read-only filesystem implementation&quot;)</span>
<span class="gi">+        details, offset = self.index[path]</span>
<span class="gi">+        if details[&quot;type&quot;] != &quot;file&quot;:</span>
<span class="gi">+            raise ValueError(&quot;Can only handle regular files&quot;)</span>
<span class="gi">+        return self.tar.extractfile(path)</span>
<span class="gh">diff --git a/fsspec/implementations/tests/local/local_fixtures.py b/fsspec/implementations/tests/local/local_fixtures.py</span>
<span class="gh">index a549f6d..bafff60 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/local/local_fixtures.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/local/local_fixtures.py</span>
<span class="gu">@@ -1,7 +1,18 @@</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>from fsspec.implementations.local import LocalFileSystem, make_path_posix
<span class="w"> </span>from fsspec.tests.abstract import AbstractFixtures


<span class="w"> </span>class LocalFixtures(AbstractFixtures):
<span class="gd">-    pass</span>
<span class="gi">+    @pytest.fixture(scope=&quot;class&quot;)</span>
<span class="gi">+    def fs(self):</span>
<span class="gi">+        return LocalFileSystem(auto_mkdir=True)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.fixture</span>
<span class="gi">+    def fs_path(self, tmpdir):</span>
<span class="gi">+        return str(tmpdir)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.fixture</span>
<span class="gi">+    def fs_sanitize_path(self):</span>
<span class="gi">+        return make_path_posix</span>
<span class="gh">diff --git a/fsspec/implementations/tests/memory/memory_fixtures.py b/fsspec/implementations/tests/memory/memory_fixtures.py</span>
<span class="gh">index 26f59cd..27d0252 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/memory/memory_fixtures.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/memory/memory_fixtures.py</span>
<span class="gu">@@ -1,7 +1,27 @@</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>from fsspec import filesystem
<span class="w"> </span>from fsspec.tests.abstract import AbstractFixtures


<span class="w"> </span>class MemoryFixtures(AbstractFixtures):
<span class="gd">-    pass</span>
<span class="gi">+    @pytest.fixture(scope=&quot;class&quot;)</span>
<span class="gi">+    def fs(self):</span>
<span class="gi">+        m = filesystem(&quot;memory&quot;)</span>
<span class="gi">+        m.store.clear()</span>
<span class="gi">+        m.pseudo_dirs.clear()</span>
<span class="gi">+        m.pseudo_dirs.append(&quot;&quot;)</span>
<span class="gi">+        try:</span>
<span class="gi">+            yield m</span>
<span class="gi">+        finally:</span>
<span class="gi">+            m.store.clear()</span>
<span class="gi">+            m.pseudo_dirs.clear()</span>
<span class="gi">+            m.pseudo_dirs.append(&quot;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.fixture</span>
<span class="gi">+    def fs_join(self):</span>
<span class="gi">+        return lambda *args: &quot;/&quot;.join(args)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.fixture</span>
<span class="gi">+    def fs_path(self):</span>
<span class="gi">+        return &quot;&quot;</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_archive.py b/fsspec/implementations/tests/test_archive.py</span>
<span class="gh">index 0c8d230..457714b 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_archive.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_archive.py</span>
<span class="gu">@@ -8,9 +8,13 @@ import tempfile</span>
<span class="w"> </span>import zipfile
<span class="w"> </span>from contextlib import contextmanager
<span class="w"> </span>from io import BytesIO
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="gd">-archive_data = {&#39;a&#39;: b&#39;&#39;, &#39;b&#39;: b&#39;hello&#39;, &#39;deeply/nested/path&#39;: b&#39;stuff&#39;}</span>
<span class="gi">+</span>
<span class="gi">+# The blueprint to create synthesized archive files from.</span>
<span class="gi">+archive_data = {&quot;a&quot;: b&quot;&quot;, &quot;b&quot;: b&quot;hello&quot;, &quot;deeply/nested/path&quot;: b&quot;stuff&quot;}</span>


<span class="w"> </span>@contextmanager
<span class="gu">@@ -18,7 +22,18 @@ def tempzip(data=None):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Provide test cases with temporary synthesized Zip archives.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    data = data or {}</span>
<span class="gi">+    f = tempfile.mkstemp(suffix=&quot;.zip&quot;)[1]</span>
<span class="gi">+    with zipfile.ZipFile(f, mode=&quot;w&quot;) as z:</span>
<span class="gi">+        for k, v in data.items():</span>
<span class="gi">+            z.writestr(k, v)</span>
<span class="gi">+    try:</span>
<span class="gi">+        yield f</span>
<span class="gi">+    finally:</span>
<span class="gi">+        try:</span>
<span class="gi">+            os.remove(f)</span>
<span class="gi">+        except OSError:</span>
<span class="gi">+            pass</span>


<span class="w"> </span>@contextmanager
<span class="gu">@@ -26,39 +41,119 @@ def temparchive(data=None):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Provide test cases with temporary synthesized 7-Zip archives.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    data = data or {}</span>
<span class="gi">+    libarchive = pytest.importorskip(&quot;libarchive&quot;)</span>
<span class="gi">+    f = tempfile.mkstemp(suffix=&quot;.7z&quot;)[1]</span>
<span class="gi">+    with libarchive.file_writer(f, &quot;7zip&quot;) as archive:</span>
<span class="gi">+        for k, v in data.items():</span>
<span class="gi">+            archive.add_file_from_memory(entry_path=k, entry_size=len(v), entry_data=v)</span>
<span class="gi">+    try:</span>
<span class="gi">+        yield f</span>
<span class="gi">+    finally:</span>
<span class="gi">+        try:</span>
<span class="gi">+            os.remove(f)</span>
<span class="gi">+        except OSError:</span>
<span class="gi">+            pass</span>


<span class="w"> </span>@contextmanager
<span class="gd">-def temptar(data=None, mode=&#39;w&#39;, suffix=&#39;.tar&#39;):</span>
<span class="gi">+def temptar(data=None, mode=&quot;w&quot;, suffix=&quot;.tar&quot;):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Provide test cases with temporary synthesized .tar archives.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    data = data or {}</span>
<span class="gi">+    fn = tempfile.mkstemp(suffix=suffix)[1]</span>
<span class="gi">+    with tarfile.TarFile.open(fn, mode=mode) as t:</span>
<span class="gi">+        touched = {}</span>
<span class="gi">+        for name, value in data.items():</span>
<span class="gi">+            # Create directory hierarchy.</span>
<span class="gi">+            # https://bugs.python.org/issue22208#msg225558</span>
<span class="gi">+            if &quot;/&quot; in name and name not in touched:</span>
<span class="gi">+                parts = os.path.dirname(name).split(&quot;/&quot;)</span>
<span class="gi">+                for index in range(1, len(parts) + 1):</span>
<span class="gi">+                    info = tarfile.TarInfo(&quot;/&quot;.join(parts[:index]))</span>
<span class="gi">+                    info.type = tarfile.DIRTYPE</span>
<span class="gi">+                    t.addfile(info)</span>
<span class="gi">+                touched[name] = True</span>
<span class="gi">+</span>
<span class="gi">+            # Add file content.</span>
<span class="gi">+            info = tarfile.TarInfo(name=name)</span>
<span class="gi">+            info.size = len(value)</span>
<span class="gi">+            t.addfile(info, BytesIO(value))</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        yield fn</span>
<span class="gi">+    finally:</span>
<span class="gi">+        try:</span>
<span class="gi">+            os.remove(fn)</span>
<span class="gi">+        except OSError:</span>
<span class="gi">+            pass</span>


<span class="w"> </span>@contextmanager
<span class="gd">-def temptargz(data=None, mode=&#39;w&#39;, suffix=&#39;.tar.gz&#39;):</span>
<span class="gi">+def temptargz(data=None, mode=&quot;w&quot;, suffix=&quot;.tar.gz&quot;):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Provide test cases with temporary synthesized .tar.gz archives.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    with temptar(data=data, mode=mode) as tarname:</span>
<span class="gi">+        fn = tempfile.mkstemp(suffix=suffix)[1]</span>
<span class="gi">+        with open(tarname, &quot;rb&quot;) as tar:</span>
<span class="gi">+            cf = gzip.GzipFile(filename=fn, mode=mode)</span>
<span class="gi">+            cf.write(tar.read())</span>
<span class="gi">+            cf.close()</span>
<span class="gi">+</span>
<span class="gi">+        try:</span>
<span class="gi">+            yield fn</span>
<span class="gi">+        finally:</span>
<span class="gi">+            try:</span>
<span class="gi">+                os.remove(fn)</span>
<span class="gi">+            except OSError:</span>
<span class="gi">+                pass</span>


<span class="w"> </span>@contextmanager
<span class="gd">-def temptarbz2(data=None, mode=&#39;w&#39;, suffix=&#39;.tar.bz2&#39;):</span>
<span class="gi">+def temptarbz2(data=None, mode=&quot;w&quot;, suffix=&quot;.tar.bz2&quot;):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Provide test cases with temporary synthesized .tar.bz2 archives.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    with temptar(data=data, mode=mode) as tarname:</span>
<span class="gi">+        fn = tempfile.mkstemp(suffix=suffix)[1]</span>
<span class="gi">+        with open(tarname, &quot;rb&quot;) as tar:</span>
<span class="gi">+            cf = bz2.BZ2File(filename=fn, mode=mode)</span>
<span class="gi">+            cf.write(tar.read())</span>
<span class="gi">+            cf.close()</span>
<span class="gi">+</span>
<span class="gi">+        try:</span>
<span class="gi">+            yield fn</span>
<span class="gi">+        finally:</span>
<span class="gi">+            try:</span>
<span class="gi">+                os.remove(fn)</span>
<span class="gi">+            except OSError:</span>
<span class="gi">+                pass</span>


<span class="w"> </span>@contextmanager
<span class="gd">-def temptarxz(data=None, mode=&#39;w&#39;, suffix=&#39;.tar.xz&#39;):</span>
<span class="gi">+def temptarxz(data=None, mode=&quot;w&quot;, suffix=&quot;.tar.xz&quot;):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Provide test cases with temporary synthesized .tar.xz archives.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    with temptar(data=data, mode=mode) as tarname:</span>
<span class="gi">+        fn = tempfile.mkstemp(suffix=suffix)[1]</span>
<span class="gi">+        with open(tarname, &quot;rb&quot;) as tar:</span>
<span class="gi">+            cf = lzma.open(filename=fn, mode=mode, format=lzma.FORMAT_XZ)</span>
<span class="gi">+            cf.write(tar.read())</span>
<span class="gi">+            cf.close()</span>
<span class="gi">+</span>
<span class="gi">+        try:</span>
<span class="gi">+            yield fn</span>
<span class="gi">+        finally:</span>
<span class="gi">+            try:</span>
<span class="gi">+                os.remove(fn)</span>
<span class="gi">+            except OSError:</span>
<span class="gi">+                pass</span>


<span class="w"> </span>class ArchiveTestScenario:
<span class="gu">@@ -67,8 +162,11 @@ class ArchiveTestScenario:</span>
<span class="w"> </span>    &quot;&quot;&quot;

<span class="w"> </span>    def __init__(self, protocol=None, provider=None, variant=None):
<span class="gi">+        # The filesystem protocol identifier. Any of &quot;zip&quot;, &quot;tar&quot; or &quot;libarchive&quot;.</span>
<span class="w"> </span>        self.protocol = protocol
<span class="gi">+        # A contextmanager function to provide temporary synthesized archives.</span>
<span class="w"> </span>        self.provider = provider
<span class="gi">+        # The filesystem protocol variant identifier. Any of &quot;gz&quot;, &quot;bz2&quot; or &quot;xz&quot;.</span>
<span class="w"> </span>        self.variant = variant


<span class="gu">@@ -86,19 +184,28 @@ def pytest_generate_tests(metafunc):</span>

<span class="w"> </span>    https://docs.pytest.org/en/latest/example/parametrize.html#a-quick-port-of-testscenarios
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    idlist = []</span>
<span class="gi">+    argnames = [&quot;scenario&quot;]</span>
<span class="gi">+    argvalues = []</span>
<span class="gi">+    for scenario in metafunc.cls.scenarios:</span>
<span class="gi">+        scenario: ArchiveTestScenario = scenario</span>
<span class="gi">+        label = scenario.protocol</span>
<span class="gi">+        if scenario.variant:</span>
<span class="gi">+            label += &quot;-&quot; + scenario.variant</span>
<span class="gi">+        idlist.append(label)</span>
<span class="gi">+        argvalues.append([scenario])</span>
<span class="gi">+    metafunc.parametrize(argnames, argvalues, ids=idlist, scope=&quot;class&quot;)</span>


<span class="gd">-scenario_zip = ArchiveTestScenario(protocol=&#39;zip&#39;, provider=tempzip)</span>
<span class="gd">-scenario_tar = ArchiveTestScenario(protocol=&#39;tar&#39;, provider=temptar)</span>
<span class="gd">-scenario_targz = ArchiveTestScenario(protocol=&#39;tar&#39;, provider=temptargz,</span>
<span class="gd">-    variant=&#39;gz&#39;)</span>
<span class="gd">-scenario_tarbz2 = ArchiveTestScenario(protocol=&#39;tar&#39;, provider=temptarbz2,</span>
<span class="gd">-    variant=&#39;bz2&#39;)</span>
<span class="gd">-scenario_tarxz = ArchiveTestScenario(protocol=&#39;tar&#39;, provider=temptarxz,</span>
<span class="gd">-    variant=&#39;xz&#39;)</span>
<span class="gd">-scenario_libarchive = ArchiveTestScenario(protocol=&#39;libarchive&#39;, provider=</span>
<span class="gd">-    temparchive)</span>
<span class="gi">+# Define test scenarios.</span>
<span class="gi">+scenario_zip = ArchiveTestScenario(protocol=&quot;zip&quot;, provider=tempzip)</span>
<span class="gi">+scenario_tar = ArchiveTestScenario(protocol=&quot;tar&quot;, provider=temptar)</span>
<span class="gi">+scenario_targz = ArchiveTestScenario(protocol=&quot;tar&quot;, provider=temptargz, variant=&quot;gz&quot;)</span>
<span class="gi">+scenario_tarbz2 = ArchiveTestScenario(</span>
<span class="gi">+    protocol=&quot;tar&quot;, provider=temptarbz2, variant=&quot;bz2&quot;</span>
<span class="gi">+)</span>
<span class="gi">+scenario_tarxz = ArchiveTestScenario(protocol=&quot;tar&quot;, provider=temptarxz, variant=&quot;xz&quot;)</span>
<span class="gi">+scenario_libarchive = ArchiveTestScenario(protocol=&quot;libarchive&quot;, provider=temparchive)</span>


<span class="w"> </span>class TestAnyArchive:
<span class="gu">@@ -106,5 +213,170 @@ class TestAnyArchive:</span>
<span class="w"> </span>    Validate that all filesystem adapter implementations for archive files
<span class="w"> </span>    will adhere to the same specification.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    scenarios = [scenario_zip, scenario_tar, scenario_targz,</span>
<span class="gd">-        scenario_tarbz2, scenario_tarxz, scenario_libarchive]</span>
<span class="gi">+</span>
<span class="gi">+    scenarios = [</span>
<span class="gi">+        scenario_zip,</span>
<span class="gi">+        scenario_tar,</span>
<span class="gi">+        scenario_targz,</span>
<span class="gi">+        scenario_tarbz2,</span>
<span class="gi">+        scenario_tarxz,</span>
<span class="gi">+        scenario_libarchive,</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+    def test_repr(self, scenario: ArchiveTestScenario):</span>
<span class="gi">+        with scenario.provider() as archive:</span>
<span class="gi">+            fs = fsspec.filesystem(scenario.protocol, fo=archive)</span>
<span class="gi">+            assert repr(fs).startswith(&quot;&lt;Archive-like object&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def test_empty(self, scenario: ArchiveTestScenario):</span>
<span class="gi">+        with scenario.provider() as archive:</span>
<span class="gi">+            fs = fsspec.filesystem(scenario.protocol, fo=archive)</span>
<span class="gi">+            assert fs.find(&quot;&quot;) == []</span>
<span class="gi">+            assert fs.find(&quot;&quot;, withdirs=True) == []</span>
<span class="gi">+            with pytest.raises(FileNotFoundError):</span>
<span class="gi">+                fs.info(&quot;&quot;)</span>
<span class="gi">+            assert fs.ls(&quot;&quot;) == []</span>
<span class="gi">+</span>
<span class="gi">+    def test_glob(self, scenario: ArchiveTestScenario):</span>
<span class="gi">+        with scenario.provider(archive_data) as archive:</span>
<span class="gi">+            fs = fsspec.filesystem(scenario.protocol, fo=archive)</span>
<span class="gi">+            assert fs.glob(&quot;*/*/*th&quot;) == [&quot;deeply/nested/path&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    def test_mapping(self, scenario: ArchiveTestScenario):</span>
<span class="gi">+        with scenario.provider(archive_data) as archive:</span>
<span class="gi">+            fs = fsspec.filesystem(scenario.protocol, fo=archive)</span>
<span class="gi">+            m = fs.get_mapper()</span>
<span class="gi">+            assert list(m) == [&quot;a&quot;, &quot;b&quot;, &quot;deeply/nested/path&quot;]</span>
<span class="gi">+            assert m[&quot;b&quot;] == archive_data[&quot;b&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    def test_pickle(self, scenario: ArchiveTestScenario):</span>
<span class="gi">+        with scenario.provider(archive_data) as archive:</span>
<span class="gi">+            fs = fsspec.filesystem(scenario.protocol, fo=archive)</span>
<span class="gi">+            fs2 = pickle.loads(pickle.dumps(fs))</span>
<span class="gi">+            assert fs2.cat(&quot;b&quot;) == b&quot;hello&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def test_all_dirnames(self, scenario: ArchiveTestScenario):</span>
<span class="gi">+        with scenario.provider(archive_data) as archive:</span>
<span class="gi">+            fs = fsspec.filesystem(scenario.protocol, fo=archive)</span>
<span class="gi">+</span>
<span class="gi">+            # fx are files, dx are a directories</span>
<span class="gi">+            assert fs._all_dirnames([]) == set()</span>
<span class="gi">+            assert fs._all_dirnames([&quot;f1&quot;]) == set()</span>
<span class="gi">+            assert fs._all_dirnames([&quot;f1&quot;, &quot;f2&quot;]) == set()</span>
<span class="gi">+            assert fs._all_dirnames([&quot;f1&quot;, &quot;f2&quot;, &quot;d1/f1&quot;]) == {&quot;d1&quot;}</span>
<span class="gi">+            assert fs._all_dirnames([&quot;f1&quot;, &quot;d1/f1&quot;, &quot;d1/f2&quot;]) == {&quot;d1&quot;}</span>
<span class="gi">+            assert fs._all_dirnames([&quot;f1&quot;, &quot;d1/f1&quot;, &quot;d2/f1&quot;]) == {&quot;d1&quot;, &quot;d2&quot;}</span>
<span class="gi">+            assert fs._all_dirnames([&quot;d1/d1/d1/f1&quot;]) == {&quot;d1&quot;, &quot;d1/d1&quot;, &quot;d1/d1/d1&quot;}</span>
<span class="gi">+</span>
<span class="gi">+    def test_ls(self, scenario: ArchiveTestScenario):</span>
<span class="gi">+        with scenario.provider(archive_data) as archive:</span>
<span class="gi">+            fs = fsspec.filesystem(scenario.protocol, fo=archive)</span>
<span class="gi">+</span>
<span class="gi">+            assert fs.ls(&quot;&quot;, detail=False) == [&quot;a&quot;, &quot;b&quot;, &quot;deeply&quot;]</span>
<span class="gi">+            assert fs.ls(&quot;/&quot;) == fs.ls(&quot;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+            assert fs.ls(&quot;deeply&quot;, detail=False) == [&quot;deeply/nested&quot;]</span>
<span class="gi">+            assert fs.ls(&quot;deeply/&quot;) == fs.ls(&quot;deeply&quot;)</span>
<span class="gi">+</span>
<span class="gi">+            assert fs.ls(&quot;deeply/nested&quot;, detail=False) == [&quot;deeply/nested/path&quot;]</span>
<span class="gi">+            assert fs.ls(&quot;deeply/nested/&quot;) == fs.ls(&quot;deeply/nested&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def test_find(self, scenario: ArchiveTestScenario):</span>
<span class="gi">+        with scenario.provider(archive_data) as archive:</span>
<span class="gi">+            fs = fsspec.filesystem(scenario.protocol, fo=archive)</span>
<span class="gi">+</span>
<span class="gi">+            assert fs.find(&quot;&quot;) == [&quot;a&quot;, &quot;b&quot;, &quot;deeply/nested/path&quot;]</span>
<span class="gi">+            assert fs.find(&quot;&quot;, withdirs=True) == [</span>
<span class="gi">+                &quot;a&quot;,</span>
<span class="gi">+                &quot;b&quot;,</span>
<span class="gi">+                &quot;deeply&quot;,</span>
<span class="gi">+                &quot;deeply/nested&quot;,</span>
<span class="gi">+                &quot;deeply/nested/path&quot;,</span>
<span class="gi">+            ]</span>
<span class="gi">+</span>
<span class="gi">+            assert fs.find(&quot;deeply&quot;) == [&quot;deeply/nested/path&quot;]</span>
<span class="gi">+            assert fs.find(&quot;deeply/&quot;) == fs.find(&quot;deeply&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;topdown&quot;, [True, False])</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;prune_nested&quot;, [True, False])</span>
<span class="gi">+    def test_walk(self, scenario: ArchiveTestScenario, topdown, prune_nested):</span>
<span class="gi">+        with scenario.provider(archive_data) as archive:</span>
<span class="gi">+            fs = fsspec.filesystem(scenario.protocol, fo=archive)</span>
<span class="gi">+            expected = [</span>
<span class="gi">+                # (dirname, list of subdirs, list of files)</span>
<span class="gi">+                (&quot;&quot;, [&quot;deeply&quot;], [&quot;a&quot;, &quot;b&quot;]),</span>
<span class="gi">+                (&quot;deeply&quot;, [&quot;nested&quot;], []),</span>
<span class="gi">+            ]</span>
<span class="gi">+            if not topdown or not prune_nested:</span>
<span class="gi">+                expected.append((&quot;deeply/nested&quot;, [], [&quot;path&quot;]))</span>
<span class="gi">+            if not topdown:</span>
<span class="gi">+                expected.reverse()</span>
<span class="gi">+</span>
<span class="gi">+            result = []</span>
<span class="gi">+            for path, dirs, files in fs.walk(&quot;&quot;, topdown=topdown):</span>
<span class="gi">+                result.append((path, dirs.copy(), files))</span>
<span class="gi">+                # Bypass the &quot;nested&quot; dir</span>
<span class="gi">+                if prune_nested and &quot;nested&quot; in dirs:</span>
<span class="gi">+                    dirs.remove(&quot;nested&quot;)</span>
<span class="gi">+</span>
<span class="gi">+            # prior py3.10 zip() does not support strict=True, we need</span>
<span class="gi">+            # a manual len check here</span>
<span class="gi">+            assert len(result) == len(expected)</span>
<span class="gi">+            for lhs, rhs in zip(result, expected):</span>
<span class="gi">+                assert lhs[0] == rhs[0]</span>
<span class="gi">+                assert sorted(lhs[1]) == sorted(rhs[1])</span>
<span class="gi">+                assert sorted(lhs[2]) == sorted(rhs[2])</span>
<span class="gi">+</span>
<span class="gi">+    def test_info(self, scenario: ArchiveTestScenario):</span>
<span class="gi">+        # https://github.com/Suor/funcy/blob/1.15/funcy/colls.py#L243-L245</span>
<span class="gi">+        def project(mapping, keys):</span>
<span class="gi">+            &quot;&quot;&quot;Leaves only given keys in mapping.&quot;&quot;&quot;</span>
<span class="gi">+            return {k: mapping[k] for k in keys if k in mapping}</span>
<span class="gi">+</span>
<span class="gi">+        with scenario.provider(archive_data) as archive:</span>
<span class="gi">+            fs = fsspec.filesystem(scenario.protocol, fo=archive)</span>
<span class="gi">+</span>
<span class="gi">+            with pytest.raises(FileNotFoundError):</span>
<span class="gi">+                fs.info(&quot;i-do-not-exist&quot;)</span>
<span class="gi">+</span>
<span class="gi">+            # Iterate over all directories.</span>
<span class="gi">+            for d in fs._all_dirnames(archive_data.keys()):</span>
<span class="gi">+                lhs = project(fs.info(d), [&quot;name&quot;, &quot;size&quot;, &quot;type&quot;])</span>
<span class="gi">+                expected = {&quot;name&quot;: f&quot;{d}&quot;, &quot;size&quot;: 0, &quot;type&quot;: &quot;directory&quot;}</span>
<span class="gi">+                assert lhs == expected</span>
<span class="gi">+</span>
<span class="gi">+            # Iterate over all files.</span>
<span class="gi">+            for f, v in archive_data.items():</span>
<span class="gi">+                lhs = fs.info(f)</span>
<span class="gi">+                assert lhs[&quot;name&quot;] == f</span>
<span class="gi">+                assert lhs[&quot;size&quot;] == len(v)</span>
<span class="gi">+                assert lhs[&quot;type&quot;] == &quot;file&quot;</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;scale&quot;, [128, 512, 4096])</span>
<span class="gi">+    def test_isdir_isfile(self, scenario: ArchiveTestScenario, scale: int):</span>
<span class="gi">+        def make_nested_dir(i):</span>
<span class="gi">+            x = f&quot;{i}&quot;</span>
<span class="gi">+            table = x.maketrans(&quot;0123456789&quot;, &quot;ABCDEFGHIJ&quot;)</span>
<span class="gi">+            return &quot;/&quot;.join(x.translate(table))</span>
<span class="gi">+</span>
<span class="gi">+        scaled_data = {f&quot;{make_nested_dir(i)}/{i}&quot;: b&quot;&quot; for i in range(1, scale + 1)}</span>
<span class="gi">+        with scenario.provider(scaled_data) as archive:</span>
<span class="gi">+            fs = fsspec.filesystem(scenario.protocol, fo=archive)</span>
<span class="gi">+</span>
<span class="gi">+            lhs_dirs, lhs_files = (</span>
<span class="gi">+                fs._all_dirnames(scaled_data.keys()),</span>
<span class="gi">+                scaled_data.keys(),</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            # Warm-up the Cache, this is done in both cases anyways...</span>
<span class="gi">+            fs._get_dirs()</span>
<span class="gi">+</span>
<span class="gi">+            entries = lhs_files | lhs_dirs</span>
<span class="gi">+</span>
<span class="gi">+            assert lhs_dirs == {e for e in entries if fs.isdir(e)}</span>
<span class="gi">+            assert lhs_files == {e for e in entries if fs.isfile(e)}</span>
<span class="gi">+</span>
<span class="gi">+    def test_read_empty_file(self, scenario: ArchiveTestScenario):</span>
<span class="gi">+        with scenario.provider(archive_data) as archive:</span>
<span class="gi">+            fs = fsspec.filesystem(scenario.protocol, fo=archive)</span>
<span class="gi">+            assert fs.open(&quot;a&quot;).read() == b&quot;&quot;</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_arrow.py b/fsspec/implementations/tests/test_arrow.py</span>
<span class="gh">index 77ace24..af706c5 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_arrow.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_arrow.py</span>
<span class="gu">@@ -1,5 +1,259 @@</span>
<span class="w"> </span>import secrets
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gd">-pyarrow_fs = pytest.importorskip(&#39;pyarrow.fs&#39;)</span>
<span class="gi">+</span>
<span class="gi">+pyarrow_fs = pytest.importorskip(&quot;pyarrow.fs&quot;)</span>
<span class="w"> </span>FileSystem = pyarrow_fs.FileSystem
<span class="gd">-from fsspec.implementations.arrow import ArrowFSWrapper, HadoopFileSystem</span>
<span class="gi">+</span>
<span class="gi">+from fsspec.implementations.arrow import ArrowFSWrapper, HadoopFileSystem  # noqa</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture(scope=&quot;function&quot;)</span>
<span class="gi">+def fs():</span>
<span class="gi">+    fs, _ = FileSystem.from_uri(&quot;mock://&quot;)</span>
<span class="gi">+    return ArrowFSWrapper(fs)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture(scope=&quot;function&quot;, params=[False, True])</span>
<span class="gi">+def remote_dir(fs, request):</span>
<span class="gi">+    directory = secrets.token_hex(16)</span>
<span class="gi">+    fs.makedirs(directory)</span>
<span class="gi">+    yield (&quot;hdfs://&quot; if request.param else &quot;/&quot;) + directory</span>
<span class="gi">+    fs.rm(directory, recursive=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_protocol():</span>
<span class="gi">+    fs, _ = FileSystem.from_uri(&quot;mock://&quot;)</span>
<span class="gi">+    fss = ArrowFSWrapper(fs)</span>
<span class="gi">+    assert fss.protocol == &quot;mock&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def strip_keys(original_entry):</span>
<span class="gi">+    entry = original_entry.copy()</span>
<span class="gi">+    entry.pop(&quot;mtime&quot;)</span>
<span class="gi">+    return entry</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_strip(fs):</span>
<span class="gi">+    assert fs._strip_protocol(&quot;/a/file&quot;) == &quot;/a/file&quot;</span>
<span class="gi">+    assert fs._strip_protocol(&quot;hdfs:///a/file&quot;) == &quot;/a/file&quot;</span>
<span class="gi">+    assert fs._strip_protocol(&quot;hdfs://1.1.1.1/a/file&quot;) == &quot;/a/file&quot;</span>
<span class="gi">+    assert fs._strip_protocol(&quot;hdfs://1.1.1.1:8888/a/file&quot;) == &quot;/a/file&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_info(fs, remote_dir):</span>
<span class="gi">+    fs.touch(remote_dir + &quot;/a.txt&quot;)</span>
<span class="gi">+    remote_dir_strip_protocol = fs._strip_protocol(remote_dir)</span>
<span class="gi">+    details = fs.info(remote_dir + &quot;/a.txt&quot;)</span>
<span class="gi">+    assert details[&quot;type&quot;] == &quot;file&quot;</span>
<span class="gi">+    assert details[&quot;name&quot;] == remote_dir_strip_protocol + &quot;/a.txt&quot;</span>
<span class="gi">+    assert details[&quot;size&quot;] == 0</span>
<span class="gi">+</span>
<span class="gi">+    fs.mkdir(remote_dir + &quot;/dir&quot;)</span>
<span class="gi">+    details = fs.info(remote_dir + &quot;/dir&quot;)</span>
<span class="gi">+    assert details[&quot;type&quot;] == &quot;directory&quot;</span>
<span class="gi">+    assert details[&quot;name&quot;] == remote_dir_strip_protocol + &quot;/dir&quot;</span>
<span class="gi">+</span>
<span class="gi">+    details = fs.info(remote_dir + &quot;/dir/&quot;)</span>
<span class="gi">+    assert details[&quot;name&quot;] == remote_dir_strip_protocol + &quot;/dir/&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_move(fs, remote_dir):</span>
<span class="gi">+    fs.touch(remote_dir + &quot;/a.txt&quot;)</span>
<span class="gi">+    initial_info = fs.info(remote_dir + &quot;/a.txt&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs.move(remote_dir + &quot;/a.txt&quot;, remote_dir + &quot;/b.txt&quot;)</span>
<span class="gi">+    secondary_info = fs.info(remote_dir + &quot;/b.txt&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert not fs.exists(remote_dir + &quot;/a.txt&quot;)</span>
<span class="gi">+    assert fs.exists(remote_dir + &quot;/b.txt&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    initial_info.pop(&quot;name&quot;)</span>
<span class="gi">+    secondary_info.pop(&quot;name&quot;)</span>
<span class="gi">+    assert initial_info == secondary_info</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_move_recursive(fs, remote_dir):</span>
<span class="gi">+    src = remote_dir + &quot;/src&quot;</span>
<span class="gi">+    dest = remote_dir + &quot;/dest&quot;</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.isdir(src) is False</span>
<span class="gi">+    fs.mkdir(src)</span>
<span class="gi">+    assert fs.isdir(src)</span>
<span class="gi">+</span>
<span class="gi">+    fs.touch(src + &quot;/a.txt&quot;)</span>
<span class="gi">+    fs.mkdir(src + &quot;/b&quot;)</span>
<span class="gi">+    fs.touch(src + &quot;/b/c.txt&quot;)</span>
<span class="gi">+    fs.move(src, dest, recursive=True)</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.isdir(src) is False</span>
<span class="gi">+    assert not fs.exists(src)</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.isdir(dest)</span>
<span class="gi">+    assert fs.exists(dest)</span>
<span class="gi">+    assert fs.cat(dest + &quot;/b/c.txt&quot;) == fs.cat(dest + &quot;/a.txt&quot;) == b&quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_copy(fs, remote_dir):</span>
<span class="gi">+    fs.touch(remote_dir + &quot;/a.txt&quot;)</span>
<span class="gi">+    initial_info = fs.info(remote_dir + &quot;/a.txt&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs.copy(remote_dir + &quot;/a.txt&quot;, remote_dir + &quot;/b.txt&quot;)</span>
<span class="gi">+    secondary_info = fs.info(remote_dir + &quot;/b.txt&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.exists(remote_dir + &quot;/a.txt&quot;)</span>
<span class="gi">+    assert fs.exists(remote_dir + &quot;/b.txt&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    initial_info.pop(&quot;name&quot;)</span>
<span class="gi">+    secondary_info.pop(&quot;name&quot;)</span>
<span class="gi">+    assert strip_keys(initial_info) == strip_keys(secondary_info)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_rm(fs, remote_dir):</span>
<span class="gi">+    fs.touch(remote_dir + &quot;/a.txt&quot;)</span>
<span class="gi">+    fs.rm(remote_dir + &quot;/a.txt&quot;, recursive=True)</span>
<span class="gi">+    assert not fs.exists(remote_dir + &quot;/a.txt&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs.mkdir(remote_dir + &quot;/dir&quot;)</span>
<span class="gi">+    fs.rm(remote_dir + &quot;/dir&quot;, recursive=True)</span>
<span class="gi">+    assert not fs.exists(remote_dir + &quot;/dir&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs.mkdir(remote_dir + &quot;/dir&quot;)</span>
<span class="gi">+    fs.touch(remote_dir + &quot;/dir/a&quot;)</span>
<span class="gi">+    fs.touch(remote_dir + &quot;/dir/b&quot;)</span>
<span class="gi">+    fs.mkdir(remote_dir + &quot;/dir/c/&quot;)</span>
<span class="gi">+    fs.touch(remote_dir + &quot;/dir/c/a&quot;)</span>
<span class="gi">+    fs.rm(remote_dir + &quot;/dir&quot;, recursive=True)</span>
<span class="gi">+    assert not fs.exists(remote_dir + &quot;/dir&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_ls(fs, remote_dir):</span>
<span class="gi">+    if remote_dir != &quot;/&quot;:</span>
<span class="gi">+        remote_dir = remote_dir + &quot;/&quot;</span>
<span class="gi">+    remote_dir_strip_protocol = fs._strip_protocol(remote_dir)</span>
<span class="gi">+    fs.mkdir(remote_dir + &quot;dir/&quot;)</span>
<span class="gi">+    files = set()</span>
<span class="gi">+    for no in range(8):</span>
<span class="gi">+        file = remote_dir + f&quot;dir/test_{no}&quot;</span>
<span class="gi">+        # we also want to make sure `fs.touch` works with protocol</span>
<span class="gi">+        fs.touch(file)</span>
<span class="gi">+        files.add(remote_dir_strip_protocol + f&quot;dir/test_{no}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert set(fs.ls(remote_dir + &quot;dir/&quot;)) == files</span>
<span class="gi">+</span>
<span class="gi">+    dirs = fs.ls(remote_dir + &quot;dir/&quot;, detail=True)</span>
<span class="gi">+    expected = [fs.info(file) for file in files]</span>
<span class="gi">+</span>
<span class="gi">+    by_name = lambda details: details[&quot;name&quot;]</span>
<span class="gi">+    dirs.sort(key=by_name)</span>
<span class="gi">+    expected.sort(key=by_name)</span>
<span class="gi">+</span>
<span class="gi">+    assert dirs == expected</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mkdir(fs, remote_dir):</span>
<span class="gi">+    if remote_dir != &quot;/&quot;:</span>
<span class="gi">+        remote_dir = remote_dir + &quot;/&quot;</span>
<span class="gi">+    fs.mkdir(remote_dir + &quot;dir/&quot;)</span>
<span class="gi">+    assert fs.isdir(remote_dir + &quot;dir/&quot;)</span>
<span class="gi">+    assert len(fs.ls(remote_dir + &quot;dir/&quot;)) == 0</span>
<span class="gi">+</span>
<span class="gi">+    fs.mkdir(remote_dir + &quot;dir/sub&quot;, create_parents=False)</span>
<span class="gi">+    assert fs.isdir(remote_dir + &quot;dir/sub&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_makedirs(fs, remote_dir):</span>
<span class="gi">+    fs.makedirs(remote_dir + &quot;dir/a/b/c/&quot;)</span>
<span class="gi">+    assert fs.isdir(remote_dir + &quot;dir/a/b/c/&quot;)</span>
<span class="gi">+    assert fs.isdir(remote_dir + &quot;dir/a/b/&quot;)</span>
<span class="gi">+    assert fs.isdir(remote_dir + &quot;dir/a/&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs.makedirs(remote_dir + &quot;dir/a/b/c/&quot;, exist_ok=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_exceptions(fs, remote_dir):</span>
<span class="gi">+    with pytest.raises(FileNotFoundError):</span>
<span class="gi">+        with fs.open(remote_dir + &quot;/a.txt&quot;):</span>
<span class="gi">+            ...</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(FileNotFoundError):</span>
<span class="gi">+        fs.copy(remote_dir + &quot;/u.txt&quot;, remote_dir + &quot;/y.txt&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_open_rw(fs, remote_dir):</span>
<span class="gi">+    data = b&quot;dvc.org&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(remote_dir + &quot;/a.txt&quot;, &quot;wb&quot;) as stream:</span>
<span class="gi">+        stream.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(remote_dir + &quot;/a.txt&quot;) as stream:</span>
<span class="gi">+        assert stream.read() == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_open_rw_flush(fs, remote_dir):</span>
<span class="gi">+    data = b&quot;dvc.org&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(remote_dir + &quot;/b.txt&quot;, &quot;wb&quot;) as stream:</span>
<span class="gi">+        for _ in range(200):</span>
<span class="gi">+            stream.write(data)</span>
<span class="gi">+            stream.write(data)</span>
<span class="gi">+            stream.flush()</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(remote_dir + &quot;/b.txt&quot;, &quot;rb&quot;) as stream:</span>
<span class="gi">+        assert stream.read() == data * 400</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_open_append(fs, remote_dir):</span>
<span class="gi">+    data = b&quot;dvc.org&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(remote_dir + &quot;/a.txt&quot;, &quot;wb&quot;) as stream:</span>
<span class="gi">+        stream.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(remote_dir + &quot;/a.txt&quot;, &quot;ab&quot;) as stream:</span>
<span class="gi">+        stream.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(remote_dir + &quot;/a.txt&quot;) as stream:</span>
<span class="gi">+        assert stream.read() == 2 * data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_open_seekable(fs, remote_dir):</span>
<span class="gi">+    data = b&quot;dvc.org&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(remote_dir + &quot;/a.txt&quot;, &quot;wb&quot;) as stream:</span>
<span class="gi">+        stream.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(remote_dir + &quot;/a.txt&quot;, &quot;rb&quot;, seekable=True) as file:</span>
<span class="gi">+        file.seek(2)</span>
<span class="gi">+        assert file.read() == data[2:]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_seekable(fs, remote_dir):</span>
<span class="gi">+    data = b&quot;dvc.org&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(remote_dir + &quot;/a.txt&quot;, &quot;wb&quot;) as stream:</span>
<span class="gi">+        stream.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    for seekable in [True, False]:</span>
<span class="gi">+        with fs.open(remote_dir + &quot;/a.txt&quot;, &quot;rb&quot;, seekable=seekable) as file:</span>
<span class="gi">+            assert file.seekable() == seekable</span>
<span class="gi">+            assert file.read() == data</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(remote_dir + &quot;/a.txt&quot;, &quot;rb&quot;, seekable=False) as file:</span>
<span class="gi">+        with pytest.raises(OSError):</span>
<span class="gi">+            file.seek(5)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_get_kwargs_from_urls_hadoop_fs():</span>
<span class="gi">+    kwargs = HadoopFileSystem._get_kwargs_from_urls(</span>
<span class="gi">+        &quot;hdfs://user@localhost:8020/?replication=2&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    assert kwargs[&quot;user&quot;] == &quot;user&quot;</span>
<span class="gi">+    assert kwargs[&quot;host&quot;] == &quot;localhost&quot;</span>
<span class="gi">+    assert kwargs[&quot;port&quot;] == 8020</span>
<span class="gi">+    assert kwargs[&quot;replication&quot;] == 2</span>
<span class="gi">+</span>
<span class="gi">+    kwargs = HadoopFileSystem._get_kwargs_from_urls(&quot;hdfs://user@localhost:8020/&quot;)</span>
<span class="gi">+    assert kwargs[&quot;user&quot;] == &quot;user&quot;</span>
<span class="gi">+    assert kwargs[&quot;host&quot;] == &quot;localhost&quot;</span>
<span class="gi">+    assert kwargs[&quot;port&quot;] == 8020</span>
<span class="gi">+    assert &quot;replication&quot; not in kwargs</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_cached.py b/fsspec/implementations/tests/test_cached.py</span>
<span class="gh">index 3baa269..aa1ac22 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_cached.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_cached.py</span>
<span class="gu">@@ -3,18 +3,1130 @@ import os</span>
<span class="w"> </span>import pickle
<span class="w"> </span>import shutil
<span class="w"> </span>import tempfile
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="w"> </span>from fsspec.compression import compr
<span class="w"> </span>from fsspec.exceptions import BlocksizeMismatchError
<span class="gd">-from fsspec.implementations.cache_mapper import BasenameCacheMapper, HashCacheMapper, create_cache_mapper</span>
<span class="gd">-from fsspec.implementations.cached import CachingFileSystem, LocalTempFile, WholeFileCacheFileSystem</span>
<span class="gi">+from fsspec.implementations.cache_mapper import (</span>
<span class="gi">+    BasenameCacheMapper,</span>
<span class="gi">+    HashCacheMapper,</span>
<span class="gi">+    create_cache_mapper,</span>
<span class="gi">+)</span>
<span class="gi">+from fsspec.implementations.cached import (</span>
<span class="gi">+    CachingFileSystem,</span>
<span class="gi">+    LocalTempFile,</span>
<span class="gi">+    WholeFileCacheFileSystem,</span>
<span class="gi">+)</span>
<span class="w"> </span>from fsspec.implementations.local import make_path_posix
<span class="w"> </span>from fsspec.implementations.zip import ZipFileSystem
<span class="w"> </span>from fsspec.tests.conftest import win
<span class="gi">+</span>
<span class="w"> </span>from .test_ftp import FTPFileSystem


<span class="gi">+@pytest.fixture</span>
<span class="gi">+def local_filecache():</span>
<span class="gi">+    import tempfile</span>
<span class="gi">+</span>
<span class="gi">+    original_location = tempfile.mkdtemp()</span>
<span class="gi">+    cache_location = tempfile.mkdtemp()</span>
<span class="gi">+    original_file = os.path.join(original_location, &quot;afile&quot;)</span>
<span class="gi">+    data = b&quot;test data&quot;</span>
<span class="gi">+    with open(original_file, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    # we can access the file and read it</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;filecache&quot;, target_protocol=&quot;file&quot;, cache_storage=cache_location</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    return data, original_file, cache_location, fs</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mapper():</span>
<span class="gi">+    mapper0 = create_cache_mapper(True)</span>
<span class="gi">+    assert mapper0(&quot;somefile&quot;) == &quot;somefile&quot;</span>
<span class="gi">+    assert mapper0(&quot;/somefile&quot;) == &quot;somefile&quot;</span>
<span class="gi">+    assert mapper0(&quot;/somedir/somefile&quot;) == &quot;somefile&quot;</span>
<span class="gi">+    assert mapper0(&quot;/otherdir/somefile&quot;) == &quot;somefile&quot;</span>
<span class="gi">+</span>
<span class="gi">+    mapper1 = create_cache_mapper(False)</span>
<span class="gi">+    assert (</span>
<span class="gi">+        mapper1(&quot;somefile&quot;)</span>
<span class="gi">+        == &quot;dd00b9487898b02555b6a2d90a070586d63f93e80c70aaa60c992fa9e81a72fe&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    assert (</span>
<span class="gi">+        mapper1(&quot;/somefile&quot;)</span>
<span class="gi">+        == &quot;884c07bc2efe65c60fb9d280a620e7f180488718fb5d97736521b7f9cf5c8b37&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    assert (</span>
<span class="gi">+        mapper1(&quot;/somedir/somefile&quot;)</span>
<span class="gi">+        == &quot;67a6956e5a5f95231263f03758c1fd9254fdb1c564d311674cec56b0372d2056&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    assert (</span>
<span class="gi">+        mapper1(&quot;/otherdir/somefile&quot;)</span>
<span class="gi">+        == &quot;f043dee01ab9b752c7f2ecaeb1a5e1b2d872018e2d0a1a26c43835ebf34e7d3e&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    assert mapper0 != mapper1</span>
<span class="gi">+    assert create_cache_mapper(True) == mapper0</span>
<span class="gi">+    assert create_cache_mapper(False) == mapper1</span>
<span class="gi">+</span>
<span class="gi">+    assert hash(mapper0) != hash(mapper1)</span>
<span class="gi">+    assert hash(create_cache_mapper(True)) == hash(mapper0)</span>
<span class="gi">+    assert hash(create_cache_mapper(False)) == hash(mapper1)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(</span>
<span class="gi">+        ValueError,</span>
<span class="gi">+        match=&quot;BasenameCacheMapper requires zero or positive directory_levels&quot;,</span>
<span class="gi">+    ):</span>
<span class="gi">+        BasenameCacheMapper(-1)</span>
<span class="gi">+</span>
<span class="gi">+    mapper2 = BasenameCacheMapper(1)</span>
<span class="gi">+    assert mapper2(&quot;/somefile&quot;) == &quot;somefile&quot;</span>
<span class="gi">+    assert mapper2(&quot;/somedir/somefile&quot;) == &quot;somedir_@_somefile&quot;</span>
<span class="gi">+    assert mapper2(&quot;/otherdir/somefile&quot;) == &quot;otherdir_@_somefile&quot;</span>
<span class="gi">+    assert mapper2(&quot;/dir1/dir2/dir3/somefile&quot;) == &quot;dir3_@_somefile&quot;</span>
<span class="gi">+</span>
<span class="gi">+    assert mapper2 != mapper0</span>
<span class="gi">+    assert mapper2 != mapper1</span>
<span class="gi">+    assert BasenameCacheMapper(1) == mapper2</span>
<span class="gi">+</span>
<span class="gi">+    assert hash(mapper2) != hash(mapper0)</span>
<span class="gi">+    assert hash(mapper2) != hash(mapper1)</span>
<span class="gi">+    assert hash(BasenameCacheMapper(1)) == hash(mapper2)</span>
<span class="gi">+</span>
<span class="gi">+    mapper3 = BasenameCacheMapper(2)</span>
<span class="gi">+    assert mapper3(&quot;/somefile&quot;) == &quot;somefile&quot;</span>
<span class="gi">+    assert mapper3(&quot;/somedir/somefile&quot;) == &quot;somedir_@_somefile&quot;</span>
<span class="gi">+    assert mapper3(&quot;/otherdir/somefile&quot;) == &quot;otherdir_@_somefile&quot;</span>
<span class="gi">+    assert mapper3(&quot;/dir1/dir2/dir3/somefile&quot;) == &quot;dir2_@_dir3_@_somefile&quot;</span>
<span class="gi">+</span>
<span class="gi">+    assert mapper3 != mapper0</span>
<span class="gi">+    assert mapper3 != mapper1</span>
<span class="gi">+    assert mapper3 != mapper2</span>
<span class="gi">+    assert BasenameCacheMapper(2) == mapper3</span>
<span class="gi">+</span>
<span class="gi">+    assert hash(mapper3) != hash(mapper0)</span>
<span class="gi">+    assert hash(mapper3) != hash(mapper1)</span>
<span class="gi">+    assert hash(mapper3) != hash(mapper2)</span>
<span class="gi">+    assert hash(BasenameCacheMapper(2)) == hash(mapper3)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;cache_mapper&quot;, [BasenameCacheMapper(), BasenameCacheMapper(1), HashCacheMapper()]</span>
<span class="gi">+)</span>
<span class="gi">+@pytest.mark.parametrize(&quot;force_save_pickle&quot;, [True, False])</span>
<span class="gi">+def test_metadata(tmpdir, cache_mapper, force_save_pickle):</span>
<span class="gi">+    source = os.path.join(tmpdir, &quot;source&quot;)</span>
<span class="gi">+    afile = os.path.join(source, &quot;afile&quot;)</span>
<span class="gi">+    os.mkdir(source)</span>
<span class="gi">+    open(afile, &quot;w&quot;).write(&quot;test&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;filecache&quot;,</span>
<span class="gi">+        target_protocol=&quot;file&quot;,</span>
<span class="gi">+        cache_storage=os.path.join(tmpdir, &quot;cache&quot;),</span>
<span class="gi">+        cache_mapper=cache_mapper,</span>
<span class="gi">+    )</span>
<span class="gi">+    fs._metadata._force_save_pickle = force_save_pickle</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(afile, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read(5) == b&quot;test&quot;</span>
<span class="gi">+</span>
<span class="gi">+    afile_posix = make_path_posix(afile)</span>
<span class="gi">+    detail = fs._metadata.cached_files[0][afile_posix]</span>
<span class="gi">+    assert sorted(detail.keys()) == [&quot;blocks&quot;, &quot;fn&quot;, &quot;original&quot;, &quot;time&quot;, &quot;uid&quot;]</span>
<span class="gi">+    assert isinstance(detail[&quot;blocks&quot;], bool)</span>
<span class="gi">+    assert isinstance(detail[&quot;fn&quot;], str)</span>
<span class="gi">+    assert isinstance(detail[&quot;time&quot;], float)</span>
<span class="gi">+    assert isinstance(detail[&quot;uid&quot;], str)</span>
<span class="gi">+</span>
<span class="gi">+    assert detail[&quot;original&quot;] == afile_posix</span>
<span class="gi">+    assert detail[&quot;fn&quot;] == fs._mapper(afile_posix)</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(cache_mapper, BasenameCacheMapper):</span>
<span class="gi">+        if cache_mapper.directory_levels == 0:</span>
<span class="gi">+            assert detail[&quot;fn&quot;] == &quot;afile&quot;</span>
<span class="gi">+        else:</span>
<span class="gi">+            assert detail[&quot;fn&quot;] == &quot;source_@_afile&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_metadata_replace_pickle_with_json(tmpdir):</span>
<span class="gi">+    # For backward compatibility will allow reading of old pickled metadata.</span>
<span class="gi">+    # When the metadata is next saved, it is in json format.</span>
<span class="gi">+    source = os.path.join(tmpdir, &quot;source&quot;)</span>
<span class="gi">+    afile = os.path.join(source, &quot;afile&quot;)</span>
<span class="gi">+    os.mkdir(source)</span>
<span class="gi">+    open(afile, &quot;w&quot;).write(&quot;test&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # Save metadata in pickle format, to simulate old metadata</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;filecache&quot;,</span>
<span class="gi">+        target_protocol=&quot;file&quot;,</span>
<span class="gi">+        cache_storage=os.path.join(tmpdir, &quot;cache&quot;),</span>
<span class="gi">+    )</span>
<span class="gi">+    fs._metadata._force_save_pickle = True</span>
<span class="gi">+    with fs.open(afile, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read(5) == b&quot;test&quot;</span>
<span class="gi">+</span>
<span class="gi">+    # Confirm metadata is in pickle format</span>
<span class="gi">+    cache_fn = os.path.join(fs.storage[-1], &quot;cache&quot;)</span>
<span class="gi">+    with open(cache_fn, &quot;rb&quot;) as f:</span>
<span class="gi">+        metadata = pickle.load(f)</span>
<span class="gi">+    assert list(metadata.keys()) == [make_path_posix(afile)]</span>
<span class="gi">+</span>
<span class="gi">+    # Force rewrite of metadata, now in json format</span>
<span class="gi">+    fs._metadata._force_save_pickle = False</span>
<span class="gi">+    fs.pop_from_cache(afile)</span>
<span class="gi">+    with fs.open(afile, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read(5) == b&quot;test&quot;</span>
<span class="gi">+</span>
<span class="gi">+    # Confirm metadata is in json format</span>
<span class="gi">+    with open(cache_fn, &quot;r&quot;) as f:</span>
<span class="gi">+        metadata = json.load(f)</span>
<span class="gi">+    assert list(metadata.keys()) == [make_path_posix(afile)]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_constructor_kwargs(tmpdir):</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;filecache&quot;, target_protocol=&quot;file&quot;, same_names=True)</span>
<span class="gi">+    assert isinstance(fs._mapper, BasenameCacheMapper)</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;filecache&quot;, target_protocol=&quot;file&quot;, same_names=False)</span>
<span class="gi">+    assert isinstance(fs._mapper, HashCacheMapper)</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;filecache&quot;, target_protocol=&quot;file&quot;)</span>
<span class="gi">+    assert isinstance(fs._mapper, HashCacheMapper)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(</span>
<span class="gi">+        ValueError, match=&quot;Cannot specify both same_names and cache_mapper&quot;</span>
<span class="gi">+    ):</span>
<span class="gi">+        fs = fsspec.filesystem(</span>
<span class="gi">+            &quot;filecache&quot;,</span>
<span class="gi">+            target_protocol=&quot;file&quot;,</span>
<span class="gi">+            cache_mapper=HashCacheMapper(),</span>
<span class="gi">+            same_names=True,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_idempotent():</span>
<span class="gi">+    fs = CachingFileSystem(&quot;file&quot;)</span>
<span class="gi">+    fs2 = CachingFileSystem(&quot;file&quot;)</span>
<span class="gi">+    assert fs2 is fs</span>
<span class="gi">+    fs3 = pickle.loads(pickle.dumps(fs))</span>
<span class="gi">+    assert fs3.storage == fs.storage</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;force_save_pickle&quot;, [True, False])</span>
<span class="gi">+def test_blockcache_workflow(ftp_writable, tmp_path, force_save_pickle):</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    fs = FTPFileSystem(host, port, user, pw)</span>
<span class="gi">+    with fs.open(&quot;/out&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;test\n&quot; * 4096)</span>
<span class="gi">+</span>
<span class="gi">+    fs_kwargs = {</span>
<span class="gi">+        &quot;skip_instance_cache&quot;: True,</span>
<span class="gi">+        &quot;cache_storage&quot;: str(tmp_path),</span>
<span class="gi">+        &quot;target_protocol&quot;: &quot;ftp&quot;,</span>
<span class="gi">+        &quot;target_options&quot;: {</span>
<span class="gi">+            &quot;host&quot;: host,</span>
<span class="gi">+            &quot;port&quot;: port,</span>
<span class="gi">+            &quot;username&quot;: user,</span>
<span class="gi">+            &quot;password&quot;: pw,</span>
<span class="gi">+        },</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+    # Open the blockcache and read a little bit of the data</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;blockcache&quot;, **fs_kwargs)</span>
<span class="gi">+    fs._metadata._force_save_pickle = force_save_pickle</span>
<span class="gi">+    with fs.open(&quot;/out&quot;, &quot;rb&quot;, block_size=5) as f:</span>
<span class="gi">+        assert f.read(5) == b&quot;test\n&quot;</span>
<span class="gi">+</span>
<span class="gi">+    # Save the cache/close it</span>
<span class="gi">+    fs.save_cache()</span>
<span class="gi">+    del fs</span>
<span class="gi">+</span>
<span class="gi">+    # Check that cache file only has the first two blocks</span>
<span class="gi">+    if force_save_pickle:</span>
<span class="gi">+        with open(tmp_path / &quot;cache&quot;, &quot;rb&quot;) as f:</span>
<span class="gi">+            cache = pickle.load(f)</span>
<span class="gi">+    else:</span>
<span class="gi">+        with open(tmp_path / &quot;cache&quot;, &quot;r&quot;) as f:</span>
<span class="gi">+            cache = json.load(f)</span>
<span class="gi">+    assert &quot;/out&quot; in cache</span>
<span class="gi">+    assert cache[&quot;/out&quot;][&quot;blocks&quot;] == [0, 1]</span>
<span class="gi">+</span>
<span class="gi">+    # Reopen the same cache and read some more...</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;blockcache&quot;, **fs_kwargs)</span>
<span class="gi">+    fs._metadata._force_save_pickle = force_save_pickle</span>
<span class="gi">+    with fs.open(&quot;/out&quot;, block_size=5) as f:</span>
<span class="gi">+        assert f.read(5) == b&quot;test\n&quot;</span>
<span class="gi">+        f.seek(30)</span>
<span class="gi">+        assert f.read(5) == b&quot;test\n&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;impl&quot;, [&quot;filecache&quot;, &quot;blockcache&quot;])</span>
<span class="gi">+def test_workflow(ftp_writable, impl):</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    fs = FTPFileSystem(host, port, user, pw)</span>
<span class="gi">+    with fs.open(&quot;/out&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;test&quot;)</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        impl,</span>
<span class="gi">+        target_protocol=&quot;ftp&quot;,</span>
<span class="gi">+        target_options={&quot;host&quot;: host, &quot;port&quot;: port, &quot;username&quot;: user, &quot;password&quot;: pw},</span>
<span class="gi">+    )</span>
<span class="gi">+    assert os.listdir(fs.storage[-1]) == []</span>
<span class="gi">+    with fs.open(&quot;/out&quot;) as f:</span>
<span class="gi">+        assert os.listdir(fs.storage[-1])</span>
<span class="gi">+        assert f.read() == b&quot;test&quot;</span>
<span class="gi">+        assert fs._metadata.cached_files[-1][&quot;/out&quot;][&quot;blocks&quot;]</span>
<span class="gi">+    assert fs.cat(&quot;/out&quot;) == b&quot;test&quot;</span>
<span class="gi">+    assert fs._metadata.cached_files[-1][&quot;/out&quot;][&quot;blocks&quot;] is True</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(&quot;/out&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;changed&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if impl == &quot;filecache&quot;:</span>
<span class="gi">+        assert (</span>
<span class="gi">+            fs.cat(&quot;/out&quot;) == b&quot;changed&quot;</span>
<span class="gi">+        )  # new value, because we overwrote the cached location</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;impl&quot;, [&quot;simplecache&quot;, &quot;blockcache&quot;])</span>
<span class="gi">+def test_glob(ftp_writable, impl):</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    fs = FTPFileSystem(host, port, user, pw)</span>
<span class="gi">+    with fs.open(&quot;/out&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;test&quot;)</span>
<span class="gi">+    with fs.open(&quot;/out2&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;test2&quot;)</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        impl,</span>
<span class="gi">+        target_protocol=&quot;ftp&quot;,</span>
<span class="gi">+        target_options={&quot;host&quot;: host, &quot;port&quot;: port, &quot;username&quot;: user, &quot;password&quot;: pw},</span>
<span class="gi">+    )</span>
<span class="gi">+    assert fs.glob(&quot;/wrong*&quot;) == []</span>
<span class="gi">+    assert fs.glob(&quot;/ou*&quot;) == [&quot;/out&quot;, &quot;/out2&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_write():</span>
<span class="gi">+    tmp = str(tempfile.mkdtemp())</span>
<span class="gi">+    fn = tmp + &quot;afile&quot;</span>
<span class="gi">+    url = f&quot;simplecache::file://{fn}&quot;</span>
<span class="gi">+    with fsspec.open(url, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;hello&quot;)</span>
<span class="gi">+        assert fn not in f.name</span>
<span class="gi">+        assert not os.listdir(tmp)</span>
<span class="gi">+</span>
<span class="gi">+    assert open(fn, &quot;rb&quot;).read() == b&quot;hello&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_clear():</span>
<span class="gi">+    import tempfile</span>
<span class="gi">+</span>
<span class="gi">+    origin = tempfile.mkdtemp()</span>
<span class="gi">+    cache1 = tempfile.mkdtemp()</span>
<span class="gi">+    data = b&quot;test data&quot;</span>
<span class="gi">+    f1 = os.path.join(origin, &quot;afile&quot;)</span>
<span class="gi">+    with open(f1, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    # populates first cache</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;filecache&quot;, target_protocol=&quot;file&quot;, cache_storage=cache1)</span>
<span class="gi">+    assert fs.cat(f1) == data</span>
<span class="gi">+</span>
<span class="gi">+    assert &quot;cache&quot; in os.listdir(cache1)</span>
<span class="gi">+    assert len(os.listdir(cache1)) == 2</span>
<span class="gi">+    assert fs._check_file(f1)</span>
<span class="gi">+</span>
<span class="gi">+    fs.clear_cache()</span>
<span class="gi">+    assert not fs._check_file(f1)</span>
<span class="gi">+    assert len(os.listdir(cache1)) &lt; 2</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;force_save_pickle&quot;, [True, False])</span>
<span class="gi">+def test_clear_expired(tmp_path, force_save_pickle):</span>
<span class="gi">+    def __ager(cache_fn, fn, del_fn=False):</span>
<span class="gi">+        &quot;&quot;&quot;</span>
<span class="gi">+        Modify the cache file to virtually add time lag to selected files.</span>
<span class="gi">+</span>
<span class="gi">+        Parameters</span>
<span class="gi">+        ---------</span>
<span class="gi">+        cache_fn: str</span>
<span class="gi">+            cache path</span>
<span class="gi">+        fn: str</span>
<span class="gi">+            file name to be modified</span>
<span class="gi">+        del_fn: bool</span>
<span class="gi">+            whether or not to delete &#39;fn&#39; from cache details</span>
<span class="gi">+        &quot;&quot;&quot;</span>
<span class="gi">+        import pathlib</span>
<span class="gi">+        import time</span>
<span class="gi">+</span>
<span class="gi">+        if os.path.exists(cache_fn):</span>
<span class="gi">+            if force_save_pickle:</span>
<span class="gi">+                with open(cache_fn, &quot;rb&quot;) as f:</span>
<span class="gi">+                    cached_files = pickle.load(f)</span>
<span class="gi">+            else:</span>
<span class="gi">+                with open(cache_fn, &quot;r&quot;) as f:</span>
<span class="gi">+                    cached_files = json.load(f)</span>
<span class="gi">+            fn_posix = pathlib.Path(fn).as_posix()</span>
<span class="gi">+            cached_files[fn_posix][&quot;time&quot;] = cached_files[fn_posix][&quot;time&quot;] - 691200</span>
<span class="gi">+            assert os.access(cache_fn, os.W_OK), &quot;Cache is not writable&quot;</span>
<span class="gi">+            if del_fn:</span>
<span class="gi">+                del cached_files[fn_posix][&quot;fn&quot;]</span>
<span class="gi">+            if force_save_pickle:</span>
<span class="gi">+                with open(cache_fn, &quot;wb&quot;) as f:</span>
<span class="gi">+                    pickle.dump(cached_files, f)</span>
<span class="gi">+            else:</span>
<span class="gi">+                with open(cache_fn, &quot;w&quot;) as f:</span>
<span class="gi">+                    json.dump(cached_files, f)</span>
<span class="gi">+            time.sleep(1)</span>
<span class="gi">+</span>
<span class="gi">+    origin = tmp_path.joinpath(&quot;origin&quot;)</span>
<span class="gi">+    cache1 = tmp_path.joinpath(&quot;cache1&quot;)</span>
<span class="gi">+    cache2 = tmp_path.joinpath(&quot;cache2&quot;)</span>
<span class="gi">+    cache3 = tmp_path.joinpath(&quot;cache3&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    origin.mkdir()</span>
<span class="gi">+    cache1.mkdir()</span>
<span class="gi">+    cache2.mkdir()</span>
<span class="gi">+    cache3.mkdir()</span>
<span class="gi">+</span>
<span class="gi">+    data = b&quot;test data&quot;</span>
<span class="gi">+    f1 = origin.joinpath(&quot;afile&quot;)</span>
<span class="gi">+    f2 = origin.joinpath(&quot;bfile&quot;)</span>
<span class="gi">+    f3 = origin.joinpath(&quot;cfile&quot;)</span>
<span class="gi">+    f4 = origin.joinpath(&quot;dfile&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with open(f1, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+    with open(f2, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+    with open(f3, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+    with open(f4, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    # populates first cache</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;filecache&quot;, target_protocol=&quot;file&quot;, cache_storage=str(cache1), cache_check=1</span>
<span class="gi">+    )</span>
<span class="gi">+    fs._metadata._force_save_pickle = force_save_pickle</span>
<span class="gi">+    assert fs.cat(str(f1)) == data</span>
<span class="gi">+</span>
<span class="gi">+    # populates &quot;last&quot; cache if file not found in first one</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;filecache&quot;,</span>
<span class="gi">+        target_protocol=&quot;file&quot;,</span>
<span class="gi">+        cache_storage=[str(cache1), str(cache2)],</span>
<span class="gi">+        cache_check=1,</span>
<span class="gi">+    )</span>
<span class="gi">+    fs._metadata._force_save_pickle = force_save_pickle</span>
<span class="gi">+    assert fs.cat(str(f2)) == data</span>
<span class="gi">+    assert fs.cat(str(f3)) == data</span>
<span class="gi">+    assert len(os.listdir(cache2)) == 3</span>
<span class="gi">+</span>
<span class="gi">+    # force the expiration</span>
<span class="gi">+    cache_fn = os.path.join(fs.storage[-1], &quot;cache&quot;)</span>
<span class="gi">+    __ager(cache_fn, f2)</span>
<span class="gi">+</span>
<span class="gi">+    # remove from cache2 the expired files</span>
<span class="gi">+    fs.clear_expired_cache()</span>
<span class="gi">+    assert len(os.listdir(cache2)) == 2</span>
<span class="gi">+</span>
<span class="gi">+    # check complete cleanup</span>
<span class="gi">+    __ager(cache_fn, f3)</span>
<span class="gi">+</span>
<span class="gi">+    fs.clear_expired_cache()</span>
<span class="gi">+    assert not fs._check_file(f2)</span>
<span class="gi">+    assert not fs._check_file(f3)</span>
<span class="gi">+    assert len(os.listdir(cache2)) &lt; 2</span>
<span class="gi">+</span>
<span class="gi">+    # check cache1 to be untouched after cleaning</span>
<span class="gi">+    assert len(os.listdir(cache1)) == 2</span>
<span class="gi">+</span>
<span class="gi">+    # check cleaning with &#39;same_name&#39; option enabled</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;filecache&quot;,</span>
<span class="gi">+        target_protocol=&quot;file&quot;,</span>
<span class="gi">+        cache_storage=[str(cache1), str(cache2), str(cache3)],</span>
<span class="gi">+        same_names=True,</span>
<span class="gi">+        cache_check=1,</span>
<span class="gi">+    )</span>
<span class="gi">+    fs._metadata._force_save_pickle = force_save_pickle</span>
<span class="gi">+    assert fs.cat(str(f4)) == data</span>
<span class="gi">+</span>
<span class="gi">+    cache_fn = os.path.join(fs.storage[-1], &quot;cache&quot;)</span>
<span class="gi">+    __ager(cache_fn, f4)</span>
<span class="gi">+</span>
<span class="gi">+    fs.clear_expired_cache()</span>
<span class="gi">+    assert not fs._check_file(str(f4))</span>
<span class="gi">+</span>
<span class="gi">+    # check cache metadata lacking &#39;fn&#39; raises RuntimeError.</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;filecache&quot;,</span>
<span class="gi">+        target_protocol=&quot;file&quot;,</span>
<span class="gi">+        cache_storage=str(cache1),</span>
<span class="gi">+        same_names=True,</span>
<span class="gi">+        cache_check=1,</span>
<span class="gi">+    )</span>
<span class="gi">+    fs._metadata._force_save_pickle = force_save_pickle</span>
<span class="gi">+    assert fs.cat(str(f1)) == data</span>
<span class="gi">+</span>
<span class="gi">+    cache_fn = os.path.join(fs.storage[-1], &quot;cache&quot;)</span>
<span class="gi">+    __ager(cache_fn, f1, del_fn=True)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(RuntimeError, match=&quot;Cache metadata does not contain &#39;fn&#39; for&quot;):</span>
<span class="gi">+        fs.clear_expired_cache()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_pop():</span>
<span class="gi">+    import tempfile</span>
<span class="gi">+</span>
<span class="gi">+    origin = tempfile.mkdtemp()</span>
<span class="gi">+    cache1 = tempfile.mkdtemp()</span>
<span class="gi">+    cache2 = tempfile.mkdtemp()</span>
<span class="gi">+    data = b&quot;test data&quot;</span>
<span class="gi">+    f1 = os.path.join(origin, &quot;afile&quot;)</span>
<span class="gi">+    f2 = os.path.join(origin, &quot;bfile&quot;)</span>
<span class="gi">+    with open(f1, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+    with open(f2, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    # populates first cache</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;filecache&quot;, target_protocol=&quot;file&quot;, cache_storage=cache1)</span>
<span class="gi">+    fs.cat(f1)</span>
<span class="gi">+</span>
<span class="gi">+    # populates last cache if file not found in first cache</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;filecache&quot;, target_protocol=&quot;file&quot;, cache_storage=[cache1, cache2]</span>
<span class="gi">+    )</span>
<span class="gi">+    assert fs.cat(f2) == data</span>
<span class="gi">+    assert len(os.listdir(cache2)) == 2</span>
<span class="gi">+    assert fs._check_file(f1)</span>
<span class="gi">+    with pytest.raises(PermissionError):</span>
<span class="gi">+        fs.pop_from_cache(f1)</span>
<span class="gi">+    fs.pop_from_cache(f2)</span>
<span class="gi">+    fs.pop_from_cache(os.path.join(origin, &quot;uncached-file&quot;))</span>
<span class="gi">+    assert len(os.listdir(cache2)) == 1</span>
<span class="gi">+    assert not fs._check_file(f2)</span>
<span class="gi">+    assert fs._check_file(f1)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_write_pickle_context():</span>
<span class="gi">+    tmp = str(tempfile.mkdtemp())</span>
<span class="gi">+    fn = tmp + &quot;afile&quot;</span>
<span class="gi">+    url = f&quot;simplecache::file://{fn}&quot;</span>
<span class="gi">+    with fsspec.open(url, &quot;wb&quot;) as f:</span>
<span class="gi">+        pickle.loads(pickle.dumps(f))</span>
<span class="gi">+        f.write(b&quot;hello &quot;)</span>
<span class="gi">+        pickle.dumps(f)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        pickle.dumps(f)</span>
<span class="gi">+</span>
<span class="gi">+    assert open(fn, &quot;rb&quot;).read() == b&quot;hello &quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_blocksize(ftp_writable):</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    fs = FTPFileSystem(host, port, user, pw)</span>
<span class="gi">+    with fs.open(&quot;/out_block&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;test&quot; * 4000)</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;blockcache&quot;,</span>
<span class="gi">+        target_protocol=&quot;ftp&quot;,</span>
<span class="gi">+        target_options={&quot;host&quot;: host, &quot;port&quot;: port, &quot;username&quot;: user, &quot;password&quot;: pw},</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(&quot;/out_block&quot;, block_size=20) as f:</span>
<span class="gi">+        assert f.read(1) == b&quot;t&quot;</span>
<span class="gi">+    with pytest.raises(BlocksizeMismatchError):</span>
<span class="gi">+        fs.open(&quot;/out_block&quot;, block_size=30)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_blockcache_multiinstance(ftp_writable):</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    fs = FTPFileSystem(host, port, user, pw)</span>
<span class="gi">+    with fs.open(&quot;/one&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;test&quot; * 40)</span>
<span class="gi">+    with fs.open(&quot;/two&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;test&quot; * 40)</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;blockcache&quot;,</span>
<span class="gi">+        target_protocol=&quot;ftp&quot;,</span>
<span class="gi">+        target_options={&quot;host&quot;: host, &quot;port&quot;: port, &quot;username&quot;: user, &quot;password&quot;: pw},</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(&quot;/one&quot;, block_size=20) as f:</span>
<span class="gi">+        assert f.read(1) == b&quot;t&quot;</span>
<span class="gi">+    fs2 = fsspec.filesystem(</span>
<span class="gi">+        &quot;blockcache&quot;,</span>
<span class="gi">+        target_protocol=&quot;ftp&quot;,</span>
<span class="gi">+        target_options={&quot;host&quot;: host, &quot;port&quot;: port, &quot;username&quot;: user, &quot;password&quot;: pw},</span>
<span class="gi">+        skip_instance_cache=True,</span>
<span class="gi">+        cache_storage=fs.storage,</span>
<span class="gi">+    )</span>
<span class="gi">+    assert fs2._metadata.cached_files  # loaded from metadata for &quot;one&quot;</span>
<span class="gi">+    with fs2.open(&quot;/two&quot;, block_size=20) as f:</span>
<span class="gi">+        assert f.read(1) == b&quot;t&quot;</span>
<span class="gi">+    assert &quot;/two&quot; in fs2._metadata.cached_files[-1]</span>
<span class="gi">+    fs.save_cache()</span>
<span class="gi">+    assert list(fs._metadata.cached_files[-1]) == [&quot;/one&quot;, &quot;/two&quot;]</span>
<span class="gi">+    assert list(fs2._metadata.cached_files[-1]) == [&quot;/one&quot;, &quot;/two&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_metadata_save_blocked(ftp_writable, caplog):</span>
<span class="gi">+    import logging</span>
<span class="gi">+</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    fs = FTPFileSystem(host, port, user, pw)</span>
<span class="gi">+    with fs.open(&quot;/one&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;test&quot; * 40)</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;blockcache&quot;,</span>
<span class="gi">+        target_protocol=&quot;ftp&quot;,</span>
<span class="gi">+        target_options={&quot;host&quot;: host, &quot;port&quot;: port, &quot;username&quot;: user, &quot;password&quot;: pw},</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(&quot;/one&quot;, block_size=20) as f:</span>
<span class="gi">+        assert f.read(1) == b&quot;t&quot;</span>
<span class="gi">+    fn = os.path.join(fs.storage[-1], &quot;cache&quot;)</span>
<span class="gi">+    with caplog.at_level(logging.DEBUG):</span>
<span class="gi">+        with fs.open(&quot;/one&quot;, block_size=20) as f:</span>
<span class="gi">+            f.seek(21)</span>
<span class="gi">+            assert f.read(1)</span>
<span class="gi">+            os.remove(fn)</span>
<span class="gi">+            os.mkdir(fn)</span>
<span class="gi">+    assert &quot;Cache saving failed while closing file&quot; in caplog.text</span>
<span class="gi">+    os.rmdir(fn)</span>
<span class="gi">+</span>
<span class="gi">+    def open_raise(*_, **__):</span>
<span class="gi">+        raise NameError</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        # To simulate an interpreter shutdown we temporarily set an open function in the</span>
<span class="gi">+        # cache_metadata module which is used on the next attempt to save metadata.</span>
<span class="gi">+        with caplog.at_level(logging.DEBUG):</span>
<span class="gi">+            with fs.open(&quot;/one&quot;, block_size=20) as f:</span>
<span class="gi">+                fsspec.implementations.cache_metadata.open = open_raise</span>
<span class="gi">+                f.seek(21)</span>
<span class="gi">+                assert f.read(1)</span>
<span class="gi">+    finally:</span>
<span class="gi">+        fsspec.implementations.cache_metadata.__dict__.pop(&quot;open&quot;, None)</span>
<span class="gi">+    assert &quot;Cache save failed due to interpreter shutdown&quot; in caplog.text</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;impl&quot;, [&quot;filecache&quot;, &quot;simplecache&quot;, &quot;blockcache&quot;])</span>
<span class="gi">+def test_local_filecache_creates_dir_if_needed(impl):</span>
<span class="gi">+    import tempfile</span>
<span class="gi">+</span>
<span class="gi">+    original_location = tempfile.mkdtemp()</span>
<span class="gi">+    cache_location = tempfile.mkdtemp()</span>
<span class="gi">+    os.rmdir(cache_location)</span>
<span class="gi">+    assert not os.path.exists(cache_location)</span>
<span class="gi">+</span>
<span class="gi">+    original_file = os.path.join(original_location, &quot;afile&quot;)</span>
<span class="gi">+    data = b&quot;test data&quot;</span>
<span class="gi">+    with open(original_file, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    # we can access the file and read it</span>
<span class="gi">+    fs = fsspec.filesystem(impl, target_protocol=&quot;file&quot;, cache_storage=cache_location)</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(original_file, &quot;rb&quot;) as f:</span>
<span class="gi">+        data_in_cache = f.read()</span>
<span class="gi">+</span>
<span class="gi">+    assert os.path.exists(cache_location)</span>
<span class="gi">+</span>
<span class="gi">+    assert data_in_cache == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;toplevel&quot;, [True, False])</span>
<span class="gi">+@pytest.mark.parametrize(&quot;impl&quot;, [&quot;filecache&quot;, &quot;simplecache&quot;, &quot;blockcache&quot;])</span>
<span class="gi">+def test_get_mapper(impl, toplevel):</span>
<span class="gi">+    import tempfile</span>
<span class="gi">+</span>
<span class="gi">+    original_location = tempfile.mkdtemp()</span>
<span class="gi">+    cache_location = tempfile.mkdtemp()</span>
<span class="gi">+    os.rmdir(cache_location)</span>
<span class="gi">+    original_file = os.path.join(original_location, &quot;afile&quot;)</span>
<span class="gi">+    data = b&quot;test data&quot;</span>
<span class="gi">+    with open(original_file, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    if toplevel:</span>
<span class="gi">+        m = fsspec.get_mapper(</span>
<span class="gi">+            f&quot;{impl}::file://{original_location}&quot;,</span>
<span class="gi">+            **{impl: {&quot;cache_storage&quot;: cache_location}},</span>
<span class="gi">+        )</span>
<span class="gi">+    else:</span>
<span class="gi">+        fs = fsspec.filesystem(</span>
<span class="gi">+            impl, target_protocol=&quot;file&quot;, cache_storage=cache_location</span>
<span class="gi">+        )</span>
<span class="gi">+        m = fs.get_mapper(original_location)</span>
<span class="gi">+</span>
<span class="gi">+    assert m[&quot;afile&quot;] == data</span>
<span class="gi">+    assert os.listdir(cache_location)</span>
<span class="gi">+    assert m[&quot;afile&quot;] == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_local_filecache_basic(local_filecache):</span>
<span class="gi">+    data, original_file, cache_location, fs = local_filecache</span>
<span class="gi">+</span>
<span class="gi">+    # reading from the file contains the right data</span>
<span class="gi">+    with fs.open(original_file, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+    assert &quot;cache&quot; in os.listdir(cache_location)</span>
<span class="gi">+</span>
<span class="gi">+    # the file in the location contains the right data</span>
<span class="gi">+    fn = list(fs._metadata.cached_files[-1].values())[0][&quot;fn&quot;]  # this is a hash value</span>
<span class="gi">+    assert fn in os.listdir(cache_location)</span>
<span class="gi">+    with open(os.path.join(cache_location, fn), &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+</span>
<span class="gi">+    # still there when original file is removed (check=False)</span>
<span class="gi">+    os.remove(original_file)</span>
<span class="gi">+    with fs.open(original_file, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_local_filecache_does_not_change_when_original_data_changed(local_filecache):</span>
<span class="gi">+    old_data, original_file, cache_location, fs = local_filecache</span>
<span class="gi">+    new_data = b&quot;abc&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(original_file, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == old_data</span>
<span class="gi">+</span>
<span class="gi">+    with open(original_file, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(new_data)</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(original_file, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == old_data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_local_filecache_gets_from_original_if_cache_deleted(local_filecache):</span>
<span class="gi">+    old_data, original_file, cache_location, fs = local_filecache</span>
<span class="gi">+    new_data = b&quot;abc&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(original_file, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == old_data</span>
<span class="gi">+</span>
<span class="gi">+    with open(original_file, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(new_data)</span>
<span class="gi">+</span>
<span class="gi">+    shutil.rmtree(cache_location)</span>
<span class="gi">+    assert os.path.exists(original_file)</span>
<span class="gi">+</span>
<span class="gi">+    with open(original_file, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == new_data</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(original_file, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == new_data</span>
<span class="gi">+</span>
<span class="gi">+    # the file in the location contains the right data</span>
<span class="gi">+    fn = list(fs._metadata.cached_files[-1].values())[0][&quot;fn&quot;]  # this is a hash value</span>
<span class="gi">+    assert fn in os.listdir(cache_location)</span>
<span class="gi">+    with open(os.path.join(cache_location, fn), &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == new_data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_local_filecache_with_new_cache_location_makes_a_new_copy(local_filecache):</span>
<span class="gi">+    import tempfile</span>
<span class="gi">+</span>
<span class="gi">+    data, original_file, old_cache_location, old_fs = local_filecache</span>
<span class="gi">+    new_cache_location = tempfile.mkdtemp()</span>
<span class="gi">+</span>
<span class="gi">+    with old_fs.open(original_file, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+</span>
<span class="gi">+    new_fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;filecache&quot;, target_protocol=&quot;file&quot;, cache_storage=new_cache_location</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    with new_fs.open(original_file, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+</span>
<span class="gi">+    # the file in the location contains the right data</span>
<span class="gi">+    fn = list(new_fs._metadata.cached_files[-1].values())[0][</span>
<span class="gi">+        &quot;fn&quot;</span>
<span class="gi">+    ]  # this is a hash value</span>
<span class="gi">+    assert fn in os.listdir(old_cache_location)</span>
<span class="gi">+    assert fn in os.listdir(new_cache_location)</span>
<span class="gi">+</span>
<span class="gi">+    with open(os.path.join(new_cache_location, fn), &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_filecache_multicache():</span>
<span class="gi">+    import tempfile</span>
<span class="gi">+</span>
<span class="gi">+    origin = tempfile.mkdtemp()</span>
<span class="gi">+    cache1 = tempfile.mkdtemp()</span>
<span class="gi">+    cache2 = tempfile.mkdtemp()</span>
<span class="gi">+    data = b&quot;test data&quot;</span>
<span class="gi">+    f1 = os.path.join(origin, &quot;afile&quot;)</span>
<span class="gi">+    f2 = os.path.join(origin, &quot;bfile&quot;)</span>
<span class="gi">+    with open(f1, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+    with open(f2, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data * 2)</span>
<span class="gi">+</span>
<span class="gi">+    # populates first cache</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;filecache&quot;, target_protocol=&quot;file&quot;, cache_storage=cache1)</span>
<span class="gi">+    assert fs.cat(f1) == data</span>
<span class="gi">+</span>
<span class="gi">+    assert len(os.listdir(cache1)) == 2  # cache and hashed afile</span>
<span class="gi">+    assert len(os.listdir(cache2)) == 0  # hasn&#39;t been initialized yet</span>
<span class="gi">+</span>
<span class="gi">+    # populates last cache if file not found in first cache</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;filecache&quot;, target_protocol=&quot;file&quot;, cache_storage=[cache1, cache2]</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.cat(f1) == data</span>
<span class="gi">+    assert fs.cat(f2) == data * 2</span>
<span class="gi">+</span>
<span class="gi">+    assert &quot;cache&quot; in os.listdir(cache1)</span>
<span class="gi">+    assert &quot;cache&quot; in os.listdir(cache2)</span>
<span class="gi">+</span>
<span class="gi">+    cache1_contents = [f for f in os.listdir(cache1) if f != &quot;cache&quot;]</span>
<span class="gi">+    assert len(cache1_contents) == 1</span>
<span class="gi">+</span>
<span class="gi">+    with open(os.path.join(cache1, cache1_contents[0]), &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+</span>
<span class="gi">+    cache2_contents = [f for f in os.listdir(cache2) if f != &quot;cache&quot;]</span>
<span class="gi">+    assert len(cache2_contents) == 1</span>
<span class="gi">+</span>
<span class="gi">+    with open(os.path.join(cache2, cache2_contents[0]), &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == data * 2</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;impl&quot;, [&quot;filecache&quot;, &quot;simplecache&quot;])</span>
<span class="gi">+def test_filecache_multicache_with_same_file_different_data_reads_from_first(impl):</span>
<span class="gi">+    import tempfile</span>
<span class="gi">+</span>
<span class="gi">+    origin = tempfile.mkdtemp()</span>
<span class="gi">+    cache1 = tempfile.mkdtemp()</span>
<span class="gi">+    cache2 = tempfile.mkdtemp()</span>
<span class="gi">+    data = b&quot;test data&quot;</span>
<span class="gi">+    f1 = os.path.join(origin, &quot;afile&quot;)</span>
<span class="gi">+    with open(f1, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    # populate first cache</span>
<span class="gi">+    fs1 = fsspec.filesystem(impl, target_protocol=&quot;file&quot;, cache_storage=cache1)</span>
<span class="gi">+    assert fs1.cat(f1) == data</span>
<span class="gi">+</span>
<span class="gi">+    with open(f1, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data * 2)</span>
<span class="gi">+</span>
<span class="gi">+    # populate second cache</span>
<span class="gi">+    fs2 = fsspec.filesystem(impl, target_protocol=&quot;file&quot;, cache_storage=cache2)</span>
<span class="gi">+</span>
<span class="gi">+    assert fs2.cat(f1) == data * 2</span>
<span class="gi">+</span>
<span class="gi">+    # the filenames in each cache are the same, but the data is different</span>
<span class="gi">+    assert sorted(os.listdir(cache1)) == sorted(os.listdir(cache2))</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(impl, target_protocol=&quot;file&quot;, cache_storage=[cache1, cache2])</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.cat(f1) == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_filecache_with_checks():</span>
<span class="gi">+    import time</span>
<span class="gi">+</span>
<span class="gi">+    origin = tempfile.mkdtemp()</span>
<span class="gi">+    cache1 = tempfile.mkdtemp()</span>
<span class="gi">+    data = b&quot;test data&quot;</span>
<span class="gi">+    f1 = os.path.join(origin, &quot;afile&quot;)</span>
<span class="gi">+    with open(f1, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    # populate first cache</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;filecache&quot;, target_protocol=&quot;file&quot;, cache_storage=cache1, expiry_time=0.1</span>
<span class="gi">+    )</span>
<span class="gi">+    fs2 = fsspec.filesystem(</span>
<span class="gi">+        &quot;filecache&quot;, target_protocol=&quot;file&quot;, cache_storage=cache1, check_files=True</span>
<span class="gi">+    )</span>
<span class="gi">+    assert fs.cat(f1) == data</span>
<span class="gi">+    assert fs2.cat(f1) == data</span>
<span class="gi">+</span>
<span class="gi">+    with open(f1, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data * 2)</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.cat(f1) == data  # does not change</span>
<span class="gi">+    assert fs2.cat(f1) == data * 2  # changed, since origin changed</span>
<span class="gi">+    with fs2.open(f1) as f:</span>
<span class="gi">+        assert f.read() == data * 2  # read also sees new data</span>
<span class="gi">+    time.sleep(0.11)  # allow cache details to expire</span>
<span class="gi">+    assert fs.cat(f1) == data * 2  # changed, since origin changed</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;impl&quot;, [&quot;filecache&quot;, &quot;simplecache&quot;, &quot;blockcache&quot;])</span>
<span class="gi">+@pytest.mark.parametrize(&quot;fs&quot;, [&quot;local&quot;, &quot;multi&quot;], indirect=[&quot;fs&quot;])</span>
<span class="gi">+def test_filecache_takes_fs_instance(impl, fs):</span>
<span class="gi">+    origin = tempfile.mkdtemp()</span>
<span class="gi">+    data = b&quot;test data&quot;</span>
<span class="gi">+    f1 = os.path.join(origin, &quot;afile&quot;)</span>
<span class="gi">+    with open(f1, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    fs2 = fsspec.filesystem(impl, fs=fs)</span>
<span class="gi">+</span>
<span class="gi">+    assert fs2.cat(f1) == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;impl&quot;, [&quot;filecache&quot;, &quot;simplecache&quot;, &quot;blockcache&quot;])</span>
<span class="gi">+@pytest.mark.parametrize(&quot;fs&quot;, [&quot;local&quot;, &quot;multi&quot;], indirect=[&quot;fs&quot;])</span>
<span class="gi">+def test_filecache_serialization(impl, fs):</span>
<span class="gi">+    fs1 = fsspec.filesystem(impl, fs=fs)</span>
<span class="gi">+    json1 = fs1.to_json()</span>
<span class="gi">+</span>
<span class="gi">+    assert fs1 is fsspec.AbstractFileSystem.from_json(json1)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_add_file_to_cache_after_save(local_filecache):</span>
<span class="gi">+    (data, original_file, cache_location, fs) = local_filecache</span>
<span class="gi">+</span>
<span class="gi">+    fs.save_cache()</span>
<span class="gi">+</span>
<span class="gi">+    fs.cat(original_file)</span>
<span class="gi">+    assert len(fs._metadata.cached_files[-1]) == 1</span>
<span class="gi">+</span>
<span class="gi">+    fs.save_cache()</span>
<span class="gi">+</span>
<span class="gi">+    fs2 = fsspec.filesystem(</span>
<span class="gi">+        &quot;filecache&quot;,</span>
<span class="gi">+        target_protocol=&quot;file&quot;,</span>
<span class="gi">+        cache_storage=cache_location,</span>
<span class="gi">+        do_not_use_cache_for_this_instance=True,  # cache is masking the issue</span>
<span class="gi">+    )</span>
<span class="gi">+    assert len(fs2._metadata.cached_files[-1]) == 1</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_cached_open_close_read(ftp_writable):</span>
<span class="gi">+    # Regression test for &lt;https://github.com/fsspec/filesystem_spec/issues/799&gt;</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    fs = FTPFileSystem(host, port, user, pw)</span>
<span class="gi">+    with fs.open(&quot;/out_block&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;test&quot; * 4000)</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;cached&quot;,</span>
<span class="gi">+        target_protocol=&quot;ftp&quot;,</span>
<span class="gi">+        target_options={&quot;host&quot;: host, &quot;port&quot;: port, &quot;username&quot;: user, &quot;password&quot;: pw},</span>
<span class="gi">+    )</span>
<span class="gi">+    with fs.open(&quot;/out_block&quot;, block_size=1024) as f:</span>
<span class="gi">+        pass</span>
<span class="gi">+    with fs.open(&quot;/out_block&quot;, block_size=1024) as f:</span>
<span class="gi">+        assert f.read(1) == b&quot;t&quot;</span>
<span class="gi">+    # Regression test for &lt;https://github.com/fsspec/filesystem_spec/issues/845&gt;</span>
<span class="gi">+    assert fs._metadata.cached_files[-1][&quot;/out_block&quot;][&quot;blocks&quot;] == {0}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;impl&quot;, [&quot;filecache&quot;, &quot;simplecache&quot;])</span>
<span class="gi">+@pytest.mark.parametrize(&quot;compression&quot;, [&quot;gzip&quot;, &quot;bz2&quot;])</span>
<span class="gi">+def test_with_compression(impl, compression):</span>
<span class="gi">+    data = b&quot;123456789&quot;</span>
<span class="gi">+    tempdir = tempfile.mkdtemp()</span>
<span class="gi">+    cachedir = tempfile.mkdtemp()</span>
<span class="gi">+    fn = os.path.join(tempdir, &quot;data&quot;)</span>
<span class="gi">+    f = compr[compression](open(fn, mode=&quot;wb&quot;), mode=&quot;w&quot;)</span>
<span class="gi">+    f.write(data)</span>
<span class="gi">+    f.close()</span>
<span class="gi">+</span>
<span class="gi">+    with fsspec.open(</span>
<span class="gi">+        f&quot;{impl}::{fn}&quot;,</span>
<span class="gi">+        &quot;rb&quot;,</span>
<span class="gi">+        compression=compression,</span>
<span class="gi">+        **{impl: {&quot;same_names&quot;: True, &quot;cache_storage&quot;: cachedir}},</span>
<span class="gi">+    ) as f:</span>
<span class="gi">+        # stores original compressed file, uncompress on read</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+        assert &quot;data&quot; in os.listdir(cachedir)</span>
<span class="gi">+        assert open(os.path.join(cachedir, &quot;data&quot;), &quot;rb&quot;).read() != data</span>
<span class="gi">+</span>
<span class="gi">+    cachedir = tempfile.mkdtemp()</span>
<span class="gi">+</span>
<span class="gi">+    with fsspec.open(</span>
<span class="gi">+        f&quot;{impl}::{fn}&quot;,</span>
<span class="gi">+        &quot;rb&quot;,</span>
<span class="gi">+        **{</span>
<span class="gi">+            impl: {</span>
<span class="gi">+                &quot;same_names&quot;: True,</span>
<span class="gi">+                &quot;compression&quot;: compression,</span>
<span class="gi">+                &quot;cache_storage&quot;: cachedir,</span>
<span class="gi">+            }</span>
<span class="gi">+        },</span>
<span class="gi">+    ) as f:</span>
<span class="gi">+        # stores uncompressed data</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+        assert &quot;data&quot; in os.listdir(cachedir)</span>
<span class="gi">+        assert open(os.path.join(cachedir, &quot;data&quot;), &quot;rb&quot;).read() == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;protocol&quot;, [&quot;simplecache&quot;, &quot;filecache&quot;])</span>
<span class="gi">+def test_again(protocol):</span>
<span class="gi">+    fn = &quot;memory://afile&quot;</span>
<span class="gi">+    with fsspec.open(fn, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;hello&quot;)</span>
<span class="gi">+    d2 = tempfile.mkdtemp()</span>
<span class="gi">+    lurl = fsspec.open_local(f&quot;{protocol}::{fn}&quot;, **{protocol: {&quot;cache_storage&quot;: d2}})</span>
<span class="gi">+    assert os.path.exists(lurl)</span>
<span class="gi">+    assert d2 in lurl</span>
<span class="gi">+    assert open(lurl, &quot;rb&quot;).read() == b&quot;hello&quot;</span>
<span class="gi">+</span>
<span class="gi">+    # remove cache dir</span>
<span class="gi">+    shutil.rmtree(d2)</span>
<span class="gi">+    assert not os.path.exists(lurl)</span>
<span class="gi">+</span>
<span class="gi">+    # gets recreated</span>
<span class="gi">+    lurl = fsspec.open_local(f&quot;{protocol}::{fn}&quot;, **{protocol: {&quot;cache_storage&quot;: d2}})</span>
<span class="gi">+    assert open(lurl, &quot;rb&quot;).read() == b&quot;hello&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;protocol&quot;, [&quot;simplecache&quot;, &quot;filecache&quot;])</span>
<span class="gi">+def test_multi_cache(protocol):</span>
<span class="gi">+    with fsspec.open_files(&quot;memory://file*&quot;, &quot;wb&quot;, num=2) as files:</span>
<span class="gi">+        for f in files:</span>
<span class="gi">+            f.write(b&quot;hello&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    d2 = tempfile.mkdtemp()</span>
<span class="gi">+    lurl = fsspec.open_local(</span>
<span class="gi">+        f&quot;{protocol}::memory://file*&quot;,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        **{protocol: {&quot;cache_storage&quot;: d2, &quot;same_names&quot;: True}},</span>
<span class="gi">+    )</span>
<span class="gi">+    assert all(d2 in u for u in lurl)</span>
<span class="gi">+    assert all(os.path.basename(f) in [&quot;file0&quot;, &quot;file1&quot;] for f in lurl)</span>
<span class="gi">+    assert all(open(u, &quot;rb&quot;).read() == b&quot;hello&quot; for u in lurl)</span>
<span class="gi">+</span>
<span class="gi">+    d2 = tempfile.mkdtemp()</span>
<span class="gi">+    lurl = fsspec.open_files(</span>
<span class="gi">+        f&quot;{protocol}::memory://file*&quot;,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        **{protocol: {&quot;cache_storage&quot;: d2, &quot;same_names&quot;: True}},</span>
<span class="gi">+    )</span>
<span class="gi">+    with lurl as files:</span>
<span class="gi">+        for f in files:</span>
<span class="gi">+            assert os.path.basename(f.name) in [&quot;file0&quot;, &quot;file1&quot;]</span>
<span class="gi">+            assert f.read() == b&quot;hello&quot;</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;memory&quot;)</span>
<span class="gi">+    fs.store.clear()</span>
<span class="gi">+    with lurl as files:</span>
<span class="gi">+        for f in files:</span>
<span class="gi">+            assert os.path.basename(f.name) in [&quot;file0&quot;, &quot;file1&quot;]</span>
<span class="gi">+            assert f.read() == b&quot;hello&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;protocol&quot;, [&quot;simplecache&quot;, &quot;filecache&quot;, &quot;blockcache&quot;])</span>
<span class="gi">+def test_multi_cat(protocol, ftp_writable):</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    fs = FTPFileSystem(host, port, user, pw)</span>
<span class="gi">+    for fn in (&quot;/file0&quot;, &quot;/file1&quot;):</span>
<span class="gi">+        with fs.open(fn, &quot;wb&quot;) as f:</span>
<span class="gi">+            f.write(b&quot;hello&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    d2 = tempfile.mkdtemp()</span>
<span class="gi">+    fs = fsspec.filesystem(protocol, storage=d2, fs=fs)</span>
<span class="gi">+    assert fs.cat(&quot;file*&quot;) == {&quot;/file0&quot;: b&quot;hello&quot;, &quot;/file1&quot;: b&quot;hello&quot;}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;protocol&quot;, [&quot;simplecache&quot;, &quot;filecache&quot;])</span>
<span class="gi">+def test_multi_cache_chain(protocol):</span>
<span class="gi">+    import zipfile</span>
<span class="gi">+</span>
<span class="gi">+    d = tempfile.mkdtemp()</span>
<span class="gi">+    fn = os.path.join(d, &quot;test.zip&quot;)</span>
<span class="gi">+    zipfile.ZipFile(fn, mode=&quot;w&quot;).open(&quot;test&quot;, &quot;w&quot;).write(b&quot;hello&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with fsspec.open_files(f&quot;zip://test::{protocol}::file://{fn}&quot;) as files:</span>
<span class="gi">+        assert d not in files[0]._fileobj._file.name</span>
<span class="gi">+        assert files[0].read() == b&quot;hello&quot;</span>
<span class="gi">+</span>
<span class="gi">+    # special test contains &quot;file:&quot; string</span>
<span class="gi">+    fn = os.path.join(d, &quot;file.zip&quot;)</span>
<span class="gi">+    zipfile.ZipFile(fn, mode=&quot;w&quot;).open(&quot;file&quot;, &quot;w&quot;).write(b&quot;hello&quot;)</span>
<span class="gi">+    with fsspec.open_files(f&quot;zip://file::{protocol}::file://{fn}&quot;) as files:</span>
<span class="gi">+        assert d not in files[0]._fileobj._file.name</span>
<span class="gi">+        assert files[0].read() == b&quot;hello&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;protocol&quot;, [&quot;blockcache&quot;, &quot;simplecache&quot;, &quot;filecache&quot;])</span>
<span class="gi">+def test_strip(protocol):</span>
<span class="gi">+    fs = fsspec.filesystem(protocol, target_protocol=&quot;memory&quot;)</span>
<span class="gi">+    url1 = &quot;memory://afile&quot;</span>
<span class="gi">+    assert fs._strip_protocol(url1) == &quot;/afile&quot;</span>
<span class="gi">+    assert fs._strip_protocol(protocol + &quot;://afile&quot;) == &quot;/afile&quot;</span>
<span class="gi">+    assert fs._strip_protocol(protocol + &quot;::memory://afile&quot;) == &quot;/afile&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;protocol&quot;, [&quot;simplecache&quot;, &quot;filecache&quot;])</span>
<span class="gi">+def test_cached_write(protocol):</span>
<span class="gi">+    d = tempfile.mkdtemp()</span>
<span class="gi">+    ofs = fsspec.open_files(f&quot;{protocol}::file://{d}/*.out&quot;, mode=&quot;wb&quot;, num=2)</span>
<span class="gi">+    with ofs as files:</span>
<span class="gi">+        for f in files:</span>
<span class="gi">+            assert isinstance(f, LocalTempFile)</span>
<span class="gi">+            f.write(b&quot;data&quot;)</span>
<span class="gi">+            fn = f.name</span>
<span class="gi">+</span>
<span class="gi">+    assert sorted(os.listdir(d)) == [&quot;0.out&quot;, &quot;1.out&quot;]</span>
<span class="gi">+    assert not os.path.exists(fn)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_expiry():</span>
<span class="gi">+    import time</span>
<span class="gi">+</span>
<span class="gi">+    d = tempfile.mkdtemp()</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;memory&quot;)</span>
<span class="gi">+    fn = &quot;/afile&quot;</span>
<span class="gi">+    fn0 = &quot;memory://afile&quot;</span>
<span class="gi">+    data = b&quot;hello&quot;</span>
<span class="gi">+    with fs.open(fn0, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;filecache&quot;,</span>
<span class="gi">+        fs=fs,</span>
<span class="gi">+        cache_storage=d,</span>
<span class="gi">+        check_files=False,</span>
<span class="gi">+        expiry_time=0.1,</span>
<span class="gi">+        same_names=True,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    # get file</span>
<span class="gi">+    assert fs._check_file(fn0) is False</span>
<span class="gi">+    assert fs.open(fn0, mode=&quot;rb&quot;).read() == data</span>
<span class="gi">+    start_time = fs._metadata.cached_files[-1][fn][&quot;time&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    # cache time..</span>
<span class="gi">+    assert fs.last_cache - start_time &lt; 0.19</span>
<span class="gi">+</span>
<span class="gi">+    # cache should have refreshed</span>
<span class="gi">+    time.sleep(0.01)</span>
<span class="gi">+</span>
<span class="gi">+    # file should still be valid... re-read</span>
<span class="gi">+    assert fs.open(fn0, mode=&quot;rb&quot;).read() == data</span>
<span class="gi">+    detail, _ = fs._check_file(fn0)</span>
<span class="gi">+    assert detail[&quot;time&quot;] == start_time</span>
<span class="gi">+</span>
<span class="gi">+    time.sleep(0.11)</span>
<span class="gi">+    # file should still be invalid... re-read</span>
<span class="gi">+    assert fs._check_file(fn0) is False</span>
<span class="gi">+    assert fs.open(fn0, mode=&quot;rb&quot;).read() == data</span>
<span class="gi">+    detail, _ = fs._check_file(fn0)</span>
<span class="gi">+    assert detail[&quot;time&quot;] - start_time &gt; 0.09</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>def test_equality(tmpdir):
<span class="w"> </span>    &quot;&quot;&quot;Test sane behaviour for equality and hashing.

<span class="gu">@@ -25,9 +1137,193 @@ def test_equality(tmpdir):</span>

<span class="w"> </span>    Related: GitHub#577, GitHub#578
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from fsspec.implementations.local import LocalFileSystem</span>
<span class="gi">+</span>
<span class="gi">+    lfs = LocalFileSystem()</span>
<span class="gi">+    dir1 = f&quot;{tmpdir}/raspberry&quot;</span>
<span class="gi">+    dir2 = f&quot;{tmpdir}/banana&quot;</span>
<span class="gi">+    cfs1 = CachingFileSystem(fs=lfs, cache_storage=dir1)</span>
<span class="gi">+    cfs2 = CachingFileSystem(fs=lfs, cache_storage=dir2)</span>
<span class="gi">+    cfs3 = CachingFileSystem(fs=lfs, cache_storage=dir2)</span>
<span class="gi">+    assert cfs1 == cfs1</span>
<span class="gi">+    assert cfs1 != cfs2</span>
<span class="gi">+    assert cfs1 != cfs3</span>
<span class="gi">+    assert cfs2 == cfs3</span>
<span class="gi">+    assert cfs1 != lfs</span>
<span class="gi">+    assert cfs2 != lfs</span>
<span class="gi">+    assert cfs3 != lfs</span>
<span class="gi">+    assert hash(lfs) != hash(cfs1)</span>
<span class="gi">+    assert hash(lfs) != hash(cfs2)</span>
<span class="gi">+    assert hash(lfs) != hash(cfs3)</span>
<span class="gi">+    assert hash(cfs1) != hash(cfs2)</span>
<span class="gi">+    assert hash(cfs1) != hash(cfs2)</span>
<span class="gi">+    assert hash(cfs2) == hash(cfs3)</span>


<span class="w"> </span>def test_str():
<span class="w"> </span>    &quot;&quot;&quot;Test that the str representation refers to correct class.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from fsspec.implementations.local import LocalFileSystem</span>
<span class="gi">+</span>
<span class="gi">+    lfs = LocalFileSystem()</span>
<span class="gi">+    cfs = CachingFileSystem(fs=lfs)</span>
<span class="gi">+    assert &quot;CachingFileSystem&quot; in str(cfs)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_getitems_errors(tmpdir):</span>
<span class="gi">+    tmpdir = str(tmpdir)</span>
<span class="gi">+    os.makedirs(os.path.join(tmpdir, &quot;afolder&quot;))</span>
<span class="gi">+    open(os.path.join(tmpdir, &quot;afile&quot;), &quot;w&quot;).write(&quot;test&quot;)</span>
<span class="gi">+    open(os.path.join(tmpdir, &quot;afolder&quot;, &quot;anotherfile&quot;), &quot;w&quot;).write(&quot;test2&quot;)</span>
<span class="gi">+    m = fsspec.get_mapper(f&quot;file://{tmpdir}&quot;)</span>
<span class="gi">+    assert m.getitems([&quot;afile&quot;, &quot;bfile&quot;], on_error=&quot;omit&quot;) == {&quot;afile&quot;: b&quot;test&quot;}</span>
<span class="gi">+</span>
<span class="gi">+    # my code</span>
<span class="gi">+    m2 = fsspec.get_mapper(f&quot;simplecache::file://{tmpdir}&quot;)</span>
<span class="gi">+    assert m2.getitems([&quot;afile&quot;], on_error=&quot;omit&quot;) == {&quot;afile&quot;: b&quot;test&quot;}  # works</span>
<span class="gi">+    assert m2.getitems([&quot;afile&quot;, &quot;bfile&quot;], on_error=&quot;omit&quot;) == {</span>
<span class="gi">+        &quot;afile&quot;: b&quot;test&quot;</span>
<span class="gi">+    }  # throws KeyError</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(KeyError):</span>
<span class="gi">+        m.getitems([&quot;afile&quot;, &quot;bfile&quot;])</span>
<span class="gi">+    out = m.getitems([&quot;afile&quot;, &quot;bfile&quot;], on_error=&quot;return&quot;)</span>
<span class="gi">+    assert isinstance(out[&quot;bfile&quot;], KeyError)</span>
<span class="gi">+    m = fsspec.get_mapper(f&quot;file://{tmpdir}&quot;, missing_exceptions=())</span>
<span class="gi">+    assert m.getitems([&quot;afile&quot;, &quot;bfile&quot;], on_error=&quot;omit&quot;) == {&quot;afile&quot;: b&quot;test&quot;}</span>
<span class="gi">+    with pytest.raises(FileNotFoundError):</span>
<span class="gi">+        m.getitems([&quot;afile&quot;, &quot;bfile&quot;])</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;temp_cache&quot;, [False, True])</span>
<span class="gi">+def test_cache_dir_auto_deleted(temp_cache, tmpdir):</span>
<span class="gi">+    import gc</span>
<span class="gi">+</span>
<span class="gi">+    source = os.path.join(tmpdir, &quot;source&quot;)</span>
<span class="gi">+    afile = os.path.join(source, &quot;afile&quot;)</span>
<span class="gi">+    os.mkdir(source)</span>
<span class="gi">+    open(afile, &quot;w&quot;).write(&quot;test&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;filecache&quot;,</span>
<span class="gi">+        target_protocol=&quot;file&quot;,</span>
<span class="gi">+        cache_storage=&quot;TMP&quot; if temp_cache else os.path.join(tmpdir, &quot;cache&quot;),</span>
<span class="gi">+        skip_instance_cache=True,  # Important to avoid fs itself being cached</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    cache_dir = fs.storage[-1]</span>
<span class="gi">+</span>
<span class="gi">+    # Force cache to be created</span>
<span class="gi">+    with fs.open(afile, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read(5) == b&quot;test&quot;</span>
<span class="gi">+</span>
<span class="gi">+    # Confirm cache exists</span>
<span class="gi">+    local = fsspec.filesystem(&quot;file&quot;)</span>
<span class="gi">+    assert local.exists(cache_dir)</span>
<span class="gi">+</span>
<span class="gi">+    # Delete file system</span>
<span class="gi">+    del fs</span>
<span class="gi">+    gc.collect()</span>
<span class="gi">+</span>
<span class="gi">+    # Ensure cache has been deleted, if it is temporary</span>
<span class="gi">+    if temp_cache:</span>
<span class="gi">+        assert not local.exists(cache_dir)</span>
<span class="gi">+    else:</span>
<span class="gi">+        assert local.exists(cache_dir)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;protocol&quot;, [&quot;filecache&quot;, &quot;blockcache&quot;, &quot;simplecache&quot;])</span>
<span class="gi">+def test_cache_size(tmpdir, protocol):</span>
<span class="gi">+    if win and protocol == &quot;blockcache&quot;:</span>
<span class="gi">+        pytest.skip(&quot;Windows file locking affects blockcache size tests&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    source = os.path.join(tmpdir, &quot;source&quot;)</span>
<span class="gi">+    afile = os.path.join(source, &quot;afile&quot;)</span>
<span class="gi">+    os.mkdir(source)</span>
<span class="gi">+    open(afile, &quot;w&quot;).write(&quot;test&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(protocol, target_protocol=&quot;file&quot;)</span>
<span class="gi">+    empty_cache_size = fs.cache_size()</span>
<span class="gi">+</span>
<span class="gi">+    # Create cache</span>
<span class="gi">+    with fs.open(afile, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read(5) == b&quot;test&quot;</span>
<span class="gi">+    single_file_cache_size = fs.cache_size()</span>
<span class="gi">+    assert single_file_cache_size &gt; empty_cache_size</span>
<span class="gi">+</span>
<span class="gi">+    # Remove cached file but leave cache metadata file</span>
<span class="gi">+    fs.pop_from_cache(afile)</span>
<span class="gi">+    if win and protocol == &quot;filecache&quot;:</span>
<span class="gi">+        assert empty_cache_size &lt; fs.cache_size()</span>
<span class="gi">+    elif protocol != &quot;simplecache&quot;:</span>
<span class="gi">+        assert empty_cache_size &lt; fs.cache_size() &lt; single_file_cache_size</span>
<span class="gi">+    else:</span>
<span class="gi">+        # simplecache never stores metadata</span>
<span class="gi">+        assert fs.cache_size() == single_file_cache_size</span>
<span class="gi">+</span>
<span class="gi">+    # Completely remove cache</span>
<span class="gi">+    fs.clear_cache()</span>
<span class="gi">+    if protocol != &quot;simplecache&quot;:</span>
<span class="gi">+        assert fs.cache_size() == empty_cache_size</span>
<span class="gi">+    else:</span>
<span class="gi">+        # Whole cache directory has been deleted</span>
<span class="gi">+        assert fs.cache_size() == 0</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_spurious_directory_issue1410(tmpdir):</span>
<span class="gi">+    import zipfile</span>
<span class="gi">+</span>
<span class="gi">+    os.chdir(tmpdir)</span>
<span class="gi">+    zipfile.ZipFile(&quot;dir.zip&quot;, mode=&quot;w&quot;).open(&quot;file.txt&quot;, &quot;w&quot;).write(b&quot;hello&quot;)</span>
<span class="gi">+    fs = WholeFileCacheFileSystem(fs=ZipFileSystem(&quot;dir.zip&quot;))</span>
<span class="gi">+</span>
<span class="gi">+    assert len(os.listdir()) == 1</span>
<span class="gi">+    with fs.open(&quot;/file.txt&quot;, &quot;rb&quot;):</span>
<span class="gi">+        pass</span>
<span class="gi">+</span>
<span class="gi">+    # There was a bug reported in issue #1410 in which a directory</span>
<span class="gi">+    # would be created and the next assertion would fail.</span>
<span class="gi">+    assert len(os.listdir()) == 1</span>
<span class="gi">+    assert fs._parent(&quot;/any/path&quot;) == &quot;any&quot;  # correct for ZIP, which has no leading /</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_write_transaction(tmpdir, m, monkeypatch):</span>
<span class="gi">+    called = [0]</span>
<span class="gi">+    orig = m.put</span>
<span class="gi">+</span>
<span class="gi">+    def patched_put(*args, **kwargs):</span>
<span class="gi">+        called[0] += 1</span>
<span class="gi">+        orig(*args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    monkeypatch.setattr(m, &quot;put&quot;, patched_put)</span>
<span class="gi">+    tmpdir = str(tmpdir)</span>
<span class="gi">+    fs, _ = fsspec.core.url_to_fs(&quot;simplecache::memory://&quot;, cache_storage=tmpdir)</span>
<span class="gi">+    with fs.transaction:</span>
<span class="gi">+        fs.pipe(&quot;myfile&quot;, b&quot;1&quot;)</span>
<span class="gi">+        fs.pipe(&quot;otherfile&quot;, b&quot;2&quot;)</span>
<span class="gi">+        fs.pipe(&quot;deep/dir/otherfile&quot;, b&quot;3&quot;)</span>
<span class="gi">+        with fs.open(&quot;blarh&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+            f.write(b&quot;ff&quot;)</span>
<span class="gi">+        assert not m.find(&quot;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        assert fs.info(&quot;otherfile&quot;)[&quot;size&quot;] == 1</span>
<span class="gi">+        assert fs.info(&quot;deep&quot;)[&quot;type&quot;] == &quot;directory&quot;</span>
<span class="gi">+        assert fs.isdir(&quot;deep&quot;)</span>
<span class="gi">+        assert fs.ls(&quot;deep&quot;, detail=False) == [&quot;/deep/dir&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    assert m.cat(&quot;myfile&quot;) == b&quot;1&quot;</span>
<span class="gi">+    assert m.cat(&quot;otherfile&quot;) == b&quot;2&quot;</span>
<span class="gi">+    assert called[0] == 1  # copy was done in one go</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_filecache_write(tmpdir, m):</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;filecache&quot;, target_protocol=&quot;memory&quot;, cache_storage=str(tmpdir)</span>
<span class="gi">+    )</span>
<span class="gi">+    fn = &quot;sample_file_in_mem.txt&quot;</span>
<span class="gi">+    data = &quot;hello world from memory&quot;</span>
<span class="gi">+    with fs.open(fn, &quot;w&quot;) as f:</span>
<span class="gi">+        assert not m.exists(fn)</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+</span>
<span class="gi">+    assert m.cat(fn) == data.encode()</span>
<span class="gi">+    assert fs.cat(fn) == data.encode()</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_common.py b/fsspec/implementations/tests/test_common.py</span>
<span class="gh">index 3f44554..f09f13c 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_common.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_common.py</span>
<span class="gu">@@ -1,5 +1,35 @@</span>
<span class="w"> </span>import datetime
<span class="w"> </span>import time
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>from fsspec import AbstractFileSystem
<span class="w"> </span>from fsspec.implementations.tests.conftest import READ_ONLY_FILESYSTEMS
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;fs&quot;, [&quot;local&quot;], indirect=[&quot;fs&quot;])</span>
<span class="gi">+def test_created(fs: AbstractFileSystem, temp_file):</span>
<span class="gi">+    try:</span>
<span class="gi">+        fs.touch(temp_file)</span>
<span class="gi">+        created = fs.created(path=temp_file)</span>
<span class="gi">+        assert isinstance(created, datetime.datetime)</span>
<span class="gi">+    finally:</span>
<span class="gi">+        if not isinstance(fs, tuple(READ_ONLY_FILESYSTEMS)):</span>
<span class="gi">+            fs.rm(temp_file)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;fs&quot;, [&quot;local&quot;, &quot;memory&quot;, &quot;arrow&quot;], indirect=[&quot;fs&quot;])</span>
<span class="gi">+def test_modified(fs: AbstractFileSystem, temp_file):</span>
<span class="gi">+    try:</span>
<span class="gi">+        fs.touch(temp_file)</span>
<span class="gi">+        # created = fs.created(path=temp_file)</span>
<span class="gi">+        created = datetime.datetime.now(</span>
<span class="gi">+            tz=datetime.timezone.utc</span>
<span class="gi">+        )  # pyarrow only have modified</span>
<span class="gi">+        time.sleep(0.05)</span>
<span class="gi">+        fs.touch(temp_file)</span>
<span class="gi">+        modified = fs.modified(path=temp_file)</span>
<span class="gi">+        assert isinstance(modified, datetime.datetime)</span>
<span class="gi">+        assert modified &gt; created</span>
<span class="gi">+    finally:</span>
<span class="gi">+        fs.rm(temp_file)</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_dask.py b/fsspec/implementations/tests/test_dask.py</span>
<span class="gh">index cb460c2..13756d9 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_dask.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_dask.py</span>
<span class="gu">@@ -1,3 +1,29 @@</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="gd">-pytest.importorskip(&#39;distributed&#39;)</span>
<span class="gi">+</span>
<span class="gi">+pytest.importorskip(&quot;distributed&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture()</span>
<span class="gi">+def cli(tmpdir):</span>
<span class="gi">+    import dask.distributed</span>
<span class="gi">+</span>
<span class="gi">+    client = dask.distributed.Client(n_workers=1)</span>
<span class="gi">+</span>
<span class="gi">+    def setup():</span>
<span class="gi">+        m = fsspec.filesystem(&quot;memory&quot;)</span>
<span class="gi">+        with m.open(&quot;afile&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+            f.write(b&quot;data&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    client.run(setup)</span>
<span class="gi">+    try:</span>
<span class="gi">+        yield client</span>
<span class="gi">+    finally:</span>
<span class="gi">+        client.shutdown()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_basic(cli):</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;dask&quot;, target_protocol=&quot;memory&quot;)</span>
<span class="gi">+    assert fs.ls(&quot;&quot;, detail=False) == [&quot;/afile&quot;]</span>
<span class="gi">+    assert fs.cat(&quot;/afile&quot;) == b&quot;data&quot;</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_data.py b/fsspec/implementations/tests/test_data.py</span>
<span class="gh">index 29bbf8e..ea99dc9 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_data.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_data.py</span>
<span class="gu">@@ -1 +1,20 @@</span>
<span class="w"> </span>import fsspec
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_1():</span>
<span class="gi">+    with fsspec.open(&quot;data:text/plain;base64,SGVsbG8sIFdvcmxkIQ==&quot;) as f:</span>
<span class="gi">+        assert f.read() == b&quot;Hello, World!&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with fsspec.open(&quot;data:,Hello%2C%20World%21&quot;) as f:</span>
<span class="gi">+        assert f.read() == b&quot;Hello, World!&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_info():</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;data&quot;)</span>
<span class="gi">+    info = fs.info(&quot;data:text/html,%3Ch1%3EHello%2C%20World%21%3C%2Fh1%3E&quot;)</span>
<span class="gi">+    assert info == {</span>
<span class="gi">+        &quot;name&quot;: &quot;%3Ch1%3EHello%2C%20World%21%3C%2Fh1%3E&quot;,</span>
<span class="gi">+        &quot;size&quot;: 22,</span>
<span class="gi">+        &quot;type&quot;: &quot;file&quot;,</span>
<span class="gi">+        &quot;mimetype&quot;: &quot;text/html&quot;,</span>
<span class="gi">+    }</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_dbfs.py b/fsspec/implementations/tests/test_dbfs.py</span>
<span class="gh">index 18a8bb2..66475b2 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_dbfs.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_dbfs.py</span>
<span class="gu">@@ -21,20 +21,25 @@ you need to re-record the answers. This can be done as follows:</span>
<span class="w"> </span>5. Now execute the tests as normal. The results of the API calls will be recorded.
<span class="w"> </span>6. Unset the environment variables and replay the tests.
<span class="w"> </span>&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>import os
<span class="w"> </span>import sys
<span class="w"> </span>from urllib.parse import urlparse
<span class="gi">+</span>
<span class="w"> </span>import numpy
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="gi">+</span>
<span class="w"> </span>if sys.version_info &gt;= (3, 10):
<span class="gd">-    pytest.skip(&#39;These tests need to be re-recorded.&#39;, allow_module_level=True)</span>
<span class="gd">-DUMMY_INSTANCE = &#39;my_instance.com&#39;</span>
<span class="gd">-INSTANCE = os.getenv(&#39;DBFS_INSTANCE&#39;, DUMMY_INSTANCE)</span>
<span class="gd">-TOKEN = os.getenv(&#39;DBFS_TOKEN&#39;, &#39;&#39;)</span>
<span class="gi">+    pytest.skip(&quot;These tests need to be re-recorded.&quot;, allow_module_level=True)</span>

<span class="gi">+DUMMY_INSTANCE = &quot;my_instance.com&quot;</span>
<span class="gi">+INSTANCE = os.getenv(&quot;DBFS_INSTANCE&quot;, DUMMY_INSTANCE)</span>
<span class="gi">+TOKEN = os.getenv(&quot;DBFS_TOKEN&quot;, &quot;&quot;)</span>

<span class="gd">-@pytest.fixture(scope=&#39;module&#39;)</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture(scope=&quot;module&quot;)</span>
<span class="w"> </span>def vcr_config():
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    To not record information in the instance and token details
<span class="gu">@@ -45,4 +50,219 @@ def vcr_config():</span>
<span class="w"> </span>    If the DBFS_TOKEN env variable is set, we record with VCR.
<span class="w"> </span>    If not, we only replay (to not accidentally record with a wrong URL).
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    def before_record_response(response):</span>
<span class="gi">+        try:</span>
<span class="gi">+            del response[&quot;headers&quot;][&quot;x-databricks-org-id&quot;]</span>
<span class="gi">+            del response[&quot;headers&quot;][&quot;date&quot;]</span>
<span class="gi">+        except KeyError:</span>
<span class="gi">+            pass</span>
<span class="gi">+        return response</span>
<span class="gi">+</span>
<span class="gi">+    def before_record_request(request):</span>
<span class="gi">+        # Replace the instance URL</span>
<span class="gi">+        uri = urlparse(request.uri)</span>
<span class="gi">+        uri = uri._replace(netloc=DUMMY_INSTANCE)</span>
<span class="gi">+        request.uri = uri.geturl()</span>
<span class="gi">+</span>
<span class="gi">+        return request</span>
<span class="gi">+</span>
<span class="gi">+    if TOKEN:</span>
<span class="gi">+        return {</span>
<span class="gi">+            &quot;record_mode&quot;: &quot;once&quot;,</span>
<span class="gi">+            &quot;filter_headers&quot;: [(&quot;authorization&quot;, &quot;DUMMY&quot;)],</span>
<span class="gi">+            &quot;before_record_response&quot;: before_record_response,</span>
<span class="gi">+            &quot;before_record_request&quot;: before_record_request,</span>
<span class="gi">+        }</span>
<span class="gi">+    else:</span>
<span class="gi">+        return {</span>
<span class="gi">+            &quot;record_mode&quot;: &quot;none&quot;,</span>
<span class="gi">+        }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def dbfsFS():</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;dbfs&quot;, instance=INSTANCE, token=TOKEN)</span>
<span class="gi">+</span>
<span class="gi">+    return fs</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def make_mock_diabetes_ds():</span>
<span class="gi">+    pa = pytest.importorskip(&quot;pyarrow&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    names = [</span>
<span class="gi">+        &quot;Pregnancies&quot;,</span>
<span class="gi">+        &quot;Glucose&quot;,</span>
<span class="gi">+        &quot;BloodPressure&quot;,</span>
<span class="gi">+        &quot;SkinThickness&quot;,</span>
<span class="gi">+        &quot;Insulin&quot;,</span>
<span class="gi">+        &quot;BMI&quot;,</span>
<span class="gi">+        &quot;DiabetesPedigreeFunction&quot;,</span>
<span class="gi">+        &quot;Age&quot;,</span>
<span class="gi">+        &quot;Outcome&quot;,</span>
<span class="gi">+    ]</span>
<span class="gi">+    pregnancies = pa.array(numpy.random.randint(low=0, high=17, size=25))</span>
<span class="gi">+    glucose = pa.array(numpy.random.randint(low=0, high=199, size=25))</span>
<span class="gi">+    blood_pressure = pa.array(numpy.random.randint(low=0, high=122, size=25))</span>
<span class="gi">+    skin_thickness = pa.array(numpy.random.randint(low=0, high=99, size=25))</span>
<span class="gi">+    insulin = pa.array(numpy.random.randint(low=0, high=846, size=25))</span>
<span class="gi">+    bmi = pa.array(numpy.random.uniform(0.0, 67.1, size=25))</span>
<span class="gi">+    diabetes_pedigree_function = pa.array(numpy.random.uniform(0.08, 2.42, size=25))</span>
<span class="gi">+    age = pa.array(numpy.random.randint(low=21, high=81, size=25))</span>
<span class="gi">+    outcome = pa.array(numpy.random.randint(low=0, high=1, size=25))</span>
<span class="gi">+</span>
<span class="gi">+    return pa.Table.from_arrays(</span>
<span class="gi">+        arrays=[</span>
<span class="gi">+            pregnancies,</span>
<span class="gi">+            glucose,</span>
<span class="gi">+            blood_pressure,</span>
<span class="gi">+            skin_thickness,</span>
<span class="gi">+            insulin,</span>
<span class="gi">+            bmi,</span>
<span class="gi">+            diabetes_pedigree_function,</span>
<span class="gi">+            age,</span>
<span class="gi">+            outcome,</span>
<span class="gi">+        ],</span>
<span class="gi">+        names=names,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.vcr()</span>
<span class="gi">+def test_dbfs_file_listing(dbfsFS):</span>
<span class="gi">+    assert &quot;/FileStore&quot; in dbfsFS.ls(&quot;/&quot;, detail=False)</span>
<span class="gi">+    assert {&quot;name&quot;: &quot;/FileStore&quot;, &quot;size&quot;: 0, &quot;type&quot;: &quot;directory&quot;} in dbfsFS.ls(</span>
<span class="gi">+        &quot;/&quot;, detail=True</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.vcr()</span>
<span class="gi">+def test_dbfs_mkdir(dbfsFS):</span>
<span class="gi">+    dbfsFS.rm(&quot;/FileStore/my&quot;, recursive=True)</span>
<span class="gi">+    assert &quot;/FileStore/my&quot; not in dbfsFS.ls(&quot;/FileStore/&quot;, detail=False)</span>
<span class="gi">+</span>
<span class="gi">+    dbfsFS.mkdir(&quot;/FileStore/my/dir&quot;, create_parents=True)</span>
<span class="gi">+</span>
<span class="gi">+    assert &quot;/FileStore/my&quot; in dbfsFS.ls(&quot;/FileStore/&quot;, detail=False)</span>
<span class="gi">+    assert &quot;/FileStore/my/dir&quot; in dbfsFS.ls(&quot;/FileStore/my/&quot;, detail=False)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(FileExistsError):</span>
<span class="gi">+        dbfsFS.mkdir(&quot;/FileStore/my/dir&quot;, create_parents=True, exist_ok=False)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(OSError):</span>
<span class="gi">+        dbfsFS.rm(&quot;/FileStore/my&quot;, recursive=False)</span>
<span class="gi">+</span>
<span class="gi">+    assert &quot;/FileStore/my&quot; in dbfsFS.ls(&quot;/FileStore/&quot;, detail=False)</span>
<span class="gi">+</span>
<span class="gi">+    dbfsFS.rm(&quot;/FileStore/my&quot;, recursive=True)</span>
<span class="gi">+    assert &quot;/FileStore/my&quot; not in dbfsFS.ls(&quot;/FileStore/&quot;, detail=False)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.vcr()</span>
<span class="gi">+def test_dbfs_write_and_read(dbfsFS):</span>
<span class="gi">+    dbfsFS.rm(&quot;/FileStore/file.csv&quot;)</span>
<span class="gi">+    assert &quot;/FileStore/file.csv&quot; not in dbfsFS.ls(&quot;/FileStore/&quot;, detail=False)</span>
<span class="gi">+</span>
<span class="gi">+    content = b&quot;This is a test\n&quot; * 100000 + b&quot;For this is the end\n&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with dbfsFS.open(&quot;/FileStore/file.csv&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(content)</span>
<span class="gi">+</span>
<span class="gi">+    assert &quot;/FileStore/file.csv&quot; in dbfsFS.ls(&quot;/FileStore&quot;, detail=False)</span>
<span class="gi">+</span>
<span class="gi">+    with dbfsFS.open(&quot;/FileStore/file.csv&quot;, &quot;rb&quot;) as f:</span>
<span class="gi">+        data = f.read()</span>
<span class="gi">+        assert data == content</span>
<span class="gi">+    dbfsFS.rm(&quot;/FileStore/file.csv&quot;)</span>
<span class="gi">+    assert &quot;/FileStore/file.csv&quot; not in dbfsFS.ls(&quot;/FileStore/&quot;, detail=False)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.vcr()</span>
<span class="gi">+def test_dbfs_read_range(dbfsFS):</span>
<span class="gi">+    dbfsFS.rm(&quot;/FileStore/file.txt&quot;)</span>
<span class="gi">+    assert &quot;/FileStore/file.txt&quot; not in dbfsFS.ls(&quot;/FileStore/&quot;, detail=False)</span>
<span class="gi">+    content = b&quot;This is a test\n&quot;</span>
<span class="gi">+    with dbfsFS.open(&quot;/FileStore/file.txt&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(content)</span>
<span class="gi">+    assert &quot;/FileStore/file.txt&quot; in dbfsFS.ls(&quot;/FileStore&quot;, detail=False)</span>
<span class="gi">+    assert dbfsFS.cat_file(&quot;/FileStore/file.txt&quot;, start=8, end=14) == content[8:14]</span>
<span class="gi">+    dbfsFS.rm(&quot;/FileStore/file.txt&quot;)</span>
<span class="gi">+    assert &quot;/FileStore/file.txt&quot; not in dbfsFS.ls(&quot;/FileStore/&quot;, detail=False)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.vcr()</span>
<span class="gi">+def test_dbfs_read_range_chunked(dbfsFS):</span>
<span class="gi">+    dbfsFS.rm(&quot;/FileStore/large_file.txt&quot;)</span>
<span class="gi">+    assert &quot;/FileStore/large_file.txt&quot; not in dbfsFS.ls(&quot;/FileStore/&quot;, detail=False)</span>
<span class="gi">+    content = b&quot;This is a test\n&quot; * (1 * 2**18) + b&quot;For this is the end\n&quot;</span>
<span class="gi">+    with dbfsFS.open(&quot;/FileStore/large_file.txt&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(content)</span>
<span class="gi">+    assert &quot;/FileStore/large_file.txt&quot; in dbfsFS.ls(&quot;/FileStore&quot;, detail=False)</span>
<span class="gi">+    assert dbfsFS.cat_file(&quot;/FileStore/large_file.txt&quot;, start=8) == content[8:]</span>
<span class="gi">+    dbfsFS.rm(&quot;/FileStore/large_file.txt&quot;)</span>
<span class="gi">+    assert &quot;/FileStore/large_file.txt&quot; not in dbfsFS.ls(&quot;/FileStore/&quot;, detail=False)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.vcr()</span>
<span class="gi">+def test_dbfs_write_pyarrow_non_partitioned(dbfsFS, make_mock_diabetes_ds):</span>
<span class="gi">+    pytest.importorskip(&quot;pyarrow.dataset&quot;)</span>
<span class="gi">+    pq = pytest.importorskip(&quot;pyarrow.parquet&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    dbfsFS.rm(&quot;/FileStore/pyarrow&quot;, recursive=True)</span>
<span class="gi">+    assert &quot;/FileStore/pyarrow&quot; not in dbfsFS.ls(&quot;/FileStore/&quot;, detail=False)</span>
<span class="gi">+</span>
<span class="gi">+    pq.write_to_dataset(</span>
<span class="gi">+        make_mock_diabetes_ds,</span>
<span class="gi">+        filesystem=dbfsFS,</span>
<span class="gi">+        compression=&quot;none&quot;,</span>
<span class="gi">+        existing_data_behavior=&quot;error&quot;,</span>
<span class="gi">+        root_path=&quot;/FileStore/pyarrow/diabetes&quot;,</span>
<span class="gi">+        use_threads=False,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    assert len(dbfsFS.ls(&quot;/FileStore/pyarrow/diabetes&quot;, detail=False)) == 1</span>
<span class="gi">+    assert (</span>
<span class="gi">+        &quot;/FileStore/pyarrow/diabetes&quot;</span>
<span class="gi">+        in dbfsFS.ls(&quot;/FileStore/pyarrow/diabetes&quot;, detail=False)[0]</span>
<span class="gi">+        and &quot;.parquet&quot; in dbfsFS.ls(&quot;/FileStore/pyarrow/diabetes&quot;, detail=False)[0]</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    dbfsFS.rm(&quot;/FileStore/pyarrow&quot;, recursive=True)</span>
<span class="gi">+    assert &quot;/FileStore/pyarrow&quot; not in dbfsFS.ls(&quot;/FileStore/&quot;, detail=False)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.vcr()</span>
<span class="gi">+def test_dbfs_read_pyarrow_non_partitioned(dbfsFS, make_mock_diabetes_ds):</span>
<span class="gi">+    ds = pytest.importorskip(&quot;pyarrow.dataset&quot;)</span>
<span class="gi">+    pq = pytest.importorskip(&quot;pyarrow.parquet&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    dbfsFS.rm(&quot;/FileStore/pyarrow&quot;, recursive=True)</span>
<span class="gi">+    assert &quot;/FileStore/pyarrow&quot; not in dbfsFS.ls(&quot;/FileStore/&quot;, detail=False)</span>
<span class="gi">+</span>
<span class="gi">+    pq.write_to_dataset(</span>
<span class="gi">+        make_mock_diabetes_ds,</span>
<span class="gi">+        filesystem=dbfsFS,</span>
<span class="gi">+        compression=&quot;none&quot;,</span>
<span class="gi">+        existing_data_behavior=&quot;error&quot;,</span>
<span class="gi">+        root_path=&quot;/FileStore/pyarrow/diabetes&quot;,</span>
<span class="gi">+        use_threads=False,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    assert len(dbfsFS.ls(&quot;/FileStore/pyarrow/diabetes&quot;, detail=False)) == 1</span>
<span class="gi">+    assert (</span>
<span class="gi">+        &quot;/FileStore/pyarrow/diabetes&quot;</span>
<span class="gi">+        in dbfsFS.ls(&quot;/FileStore/pyarrow/diabetes&quot;, detail=False)[0]</span>
<span class="gi">+        and &quot;.parquet&quot; in dbfsFS.ls(&quot;/FileStore/pyarrow/diabetes&quot;, detail=False)[0]</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    arr_res = ds.dataset(</span>
<span class="gi">+        source=&quot;/FileStore/pyarrow/diabetes&quot;,</span>
<span class="gi">+        filesystem=dbfsFS,</span>
<span class="gi">+    ).to_table()</span>
<span class="gi">+</span>
<span class="gi">+    assert arr_res.num_rows == make_mock_diabetes_ds.num_rows</span>
<span class="gi">+    assert arr_res.num_columns == make_mock_diabetes_ds.num_columns</span>
<span class="gi">+    assert set(arr_res.schema).difference(set(make_mock_diabetes_ds.schema)) == set()</span>
<span class="gi">+</span>
<span class="gi">+    dbfsFS.rm(&quot;/FileStore/pyarrow&quot;, recursive=True)</span>
<span class="gi">+    assert &quot;/FileStore/pyarrow&quot; not in dbfsFS.ls(&quot;/FileStore/&quot;, detail=False)</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_dirfs.py b/fsspec/implementations/tests/test_dirfs.py</span>
<span class="gh">index 45da94d..c04ba66 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_dirfs.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_dirfs.py</span>
<span class="gu">@@ -1,7 +1,591 @@</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>from fsspec.asyn import AsyncFileSystem
<span class="w"> </span>from fsspec.implementations.dirfs import DirFileSystem
<span class="w"> </span>from fsspec.spec import AbstractFileSystem
<span class="gd">-PATH = &#39;path/to/dir&#39;</span>
<span class="gd">-ARGS = [&#39;foo&#39;, &#39;bar&#39;]</span>
<span class="gd">-KWARGS = {&#39;baz&#39;: &#39;baz&#39;, &#39;qux&#39;: &#39;qux&#39;}</span>
<span class="gi">+</span>
<span class="gi">+PATH = &quot;path/to/dir&quot;</span>
<span class="gi">+ARGS = [&quot;foo&quot;, &quot;bar&quot;]</span>
<span class="gi">+KWARGS = {&quot;baz&quot;: &quot;baz&quot;, &quot;qux&quot;: &quot;qux&quot;}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def make_fs(mocker):</span>
<span class="gi">+    def _make_fs(async_impl=False, asynchronous=False):</span>
<span class="gi">+        attrs = {</span>
<span class="gi">+            &quot;sep&quot;: &quot;/&quot;,</span>
<span class="gi">+            &quot;async_impl&quot;: async_impl,</span>
<span class="gi">+            &quot;_strip_protocol&quot;: lambda path: path,</span>
<span class="gi">+        }</span>
<span class="gi">+</span>
<span class="gi">+        if async_impl:</span>
<span class="gi">+            attrs[&quot;asynchronous&quot;] = asynchronous</span>
<span class="gi">+            cls = AsyncFileSystem</span>
<span class="gi">+        else:</span>
<span class="gi">+            cls = AbstractFileSystem</span>
<span class="gi">+</span>
<span class="gi">+        fs = mocker.MagicMock(spec=cls, **attrs)</span>
<span class="gi">+</span>
<span class="gi">+        return fs</span>
<span class="gi">+</span>
<span class="gi">+    return _make_fs</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture(</span>
<span class="gi">+    params=[</span>
<span class="gi">+        pytest.param(False, id=&quot;sync&quot;),</span>
<span class="gi">+        pytest.param(True, id=&quot;async&quot;),</span>
<span class="gi">+    ]</span>
<span class="gi">+)</span>
<span class="gi">+def fs(make_fs, request):</span>
<span class="gi">+    return make_fs(async_impl=request.param)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def asyncfs(make_fs):</span>
<span class="gi">+    return make_fs(async_impl=True, asynchronous=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def make_dirfs():</span>
<span class="gi">+    def _make_dirfs(fs, asynchronous=False):</span>
<span class="gi">+        return DirFileSystem(PATH, fs, asynchronous=asynchronous)</span>
<span class="gi">+</span>
<span class="gi">+    return _make_dirfs</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def dirfs(make_dirfs, fs):</span>
<span class="gi">+    return make_dirfs(fs)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def adirfs(make_dirfs, asyncfs):</span>
<span class="gi">+    return make_dirfs(asyncfs, asynchronous=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_dirfs(fs, asyncfs):</span>
<span class="gi">+    DirFileSystem(&quot;path&quot;, fs)</span>
<span class="gi">+    DirFileSystem(&quot;path&quot;, asyncfs, asynchronous=True)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        DirFileSystem(&quot;path&quot;, asyncfs)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        DirFileSystem(&quot;path&quot;, fs, asynchronous=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;root, rel, full&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        (&quot;&quot;, &quot;&quot;, &quot;&quot;),</span>
<span class="gi">+        (&quot;&quot;, &quot;foo&quot;, &quot;foo&quot;),</span>
<span class="gi">+        (&quot;root&quot;, &quot;&quot;, &quot;root&quot;),</span>
<span class="gi">+        (&quot;root&quot;, &quot;foo&quot;, &quot;root/foo&quot;),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_path(fs, root, rel, full):</span>
<span class="gi">+    dirfs = DirFileSystem(root, fs)</span>
<span class="gi">+    assert dirfs._join(rel) == full</span>
<span class="gi">+    assert dirfs._relpath(full) == rel</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_sep(mocker, dirfs):</span>
<span class="gi">+    sep = mocker.Mock()</span>
<span class="gi">+    dirfs.fs.sep = sep</span>
<span class="gi">+    assert dirfs.sep == sep</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_set_session(mocker, adirfs):</span>
<span class="gi">+    adirfs.fs.set_session = mocker.AsyncMock()</span>
<span class="gi">+    assert (</span>
<span class="gi">+        await adirfs.set_session(*ARGS, **KWARGS) == adirfs.fs.set_session.return_value</span>
<span class="gi">+    )</span>
<span class="gi">+    adirfs.fs.set_session.assert_called_once_with(*ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_rm_file(adirfs):</span>
<span class="gi">+    await adirfs._rm_file(&quot;file&quot;, **KWARGS)</span>
<span class="gi">+    adirfs.fs._rm_file.assert_called_once_with(f&quot;{PATH}/file&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_rm_file(dirfs):</span>
<span class="gi">+    dirfs.rm_file(&quot;file&quot;, **KWARGS)</span>
<span class="gi">+    dirfs.fs.rm_file.assert_called_once_with(&quot;path/to/dir/file&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_rm(adirfs):</span>
<span class="gi">+    await adirfs._rm(&quot;file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+    adirfs.fs._rm.assert_called_once_with(&quot;path/to/dir/file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_rm(dirfs):</span>
<span class="gi">+    dirfs.rm(&quot;file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+    dirfs.fs.rm.assert_called_once_with(&quot;path/to/dir/file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_cp_file(adirfs):</span>
<span class="gi">+    await adirfs._cp_file(&quot;one&quot;, &quot;two&quot;, **KWARGS)</span>
<span class="gi">+    adirfs.fs._cp_file.assert_called_once_with(f&quot;{PATH}/one&quot;, f&quot;{PATH}/two&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_cp_file(dirfs):</span>
<span class="gi">+    dirfs.cp_file(&quot;one&quot;, &quot;two&quot;, **KWARGS)</span>
<span class="gi">+    dirfs.fs.cp_file.assert_called_once_with(f&quot;{PATH}/one&quot;, f&quot;{PATH}/two&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_copy(adirfs):</span>
<span class="gi">+    await adirfs._copy(&quot;one&quot;, &quot;two&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+    adirfs.fs._copy.assert_called_once_with(</span>
<span class="gi">+        f&quot;{PATH}/one&quot;, f&quot;{PATH}/two&quot;, *ARGS, **KWARGS</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_copy(dirfs):</span>
<span class="gi">+    dirfs.copy(&quot;one&quot;, &quot;two&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+    dirfs.fs.copy.assert_called_once_with(f&quot;{PATH}/one&quot;, f&quot;{PATH}/two&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_pipe(adirfs):</span>
<span class="gi">+    await adirfs._pipe(&quot;file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+    adirfs.fs._pipe.assert_called_once_with(f&quot;{PATH}/file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_pipe(dirfs):</span>
<span class="gi">+    dirfs.pipe(&quot;file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+    dirfs.fs.pipe.assert_called_once_with(f&quot;{PATH}/file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_pipe_dict(dirfs):</span>
<span class="gi">+    dirfs.pipe({&quot;file&quot;: b&quot;foo&quot;}, *ARGS, **KWARGS)</span>
<span class="gi">+    dirfs.fs.pipe.assert_called_once_with({f&quot;{PATH}/file&quot;: b&quot;foo&quot;}, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_pipe_file(adirfs):</span>
<span class="gi">+    await adirfs._pipe_file(&quot;file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+    adirfs.fs._pipe_file.assert_called_once_with(f&quot;{PATH}/file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_pipe_file(dirfs):</span>
<span class="gi">+    dirfs.pipe_file(&quot;file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+    dirfs.fs.pipe_file.assert_called_once_with(f&quot;{PATH}/file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_cat_file(adirfs):</span>
<span class="gi">+    assert (</span>
<span class="gi">+        await adirfs._cat_file(&quot;file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+        == adirfs.fs._cat_file.return_value</span>
<span class="gi">+    )</span>
<span class="gi">+    adirfs.fs._cat_file.assert_called_once_with(f&quot;{PATH}/file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_cat_file(dirfs):</span>
<span class="gi">+    assert dirfs.cat_file(&quot;file&quot;, *ARGS, **KWARGS) == dirfs.fs.cat_file.return_value</span>
<span class="gi">+    dirfs.fs.cat_file.assert_called_once_with(f&quot;{PATH}/file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_cat(adirfs):</span>
<span class="gi">+    assert await adirfs._cat(&quot;file&quot;, *ARGS, **KWARGS) == adirfs.fs._cat.return_value</span>
<span class="gi">+    adirfs.fs._cat.assert_called_once_with(f&quot;{PATH}/file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_cat(dirfs):</span>
<span class="gi">+    assert dirfs.cat(&quot;file&quot;, *ARGS, **KWARGS) == dirfs.fs.cat.return_value</span>
<span class="gi">+    dirfs.fs.cat.assert_called_once_with(f&quot;{PATH}/file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_cat_list(adirfs):</span>
<span class="gi">+    adirfs.fs._cat.return_value = {f&quot;{PATH}/one&quot;: &quot;foo&quot;, f&quot;{PATH}/two&quot;: &quot;bar&quot;}</span>
<span class="gi">+    assert await adirfs._cat([&quot;one&quot;, &quot;two&quot;], *ARGS, **KWARGS) == {</span>
<span class="gi">+        &quot;one&quot;: &quot;foo&quot;,</span>
<span class="gi">+        &quot;two&quot;: &quot;bar&quot;,</span>
<span class="gi">+    }</span>
<span class="gi">+    adirfs.fs._cat.assert_called_once_with(</span>
<span class="gi">+        [f&quot;{PATH}/one&quot;, f&quot;{PATH}/two&quot;], *ARGS, **KWARGS</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_cat_list(dirfs):</span>
<span class="gi">+    dirfs.fs.cat.return_value = {f&quot;{PATH}/one&quot;: &quot;foo&quot;, f&quot;{PATH}/two&quot;: &quot;bar&quot;}</span>
<span class="gi">+    assert dirfs.cat([&quot;one&quot;, &quot;two&quot;], *ARGS, **KWARGS) == {&quot;one&quot;: &quot;foo&quot;, &quot;two&quot;: &quot;bar&quot;}</span>
<span class="gi">+    dirfs.fs.cat.assert_called_once_with(</span>
<span class="gi">+        [f&quot;{PATH}/one&quot;, f&quot;{PATH}/two&quot;], *ARGS, **KWARGS</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_put_file(adirfs):</span>
<span class="gi">+    await adirfs._put_file(&quot;local&quot;, &quot;file&quot;, **KWARGS)</span>
<span class="gi">+    adirfs.fs._put_file.assert_called_once_with(&quot;local&quot;, f&quot;{PATH}/file&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_put_file(dirfs):</span>
<span class="gi">+    dirfs.put_file(&quot;local&quot;, &quot;file&quot;, **KWARGS)</span>
<span class="gi">+    dirfs.fs.put_file.assert_called_once_with(&quot;local&quot;, f&quot;{PATH}/file&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_put(adirfs):</span>
<span class="gi">+    await adirfs._put(&quot;local&quot;, &quot;file&quot;, **KWARGS)</span>
<span class="gi">+    adirfs.fs._put.assert_called_once_with(&quot;local&quot;, f&quot;{PATH}/file&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_put(dirfs):</span>
<span class="gi">+    dirfs.put(&quot;local&quot;, &quot;file&quot;, **KWARGS)</span>
<span class="gi">+    dirfs.fs.put.assert_called_once_with(&quot;local&quot;, f&quot;{PATH}/file&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_get_file(adirfs):</span>
<span class="gi">+    await adirfs._get_file(&quot;file&quot;, &quot;local&quot;, **KWARGS)</span>
<span class="gi">+    adirfs.fs._get_file.assert_called_once_with(f&quot;{PATH}/file&quot;, &quot;local&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_get_file(dirfs):</span>
<span class="gi">+    dirfs.get_file(&quot;file&quot;, &quot;local&quot;, **KWARGS)</span>
<span class="gi">+    dirfs.fs.get_file.assert_called_once_with(f&quot;{PATH}/file&quot;, &quot;local&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_get(adirfs):</span>
<span class="gi">+    await adirfs._get(&quot;file&quot;, &quot;local&quot;, **KWARGS)</span>
<span class="gi">+    adirfs.fs._get.assert_called_once_with(f&quot;{PATH}/file&quot;, &quot;local&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_get(dirfs):</span>
<span class="gi">+    dirfs.get(&quot;file&quot;, &quot;local&quot;, **KWARGS)</span>
<span class="gi">+    dirfs.fs.get.assert_called_once_with(f&quot;{PATH}/file&quot;, &quot;local&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_isfile(adirfs):</span>
<span class="gi">+    assert await adirfs._isfile(&quot;file&quot;) == adirfs.fs._isfile.return_value</span>
<span class="gi">+    adirfs.fs._isfile.assert_called_once_with(f&quot;{PATH}/file&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_isfile(dirfs):</span>
<span class="gi">+    assert dirfs.isfile(&quot;file&quot;) == dirfs.fs.isfile.return_value</span>
<span class="gi">+    dirfs.fs.isfile.assert_called_once_with(f&quot;{PATH}/file&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_isdir(adirfs):</span>
<span class="gi">+    assert await adirfs._isdir(&quot;file&quot;) == adirfs.fs._isdir.return_value</span>
<span class="gi">+    adirfs.fs._isdir.assert_called_once_with(f&quot;{PATH}/file&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_isdir(dirfs):</span>
<span class="gi">+    assert dirfs.isdir(&quot;file&quot;) == dirfs.fs.isdir.return_value</span>
<span class="gi">+    dirfs.fs.isdir.assert_called_once_with(f&quot;{PATH}/file&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_size(adirfs):</span>
<span class="gi">+    assert await adirfs._size(&quot;file&quot;) == adirfs.fs._size.return_value</span>
<span class="gi">+    adirfs.fs._size.assert_called_once_with(f&quot;{PATH}/file&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_size(dirfs):</span>
<span class="gi">+    assert dirfs.size(&quot;file&quot;) == dirfs.fs.size.return_value</span>
<span class="gi">+    dirfs.fs.size.assert_called_once_with(f&quot;{PATH}/file&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_exists(adirfs):</span>
<span class="gi">+    assert await adirfs._exists(&quot;file&quot;) == adirfs.fs._exists.return_value</span>
<span class="gi">+    adirfs.fs._exists.assert_called_once_with(f&quot;{PATH}/file&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_exists(dirfs):</span>
<span class="gi">+    assert dirfs.exists(&quot;file&quot;) == dirfs.fs.exists.return_value</span>
<span class="gi">+    dirfs.fs.exists.assert_called_once_with(f&quot;{PATH}/file&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_info(adirfs):</span>
<span class="gi">+    assert await adirfs._info(&quot;file&quot;, **KWARGS) == adirfs.fs._info.return_value</span>
<span class="gi">+    adirfs.fs._info.assert_called_once_with(f&quot;{PATH}/file&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_info(dirfs):</span>
<span class="gi">+    assert dirfs.info(&quot;file&quot;, **KWARGS) == dirfs.fs.info.return_value</span>
<span class="gi">+    dirfs.fs.info.assert_called_once_with(f&quot;{PATH}/file&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_ls(adirfs):</span>
<span class="gi">+    adirfs.fs._ls.return_value = [f&quot;{PATH}/file&quot;]</span>
<span class="gi">+    assert await adirfs._ls(&quot;file&quot;, detail=False, **KWARGS) == [&quot;file&quot;]</span>
<span class="gi">+    adirfs.fs._ls.assert_called_once_with(f&quot;{PATH}/file&quot;, detail=False, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_ls(dirfs):</span>
<span class="gi">+    dirfs.fs.ls.return_value = [f&quot;{PATH}/file&quot;]</span>
<span class="gi">+    assert dirfs.ls(&quot;file&quot;, detail=False, **KWARGS) == [&quot;file&quot;]</span>
<span class="gi">+    dirfs.fs.ls.assert_called_once_with(f&quot;{PATH}/file&quot;, detail=False, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_ls_detail(adirfs):</span>
<span class="gi">+    adirfs.fs._ls.return_value = [{&quot;name&quot;: f&quot;{PATH}/file&quot;, &quot;foo&quot;: &quot;bar&quot;}]</span>
<span class="gi">+    assert await adirfs._ls(&quot;file&quot;, detail=True, **KWARGS) == [</span>
<span class="gi">+        {&quot;name&quot;: &quot;file&quot;, &quot;foo&quot;: &quot;bar&quot;}</span>
<span class="gi">+    ]</span>
<span class="gi">+    adirfs.fs._ls.assert_called_once_with(f&quot;{PATH}/file&quot;, detail=True, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_ls_detail(dirfs):</span>
<span class="gi">+    dirfs.fs.ls.return_value = [{&quot;name&quot;: f&quot;{PATH}/file&quot;, &quot;foo&quot;: &quot;bar&quot;}]</span>
<span class="gi">+    assert dirfs.ls(&quot;file&quot;, detail=True, **KWARGS) == [{&quot;name&quot;: &quot;file&quot;, &quot;foo&quot;: &quot;bar&quot;}]</span>
<span class="gi">+    dirfs.fs.ls.assert_called_once_with(f&quot;{PATH}/file&quot;, detail=True, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_walk(adirfs, mocker):</span>
<span class="gi">+    async def _walk(path, *args, **kwargs):</span>
<span class="gi">+        yield (f&quot;{PATH}/root&quot;, [&quot;foo&quot;, &quot;bar&quot;], [&quot;baz&quot;, &quot;qux&quot;])</span>
<span class="gi">+</span>
<span class="gi">+    adirfs.fs._walk = mocker.MagicMock()</span>
<span class="gi">+    adirfs.fs._walk.side_effect = _walk</span>
<span class="gi">+</span>
<span class="gi">+    actual = [entry async for entry in adirfs._walk(&quot;root&quot;, *ARGS, **KWARGS)]</span>
<span class="gi">+    assert actual == [(&quot;root&quot;, [&quot;foo&quot;, &quot;bar&quot;], [&quot;baz&quot;, &quot;qux&quot;])]</span>
<span class="gi">+    adirfs.fs._walk.assert_called_once_with(f&quot;{PATH}/root&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_walk(dirfs):</span>
<span class="gi">+    dirfs.fs.walk.return_value = iter(</span>
<span class="gi">+        [(f&quot;{PATH}/root&quot;, [&quot;foo&quot;, &quot;bar&quot;], [&quot;baz&quot;, &quot;qux&quot;])]</span>
<span class="gi">+    )</span>
<span class="gi">+    assert list(dirfs.walk(&quot;root&quot;, *ARGS, **KWARGS)) == [</span>
<span class="gi">+        (&quot;root&quot;, [&quot;foo&quot;, &quot;bar&quot;], [&quot;baz&quot;, &quot;qux&quot;])</span>
<span class="gi">+    ]</span>
<span class="gi">+    dirfs.fs.walk.assert_called_once_with(f&quot;{PATH}/root&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_glob(adirfs):</span>
<span class="gi">+    adirfs.fs._glob.return_value = [f&quot;{PATH}/one&quot;, f&quot;{PATH}/two&quot;]</span>
<span class="gi">+    assert await adirfs._glob(&quot;*&quot;, **KWARGS) == [&quot;one&quot;, &quot;two&quot;]</span>
<span class="gi">+    adirfs.fs._glob.assert_called_once_with(f&quot;{PATH}/*&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_glob(dirfs):</span>
<span class="gi">+    dirfs.fs.glob.return_value = [f&quot;{PATH}/one&quot;, f&quot;{PATH}/two&quot;]</span>
<span class="gi">+    assert dirfs.glob(&quot;*&quot;, **KWARGS) == [&quot;one&quot;, &quot;two&quot;]</span>
<span class="gi">+    dirfs.fs.glob.assert_called_once_with(f&quot;{PATH}/*&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_glob_with_protocol(dirfs):</span>
<span class="gi">+    dirfs.fs.glob.return_value = [f&quot;{PATH}/one&quot;, f&quot;{PATH}/two&quot;]</span>
<span class="gi">+    assert dirfs.glob(&quot;dir://*&quot;, **KWARGS) == [&quot;one&quot;, &quot;two&quot;]</span>
<span class="gi">+    dirfs.fs.glob.assert_called_once_with(f&quot;{PATH}/*&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_glob_detail(adirfs):</span>
<span class="gi">+    adirfs.fs._glob.return_value = {</span>
<span class="gi">+        f&quot;{PATH}/one&quot;: {&quot;foo&quot;: &quot;bar&quot;},</span>
<span class="gi">+        f&quot;{PATH}/two&quot;: {&quot;baz&quot;: &quot;qux&quot;},</span>
<span class="gi">+    }</span>
<span class="gi">+    assert await adirfs._glob(&quot;*&quot;, detail=True, **KWARGS) == {</span>
<span class="gi">+        &quot;one&quot;: {&quot;foo&quot;: &quot;bar&quot;},</span>
<span class="gi">+        &quot;two&quot;: {&quot;baz&quot;: &quot;qux&quot;},</span>
<span class="gi">+    }</span>
<span class="gi">+    adirfs.fs._glob.assert_called_once_with(f&quot;{PATH}/*&quot;, detail=True, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_glob_detail(dirfs):</span>
<span class="gi">+    dirfs.fs.glob.return_value = {</span>
<span class="gi">+        f&quot;{PATH}/one&quot;: {&quot;foo&quot;: &quot;bar&quot;},</span>
<span class="gi">+        f&quot;{PATH}/two&quot;: {&quot;baz&quot;: &quot;qux&quot;},</span>
<span class="gi">+    }</span>
<span class="gi">+    assert dirfs.glob(&quot;*&quot;, detail=True, **KWARGS) == {</span>
<span class="gi">+        &quot;one&quot;: {&quot;foo&quot;: &quot;bar&quot;},</span>
<span class="gi">+        &quot;two&quot;: {&quot;baz&quot;: &quot;qux&quot;},</span>
<span class="gi">+    }</span>
<span class="gi">+    dirfs.fs.glob.assert_called_once_with(f&quot;{PATH}/*&quot;, detail=True, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_du(adirfs):</span>
<span class="gi">+    adirfs.fs._du.return_value = 1234</span>
<span class="gi">+    assert await adirfs._du(&quot;file&quot;, *ARGS, **KWARGS) == 1234</span>
<span class="gi">+    adirfs.fs._du.assert_called_once_with(f&quot;{PATH}/file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_du(dirfs):</span>
<span class="gi">+    dirfs.fs.du.return_value = 1234</span>
<span class="gi">+    assert dirfs.du(&quot;file&quot;, *ARGS, **KWARGS) == 1234</span>
<span class="gi">+    dirfs.fs.du.assert_called_once_with(f&quot;{PATH}/file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_du_granular(adirfs):</span>
<span class="gi">+    adirfs.fs._du.return_value = {f&quot;{PATH}/dir/one&quot;: 1, f&quot;{PATH}/dir/two&quot;: 2}</span>
<span class="gi">+    assert await adirfs._du(&quot;dir&quot;, *ARGS, total=False, **KWARGS) == {</span>
<span class="gi">+        &quot;dir/one&quot;: 1,</span>
<span class="gi">+        &quot;dir/two&quot;: 2,</span>
<span class="gi">+    }</span>
<span class="gi">+    adirfs.fs._du.assert_called_once_with(f&quot;{PATH}/dir&quot;, *ARGS, total=False, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_du_granular(dirfs):</span>
<span class="gi">+    dirfs.fs.du.return_value = {f&quot;{PATH}/dir/one&quot;: 1, f&quot;{PATH}/dir/two&quot;: 2}</span>
<span class="gi">+    assert dirfs.du(&quot;dir&quot;, *ARGS, total=False, **KWARGS) == {&quot;dir/one&quot;: 1, &quot;dir/two&quot;: 2}</span>
<span class="gi">+    dirfs.fs.du.assert_called_once_with(f&quot;{PATH}/dir&quot;, *ARGS, total=False, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_find(adirfs):</span>
<span class="gi">+    adirfs.fs._find.return_value = [f&quot;{PATH}/dir/one&quot;, f&quot;{PATH}/dir/two&quot;]</span>
<span class="gi">+    assert await adirfs._find(&quot;dir&quot;, *ARGS, **KWARGS) == [&quot;dir/one&quot;, &quot;dir/two&quot;]</span>
<span class="gi">+    adirfs.fs._find.assert_called_once_with(f&quot;{PATH}/dir&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_find(dirfs):</span>
<span class="gi">+    dirfs.fs.find.return_value = [f&quot;{PATH}/dir/one&quot;, f&quot;{PATH}/dir/two&quot;]</span>
<span class="gi">+    assert dirfs.find(&quot;dir&quot;, *ARGS, **KWARGS) == [&quot;dir/one&quot;, &quot;dir/two&quot;]</span>
<span class="gi">+    dirfs.fs.find.assert_called_once_with(f&quot;{PATH}/dir&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_find_detail(adirfs):</span>
<span class="gi">+    adirfs.fs._find.return_value = {</span>
<span class="gi">+        f&quot;{PATH}/dir/one&quot;: {&quot;foo&quot;: &quot;bar&quot;},</span>
<span class="gi">+        f&quot;{PATH}/dir/two&quot;: {&quot;baz&quot;: &quot;qux&quot;},</span>
<span class="gi">+    }</span>
<span class="gi">+    assert await adirfs._find(&quot;dir&quot;, *ARGS, detail=True, **KWARGS) == {</span>
<span class="gi">+        &quot;dir/one&quot;: {&quot;foo&quot;: &quot;bar&quot;},</span>
<span class="gi">+        &quot;dir/two&quot;: {&quot;baz&quot;: &quot;qux&quot;},</span>
<span class="gi">+    }</span>
<span class="gi">+    adirfs.fs._find.assert_called_once_with(f&quot;{PATH}/dir&quot;, *ARGS, detail=True, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_find_detail(dirfs):</span>
<span class="gi">+    dirfs.fs.find.return_value = {</span>
<span class="gi">+        f&quot;{PATH}/dir/one&quot;: {&quot;foo&quot;: &quot;bar&quot;},</span>
<span class="gi">+        f&quot;{PATH}/dir/two&quot;: {&quot;baz&quot;: &quot;qux&quot;},</span>
<span class="gi">+    }</span>
<span class="gi">+    assert dirfs.find(&quot;dir&quot;, *ARGS, detail=True, **KWARGS) == {</span>
<span class="gi">+        &quot;dir/one&quot;: {&quot;foo&quot;: &quot;bar&quot;},</span>
<span class="gi">+        &quot;dir/two&quot;: {&quot;baz&quot;: &quot;qux&quot;},</span>
<span class="gi">+    }</span>
<span class="gi">+    dirfs.fs.find.assert_called_once_with(f&quot;{PATH}/dir&quot;, *ARGS, detail=True, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_expand_path(adirfs):</span>
<span class="gi">+    adirfs.fs._expand_path.return_value = [f&quot;{PATH}/file&quot;]</span>
<span class="gi">+    assert await adirfs._expand_path(&quot;*&quot;, *ARGS, **KWARGS) == [&quot;file&quot;]</span>
<span class="gi">+    adirfs.fs._expand_path.assert_called_once_with(f&quot;{PATH}/*&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_expand_path(dirfs):</span>
<span class="gi">+    dirfs.fs.expand_path.return_value = [f&quot;{PATH}/file&quot;]</span>
<span class="gi">+    assert dirfs.expand_path(&quot;*&quot;, *ARGS, **KWARGS) == [&quot;file&quot;]</span>
<span class="gi">+    dirfs.fs.expand_path.assert_called_once_with(f&quot;{PATH}/*&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_expand_path_list(adirfs):</span>
<span class="gi">+    adirfs.fs._expand_path.return_value = [f&quot;{PATH}/1file&quot;, f&quot;{PATH}/2file&quot;]</span>
<span class="gi">+    assert await adirfs._expand_path([&quot;1*&quot;, &quot;2*&quot;], *ARGS, **KWARGS) == [</span>
<span class="gi">+        &quot;1file&quot;,</span>
<span class="gi">+        &quot;2file&quot;,</span>
<span class="gi">+    ]</span>
<span class="gi">+    adirfs.fs._expand_path.assert_called_once_with(</span>
<span class="gi">+        [f&quot;{PATH}/1*&quot;, f&quot;{PATH}/2*&quot;], *ARGS, **KWARGS</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_expand_path_list(dirfs):</span>
<span class="gi">+    dirfs.fs.expand_path.return_value = [f&quot;{PATH}/1file&quot;, f&quot;{PATH}/2file&quot;]</span>
<span class="gi">+    assert dirfs.expand_path([&quot;1*&quot;, &quot;2*&quot;], *ARGS, **KWARGS) == [&quot;1file&quot;, &quot;2file&quot;]</span>
<span class="gi">+    dirfs.fs.expand_path.assert_called_once_with(</span>
<span class="gi">+        [f&quot;{PATH}/1*&quot;, f&quot;{PATH}/2*&quot;], *ARGS, **KWARGS</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_mkdir(adirfs):</span>
<span class="gi">+    await adirfs._mkdir(&quot;dir&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+    adirfs.fs._mkdir.assert_called_once_with(f&quot;{PATH}/dir&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mkdir(dirfs):</span>
<span class="gi">+    dirfs.mkdir(&quot;dir&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+    dirfs.fs.mkdir.assert_called_once_with(f&quot;{PATH}/dir&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_makedirs(adirfs):</span>
<span class="gi">+    await adirfs._makedirs(&quot;dir&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+    adirfs.fs._makedirs.assert_called_once_with(f&quot;{PATH}/dir&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_makedirs(dirfs):</span>
<span class="gi">+    dirfs.makedirs(&quot;dir&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+    dirfs.fs.makedirs.assert_called_once_with(f&quot;{PATH}/dir&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_rmdir(mocker, dirfs):</span>
<span class="gi">+    dirfs.fs.rmdir = mocker.Mock()</span>
<span class="gi">+    dirfs.rmdir(&quot;dir&quot;)</span>
<span class="gi">+    dirfs.fs.rmdir.assert_called_once_with(f&quot;{PATH}/dir&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mv(mocker, dirfs):</span>
<span class="gi">+    dirfs.fs.mv = mocker.Mock()</span>
<span class="gi">+    dirfs.mv(&quot;one&quot;, &quot;two&quot;, **KWARGS)</span>
<span class="gi">+    dirfs.fs.mv.assert_called_once_with(f&quot;{PATH}/one&quot;, f&quot;{PATH}/two&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_touch(mocker, dirfs):</span>
<span class="gi">+    dirfs.fs.touch = mocker.Mock()</span>
<span class="gi">+    dirfs.touch(&quot;file&quot;, **KWARGS)</span>
<span class="gi">+    dirfs.fs.touch.assert_called_once_with(f&quot;{PATH}/file&quot;, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_created(mocker, dirfs):</span>
<span class="gi">+    dirfs.fs.created = mocker.Mock(return_value=&quot;date&quot;)</span>
<span class="gi">+    assert dirfs.created(&quot;file&quot;) == &quot;date&quot;</span>
<span class="gi">+    dirfs.fs.created.assert_called_once_with(f&quot;{PATH}/file&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_modified(mocker, dirfs):</span>
<span class="gi">+    dirfs.fs.modified = mocker.Mock(return_value=&quot;date&quot;)</span>
<span class="gi">+    assert dirfs.modified(&quot;file&quot;) == &quot;date&quot;</span>
<span class="gi">+    dirfs.fs.modified.assert_called_once_with(f&quot;{PATH}/file&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_sign(mocker, dirfs):</span>
<span class="gi">+    dirfs.fs.sign = mocker.Mock(return_value=&quot;url&quot;)</span>
<span class="gi">+    assert dirfs.sign(&quot;file&quot;, *ARGS, **KWARGS) == &quot;url&quot;</span>
<span class="gi">+    dirfs.fs.sign.assert_called_once_with(f&quot;{PATH}/file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_open(mocker, dirfs):</span>
<span class="gi">+    dirfs.fs.open = mocker.Mock()</span>
<span class="gi">+    assert dirfs.open(&quot;file&quot;, *ARGS, **KWARGS) == dirfs.fs.open.return_value</span>
<span class="gi">+    dirfs.fs.open.assert_called_once_with(f&quot;{PATH}/file&quot;, *ARGS, **KWARGS)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_from_url(m):</span>
<span class="gi">+    from fsspec.core import url_to_fs</span>
<span class="gi">+</span>
<span class="gi">+    m.pipe(&quot;inner/file&quot;, b&quot;data&quot;)</span>
<span class="gi">+    fs, _ = url_to_fs(&quot;dir::memory://inner&quot;)</span>
<span class="gi">+    assert fs.ls(&quot;&quot;, False) == [&quot;file&quot;]</span>
<span class="gi">+    assert fs.ls(&quot;&quot;, True)[0][&quot;name&quot;] == &quot;file&quot;</span>
<span class="gi">+    assert fs.cat(&quot;file&quot;) == b&quot;data&quot;</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_ftp.py b/fsspec/implementations/tests/test_ftp.py</span>
<span class="gh">index 65bf2c1..d443d86 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_ftp.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_ftp.py</span>
<span class="gu">@@ -2,9 +2,177 @@ import os</span>
<span class="w"> </span>import subprocess
<span class="w"> </span>import sys
<span class="w"> </span>import time
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="w"> </span>from fsspec import open_files
<span class="w"> </span>from fsspec.implementations.ftp import FTPFileSystem
<span class="gd">-ftplib = pytest.importorskip(&#39;ftplib&#39;)</span>
<span class="gi">+</span>
<span class="gi">+ftplib = pytest.importorskip(&quot;ftplib&quot;)</span>
<span class="w"> </span>here = os.path.dirname(os.path.abspath(__file__))
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture()</span>
<span class="gi">+def ftp():</span>
<span class="gi">+    pytest.importorskip(&quot;pyftpdlib&quot;)</span>
<span class="gi">+    P = subprocess.Popen(</span>
<span class="gi">+        [sys.executable, &quot;-m&quot;, &quot;pyftpdlib&quot;, &quot;-d&quot;, here],</span>
<span class="gi">+        stderr=subprocess.STDOUT,</span>
<span class="gi">+        stdout=subprocess.PIPE,</span>
<span class="gi">+    )</span>
<span class="gi">+    try:</span>
<span class="gi">+        time.sleep(1)</span>
<span class="gi">+        yield &quot;localhost&quot;, 2121</span>
<span class="gi">+    finally:</span>
<span class="gi">+        P.terminate()</span>
<span class="gi">+        P.wait()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_basic(ftp):</span>
<span class="gi">+    host, port = ftp</span>
<span class="gi">+    fs = FTPFileSystem(host, port)</span>
<span class="gi">+    assert fs.ls(&quot;/&quot;, detail=False) == sorted(os.listdir(here))</span>
<span class="gi">+    out = fs.cat(f&quot;/{os.path.basename(__file__)}&quot;)</span>
<span class="gi">+    assert out == open(__file__, &quot;rb&quot;).read()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_not_cached(ftp):</span>
<span class="gi">+    host, port = ftp</span>
<span class="gi">+    fs = FTPFileSystem(host, port)</span>
<span class="gi">+    fs2 = FTPFileSystem(host, port)</span>
<span class="gi">+    assert fs is not fs2</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;cache_type&quot;, [&quot;bytes&quot;, &quot;mmap&quot;])</span>
<span class="gi">+def test_complex(ftp_writable, cache_type):</span>
<span class="gi">+    from fsspec.core import BytesCache</span>
<span class="gi">+</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    files = open_files(</span>
<span class="gi">+        &quot;ftp:///ou*&quot;,</span>
<span class="gi">+        host=host,</span>
<span class="gi">+        port=port,</span>
<span class="gi">+        username=user,</span>
<span class="gi">+        password=pw,</span>
<span class="gi">+        block_size=10000,</span>
<span class="gi">+        cache_type=cache_type,</span>
<span class="gi">+    )</span>
<span class="gi">+    assert len(files) == 1</span>
<span class="gi">+    with files[0] as fo:</span>
<span class="gi">+        assert fo.read(10) == b&quot;hellohello&quot;</span>
<span class="gi">+        if isinstance(fo.cache, BytesCache):</span>
<span class="gi">+            assert len(fo.cache.cache) == 10010</span>
<span class="gi">+        assert fo.read(2) == b&quot;he&quot;</span>
<span class="gi">+        assert fo.tell() == 12</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_write_small(ftp_writable):</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    fs = FTPFileSystem(host, port, user, pw)</span>
<span class="gi">+    with fs.open(&quot;/out2&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;oi&quot;)</span>
<span class="gi">+    assert fs.cat(&quot;/out2&quot;) == b&quot;oi&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_with_url(ftp_writable):</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    fo = fsspec.open(f&quot;ftp://{user}:{pw}@{host}:{port}/out&quot;, &quot;wb&quot;)</span>
<span class="gi">+    with fo as f:</span>
<span class="gi">+        f.write(b&quot;hello&quot;)</span>
<span class="gi">+    fo = fsspec.open(f&quot;ftp://{user}:{pw}@{host}:{port}/out&quot;, &quot;rb&quot;)</span>
<span class="gi">+    with fo as f:</span>
<span class="gi">+        assert f.read() == b&quot;hello&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;cache_type&quot;, [&quot;bytes&quot;, &quot;mmap&quot;])</span>
<span class="gi">+def test_write_big(ftp_writable, cache_type):</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    fs = FTPFileSystem(host, port, user, pw, block_size=1000, cache_type=cache_type)</span>
<span class="gi">+    fn = &quot;/bigger&quot;</span>
<span class="gi">+    with fs.open(fn, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;o&quot; * 500)</span>
<span class="gi">+        assert not fs.exists(fn)</span>
<span class="gi">+        f.write(b&quot;o&quot; * 1000)</span>
<span class="gi">+        fs.invalidate_cache()</span>
<span class="gi">+        assert fs.exists(fn)</span>
<span class="gi">+        f.write(b&quot;o&quot; * 200)</span>
<span class="gi">+        f.flush()</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.info(fn)[&quot;size&quot;] == 1700</span>
<span class="gi">+    assert fs.cat(fn) == b&quot;o&quot; * 1700</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_transaction(ftp_writable):</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    fs = FTPFileSystem(host, port, user, pw)</span>
<span class="gi">+    fs.mkdir(&quot;/tmp&quot;)</span>
<span class="gi">+    fn = &quot;/tr&quot;</span>
<span class="gi">+    with fs.transaction:</span>
<span class="gi">+        with fs.open(fn, &quot;wb&quot;) as f:</span>
<span class="gi">+            f.write(b&quot;not&quot;)</span>
<span class="gi">+        assert not fs.exists(fn)</span>
<span class="gi">+    assert fs.exists(fn)</span>
<span class="gi">+    assert fs.cat(fn) == b&quot;not&quot;</span>
<span class="gi">+</span>
<span class="gi">+    fs.rm(fn)</span>
<span class="gi">+    assert not fs.exists(fn)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_transaction_with_cache(ftp_writable, tmpdir):</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    fs = FTPFileSystem(host, port, user, pw)</span>
<span class="gi">+    fs.mkdir(&quot;/tmp&quot;)</span>
<span class="gi">+    fs.mkdir(&quot;/tmp/dir&quot;)</span>
<span class="gi">+    assert &quot;dir&quot; in fs.ls(&quot;/tmp&quot;, detail=False)</span>
<span class="gi">+</span>
<span class="gi">+    with fs.transaction:</span>
<span class="gi">+        fs.rmdir(&quot;/tmp/dir&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert &quot;dir&quot; not in fs.ls(&quot;/tmp&quot;, detail=False)</span>
<span class="gi">+    assert not fs.exists(&quot;/tmp/dir&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_cat_get(ftp_writable, tmpdir):</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    fs = FTPFileSystem(host, port, user, pw, block_size=500)</span>
<span class="gi">+    fs.mkdir(&quot;/tmp&quot;)</span>
<span class="gi">+    data = b&quot;hello&quot; * 500</span>
<span class="gi">+    fs.pipe(&quot;/tmp/myfile&quot;, data)</span>
<span class="gi">+    assert fs.cat_file(&quot;/tmp/myfile&quot;) == data</span>
<span class="gi">+</span>
<span class="gi">+    fn = os.path.join(tmpdir, &quot;lfile&quot;)</span>
<span class="gi">+    fs.get_file(&quot;/tmp/myfile&quot;, fn)</span>
<span class="gi">+    assert open(fn, &quot;rb&quot;).read() == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mkdir(ftp_writable):</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    fs = FTPFileSystem(host, port, user, pw)</span>
<span class="gi">+    with pytest.raises(ftplib.error_perm):</span>
<span class="gi">+        fs.mkdir(&quot;/tmp/not/exist&quot;, create_parents=False)</span>
<span class="gi">+    fs.mkdir(&quot;/tmp/not/exist&quot;)</span>
<span class="gi">+    assert fs.exists(&quot;/tmp/not/exist&quot;)</span>
<span class="gi">+    fs.makedirs(&quot;/tmp/not/exist&quot;, exist_ok=True)</span>
<span class="gi">+    with pytest.raises(FileExistsError):</span>
<span class="gi">+        fs.makedirs(&quot;/tmp/not/exist&quot;, exist_ok=False)</span>
<span class="gi">+    fs.makedirs(&quot;/tmp/not/exist/inner/inner&quot;)</span>
<span class="gi">+    assert fs.isdir(&quot;/tmp/not/exist/inner/inner&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_rm_get_recursive(ftp_writable, tmpdir):</span>
<span class="gi">+    tmpdir = str(tmpdir)</span>
<span class="gi">+    host, port, user, pw = ftp_writable</span>
<span class="gi">+    fs = FTPFileSystem(host, port, user, pw)</span>
<span class="gi">+    fs.mkdir(&quot;/tmp/topdir&quot;)</span>
<span class="gi">+    fs.mkdir(&quot;/tmp/topdir/underdir&quot;)</span>
<span class="gi">+    fs.touch(&quot;/tmp/topdir/afile&quot;)</span>
<span class="gi">+    fs.touch(&quot;/tmp/topdir/underdir/afile&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs.get(&quot;/tmp/topdir&quot;, tmpdir, recursive=True)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ftplib.error_perm):</span>
<span class="gi">+        fs.rmdir(&quot;/tmp/topdir&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs.rm(&quot;/tmp/topdir&quot;, recursive=True)</span>
<span class="gi">+    assert not fs.exists(&quot;/tmp/topdir&quot;)</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_git.py b/fsspec/implementations/tests/test_git.py</span>
<span class="gh">index f742628..ffa7b47 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_git.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_git.py</span>
<span class="gu">@@ -2,7 +2,75 @@ import os</span>
<span class="w"> </span>import shutil
<span class="w"> </span>import subprocess
<span class="w"> </span>import tempfile
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="w"> </span>from fsspec.implementations.local import make_path_posix
<span class="gd">-pygit2 = pytest.importorskip(&#39;pygit2&#39;)</span>
<span class="gi">+</span>
<span class="gi">+pygit2 = pytest.importorskip(&quot;pygit2&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture()</span>
<span class="gi">+def repo():</span>
<span class="gi">+    orig_dir = os.getcwd()</span>
<span class="gi">+    d = tempfile.mkdtemp()</span>
<span class="gi">+    try:</span>
<span class="gi">+        os.chdir(d)</span>
<span class="gi">+        subprocess.call(&quot;git init -b master&quot;, shell=True, cwd=d)</span>
<span class="gi">+        subprocess.call(&quot;git init -b master&quot;, shell=True, cwd=d)</span>
<span class="gi">+        subprocess.call(&#39;git config user.email &quot;you@example.com&quot;&#39;, shell=True, cwd=d)</span>
<span class="gi">+        subprocess.call(&#39;git config user.name &quot;Your Name&quot;&#39;, shell=True, cwd=d)</span>
<span class="gi">+        open(os.path.join(d, &quot;file1&quot;), &quot;wb&quot;).write(b&quot;data0&quot;)</span>
<span class="gi">+        subprocess.call(&quot;git add file1&quot;, shell=True, cwd=d)</span>
<span class="gi">+        subprocess.call(&#39;git commit -m &quot;init&quot;&#39;, shell=True, cwd=d)</span>
<span class="gi">+        sha = open(os.path.join(d, &quot;.git/refs/heads/master&quot;), &quot;r&quot;).read().strip()</span>
<span class="gi">+        open(os.path.join(d, &quot;file1&quot;), &quot;wb&quot;).write(b&quot;data00&quot;)</span>
<span class="gi">+        subprocess.check_output(&#39;git commit -a -m &quot;tagger&quot;&#39;, shell=True, cwd=d)</span>
<span class="gi">+        subprocess.call(&#39;git tag -a thetag -m &quot;make tag&quot;&#39;, shell=True, cwd=d)</span>
<span class="gi">+        open(os.path.join(d, &quot;file2&quot;), &quot;wb&quot;).write(b&quot;data000&quot;)</span>
<span class="gi">+        subprocess.call(&quot;git add file2&quot;, shell=True)</span>
<span class="gi">+        subprocess.call(&#39;git commit -m &quot;master tip&quot;&#39;, shell=True, cwd=d)</span>
<span class="gi">+        subprocess.call(&quot;git checkout -b abranch&quot;, shell=True, cwd=d)</span>
<span class="gi">+        os.mkdir(&quot;inner&quot;)</span>
<span class="gi">+        open(os.path.join(d, &quot;inner&quot;, &quot;file1&quot;), &quot;wb&quot;).write(b&quot;data3&quot;)</span>
<span class="gi">+        subprocess.call(&quot;git add inner/file1&quot;, shell=True, cwd=d)</span>
<span class="gi">+        subprocess.call(&#39;git commit -m &quot;branch tip&quot;&#39;, shell=True, cwd=d)</span>
<span class="gi">+        os.chdir(orig_dir)</span>
<span class="gi">+        yield d, sha</span>
<span class="gi">+    finally:</span>
<span class="gi">+        os.chdir(orig_dir)</span>
<span class="gi">+        shutil.rmtree(d)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_refs(repo):</span>
<span class="gi">+    d, sha = repo</span>
<span class="gi">+    with fsspec.open(&quot;git://file1&quot;, path=d, ref=sha) as f:</span>
<span class="gi">+        assert f.read() == b&quot;data0&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with fsspec.open(&quot;git://file1&quot;, path=d, ref=&quot;thetag&quot;) as f:</span>
<span class="gi">+        assert f.read() == b&quot;data00&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with fsspec.open(&quot;git://file2&quot;, path=d, ref=&quot;master&quot;) as f:</span>
<span class="gi">+        assert f.read() == b&quot;data000&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with fsspec.open(&quot;git://file2&quot;, path=d, ref=None) as f:</span>
<span class="gi">+        assert f.read() == b&quot;data000&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with fsspec.open(&quot;git://inner/file1&quot;, path=d, ref=&quot;abranch&quot;) as f:</span>
<span class="gi">+        assert f.read() == b&quot;data3&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_url(repo):</span>
<span class="gi">+    d, sha = repo</span>
<span class="gi">+    fs, _, paths = fsspec.core.get_fs_token_paths(f&quot;git://file1::file://{d}&quot;)</span>
<span class="gi">+    assert make_path_posix(d) in make_path_posix(fs.repo.path)</span>
<span class="gi">+    assert paths == [&quot;file1&quot;]</span>
<span class="gi">+    with fsspec.open(f&quot;git://file1::file://{d}&quot;) as f:</span>
<span class="gi">+        assert f.read() == b&quot;data00&quot;</span>
<span class="gi">+</span>
<span class="gi">+    fs, _, paths = fsspec.core.get_fs_token_paths(f&quot;git://{d}:master@file1&quot;)</span>
<span class="gi">+    assert make_path_posix(d) in make_path_posix(fs.repo.path)</span>
<span class="gi">+    assert paths == [&quot;file1&quot;]</span>
<span class="gi">+    with fsspec.open(f&quot;git://{d}:master@file1&quot;) as f:</span>
<span class="gi">+        assert f.read() == b&quot;data00&quot;</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_http.py b/fsspec/implementations/tests/test_http.py</span>
<span class="gh">index 4ff3da6..81e438a 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_http.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_http.py</span>
<span class="gu">@@ -4,9 +4,572 @@ import json</span>
<span class="w"> </span>import os
<span class="w"> </span>import sys
<span class="w"> </span>import time
<span class="gi">+</span>
<span class="w"> </span>import aiohttp
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>import fsspec.asyn
<span class="w"> </span>import fsspec.utils
<span class="w"> </span>from fsspec.implementations.http import HTTPStreamFile
<span class="gd">-from fsspec.tests.conftest import data, reset_files, server, win</span>
<span class="gi">+from fsspec.tests.conftest import data, reset_files, server, win  # noqa: F401</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_list(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+    out = h.glob(server + &quot;/index/*&quot;)</span>
<span class="gi">+    assert out == [server + &quot;/index/realfile&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_list_invalid_args(server):</span>
<span class="gi">+    with pytest.raises(TypeError):</span>
<span class="gi">+        h = fsspec.filesystem(&quot;http&quot;, use_foobar=True)</span>
<span class="gi">+        h.glob(server + &quot;/index/*&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_list_cache(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, use_listings_cache=True)</span>
<span class="gi">+    out = h.glob(server + &quot;/index/*&quot;)</span>
<span class="gi">+    assert out == [server + &quot;/index/realfile&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_list_cache_with_expiry_time_cached(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, use_listings_cache=True, listings_expiry_time=30)</span>
<span class="gi">+</span>
<span class="gi">+    # First, the directory cache is not initialized.</span>
<span class="gi">+    assert not h.dircache</span>
<span class="gi">+</span>
<span class="gi">+    # By querying the filesystem with &quot;use_listings_cache=True&quot;,</span>
<span class="gi">+    # the cache will automatically get populated.</span>
<span class="gi">+    out = h.glob(server + &quot;/index/*&quot;)</span>
<span class="gi">+    assert out == [server + &quot;/index/realfile&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    # Verify cache content.</span>
<span class="gi">+    assert len(h.dircache) == 1</span>
<span class="gi">+</span>
<span class="gi">+    out = h.glob(server + &quot;/index/*&quot;)</span>
<span class="gi">+    assert out == [server + &quot;/index/realfile&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_list_cache_with_expiry_time_purged(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, use_listings_cache=True, listings_expiry_time=0.3)</span>
<span class="gi">+</span>
<span class="gi">+    # First, the directory cache is not initialized.</span>
<span class="gi">+    assert not h.dircache</span>
<span class="gi">+</span>
<span class="gi">+    # By querying the filesystem with &quot;use_listings_cache=True&quot;,</span>
<span class="gi">+    # the cache will automatically get populated.</span>
<span class="gi">+    out = h.glob(server + &quot;/index/*&quot;)</span>
<span class="gi">+    assert out == [server + &quot;/index/realfile&quot;]</span>
<span class="gi">+    assert len(h.dircache) == 1</span>
<span class="gi">+</span>
<span class="gi">+    # Verify cache content.</span>
<span class="gi">+    assert server + &quot;/index/&quot; in h.dircache</span>
<span class="gi">+    assert len(h.dircache.get(server + &quot;/index/&quot;)) == 1</span>
<span class="gi">+</span>
<span class="gi">+    # Wait beyond the TTL / cache expiry time.</span>
<span class="gi">+    time.sleep(0.31)</span>
<span class="gi">+</span>
<span class="gi">+    # Verify that the cache item should have been purged.</span>
<span class="gi">+    cached_items = h.dircache.get(server + &quot;/index/&quot;)</span>
<span class="gi">+    assert cached_items is None</span>
<span class="gi">+</span>
<span class="gi">+    # Verify that after clearing the item from the cache,</span>
<span class="gi">+    # it can get populated again.</span>
<span class="gi">+    out = h.glob(server + &quot;/index/*&quot;)</span>
<span class="gi">+    assert out == [server + &quot;/index/realfile&quot;]</span>
<span class="gi">+    cached_items = h.dircache.get(server + &quot;/index/&quot;)</span>
<span class="gi">+    assert len(cached_items) == 1</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_list_cache_reuse(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, use_listings_cache=True, listings_expiry_time=5)</span>
<span class="gi">+</span>
<span class="gi">+    # First, the directory cache is not initialized.</span>
<span class="gi">+    assert not h.dircache</span>
<span class="gi">+</span>
<span class="gi">+    # By querying the filesystem with &quot;use_listings_cache=True&quot;,</span>
<span class="gi">+    # the cache will automatically get populated.</span>
<span class="gi">+    out = h.glob(server + &quot;/index/*&quot;)</span>
<span class="gi">+    assert out == [server + &quot;/index/realfile&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    # Verify cache content.</span>
<span class="gi">+    assert len(h.dircache) == 1</span>
<span class="gi">+</span>
<span class="gi">+    # Verify another instance without caching enabled does not have cache content.</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, use_listings_cache=False)</span>
<span class="gi">+    assert not h.dircache</span>
<span class="gi">+</span>
<span class="gi">+    # Verify that yet another new instance, with caching enabled,</span>
<span class="gi">+    # will see the same cache content again.</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, use_listings_cache=True, listings_expiry_time=5)</span>
<span class="gi">+    assert len(h.dircache) == 1</span>
<span class="gi">+</span>
<span class="gi">+    # However, yet another instance with a different expiry time will also not have</span>
<span class="gi">+    # any valid cache content.</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, use_listings_cache=True, listings_expiry_time=666)</span>
<span class="gi">+    assert len(h.dircache) == 0</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_ls_raises_filenotfound(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(FileNotFoundError):</span>
<span class="gi">+        h.ls(server + &quot;/not-a-key&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_list_cache_with_max_paths(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, use_listings_cache=True, max_paths=5)</span>
<span class="gi">+    out = h.glob(server + &quot;/index/*&quot;)</span>
<span class="gi">+    assert out == [server + &quot;/index/realfile&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_list_cache_with_skip_instance_cache(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, use_listings_cache=True, skip_instance_cache=True)</span>
<span class="gi">+    out = h.glob(server + &quot;/index/*&quot;)</span>
<span class="gi">+    assert out == [server + &quot;/index/realfile&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_glob_return_subfolders(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+    out = h.glob(server + &quot;/simple/*&quot;)</span>
<span class="gi">+    assert set(out) == {</span>
<span class="gi">+        server + &quot;/simple/dir/&quot;,</span>
<span class="gi">+        server + &quot;/simple/file&quot;,</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_isdir(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+    assert h.isdir(server + &quot;/index/&quot;)</span>
<span class="gi">+    assert not h.isdir(server + &quot;/index/realfile&quot;)</span>
<span class="gi">+    assert not h.isdir(server + &quot;doesnotevenexist&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_policy_arg(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, size_policy=&quot;get&quot;)</span>
<span class="gi">+    out = h.glob(server + &quot;/index/*&quot;)</span>
<span class="gi">+    assert out == [server + &quot;/index/realfile&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_exists(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+    assert not h.exists(server + &quot;/notafile&quot;)</span>
<span class="gi">+    with pytest.raises(FileNotFoundError):</span>
<span class="gi">+        h.cat(server + &quot;/notafile&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+    out = server + &quot;/index/realfile&quot;</span>
<span class="gi">+    with h.open(out, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+    with h.open(out, &quot;rb&quot;, block_size=0) as f:</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+    with h.open(out, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read(100) + f.read() == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_file_pickle(server):</span>
<span class="gi">+    import pickle</span>
<span class="gi">+</span>
<span class="gi">+    # via HTTPFile</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, headers={&quot;give_length&quot;: &quot;true&quot;, &quot;head_ok&quot;: &quot;true&quot;})</span>
<span class="gi">+    out = server + &quot;/index/realfile&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with fsspec.open(out, headers={&quot;give_length&quot;: &quot;true&quot;, &quot;head_ok&quot;: &quot;true&quot;}) as f:</span>
<span class="gi">+        pic = pickle.loads(pickle.dumps(f))</span>
<span class="gi">+        assert pic.read() == data</span>
<span class="gi">+</span>
<span class="gi">+    with h.open(out, &quot;rb&quot;) as f:</span>
<span class="gi">+        pic = pickle.dumps(f)</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+    with pickle.loads(pic) as f:</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+</span>
<span class="gi">+    # via HTTPStreamFile</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+    out = server + &quot;/index/realfile&quot;</span>
<span class="gi">+    with h.open(out, &quot;rb&quot;) as f:</span>
<span class="gi">+        out = pickle.dumps(f)</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+    with pickle.loads(out) as f:</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_methods(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+    url = server + &quot;/index/realfile&quot;</span>
<span class="gi">+    assert h.exists(url)</span>
<span class="gi">+    assert h.cat(url) == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;headers&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        {},</span>
<span class="gi">+        {&quot;give_length&quot;: &quot;true&quot;},</span>
<span class="gi">+        {&quot;give_length&quot;: &quot;true&quot;, &quot;head_ok&quot;: &quot;true&quot;},</span>
<span class="gi">+        {&quot;give_range&quot;: &quot;true&quot;},</span>
<span class="gi">+        {&quot;give_length&quot;: &quot;true&quot;, &quot;head_not_auth&quot;: &quot;true&quot;},</span>
<span class="gi">+        {&quot;give_range&quot;: &quot;true&quot;, &quot;head_not_auth&quot;: &quot;true&quot;},</span>
<span class="gi">+        {&quot;use_206&quot;: &quot;true&quot;, &quot;head_ok&quot;: &quot;true&quot;, &quot;head_give_length&quot;: &quot;true&quot;},</span>
<span class="gi">+        {&quot;use_206&quot;: &quot;true&quot;, &quot;give_length&quot;: &quot;true&quot;},</span>
<span class="gi">+        {&quot;use_206&quot;: &quot;true&quot;, &quot;give_range&quot;: &quot;true&quot;},</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_random_access(server, headers):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, headers=headers)</span>
<span class="gi">+    url = server + &quot;/index/realfile&quot;</span>
<span class="gi">+    with h.open(url, &quot;rb&quot;) as f:</span>
<span class="gi">+        if headers:</span>
<span class="gi">+            assert f.size == len(data)</span>
<span class="gi">+        assert f.read(5) == data[:5]</span>
<span class="gi">+</span>
<span class="gi">+        if headers:</span>
<span class="gi">+            f.seek(5, 1)</span>
<span class="gi">+            assert f.read(5) == data[10:15]</span>
<span class="gi">+        else:</span>
<span class="gi">+            with pytest.raises(ValueError):</span>
<span class="gi">+                f.seek(5, 1)</span>
<span class="gi">+    assert f.closed</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;headers&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        {&quot;ignore_range&quot;: &quot;true&quot;, &quot;head_ok&quot;: &quot;true&quot;, &quot;head_give_length&quot;: &quot;true&quot;},</span>
<span class="gi">+        {&quot;ignore_range&quot;: &quot;true&quot;, &quot;give_length&quot;: &quot;true&quot;},</span>
<span class="gi">+        {&quot;ignore_range&quot;: &quot;true&quot;, &quot;give_range&quot;: &quot;true&quot;},</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_no_range_support(server, headers):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, headers=headers)</span>
<span class="gi">+    url = server + &quot;/index/realfile&quot;</span>
<span class="gi">+    with h.open(url, &quot;rb&quot;) as f:</span>
<span class="gi">+        # Random access is not possible if the server doesn&#39;t respect Range</span>
<span class="gi">+        f.seek(5)</span>
<span class="gi">+        with pytest.raises(ValueError):</span>
<span class="gi">+            f.read(10)</span>
<span class="gi">+</span>
<span class="gi">+        # Reading from the beginning should still work</span>
<span class="gi">+        f.seek(0)</span>
<span class="gi">+        assert f.read(10) == data[:10]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_stream_seek(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+    url = server + &quot;/index/realfile&quot;</span>
<span class="gi">+    with h.open(url, &quot;rb&quot;) as f:</span>
<span class="gi">+        f.seek(0)  # is OK</span>
<span class="gi">+        data1 = f.read(5)</span>
<span class="gi">+        assert len(data1) == 5</span>
<span class="gi">+        f.seek(5)</span>
<span class="gi">+        f.seek(0, 1)</span>
<span class="gi">+        data2 = f.read()</span>
<span class="gi">+        assert data1 + data2 == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mapper_url(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+    mapper = h.get_mapper(server + &quot;/index/&quot;)</span>
<span class="gi">+    assert mapper.root.startswith(&quot;http:&quot;)</span>
<span class="gi">+    assert list(mapper)</span>
<span class="gi">+</span>
<span class="gi">+    mapper2 = fsspec.get_mapper(server + &quot;/index/&quot;)</span>
<span class="gi">+    assert mapper2.root.startswith(&quot;http:&quot;)</span>
<span class="gi">+    assert list(mapper) == list(mapper2)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_content_length_zero(server):</span>
<span class="gi">+    h = fsspec.filesystem(</span>
<span class="gi">+        &quot;http&quot;, headers={&quot;give_length&quot;: &quot;true&quot;, &quot;zero_length&quot;: &quot;true&quot;}</span>
<span class="gi">+    )</span>
<span class="gi">+    url = server + &quot;/index/realfile&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with h.open(url, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_content_encoding_gzip(server):</span>
<span class="gi">+    h = fsspec.filesystem(</span>
<span class="gi">+        &quot;http&quot;, headers={&quot;give_length&quot;: &quot;true&quot;, &quot;gzip_encoding&quot;: &quot;true&quot;}</span>
<span class="gi">+    )</span>
<span class="gi">+    url = server + &quot;/index/realfile&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with h.open(url, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert isinstance(f, HTTPStreamFile)</span>
<span class="gi">+        assert f.size is None</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_download(server, tmpdir):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, headers={&quot;give_length&quot;: &quot;true&quot;, &quot;head_ok&quot;: &quot;true &quot;})</span>
<span class="gi">+    url = server + &quot;/index/realfile&quot;</span>
<span class="gi">+    fn = os.path.join(tmpdir, &quot;afile&quot;)</span>
<span class="gi">+    h.get(url, fn)</span>
<span class="gi">+    assert open(fn, &quot;rb&quot;).read() == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_multi_download(server, tmpdir):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, headers={&quot;give_length&quot;: &quot;true&quot;, &quot;head_ok&quot;: &quot;true &quot;})</span>
<span class="gi">+    urla = server + &quot;/index/realfile&quot;</span>
<span class="gi">+    urlb = server + &quot;/index/otherfile&quot;</span>
<span class="gi">+    fna = os.path.join(tmpdir, &quot;afile&quot;)</span>
<span class="gi">+    fnb = os.path.join(tmpdir, &quot;bfile&quot;)</span>
<span class="gi">+    h.get([urla, urlb], [fna, fnb])</span>
<span class="gi">+    assert open(fna, &quot;rb&quot;).read() == data</span>
<span class="gi">+    assert open(fnb, &quot;rb&quot;).read() == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_ls(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+    l = h.ls(server + &quot;/data/20020401/&quot;, detail=False)</span>
<span class="gi">+    nc = server + &quot;/data/20020401/GRACEDADM_CLSM0125US_7D.A20020401.030.nc4&quot;</span>
<span class="gi">+    assert nc in l</span>
<span class="gi">+    assert len(l) == 11</span>
<span class="gi">+    assert all(u[&quot;type&quot;] == &quot;file&quot; for u in h.ls(server + &quot;/data/20020401/&quot;))</span>
<span class="gi">+    assert h.glob(server + &quot;/data/20020401/*.nc4&quot;) == [nc]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mcat(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, headers={&quot;give_length&quot;: &quot;true&quot;, &quot;head_ok&quot;: &quot;true &quot;})</span>
<span class="gi">+    urla = server + &quot;/index/realfile&quot;</span>
<span class="gi">+    urlb = server + &quot;/index/otherfile&quot;</span>
<span class="gi">+    out = h.cat([urla, urlb])</span>
<span class="gi">+    assert out == {urla: data, urlb: data}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_cat_file_range(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, headers={&quot;give_length&quot;: &quot;true&quot;, &quot;head_ok&quot;: &quot;true &quot;})</span>
<span class="gi">+    urla = server + &quot;/index/realfile&quot;</span>
<span class="gi">+    assert h.cat(urla, start=1, end=10) == data[1:10]</span>
<span class="gi">+    assert h.cat(urla, start=1) == data[1:]</span>
<span class="gi">+</span>
<span class="gi">+    assert h.cat(urla, start=-10) == data[-10:]</span>
<span class="gi">+    assert h.cat(urla, start=-10, end=-2) == data[-10:-2]</span>
<span class="gi">+</span>
<span class="gi">+    assert h.cat(urla, end=-10) == data[:-10]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_cat_file_range_numpy(server):</span>
<span class="gi">+    np = pytest.importorskip(&quot;numpy&quot;)</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, headers={&quot;give_length&quot;: &quot;true&quot;, &quot;head_ok&quot;: &quot;true &quot;})</span>
<span class="gi">+    urla = server + &quot;/index/realfile&quot;</span>
<span class="gi">+    assert h.cat(urla, start=np.int8(1), end=np.int8(10)) == data[1:10]</span>
<span class="gi">+    out = h.cat_ranges([urla, urla], starts=np.array([1, 5]), ends=np.array([10, 15]))</span>
<span class="gi">+    assert out == [data[1:10], data[5:15]]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mcat_cache(server):</span>
<span class="gi">+    urla = server + &quot;/index/realfile&quot;</span>
<span class="gi">+    urlb = server + &quot;/index/otherfile&quot;</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;simplecache&quot;, target_protocol=&quot;http&quot;)</span>
<span class="gi">+    assert fs.cat([urla, urlb]) == {urla: data, urlb: data}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mcat_expand(server):</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, headers={&quot;give_length&quot;: &quot;true&quot;, &quot;head_ok&quot;: &quot;true &quot;})</span>
<span class="gi">+    out = h.cat(server + &quot;/index/*&quot;)</span>
<span class="gi">+    assert out == {server + &quot;/index/realfile&quot;: data}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_info(server):</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;http&quot;, headers={&quot;give_etag&quot;: &quot;true&quot;, &quot;head_ok&quot;: &quot;true&quot;})</span>
<span class="gi">+    info = fs.info(server + &quot;/index/realfile&quot;)</span>
<span class="gi">+    assert info[&quot;ETag&quot;] == &quot;xxx&quot;</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;http&quot;, headers={&quot;give_mimetype&quot;: &quot;true&quot;})</span>
<span class="gi">+    info = fs.info(server + &quot;/index/realfile&quot;)</span>
<span class="gi">+    assert info[&quot;mimetype&quot;] == &quot;text/html&quot;</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;http&quot;, headers={&quot;redirect&quot;: &quot;true&quot;})</span>
<span class="gi">+    info = fs.info(server + &quot;/redirectme&quot;)</span>
<span class="gi">+    assert info[&quot;url&quot;] == server + &quot;/index/realfile&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;method&quot;, [&quot;POST&quot;, &quot;PUT&quot;])</span>
<span class="gi">+def test_put_file(server, tmp_path, method, reset_files):</span>
<span class="gi">+    src_file = tmp_path / &quot;file_1&quot;</span>
<span class="gi">+    src_file.write_bytes(data)</span>
<span class="gi">+</span>
<span class="gi">+    dwl_file = tmp_path / &quot;down_1&quot;</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;http&quot;, headers={&quot;head_ok&quot;: &quot;true&quot;, &quot;give_length&quot;: &quot;true&quot;})</span>
<span class="gi">+    with pytest.raises(FileNotFoundError):</span>
<span class="gi">+        fs.info(server + &quot;/hey&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs.put_file(src_file, server + &quot;/hey&quot;, method=method)</span>
<span class="gi">+    assert fs.info(server + &quot;/hey&quot;)[&quot;size&quot;] == len(data)</span>
<span class="gi">+</span>
<span class="gi">+    fs.get_file(server + &quot;/hey&quot;, dwl_file)</span>
<span class="gi">+    assert dwl_file.read_bytes() == data</span>
<span class="gi">+</span>
<span class="gi">+    src_file.write_bytes(b&quot;xxx&quot;)</span>
<span class="gi">+    with open(src_file, &quot;rb&quot;) as stream:</span>
<span class="gi">+        fs.put_file(stream, server + &quot;/hey_2&quot;, method=method)</span>
<span class="gi">+    assert fs.cat(server + &quot;/hey_2&quot;) == b&quot;xxx&quot;</span>
<span class="gi">+</span>
<span class="gi">+    fs.put_file(io.BytesIO(b&quot;yyy&quot;), server + &quot;/hey_3&quot;, method=method)</span>
<span class="gi">+    assert fs.cat(server + &quot;/hey_3&quot;) == b&quot;yyy&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+async def get_aiohttp():</span>
<span class="gi">+    from aiohttp import ClientSession</span>
<span class="gi">+</span>
<span class="gi">+    return ClientSession()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+async def get_proxy():</span>
<span class="gi">+    class ProxyClient:</span>
<span class="gi">+        pass</span>
<span class="gi">+</span>
<span class="gi">+    return ProxyClient()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.xfail(</span>
<span class="gi">+    condition=sys.flags.optimize &gt; 1, reason=&quot;no docstrings when optimised&quot;</span>
<span class="gi">+)</span>
<span class="gi">+def test_docstring():</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+    # most methods have empty docstrings and draw from base class, but this one</span>
<span class="gi">+    # is generated</span>
<span class="gi">+    assert h.pipe.__doc__</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_async_other_thread(server):</span>
<span class="gi">+    import threading</span>
<span class="gi">+</span>
<span class="gi">+    loop = asyncio.get_event_loop()</span>
<span class="gi">+    th = threading.Thread(target=loop.run_forever)</span>
<span class="gi">+</span>
<span class="gi">+    th.daemon = True</span>
<span class="gi">+    th.start()</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;http&quot;, asynchronous=True, loop=loop)</span>
<span class="gi">+    asyncio.run_coroutine_threadsafe(fs.set_session(), loop=loop).result()</span>
<span class="gi">+    url = server + &quot;/index/realfile&quot;</span>
<span class="gi">+    cor = fs._cat([url])</span>
<span class="gi">+    fut = asyncio.run_coroutine_threadsafe(cor, loop=loop)</span>
<span class="gi">+    assert fut.result() == {url: data}</span>
<span class="gi">+    loop.call_soon_threadsafe(loop.stop)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_async_this_thread(server):</span>
<span class="gi">+    async def _():</span>
<span class="gi">+        fs = fsspec.filesystem(&quot;http&quot;, asynchronous=True)</span>
<span class="gi">+</span>
<span class="gi">+        session = await fs.set_session()  # creates client</span>
<span class="gi">+</span>
<span class="gi">+        url = server + &quot;/index/realfile&quot;</span>
<span class="gi">+        with pytest.raises((NotImplementedError, RuntimeError)):</span>
<span class="gi">+            fs.cat([url])</span>
<span class="gi">+        out = await fs._cat([url])</span>
<span class="gi">+        del fs</span>
<span class="gi">+        assert out == {url: data}</span>
<span class="gi">+        await session.close()</span>
<span class="gi">+</span>
<span class="gi">+    asyncio.run(_())</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _inner_pass(fs, q, fn):</span>
<span class="gi">+    # pass the FS instance, but don&#39;t use it; in new process, the instance</span>
<span class="gi">+    # cache should be skipped to make a new instance</span>
<span class="gi">+    import traceback</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        fs = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+        q.put(fs.cat(fn))</span>
<span class="gi">+    except Exception:</span>
<span class="gi">+        q.put(traceback.format_exc())</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;method&quot;, [&quot;spawn&quot;, &quot;forkserver&quot;])</span>
<span class="gi">+def test_processes(server, method):</span>
<span class="gi">+    import multiprocessing as mp</span>
<span class="gi">+</span>
<span class="gi">+    if win and method != &quot;spawn&quot;:</span>
<span class="gi">+        pytest.skip(&quot;Windows can only spawn&quot;)</span>
<span class="gi">+    ctx = mp.get_context(method)</span>
<span class="gi">+    fn = server + &quot;/index/realfile&quot;</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    q = ctx.Queue()</span>
<span class="gi">+    p = ctx.Process(target=_inner_pass, args=(fs, q, fn))</span>
<span class="gi">+    p.start()</span>
<span class="gi">+    out = q.get()</span>
<span class="gi">+    assert out == fs.cat(fn)</span>
<span class="gi">+    p.join()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;get_client&quot;, [get_aiohttp, get_proxy])</span>
<span class="gi">+def test_close(get_client):</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;http&quot;, skip_instance_cache=True)</span>
<span class="gi">+    fs.close_session(None, asyncio.run(get_client()))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_file(server):</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;http&quot;, asynchronous=True, skip_instance_cache=True)</span>
<span class="gi">+    fn = server + &quot;/index/realfile&quot;</span>
<span class="gi">+    of = await fs.open_async(fn)</span>
<span class="gi">+    async with of as f:</span>
<span class="gi">+        out1 = await f.read(10)</span>
<span class="gi">+        assert data.startswith(out1)</span>
<span class="gi">+        out2 = await f.read()</span>
<span class="gi">+        assert data == out1 + out2</span>
<span class="gi">+    await fs._session.close()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_encoded(server):</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;http&quot;, encoded=True)</span>
<span class="gi">+    out = fs.cat(server + &quot;/Hello%3A%20G%C3%BCnter&quot;, headers={&quot;give_path&quot;: &quot;true&quot;})</span>
<span class="gi">+    assert json.loads(out)[&quot;path&quot;] == &quot;/Hello%3A%20G%C3%BCnter&quot;</span>
<span class="gi">+    with pytest.raises(aiohttp.client_exceptions.ClientError):</span>
<span class="gi">+        fs.cat(server + &quot;/Hello: Günter&quot;, headers={&quot;give_path&quot;: &quot;true&quot;})</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;http&quot;, encoded=False)</span>
<span class="gi">+    out = fs.cat(server + &quot;/Hello: Günter&quot;, headers={&quot;give_path&quot;: &quot;true&quot;})</span>
<span class="gi">+    assert json.loads(out)[&quot;path&quot;] == &quot;/Hello:%20G%C3%BCnter&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_with_cache(server):</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;http&quot;, headers={&quot;head_ok&quot;: &quot;true&quot;, &quot;give_length&quot;: &quot;true&quot;})</span>
<span class="gi">+    fn = server + &quot;/index/realfile&quot;</span>
<span class="gi">+    fs1 = fsspec.filesystem(&quot;blockcache&quot;, fs=fs)</span>
<span class="gi">+    with fs1.open(fn, &quot;rb&quot;) as f:</span>
<span class="gi">+        out = f.read()</span>
<span class="gi">+    assert out == fs1.cat(fn)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_expand_path(server):</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;http&quot;, asynchronous=True, skip_instance_cache=True)</span>
<span class="gi">+</span>
<span class="gi">+    # maxdepth=1</span>
<span class="gi">+    assert await fs._expand_path(server + &quot;/index&quot;, recursive=True, maxdepth=1) == [</span>
<span class="gi">+        server + &quot;/index&quot;,</span>
<span class="gi">+        server + &quot;/index/realfile&quot;,</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+    # maxdepth=0</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        await fs._expand_path(server + &quot;/index&quot;, maxdepth=0)</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        await fs._expand_path(server + &quot;/index&quot;, recursive=True, maxdepth=0)</span>
<span class="gi">+</span>
<span class="gi">+    await fs._session.close()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.asyncio</span>
<span class="gi">+async def test_async_walk(server):</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;http&quot;, asynchronous=True, skip_instance_cache=True)</span>
<span class="gi">+</span>
<span class="gi">+    # No maxdepth</span>
<span class="gi">+    res = [a async for a in fs._walk(server + &quot;/index&quot;)]</span>
<span class="gi">+    assert res == [(server + &quot;/index&quot;, [], [&quot;realfile&quot;])]</span>
<span class="gi">+</span>
<span class="gi">+    # maxdepth=0</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        async for a in fs._walk(server + &quot;/index&quot;, maxdepth=0):</span>
<span class="gi">+            pass</span>
<span class="gi">+</span>
<span class="gi">+    await fs._session.close()</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_jupyter.py b/fsspec/implementations/tests/test_jupyter.py</span>
<span class="gh">index 9e56841..9b2eaa9 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_jupyter.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_jupyter.py</span>
<span class="gu">@@ -2,7 +2,56 @@ import os</span>
<span class="w"> </span>import shlex
<span class="w"> </span>import subprocess
<span class="w"> </span>import time
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="gd">-pytest.importorskip(&#39;notebook&#39;)</span>
<span class="gd">-requests = pytest.importorskip(&#39;requests&#39;)</span>
<span class="gi">+</span>
<span class="gi">+pytest.importorskip(&quot;notebook&quot;)</span>
<span class="gi">+requests = pytest.importorskip(&quot;requests&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture()</span>
<span class="gi">+def jupyter(tmpdir):</span>
<span class="gi">+    tmpdir = str(tmpdir)</span>
<span class="gi">+    os.environ[&quot;JUPYTER_TOKEN&quot;] = &quot;blah&quot;</span>
<span class="gi">+    try:</span>
<span class="gi">+        cmd = f&#39;jupyter notebook --notebook-dir=&quot;{tmpdir}&quot; --no-browser --port=5566&#39;</span>
<span class="gi">+        P = subprocess.Popen(shlex.split(cmd))</span>
<span class="gi">+    except FileNotFoundError:</span>
<span class="gi">+        pytest.skip(&quot;notebook not installed correctly&quot;)</span>
<span class="gi">+    try:</span>
<span class="gi">+        timeout = 15</span>
<span class="gi">+        while True:</span>
<span class="gi">+            try:</span>
<span class="gi">+                r = requests.get(&quot;http://localhost:5566/?token=blah&quot;)</span>
<span class="gi">+                r.raise_for_status()</span>
<span class="gi">+                break</span>
<span class="gi">+            except (requests.exceptions.BaseHTTPError, OSError):</span>
<span class="gi">+                time.sleep(0.1)</span>
<span class="gi">+                timeout -= 0.1</span>
<span class="gi">+                if timeout &lt; 0:</span>
<span class="gi">+                    pytest.xfail(&quot;Timed out for jupyter&quot;)</span>
<span class="gi">+        yield &quot;http://localhost:5566/?token=blah&quot;, tmpdir</span>
<span class="gi">+    finally:</span>
<span class="gi">+        P.terminate()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_simple(jupyter):</span>
<span class="gi">+    url, d = jupyter</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;jupyter&quot;, url=url)</span>
<span class="gi">+    assert fs.ls(&quot;&quot;) == []</span>
<span class="gi">+</span>
<span class="gi">+    fs.pipe(&quot;afile&quot;, b&quot;data&quot;)</span>
<span class="gi">+    assert fs.cat(&quot;afile&quot;) == b&quot;data&quot;</span>
<span class="gi">+    assert &quot;afile&quot; in os.listdir(d)</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(&quot;bfile&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;more&quot;)</span>
<span class="gi">+    with fs.open(&quot;bfile&quot;, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == b&quot;more&quot;</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.info(&quot;bfile&quot;)[&quot;size&quot;] == 4</span>
<span class="gi">+    fs.rm(&quot;afile&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert &quot;afile&quot; not in os.listdir(d)</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_libarchive.py b/fsspec/implementations/tests/test_libarchive.py</span>
<span class="gh">index 5aabc42..a5bef34 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_libarchive.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_libarchive.py</span>
<span class="gu">@@ -1,2 +1,33 @@</span>
<span class="gi">+# this test case checks that the libarchive can be used from a seekable source (any fs</span>
<span class="gi">+# with a block cache active)</span>
<span class="w"> </span>import fsspec
<span class="w"> </span>from fsspec.implementations.tests.test_archive import archive_data, temparchive
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_cache(ftp_writable):</span>
<span class="gi">+    host, port, username, password = &quot;localhost&quot;, 2121, &quot;user&quot;, &quot;pass&quot;</span>
<span class="gi">+</span>
<span class="gi">+    with temparchive(archive_data) as archive_file:</span>
<span class="gi">+        with fsspec.open(</span>
<span class="gi">+            &quot;ftp:///archive.7z&quot;,</span>
<span class="gi">+            &quot;wb&quot;,</span>
<span class="gi">+            host=host,</span>
<span class="gi">+            port=port,</span>
<span class="gi">+            username=username,</span>
<span class="gi">+            password=password,</span>
<span class="gi">+        ) as f:</span>
<span class="gi">+            f.write(open(archive_file, &quot;rb&quot;).read())</span>
<span class="gi">+        of = fsspec.open(</span>
<span class="gi">+            &quot;libarchive://deeply/nested/path::ftp:///archive.7z&quot;,</span>
<span class="gi">+            ftp={</span>
<span class="gi">+                &quot;host&quot;: host,</span>
<span class="gi">+                &quot;port&quot;: port,</span>
<span class="gi">+                &quot;username&quot;: username,</span>
<span class="gi">+                &quot;password&quot;: password,</span>
<span class="gi">+            },</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        with of as f:</span>
<span class="gi">+            readdata = f.read()</span>
<span class="gi">+</span>
<span class="gi">+        assert readdata == archive_data[&quot;deeply/nested/path&quot;]</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_local.py b/fsspec/implementations/tests/test_local.py</span>
<span class="gh">index ccabb9c..ef39279 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_local.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_local.py</span>
<span class="gu">@@ -9,42 +9,1277 @@ import tempfile</span>
<span class="w"> </span>from contextlib import contextmanager
<span class="w"> </span>from pathlib import Path
<span class="w"> </span>from unittest.mock import patch
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="w"> </span>from fsspec import compression
<span class="w"> </span>from fsspec.core import OpenFile, get_fs_token_paths, open_files
<span class="w"> </span>from fsspec.implementations.local import LocalFileSystem, make_path_posix
<span class="w"> </span>from fsspec.tests.test_utils import WIN
<span class="gd">-files = {&#39;.test.accounts.1.json&#39;:</span>
<span class="gd">-    b&#39;{&quot;amount&quot;: 100, &quot;name&quot;: &quot;Alice&quot;}\n{&quot;amount&quot;: 200, &quot;name&quot;: &quot;Bob&quot;}\n{&quot;amount&quot;: 300, &quot;name&quot;: &quot;Charlie&quot;}\n{&quot;amount&quot;: 400, &quot;name&quot;: &quot;Dennis&quot;}\n&#39;</span>
<span class="gd">-    , &#39;.test.accounts.2.json&#39;:</span>
<span class="gd">-    b&#39;{&quot;amount&quot;: 500, &quot;name&quot;: &quot;Alice&quot;}\n{&quot;amount&quot;: 600, &quot;name&quot;: &quot;Bob&quot;}\n{&quot;amount&quot;: 700, &quot;name&quot;: &quot;Charlie&quot;}\n{&quot;amount&quot;: 800, &quot;name&quot;: &quot;Dennis&quot;}\n&#39;</span>
<span class="gd">-    }</span>
<span class="gd">-csv_files = {&#39;.test.fakedata.1.csv&#39;: b&#39;a,b\n1,2\n&#39;, &#39;.test.fakedata.2.csv&#39;:</span>
<span class="gd">-    b&#39;a,b\n3,4\n&#39;}</span>
<span class="gi">+</span>
<span class="gi">+files = {</span>
<span class="gi">+    &quot;.test.accounts.1.json&quot;: (</span>
<span class="gi">+        b&#39;{&quot;amount&quot;: 100, &quot;name&quot;: &quot;Alice&quot;}\n&#39;</span>
<span class="gi">+        b&#39;{&quot;amount&quot;: 200, &quot;name&quot;: &quot;Bob&quot;}\n&#39;</span>
<span class="gi">+        b&#39;{&quot;amount&quot;: 300, &quot;name&quot;: &quot;Charlie&quot;}\n&#39;</span>
<span class="gi">+        b&#39;{&quot;amount&quot;: 400, &quot;name&quot;: &quot;Dennis&quot;}\n&#39;</span>
<span class="gi">+    ),</span>
<span class="gi">+    &quot;.test.accounts.2.json&quot;: (</span>
<span class="gi">+        b&#39;{&quot;amount&quot;: 500, &quot;name&quot;: &quot;Alice&quot;}\n&#39;</span>
<span class="gi">+        b&#39;{&quot;amount&quot;: 600, &quot;name&quot;: &quot;Bob&quot;}\n&#39;</span>
<span class="gi">+        b&#39;{&quot;amount&quot;: 700, &quot;name&quot;: &quot;Charlie&quot;}\n&#39;</span>
<span class="gi">+        b&#39;{&quot;amount&quot;: 800, &quot;name&quot;: &quot;Dennis&quot;}\n&#39;</span>
<span class="gi">+    ),</span>
<span class="gi">+}</span>
<span class="gi">+</span>
<span class="gi">+csv_files = {</span>
<span class="gi">+    &quot;.test.fakedata.1.csv&quot;: (b&quot;a,b\n1,2\n&quot;),</span>
<span class="gi">+    &quot;.test.fakedata.2.csv&quot;: (b&quot;a,b\n3,4\n&quot;),</span>
<span class="gi">+}</span>
<span class="w"> </span>odir = os.getcwd()


<span class="gi">+@pytest.fixture()</span>
<span class="gi">+def cwd():</span>
<span class="gi">+    pth = os.getcwd().replace(&quot;\\&quot;, &quot;/&quot;)</span>
<span class="gi">+    assert not pth.endswith(&quot;/&quot;)</span>
<span class="gi">+    yield pth</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture()</span>
<span class="gi">+def current_drive(cwd):</span>
<span class="gi">+    drive = os.path.splitdrive(cwd)[0]</span>
<span class="gi">+    assert not drive or (len(drive) == 2 and drive.endswith(&quot;:&quot;))</span>
<span class="gi">+    yield drive</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture()</span>
<span class="gi">+def user_home():</span>
<span class="gi">+    pth = os.path.expanduser(&quot;~&quot;).replace(&quot;\\&quot;, &quot;/&quot;)</span>
<span class="gi">+    assert not pth.endswith(&quot;/&quot;)</span>
<span class="gi">+    yield pth</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def winonly(*args):</span>
<span class="gi">+    return pytest.param(*args, marks=pytest.mark.skipif(not WIN, reason=&quot;Windows only&quot;))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def posixonly(*args):</span>
<span class="gi">+    return pytest.param(*args, marks=pytest.mark.skipif(WIN, reason=&quot;Posix only&quot;))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>@contextmanager
<span class="gd">-def filetexts(d, open=open, mode=&#39;t&#39;):</span>
<span class="gi">+def filetexts(d, open=open, mode=&quot;t&quot;):</span>
<span class="w"> </span>    &quot;&quot;&quot;Dumps a number of textfiles to disk

<span class="w"> </span>    d - dict
<span class="gd">-        a mapping from filename to text like {&#39;a.csv&#39;: &#39;1,1</span>
<span class="gd">-2,2&#39;}</span>
<span class="gi">+        a mapping from filename to text like {&#39;a.csv&#39;: &#39;1,1\n2,2&#39;}</span>

<span class="w"> </span>    Since this is meant for use in tests, this context manager will
<span class="w"> </span>    automatically switch to a temporary current directory, to avoid
<span class="w"> </span>    race conditions when running tests in parallel.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    dirname = tempfile.mkdtemp()</span>
<span class="gi">+    try:</span>
<span class="gi">+        os.chdir(dirname)</span>
<span class="gi">+        for filename, text in d.items():</span>
<span class="gi">+            if dirname := os.path.dirname(filename):</span>
<span class="gi">+                os.makedirs(dirname, exist_ok=True)</span>
<span class="gi">+            f = open(filename, f&quot;w{mode}&quot;)</span>
<span class="gi">+            try:</span>
<span class="gi">+                f.write(text)</span>
<span class="gi">+            finally:</span>
<span class="gi">+                try:</span>
<span class="gi">+                    f.close()</span>
<span class="gi">+                except AttributeError:</span>
<span class="gi">+                    pass</span>
<span class="gi">+</span>
<span class="gi">+        yield list(d)</span>
<span class="gi">+</span>
<span class="gi">+        for filename in d:</span>
<span class="gi">+            if os.path.exists(filename):</span>
<span class="gi">+                try:</span>
<span class="gi">+                    os.remove(filename)</span>
<span class="gi">+                except OSError:</span>
<span class="gi">+                    pass</span>
<span class="gi">+    finally:</span>
<span class="gi">+        os.chdir(odir)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_urlpath_inference_strips_protocol(tmpdir):</span>
<span class="gi">+    tmpdir = make_path_posix(str(tmpdir))</span>
<span class="gi">+    paths = [&quot;/&quot;.join([tmpdir, f&quot;test.{i:02d}.csv&quot;]) for i in range(20)]</span>
<span class="gi">+</span>
<span class="gi">+    for path in paths:</span>
<span class="gi">+        with open(path, &quot;wb&quot;) as f:</span>
<span class="gi">+            f.write(b&quot;1,2,3\n&quot; * 10)</span>
<span class="gi">+</span>
<span class="gi">+    # globstring</span>
<span class="gi">+    protocol = &quot;file:///&quot; if sys.platform == &quot;win32&quot; else &quot;file://&quot;</span>
<span class="gi">+    urlpath = protocol + os.path.join(tmpdir, &quot;test.*.csv&quot;)</span>
<span class="gi">+    _, _, paths2 = get_fs_token_paths(urlpath)</span>
<span class="gi">+    assert paths2 == paths</span>
<span class="gi">+</span>
<span class="gi">+    # list of paths</span>
<span class="gi">+    _, _, paths2 = get_fs_token_paths([protocol + p for p in paths])</span>
<span class="gi">+    assert paths2 == paths</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_urlpath_inference_errors():</span>
<span class="gi">+    # Empty list</span>
<span class="gi">+    with pytest.raises(ValueError) as err:</span>
<span class="gi">+        get_fs_token_paths([])</span>
<span class="gi">+    assert &quot;empty&quot; in str(err.value)</span>
<span class="gi">+</span>
<span class="gi">+    pytest.importorskip(&quot;s3fs&quot;)</span>
<span class="gi">+    # Protocols differ</span>
<span class="gi">+    with pytest.raises(ValueError) as err:</span>
<span class="gi">+        get_fs_token_paths([&quot;s3://test/path.csv&quot;, &quot;/other/path.csv&quot;])</span>
<span class="gi">+    assert &quot;Protocol&quot; in str(err.value)</span>


<span class="w"> </span>def test_urlpath_expand_read():
<span class="w"> </span>    &quot;&quot;&quot;Make sure * is expanded in file paths when reading.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # when reading, globs should be expanded to read files by mask</span>
<span class="gi">+    with filetexts(csv_files, mode=&quot;b&quot;):</span>
<span class="gi">+        _, _, paths = get_fs_token_paths(&quot;./.*.csv&quot;)</span>
<span class="gi">+        assert len(paths) == 2</span>
<span class="gi">+        _, _, paths = get_fs_token_paths([&quot;./.*.csv&quot;])</span>
<span class="gi">+        assert len(paths) == 2</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_cats():</span>
<span class="gi">+    with filetexts(csv_files, mode=&quot;b&quot;):</span>
<span class="gi">+        fs = fsspec.filesystem(&quot;file&quot;)</span>
<span class="gi">+        assert fs.cat(&quot;.test.fakedata.1.csv&quot;) == b&quot;a,b\n1,2\n&quot;</span>
<span class="gi">+        out = set(fs.cat([&quot;.test.fakedata.1.csv&quot;, &quot;.test.fakedata.2.csv&quot;]).values())</span>
<span class="gi">+        assert out == {b&quot;a,b\n1,2\n&quot;, b&quot;a,b\n3,4\n&quot;}</span>
<span class="gi">+        assert fs.cat(&quot;.test.fakedata.1.csv&quot;, None, None) == b&quot;a,b\n1,2\n&quot;</span>
<span class="gi">+        assert fs.cat(&quot;.test.fakedata.1.csv&quot;, start=1, end=6) == b&quot;a,b\n1,2\n&quot;[1:6]</span>
<span class="gi">+        assert fs.cat(&quot;.test.fakedata.1.csv&quot;, start=-1) == b&quot;a,b\n1,2\n&quot;[-1:]</span>
<span class="gi">+        assert fs.cat(&quot;.test.fakedata.1.csv&quot;, start=1, end=-2) == b&quot;a,b\n1,2\n&quot;[1:-2]</span>
<span class="gi">+        out = set(</span>
<span class="gi">+            fs.cat(</span>
<span class="gi">+                [&quot;.test.fakedata.1.csv&quot;, &quot;.test.fakedata.2.csv&quot;], start=1, end=-1</span>
<span class="gi">+            ).values()</span>
<span class="gi">+        )</span>
<span class="gi">+        assert out == {b&quot;a,b\n1,2\n&quot;[1:-1], b&quot;a,b\n3,4\n&quot;[1:-1]}</span>


<span class="w"> </span>def test_urlpath_expand_write():
<span class="w"> </span>    &quot;&quot;&quot;Make sure * is expanded in file paths when writing.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    _, _, paths = get_fs_token_paths(&quot;prefix-*.csv&quot;, mode=&quot;wb&quot;, num=2)</span>
<span class="gi">+    assert all(</span>
<span class="gi">+        p.endswith(pa) for p, pa in zip(paths, [&quot;/prefix-0.csv&quot;, &quot;/prefix-1.csv&quot;])</span>
<span class="gi">+    )</span>
<span class="gi">+    _, _, paths = get_fs_token_paths([&quot;prefix-*.csv&quot;], mode=&quot;wb&quot;, num=2)</span>
<span class="gi">+    assert all(</span>
<span class="gi">+        p.endswith(pa) for p, pa in zip(paths, [&quot;/prefix-0.csv&quot;, &quot;/prefix-1.csv&quot;])</span>
<span class="gi">+    )</span>
<span class="gi">+    # we can read with multiple masks, but not write</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        _, _, paths = get_fs_token_paths(</span>
<span class="gi">+            [&quot;prefix1-*.csv&quot;, &quot;prefix2-*.csv&quot;], mode=&quot;wb&quot;, num=2</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_open_files():</span>
<span class="gi">+    with filetexts(files, mode=&quot;b&quot;):</span>
<span class="gi">+        myfiles = open_files(&quot;./.test.accounts.*&quot;)</span>
<span class="gi">+        assert len(myfiles) == len(files)</span>
<span class="gi">+        for lazy_file, data_file in zip(myfiles, sorted(files)):</span>
<span class="gi">+            with lazy_file as f:</span>
<span class="gi">+                x = f.read()</span>
<span class="gi">+                assert x == files[data_file]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;encoding&quot;, [&quot;utf-8&quot;, &quot;ascii&quot;])</span>
<span class="gi">+def test_open_files_text_mode(encoding):</span>
<span class="gi">+    with filetexts(files, mode=&quot;b&quot;):</span>
<span class="gi">+        myfiles = open_files(&quot;./.test.accounts.*&quot;, mode=&quot;rt&quot;, encoding=encoding)</span>
<span class="gi">+        assert len(myfiles) == len(files)</span>
<span class="gi">+        data = []</span>
<span class="gi">+        for file in myfiles:</span>
<span class="gi">+            with file as f:</span>
<span class="gi">+                data.append(f.read())</span>
<span class="gi">+        assert list(data) == [files[k].decode(encoding) for k in sorted(files)]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;mode&quot;, [&quot;rt&quot;, &quot;rb&quot;])</span>
<span class="gi">+@pytest.mark.parametrize(&quot;fmt&quot;, list(compression.compr))</span>
<span class="gi">+def test_compressions(fmt, mode, tmpdir):</span>
<span class="gi">+    tmpdir = str(tmpdir)</span>
<span class="gi">+    fn = os.path.join(tmpdir, &quot;.tmp.getsize&quot;)</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    f = OpenFile(fs, fn, compression=fmt, mode=&quot;wb&quot;)</span>
<span class="gi">+    data = b&quot;Long line of readily compressible text&quot;</span>
<span class="gi">+    with f as fo:</span>
<span class="gi">+        fo.write(data)</span>
<span class="gi">+    if fmt is None:</span>
<span class="gi">+        assert fs.size(fn) == len(data)</span>
<span class="gi">+    else:</span>
<span class="gi">+        assert fs.size(fn) != len(data)</span>
<span class="gi">+</span>
<span class="gi">+    f = OpenFile(fs, fn, compression=fmt, mode=mode)</span>
<span class="gi">+    with f as fo:</span>
<span class="gi">+        if mode == &quot;rb&quot;:</span>
<span class="gi">+            assert fo.read() == data</span>
<span class="gi">+        else:</span>
<span class="gi">+            assert fo.read() == data.decode()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_bad_compression():</span>
<span class="gi">+    with filetexts(files, mode=&quot;b&quot;):</span>
<span class="gi">+        for func in [open_files]:</span>
<span class="gi">+            with pytest.raises(ValueError):</span>
<span class="gi">+                func(&quot;./.test.accounts.*&quot;, compression=&quot;not-found&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_not_found():</span>
<span class="gi">+    fn = &quot;not-a-file&quot;</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    with pytest.raises((FileNotFoundError, OSError)):</span>
<span class="gi">+        with OpenFile(fs, fn, mode=&quot;rb&quot;):</span>
<span class="gi">+            pass</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_isfile():</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    with filetexts(files, mode=&quot;b&quot;):</span>
<span class="gi">+        for f in files.keys():</span>
<span class="gi">+            assert fs.isfile(f)</span>
<span class="gi">+            assert fs.isfile(f&quot;file://{f}&quot;)</span>
<span class="gi">+        assert not fs.isfile(&quot;not-a-file&quot;)</span>
<span class="gi">+        assert not fs.isfile(&quot;file://not-a-file&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_isdir():</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    with filetexts(files, mode=&quot;b&quot;):</span>
<span class="gi">+        for f in files.keys():</span>
<span class="gi">+            assert fs.isdir(os.path.dirname(os.path.abspath(f)))</span>
<span class="gi">+            assert not fs.isdir(f)</span>
<span class="gi">+        assert not fs.isdir(&quot;not-a-dir&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;compression_opener&quot;, [(None, open), (&quot;gzip&quot;, gzip.open)])</span>
<span class="gi">+def test_open_files_write(tmpdir, compression_opener):</span>
<span class="gi">+    tmpdir = str(tmpdir)</span>
<span class="gi">+    compression, opener = compression_opener</span>
<span class="gi">+    fn = str(tmpdir) + &quot;/*.part&quot;</span>
<span class="gi">+    files = open_files(fn, num=2, mode=&quot;wb&quot;, compression=compression)</span>
<span class="gi">+    assert len(files) == 2</span>
<span class="gi">+    assert {f.mode for f in files} == {&quot;wb&quot;}</span>
<span class="gi">+    for fil in files:</span>
<span class="gi">+        with fil as f:</span>
<span class="gi">+            f.write(b&quot;000&quot;)</span>
<span class="gi">+    files = sorted(os.listdir(tmpdir))</span>
<span class="gi">+    assert files == [&quot;0.part&quot;, &quot;1.part&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    with opener(os.path.join(tmpdir, files[0]), &quot;rb&quot;) as f:</span>
<span class="gi">+        d = f.read()</span>
<span class="gi">+    assert d == b&quot;000&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_pickability_of_lazy_files(tmpdir):</span>
<span class="gi">+    tmpdir = str(tmpdir)</span>
<span class="gi">+    cloudpickle = pytest.importorskip(&quot;cloudpickle&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with filetexts(files, mode=&quot;b&quot;):</span>
<span class="gi">+        myfiles = open_files(&quot;./.test.accounts.*&quot;)</span>
<span class="gi">+        myfiles2 = cloudpickle.loads(cloudpickle.dumps(myfiles))</span>
<span class="gi">+</span>
<span class="gi">+        for f, f2 in zip(myfiles, myfiles2):</span>
<span class="gi">+            assert f.path == f2.path</span>
<span class="gi">+            assert isinstance(f.fs, type(f2.fs))</span>
<span class="gi">+            with f as f_open, f2 as f2_open:</span>
<span class="gi">+                assert f_open.read() == f2_open.read()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_abs_paths(tmpdir):</span>
<span class="gi">+    tmpdir = str(tmpdir)</span>
<span class="gi">+    here = os.getcwd()</span>
<span class="gi">+    os.chdir(tmpdir)</span>
<span class="gi">+    with open(&quot;tmp&quot;, &quot;w&quot;) as f:</span>
<span class="gi">+        f.write(&quot;hi&quot;)</span>
<span class="gi">+    out = LocalFileSystem().glob(&quot;./*&quot;)</span>
<span class="gi">+    assert len(out) == 1</span>
<span class="gi">+    assert &quot;/&quot; in out[0]</span>
<span class="gi">+    assert &quot;tmp&quot; in out[0]</span>
<span class="gi">+</span>
<span class="gi">+    # I don&#39;t know what this was testing - but should avoid local paths anyway</span>
<span class="gi">+    # fs = LocalFileSystem()</span>
<span class="gi">+    os.chdir(here)</span>
<span class="gi">+    # with fs.open(&#39;tmp&#39;, &#39;r&#39;) as f:</span>
<span class="gi">+    #     res = f.read()</span>
<span class="gi">+    # assert res == &#39;hi&#39;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;sep&quot;, [&quot;/&quot;, &quot;\\&quot;])</span>
<span class="gi">+@pytest.mark.parametrize(&quot;chars&quot;, [&quot;+&quot;, &quot;++&quot;, &quot;(&quot;, &quot;)&quot;, &quot;|&quot;, &quot;\\&quot;])</span>
<span class="gi">+def test_glob_weird_characters(tmpdir, sep, chars):</span>
<span class="gi">+    tmpdir = make_path_posix(str(tmpdir))</span>
<span class="gi">+</span>
<span class="gi">+    subdir = f&quot;{tmpdir}{sep}test{chars}x&quot;</span>
<span class="gi">+    try:</span>
<span class="gi">+        os.makedirs(subdir, exist_ok=True)</span>
<span class="gi">+    except OSError as e:</span>
<span class="gi">+        if WIN and &quot;label syntax&quot; in str(e):</span>
<span class="gi">+            pytest.xfail(&quot;Illegal windows directory name&quot;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise</span>
<span class="gi">+    with open(subdir + sep + &quot;tmp&quot;, &quot;w&quot;) as f:</span>
<span class="gi">+        f.write(&quot;hi&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    out = LocalFileSystem().glob(subdir + sep + &quot;*&quot;)</span>
<span class="gi">+    assert len(out) == 1</span>
<span class="gi">+    assert &quot;/&quot; in out[0]</span>
<span class="gi">+    assert &quot;tmp&quot; in out[0]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_globfind_dirs(tmpdir):</span>
<span class="gi">+    tmpdir = make_path_posix(str(tmpdir))</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;file&quot;)</span>
<span class="gi">+    fs.mkdir(tmpdir + &quot;/dir&quot;)</span>
<span class="gi">+    fs.touch(tmpdir + &quot;/dir/afile&quot;)</span>
<span class="gi">+    assert [tmpdir + &quot;/dir&quot;] == fs.glob(tmpdir + &quot;/*&quot;)</span>
<span class="gi">+    assert fs.glob(tmpdir + &quot;/*&quot;, detail=True)[tmpdir + &quot;/dir&quot;][&quot;type&quot;] == &quot;directory&quot;</span>
<span class="gi">+    assert (</span>
<span class="gi">+        fs.glob(tmpdir + &quot;/dir/*&quot;, detail=True)[tmpdir + &quot;/dir/afile&quot;][&quot;type&quot;] == &quot;file&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    assert [tmpdir + &quot;/dir/afile&quot;] == fs.find(tmpdir)</span>
<span class="gi">+    assert [tmpdir, tmpdir + &quot;/dir&quot;, tmpdir + &quot;/dir/afile&quot;] == fs.find(</span>
<span class="gi">+        tmpdir, withdirs=True</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_touch(tmpdir):</span>
<span class="gi">+    import time</span>
<span class="gi">+</span>
<span class="gi">+    fn = str(tmpdir + &quot;/in/file&quot;)</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;file&quot;, auto_mkdir=False)</span>
<span class="gi">+    with pytest.raises(OSError):</span>
<span class="gi">+        fs.touch(fn)</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;file&quot;, auto_mkdir=True)</span>
<span class="gi">+    fs.touch(fn)</span>
<span class="gi">+    info = fs.info(fn)</span>
<span class="gi">+    time.sleep(0.2)</span>
<span class="gi">+    fs.touch(fn)</span>
<span class="gi">+    info2 = fs.info(fn)</span>
<span class="gi">+    if not WIN:</span>
<span class="gi">+        assert info2[&quot;mtime&quot;] &gt; info[&quot;mtime&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_touch_truncate(tmpdir):</span>
<span class="gi">+    fn = str(tmpdir + &quot;/tfile&quot;)</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;file&quot;)</span>
<span class="gi">+    fs.touch(fn, truncate=True)</span>
<span class="gi">+    fs.pipe(fn, b&quot;a&quot;)</span>
<span class="gi">+    fs.touch(fn, truncate=True)</span>
<span class="gi">+    assert fs.cat(fn) == b&quot;&quot;</span>
<span class="gi">+    fs.pipe(fn, b&quot;a&quot;)</span>
<span class="gi">+    fs.touch(fn, truncate=False)</span>
<span class="gi">+    assert fs.cat(fn) == b&quot;a&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_directories(tmpdir):</span>
<span class="gi">+    tmpdir = make_path_posix(str(tmpdir))</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    fs.mkdir(tmpdir + &quot;/dir&quot;)</span>
<span class="gi">+    assert tmpdir + &quot;/dir&quot; in fs.ls(tmpdir)</span>
<span class="gi">+    assert fs.ls(tmpdir, True)[0][&quot;type&quot;] == &quot;directory&quot;</span>
<span class="gi">+    fs.rmdir(tmpdir + &quot;/dir&quot;)</span>
<span class="gi">+    assert not fs.ls(tmpdir)</span>
<span class="gi">+    assert fs.ls(fs.root_marker)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_ls_on_file(tmpdir):</span>
<span class="gi">+    tmpdir = make_path_posix(str(tmpdir))</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    resource = tmpdir + &quot;/a.json&quot;</span>
<span class="gi">+    fs.touch(resource)</span>
<span class="gi">+    assert fs.exists(resource)</span>
<span class="gi">+    assert fs.ls(tmpdir) == fs.ls(resource)</span>
<span class="gi">+    assert fs.ls(resource, detail=True)[0] == fs.info(resource)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;file_protocol&quot;, [&quot;&quot;, &quot;file://&quot;])</span>
<span class="gi">+def test_file_ops(tmpdir, file_protocol):</span>
<span class="gi">+    tmpdir = make_path_posix(str(tmpdir))</span>
<span class="gi">+    tmpdir_with_protocol = file_protocol + tmpdir</span>
<span class="gi">+    fs = LocalFileSystem(auto_mkdir=True)</span>
<span class="gi">+    with pytest.raises(FileNotFoundError):</span>
<span class="gi">+        fs.info(tmpdir_with_protocol + &quot;/nofile&quot;)</span>
<span class="gi">+    fs.touch(tmpdir_with_protocol + &quot;/afile&quot;)</span>
<span class="gi">+    i1 = fs.ukey(tmpdir_with_protocol + &quot;/afile&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert tmpdir + &quot;/afile&quot; in fs.ls(tmpdir_with_protocol)</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(tmpdir_with_protocol + &quot;/afile&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;data&quot;)</span>
<span class="gi">+    i2 = fs.ukey(tmpdir_with_protocol + &quot;/afile&quot;)</span>
<span class="gi">+    assert i1 != i2  # because file changed</span>
<span class="gi">+</span>
<span class="gi">+    fs.copy(tmpdir_with_protocol + &quot;/afile&quot;, tmpdir_with_protocol + &quot;/afile2&quot;)</span>
<span class="gi">+    assert tmpdir + &quot;/afile2&quot; in fs.ls(tmpdir_with_protocol)</span>
<span class="gi">+</span>
<span class="gi">+    fs.move(tmpdir_with_protocol + &quot;/afile&quot;, tmpdir_with_protocol + &quot;/afile3&quot;)</span>
<span class="gi">+    assert not fs.exists(tmpdir_with_protocol + &quot;/afile&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs.cp(</span>
<span class="gi">+        tmpdir_with_protocol + &quot;/afile3&quot;, tmpdir_with_protocol + &quot;/deeply/nested/file&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    assert fs.exists(tmpdir_with_protocol + &quot;/deeply/nested/file&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs.rm(tmpdir_with_protocol + &quot;/afile3&quot;, recursive=True)</span>
<span class="gi">+    assert not fs.exists(tmpdir_with_protocol + &quot;/afile3&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    files = [tmpdir_with_protocol + &quot;/afile4&quot;, tmpdir_with_protocol + &quot;/afile5&quot;]</span>
<span class="gi">+    [fs.touch(f) for f in files]</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(AttributeError):</span>
<span class="gi">+        fs.rm_file(files)</span>
<span class="gi">+    fs.rm(files)</span>
<span class="gi">+    assert all(not fs.exists(f) for f in files)</span>
<span class="gi">+</span>
<span class="gi">+    fs.touch(tmpdir_with_protocol + &quot;/afile6&quot;)</span>
<span class="gi">+    fs.rm_file(tmpdir_with_protocol + &quot;/afile6&quot;)</span>
<span class="gi">+    assert not fs.exists(tmpdir_with_protocol + &quot;/afile6&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # IsADirectoryError raised on Linux, PermissionError on Windows</span>
<span class="gi">+    with pytest.raises((IsADirectoryError, PermissionError)):</span>
<span class="gi">+        fs.rm_file(tmpdir_with_protocol)</span>
<span class="gi">+</span>
<span class="gi">+    fs.rm(tmpdir_with_protocol, recursive=True)</span>
<span class="gi">+    assert not fs.exists(tmpdir_with_protocol)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_recursive_get_put(tmpdir):</span>
<span class="gi">+    tmpdir = make_path_posix(str(tmpdir))</span>
<span class="gi">+    fs = LocalFileSystem(auto_mkdir=True)</span>
<span class="gi">+</span>
<span class="gi">+    fs.mkdir(tmpdir + &quot;/a1/a2/a3&quot;)</span>
<span class="gi">+    fs.touch(tmpdir + &quot;/a1/a2/a3/afile&quot;)</span>
<span class="gi">+    fs.touch(tmpdir + &quot;/a1/afile&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs.get(f&quot;file://{tmpdir}/a1&quot;, tmpdir + &quot;/b1&quot;, recursive=True)</span>
<span class="gi">+    assert fs.isfile(tmpdir + &quot;/b1/afile&quot;)</span>
<span class="gi">+    assert fs.isfile(tmpdir + &quot;/b1/a2/a3/afile&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs.put(tmpdir + &quot;/b1&quot;, f&quot;file://{tmpdir}/c1&quot;, recursive=True)</span>
<span class="gi">+    assert fs.isfile(tmpdir + &quot;/c1/afile&quot;)</span>
<span class="gi">+    assert fs.isfile(tmpdir + &quot;/c1/a2/a3/afile&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_commit_discard(tmpdir):</span>
<span class="gi">+    tmpdir = str(tmpdir)</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    with fs.transaction:</span>
<span class="gi">+        with fs.open(tmpdir + &quot;/afile&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+            assert not fs.exists(tmpdir + &quot;/afile&quot;)</span>
<span class="gi">+            f.write(b&quot;data&quot;)</span>
<span class="gi">+        assert not fs.exists(tmpdir + &quot;/afile&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert fs._transaction is None</span>
<span class="gi">+    assert fs.cat(tmpdir + &quot;/afile&quot;) == b&quot;data&quot;</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        with fs.transaction:</span>
<span class="gi">+            with fs.open(tmpdir + &quot;/bfile&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+                f.write(b&quot;data&quot;)</span>
<span class="gi">+            raise KeyboardInterrupt</span>
<span class="gi">+    except KeyboardInterrupt:</span>
<span class="gi">+        assert not fs.exists(tmpdir + &quot;/bfile&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_make_path_posix():</span>
<span class="gi">+    cwd = os.getcwd()</span>
<span class="gi">+    if WIN:</span>
<span class="gi">+        drive = cwd[0]</span>
<span class="gi">+        assert make_path_posix(&quot;/a/posix/path&quot;) == f&quot;{drive}:/a/posix/path&quot;</span>
<span class="gi">+        assert make_path_posix(&quot;/posix&quot;) == f&quot;{drive}:/posix&quot;</span>
<span class="gi">+        # Windows drive requires trailing slash</span>
<span class="gi">+        assert make_path_posix(&quot;C:\\&quot;) == &quot;C:/&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        assert make_path_posix(&quot;/a/posix/path&quot;) == &quot;/a/posix/path&quot;</span>
<span class="gi">+        assert make_path_posix(&quot;/posix&quot;) == &quot;/posix&quot;</span>
<span class="gi">+    assert make_path_posix(&quot;relpath&quot;) == posixpath.join(make_path_posix(cwd), &quot;relpath&quot;)</span>
<span class="gi">+    assert make_path_posix(&quot;rel/path&quot;) == posixpath.join(</span>
<span class="gi">+        make_path_posix(cwd), &quot;rel/path&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    # NT style</span>
<span class="gi">+    if WIN:</span>
<span class="gi">+        assert make_path_posix(&quot;C:\\path&quot;) == &quot;C:/path&quot;</span>
<span class="gi">+        assert (</span>
<span class="gi">+            make_path_posix(</span>
<span class="gi">+                &quot;\\\\windows-server\\someshare\\path\\more\\path\\dir\\foo.parquet&quot;,</span>
<span class="gi">+            )</span>
<span class="gi">+            == &quot;//windows-server/someshare/path/more/path/dir/foo.parquet&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+        assert (</span>
<span class="gi">+            make_path_posix(</span>
<span class="gi">+                &quot;\\\\SERVER\\UserHomeFolder$\\me\\My Documents\\proj\\data\\fname.csv&quot;,</span>
<span class="gi">+            )</span>
<span class="gi">+            == &quot;//SERVER/UserHomeFolder$/me/My Documents/proj/data/fname.csv&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+    assert &quot;/&quot; in make_path_posix(&quot;rel\\path&quot;)</span>
<span class="gi">+    # Relative</span>
<span class="gi">+    pp = make_path_posix(&quot;./path&quot;)</span>
<span class="gi">+    cd = make_path_posix(cwd)</span>
<span class="gi">+    assert pp == cd + &quot;/path&quot;</span>
<span class="gi">+    # Userpath</span>
<span class="gi">+    userpath = make_path_posix(&quot;~/path&quot;)</span>
<span class="gi">+    assert userpath.endswith(&quot;/path&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;path&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        &quot;/abc/def&quot;,</span>
<span class="gi">+        &quot;abc/def&quot;,</span>
<span class="gi">+        &quot;&quot;,</span>
<span class="gi">+        &quot;.&quot;,</span>
<span class="gi">+        &quot;//server/share/&quot;,</span>
<span class="gi">+        &quot;\\\\server\\share\\&quot;,</span>
<span class="gi">+        &quot;C:\\&quot;,</span>
<span class="gi">+        &quot;d:/abc/def&quot;,</span>
<span class="gi">+        &quot;e:&quot;,</span>
<span class="gi">+        pytest.param(</span>
<span class="gi">+            &quot;\\\\server\\share&quot;,</span>
<span class="gi">+            marks=[</span>
<span class="gi">+                pytest.mark.xfail(</span>
<span class="gi">+                    WIN and sys.version_info &lt; (3, 11),</span>
<span class="gi">+                    reason=&quot;requires py3.11+ see: python/cpython#96290&quot;,</span>
<span class="gi">+                )</span>
<span class="gi">+            ],</span>
<span class="gi">+        ),</span>
<span class="gi">+        pytest.param(</span>
<span class="gi">+            &quot;f:foo&quot;,</span>
<span class="gi">+            marks=[pytest.mark.xfail(WIN, reason=&quot;unsupported&quot;)],</span>
<span class="gi">+            id=&quot;relative-path-with-drive&quot;,</span>
<span class="gi">+        ),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_make_path_posix_returns_absolute_paths(path):</span>
<span class="gi">+    posix_pth = make_path_posix(path)</span>
<span class="gi">+    assert os.path.isabs(posix_pth)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;container_cls&quot;, [list, set, tuple])</span>
<span class="gi">+def test_make_path_posix_set_list_tuple(container_cls):</span>
<span class="gi">+    paths = container_cls(</span>
<span class="gi">+        [</span>
<span class="gi">+            &quot;/foo/bar&quot;,</span>
<span class="gi">+            &quot;bar/foo&quot;,</span>
<span class="gi">+        ]</span>
<span class="gi">+    )</span>
<span class="gi">+    posix_paths = make_path_posix(paths)</span>
<span class="gi">+    assert isinstance(posix_paths, container_cls)</span>
<span class="gi">+    assert posix_paths == container_cls(</span>
<span class="gi">+        [</span>
<span class="gi">+            make_path_posix(&quot;/foo/bar&quot;),</span>
<span class="gi">+            make_path_posix(&quot;bar/foo&quot;),</span>
<span class="gi">+        ]</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;obj&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        1,</span>
<span class="gi">+        True,</span>
<span class="gi">+        None,</span>
<span class="gi">+        object(),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_make_path_posix_wrong_type(obj):</span>
<span class="gi">+    with pytest.raises(TypeError):</span>
<span class="gi">+        make_path_posix(obj)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_parent():</span>
<span class="gi">+    if WIN:</span>
<span class="gi">+        assert LocalFileSystem._parent(&quot;C:\\file or folder&quot;) == &quot;C:/&quot;</span>
<span class="gi">+        assert LocalFileSystem._parent(&quot;C:\\&quot;) == &quot;C:/&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        assert LocalFileSystem._parent(&quot;/file or folder&quot;) == &quot;/&quot;</span>
<span class="gi">+        assert LocalFileSystem._parent(&quot;/&quot;) == &quot;/&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;path,parent&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        (&quot;C:\\&quot;, &quot;C:/&quot;),</span>
<span class="gi">+        (&quot;C:\\.&quot;, &quot;C:/&quot;),</span>
<span class="gi">+        (&quot;C:\\.\\&quot;, &quot;C:/&quot;),</span>
<span class="gi">+        (&quot;file:C:/&quot;, &quot;C:/&quot;),</span>
<span class="gi">+        (&quot;file://C:/&quot;, &quot;C:/&quot;),</span>
<span class="gi">+        (&quot;local:C:/&quot;, &quot;C:/&quot;),</span>
<span class="gi">+        (&quot;local://C:/&quot;, &quot;C:/&quot;),</span>
<span class="gi">+        (&quot;\\\\server\\share&quot;, &quot;//server/share&quot;),</span>
<span class="gi">+        (&quot;\\\\server\\share\\&quot;, &quot;//server/share&quot;),</span>
<span class="gi">+        (&quot;\\\\server\\share\\path&quot;, &quot;//server/share&quot;),</span>
<span class="gi">+        (&quot;//server/share&quot;, &quot;//server/share&quot;),</span>
<span class="gi">+        (&quot;//server/share/&quot;, &quot;//server/share&quot;),</span>
<span class="gi">+        (&quot;//server/share/path&quot;, &quot;//server/share&quot;),</span>
<span class="gi">+        (&quot;C:\\file or folder&quot;, &quot;C:/&quot;),</span>
<span class="gi">+        (&quot;C:\\file or folder\\&quot;, &quot;C:/&quot;),</span>
<span class="gi">+        (&quot;file:///&quot;, &quot;{current_drive}/&quot;),</span>
<span class="gi">+        (&quot;file:///path&quot;, &quot;{current_drive}/&quot;),</span>
<span class="gi">+    ]</span>
<span class="gi">+    if WIN</span>
<span class="gi">+    else [</span>
<span class="gi">+        (&quot;/&quot;, &quot;/&quot;),</span>
<span class="gi">+        (&quot;/.&quot;, &quot;/&quot;),</span>
<span class="gi">+        (&quot;/./&quot;, &quot;/&quot;),</span>
<span class="gi">+        (&quot;file:/&quot;, &quot;/&quot;),</span>
<span class="gi">+        (&quot;file:///&quot;, &quot;/&quot;),</span>
<span class="gi">+        (&quot;local:/&quot;, &quot;/&quot;),</span>
<span class="gi">+        (&quot;local:///&quot;, &quot;/&quot;),</span>
<span class="gi">+        (&quot;/file or folder&quot;, &quot;/&quot;),</span>
<span class="gi">+        (&quot;/file or folder/&quot;, &quot;/&quot;),</span>
<span class="gi">+        (&quot;file:///path&quot;, &quot;/&quot;),</span>
<span class="gi">+        (&quot;file://c/&quot;, &quot;{cwd}&quot;),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_parent_edge_cases(path, parent, cwd, current_drive):</span>
<span class="gi">+    parent = parent.format(cwd=cwd, current_drive=current_drive)</span>
<span class="gi">+</span>
<span class="gi">+    assert LocalFileSystem._parent(path) == parent</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_linked_files(tmpdir):</span>
<span class="gi">+    tmpdir = str(tmpdir)</span>
<span class="gi">+    fn0 = os.path.join(tmpdir, &quot;target&quot;)</span>
<span class="gi">+    fn1 = os.path.join(tmpdir, &quot;link1&quot;)</span>
<span class="gi">+    fn2 = os.path.join(tmpdir, &quot;link2&quot;)</span>
<span class="gi">+    data = b&quot;my target data&quot;</span>
<span class="gi">+    with open(fn0, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+    try:</span>
<span class="gi">+        os.symlink(fn0, fn1)</span>
<span class="gi">+        os.symlink(fn0, fn2)</span>
<span class="gi">+    except OSError:</span>
<span class="gi">+        if WIN:</span>
<span class="gi">+            pytest.xfail(&quot;Ran on win without admin permissions&quot;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise</span>
<span class="gi">+</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    assert fs.info(fn0)[&quot;type&quot;] == &quot;file&quot;</span>
<span class="gi">+    assert fs.info(fn1)[&quot;type&quot;] == &quot;file&quot;</span>
<span class="gi">+    assert fs.info(fn2)[&quot;type&quot;] == &quot;file&quot;</span>
<span class="gi">+</span>
<span class="gi">+    assert not fs.info(fn0)[&quot;islink&quot;]</span>
<span class="gi">+    assert fs.info(fn1)[&quot;islink&quot;]</span>
<span class="gi">+    assert fs.info(fn2)[&quot;islink&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.info(fn0)[&quot;size&quot;] == len(data)</span>
<span class="gi">+    assert fs.info(fn1)[&quot;size&quot;] == len(data)</span>
<span class="gi">+    assert fs.info(fn2)[&quot;size&quot;] == len(data)</span>
<span class="gi">+</span>
<span class="gi">+    of = fsspec.open(fn1, &quot;rb&quot;)</span>
<span class="gi">+    with of as f:</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+</span>
<span class="gi">+    of = fsspec.open(fn2, &quot;rb&quot;)</span>
<span class="gi">+    with of as f:</span>
<span class="gi">+        assert f.read() == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_linked_files_exists(tmpdir):</span>
<span class="gi">+    origin = tmpdir / &quot;original&quot;</span>
<span class="gi">+    copy_file = tmpdir / &quot;copy&quot;</span>
<span class="gi">+</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    fs.touch(origin)</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        os.symlink(origin, copy_file)</span>
<span class="gi">+    except OSError:</span>
<span class="gi">+        if WIN:</span>
<span class="gi">+            pytest.xfail(&quot;Ran on win without admin permissions&quot;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.exists(copy_file)</span>
<span class="gi">+    assert fs.lexists(copy_file)</span>
<span class="gi">+</span>
<span class="gi">+    os.unlink(origin)</span>
<span class="gi">+</span>
<span class="gi">+    assert not fs.exists(copy_file)</span>
<span class="gi">+    assert fs.lexists(copy_file)</span>
<span class="gi">+</span>
<span class="gi">+    os.unlink(copy_file)</span>
<span class="gi">+</span>
<span class="gi">+    assert not fs.exists(copy_file)</span>
<span class="gi">+    assert not fs.lexists(copy_file)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_linked_directories(tmpdir):</span>
<span class="gi">+    tmpdir = str(tmpdir)</span>
<span class="gi">+</span>
<span class="gi">+    subdir0 = os.path.join(tmpdir, &quot;target&quot;)</span>
<span class="gi">+    subdir1 = os.path.join(tmpdir, &quot;link1&quot;)</span>
<span class="gi">+    subdir2 = os.path.join(tmpdir, &quot;link2&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    os.makedirs(subdir0)</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        os.symlink(subdir0, subdir1)</span>
<span class="gi">+        os.symlink(subdir0, subdir2)</span>
<span class="gi">+    except OSError:</span>
<span class="gi">+        if WIN:</span>
<span class="gi">+            pytest.xfail(&quot;Ran on win without admin permissions&quot;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise</span>
<span class="gi">+</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    assert fs.info(subdir0)[&quot;type&quot;] == &quot;directory&quot;</span>
<span class="gi">+    assert fs.info(subdir1)[&quot;type&quot;] == &quot;directory&quot;</span>
<span class="gi">+    assert fs.info(subdir2)[&quot;type&quot;] == &quot;directory&quot;</span>
<span class="gi">+</span>
<span class="gi">+    assert not fs.info(subdir0)[&quot;islink&quot;]</span>
<span class="gi">+    assert fs.info(subdir1)[&quot;islink&quot;]</span>
<span class="gi">+    assert fs.info(subdir2)[&quot;islink&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_isfilestore():</span>
<span class="gi">+    fs = LocalFileSystem(auto_mkdir=False)</span>
<span class="gi">+    assert fs._isfilestore()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_pickle(tmpdir):</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    tmpdir = str(tmpdir)</span>
<span class="gi">+    fn0 = os.path.join(tmpdir, &quot;target&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with open(fn0, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;data&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    f = fs.open(fn0, &quot;rb&quot;)</span>
<span class="gi">+    f.seek(1)</span>
<span class="gi">+    f2 = pickle.loads(pickle.dumps(f))</span>
<span class="gi">+    assert f2.read() == f.read()</span>
<span class="gi">+</span>
<span class="gi">+    f = fs.open(fn0, &quot;wb&quot;)</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        pickle.dumps(f)</span>
<span class="gi">+</span>
<span class="gi">+    # with context</span>
<span class="gi">+    with fs.open(fn0, &quot;rb&quot;) as f:</span>
<span class="gi">+        f.seek(1)</span>
<span class="gi">+        f2 = pickle.loads(pickle.dumps(f))</span>
<span class="gi">+        assert f2.tell() == 1</span>
<span class="gi">+        assert f2.read() == f.read()</span>
<span class="gi">+</span>
<span class="gi">+    # with fsspec.open https://github.com/fsspec/filesystem_spec/issues/579</span>
<span class="gi">+    with fsspec.open(fn0, &quot;rb&quot;) as f:</span>
<span class="gi">+        f.seek(1)</span>
<span class="gi">+        f2 = pickle.loads(pickle.dumps(f))</span>
<span class="gi">+        assert f2.tell() == 1</span>
<span class="gi">+        assert f2.read() == f.read()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;uri, expected&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        (&quot;file://~/foo/bar&quot;, &quot;{user_home}/foo/bar&quot;),</span>
<span class="gi">+        (&quot;~/foo/bar&quot;, &quot;{user_home}/foo/bar&quot;),</span>
<span class="gi">+        winonly(&quot;~\\foo\\bar&quot;, &quot;{user_home}/foo/bar&quot;),</span>
<span class="gi">+        winonly(&quot;file://~\\foo\\bar&quot;, &quot;{user_home}/foo/bar&quot;),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_strip_protocol_expanduser(uri, expected, user_home):</span>
<span class="gi">+    expected = expected.format(user_home=user_home)</span>
<span class="gi">+</span>
<span class="gi">+    stripped = LocalFileSystem._strip_protocol(uri)</span>
<span class="gi">+    assert expected == stripped</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;uri, expected&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        (&quot;file://&quot;, &quot;{cwd}&quot;),</span>
<span class="gi">+        (&quot;file://.&quot;, &quot;{cwd}&quot;),</span>
<span class="gi">+        (&quot;file://./&quot;, &quot;{cwd}&quot;),</span>
<span class="gi">+        (&quot;./&quot;, &quot;{cwd}&quot;),</span>
<span class="gi">+        (&quot;file:path&quot;, &quot;{cwd}/path&quot;),</span>
<span class="gi">+        (&quot;file://path&quot;, &quot;{cwd}/path&quot;),</span>
<span class="gi">+        (&quot;path&quot;, &quot;{cwd}/path&quot;),</span>
<span class="gi">+        (&quot;./path&quot;, &quot;{cwd}/path&quot;),</span>
<span class="gi">+        winonly(&quot;.\\&quot;, &quot;{cwd}&quot;),</span>
<span class="gi">+        winonly(&quot;file://.\\path&quot;, &quot;{cwd}/path&quot;),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_strip_protocol_relative_paths(uri, expected, cwd):</span>
<span class="gi">+    expected = expected.format(cwd=cwd)</span>
<span class="gi">+</span>
<span class="gi">+    stripped = LocalFileSystem._strip_protocol(uri)</span>
<span class="gi">+    assert expected == stripped</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;uri, expected&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        posixonly(&quot;file:/foo/bar&quot;, &quot;/foo/bar&quot;),</span>
<span class="gi">+        winonly(&quot;file:/foo/bar&quot;, &quot;{current_drive}/foo/bar&quot;),</span>
<span class="gi">+        winonly(&quot;file:\\foo\\bar&quot;, &quot;{current_drive}/foo/bar&quot;),</span>
<span class="gi">+        winonly(&quot;file:D:\\path\\file&quot;, &quot;D:/path/file&quot;),</span>
<span class="gi">+        winonly(&quot;file:/D:\\path\\file&quot;, &quot;D:/path/file&quot;),</span>
<span class="gi">+        winonly(&quot;file://D:\\path\\file&quot;, &quot;D:/path/file&quot;),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_strip_protocol_no_authority(uri, expected, cwd, current_drive):</span>
<span class="gi">+    expected = expected.format(cwd=cwd, current_drive=current_drive)</span>
<span class="gi">+</span>
<span class="gi">+    stripped = LocalFileSystem._strip_protocol(uri)</span>
<span class="gi">+    assert expected == stripped</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;uri, expected&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        (&quot;file:/path&quot;, &quot;/path&quot;),</span>
<span class="gi">+        (&quot;file:///path&quot;, &quot;/path&quot;),</span>
<span class="gi">+        (&quot;file:////path&quot;, &quot;//path&quot;),</span>
<span class="gi">+        (&quot;local:/path&quot;, &quot;/path&quot;),</span>
<span class="gi">+        (&quot;s3://bucket/key&quot;, &quot;{cwd}/s3://bucket/key&quot;),</span>
<span class="gi">+        (&quot;/path&quot;, &quot;/path&quot;),</span>
<span class="gi">+        (&quot;file:///&quot;, &quot;/&quot;),</span>
<span class="gi">+    ]</span>
<span class="gi">+    if not WIN</span>
<span class="gi">+    else [</span>
<span class="gi">+        (&quot;file:c:/path&quot;, &quot;c:/path&quot;),</span>
<span class="gi">+        (&quot;file:/c:/path&quot;, &quot;c:/path&quot;),</span>
<span class="gi">+        (&quot;file:/C:/path&quot;, &quot;C:/path&quot;),</span>
<span class="gi">+        (&quot;file://c:/path&quot;, &quot;c:/path&quot;),</span>
<span class="gi">+        (&quot;file:///c:/path&quot;, &quot;c:/path&quot;),</span>
<span class="gi">+        (&quot;local:/path&quot;, &quot;{current_drive}/path&quot;),</span>
<span class="gi">+        (&quot;s3://bucket/key&quot;, &quot;{cwd}/s3://bucket/key&quot;),</span>
<span class="gi">+        (&quot;c:/path&quot;, &quot;c:/path&quot;),</span>
<span class="gi">+        (&quot;c:\\path&quot;, &quot;c:/path&quot;),</span>
<span class="gi">+        (&quot;file:///&quot;, &quot;{current_drive}/&quot;),</span>
<span class="gi">+        pytest.param(</span>
<span class="gi">+            &quot;file://localhost/c:/path&quot;,</span>
<span class="gi">+            &quot;c:/path&quot;,</span>
<span class="gi">+            marks=pytest.mark.xfail(</span>
<span class="gi">+                reason=&quot;rfc8089 section3 &#39;localhost uri&#39; not supported&quot;</span>
<span class="gi">+            ),</span>
<span class="gi">+        ),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_strip_protocol_absolute_paths(uri, expected, current_drive, cwd):</span>
<span class="gi">+    expected = expected.format(current_drive=current_drive, cwd=cwd)</span>
<span class="gi">+</span>
<span class="gi">+    stripped = LocalFileSystem._strip_protocol(uri)</span>
<span class="gi">+    assert expected == stripped</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;uri, expected&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        (&quot;file:c|/path&quot;, &quot;c:/path&quot;),</span>
<span class="gi">+        (&quot;file:/D|/path&quot;, &quot;D:/path&quot;),</span>
<span class="gi">+        (&quot;file:///C|/path&quot;, &quot;C:/path&quot;),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+@pytest.mark.skipif(not WIN, reason=&quot;Windows only&quot;)</span>
<span class="gi">+@pytest.mark.xfail(WIN, reason=&quot;legacy dos uris not supported&quot;)</span>
<span class="gi">+def test_strip_protocol_legacy_dos_uris(uri, expected):</span>
<span class="gi">+    stripped = LocalFileSystem._strip_protocol(uri)</span>
<span class="gi">+    assert expected == stripped</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;uri, stripped&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        (&quot;file://remote/share/pth&quot;, &quot;{cwd}/remote/share/pth&quot;),</span>
<span class="gi">+        (&quot;file:////remote/share/pth&quot;, &quot;//remote/share/pth&quot;),</span>
<span class="gi">+        (&quot;file://///remote/share/pth&quot;, &quot;///remote/share/pth&quot;),</span>
<span class="gi">+        (&quot;//remote/share/pth&quot;, &quot;//remote/share/pth&quot;),</span>
<span class="gi">+        winonly(&quot;\\\\remote\\share\\pth&quot;, &quot;//remote/share/pth&quot;),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_strip_protocol_windows_remote_shares(uri, stripped, cwd):</span>
<span class="gi">+    stripped = stripped.format(cwd=cwd)</span>
<span class="gi">+</span>
<span class="gi">+    assert LocalFileSystem._strip_protocol(uri) == stripped</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mkdir_twice_faile(tmpdir):</span>
<span class="gi">+    fn = os.path.join(tmpdir, &quot;test&quot;)</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;file&quot;)</span>
<span class="gi">+    fs.mkdir(fn)</span>
<span class="gi">+    with pytest.raises(FileExistsError):</span>
<span class="gi">+        fs.mkdir(fn)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_iterable(tmpdir):</span>
<span class="gi">+    data = b&quot;a\nhello\noi&quot;</span>
<span class="gi">+    fn = os.path.join(tmpdir, &quot;test&quot;)</span>
<span class="gi">+    with open(fn, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(data)</span>
<span class="gi">+    of = fsspec.open(f&quot;file://{fn}&quot;, &quot;rb&quot;)</span>
<span class="gi">+    with of as f:</span>
<span class="gi">+        out = list(f)</span>
<span class="gi">+    assert b&quot;&quot;.join(out) == data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mv_empty(tmpdir):</span>
<span class="gi">+    localfs = fsspec.filesystem(&quot;file&quot;)</span>
<span class="gi">+    src = os.path.join(str(tmpdir), &quot;src&quot;)</span>
<span class="gi">+    dest = os.path.join(str(tmpdir), &quot;dest&quot;)</span>
<span class="gi">+    assert localfs.isdir(src) is False</span>
<span class="gi">+    localfs.mkdir(src)</span>
<span class="gi">+    assert localfs.isdir(src)</span>
<span class="gi">+    localfs.move(src, dest, recursive=True)</span>
<span class="gi">+    assert localfs.isdir(src) is False</span>
<span class="gi">+    assert localfs.isdir(dest)</span>
<span class="gi">+    assert localfs.info(dest)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mv_recursive(tmpdir):</span>
<span class="gi">+    localfs = fsspec.filesystem(&quot;file&quot;)</span>
<span class="gi">+    src = os.path.join(str(tmpdir), &quot;src&quot;)</span>
<span class="gi">+    dest = os.path.join(str(tmpdir), &quot;dest&quot;)</span>
<span class="gi">+    assert localfs.isdir(src) is False</span>
<span class="gi">+    localfs.mkdir(src)</span>
<span class="gi">+    assert localfs.isdir(src)</span>
<span class="gi">+    localfs.touch(os.path.join(src, &quot;afile&quot;))</span>
<span class="gi">+    localfs.move(src, dest, recursive=True)</span>
<span class="gi">+    assert localfs.isdir(src) is False</span>
<span class="gi">+    assert localfs.isdir(dest)</span>
<span class="gi">+    assert localfs.info(os.path.join(dest, &quot;afile&quot;))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.xfail(WIN, reason=&quot;windows expand path to be revisited&quot;)</span>
<span class="gi">+def test_copy_errors(tmpdir):</span>
<span class="gi">+    localfs = fsspec.filesystem(&quot;file&quot;, auto_mkdir=True)</span>
<span class="gi">+</span>
<span class="gi">+    dest1 = os.path.join(str(tmpdir), &quot;dest1&quot;)</span>
<span class="gi">+    dest2 = os.path.join(str(tmpdir), &quot;dest2&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    src = os.path.join(str(tmpdir), &quot;src&quot;)</span>
<span class="gi">+    file1 = os.path.join(src, &quot;afile1&quot;)</span>
<span class="gi">+    file2 = os.path.join(src, &quot;afile2&quot;)</span>
<span class="gi">+    dne = os.path.join(str(tmpdir), &quot;src&quot;, &quot;notafile&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    localfs.mkdir(src)</span>
<span class="gi">+    localfs.mkdir(dest1)</span>
<span class="gi">+    localfs.mkdir(dest2)</span>
<span class="gi">+    localfs.touch(file1)</span>
<span class="gi">+    localfs.touch(file2)</span>
<span class="gi">+</span>
<span class="gi">+    # Non recursive should raise an error unless we specify ignore</span>
<span class="gi">+    with pytest.raises(FileNotFoundError):</span>
<span class="gi">+        localfs.copy([file1, file2, dne], dest1)</span>
<span class="gi">+</span>
<span class="gi">+    localfs.copy([file1, file2, dne], dest1, on_error=&quot;ignore&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert sorted(localfs.ls(dest1)) == [</span>
<span class="gi">+        make_path_posix(os.path.join(dest1, &quot;afile1&quot;)),</span>
<span class="gi">+        make_path_posix(os.path.join(dest1, &quot;afile2&quot;)),</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+    # Recursive should raise an error only if we specify raise</span>
<span class="gi">+    # the patch simulates the filesystem finding a file that does not</span>
<span class="gi">+    # exist in the directory</span>
<span class="gi">+    current_files = localfs.expand_path(src, recursive=True)</span>
<span class="gi">+    with patch.object(localfs, &quot;expand_path&quot;, return_value=current_files + [dne]):</span>
<span class="gi">+        with pytest.raises(FileNotFoundError):</span>
<span class="gi">+            localfs.copy(src + &quot;/&quot;, dest2, recursive=True, on_error=&quot;raise&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        localfs.copy(src + &quot;/&quot;, dest2, recursive=True)</span>
<span class="gi">+        assert sorted(localfs.ls(dest2)) == [</span>
<span class="gi">+            make_path_posix(os.path.join(dest2, &quot;afile1&quot;)),</span>
<span class="gi">+            make_path_posix(os.path.join(dest2, &quot;afile2&quot;)),</span>
<span class="gi">+        ]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_transaction(tmpdir):</span>
<span class="gi">+    file = str(tmpdir / &quot;test.txt&quot;)</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+</span>
<span class="gi">+    with fs.transaction:</span>
<span class="gi">+        content = &quot;hello world&quot;</span>
<span class="gi">+        with fs.open(file, &quot;w&quot;) as fp:</span>
<span class="gi">+            fp.write(content)</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(file, &quot;r&quot;) as fp:</span>
<span class="gi">+        read_content = fp.read()</span>
<span class="gi">+</span>
<span class="gi">+    assert content == read_content</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_delete_cwd(tmpdir):</span>
<span class="gi">+    cwd = os.getcwd()</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    try:</span>
<span class="gi">+        os.chdir(tmpdir)</span>
<span class="gi">+        with pytest.raises(ValueError):</span>
<span class="gi">+            fs.rm(&quot;.&quot;, recursive=True)</span>
<span class="gi">+    finally:</span>
<span class="gi">+        os.chdir(cwd)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_delete_non_recursive_dir_fails(tmpdir):</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    subdir = os.path.join(tmpdir, &quot;testdir&quot;)</span>
<span class="gi">+    fs.mkdir(subdir)</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        fs.rm(subdir)</span>
<span class="gi">+    fs.rm(subdir, recursive=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;opener, ext&quot;, [(bz2.open, &quot;.bz2&quot;), (gzip.open, &quot;.gz&quot;), (open, &quot;&quot;)]</span>
<span class="gi">+)</span>
<span class="gi">+def test_infer_compression(tmpdir, opener, ext):</span>
<span class="gi">+    filename = str(tmpdir / f&quot;test{ext}&quot;)</span>
<span class="gi">+    content = b&quot;hello world&quot;</span>
<span class="gi">+    with opener(filename, &quot;wb&quot;) as fp:</span>
<span class="gi">+        fp.write(content)</span>
<span class="gi">+</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    with fs.open(f&quot;file://{filename}&quot;, &quot;rb&quot;, compression=&quot;infer&quot;) as fp:</span>
<span class="gi">+        read_content = fp.read()</span>
<span class="gi">+</span>
<span class="gi">+    assert content == read_content</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_info_path_like(tmpdir):</span>
<span class="gi">+    path = Path(tmpdir / &quot;test_info&quot;)</span>
<span class="gi">+    path.write_text(&quot;fsspec&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    assert fs.exists(path)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_seekable(tmpdir):</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    tmpdir = str(tmpdir)</span>
<span class="gi">+    fn0 = os.path.join(tmpdir, &quot;target&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with open(fn0, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;data&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    f = fs.open(fn0, &quot;rt&quot;)</span>
<span class="gi">+    assert f.seekable(), &quot;file is not seekable&quot;</span>
<span class="gi">+    f.seek(1)</span>
<span class="gi">+    assert f.read(1) == &quot;a&quot;</span>
<span class="gi">+    assert f.tell() == 2</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_numpy_fromfile(tmpdir):</span>
<span class="gi">+    # Regression test for #1005.</span>
<span class="gi">+    np = pytest.importorskip(&quot;numpy&quot;)</span>
<span class="gi">+    fn = str(tmpdir / &quot;test_arr.npy&quot;)</span>
<span class="gi">+    dt = np.int64</span>
<span class="gi">+    arr = np.arange(10, dtype=dt)</span>
<span class="gi">+    arr.tofile(fn)</span>
<span class="gi">+    assert np.array_equal(np.fromfile(fn, dtype=dt), arr)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_link(tmpdir):</span>
<span class="gi">+    target = os.path.join(tmpdir, &quot;target&quot;)</span>
<span class="gi">+    link = os.path.join(tmpdir, &quot;link&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    fs.touch(target)</span>
<span class="gi">+</span>
<span class="gi">+    fs.link(target, link)</span>
<span class="gi">+    assert fs.info(link)[&quot;nlink&quot;] &gt; 1</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_symlink(tmpdir):</span>
<span class="gi">+    target = os.path.join(tmpdir, &quot;target&quot;)</span>
<span class="gi">+    link = os.path.join(tmpdir, &quot;link&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    fs.touch(target)</span>
<span class="gi">+    try:</span>
<span class="gi">+        fs.symlink(target, link)</span>
<span class="gi">+    except OSError as e:</span>
<span class="gi">+        if &quot;[WinError 1314]&quot; in str(e):</span>
<span class="gi">+            # Windows requires developer mode to be enabled to use symbolic links</span>
<span class="gi">+            return</span>
<span class="gi">+        raise</span>
<span class="gi">+    assert fs.islink(link)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# https://github.com/fsspec/filesystem_spec/issues/967</span>
<span class="gi">+def test_put_file_to_dir(tmpdir):</span>
<span class="gi">+    src_file = os.path.join(str(tmpdir), &quot;src&quot;)</span>
<span class="gi">+    target_dir = os.path.join(str(tmpdir), &quot;target&quot;)</span>
<span class="gi">+    target_file = os.path.join(target_dir, &quot;src&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    fs.touch(src_file)</span>
<span class="gi">+    fs.mkdir(target_dir)</span>
<span class="gi">+    fs.put(src_file, target_dir)</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.isfile(target_file)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_du(tmpdir):</span>
<span class="gi">+    file = tmpdir / &quot;file&quot;</span>
<span class="gi">+    subdir = tmpdir / &quot;subdir&quot;</span>
<span class="gi">+    subfile = subdir / &quot;subfile&quot;</span>
<span class="gi">+</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    with open(file, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;4444&quot;)</span>
<span class="gi">+    fs.mkdir(subdir)</span>
<span class="gi">+    with open(subfile, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;7777777&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # Switch to posix paths for comparisons</span>
<span class="gi">+    tmpdir_posix = Path(tmpdir).as_posix()</span>
<span class="gi">+    file_posix = Path(file).as_posix()</span>
<span class="gi">+    subdir_posix = Path(subdir).as_posix()</span>
<span class="gi">+    subfile_posix = Path(subfile).as_posix()</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.du(tmpdir) == 11</span>
<span class="gi">+    assert fs.du(tmpdir, total=False) == {file_posix: 4, subfile_posix: 7}</span>
<span class="gi">+    # Note directory size is OS-specific, but must be &gt;= 0</span>
<span class="gi">+    assert fs.du(tmpdir, withdirs=True) &gt;= 11</span>
<span class="gi">+</span>
<span class="gi">+    d = fs.du(tmpdir, total=False, withdirs=True)</span>
<span class="gi">+    assert len(d) == 4</span>
<span class="gi">+    assert d[file_posix] == 4</span>
<span class="gi">+    assert d[subfile_posix] == 7</span>
<span class="gi">+    assert d[tmpdir_posix] &gt;= 0</span>
<span class="gi">+    assert d[subdir_posix] &gt;= 0</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.du(tmpdir, maxdepth=2) == 11</span>
<span class="gi">+    assert fs.du(tmpdir, maxdepth=1) == 4</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        fs.du(tmpdir, maxdepth=0)</span>
<span class="gi">+</span>
<span class="gi">+    # Size of file only.</span>
<span class="gi">+    assert fs.du(file) == 4</span>
<span class="gi">+    assert fs.du(file, withdirs=True) == 4</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;funcname&quot;, [&quot;cp&quot;, &quot;get&quot;, &quot;put&quot;])</span>
<span class="gi">+def test_cp_get_put_directory_recursive(tmpdir, funcname):</span>
<span class="gi">+    # https://github.com/fsspec/filesystem_spec/issues/1062</span>
<span class="gi">+    # Recursive cp/get/put of source directory into non-existent target directory.</span>
<span class="gi">+    fs = LocalFileSystem()</span>
<span class="gi">+    src = os.path.join(str(tmpdir), &quot;src&quot;)</span>
<span class="gi">+    fs.mkdir(src)</span>
<span class="gi">+    fs.touch(os.path.join(src, &quot;file&quot;))</span>
<span class="gi">+</span>
<span class="gi">+    target = os.path.join(str(tmpdir), &quot;target&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if funcname == &quot;cp&quot;:</span>
<span class="gi">+        func = fs.cp</span>
<span class="gi">+    elif funcname == &quot;get&quot;:</span>
<span class="gi">+        func = fs.get</span>
<span class="gi">+    elif funcname == &quot;put&quot;:</span>
<span class="gi">+        func = fs.put</span>
<span class="gi">+</span>
<span class="gi">+    # cp/get/put without slash</span>
<span class="gi">+    assert not fs.exists(target)</span>
<span class="gi">+    for loop in range(2):</span>
<span class="gi">+        func(src, target, recursive=True)</span>
<span class="gi">+        assert fs.isdir(target)</span>
<span class="gi">+</span>
<span class="gi">+        if loop == 0:</span>
<span class="gi">+            assert fs.find(target) == [make_path_posix(os.path.join(target, &quot;file&quot;))]</span>
<span class="gi">+        else:</span>
<span class="gi">+            assert sorted(fs.find(target)) == [</span>
<span class="gi">+                make_path_posix(os.path.join(target, &quot;file&quot;)),</span>
<span class="gi">+                make_path_posix(os.path.join(target, &quot;src&quot;, &quot;file&quot;)),</span>
<span class="gi">+            ]</span>
<span class="gi">+</span>
<span class="gi">+    fs.rm(target, recursive=True)</span>
<span class="gi">+</span>
<span class="gi">+    # cp/get/put with slash</span>
<span class="gi">+    assert not fs.exists(target)</span>
<span class="gi">+    for loop in range(2):</span>
<span class="gi">+        func(src + &quot;/&quot;, target, recursive=True)</span>
<span class="gi">+        assert fs.isdir(target)</span>
<span class="gi">+        assert fs.find(target) == [make_path_posix(os.path.join(target, &quot;file&quot;))]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;funcname&quot;, [&quot;cp&quot;, &quot;get&quot;, &quot;put&quot;])</span>
<span class="gi">+def test_cp_get_put_empty_directory(tmpdir, funcname):</span>
<span class="gi">+    # https://github.com/fsspec/filesystem_spec/issues/1198</span>
<span class="gi">+    # cp/get/put of empty directory.</span>
<span class="gi">+    fs = LocalFileSystem(auto_mkdir=True)</span>
<span class="gi">+    empty = os.path.join(str(tmpdir), &quot;empty&quot;)</span>
<span class="gi">+    fs.mkdir(empty)</span>
<span class="gi">+</span>
<span class="gi">+    target = os.path.join(str(tmpdir), &quot;target&quot;)</span>
<span class="gi">+    fs.mkdir(target)</span>
<span class="gi">+</span>
<span class="gi">+    if funcname == &quot;cp&quot;:</span>
<span class="gi">+        func = fs.cp</span>
<span class="gi">+    elif funcname == &quot;get&quot;:</span>
<span class="gi">+        func = fs.get</span>
<span class="gi">+    elif funcname == &quot;put&quot;:</span>
<span class="gi">+        func = fs.put</span>
<span class="gi">+</span>
<span class="gi">+    # cp/get/put without slash, target directory exists</span>
<span class="gi">+    assert fs.isdir(target)</span>
<span class="gi">+    func(empty, target)</span>
<span class="gi">+    assert fs.find(target, withdirs=True) == [make_path_posix(target)]</span>
<span class="gi">+</span>
<span class="gi">+    # cp/get/put with slash, target directory exists</span>
<span class="gi">+    assert fs.isdir(target)</span>
<span class="gi">+    func(empty + &quot;/&quot;, target)</span>
<span class="gi">+    assert fs.find(target, withdirs=True) == [make_path_posix(target)]</span>
<span class="gi">+</span>
<span class="gi">+    fs.rmdir(target)</span>
<span class="gi">+</span>
<span class="gi">+    # cp/get/put without slash, target directory doesn&#39;t exist</span>
<span class="gi">+    assert not fs.isdir(target)</span>
<span class="gi">+    func(empty, target)</span>
<span class="gi">+    assert not fs.isdir(target)</span>
<span class="gi">+</span>
<span class="gi">+    # cp/get/put with slash, target directory doesn&#39;t exist</span>
<span class="gi">+    assert not fs.isdir(target)</span>
<span class="gi">+    func(empty + &quot;/&quot;, target)</span>
<span class="gi">+    assert not fs.isdir(target)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_cp_two_files(tmpdir):</span>
<span class="gi">+    fs = LocalFileSystem(auto_mkdir=True)</span>
<span class="gi">+    src = os.path.join(str(tmpdir), &quot;src&quot;)</span>
<span class="gi">+    file0 = os.path.join(src, &quot;file0&quot;)</span>
<span class="gi">+    file1 = os.path.join(src, &quot;file1&quot;)</span>
<span class="gi">+    fs.mkdir(src)</span>
<span class="gi">+    fs.touch(file0)</span>
<span class="gi">+    fs.touch(file1)</span>
<span class="gi">+</span>
<span class="gi">+    target = os.path.join(str(tmpdir), &quot;target&quot;)</span>
<span class="gi">+    assert not fs.exists(target)</span>
<span class="gi">+</span>
<span class="gi">+    fs.cp([file0, file1], target)</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.isdir(target)</span>
<span class="gi">+    assert sorted(fs.find(target)) == [</span>
<span class="gi">+        make_path_posix(os.path.join(target, &quot;file0&quot;)),</span>
<span class="gi">+        make_path_posix(os.path.join(target, &quot;file1&quot;)),</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(WIN, reason=&quot;Windows does not support colons in filenames&quot;)</span>
<span class="gi">+def test_issue_1447():</span>
<span class="gi">+    files_with_colons = {</span>
<span class="gi">+        &quot;.local:file:with:colons.txt&quot;: b&quot;content1&quot;,</span>
<span class="gi">+        &quot;.colons-after-extension.txt:after&quot;: b&quot;content2&quot;,</span>
<span class="gi">+        &quot;.colons-after-extension/file:colon.txt:before/after&quot;: b&quot;content3&quot;,</span>
<span class="gi">+    }</span>
<span class="gi">+    with filetexts(files_with_colons, mode=&quot;b&quot;):</span>
<span class="gi">+        for file, contents in files_with_colons.items():</span>
<span class="gi">+            with fsspec.filesystem(&quot;file&quot;).open(file, &quot;rb&quot;) as f:</span>
<span class="gi">+                assert f.read() == contents</span>
<span class="gi">+</span>
<span class="gi">+            fs, urlpath = fsspec.core.url_to_fs(file)</span>
<span class="gi">+            assert isinstance(fs, fsspec.implementations.local.LocalFileSystem)</span>
<span class="gi">+            with fs.open(urlpath, &quot;rb&quot;) as f:</span>
<span class="gi">+                assert f.read() == contents</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_memory.py b/fsspec/implementations/tests/test_memory.py</span>
<span class="gh">index 105eeb8..600022a 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_memory.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_memory.py</span>
<span class="gu">@@ -1,4 +1,382 @@</span>
<span class="w"> </span>import os
<span class="w"> </span>from pathlib import PurePosixPath, PureWindowsPath
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>from fsspec.implementations.local import LocalFileSystem, make_path_posix
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_1(m):</span>
<span class="gi">+    m.touch(&quot;/somefile&quot;)  # NB: is found with or without initial /</span>
<span class="gi">+    m.touch(&quot;afiles/and/another&quot;)</span>
<span class="gi">+    files = m.find(&quot;&quot;)</span>
<span class="gi">+    assert files == [&quot;/afiles/and/another&quot;, &quot;/somefile&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    files = sorted(m.get_mapper())</span>
<span class="gi">+    assert files == [&quot;afiles/and/another&quot;, &quot;somefile&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_strip(m):</span>
<span class="gi">+    assert m._strip_protocol(&quot;&quot;) == &quot;&quot;</span>
<span class="gi">+    assert m._strip_protocol(&quot;memory://&quot;) == &quot;&quot;</span>
<span class="gi">+    assert m._strip_protocol(&quot;afile&quot;) == &quot;/afile&quot;</span>
<span class="gi">+    assert m._strip_protocol(&quot;/b/c&quot;) == &quot;/b/c&quot;</span>
<span class="gi">+    assert m._strip_protocol(&quot;/b/c/&quot;) == &quot;/b/c&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_ls(m):</span>
<span class="gi">+    m.mkdir(&quot;/dir&quot;)</span>
<span class="gi">+    m.mkdir(&quot;/dir/dir1&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    m.touch(&quot;/dir/afile&quot;)</span>
<span class="gi">+    m.touch(&quot;/dir/dir1/bfile&quot;)</span>
<span class="gi">+    m.touch(&quot;/dir/dir1/cfile&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert m.ls(&quot;/&quot;, False) == [&quot;/dir&quot;]</span>
<span class="gi">+    assert m.ls(&quot;/dir&quot;, False) == [&quot;/dir/afile&quot;, &quot;/dir/dir1&quot;]</span>
<span class="gi">+    assert m.ls(&quot;/dir&quot;, True)[0][&quot;type&quot;] == &quot;file&quot;</span>
<span class="gi">+    assert m.ls(&quot;/dir&quot;, True)[1][&quot;type&quot;] == &quot;directory&quot;</span>
<span class="gi">+    assert m.ls(&quot;/dir/afile&quot;, False) == [&quot;/dir/afile&quot;]</span>
<span class="gi">+    assert m.ls(&quot;/dir/afile&quot;, True)[0][&quot;type&quot;] == &quot;file&quot;</span>
<span class="gi">+</span>
<span class="gi">+    assert len(m.ls(&quot;/dir/dir1&quot;)) == 2</span>
<span class="gi">+    assert len(m.ls(&quot;/dir/afile&quot;)) == 1</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_directories(m):</span>
<span class="gi">+    m.mkdir(&quot;outer/inner&quot;)</span>
<span class="gi">+    assert m.info(&quot;outer/inner&quot;)[&quot;type&quot;] == &quot;directory&quot;</span>
<span class="gi">+</span>
<span class="gi">+    assert m.ls(&quot;outer&quot;)</span>
<span class="gi">+    assert m.ls(&quot;outer/inner&quot;) == []</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(OSError):</span>
<span class="gi">+        m.rmdir(&quot;outer&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    m.rmdir(&quot;outer/inner&quot;)</span>
<span class="gi">+    m.rmdir(&quot;outer&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert not m.store</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_exists_isdir_isfile(m):</span>
<span class="gi">+    m.mkdir(&quot;/root&quot;)</span>
<span class="gi">+    m.touch(&quot;/root/a&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert m.exists(&quot;/root&quot;)</span>
<span class="gi">+    assert m.isdir(&quot;/root&quot;)</span>
<span class="gi">+    assert not m.isfile(&quot;/root&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert m.exists(&quot;/root/a&quot;)</span>
<span class="gi">+    assert m.isfile(&quot;/root/a&quot;)</span>
<span class="gi">+    assert not m.isdir(&quot;/root/a&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert not m.exists(&quot;/root/not-exists&quot;)</span>
<span class="gi">+    assert not m.isfile(&quot;/root/not-exists&quot;)</span>
<span class="gi">+    assert not m.isdir(&quot;/root/not-exists&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    m.rm(&quot;/root/a&quot;)</span>
<span class="gi">+    m.rmdir(&quot;/root&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert not m.exists(&quot;/root&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    m.touch(&quot;/a/b&quot;)</span>
<span class="gi">+    assert m.isfile(&quot;/a/b&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert m.exists(&quot;/a&quot;)</span>
<span class="gi">+    assert m.isdir(&quot;/a&quot;)</span>
<span class="gi">+    assert not m.isfile(&quot;/a&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_touch(m):</span>
<span class="gi">+    m.touch(&quot;/root/a&quot;)</span>
<span class="gi">+    with pytest.raises(FileExistsError):</span>
<span class="gi">+        m.touch(&quot;/root/a/b&quot;)</span>
<span class="gi">+    with pytest.raises(FileExistsError):</span>
<span class="gi">+        m.touch(&quot;/root/a/b/c&quot;)</span>
<span class="gi">+    assert not m.exists(&quot;/root/a/b/&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mv_recursive(m):</span>
<span class="gi">+    m.mkdir(&quot;src&quot;)</span>
<span class="gi">+    m.touch(&quot;src/file.txt&quot;)</span>
<span class="gi">+    m.mv(&quot;src&quot;, &quot;dest&quot;, recursive=True)</span>
<span class="gi">+    assert m.exists(&quot;dest/file.txt&quot;)</span>
<span class="gi">+    assert not m.exists(&quot;src&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mv_same_paths(m):</span>
<span class="gi">+    m.mkdir(&quot;src&quot;)</span>
<span class="gi">+    m.touch(&quot;src/file.txt&quot;)</span>
<span class="gi">+    m.mv(&quot;src&quot;, &quot;src&quot;, recursive=True)</span>
<span class="gi">+    assert m.exists(&quot;src/file.txt&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_rm_no_pseudo_dir(m):</span>
<span class="gi">+    m.touch(&quot;/dir1/dir2/file&quot;)</span>
<span class="gi">+    m.rm(&quot;/dir1&quot;, recursive=True)</span>
<span class="gi">+    assert not m.exists(&quot;/dir1/dir2/file&quot;)</span>
<span class="gi">+    assert not m.exists(&quot;/dir1/dir2&quot;)</span>
<span class="gi">+    assert not m.exists(&quot;/dir1&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(FileNotFoundError):</span>
<span class="gi">+        m.rm(&quot;/dir1&quot;, recursive=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_rewind(m):</span>
<span class="gi">+    # https://github.com/fsspec/filesystem_spec/issues/349</span>
<span class="gi">+    with m.open(&quot;src/file.txt&quot;, &quot;w&quot;) as f:</span>
<span class="gi">+        f.write(&quot;content&quot;)</span>
<span class="gi">+    with m.open(&quot;src/file.txt&quot;) as f:</span>
<span class="gi">+        assert f.tell() == 0</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_empty_raises(m):</span>
<span class="gi">+    with pytest.raises(FileNotFoundError):</span>
<span class="gi">+        m.ls(&quot;nonexistent&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(FileNotFoundError):</span>
<span class="gi">+        m.info(&quot;nonexistent&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_dir_errors(m):</span>
<span class="gi">+    m.mkdir(&quot;/first&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(FileExistsError):</span>
<span class="gi">+        m.mkdir(&quot;/first&quot;)</span>
<span class="gi">+    with pytest.raises(FileExistsError):</span>
<span class="gi">+        m.makedirs(&quot;/first&quot;, exist_ok=False)</span>
<span class="gi">+    m.makedirs(&quot;/first&quot;, exist_ok=True)</span>
<span class="gi">+    m.makedirs(&quot;/first/second/third&quot;)</span>
<span class="gi">+    assert &quot;/first/second&quot; in m.pseudo_dirs</span>
<span class="gi">+</span>
<span class="gi">+    m.touch(&quot;/afile&quot;)</span>
<span class="gi">+    with pytest.raises(NotADirectoryError):</span>
<span class="gi">+        m.mkdir(&quot;/afile/nodir&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_no_rewind_append_mode(m):</span>
<span class="gi">+    # https://github.com/fsspec/filesystem_spec/issues/349</span>
<span class="gi">+    with m.open(&quot;src/file.txt&quot;, &quot;w&quot;) as f:</span>
<span class="gi">+        f.write(&quot;content&quot;)</span>
<span class="gi">+    with m.open(&quot;src/file.txt&quot;, &quot;a&quot;) as f:</span>
<span class="gi">+        assert f.tell() == 7</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_moves(m):</span>
<span class="gi">+    m.touch(&quot;source.txt&quot;)</span>
<span class="gi">+    m.mv(&quot;source.txt&quot;, &quot;target.txt&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    m.touch(&quot;source2.txt&quot;)</span>
<span class="gi">+    m.mv(&quot;source2.txt&quot;, &quot;target2.txt&quot;, recursive=True)</span>
<span class="gi">+    assert m.find(&quot;&quot;) == [&quot;/target.txt&quot;, &quot;/target2.txt&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_rm_reursive_empty_subdir(m):</span>
<span class="gi">+    # https://github.com/fsspec/filesystem_spec/issues/500</span>
<span class="gi">+    m.mkdir(&quot;recdir&quot;)</span>
<span class="gi">+    m.mkdir(&quot;recdir/subdir2&quot;)</span>
<span class="gi">+    m.rm(&quot;recdir/&quot;, recursive=True)</span>
<span class="gi">+    assert not m.exists(&quot;dir&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_seekable(m):</span>
<span class="gi">+    fn0 = &quot;foo.txt&quot;</span>
<span class="gi">+    with m.open(fn0, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;data&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    f = m.open(fn0, &quot;rt&quot;)</span>
<span class="gi">+    assert f.seekable(), &quot;file is not seekable&quot;</span>
<span class="gi">+    f.seek(1)</span>
<span class="gi">+    assert f.read(1) == &quot;a&quot;</span>
<span class="gi">+    assert f.tell() == 2</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# https://github.com/fsspec/filesystem_spec/issues/1425</span>
<span class="gi">+@pytest.mark.parametrize(&quot;mode&quot;, [&quot;r&quot;, &quot;rb&quot;, &quot;w&quot;, &quot;wb&quot;, &quot;ab&quot;, &quot;r+b&quot;])</span>
<span class="gi">+def test_open_mode(m, mode):</span>
<span class="gi">+    filename = &quot;mode.txt&quot;</span>
<span class="gi">+    m.touch(filename)</span>
<span class="gi">+    with m.open(filename, mode=mode) as _:</span>
<span class="gi">+        pass</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_remove_all(m):</span>
<span class="gi">+    m.touch(&quot;afile&quot;)</span>
<span class="gi">+    m.rm(&quot;/&quot;, recursive=True)</span>
<span class="gi">+    assert not m.ls(&quot;/&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_cp_directory_recursive(m):</span>
<span class="gi">+    # https://github.com/fsspec/filesystem_spec/issues/1062</span>
<span class="gi">+    # Recursive cp/get/put of source directory into non-existent target directory.</span>
<span class="gi">+    src = &quot;/src&quot;</span>
<span class="gi">+    src_file = src + &quot;/file&quot;</span>
<span class="gi">+    m.mkdir(src)</span>
<span class="gi">+    m.touch(src_file)</span>
<span class="gi">+</span>
<span class="gi">+    target = &quot;/target&quot;</span>
<span class="gi">+</span>
<span class="gi">+    # cp without slash</span>
<span class="gi">+    assert not m.exists(target)</span>
<span class="gi">+    for loop in range(2):</span>
<span class="gi">+        m.cp(src, target, recursive=True)</span>
<span class="gi">+        assert m.isdir(target)</span>
<span class="gi">+</span>
<span class="gi">+        if loop == 0:</span>
<span class="gi">+            correct = [target + &quot;/file&quot;]</span>
<span class="gi">+            assert m.find(target) == correct</span>
<span class="gi">+        else:</span>
<span class="gi">+            correct = [target + &quot;/file&quot;, target + &quot;/src/file&quot;]</span>
<span class="gi">+            assert sorted(m.find(target)) == correct</span>
<span class="gi">+</span>
<span class="gi">+    m.rm(target, recursive=True)</span>
<span class="gi">+</span>
<span class="gi">+    # cp with slash</span>
<span class="gi">+    assert not m.exists(target)</span>
<span class="gi">+    for loop in range(2):</span>
<span class="gi">+        m.cp(src + &quot;/&quot;, target, recursive=True)</span>
<span class="gi">+        assert m.isdir(target)</span>
<span class="gi">+        correct = [target + &quot;/file&quot;]</span>
<span class="gi">+        assert m.find(target) == correct</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_get_directory_recursive(m, tmpdir):</span>
<span class="gi">+    # https://github.com/fsspec/filesystem_spec/issues/1062</span>
<span class="gi">+    # Recursive cp/get/put of source directory into non-existent target directory.</span>
<span class="gi">+    src = &quot;/src&quot;</span>
<span class="gi">+    src_file = src + &quot;/file&quot;</span>
<span class="gi">+    m.mkdir(src)</span>
<span class="gi">+    m.touch(src_file)</span>
<span class="gi">+</span>
<span class="gi">+    target = os.path.join(tmpdir, &quot;target&quot;)</span>
<span class="gi">+    target_fs = LocalFileSystem()</span>
<span class="gi">+</span>
<span class="gi">+    # get without slash</span>
<span class="gi">+    assert not target_fs.exists(target)</span>
<span class="gi">+    for loop in range(2):</span>
<span class="gi">+        m.get(src, target, recursive=True)</span>
<span class="gi">+        assert target_fs.isdir(target)</span>
<span class="gi">+</span>
<span class="gi">+        if loop == 0:</span>
<span class="gi">+            correct = [make_path_posix(os.path.join(target, &quot;file&quot;))]</span>
<span class="gi">+            assert target_fs.find(target) == correct</span>
<span class="gi">+        else:</span>
<span class="gi">+            correct = [</span>
<span class="gi">+                make_path_posix(os.path.join(target, &quot;file&quot;)),</span>
<span class="gi">+                make_path_posix(os.path.join(target, &quot;src&quot;, &quot;file&quot;)),</span>
<span class="gi">+            ]</span>
<span class="gi">+            assert sorted(target_fs.find(target)) == correct</span>
<span class="gi">+</span>
<span class="gi">+    target_fs.rm(target, recursive=True)</span>
<span class="gi">+</span>
<span class="gi">+    # get with slash</span>
<span class="gi">+    assert not target_fs.exists(target)</span>
<span class="gi">+    for loop in range(2):</span>
<span class="gi">+        m.get(src + &quot;/&quot;, target, recursive=True)</span>
<span class="gi">+        assert target_fs.isdir(target)</span>
<span class="gi">+        correct = [make_path_posix(os.path.join(target, &quot;file&quot;))]</span>
<span class="gi">+        assert target_fs.find(target) == correct</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_put_directory_recursive(m, tmpdir):</span>
<span class="gi">+    # https://github.com/fsspec/filesystem_spec/issues/1062</span>
<span class="gi">+    # Recursive cp/get/put of source directory into non-existent target directory.</span>
<span class="gi">+    src = os.path.join(tmpdir, &quot;src&quot;)</span>
<span class="gi">+    src_file = os.path.join(src, &quot;file&quot;)</span>
<span class="gi">+    source_fs = LocalFileSystem()</span>
<span class="gi">+    source_fs.mkdir(src)</span>
<span class="gi">+    source_fs.touch(src_file)</span>
<span class="gi">+</span>
<span class="gi">+    target = &quot;/target&quot;</span>
<span class="gi">+</span>
<span class="gi">+    # put without slash</span>
<span class="gi">+    assert not m.exists(target)</span>
<span class="gi">+    for loop in range(2):</span>
<span class="gi">+        m.put(src, target, recursive=True)</span>
<span class="gi">+        assert m.isdir(target)</span>
<span class="gi">+</span>
<span class="gi">+        if loop == 0:</span>
<span class="gi">+            correct = [target + &quot;/file&quot;]</span>
<span class="gi">+            assert m.find(target) == correct</span>
<span class="gi">+        else:</span>
<span class="gi">+            correct = [target + &quot;/file&quot;, target + &quot;/src/file&quot;]</span>
<span class="gi">+            assert sorted(m.find(target)) == correct</span>
<span class="gi">+</span>
<span class="gi">+    m.rm(target, recursive=True)</span>
<span class="gi">+</span>
<span class="gi">+    # put with slash</span>
<span class="gi">+    assert not m.exists(target)</span>
<span class="gi">+    for loop in range(2):</span>
<span class="gi">+        m.put(src + &quot;/&quot;, target, recursive=True)</span>
<span class="gi">+        assert m.isdir(target)</span>
<span class="gi">+        correct = [target + &quot;/file&quot;]</span>
<span class="gi">+        assert m.find(target) == correct</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_cp_empty_directory(m):</span>
<span class="gi">+    # https://github.com/fsspec/filesystem_spec/issues/1198</span>
<span class="gi">+    # cp/get/put of empty directory.</span>
<span class="gi">+    empty = &quot;/src/empty&quot;</span>
<span class="gi">+    m.mkdir(empty)</span>
<span class="gi">+</span>
<span class="gi">+    target = &quot;/target&quot;</span>
<span class="gi">+    m.mkdir(target)</span>
<span class="gi">+</span>
<span class="gi">+    # cp without slash, target directory exists</span>
<span class="gi">+    assert m.isdir(target)</span>
<span class="gi">+    m.cp(empty, target)</span>
<span class="gi">+    assert m.find(target, withdirs=True) == [target]</span>
<span class="gi">+</span>
<span class="gi">+    # cp with slash, target directory exists</span>
<span class="gi">+    assert m.isdir(target)</span>
<span class="gi">+    m.cp(empty + &quot;/&quot;, target)</span>
<span class="gi">+    assert m.find(target, withdirs=True) == [target]</span>
<span class="gi">+</span>
<span class="gi">+    m.rmdir(target)</span>
<span class="gi">+</span>
<span class="gi">+    # cp without slash, target directory doesn&#39;t exist</span>
<span class="gi">+    assert not m.isdir(target)</span>
<span class="gi">+    m.cp(empty, target)</span>
<span class="gi">+    assert not m.isdir(target)</span>
<span class="gi">+</span>
<span class="gi">+    # cp with slash, target directory doesn&#39;t exist</span>
<span class="gi">+    assert not m.isdir(target)</span>
<span class="gi">+    m.cp(empty + &quot;/&quot;, target)</span>
<span class="gi">+    assert not m.isdir(target)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_cp_two_files(m):</span>
<span class="gi">+    src = &quot;/src&quot;</span>
<span class="gi">+    file0 = src + &quot;/file0&quot;</span>
<span class="gi">+    file1 = src + &quot;/file1&quot;</span>
<span class="gi">+    m.mkdir(src)</span>
<span class="gi">+    m.touch(file0)</span>
<span class="gi">+    m.touch(file1)</span>
<span class="gi">+</span>
<span class="gi">+    target = &quot;/target&quot;</span>
<span class="gi">+    assert not m.exists(target)</span>
<span class="gi">+</span>
<span class="gi">+    m.cp([file0, file1], target)</span>
<span class="gi">+</span>
<span class="gi">+    assert m.isdir(target)</span>
<span class="gi">+    assert sorted(m.find(target)) == [</span>
<span class="gi">+        &quot;/target/file0&quot;,</span>
<span class="gi">+        &quot;/target/file1&quot;,</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_open_path_posix(m):</span>
<span class="gi">+    path = PurePosixPath(&quot;/myfile/foo/bar&quot;)</span>
<span class="gi">+    with m.open(path, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;some\nlines\nof\ntext&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert m.read_text(path) == &quot;some\nlines\nof\ntext&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_open_path_windows(m):</span>
<span class="gi">+    path = PureWindowsPath(&quot;C:\\myfile\\foo\\bar&quot;)</span>
<span class="gi">+    with m.open(path, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;some\nlines\nof\ntext&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert m.read_text(path) == &quot;some\nlines\nof\ntext&quot;</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_reference.py b/fsspec/implementations/tests/test_reference.py</span>
<span class="gh">index 99b84b2..762d831 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_reference.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_reference.py</span>
<span class="gu">@@ -1,10 +1,192 @@</span>
<span class="w"> </span>import json
<span class="w"> </span>import os
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="w"> </span>from fsspec.implementations.local import LocalFileSystem
<span class="gd">-from fsspec.implementations.reference import LazyReferenceMapper, ReferenceFileSystem, ReferenceNotReachable</span>
<span class="gd">-from fsspec.tests.conftest import data, realfile, reset_files, server, win</span>
<span class="gi">+from fsspec.implementations.reference import (</span>
<span class="gi">+    LazyReferenceMapper,</span>
<span class="gi">+    ReferenceFileSystem,</span>
<span class="gi">+    ReferenceNotReachable,</span>
<span class="gi">+)</span>
<span class="gi">+from fsspec.tests.conftest import data, realfile, reset_files, server, win  # noqa: F401</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_simple(server):  # noqa: F811</span>
<span class="gi">+    # The dictionary in refs may be dumped with a different separator</span>
<span class="gi">+    # depending on whether json or ujson is imported</span>
<span class="gi">+    from fsspec.implementations.reference import json as json_impl</span>
<span class="gi">+</span>
<span class="gi">+    refs = {</span>
<span class="gi">+        &quot;a&quot;: b&quot;data&quot;,</span>
<span class="gi">+        &quot;b&quot;: (realfile, 0, 5),</span>
<span class="gi">+        &quot;c&quot;: (realfile, 1, 5),</span>
<span class="gi">+        &quot;d&quot;: b&quot;base64:aGVsbG8=&quot;,</span>
<span class="gi">+        &quot;e&quot;: {&quot;key&quot;: &quot;value&quot;},</span>
<span class="gi">+    }</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo=refs, fs=h)</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.cat(&quot;a&quot;) == b&quot;data&quot;</span>
<span class="gi">+    assert fs.cat(&quot;b&quot;) == data[:5]</span>
<span class="gi">+    assert fs.cat(&quot;c&quot;) == data[1 : 1 + 5]</span>
<span class="gi">+    assert fs.cat(&quot;d&quot;) == b&quot;hello&quot;</span>
<span class="gi">+    assert fs.cat(&quot;e&quot;) == json_impl.dumps(refs[&quot;e&quot;]).encode(&quot;utf-8&quot;)</span>
<span class="gi">+    with fs.open(&quot;d&quot;, &quot;rt&quot;) as f:</span>
<span class="gi">+        assert f.read(2) == &quot;he&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_simple_ver1(server):  # noqa: F811</span>
<span class="gi">+    # The dictionary in refs may be dumped with a different separator</span>
<span class="gi">+    # depending on whether json or ujson is imported</span>
<span class="gi">+    from fsspec.implementations.reference import json as json_impl</span>
<span class="gi">+</span>
<span class="gi">+    in_data = {</span>
<span class="gi">+        &quot;version&quot;: 1,</span>
<span class="gi">+        &quot;refs&quot;: {</span>
<span class="gi">+            &quot;a&quot;: b&quot;data&quot;,</span>
<span class="gi">+            &quot;b&quot;: (realfile, 0, 5),</span>
<span class="gi">+            &quot;c&quot;: (realfile, 1, 5),</span>
<span class="gi">+            &quot;d&quot;: b&quot;base64:aGVsbG8=&quot;,</span>
<span class="gi">+            &quot;e&quot;: {&quot;key&quot;: &quot;value&quot;},</span>
<span class="gi">+        },</span>
<span class="gi">+    }</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo=in_data, fs=h)</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.cat(&quot;a&quot;) == b&quot;data&quot;</span>
<span class="gi">+    assert fs.cat(&quot;b&quot;) == data[:5]</span>
<span class="gi">+    assert fs.cat(&quot;c&quot;) == data[1 : 1 + 5]</span>
<span class="gi">+    assert fs.cat(&quot;d&quot;) == b&quot;hello&quot;</span>
<span class="gi">+    assert fs.cat(&quot;e&quot;) == json_impl.dumps(in_data[&quot;refs&quot;][&quot;e&quot;]).encode(&quot;utf-8&quot;)</span>
<span class="gi">+    with fs.open(&quot;d&quot;, &quot;rt&quot;) as f:</span>
<span class="gi">+        assert f.read(2) == &quot;he&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_target_options(m):</span>
<span class="gi">+    m.pipe(&quot;data/0&quot;, b&quot;hello&quot;)</span>
<span class="gi">+    refs = {&quot;a&quot;: [&quot;memory://data/0&quot;]}</span>
<span class="gi">+    fn = &quot;memory://refs.json.gz&quot;</span>
<span class="gi">+    with fsspec.open(fn, &quot;wt&quot;, compression=&quot;gzip&quot;) as f:</span>
<span class="gi">+        json.dump(refs, f)</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo=fn, target_options={&quot;compression&quot;: &quot;gzip&quot;})</span>
<span class="gi">+    assert fs.cat(&quot;a&quot;) == b&quot;hello&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_ls(server):  # noqa: F811</span>
<span class="gi">+    refs = {&quot;a&quot;: b&quot;data&quot;, &quot;b&quot;: (realfile, 0, 5), &quot;c/d&quot;: (realfile, 1, 6)}</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;)</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo=refs, fs=h)</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.ls(&quot;&quot;, detail=False) == [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]</span>
<span class="gi">+    assert {&quot;name&quot;: &quot;c&quot;, &quot;type&quot;: &quot;directory&quot;, &quot;size&quot;: 0} in fs.ls(&quot;&quot;, detail=True)</span>
<span class="gi">+    assert fs.find(&quot;&quot;) == [&quot;a&quot;, &quot;b&quot;, &quot;c/d&quot;]</span>
<span class="gi">+    assert fs.find(&quot;&quot;, withdirs=True) == [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;c/d&quot;]</span>
<span class="gi">+    assert fs.find(&quot;c&quot;, detail=True) == {</span>
<span class="gi">+        &quot;c/d&quot;: {&quot;name&quot;: &quot;c/d&quot;, &quot;size&quot;: 6, &quot;type&quot;: &quot;file&quot;}</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_nested_dirs_ls():</span>
<span class="gi">+    # issue #1430</span>
<span class="gi">+    refs = {&quot;a&quot;: &quot;A&quot;, &quot;B/C/b&quot;: &quot;B&quot;, &quot;B/C/d&quot;: &quot;d&quot;, &quot;B/_&quot;: &quot;_&quot;}</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo=refs)</span>
<span class="gi">+    assert len(fs.ls(&quot;&quot;)) == 2</span>
<span class="gi">+    assert {e[&quot;name&quot;] for e in fs.ls(&quot;&quot;)} == {&quot;a&quot;, &quot;B&quot;}</span>
<span class="gi">+    assert len(fs.ls(&quot;B&quot;)) == 2</span>
<span class="gi">+    assert {e[&quot;name&quot;] for e in fs.ls(&quot;B&quot;)} == {&quot;B/C&quot;, &quot;B/_&quot;}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_info(server):  # noqa: F811</span>
<span class="gi">+    refs = {</span>
<span class="gi">+        &quot;a&quot;: b&quot;data&quot;,</span>
<span class="gi">+        &quot;b&quot;: (realfile, 0, 5),</span>
<span class="gi">+        &quot;c/d&quot;: (realfile, 1, 6),</span>
<span class="gi">+        &quot;e&quot;: (realfile,),</span>
<span class="gi">+    }</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, headers={&quot;give_length&quot;: &quot;true&quot;, &quot;head_ok&quot;: &quot;true&quot;})</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo=refs, fs=h)</span>
<span class="gi">+    assert fs.size(&quot;a&quot;) == 4</span>
<span class="gi">+    assert fs.size(&quot;b&quot;) == 5</span>
<span class="gi">+    assert fs.size(&quot;c/d&quot;) == 6</span>
<span class="gi">+    assert fs.info(&quot;e&quot;)[&quot;size&quot;] == len(data)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mutable(server, m):</span>
<span class="gi">+    refs = {</span>
<span class="gi">+        &quot;a&quot;: b&quot;data&quot;,</span>
<span class="gi">+        &quot;b&quot;: (realfile, 0, 5),</span>
<span class="gi">+        &quot;c/d&quot;: (realfile, 1, 6),</span>
<span class="gi">+        &quot;e&quot;: (realfile,),</span>
<span class="gi">+    }</span>
<span class="gi">+    h = fsspec.filesystem(&quot;http&quot;, headers={&quot;give_length&quot;: &quot;true&quot;, &quot;head_ok&quot;: &quot;true&quot;})</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo=refs, fs=h)</span>
<span class="gi">+    fs.rm(&quot;a&quot;)</span>
<span class="gi">+    assert not fs.exists(&quot;a&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    bin_data = b&quot;bin data&quot;</span>
<span class="gi">+    fs.pipe(&quot;aa&quot;, bin_data)</span>
<span class="gi">+    assert fs.cat(&quot;aa&quot;) == bin_data</span>
<span class="gi">+</span>
<span class="gi">+    fs.save_json(&quot;memory://refs.json&quot;)</span>
<span class="gi">+    assert m.exists(&quot;refs.json&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo=&quot;memory://refs.json&quot;, remote_protocol=&quot;http&quot;)</span>
<span class="gi">+    assert not fs.exists(&quot;a&quot;)</span>
<span class="gi">+    assert fs.cat(&quot;aa&quot;) == bin_data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_put_get(tmpdir):</span>
<span class="gi">+    d1 = f&quot;{tmpdir}/d1&quot;</span>
<span class="gi">+    os.mkdir(d1)</span>
<span class="gi">+    with open(f&quot;{d1}/a&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;1&quot;)</span>
<span class="gi">+    with open(f&quot;{d1}/b&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;2&quot;)</span>
<span class="gi">+    d2 = f&quot;{tmpdir}/d2&quot;</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo={}, remote_protocol=&quot;file&quot;)</span>
<span class="gi">+    fs.put(d1, &quot;out&quot;, recursive=True)</span>
<span class="gi">+</span>
<span class="gi">+    fs.get(&quot;out&quot;, d2, recursive=True)</span>
<span class="gi">+    assert open(f&quot;{d2}/a&quot;, &quot;rb&quot;).read() == b&quot;1&quot;</span>
<span class="gi">+    assert open(f&quot;{d2}/b&quot;, &quot;rb&quot;).read() == b&quot;2&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_put_get_single(tmpdir):</span>
<span class="gi">+    d1 = f&quot;{tmpdir}/f1&quot;</span>
<span class="gi">+    d2 = f&quot;{tmpdir}/f2&quot;</span>
<span class="gi">+    with open(d1, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;1&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # skip instance cache since this is the same kwargs as previous test</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;reference&quot;, fo={}, remote_protocol=&quot;file&quot;, skip_instance_cache=True</span>
<span class="gi">+    )</span>
<span class="gi">+    fs.put_file(d1, &quot;out&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs.get_file(&quot;out&quot;, d2)</span>
<span class="gi">+    assert open(d2, &quot;rb&quot;).read() == b&quot;1&quot;</span>
<span class="gi">+    fs.pipe({&quot;hi&quot;: b&quot;data&quot;})</span>
<span class="gi">+    assert fs.cat(&quot;hi&quot;) == b&quot;data&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_defaults(server):  # noqa: F811</span>
<span class="gi">+    refs = {&quot;a&quot;: b&quot;data&quot;, &quot;b&quot;: (None, 0, 5)}</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;reference&quot;,</span>
<span class="gi">+        fo=refs,</span>
<span class="gi">+        target_protocol=&quot;http&quot;,</span>
<span class="gi">+        target=realfile,</span>
<span class="gi">+        remote_protocol=&quot;http&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.cat(&quot;a&quot;) == b&quot;data&quot;</span>
<span class="gi">+    assert fs.cat(&quot;b&quot;) == data[:5]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>jdata = &quot;&quot;&quot;{
<span class="w"> </span>    &quot;metadata&quot;: {
<span class="w"> </span>        &quot;.zattrs&quot;: {
<span class="gu">@@ -43,3 +225,537 @@ jdata = &quot;&quot;&quot;{</span>
<span class="w"> </span>    &quot;zarr_consolidated_format&quot;: 1
<span class="w"> </span>}
<span class="w"> </span>&quot;&quot;&quot;
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_spec1_expand():</span>
<span class="gi">+    pytest.importorskip(&quot;jinja2&quot;)</span>
<span class="gi">+    from fsspec.implementations.reference import json as json_impl</span>
<span class="gi">+</span>
<span class="gi">+    in_data = {</span>
<span class="gi">+        &quot;version&quot;: 1,</span>
<span class="gi">+        &quot;templates&quot;: {&quot;u&quot;: &quot;server.domain/path&quot;, &quot;f&quot;: &quot;{{c}}&quot;},</span>
<span class="gi">+        &quot;gen&quot;: [</span>
<span class="gi">+            {</span>
<span class="gi">+                &quot;key&quot;: &quot;gen_key{{i}}&quot;,</span>
<span class="gi">+                &quot;url&quot;: &quot;http://{{u}}_{{i}}&quot;,</span>
<span class="gi">+                &quot;offset&quot;: &quot;{{(i + 1) * 1000}}&quot;,</span>
<span class="gi">+                &quot;length&quot;: &quot;1000&quot;,</span>
<span class="gi">+                &quot;dimensions&quot;: {&quot;i&quot;: {&quot;stop&quot;: 5}},</span>
<span class="gi">+            },</span>
<span class="gi">+            {</span>
<span class="gi">+                &quot;key&quot;: &quot;gen_key{{i}}&quot;,</span>
<span class="gi">+                &quot;url&quot;: &quot;http://{{u}}_{{i}}&quot;,</span>
<span class="gi">+                &quot;dimensions&quot;: {&quot;i&quot;: {&quot;start&quot;: 5, &quot;stop&quot;: 7}},</span>
<span class="gi">+            },</span>
<span class="gi">+        ],</span>
<span class="gi">+        &quot;refs&quot;: {</span>
<span class="gi">+            &quot;key0&quot;: &quot;data&quot;,</span>
<span class="gi">+            &quot;key1&quot;: [&quot;http://target_url&quot;, 10000, 100],</span>
<span class="gi">+            &quot;key2&quot;: [&quot;http://{{u}}&quot;, 10000, 100],</span>
<span class="gi">+            &quot;key3&quot;: [&quot;http://{{f(c=&#39;text&#39;)}}&quot;, 10000, 100],</span>
<span class="gi">+            &quot;key4&quot;: [&quot;http://target_url&quot;],</span>
<span class="gi">+            &quot;key5&quot;: {&quot;key&quot;: &quot;value&quot;},</span>
<span class="gi">+        },</span>
<span class="gi">+    }</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;reference&quot;, fo=in_data, target_protocol=&quot;http&quot;, simple_templates=False</span>
<span class="gi">+    )</span>
<span class="gi">+    assert fs.references == {</span>
<span class="gi">+        &quot;key0&quot;: &quot;data&quot;,</span>
<span class="gi">+        &quot;key1&quot;: [&quot;http://target_url&quot;, 10000, 100],</span>
<span class="gi">+        &quot;key2&quot;: [&quot;http://server.domain/path&quot;, 10000, 100],</span>
<span class="gi">+        &quot;key3&quot;: [&quot;http://text&quot;, 10000, 100],</span>
<span class="gi">+        &quot;key4&quot;: [&quot;http://target_url&quot;],</span>
<span class="gi">+        &quot;key5&quot;: json_impl.dumps(in_data[&quot;refs&quot;][&quot;key5&quot;]),</span>
<span class="gi">+        &quot;gen_key0&quot;: [&quot;http://server.domain/path_0&quot;, 1000, 1000],</span>
<span class="gi">+        &quot;gen_key1&quot;: [&quot;http://server.domain/path_1&quot;, 2000, 1000],</span>
<span class="gi">+        &quot;gen_key2&quot;: [&quot;http://server.domain/path_2&quot;, 3000, 1000],</span>
<span class="gi">+        &quot;gen_key3&quot;: [&quot;http://server.domain/path_3&quot;, 4000, 1000],</span>
<span class="gi">+        &quot;gen_key4&quot;: [&quot;http://server.domain/path_4&quot;, 5000, 1000],</span>
<span class="gi">+        &quot;gen_key5&quot;: [&quot;http://server.domain/path_5&quot;],</span>
<span class="gi">+        &quot;gen_key6&quot;: [&quot;http://server.domain/path_6&quot;],</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_spec1_expand_simple():</span>
<span class="gi">+    pytest.importorskip(&quot;jinja2&quot;)</span>
<span class="gi">+    from fsspec.implementations.reference import json as json_impl</span>
<span class="gi">+</span>
<span class="gi">+    in_data = {</span>
<span class="gi">+        &quot;version&quot;: 1,</span>
<span class="gi">+        &quot;templates&quot;: {&quot;u&quot;: &quot;server.domain/path&quot;},</span>
<span class="gi">+        &quot;refs&quot;: {</span>
<span class="gi">+            &quot;key0&quot;: &quot;base64:ZGF0YQ==&quot;,</span>
<span class="gi">+            &quot;key2&quot;: [&quot;http://{{u}}&quot;, 10000, 100],</span>
<span class="gi">+            &quot;key4&quot;: [&quot;http://target_url&quot;],</span>
<span class="gi">+            &quot;key5&quot;: {&quot;key&quot;: &quot;value&quot;},</span>
<span class="gi">+        },</span>
<span class="gi">+    }</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo=in_data, target_protocol=&quot;http&quot;)</span>
<span class="gi">+    assert fs.references[&quot;key2&quot;] == [&quot;http://server.domain/path&quot;, 10000, 100]</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;reference&quot;,</span>
<span class="gi">+        fo=in_data,</span>
<span class="gi">+        target_protocol=&quot;http&quot;,</span>
<span class="gi">+        template_overrides={&quot;u&quot;: &quot;not.org/p&quot;},</span>
<span class="gi">+    )</span>
<span class="gi">+    assert fs.references[&quot;key2&quot;] == [&quot;http://not.org/p&quot;, 10000, 100]</span>
<span class="gi">+    assert fs.cat(&quot;key0&quot;) == b&quot;data&quot;</span>
<span class="gi">+    assert fs.cat(&quot;key5&quot;) == json_impl.dumps(in_data[&quot;refs&quot;][&quot;key5&quot;]).encode(&quot;utf-8&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_spec1_gen_variants():</span>
<span class="gi">+    pytest.importorskip(&quot;jinja2&quot;)</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        missing_length_spec = {</span>
<span class="gi">+            &quot;version&quot;: 1,</span>
<span class="gi">+            &quot;templates&quot;: {&quot;u&quot;: &quot;server.domain/path&quot;},</span>
<span class="gi">+            &quot;gen&quot;: [</span>
<span class="gi">+                {</span>
<span class="gi">+                    &quot;key&quot;: &quot;gen_key{{i}}&quot;,</span>
<span class="gi">+                    &quot;url&quot;: &quot;http://{{u}}_{{i}}&quot;,</span>
<span class="gi">+                    &quot;offset&quot;: &quot;{{(i + 1) * 1000}}&quot;,</span>
<span class="gi">+                    &quot;dimensions&quot;: {&quot;i&quot;: {&quot;stop&quot;: 2}},</span>
<span class="gi">+                },</span>
<span class="gi">+            ],</span>
<span class="gi">+        }</span>
<span class="gi">+        fsspec.filesystem(&quot;reference&quot;, fo=missing_length_spec, target_protocol=&quot;http&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        missing_offset_spec = {</span>
<span class="gi">+            &quot;version&quot;: 1,</span>
<span class="gi">+            &quot;templates&quot;: {&quot;u&quot;: &quot;server.domain/path&quot;},</span>
<span class="gi">+            &quot;gen&quot;: [</span>
<span class="gi">+                {</span>
<span class="gi">+                    &quot;key&quot;: &quot;gen_key{{i}}&quot;,</span>
<span class="gi">+                    &quot;url&quot;: &quot;http://{{u}}_{{i}}&quot;,</span>
<span class="gi">+                    &quot;length&quot;: &quot;1000&quot;,</span>
<span class="gi">+                    &quot;dimensions&quot;: {&quot;i&quot;: {&quot;stop&quot;: 2}},</span>
<span class="gi">+                },</span>
<span class="gi">+            ],</span>
<span class="gi">+        }</span>
<span class="gi">+        fsspec.filesystem(&quot;reference&quot;, fo=missing_offset_spec, target_protocol=&quot;http&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    url_only_gen_spec = {</span>
<span class="gi">+        &quot;version&quot;: 1,</span>
<span class="gi">+        &quot;templates&quot;: {&quot;u&quot;: &quot;server.domain/path&quot;},</span>
<span class="gi">+        &quot;gen&quot;: [</span>
<span class="gi">+            {</span>
<span class="gi">+                &quot;key&quot;: &quot;gen_key{{i}}&quot;,</span>
<span class="gi">+                &quot;url&quot;: &quot;http://{{u}}_{{i}}&quot;,</span>
<span class="gi">+                &quot;dimensions&quot;: {&quot;i&quot;: {&quot;stop&quot;: 2}},</span>
<span class="gi">+            },</span>
<span class="gi">+        ],</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo=url_only_gen_spec, target_protocol=&quot;http&quot;)</span>
<span class="gi">+    assert fs.references == {</span>
<span class="gi">+        &quot;gen_key0&quot;: [&quot;http://server.domain/path_0&quot;],</span>
<span class="gi">+        &quot;gen_key1&quot;: [&quot;http://server.domain/path_1&quot;],</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_empty():</span>
<span class="gi">+    pytest.importorskip(&quot;jinja2&quot;)</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo={&quot;version&quot;: 1}, target_protocol=&quot;http&quot;)</span>
<span class="gi">+    assert fs.references == {}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_get_sync(tmpdir):</span>
<span class="gi">+    localfs = LocalFileSystem()</span>
<span class="gi">+</span>
<span class="gi">+    real = tmpdir / &quot;file&quot;</span>
<span class="gi">+    real.write_binary(b&quot;0123456789&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    refs = {&quot;a&quot;: b&quot;data&quot;, &quot;b&quot;: (str(real), 0, 5), &quot;c/d&quot;: (str(real), 1, 6)}</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo=refs, fs=localfs)</span>
<span class="gi">+</span>
<span class="gi">+    fs.get(&quot;a&quot;, str(tmpdir / &quot;a&quot;))</span>
<span class="gi">+    assert (tmpdir / &quot;a&quot;).read_binary() == b&quot;data&quot;</span>
<span class="gi">+    fs.get(&quot;b&quot;, str(tmpdir / &quot;b&quot;))</span>
<span class="gi">+    assert (tmpdir / &quot;b&quot;).read_binary() == b&quot;01234&quot;</span>
<span class="gi">+    fs.get(&quot;c/d&quot;, str(tmpdir / &quot;d&quot;))</span>
<span class="gi">+    assert (tmpdir / &quot;d&quot;).read_binary() == b&quot;123456&quot;</span>
<span class="gi">+    fs.get(&quot;c&quot;, str(tmpdir / &quot;c&quot;), recursive=True)</span>
<span class="gi">+    assert (tmpdir / &quot;c&quot;).isdir()</span>
<span class="gi">+    assert (tmpdir / &quot;c&quot; / &quot;d&quot;).read_binary() == b&quot;123456&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_multi_fs_provided(m, tmpdir):</span>
<span class="gi">+    localfs = LocalFileSystem()</span>
<span class="gi">+</span>
<span class="gi">+    real = tmpdir / &quot;file&quot;</span>
<span class="gi">+    real.write_binary(b&quot;0123456789&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    m.pipe(&quot;afile&quot;, b&quot;hello&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # local URLs are file:// by default</span>
<span class="gi">+    refs = {</span>
<span class="gi">+        &quot;a&quot;: b&quot;data&quot;,</span>
<span class="gi">+        &quot;b&quot;: (f&quot;file://{real}&quot;, 0, 5),</span>
<span class="gi">+        &quot;c/d&quot;: (f&quot;file://{real}&quot;, 1, 6),</span>
<span class="gi">+        &quot;c/e&quot;: [&quot;memory://afile&quot;],</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo=refs, fs={&quot;file&quot;: localfs, &quot;memory&quot;: m})</span>
<span class="gi">+    assert fs.cat(&quot;c/e&quot;) == b&quot;hello&quot;</span>
<span class="gi">+    assert fs.cat([&quot;c/e&quot;, &quot;a&quot;, &quot;b&quot;]) == {</span>
<span class="gi">+        &quot;a&quot;: b&quot;data&quot;,</span>
<span class="gi">+        &quot;b&quot;: b&quot;01234&quot;,</span>
<span class="gi">+        &quot;c/e&quot;: b&quot;hello&quot;,</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_multi_fs_created(m, tmpdir):</span>
<span class="gi">+    real = tmpdir / &quot;file&quot;</span>
<span class="gi">+    real.write_binary(b&quot;0123456789&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    m.pipe(&quot;afile&quot;, b&quot;hello&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # local URLs are file:// by default</span>
<span class="gi">+    refs = {</span>
<span class="gi">+        &quot;a&quot;: b&quot;data&quot;,</span>
<span class="gi">+        &quot;b&quot;: (f&quot;file://{real}&quot;, 0, 5),</span>
<span class="gi">+        &quot;c/d&quot;: (f&quot;file://{real}&quot;, 1, 6),</span>
<span class="gi">+        &quot;c/e&quot;: [&quot;memory://afile&quot;],</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo=refs, fs={&quot;file&quot;: {}, &quot;memory&quot;: {}})</span>
<span class="gi">+    assert fs.cat(&quot;c/e&quot;) == b&quot;hello&quot;</span>
<span class="gi">+    assert fs.cat([&quot;c/e&quot;, &quot;a&quot;, &quot;b&quot;]) == {</span>
<span class="gi">+        &quot;a&quot;: b&quot;data&quot;,</span>
<span class="gi">+        &quot;b&quot;: b&quot;01234&quot;,</span>
<span class="gi">+        &quot;c/e&quot;: b&quot;hello&quot;,</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_missing_nonasync(m):</span>
<span class="gi">+    zarr = pytest.importorskip(&quot;zarr&quot;)</span>
<span class="gi">+    zarray = {</span>
<span class="gi">+        &quot;chunks&quot;: [1],</span>
<span class="gi">+        &quot;compressor&quot;: None,</span>
<span class="gi">+        &quot;dtype&quot;: &quot;&lt;f8&quot;,</span>
<span class="gi">+        &quot;fill_value&quot;: &quot;NaN&quot;,</span>
<span class="gi">+        &quot;filters&quot;: [],</span>
<span class="gi">+        &quot;order&quot;: &quot;C&quot;,</span>
<span class="gi">+        &quot;shape&quot;: [10],</span>
<span class="gi">+        &quot;zarr_format&quot;: 2,</span>
<span class="gi">+    }</span>
<span class="gi">+    refs = {&quot;.zarray&quot;: json.dumps(zarray)}</span>
<span class="gi">+</span>
<span class="gi">+    m = fsspec.get_mapper(&quot;reference://&quot;, fo=refs, remote_protocol=&quot;memory&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    a = zarr.open_array(m)</span>
<span class="gi">+    assert str(a[0]) == &quot;nan&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_fss_has_defaults(m):</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo={})</span>
<span class="gi">+    assert None in fs.fss</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo={}, remote_protocol=&quot;memory&quot;)</span>
<span class="gi">+    assert fs.fss[None].protocol == &quot;memory&quot;</span>
<span class="gi">+    assert fs.fss[&quot;memory&quot;].protocol == &quot;memory&quot;</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fs=m, fo={})</span>
<span class="gi">+    assert fs.fss[None] is m</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fs={&quot;memory&quot;: m}, fo={})</span>
<span class="gi">+    assert fs.fss[&quot;memory&quot;] is m</span>
<span class="gi">+    assert fs.fss[None].protocol == (&quot;file&quot;, &quot;local&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fs={None: m}, fo={})</span>
<span class="gi">+    assert fs.fss[None] is m</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo={&quot;key&quot;: [&quot;memory://a&quot;]})</span>
<span class="gi">+    assert fs.fss[None] is fs.fss[&quot;memory&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo={&quot;key&quot;: [&quot;memory://a&quot;], &quot;blah&quot;: [&quot;path&quot;]})</span>
<span class="gi">+    assert fs.fss[None] is fs.fss[&quot;memory&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_merging(m):</span>
<span class="gi">+    m.pipe(&quot;/a&quot;, b&quot;test data&quot;)</span>
<span class="gi">+    other = b&quot;other test data&quot;</span>
<span class="gi">+    m.pipe(&quot;/b&quot;, other)</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;reference&quot;,</span>
<span class="gi">+        fo={</span>
<span class="gi">+            &quot;a&quot;: [&quot;memory://a&quot;, 1, 1],</span>
<span class="gi">+            &quot;b&quot;: [&quot;memory://a&quot;, 2, 1],</span>
<span class="gi">+            &quot;c&quot;: [&quot;memory://b&quot;],</span>
<span class="gi">+            &quot;d&quot;: [&quot;memory://b&quot;, 4, 6],</span>
<span class="gi">+        },</span>
<span class="gi">+    )</span>
<span class="gi">+    out = fs.cat([&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;])</span>
<span class="gi">+    assert out == {&quot;a&quot;: b&quot;e&quot;, &quot;b&quot;: b&quot;s&quot;, &quot;c&quot;: other, &quot;d&quot;: other[4:10]}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_cat_file_ranges(m):</span>
<span class="gi">+    other = b&quot;other test data&quot;</span>
<span class="gi">+    m.pipe(&quot;/b&quot;, other)</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;reference&quot;,</span>
<span class="gi">+        fo={</span>
<span class="gi">+            &quot;c&quot;: [&quot;memory://b&quot;],</span>
<span class="gi">+            &quot;d&quot;: [&quot;memory://b&quot;, 4, 6],</span>
<span class="gi">+        },</span>
<span class="gi">+    )</span>
<span class="gi">+    assert fs.cat_file(&quot;c&quot;) == other</span>
<span class="gi">+    assert fs.cat_file(&quot;c&quot;, start=1) == other[1:]</span>
<span class="gi">+    assert fs.cat_file(&quot;c&quot;, start=-5) == other[-5:]</span>
<span class="gi">+    assert fs.cat_file(&quot;c&quot;, 1, -5) == other[1:-5]</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.cat_file(&quot;d&quot;) == other[4:10]</span>
<span class="gi">+    assert fs.cat_file(&quot;d&quot;, start=1) == other[4:10][1:]</span>
<span class="gi">+    assert fs.cat_file(&quot;d&quot;, start=-5) == other[4:10][-5:]</span>
<span class="gi">+    assert fs.cat_file(&quot;d&quot;, 1, -3) == other[4:10][1:-3]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;fo&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;c&quot;: [&quot;memory://b&quot;],</span>
<span class="gi">+            &quot;d&quot;: [&quot;memory://unknown&quot;, 4, 6],</span>
<span class="gi">+        },</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;c&quot;: [&quot;memory://b&quot;],</span>
<span class="gi">+            &quot;d&quot;: [&quot;//unknown&quot;, 4, 6],</span>
<span class="gi">+        },</span>
<span class="gi">+    ],</span>
<span class="gi">+    ids=[&quot;memory protocol&quot;, &quot;mixed protocols: memory and unspecified&quot;],</span>
<span class="gi">+)</span>
<span class="gi">+def test_cat_missing(m, fo):</span>
<span class="gi">+    other = b&quot;other test data&quot;</span>
<span class="gi">+    m.pipe(&quot;/b&quot;, other)</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;reference&quot;,</span>
<span class="gi">+        fo=fo,</span>
<span class="gi">+    )</span>
<span class="gi">+    with pytest.raises(FileNotFoundError):</span>
<span class="gi">+        fs.cat(&quot;notafile&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(FileNotFoundError):</span>
<span class="gi">+        fs.cat([&quot;notone&quot;, &quot;nottwo&quot;])</span>
<span class="gi">+</span>
<span class="gi">+    mapper = fs.get_mapper(&quot;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(KeyError):</span>
<span class="gi">+        mapper[&quot;notakey&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(KeyError):</span>
<span class="gi">+        mapper.getitems([&quot;notone&quot;, &quot;nottwo&quot;])</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ReferenceNotReachable) as ex:</span>
<span class="gi">+        fs.cat(&quot;d&quot;)</span>
<span class="gi">+    assert ex.value.__cause__</span>
<span class="gi">+    out = fs.cat(&quot;d&quot;, on_error=&quot;return&quot;)</span>
<span class="gi">+    assert isinstance(out, ReferenceNotReachable)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ReferenceNotReachable) as e:</span>
<span class="gi">+        mapper[&quot;d&quot;]</span>
<span class="gi">+    assert &#39;&quot;d&quot;&#39; in str(e.value)</span>
<span class="gi">+    assert &quot;//unknown&quot; in str(e.value)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ReferenceNotReachable):</span>
<span class="gi">+        mapper.getitems([&quot;c&quot;, &quot;d&quot;])</span>
<span class="gi">+</span>
<span class="gi">+    out = mapper.getitems([&quot;c&quot;, &quot;d&quot;], on_error=&quot;return&quot;)</span>
<span class="gi">+    assert isinstance(out[&quot;d&quot;], ReferenceNotReachable)</span>
<span class="gi">+</span>
<span class="gi">+    out = fs.cat([&quot;notone&quot;, &quot;c&quot;, &quot;d&quot;], on_error=&quot;return&quot;)</span>
<span class="gi">+    assert isinstance(out[&quot;notone&quot;], FileNotFoundError)</span>
<span class="gi">+    assert out[&quot;c&quot;] == other</span>
<span class="gi">+    assert isinstance(out[&quot;d&quot;], ReferenceNotReachable)</span>
<span class="gi">+</span>
<span class="gi">+    out = mapper.getitems([&quot;c&quot;, &quot;d&quot;], on_error=&quot;omit&quot;)</span>
<span class="gi">+    assert list(out) == [&quot;c&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_df_single(m):</span>
<span class="gi">+    pd = pytest.importorskip(&quot;pandas&quot;)</span>
<span class="gi">+    pytest.importorskip(&quot;fastparquet&quot;)</span>
<span class="gi">+    data = b&quot;data0data1data2&quot;</span>
<span class="gi">+    m.pipe({&quot;data&quot;: data})</span>
<span class="gi">+    df = pd.DataFrame(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;path&quot;: [None, &quot;memory://data&quot;, &quot;memory://data&quot;],</span>
<span class="gi">+            &quot;offset&quot;: [0, 0, 4],</span>
<span class="gi">+            &quot;size&quot;: [0, 0, 4],</span>
<span class="gi">+            &quot;raw&quot;: [b&quot;raw&quot;, None, None],</span>
<span class="gi">+        }</span>
<span class="gi">+    )</span>
<span class="gi">+    df.to_parquet(&quot;memory://stuff/refs.0.parq&quot;)</span>
<span class="gi">+    m.pipe(</span>
<span class="gi">+        &quot;.zmetadata&quot;,</span>
<span class="gi">+        b&quot;&quot;&quot;{</span>
<span class="gi">+    &quot;metadata&quot;: {</span>
<span class="gi">+        &quot;.zgroup&quot;: {</span>
<span class="gi">+            &quot;zarr_format&quot;: 2</span>
<span class="gi">+        },</span>
<span class="gi">+        &quot;stuff/.zarray&quot;: {</span>
<span class="gi">+            &quot;chunks&quot;: [1],</span>
<span class="gi">+            &quot;compressor&quot;: null,</span>
<span class="gi">+            &quot;dtype&quot;: &quot;i8&quot;,</span>
<span class="gi">+            &quot;filters&quot;: null,</span>
<span class="gi">+            &quot;shape&quot;: [3],</span>
<span class="gi">+            &quot;zarr_format&quot;: 2</span>
<span class="gi">+        }</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;zarr_consolidated_format&quot;: 1,</span>
<span class="gi">+    &quot;record_size&quot;: 10</span>
<span class="gi">+    }</span>
<span class="gi">+    &quot;&quot;&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+    fs = ReferenceFileSystem(fo=&quot;memory:///&quot;, remote_protocol=&quot;memory&quot;)</span>
<span class="gi">+    allfiles = fs.find(&quot;&quot;)</span>
<span class="gi">+    assert &quot;.zmetadata&quot; in allfiles</span>
<span class="gi">+    assert &quot;.zgroup&quot; in allfiles</span>
<span class="gi">+    assert &quot;stuff/2&quot; in allfiles</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.cat(&quot;stuff/0&quot;) == b&quot;raw&quot;</span>
<span class="gi">+    assert fs.cat(&quot;stuff/1&quot;) == data</span>
<span class="gi">+    assert fs.cat(&quot;stuff/2&quot;) == data[4:8]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_df_multi(m):</span>
<span class="gi">+    pd = pytest.importorskip(&quot;pandas&quot;)</span>
<span class="gi">+    pytest.importorskip(&quot;fastparquet&quot;)</span>
<span class="gi">+    data = b&quot;data0data1data2&quot;</span>
<span class="gi">+    m.pipe({&quot;data&quot;: data})</span>
<span class="gi">+    df0 = pd.DataFrame(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;path&quot;: [None, &quot;memory://data&quot;, &quot;memory://data&quot;],</span>
<span class="gi">+            &quot;offset&quot;: [0, 0, 4],</span>
<span class="gi">+            &quot;size&quot;: [0, 0, 4],</span>
<span class="gi">+            &quot;raw&quot;: [b&quot;raw1&quot;, None, None],</span>
<span class="gi">+        }</span>
<span class="gi">+    )</span>
<span class="gi">+    df0.to_parquet(&quot;memory://stuff/refs.0.parq&quot;)</span>
<span class="gi">+    df1 = pd.DataFrame(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;path&quot;: [None, &quot;memory://data&quot;, &quot;memory://data&quot;],</span>
<span class="gi">+            &quot;offset&quot;: [0, 0, 2],</span>
<span class="gi">+            &quot;size&quot;: [0, 0, 2],</span>
<span class="gi">+            &quot;raw&quot;: [b&quot;raw2&quot;, None, None],</span>
<span class="gi">+        }</span>
<span class="gi">+    )</span>
<span class="gi">+    df1.to_parquet(&quot;memory://stuff/refs.1.parq&quot;)</span>
<span class="gi">+    m.pipe(</span>
<span class="gi">+        &quot;.zmetadata&quot;,</span>
<span class="gi">+        b&quot;&quot;&quot;{</span>
<span class="gi">+    &quot;metadata&quot;: {</span>
<span class="gi">+        &quot;.zgroup&quot;: {</span>
<span class="gi">+            &quot;zarr_format&quot;: 2</span>
<span class="gi">+        },</span>
<span class="gi">+        &quot;stuff/.zarray&quot;: {</span>
<span class="gi">+            &quot;chunks&quot;: [1],</span>
<span class="gi">+            &quot;compressor&quot;: null,</span>
<span class="gi">+            &quot;dtype&quot;: &quot;i8&quot;,</span>
<span class="gi">+            &quot;filters&quot;: null,</span>
<span class="gi">+            &quot;shape&quot;: [6],</span>
<span class="gi">+            &quot;zarr_format&quot;: 2</span>
<span class="gi">+        }</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;zarr_consolidated_format&quot;: 1,</span>
<span class="gi">+    &quot;record_size&quot;: 3</span>
<span class="gi">+    }</span>
<span class="gi">+    &quot;&quot;&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+    fs = ReferenceFileSystem(</span>
<span class="gi">+        fo=&quot;memory:///&quot;, remote_protocol=&quot;memory&quot;, skip_instance_cache=True</span>
<span class="gi">+    )</span>
<span class="gi">+    allfiles = fs.find(&quot;&quot;)</span>
<span class="gi">+    assert &quot;.zmetadata&quot; in allfiles</span>
<span class="gi">+    assert &quot;.zgroup&quot; in allfiles</span>
<span class="gi">+    assert &quot;stuff/2&quot; in allfiles</span>
<span class="gi">+    assert &quot;stuff/4&quot; in allfiles</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.cat(&quot;stuff/0&quot;) == b&quot;raw1&quot;</span>
<span class="gi">+    assert fs.cat(&quot;stuff/1&quot;) == data</span>
<span class="gi">+    assert fs.cat(&quot;stuff/2&quot;) == data[4:8]</span>
<span class="gi">+    assert fs.cat(&quot;stuff/3&quot;) == b&quot;raw2&quot;</span>
<span class="gi">+    assert fs.cat(&quot;stuff/4&quot;) == data</span>
<span class="gi">+    assert fs.cat(&quot;stuff/5&quot;) == data[2:4]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mapping_getitems(m):</span>
<span class="gi">+    m.pipe({&quot;a&quot;: b&quot;A&quot;, &quot;b&quot;: b&quot;B&quot;})</span>
<span class="gi">+</span>
<span class="gi">+    refs = {</span>
<span class="gi">+        &quot;a&quot;: [&quot;a&quot;],</span>
<span class="gi">+        &quot;b&quot;: [&quot;b&quot;],</span>
<span class="gi">+    }</span>
<span class="gi">+    h = fsspec.filesystem(&quot;memory&quot;)</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;reference&quot;, fo=refs, fs=h)</span>
<span class="gi">+    mapping = fs.get_mapper(&quot;&quot;)</span>
<span class="gi">+    assert mapping.getitems([&quot;b&quot;, &quot;a&quot;]) == {&quot;a&quot;: b&quot;A&quot;, &quot;b&quot;: b&quot;B&quot;}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_cached(m, tmpdir):</span>
<span class="gi">+    fn = f&quot;{tmpdir}/ref.json&quot;</span>
<span class="gi">+</span>
<span class="gi">+    m.pipe({&quot;a&quot;: b&quot;A&quot;, &quot;b&quot;: b&quot;B&quot;})</span>
<span class="gi">+    m.pipe(&quot;ref.json&quot;, b&quot;&quot;&quot;{&quot;a&quot;: [&quot;a&quot;], &quot;b&quot;: [&quot;b&quot;]}&quot;&quot;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;reference&quot;,</span>
<span class="gi">+        fo=&quot;simplecache::memory://ref.json&quot;,</span>
<span class="gi">+        fs=m,</span>
<span class="gi">+        target_options={&quot;cache_storage&quot;: str(tmpdir), &quot;same_names&quot;: True},</span>
<span class="gi">+    )</span>
<span class="gi">+    assert fs.cat(&quot;a&quot;) == b&quot;A&quot;</span>
<span class="gi">+    assert os.path.exists(fn)</span>
<span class="gi">+</span>
<span class="gi">+    # truncate original file to show we are loading from the cached version</span>
<span class="gi">+    m.pipe(&quot;ref.json&quot;, b&quot;&quot;)</span>
<span class="gi">+    fs = fsspec.filesystem(</span>
<span class="gi">+        &quot;reference&quot;,</span>
<span class="gi">+        fo=&quot;simplecache::memory://ref.json&quot;,</span>
<span class="gi">+        fs=m,</span>
<span class="gi">+        target_options={&quot;cache_storage&quot;: str(tmpdir), &quot;same_names&quot;: True},</span>
<span class="gi">+        skip_instance_cache=True,</span>
<span class="gi">+    )</span>
<span class="gi">+    assert fs.cat(&quot;a&quot;) == b&quot;A&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture()</span>
<span class="gi">+def lazy_refs(m):</span>
<span class="gi">+    zarr = pytest.importorskip(&quot;zarr&quot;)</span>
<span class="gi">+    l = LazyReferenceMapper.create(&quot;memory://refs&quot;, fs=m)</span>
<span class="gi">+    g = zarr.open(l, mode=&quot;w&quot;)</span>
<span class="gi">+    g.create_dataset(name=&quot;data&quot;, shape=(100,), chunks=(10,), dtype=&quot;int64&quot;)</span>
<span class="gi">+    return l</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_append_parquet(lazy_refs, m):</span>
<span class="gi">+    pytest.importorskip(&quot;kerchunk&quot;)</span>
<span class="gi">+    with pytest.raises(KeyError):</span>
<span class="gi">+        lazy_refs[&quot;data/0&quot;]</span>
<span class="gi">+    lazy_refs[&quot;data/0&quot;] = b&quot;data&quot;</span>
<span class="gi">+    assert lazy_refs[&quot;data/0&quot;] == b&quot;data&quot;</span>
<span class="gi">+    lazy_refs.flush()</span>
<span class="gi">+</span>
<span class="gi">+    lazy2 = LazyReferenceMapper(&quot;memory://refs&quot;, fs=m)</span>
<span class="gi">+    assert lazy2[&quot;data/0&quot;] == b&quot;data&quot;</span>
<span class="gi">+    with pytest.raises(KeyError):</span>
<span class="gi">+        lazy_refs[&quot;data/1&quot;]</span>
<span class="gi">+    lazy2[&quot;data/1&quot;] = b&quot;Bdata&quot;</span>
<span class="gi">+    assert lazy2[&quot;data/1&quot;] == b&quot;Bdata&quot;</span>
<span class="gi">+    lazy2.flush()</span>
<span class="gi">+</span>
<span class="gi">+    lazy2 = LazyReferenceMapper(&quot;memory://refs&quot;, fs=m)</span>
<span class="gi">+    assert lazy2[&quot;data/0&quot;] == b&quot;data&quot;</span>
<span class="gi">+    assert lazy2[&quot;data/1&quot;] == b&quot;Bdata&quot;</span>
<span class="gi">+    lazy2[&quot;data/1&quot;] = b&quot;Adata&quot;</span>
<span class="gi">+    del lazy2[&quot;data/0&quot;]</span>
<span class="gi">+    assert lazy2[&quot;data/1&quot;] == b&quot;Adata&quot;</span>
<span class="gi">+    assert &quot;data/0&quot; not in lazy2</span>
<span class="gi">+    lazy2.flush()</span>
<span class="gi">+</span>
<span class="gi">+    lazy2 = LazyReferenceMapper(&quot;memory://refs&quot;, fs=m)</span>
<span class="gi">+    with pytest.raises(KeyError):</span>
<span class="gi">+        lazy2[&quot;data/0&quot;]</span>
<span class="gi">+    assert lazy2[&quot;data/1&quot;] == b&quot;Adata&quot;</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_sftp.py b/fsspec/implementations/tests/test_sftp.py</span>
<span class="gh">index c50f763..b91f0b5 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_sftp.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_sftp.py</span>
<span class="gu">@@ -3,11 +3,231 @@ import shlex</span>
<span class="w"> </span>import subprocess
<span class="w"> </span>import time
<span class="w"> </span>from tarfile import TarFile
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="gd">-pytest.importorskip(&#39;paramiko&#39;)</span>
<span class="gi">+</span>
<span class="gi">+pytest.importorskip(&quot;paramiko&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def stop_docker(name):</span>
<span class="gi">+    cmd = shlex.split(f&#39;docker ps -a -q --filter &quot;name={name}&quot;&#39;)</span>
<span class="gi">+    cid = subprocess.check_output(cmd).strip().decode()</span>
<span class="gi">+    if cid:</span>
<span class="gi">+        subprocess.call([&quot;docker&quot;, &quot;rm&quot;, &quot;-f&quot;, cid])</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture(scope=&quot;module&quot;)</span>
<span class="gi">+def ssh():</span>
<span class="gi">+    try:</span>
<span class="gi">+        pchk = [&quot;docker&quot;, &quot;run&quot;, &quot;--name&quot;, &quot;fsspec_test_sftp&quot;, &quot;hello-world&quot;]</span>
<span class="gi">+        subprocess.check_call(pchk)</span>
<span class="gi">+        stop_docker(&quot;fsspec_test_sftp&quot;)</span>
<span class="gi">+    except (subprocess.CalledProcessError, FileNotFoundError):</span>
<span class="gi">+        pytest.skip(&quot;docker run not available&quot;)</span>
<span class="gi">+        return</span>
<span class="gi">+</span>
<span class="gi">+    # requires docker</span>
<span class="gi">+    cmds = [</span>
<span class="gi">+        r&quot;apt-get update&quot;,</span>
<span class="gi">+        r&quot;apt-get install -y openssh-server&quot;,</span>
<span class="gi">+        r&quot;mkdir /var/run/sshd&quot;,</span>
<span class="gi">+        &quot;bash -c \&quot;echo &#39;root:pass&#39; | chpasswd\&quot;&quot;,</span>
<span class="gi">+        (</span>
<span class="gi">+            r&quot;sed -i &#39;s/PermitRootLogin prohibit-password/PermitRootLogin yes/&#39; &quot;</span>
<span class="gi">+            r&quot;/etc/ssh/sshd_config&quot;</span>
<span class="gi">+        ),</span>
<span class="gi">+        (</span>
<span class="gi">+            r&quot;sed &#39;s@session\s*required\s*pam_loginuid.so@session optional &quot;</span>
<span class="gi">+            r&quot;pam_loginuid.so@g&#39; -i /etc/pam.d/sshd&quot;</span>
<span class="gi">+        ),</span>
<span class="gi">+        r&#39;bash -c &quot;echo \&quot;export VISIBLE=now\&quot; &gt;&gt; /etc/profile&quot;&#39;,</span>
<span class="gi">+        r&quot;/usr/sbin/sshd&quot;,</span>
<span class="gi">+    ]</span>
<span class="gi">+    name = &quot;fsspec_sftp&quot;</span>
<span class="gi">+    stop_docker(name)</span>
<span class="gi">+    cmd = f&quot;docker run -d -p 9200:22 --name {name} ubuntu:16.04 sleep 9000&quot;</span>
<span class="gi">+    try:</span>
<span class="gi">+        cid = subprocess.check_output(shlex.split(cmd)).strip().decode()</span>
<span class="gi">+        for cmd in cmds:</span>
<span class="gi">+            subprocess.call([&quot;docker&quot;, &quot;exec&quot;, cid] + shlex.split(cmd))</span>
<span class="gi">+        time.sleep(1)</span>
<span class="gi">+        yield {</span>
<span class="gi">+            &quot;host&quot;: &quot;localhost&quot;,</span>
<span class="gi">+            &quot;port&quot;: 9200,</span>
<span class="gi">+            &quot;username&quot;: &quot;root&quot;,</span>
<span class="gi">+            &quot;password&quot;: &quot;pass&quot;,</span>
<span class="gi">+        }</span>
<span class="gi">+    finally:</span>
<span class="gi">+        stop_docker(name)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture(scope=&quot;module&quot;)</span>
<span class="gi">+def root_path():</span>
<span class="gi">+    return &quot;/home/someuser/&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_simple(ssh, root_path):</span>
<span class="gi">+    f = fsspec.get_filesystem_class(&quot;sftp&quot;)(**ssh)</span>
<span class="gi">+    f.mkdirs(root_path + &quot;deeper&quot;)</span>
<span class="gi">+    try:</span>
<span class="gi">+        f.touch(root_path + &quot;deeper/afile&quot;)</span>
<span class="gi">+        assert f.find(root_path) == [root_path + &quot;deeper/afile&quot;]</span>
<span class="gi">+        assert f.ls(root_path + &quot;deeper/&quot;) == [root_path + &quot;deeper/afile&quot;]</span>
<span class="gi">+        assert f.info(root_path + &quot;deeper/afile&quot;)[&quot;type&quot;] == &quot;file&quot;</span>
<span class="gi">+        assert f.info(root_path + &quot;deeper/afile&quot;)[&quot;size&quot;] == 0</span>
<span class="gi">+        assert f.exists(root_path)</span>
<span class="gi">+    finally:</span>
<span class="gi">+        f.rm(root_path, recursive=True)</span>
<span class="gi">+        assert not f.exists(root_path)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;protocol&quot;, [&quot;sftp&quot;, &quot;ssh&quot;])</span>
<span class="gi">+def test_with_url(protocol, ssh):</span>
<span class="gi">+    fo = fsspec.open(</span>
<span class="gi">+        protocol</span>
<span class="gi">+        + &quot;://{username}:{password}@{host}:{port}/home/someuserout&quot;.format(**ssh),</span>
<span class="gi">+        &quot;wb&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+    with fo as f:</span>
<span class="gi">+        f.write(b&quot;hello&quot;)</span>
<span class="gi">+    fo = fsspec.open(</span>
<span class="gi">+        protocol</span>
<span class="gi">+        + &quot;://{username}:{password}@{host}:{port}/home/someuserout&quot;.format(**ssh),</span>
<span class="gi">+        &quot;rb&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+    with fo as f:</span>
<span class="gi">+        assert f.read() == b&quot;hello&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;protocol&quot;, [&quot;sftp&quot;, &quot;ssh&quot;])</span>
<span class="gi">+def test_get_dir(protocol, ssh, root_path, tmpdir):</span>
<span class="gi">+    path = str(tmpdir)</span>
<span class="gi">+    f = fsspec.filesystem(protocol, **ssh)</span>
<span class="gi">+    f.mkdirs(root_path + &quot;deeper&quot;, exist_ok=True)</span>
<span class="gi">+    f.touch(root_path + &quot;deeper/afile&quot;)</span>
<span class="gi">+    f.get(root_path, path, recursive=True)</span>
<span class="gi">+</span>
<span class="gi">+    assert os.path.isdir(f&quot;{path}/deeper&quot;)</span>
<span class="gi">+    assert os.path.isfile(f&quot;{path}/deeper/afile&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    f.get(</span>
<span class="gi">+        protocol</span>
<span class="gi">+        + &quot;://{username}:{password}@{host}:{port}{root_path}&quot;.format(</span>
<span class="gi">+            root_path=root_path, **ssh</span>
<span class="gi">+        ),</span>
<span class="gi">+        f&quot;{path}/test2&quot;,</span>
<span class="gi">+        recursive=True,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    assert os.path.isdir(f&quot;{path}/test2/deeper&quot;)</span>
<span class="gi">+    assert os.path.isfile(f&quot;{path}/test2/deeper/afile&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture(scope=&quot;module&quot;)</span>
<span class="gi">+def netloc(ssh):</span>
<span class="gi">+    username = ssh.get(&quot;username&quot;)</span>
<span class="gi">+    password = ssh.get(&quot;password&quot;)</span>
<span class="gi">+    host = ssh.get(&quot;host&quot;)</span>
<span class="gi">+    port = ssh.get(&quot;port&quot;)</span>
<span class="gi">+    userpass = (</span>
<span class="gi">+        f&quot;{username}:{password if password is not None else &#39;&#39;}@&quot;</span>
<span class="gi">+        if username is not None</span>
<span class="gi">+        else &quot;&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    netloc = f&quot;{host}:{port if port is not None else &#39;&#39;}&quot;</span>
<span class="gi">+    return userpass + netloc</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_put_file(ssh, tmp_path, root_path):</span>
<span class="gi">+    tmp_file = tmp_path / &quot;a.txt&quot;</span>
<span class="gi">+    with open(tmp_file, mode=&quot;w&quot;) as fd:</span>
<span class="gi">+        fd.write(&quot;blabla&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    f = fsspec.get_filesystem_class(&quot;sftp&quot;)(**ssh)</span>
<span class="gi">+    f.put_file(lpath=tmp_file, rpath=root_path + &quot;a.txt&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_simple_with_tar(ssh, netloc, tmp_path, root_path):</span>
<span class="gi">+    files_to_pack = [&quot;a.txt&quot;, &quot;b.txt&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    tar_filename = make_tarfile(files_to_pack, tmp_path)</span>
<span class="gi">+</span>
<span class="gi">+    f = fsspec.get_filesystem_class(&quot;sftp&quot;)(**ssh)</span>
<span class="gi">+    f.mkdirs(f&quot;{root_path}deeper&quot;, exist_ok=True)</span>
<span class="gi">+    try:</span>
<span class="gi">+        remote_tar_filename = f&quot;{root_path}deeper/somefile.tar&quot;</span>
<span class="gi">+        with f.open(remote_tar_filename, mode=&quot;wb&quot;) as wfd:</span>
<span class="gi">+            with open(tar_filename, mode=&quot;rb&quot;) as rfd:</span>
<span class="gi">+                wfd.write(rfd.read())</span>
<span class="gi">+        fs = fsspec.open(f&quot;tar::ssh://{netloc}{remote_tar_filename}&quot;).fs</span>
<span class="gi">+        files = fs.find(&quot;/&quot;)</span>
<span class="gi">+        assert files == files_to_pack</span>
<span class="gi">+    finally:</span>
<span class="gi">+        f.rm(root_path, recursive=True)</span>


<span class="w"> </span>def make_tarfile(files_to_pack, tmp_path):
<span class="w"> </span>    &quot;&quot;&quot;Create a tarfile with some files.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    tar_filename = tmp_path / &quot;sometarfile.tar&quot;</span>
<span class="gi">+    for filename in files_to_pack:</span>
<span class="gi">+        with open(tmp_path / filename, mode=&quot;w&quot;) as fd:</span>
<span class="gi">+            fd.write(&quot;&quot;)</span>
<span class="gi">+    with TarFile(tar_filename, mode=&quot;w&quot;) as tf:</span>
<span class="gi">+        for filename in files_to_pack:</span>
<span class="gi">+            tf.add(tmp_path / filename, arcname=filename)</span>
<span class="gi">+    return tar_filename</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_transaction(ssh, root_path):</span>
<span class="gi">+    f = fsspec.get_filesystem_class(&quot;sftp&quot;)(**ssh)</span>
<span class="gi">+    f.mkdirs(root_path + &quot;deeper&quot;, exist_ok=True)</span>
<span class="gi">+    try:</span>
<span class="gi">+        f.start_transaction()</span>
<span class="gi">+        f.touch(root_path + &quot;deeper/afile&quot;)</span>
<span class="gi">+        assert f.find(root_path) == []</span>
<span class="gi">+        f.end_transaction()</span>
<span class="gi">+        assert f.find(root_path) == [root_path + &quot;deeper/afile&quot;]</span>
<span class="gi">+</span>
<span class="gi">+        with f.transaction:</span>
<span class="gi">+            assert f._intrans</span>
<span class="gi">+            f.touch(root_path + &quot;deeper/afile2&quot;)</span>
<span class="gi">+            assert f.find(root_path) == [root_path + &quot;deeper/afile&quot;]</span>
<span class="gi">+        assert f.find(root_path) == [</span>
<span class="gi">+            root_path + &quot;deeper/afile&quot;,</span>
<span class="gi">+            root_path + &quot;deeper/afile2&quot;,</span>
<span class="gi">+        ]</span>
<span class="gi">+    finally:</span>
<span class="gi">+        f.rm(root_path, recursive=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;path&quot;, [&quot;/a/b/c&quot;, &quot;a/b/c&quot;])</span>
<span class="gi">+def test_mkdir_create_parent(ssh, path):</span>
<span class="gi">+    f = fsspec.get_filesystem_class(&quot;sftp&quot;)(**ssh)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(FileNotFoundError):</span>
<span class="gi">+        f.mkdir(path, create_parents=False)</span>
<span class="gi">+</span>
<span class="gi">+    f.mkdir(path)</span>
<span class="gi">+    assert f.exists(path)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(FileExistsError, match=path):</span>
<span class="gi">+        f.mkdir(path)</span>
<span class="gi">+</span>
<span class="gi">+    f.rm(path, recursive=True)</span>
<span class="gi">+    assert not f.exists(path)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;path&quot;, [&quot;/a/b/c&quot;, &quot;a/b/c&quot;])</span>
<span class="gi">+def test_makedirs_exist_ok(ssh, path):</span>
<span class="gi">+    f = fsspec.get_filesystem_class(&quot;sftp&quot;)(**ssh)</span>
<span class="gi">+</span>
<span class="gi">+    f.makedirs(path, exist_ok=False)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(FileExistsError, match=path):</span>
<span class="gi">+        f.makedirs(path, exist_ok=False)</span>
<span class="gi">+</span>
<span class="gi">+    f.makedirs(path, exist_ok=True)</span>
<span class="gi">+    f.rm(path, recursive=True)</span>
<span class="gi">+    assert not f.exists(path)</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_smb.py b/fsspec/implementations/tests/test_smb.py</span>
<span class="gh">index 625eb22..68b5957 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_smb.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_smb.py</span>
<span class="gu">@@ -1,16 +1,166 @@</span>
<span class="w"> </span>&quot;&quot;&quot;
<span class="w"> </span>Test SMBFileSystem class using a docker container
<span class="w"> </span>&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>import logging
<span class="w"> </span>import os
<span class="w"> </span>import shlex
<span class="w"> </span>import subprocess
<span class="w"> </span>import time
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="gd">-pytest.importorskip(&#39;smbprotocol&#39;)</span>
<span class="gd">-if os.environ.get(&#39;WSL_INTEROP&#39;):</span>
<span class="gi">+</span>
<span class="gi">+pytest.importorskip(&quot;smbprotocol&quot;)</span>
<span class="gi">+</span>
<span class="gi">+# ruff: noqa: F821</span>
<span class="gi">+</span>
<span class="gi">+if os.environ.get(&quot;WSL_INTEROP&quot;):</span>
<span class="gi">+    # Running on WSL (Windows)</span>
<span class="w"> </span>    port_test = [9999]
<span class="gi">+</span>
<span class="w"> </span>else:
<span class="gi">+    # ! pylint: disable=redefined-outer-name,missing-function-docstring</span>
<span class="gi">+</span>
<span class="gi">+    # Test standard and non-standard ports</span>
<span class="w"> </span>    default_port = 445
<span class="w"> </span>    port_test = [None, default_port, 9999]
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def stop_docker(container):</span>
<span class="gi">+    cmd = shlex.split(&#39;docker ps -a -q --filter &quot;name=%s&quot;&#39; % container)</span>
<span class="gi">+    cid = subprocess.check_output(cmd).strip().decode()</span>
<span class="gi">+    if cid:</span>
<span class="gi">+        subprocess.call([&quot;docker&quot;, &quot;rm&quot;, &quot;-f&quot;, &quot;-v&quot;, cid])</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture(scope=&quot;module&quot;, params=port_test)</span>
<span class="gi">+def smb_params(request):</span>
<span class="gi">+    try:</span>
<span class="gi">+        pchk = [&quot;docker&quot;, &quot;run&quot;, &quot;--name&quot;, &quot;fsspec_test_smb&quot;, &quot;hello-world&quot;]</span>
<span class="gi">+        subprocess.check_call(pchk)</span>
<span class="gi">+        stop_docker(&quot;fsspec_test_smb&quot;)</span>
<span class="gi">+    except (subprocess.CalledProcessError, FileNotFoundError):</span>
<span class="gi">+        pytest.skip(&quot;docker run not available&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # requires docker</span>
<span class="gi">+    container = &quot;fsspec_smb&quot;</span>
<span class="gi">+    stop_docker(container)</span>
<span class="gi">+    cfg = &quot;-p -u &#39;testuser;testpass&#39; -s &#39;home;/share;no;no;no;testuser&#39;&quot;</span>
<span class="gi">+    port = request.param if request.param is not None else default_port</span>
<span class="gi">+    img = (</span>
<span class="gi">+        f&quot;docker run --name {container} --detach -p 139:139 -p {port}:445 dperson/samba&quot;  # noqa: E231 E501</span>
<span class="gi">+    )</span>
<span class="gi">+    cmd = f&quot;{img} {cfg}&quot;</span>
<span class="gi">+    try:</span>
<span class="gi">+        cid = subprocess.check_output(shlex.split(cmd)).strip().decode()</span>
<span class="gi">+        logger = logging.getLogger(&quot;fsspec&quot;)</span>
<span class="gi">+        logger.debug(&quot;Container: %s&quot;, cid)</span>
<span class="gi">+        time.sleep(1)</span>
<span class="gi">+        yield {</span>
<span class="gi">+            &quot;host&quot;: &quot;localhost&quot;,</span>
<span class="gi">+            &quot;port&quot;: request.param,</span>
<span class="gi">+            &quot;username&quot;: &quot;testuser&quot;,</span>
<span class="gi">+            &quot;password&quot;: &quot;testpass&quot;,</span>
<span class="gi">+            &quot;register_session_retries&quot;: 100,  # max ~= 10 seconds</span>
<span class="gi">+        }</span>
<span class="gi">+    finally:</span>
<span class="gi">+        import smbclient  # pylint: disable=import-outside-toplevel</span>
<span class="gi">+</span>
<span class="gi">+        smbclient.reset_connection_cache()</span>
<span class="gi">+        stop_docker(container)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.flaky(reruns=2, reruns_delay=2)</span>
<span class="gi">+def test_simple(smb_params):</span>
<span class="gi">+    adir = &quot;/home/adir&quot;</span>
<span class="gi">+    adir2 = &quot;/home/adir/otherdir/&quot;</span>
<span class="gi">+    afile = &quot;/home/adir/otherdir/afile&quot;</span>
<span class="gi">+    fsmb = fsspec.get_filesystem_class(&quot;smb&quot;)(**smb_params)</span>
<span class="gi">+    fsmb.mkdirs(adir2)</span>
<span class="gi">+    fsmb.touch(afile)</span>
<span class="gi">+    assert fsmb.find(adir) == [afile]</span>
<span class="gi">+    assert fsmb.ls(adir2, detail=False) == [afile]</span>
<span class="gi">+    assert fsmb.info(afile)[&quot;type&quot;] == &quot;file&quot;</span>
<span class="gi">+    assert fsmb.info(afile)[&quot;size&quot;] == 0</span>
<span class="gi">+    assert fsmb.exists(adir)</span>
<span class="gi">+    fsmb.rm(adir, recursive=True)</span>
<span class="gi">+    assert not fsmb.exists(adir)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.flaky(reruns=2, reruns_delay=2)</span>
<span class="gi">+def test_auto_mkdir(smb_params):</span>
<span class="gi">+    adir = &quot;/home/adir&quot;</span>
<span class="gi">+    adir2 = &quot;/home/adir/otherdir/&quot;</span>
<span class="gi">+    afile = &quot;/home/adir/otherdir/afile&quot;</span>
<span class="gi">+    fsmb = fsspec.get_filesystem_class(&quot;smb&quot;)(**smb_params, auto_mkdir=True)</span>
<span class="gi">+    fsmb.touch(afile)</span>
<span class="gi">+    assert fsmb.exists(adir)</span>
<span class="gi">+    assert fsmb.exists(adir2)</span>
<span class="gi">+    assert fsmb.exists(afile)</span>
<span class="gi">+    assert fsmb.info(afile)[&quot;type&quot;] == &quot;file&quot;</span>
<span class="gi">+</span>
<span class="gi">+    another_dir = &quot;/home/another_dir&quot;</span>
<span class="gi">+    another_dir2 = &quot;/home/another_dir/another_nested_dir/&quot;</span>
<span class="gi">+    another_file = &quot;/home/another_dir/another_nested_dir/another_file&quot;</span>
<span class="gi">+    fsmb.copy(afile, another_file)</span>
<span class="gi">+    assert fsmb.exists(another_dir)</span>
<span class="gi">+    assert fsmb.exists(another_dir2)</span>
<span class="gi">+    assert fsmb.exists(another_file)</span>
<span class="gi">+    assert fsmb.info(another_file)[&quot;type&quot;] == &quot;file&quot;</span>
<span class="gi">+</span>
<span class="gi">+    fsmb.rm(adir, recursive=True)</span>
<span class="gi">+    fsmb.rm(another_dir, recursive=True)</span>
<span class="gi">+    assert not fsmb.exists(adir)</span>
<span class="gi">+    assert not fsmb.exists(another_dir)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.flaky(reruns=2, reruns_delay=2)</span>
<span class="gi">+def test_with_url(smb_params):</span>
<span class="gi">+    if smb_params[&quot;port&quot;] is None:</span>
<span class="gi">+        smb_url = &quot;smb://{username}:{password}@{host}/home/someuser.txt&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        smb_url = &quot;smb://{username}:{password}@{host}:{port}/home/someuser.txt&quot;</span>
<span class="gi">+    fwo = fsspec.open(smb_url.format(**smb_params), &quot;wb&quot;)</span>
<span class="gi">+    with fwo as fwr:</span>
<span class="gi">+        fwr.write(b&quot;hello&quot;)</span>
<span class="gi">+    fro = fsspec.open(smb_url.format(**smb_params), &quot;rb&quot;)</span>
<span class="gi">+    with fro as frd:</span>
<span class="gi">+        read_result = frd.read()</span>
<span class="gi">+        assert read_result == b&quot;hello&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.flaky(reruns=2, reruns_delay=2)</span>
<span class="gi">+def test_transaction(smb_params):</span>
<span class="gi">+    afile = &quot;/home/afolder/otherdir/afile&quot;</span>
<span class="gi">+    afile2 = &quot;/home/afolder/otherdir/afile2&quot;</span>
<span class="gi">+    adir = &quot;/home/afolder&quot;</span>
<span class="gi">+    adir2 = &quot;/home/afolder/otherdir&quot;</span>
<span class="gi">+    fsmb = fsspec.get_filesystem_class(&quot;smb&quot;)(**smb_params)</span>
<span class="gi">+    fsmb.mkdirs(adir2)</span>
<span class="gi">+    fsmb.start_transaction()</span>
<span class="gi">+    fsmb.touch(afile)</span>
<span class="gi">+    assert fsmb.find(adir) == []</span>
<span class="gi">+    fsmb.end_transaction()</span>
<span class="gi">+    assert fsmb.find(adir) == [afile]</span>
<span class="gi">+</span>
<span class="gi">+    with fsmb.transaction:</span>
<span class="gi">+        assert fsmb._intrans</span>
<span class="gi">+        fsmb.touch(afile2)</span>
<span class="gi">+        assert fsmb.find(adir) == [afile]</span>
<span class="gi">+    assert fsmb.find(adir) == [afile, afile2]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.flaky(reruns=2, reruns_delay=2)</span>
<span class="gi">+def test_makedirs_exist_ok(smb_params):</span>
<span class="gi">+    fsmb = fsspec.get_filesystem_class(&quot;smb&quot;)(**smb_params)</span>
<span class="gi">+    fsmb.makedirs(&quot;/home/a/b/c&quot;)</span>
<span class="gi">+    fsmb.makedirs(&quot;/home/a/b/c&quot;, exist_ok=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.flaky(reruns=2, reruns_delay=2)</span>
<span class="gi">+def test_rename_from_upath(smb_params):</span>
<span class="gi">+    fsmb = fsspec.get_filesystem_class(&quot;smb&quot;)(**smb_params)</span>
<span class="gi">+    fsmb.makedirs(&quot;/home/a/b/c&quot;, exist_ok=True)</span>
<span class="gi">+    fsmb.mv(&quot;/home/a/b/c&quot;, &quot;/home/a/b/d&quot;, recursive=False, maxdepth=None)</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_tar.py b/fsspec/implementations/tests/test_tar.py</span>
<span class="gh">index 754de3b..0ec7c8a 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_tar.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_tar.py</span>
<span class="gu">@@ -1,11 +1,14 @@</span>
<span class="w"> </span>from __future__ import annotations
<span class="gi">+</span>
<span class="w"> </span>import os
<span class="w"> </span>import shutil
<span class="w"> </span>import tarfile
<span class="w"> </span>import tempfile
<span class="w"> </span>from io import BytesIO
<span class="w"> </span>from pathlib import Path
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="w"> </span>from fsspec.core import OpenFile
<span class="w"> </span>from fsspec.implementations.cached import WholeFileCacheFileSystem
<span class="gu">@@ -13,50 +16,228 @@ from fsspec.implementations.tar import TarFileSystem</span>
<span class="w"> </span>from fsspec.implementations.tests.test_archive import archive_data, temptar


<span class="gd">-@pytest.mark.parametrize(&#39;recipe&#39;, [{&#39;mode&#39;: &#39;w&#39;, &#39;suffix&#39;: &#39;.tar&#39;, &#39;magic&#39;:</span>
<span class="gd">-    b&#39;a\x00\x00\x00\x00&#39;}, {&#39;mode&#39;: &#39;w:gz&#39;, &#39;suffix&#39;: &#39;.tar.gz&#39;, &#39;magic&#39;:</span>
<span class="gd">-    b&#39;\x1f\x8b\x08\x08&#39;}, {&#39;mode&#39;: &#39;w:bz2&#39;, &#39;suffix&#39;: &#39;.tar.bz2&#39;, &#39;magic&#39;:</span>
<span class="gd">-    b&#39;BZh91AY&#39;}, {&#39;mode&#39;: &#39;w:xz&#39;, &#39;suffix&#39;: &#39;.tar.xz&#39;, &#39;magic&#39;:</span>
<span class="gd">-    b&#39;\xfd7zXZ\x00\x00&#39;}], ids=[&#39;tar&#39;, &#39;tar-gz&#39;, &#39;tar-bz2&#39;, &#39;tar-xz&#39;])</span>
<span class="gi">+def test_info():</span>
<span class="gi">+    with temptar(archive_data) as t:</span>
<span class="gi">+        fs = fsspec.filesystem(&quot;tar&quot;, fo=t)</span>
<span class="gi">+</span>
<span class="gi">+        # Iterate over all directories.</span>
<span class="gi">+        # Probe specific fields of Tar archives.</span>
<span class="gi">+        for d in fs._all_dirnames(archive_data.keys()):</span>
<span class="gi">+            lhs = fs.info(d)</span>
<span class="gi">+            del lhs[&quot;chksum&quot;]</span>
<span class="gi">+            expected = {</span>
<span class="gi">+                &quot;name&quot;: f&quot;{d}&quot;,</span>
<span class="gi">+                &quot;size&quot;: 0,</span>
<span class="gi">+                &quot;type&quot;: &quot;directory&quot;,</span>
<span class="gi">+                &quot;devmajor&quot;: 0,</span>
<span class="gi">+                &quot;devminor&quot;: 0,</span>
<span class="gi">+                &quot;gname&quot;: &quot;&quot;,</span>
<span class="gi">+                &quot;linkname&quot;: &quot;&quot;,</span>
<span class="gi">+                &quot;uid&quot;: 0,</span>
<span class="gi">+                &quot;gid&quot;: 0,</span>
<span class="gi">+                &quot;mode&quot;: 420,</span>
<span class="gi">+                &quot;mtime&quot;: 0,</span>
<span class="gi">+                &quot;uname&quot;: &quot;&quot;,</span>
<span class="gi">+            }</span>
<span class="gi">+            assert lhs == expected</span>
<span class="gi">+</span>
<span class="gi">+        # Iterate over all files.</span>
<span class="gi">+        for f in archive_data:</span>
<span class="gi">+            lhs = fs.info(f)</span>
<span class="gi">+</span>
<span class="gi">+            # Probe some specific fields of Tar archives.</span>
<span class="gi">+            assert &quot;mode&quot; in lhs</span>
<span class="gi">+            assert &quot;uid&quot; in lhs</span>
<span class="gi">+            assert &quot;gid&quot; in lhs</span>
<span class="gi">+            assert &quot;mtime&quot; in lhs</span>
<span class="gi">+            assert &quot;chksum&quot; in lhs</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;recipe&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w&quot;, &quot;suffix&quot;: &quot;.tar&quot;, &quot;magic&quot;: b&quot;a\x00\x00\x00\x00&quot;},</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w:gz&quot;, &quot;suffix&quot;: &quot;.tar.gz&quot;, &quot;magic&quot;: b&quot;\x1f\x8b\x08\x08&quot;},</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w:bz2&quot;, &quot;suffix&quot;: &quot;.tar.bz2&quot;, &quot;magic&quot;: b&quot;BZh91AY&quot;},</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w:xz&quot;, &quot;suffix&quot;: &quot;.tar.xz&quot;, &quot;magic&quot;: b&quot;\xfd7zXZ\x00\x00&quot;},</span>
<span class="gi">+    ],</span>
<span class="gi">+    ids=[&quot;tar&quot;, &quot;tar-gz&quot;, &quot;tar-bz2&quot;, &quot;tar-xz&quot;],</span>
<span class="gi">+)</span>
<span class="w"> </span>def test_compressions(recipe):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Run tests on all available tar file compression variants.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    with temptar(archive_data, mode=recipe[&quot;mode&quot;], suffix=recipe[&quot;suffix&quot;]) as t:</span>
<span class="gi">+        fs = fsspec.filesystem(&quot;tar&quot;, fo=t)</span>

<span class="gi">+        # Verify that the tar archive has the correct compression.</span>
<span class="gi">+        with open(t, &quot;rb&quot;) as raw:</span>
<span class="gi">+            assert raw.read()[:10].startswith(recipe[&quot;magic&quot;])</span>

<span class="gd">-@pytest.mark.parametrize(&#39;recipe&#39;, [{&#39;mode&#39;: &#39;w&#39;, &#39;suffix&#39;: &#39;.tar&#39;, &#39;magic&#39;:</span>
<span class="gd">-    b&#39;a\x00\x00\x00\x00&#39;}, {&#39;mode&#39;: &#39;w:gz&#39;, &#39;suffix&#39;: &#39;.tar.gz&#39;, &#39;magic&#39;:</span>
<span class="gd">-    b&#39;\x1f\x8b\x08\x08&#39;}, {&#39;mode&#39;: &#39;w:bz2&#39;, &#39;suffix&#39;: &#39;.tar.bz2&#39;, &#39;magic&#39;:</span>
<span class="gd">-    b&#39;BZh91AY&#39;}, {&#39;mode&#39;: &#39;w:xz&#39;, &#39;suffix&#39;: &#39;.tar.xz&#39;, &#39;magic&#39;:</span>
<span class="gd">-    b&#39;\xfd7zXZ\x00\x00&#39;}], ids=[&#39;tar&#39;, &#39;tar-gz&#39;, &#39;tar-bz2&#39;, &#39;tar-xz&#39;])</span>
<span class="gi">+        # Verify content of a sample file.</span>
<span class="gi">+        assert fs.cat(&quot;b&quot;) == b&quot;hello&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;recipe&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w&quot;, &quot;suffix&quot;: &quot;.tar&quot;, &quot;magic&quot;: b&quot;a\x00\x00\x00\x00&quot;},</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w:gz&quot;, &quot;suffix&quot;: &quot;.tar.gz&quot;, &quot;magic&quot;: b&quot;\x1f\x8b\x08\x08&quot;},</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w:bz2&quot;, &quot;suffix&quot;: &quot;.tar.bz2&quot;, &quot;magic&quot;: b&quot;BZh91AY&quot;},</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w:xz&quot;, &quot;suffix&quot;: &quot;.tar.xz&quot;, &quot;magic&quot;: b&quot;\xfd7zXZ\x00\x00&quot;},</span>
<span class="gi">+    ],</span>
<span class="gi">+    ids=[&quot;tar&quot;, &quot;tar-gz&quot;, &quot;tar-bz2&quot;, &quot;tar-xz&quot;],</span>
<span class="gi">+)</span>
<span class="w"> </span>def test_filesystem_direct(recipe, tmpdir):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Run tests through a real fsspec filesystem implementation.
<span class="w"> </span>    Here: `LocalFileSystem`.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(tmpdir, f&#39;temp{recipe[&quot;suffix&quot;]}&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;file&quot;)</span>
<span class="gi">+    f = OpenFile(fs, filename, mode=&quot;wb&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with temptar(archive_data, mode=recipe[&quot;mode&quot;], suffix=recipe[&quot;suffix&quot;]) as tf:</span>
<span class="gi">+        with f as fo:</span>
<span class="gi">+            fo.write(open(tf, &quot;rb&quot;).read())</span>
<span class="gi">+</span>
<span class="gi">+    # Verify that the tar archive has the correct compression.</span>
<span class="gi">+    with open(filename, &quot;rb&quot;) as raw:</span>
<span class="gi">+        assert raw.read()[:10].startswith(recipe[&quot;magic&quot;])</span>
<span class="gi">+</span>
<span class="gi">+    # Verify content of a sample file.</span>
<span class="gi">+    with fs.open(filename) as resource:</span>
<span class="gi">+        tarfs = fsspec.filesystem(&quot;tar&quot;, fo=resource)</span>
<span class="gi">+        assert tarfs.cat(&quot;b&quot;) == b&quot;hello&quot;</span>


<span class="gd">-@pytest.mark.parametrize(&#39;recipe&#39;, [{&#39;mode&#39;: &#39;w&#39;, &#39;suffix&#39;: &#39;.tar&#39;, &#39;magic&#39;:</span>
<span class="gd">-    b&#39;a\x00\x00\x00\x00&#39;}, {&#39;mode&#39;: &#39;w:gz&#39;, &#39;suffix&#39;: &#39;.tar.gz&#39;, &#39;magic&#39;:</span>
<span class="gd">-    b&#39;\x1f\x8b\x08\x08&#39;}, {&#39;mode&#39;: &#39;w:bz2&#39;, &#39;suffix&#39;: &#39;.tar.bz2&#39;, &#39;magic&#39;:</span>
<span class="gd">-    b&#39;BZh91AY&#39;}, {&#39;mode&#39;: &#39;w:xz&#39;, &#39;suffix&#39;: &#39;.tar.xz&#39;, &#39;magic&#39;:</span>
<span class="gd">-    b&#39;\xfd7zXZ\x00\x00&#39;}], ids=[&#39;tar&#39;, &#39;tar-gz&#39;, &#39;tar-bz2&#39;, &#39;tar-xz&#39;])</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;recipe&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w&quot;, &quot;suffix&quot;: &quot;.tar&quot;, &quot;magic&quot;: b&quot;a\x00\x00\x00\x00&quot;},</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w:gz&quot;, &quot;suffix&quot;: &quot;.tar.gz&quot;, &quot;magic&quot;: b&quot;\x1f\x8b\x08\x08&quot;},</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w:bz2&quot;, &quot;suffix&quot;: &quot;.tar.bz2&quot;, &quot;magic&quot;: b&quot;BZh91AY&quot;},</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w:xz&quot;, &quot;suffix&quot;: &quot;.tar.xz&quot;, &quot;magic&quot;: b&quot;\xfd7zXZ\x00\x00&quot;},</span>
<span class="gi">+    ],</span>
<span class="gi">+    ids=[&quot;tar&quot;, &quot;tar-gz&quot;, &quot;tar-bz2&quot;, &quot;tar-xz&quot;],</span>
<span class="gi">+)</span>
<span class="w"> </span>def test_filesystem_cached(recipe, tmpdir):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Run tests through a real, cached, fsspec filesystem implementation.
<span class="w"> </span>    Here: `TarFileSystem` over `WholeFileCacheFileSystem` over `LocalFileSystem`.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(tmpdir, f&#39;temp{recipe[&quot;suffix&quot;]}&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    # Create a filesystem from test fixture.</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;file&quot;)</span>
<span class="gi">+    f = OpenFile(fs, filename, mode=&quot;wb&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with temptar(archive_data, mode=recipe[&quot;mode&quot;], suffix=recipe[&quot;suffix&quot;]) as tf:</span>
<span class="gi">+        with f as fo:</span>
<span class="gi">+            fo.write(open(tf, &quot;rb&quot;).read())</span>
<span class="gi">+</span>
<span class="gi">+    # Verify that the tar archive has the correct compression.</span>
<span class="gi">+    with open(filename, &quot;rb&quot;) as raw:</span>
<span class="gi">+        assert raw.read()[:10].startswith(recipe[&quot;magic&quot;])</span>
<span class="gi">+</span>
<span class="gi">+    # Access cached filesystem.</span>
<span class="gi">+    cachedir = tempfile.mkdtemp()</span>
<span class="gi">+    filesystem = WholeFileCacheFileSystem(fs=fs, cache_storage=cachedir)</span>
<span class="gi">+</span>
<span class="gi">+    # Verify the cache is empty beforehand.</span>
<span class="gi">+    assert os.listdir(cachedir) == []</span>
<span class="gi">+</span>
<span class="gi">+    # Verify content of a sample file.</span>
<span class="gi">+    with filesystem.open(filename) as resource:</span>
<span class="gi">+        tarfs = fsspec.filesystem(&quot;tar&quot;, fo=resource)</span>
<span class="gi">+        assert tarfs.cat(&quot;b&quot;) == b&quot;hello&quot;</span>
<span class="gi">+</span>
<span class="gi">+    # Verify the cache is populated afterwards.</span>
<span class="gi">+    assert len(os.listdir(cachedir)) == 2</span>
<span class="gi">+</span>
<span class="gi">+    # Verify that the cache is empty after clearing it.</span>
<span class="gi">+    filesystem.clear_cache()</span>
<span class="gi">+    assert os.listdir(cachedir) == []</span>
<span class="gi">+</span>
<span class="gi">+    filesystem.clear_cache()</span>
<span class="gi">+    shutil.rmtree(cachedir)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;recipe&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w&quot;, &quot;suffix&quot;: &quot;.tar&quot;, &quot;magic&quot;: b&quot;a\x00\x00\x00\x00&quot;},</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w:gz&quot;, &quot;suffix&quot;: &quot;.tar.gz&quot;, &quot;magic&quot;: b&quot;\x1f\x8b\x08\x08&quot;},</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w:bz2&quot;, &quot;suffix&quot;: &quot;.tar.bz2&quot;, &quot;magic&quot;: b&quot;BZh91AY&quot;},</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w:xz&quot;, &quot;suffix&quot;: &quot;.tar.xz&quot;, &quot;magic&quot;: b&quot;\xfd7zXZ\x00\x00&quot;},</span>
<span class="gi">+    ],</span>
<span class="gi">+    ids=[&quot;tar&quot;, &quot;tar-gz&quot;, &quot;tar-bz2&quot;, &quot;tar-xz&quot;],</span>
<span class="gi">+)</span>
<span class="gi">+def test_url_to_fs_direct(recipe, tmpdir):</span>
<span class="gi">+    with temptar(archive_data, mode=recipe[&quot;mode&quot;], suffix=recipe[&quot;suffix&quot;]) as tf:</span>
<span class="gi">+        url = f&quot;tar://inner::file://{tf}&quot;</span>
<span class="gi">+        fs, url = fsspec.core.url_to_fs(url=url)</span>
<span class="gi">+        assert fs.cat(&quot;b&quot;) == b&quot;hello&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;recipe&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w&quot;, &quot;suffix&quot;: &quot;.tar&quot;},</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w:gz&quot;, &quot;suffix&quot;: &quot;.tar.gz&quot;},</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w:bz2&quot;, &quot;suffix&quot;: &quot;.tar.bz2&quot;},</span>
<span class="gi">+        {&quot;mode&quot;: &quot;w:xz&quot;, &quot;suffix&quot;: &quot;.tar.xz&quot;},</span>
<span class="gi">+    ],</span>
<span class="gi">+    ids=[&quot;tar&quot;, &quot;tar-gz&quot;, &quot;tar-bz2&quot;, &quot;tar-xz&quot;],</span>
<span class="gi">+)</span>
<span class="gi">+def test_url_to_fs_cached(recipe, tmpdir):</span>
<span class="gi">+    with temptar(archive_data, mode=recipe[&quot;mode&quot;], suffix=recipe[&quot;suffix&quot;]) as tf:</span>
<span class="gi">+        url = f&quot;tar://inner::simplecache::file://{tf}&quot;</span>
<span class="gi">+        # requires same_names in order to be able to guess compression from</span>
<span class="gi">+        # filename</span>
<span class="gi">+        fs, url = fsspec.core.url_to_fs(url=url, simplecache={&quot;same_names&quot;: True})</span>
<span class="gi">+        assert fs.cat(&quot;b&quot;) == b&quot;hello&quot;</span>


<span class="gd">-@pytest.mark.parametrize(&#39;compression&#39;, [&#39;&#39;, &#39;gz&#39;, &#39;bz2&#39;, &#39;xz&#39;], ids=[&#39;tar&#39;,</span>
<span class="gd">-    &#39;tar-gz&#39;, &#39;tar-bz2&#39;, &#39;tar-xz&#39;])</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;compression&quot;, [&quot;&quot;, &quot;gz&quot;, &quot;bz2&quot;, &quot;xz&quot;], ids=[&quot;tar&quot;, &quot;tar-gz&quot;, &quot;tar-bz2&quot;, &quot;tar-xz&quot;]</span>
<span class="gi">+)</span>
<span class="w"> </span>def test_ls_with_folders(compression: str, tmp_path: Path):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Create a tar file that doesn&#39;t include the intermediate folder structure,
<span class="w"> </span>    but make sure that the reading filesystem is still able to resolve the
<span class="w"> </span>    intermediate folders, like the ZipFileSystem.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    tar_data: dict[str, bytes] = {</span>
<span class="gi">+        &quot;a.pdf&quot;: b&quot;Hello A!&quot;,</span>
<span class="gi">+        &quot;b/c.pdf&quot;: b&quot;Hello C!&quot;,</span>
<span class="gi">+        &quot;d/e/f.pdf&quot;: b&quot;Hello F!&quot;,</span>
<span class="gi">+        &quot;d/g.pdf&quot;: b&quot;Hello G!&quot;,</span>
<span class="gi">+    }</span>
<span class="gi">+    if compression:</span>
<span class="gi">+        temp_archive_file = tmp_path / f&quot;test_tar_file.tar.{compression}&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        temp_archive_file = tmp_path / &quot;test_tar_file.tar&quot;</span>
<span class="gi">+    with open(temp_archive_file, &quot;wb&quot;) as fd:</span>
<span class="gi">+        # We need to manually write the tarfile here, because temptar</span>
<span class="gi">+        # creates intermediate directories which is not how tars are always created</span>
<span class="gi">+        with tarfile.open(fileobj=fd, mode=f&quot;w:{compression}&quot;) as tf:</span>
<span class="gi">+            for tar_file_path, data in tar_data.items():</span>
<span class="gi">+                content = data</span>
<span class="gi">+                info = tarfile.TarInfo(name=tar_file_path)</span>
<span class="gi">+                info.size = len(content)</span>
<span class="gi">+                tf.addfile(info, BytesIO(content))</span>
<span class="gi">+    with open(temp_archive_file, &quot;rb&quot;) as fd:</span>
<span class="gi">+        fs = TarFileSystem(fd)</span>
<span class="gi">+        assert fs.find(&quot;/&quot;, withdirs=True) == [</span>
<span class="gi">+            &quot;a.pdf&quot;,</span>
<span class="gi">+            &quot;b&quot;,</span>
<span class="gi">+            &quot;b/c.pdf&quot;,</span>
<span class="gi">+            &quot;d&quot;,</span>
<span class="gi">+            &quot;d/e&quot;,</span>
<span class="gi">+            &quot;d/e/f.pdf&quot;,</span>
<span class="gi">+            &quot;d/g.pdf&quot;,</span>
<span class="gi">+        ]</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_webhdfs.py b/fsspec/implementations/tests/test_webhdfs.py</span>
<span class="gh">index 3b3a915..fac34c7 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_webhdfs.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_webhdfs.py</span>
<span class="gu">@@ -2,7 +2,196 @@ import pickle</span>
<span class="w"> </span>import shlex
<span class="w"> </span>import subprocess
<span class="w"> </span>import time
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="gd">-requests = pytest.importorskip(&#39;requests&#39;)</span>
<span class="gd">-from fsspec.implementations.webhdfs import WebHDFS</span>
<span class="gi">+</span>
<span class="gi">+requests = pytest.importorskip(&quot;requests&quot;)</span>
<span class="gi">+</span>
<span class="gi">+from fsspec.implementations.webhdfs import WebHDFS  # noqa: E402</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture(scope=&quot;module&quot;)</span>
<span class="gi">+def hdfs_cluster():</span>
<span class="gi">+    cmd0 = shlex.split(&quot;htcluster shutdown&quot;)</span>
<span class="gi">+    try:</span>
<span class="gi">+        subprocess.check_output(cmd0, stderr=subprocess.STDOUT)</span>
<span class="gi">+    except FileNotFoundError:</span>
<span class="gi">+        pytest.skip(&quot;htcluster not found&quot;)</span>
<span class="gi">+    except subprocess.CalledProcessError as ex:</span>
<span class="gi">+        pytest.skip(f&quot;htcluster failed: {ex.output.decode()}&quot;)</span>
<span class="gi">+    cmd1 = shlex.split(&quot;htcluster startup --image base&quot;)</span>
<span class="gi">+    subprocess.check_output(cmd1)</span>
<span class="gi">+    try:</span>
<span class="gi">+        while True:</span>
<span class="gi">+            t = 90</span>
<span class="gi">+            try:</span>
<span class="gi">+                requests.get(&quot;http://localhost:50070/webhdfs/v1/?op=LISTSTATUS&quot;)</span>
<span class="gi">+            except:  # noqa: E722</span>
<span class="gi">+                t -= 1</span>
<span class="gi">+                assert t &gt; 0, &quot;Timeout waiting for HDFS&quot;</span>
<span class="gi">+                time.sleep(1)</span>
<span class="gi">+                continue</span>
<span class="gi">+            break</span>
<span class="gi">+        time.sleep(7)</span>
<span class="gi">+        yield &quot;localhost&quot;</span>
<span class="gi">+    finally:</span>
<span class="gi">+        subprocess.check_output(cmd0)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_pickle(hdfs_cluster):</span>
<span class="gi">+    w = WebHDFS(hdfs_cluster, user=&quot;testuser&quot;)</span>
<span class="gi">+    w2 = pickle.loads(pickle.dumps(w))</span>
<span class="gi">+    assert w == w2</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_simple(hdfs_cluster):</span>
<span class="gi">+    w = WebHDFS(hdfs_cluster, user=&quot;testuser&quot;)</span>
<span class="gi">+    home = w.home_directory()</span>
<span class="gi">+    assert home == &quot;/user/testuser&quot;</span>
<span class="gi">+    with pytest.raises(PermissionError):</span>
<span class="gi">+        w.mkdir(&quot;/root&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_url(hdfs_cluster):</span>
<span class="gi">+    url = &quot;webhdfs://testuser@localhost:50070/user/testuser/myfile&quot;</span>
<span class="gi">+    fo = fsspec.open(url, &quot;wb&quot;, data_proxy={&quot;worker.example.com&quot;: &quot;localhost&quot;})</span>
<span class="gi">+    with fo as f:</span>
<span class="gi">+        f.write(b&quot;hello&quot;)</span>
<span class="gi">+    fo = fsspec.open(url, &quot;rb&quot;, data_proxy={&quot;worker.example.com&quot;: &quot;localhost&quot;})</span>
<span class="gi">+    with fo as f:</span>
<span class="gi">+        assert f.read() == b&quot;hello&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_workflow(hdfs_cluster):</span>
<span class="gi">+    w = WebHDFS(</span>
<span class="gi">+        hdfs_cluster, user=&quot;testuser&quot;, data_proxy={&quot;worker.example.com&quot;: &quot;localhost&quot;}</span>
<span class="gi">+    )</span>
<span class="gi">+    fn = &quot;/user/testuser/testrun/afile&quot;</span>
<span class="gi">+    w.mkdir(&quot;/user/testuser/testrun&quot;)</span>
<span class="gi">+    with w.open(fn, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;hello&quot;)</span>
<span class="gi">+    assert w.exists(fn)</span>
<span class="gi">+    info = w.info(fn)</span>
<span class="gi">+    assert info[&quot;size&quot;] == 5</span>
<span class="gi">+    assert w.isfile(fn)</span>
<span class="gi">+    assert w.cat(fn) == b&quot;hello&quot;</span>
<span class="gi">+    w.rm(&quot;/user/testuser/testrun&quot;, recursive=True)</span>
<span class="gi">+    assert not w.exists(fn)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_with_gzip(hdfs_cluster):</span>
<span class="gi">+    from gzip import GzipFile</span>
<span class="gi">+</span>
<span class="gi">+    w = WebHDFS(</span>
<span class="gi">+        hdfs_cluster, user=&quot;testuser&quot;, data_proxy={&quot;worker.example.com&quot;: &quot;localhost&quot;}</span>
<span class="gi">+    )</span>
<span class="gi">+    fn = &quot;/user/testuser/gzfile&quot;</span>
<span class="gi">+    with w.open(fn, &quot;wb&quot;) as f:</span>
<span class="gi">+        gf = GzipFile(fileobj=f, mode=&quot;w&quot;)</span>
<span class="gi">+        gf.write(b&quot;hello&quot;)</span>
<span class="gi">+        gf.close()</span>
<span class="gi">+    with w.open(fn, &quot;rb&quot;) as f:</span>
<span class="gi">+        gf = GzipFile(fileobj=f, mode=&quot;r&quot;)</span>
<span class="gi">+        assert gf.read() == b&quot;hello&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_workflow_transaction(hdfs_cluster):</span>
<span class="gi">+    w = WebHDFS(</span>
<span class="gi">+        hdfs_cluster, user=&quot;testuser&quot;, data_proxy={&quot;worker.example.com&quot;: &quot;localhost&quot;}</span>
<span class="gi">+    )</span>
<span class="gi">+    fn = &quot;/user/testuser/testrun/afile&quot;</span>
<span class="gi">+    w.mkdirs(&quot;/user/testuser/testrun&quot;)</span>
<span class="gi">+    with w.transaction:</span>
<span class="gi">+        with w.open(fn, &quot;wb&quot;) as f:</span>
<span class="gi">+            f.write(b&quot;hello&quot;)</span>
<span class="gi">+        assert not w.exists(fn)</span>
<span class="gi">+    assert w.exists(fn)</span>
<span class="gi">+    assert w.ukey(fn)</span>
<span class="gi">+    files = w.ls(&quot;/user/testuser/testrun&quot;, True)</span>
<span class="gi">+    summ = w.content_summary(&quot;/user/testuser/testrun&quot;)</span>
<span class="gi">+    assert summ[&quot;length&quot;] == files[0][&quot;size&quot;]</span>
<span class="gi">+    assert summ[&quot;fileCount&quot;] == 1</span>
<span class="gi">+</span>
<span class="gi">+    w.rm(&quot;/user/testuser/testrun&quot;, recursive=True)</span>
<span class="gi">+    assert not w.exists(fn)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_webhdfs_cp_file(hdfs_cluster):</span>
<span class="gi">+    fs = WebHDFS(</span>
<span class="gi">+        hdfs_cluster, user=&quot;testuser&quot;, data_proxy={&quot;worker.example.com&quot;: &quot;localhost&quot;}</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    src, dst = &quot;/user/testuser/testrun/f1&quot;, &quot;/user/testuser/testrun/f2&quot;</span>
<span class="gi">+</span>
<span class="gi">+    fs.mkdir(&quot;/user/testuser/testrun&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(src, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;hello&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs.cp_file(src, dst)</span>
<span class="gi">+</span>
<span class="gi">+    assert fs.exists(src)</span>
<span class="gi">+    assert fs.exists(dst)</span>
<span class="gi">+    assert fs.cat(src) == fs.cat(dst)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_path_with_equals(hdfs_cluster):</span>
<span class="gi">+    fs = WebHDFS(</span>
<span class="gi">+        hdfs_cluster, user=&quot;testuser&quot;, data_proxy={&quot;worker.example.com&quot;: &quot;localhost&quot;}</span>
<span class="gi">+    )</span>
<span class="gi">+    path_with_equals = &quot;/user/testuser/some_table/datestamp=2023-11-11&quot;</span>
<span class="gi">+</span>
<span class="gi">+    fs.mkdir(path_with_equals)</span>
<span class="gi">+</span>
<span class="gi">+    result = fs.ls(path_with_equals)</span>
<span class="gi">+    assert result is not None</span>
<span class="gi">+    assert fs.exists(path_with_equals)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_error_handling_with_equals_in_path(hdfs_cluster):</span>
<span class="gi">+    fs = WebHDFS(hdfs_cluster, user=&quot;testuser&quot;)</span>
<span class="gi">+    invalid_path_with_equals = (</span>
<span class="gi">+        &quot;/user/testuser/some_table/invalid_path=datestamp=2023-11-11&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(FileNotFoundError):</span>
<span class="gi">+        fs.ls(invalid_path_with_equals)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_create_and_touch_file_with_equals(hdfs_cluster):</span>
<span class="gi">+    fs = WebHDFS(</span>
<span class="gi">+        hdfs_cluster,</span>
<span class="gi">+        user=&quot;testuser&quot;,</span>
<span class="gi">+        data_proxy={&quot;worker.example.com&quot;: &quot;localhost&quot;},</span>
<span class="gi">+    )</span>
<span class="gi">+    base_path = &quot;/user/testuser/some_table/datestamp=2023-11-11&quot;</span>
<span class="gi">+    file_path = f&quot;{base_path}/testfile.txt&quot;</span>
<span class="gi">+</span>
<span class="gi">+    fs.mkdir(base_path)</span>
<span class="gi">+    fs.touch(file_path, &quot;wb&quot;)</span>
<span class="gi">+    assert fs.exists(file_path)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_write_read_verify_file_with_equals(hdfs_cluster):</span>
<span class="gi">+    fs = WebHDFS(</span>
<span class="gi">+        hdfs_cluster,</span>
<span class="gi">+        user=&quot;testuser&quot;,</span>
<span class="gi">+        data_proxy={&quot;worker.example.com&quot;: &quot;localhost&quot;},</span>
<span class="gi">+    )</span>
<span class="gi">+    base_path = &quot;/user/testuser/some_table/datestamp=2023-11-11&quot;</span>
<span class="gi">+    file_path = f&quot;{base_path}/testfile.txt&quot;</span>
<span class="gi">+    content = b&quot;This is some content!&quot;</span>
<span class="gi">+</span>
<span class="gi">+    fs.mkdir(base_path)</span>
<span class="gi">+    with fs.open(file_path, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(content)</span>
<span class="gi">+</span>
<span class="gi">+    with fs.open(file_path, &quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == content</span>
<span class="gi">+</span>
<span class="gi">+    file_info = fs.ls(base_path, detail=True)</span>
<span class="gi">+    assert len(file_info) == 1</span>
<span class="gi">+    assert file_info[0][&quot;name&quot;] == file_path</span>
<span class="gi">+    assert file_info[0][&quot;size&quot;] == len(content)</span>
<span class="gh">diff --git a/fsspec/implementations/tests/test_zip.py b/fsspec/implementations/tests/test_zip.py</span>
<span class="gh">index c554e22..ec30c87 100644</span>
<span class="gd">--- a/fsspec/implementations/tests/test_zip.py</span>
<span class="gi">+++ b/fsspec/implementations/tests/test_zip.py</span>
<span class="gu">@@ -1,10 +1,134 @@</span>
<span class="w"> </span>import collections.abc
<span class="w"> </span>import os.path
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="w"> </span>from fsspec.implementations.tests.test_archive import archive_data, tempzip


<span class="gi">+def test_info():</span>
<span class="gi">+    with tempzip(archive_data) as z:</span>
<span class="gi">+        fs = fsspec.filesystem(&quot;zip&quot;, fo=z)</span>
<span class="gi">+</span>
<span class="gi">+        # Iterate over all files.</span>
<span class="gi">+        for f in archive_data:</span>
<span class="gi">+            lhs = fs.info(f)</span>
<span class="gi">+</span>
<span class="gi">+            # Probe some specific fields of Zip archives.</span>
<span class="gi">+            assert &quot;CRC&quot; in lhs</span>
<span class="gi">+            assert &quot;compress_size&quot; in lhs</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>def test_fsspec_get_mapper():
<span class="w"> </span>    &quot;&quot;&quot;Added for #788&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    with tempzip(archive_data) as z:</span>
<span class="gi">+        mapping = fsspec.get_mapper(f&quot;zip::{z}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        assert isinstance(mapping, collections.abc.Mapping)</span>
<span class="gi">+        keys = sorted(mapping.keys())</span>
<span class="gi">+        assert keys == [&quot;a&quot;, &quot;b&quot;, &quot;deeply/nested/path&quot;]</span>
<span class="gi">+</span>
<span class="gi">+        # mapping.getitems() will call FSMap.fs.cat()</span>
<span class="gi">+        # which was not accurately implemented for zip.</span>
<span class="gi">+        assert isinstance(mapping, fsspec.mapping.FSMap)</span>
<span class="gi">+        items = dict(mapping.getitems(keys))</span>
<span class="gi">+        assert items == {&quot;a&quot;: b&quot;&quot;, &quot;b&quot;: b&quot;hello&quot;, &quot;deeply/nested/path&quot;: b&quot;stuff&quot;}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_not_cached():</span>
<span class="gi">+    with tempzip(archive_data) as z:</span>
<span class="gi">+        fs = fsspec.filesystem(&quot;zip&quot;, fo=z)</span>
<span class="gi">+        fs2 = fsspec.filesystem(&quot;zip&quot;, fo=z)</span>
<span class="gi">+        assert fs is not fs2</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_root_info():</span>
<span class="gi">+    with tempzip(archive_data) as z:</span>
<span class="gi">+        fs = fsspec.filesystem(&quot;zip&quot;, fo=z)</span>
<span class="gi">+        assert fs.info(&quot;/&quot;) == {&quot;name&quot;: &quot;&quot;, &quot;type&quot;: &quot;directory&quot;, &quot;size&quot;: 0}</span>
<span class="gi">+        assert fs.info(&quot;&quot;) == {&quot;name&quot;: &quot;&quot;, &quot;type&quot;: &quot;directory&quot;, &quot;size&quot;: 0}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_write_seek(m):</span>
<span class="gi">+    with m.open(&quot;afile.zip&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        fs = fsspec.filesystem(&quot;zip&quot;, fo=f, mode=&quot;w&quot;)</span>
<span class="gi">+        fs.pipe(&quot;another&quot;, b&quot;hi&quot;)</span>
<span class="gi">+        fs.zip.close()</span>
<span class="gi">+</span>
<span class="gi">+    with m.open(&quot;afile.zip&quot;, &quot;rb&quot;) as f:</span>
<span class="gi">+        fs = fsspec.filesystem(&quot;zip&quot;, fo=f)</span>
<span class="gi">+        assert fs.cat(&quot;another&quot;) == b&quot;hi&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_rw(m):</span>
<span class="gi">+    # extra arg to zip means &quot;create archive&quot;</span>
<span class="gi">+    with fsspec.open(</span>
<span class="gi">+        &quot;zip://afile::memory://out.zip&quot;, mode=&quot;wb&quot;, zip={&quot;mode&quot;: &quot;w&quot;}</span>
<span class="gi">+    ) as f:</span>
<span class="gi">+        f.write(b&quot;data&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with fsspec.open(&quot;zip://afile::memory://out.zip&quot;, mode=&quot;rb&quot;) as f:</span>
<span class="gi">+        assert f.read() == b&quot;data&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mapper(m):</span>
<span class="gi">+    # extra arg to zip means &quot;create archive&quot;</span>
<span class="gi">+    mapper = fsspec.get_mapper(&quot;zip::memory://out.zip&quot;, zip={&quot;mode&quot;: &quot;w&quot;})</span>
<span class="gi">+    with pytest.raises(KeyError):</span>
<span class="gi">+        mapper[&quot;a&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    mapper[&quot;a&quot;] = b&quot;data&quot;</span>
<span class="gi">+    with pytest.raises(OSError):</span>
<span class="gi">+        # fails because this is write mode and we cannot also read</span>
<span class="gi">+        mapper[&quot;a&quot;]</span>
<span class="gi">+    assert &quot;a&quot; in mapper  # but be can list</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_zip_glob_star(m):</span>
<span class="gi">+    with fsspec.open(</span>
<span class="gi">+        &quot;zip://adir/afile::memory://out.zip&quot;, mode=&quot;wb&quot;, zip={&quot;mode&quot;: &quot;w&quot;}</span>
<span class="gi">+    ) as f:</span>
<span class="gi">+        f.write(b&quot;data&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    fs, _ = fsspec.core.url_to_fs(&quot;zip::memory://out.zip&quot;)</span>
<span class="gi">+    outfiles = fs.glob(&quot;*&quot;)</span>
<span class="gi">+    assert len(outfiles) == 1</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;zip&quot;, fo=&quot;memory://out.zip&quot;, mode=&quot;w&quot;)</span>
<span class="gi">+    fs.mkdir(&quot;adir&quot;)</span>
<span class="gi">+    fs.pipe(&quot;adir/afile&quot;, b&quot;data&quot;)</span>
<span class="gi">+    outfiles = fs.glob(&quot;*&quot;)</span>
<span class="gi">+    assert len(outfiles) == 1</span>
<span class="gi">+</span>
<span class="gi">+    fn = f&quot;{os.path.dirname(os.path.abspath((__file__)))}/out.zip&quot;</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;zip&quot;, fo=fn, mode=&quot;r&quot;)</span>
<span class="gi">+    outfiles = fs.glob(&quot;*&quot;)</span>
<span class="gi">+    assert len(outfiles) == 1</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_append(m, tmpdir):</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;zip&quot;, fo=&quot;memory://out.zip&quot;, mode=&quot;w&quot;)</span>
<span class="gi">+    with fs.open(&quot;afile&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;data&quot;)</span>
<span class="gi">+    fs.close()</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;zip&quot;, fo=&quot;memory://out.zip&quot;, mode=&quot;a&quot;)</span>
<span class="gi">+    with fs.open(&quot;bfile&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;data&quot;)</span>
<span class="gi">+    fs.close()</span>
<span class="gi">+</span>
<span class="gi">+    assert len(fsspec.open_files(&quot;zip://*::memory://out.zip&quot;)) == 2</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;zip&quot;, fo=f&quot;{tmpdir}/out.zip&quot;, mode=&quot;w&quot;)</span>
<span class="gi">+    with fs.open(&quot;afile&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;data&quot;)</span>
<span class="gi">+    fs.close()</span>
<span class="gi">+</span>
<span class="gi">+    fs = fsspec.filesystem(&quot;zip&quot;, fo=f&quot;{tmpdir}/out.zip&quot;, mode=&quot;a&quot;)</span>
<span class="gi">+    with fs.open(&quot;bfile&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        f.write(b&quot;data&quot;)</span>
<span class="gi">+    fs.close()</span>
<span class="gi">+</span>
<span class="gi">+    assert len(fsspec.open_files(&quot;zip://*::memory://out.zip&quot;)) == 2</span>
<span class="gh">diff --git a/fsspec/implementations/webhdfs.py b/fsspec/implementations/webhdfs.py</span>
<span class="gh">index bc3c00b..4bac5d5 100644</span>
<span class="gd">--- a/fsspec/implementations/webhdfs.py</span>
<span class="gi">+++ b/fsspec/implementations/webhdfs.py</span>
<span class="gu">@@ -1,3 +1,5 @@</span>
<span class="gi">+# https://hadoop.apache.org/docs/r1.0.4/webhdfs.html</span>
<span class="gi">+</span>
<span class="w"> </span>import logging
<span class="w"> </span>import os
<span class="w"> </span>import secrets
<span class="gu">@@ -6,10 +8,13 @@ import tempfile</span>
<span class="w"> </span>import uuid
<span class="w"> </span>from contextlib import suppress
<span class="w"> </span>from urllib.parse import quote
<span class="gi">+</span>
<span class="w"> </span>import requests
<span class="gi">+</span>
<span class="w"> </span>from ..spec import AbstractBufferedFile, AbstractFileSystem
<span class="w"> </span>from ..utils import infer_storage_options, tokenize
<span class="gd">-logger = logging.getLogger(&#39;webhdfs&#39;)</span>
<span class="gi">+</span>
<span class="gi">+logger = logging.getLogger(&quot;webhdfs&quot;)</span>


<span class="w"> </span>class WebHDFS(AbstractFileSystem):
<span class="gu">@@ -33,13 +38,26 @@ class WebHDFS(AbstractFileSystem):</span>
<span class="w"> </span>        are provided.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>    tempdir = str(tempfile.gettempdir())
<span class="gd">-    protocol = &#39;webhdfs&#39;, &#39;webHDFS&#39;</span>
<span class="gi">+    protocol = &quot;webhdfs&quot;, &quot;webHDFS&quot;</span>

<span class="gd">-    def __init__(self, host, port=50070, kerberos=False, token=None, user=</span>
<span class="gd">-        None, password=None, proxy_to=None, kerb_kwargs=None, data_proxy=</span>
<span class="gd">-        None, use_https=False, session_cert=None, session_verify=True, **kwargs</span>
<span class="gd">-        ):</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        host,</span>
<span class="gi">+        port=50070,</span>
<span class="gi">+        kerberos=False,</span>
<span class="gi">+        token=None,</span>
<span class="gi">+        user=None,</span>
<span class="gi">+        password=None,</span>
<span class="gi">+        proxy_to=None,</span>
<span class="gi">+        kerb_kwargs=None,</span>
<span class="gi">+        data_proxy=None,</span>
<span class="gi">+        use_https=False,</span>
<span class="gi">+        session_cert=None,</span>
<span class="gi">+        session_verify=True,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Parameters
<span class="w"> </span>        ----------
<span class="gu">@@ -84,8 +102,7 @@ class WebHDFS(AbstractFileSystem):</span>
<span class="w"> </span>        if self._cached:
<span class="w"> </span>            return
<span class="w"> </span>        super().__init__(**kwargs)
<span class="gd">-        self.url = (</span>
<span class="gd">-            f&quot;{&#39;https&#39; if use_https else &#39;http&#39;}://{host}:{port}/webhdfs/v1&quot;)</span>
<span class="gi">+        self.url = f&quot;{&#39;https&#39; if use_https else &#39;http&#39;}://{host}:{port}/webhdfs/v1&quot;  # noqa</span>
<span class="w"> </span>        self.kerb = kerberos
<span class="w"> </span>        self.kerb_kwargs = kerb_kwargs or {}
<span class="w"> </span>        self.pars = {}
<span class="gu">@@ -93,31 +110,103 @@ class WebHDFS(AbstractFileSystem):</span>
<span class="w"> </span>        if token is not None:
<span class="w"> </span>            if user is not None or proxy_to is not None:
<span class="w"> </span>                raise ValueError(
<span class="gd">-                    &#39;If passing a delegation token, must not set user or proxy_to, as these are encoded in the token&#39;</span>
<span class="gd">-                    )</span>
<span class="gd">-            self.pars[&#39;delegation&#39;] = token</span>
<span class="gi">+                    &quot;If passing a delegation token, must not set &quot;</span>
<span class="gi">+                    &quot;user or proxy_to, as these are encoded in the&quot;</span>
<span class="gi">+                    &quot; token&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+            self.pars[&quot;delegation&quot;] = token</span>
<span class="w"> </span>        self.user = user
<span class="w"> </span>        self.password = password
<span class="gi">+</span>
<span class="w"> </span>        if password is not None:
<span class="w"> </span>            if user is None:
<span class="w"> </span>                raise ValueError(
<span class="gd">-                    &#39;If passing a password, the user must also beset in order to set up the basic-auth&#39;</span>
<span class="gd">-                    )</span>
<span class="gd">-        elif user is not None:</span>
<span class="gd">-            self.pars[&#39;user.name&#39;] = user</span>
<span class="gi">+                    &quot;If passing a password, the user must also be&quot;</span>
<span class="gi">+                    &quot;set in order to set up the basic-auth&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+        else:</span>
<span class="gi">+            if user is not None:</span>
<span class="gi">+                self.pars[&quot;user.name&quot;] = user</span>
<span class="gi">+</span>
<span class="w"> </span>        if proxy_to is not None:
<span class="gd">-            self.pars[&#39;doas&#39;] = proxy_to</span>
<span class="gi">+            self.pars[&quot;doas&quot;] = proxy_to</span>
<span class="w"> </span>        if kerberos and user is not None:
<span class="w"> </span>            raise ValueError(
<span class="gd">-                &#39;If using Kerberos auth, do not specify the user, this is handled by kinit.&#39;</span>
<span class="gd">-                )</span>
<span class="gi">+                &quot;If using Kerberos auth, do not specify the &quot;</span>
<span class="gi">+                &quot;user, this is handled by kinit.&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="w"> </span>        self.session_cert = session_cert
<span class="w"> </span>        self.session_verify = session_verify
<span class="gi">+</span>
<span class="w"> </span>        self._connect()
<span class="gd">-        self._fsid = f&#39;webhdfs_{tokenize(host, port)}&#39;</span>

<span class="gd">-    def _open(self, path, mode=&#39;rb&#39;, block_size=None, autocommit=True,</span>
<span class="gd">-        replication=None, permissions=None, **kwargs):</span>
<span class="gi">+        self._fsid = f&quot;webhdfs_{tokenize(host, port)}&quot;</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def fsid(self):</span>
<span class="gi">+        return self._fsid</span>
<span class="gi">+</span>
<span class="gi">+    def _connect(self):</span>
<span class="gi">+        self.session = requests.Session()</span>
<span class="gi">+</span>
<span class="gi">+        if self.session_cert:</span>
<span class="gi">+            self.session.cert = self.session_cert</span>
<span class="gi">+</span>
<span class="gi">+        self.session.verify = self.session_verify</span>
<span class="gi">+</span>
<span class="gi">+        if self.kerb:</span>
<span class="gi">+            from requests_kerberos import HTTPKerberosAuth</span>
<span class="gi">+</span>
<span class="gi">+            self.session.auth = HTTPKerberosAuth(**self.kerb_kwargs)</span>
<span class="gi">+</span>
<span class="gi">+        if self.user is not None and self.password is not None:</span>
<span class="gi">+            from requests.auth import HTTPBasicAuth</span>
<span class="gi">+</span>
<span class="gi">+            self.session.auth = HTTPBasicAuth(self.user, self.password)</span>
<span class="gi">+</span>
<span class="gi">+    def _call(self, op, method=&quot;get&quot;, path=None, data=None, redirect=True, **kwargs):</span>
<span class="gi">+        url = self._apply_proxy(self.url + quote(path or &quot;&quot;, safe=&quot;/=&quot;))</span>
<span class="gi">+        args = kwargs.copy()</span>
<span class="gi">+        args.update(self.pars)</span>
<span class="gi">+        args[&quot;op&quot;] = op.upper()</span>
<span class="gi">+        logger.debug(&quot;sending %s with %s&quot;, url, method)</span>
<span class="gi">+        out = self.session.request(</span>
<span class="gi">+            method=method.upper(),</span>
<span class="gi">+            url=url,</span>
<span class="gi">+            params=args,</span>
<span class="gi">+            data=data,</span>
<span class="gi">+            allow_redirects=redirect,</span>
<span class="gi">+        )</span>
<span class="gi">+        if out.status_code in [400, 401, 403, 404, 500]:</span>
<span class="gi">+            try:</span>
<span class="gi">+                err = out.json()</span>
<span class="gi">+                msg = err[&quot;RemoteException&quot;][&quot;message&quot;]</span>
<span class="gi">+                exp = err[&quot;RemoteException&quot;][&quot;exception&quot;]</span>
<span class="gi">+            except (ValueError, KeyError):</span>
<span class="gi">+                pass</span>
<span class="gi">+            else:</span>
<span class="gi">+                if exp in [&quot;IllegalArgumentException&quot;, &quot;UnsupportedOperationException&quot;]:</span>
<span class="gi">+                    raise ValueError(msg)</span>
<span class="gi">+                elif exp in [&quot;SecurityException&quot;, &quot;AccessControlException&quot;]:</span>
<span class="gi">+                    raise PermissionError(msg)</span>
<span class="gi">+                elif exp in [&quot;FileNotFoundException&quot;]:</span>
<span class="gi">+                    raise FileNotFoundError(msg)</span>
<span class="gi">+                else:</span>
<span class="gi">+                    raise RuntimeError(msg)</span>
<span class="gi">+        out.raise_for_status()</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    def _open(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=None,</span>
<span class="gi">+        autocommit=True,</span>
<span class="gi">+        replication=None,</span>
<span class="gi">+        permissions=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;

<span class="w"> </span>        Parameters
<span class="gu">@@ -141,19 +230,75 @@ class WebHDFS(AbstractFileSystem):</span>
<span class="w"> </span>        -------
<span class="w"> </span>        WebHDFile instance
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        block_size = block_size or self.blocksize</span>
<span class="gi">+        return WebHDFile(</span>
<span class="gi">+            self,</span>
<span class="gi">+            path,</span>
<span class="gi">+            mode=mode,</span>
<span class="gi">+            block_size=block_size,</span>
<span class="gi">+            tempdir=self.tempdir,</span>
<span class="gi">+            autocommit=autocommit,</span>
<span class="gi">+            replication=replication,</span>
<span class="gi">+            permissions=permissions,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _process_info(info):</span>
<span class="gi">+        info[&quot;type&quot;] = info[&quot;type&quot;].lower()</span>
<span class="gi">+        info[&quot;size&quot;] = info[&quot;length&quot;]</span>
<span class="gi">+        return info</span>
<span class="gi">+</span>
<span class="gi">+    @classmethod</span>
<span class="gi">+    def _strip_protocol(cls, path):</span>
<span class="gi">+        return infer_storage_options(path)[&quot;path&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _get_kwargs_from_urls(urlpath):</span>
<span class="gi">+        out = infer_storage_options(urlpath)</span>
<span class="gi">+        out.pop(&quot;path&quot;, None)</span>
<span class="gi">+        out.pop(&quot;protocol&quot;, None)</span>
<span class="gi">+        if &quot;username&quot; in out:</span>
<span class="gi">+            out[&quot;user&quot;] = out.pop(&quot;username&quot;)</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    def info(self, path):</span>
<span class="gi">+        out = self._call(&quot;GETFILESTATUS&quot;, path=path)</span>
<span class="gi">+        info = out.json()[&quot;FileStatus&quot;]</span>
<span class="gi">+        info[&quot;name&quot;] = path</span>
<span class="gi">+        return self._process_info(info)</span>
<span class="gi">+</span>
<span class="gi">+    def ls(self, path, detail=False):</span>
<span class="gi">+        out = self._call(&quot;LISTSTATUS&quot;, path=path)</span>
<span class="gi">+        infos = out.json()[&quot;FileStatuses&quot;][&quot;FileStatus&quot;]</span>
<span class="gi">+        for info in infos:</span>
<span class="gi">+            self._process_info(info)</span>
<span class="gi">+            info[&quot;name&quot;] = path.rstrip(&quot;/&quot;) + &quot;/&quot; + info[&quot;pathSuffix&quot;]</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return sorted(infos, key=lambda i: i[&quot;name&quot;])</span>
<span class="gi">+        else:</span>
<span class="gi">+            return sorted(info[&quot;name&quot;] for info in infos)</span>

<span class="w"> </span>    def content_summary(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Total numbers of files, directories and bytes under path&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        out = self._call(&quot;GETCONTENTSUMMARY&quot;, path=path)</span>
<span class="gi">+        return out.json()[&quot;ContentSummary&quot;]</span>

<span class="w"> </span>    def ukey(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Checksum info of file, giving method and result&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        out = self._call(&quot;GETFILECHECKSUM&quot;, path=path, redirect=False)</span>
<span class="gi">+        if &quot;Location&quot; in out.headers:</span>
<span class="gi">+            location = self._apply_proxy(out.headers[&quot;Location&quot;])</span>
<span class="gi">+            out2 = self.session.get(location)</span>
<span class="gi">+            out2.raise_for_status()</span>
<span class="gi">+            return out2.json()[&quot;FileChecksum&quot;]</span>
<span class="gi">+        else:</span>
<span class="gi">+            out.raise_for_status()</span>
<span class="gi">+            return out.json()[&quot;FileChecksum&quot;]</span>

<span class="w"> </span>    def home_directory(self):
<span class="w"> </span>        &quot;&quot;&quot;Get user&#39;s home directory&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        out = self._call(&quot;GETHOMEDIRECTORY&quot;)</span>
<span class="gi">+        return out.json()[&quot;Path&quot;]</span>

<span class="w"> </span>    def get_delegation_token(self, renewer=None):
<span class="w"> </span>        &quot;&quot;&quot;Retrieve token which can give the same authority to other uses
<span class="gu">@@ -163,15 +308,23 @@ class WebHDFS(AbstractFileSystem):</span>
<span class="w"> </span>        renewer: str or None
<span class="w"> </span>            User who may use this token; if None, will be current user
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if renewer:</span>
<span class="gi">+            out = self._call(&quot;GETDELEGATIONTOKEN&quot;, renewer=renewer)</span>
<span class="gi">+        else:</span>
<span class="gi">+            out = self._call(&quot;GETDELEGATIONTOKEN&quot;)</span>
<span class="gi">+        t = out.json()[&quot;Token&quot;]</span>
<span class="gi">+        if t is None:</span>
<span class="gi">+            raise ValueError(&quot;No token available for this user/security context&quot;)</span>
<span class="gi">+        return t[&quot;urlString&quot;]</span>

<span class="w"> </span>    def renew_delegation_token(self, token):
<span class="w"> </span>        &quot;&quot;&quot;Make token live longer. Returns new expiry time&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        out = self._call(&quot;RENEWDELEGATIONTOKEN&quot;, method=&quot;put&quot;, token=token)</span>
<span class="gi">+        return out.json()[&quot;long&quot;]</span>

<span class="w"> </span>    def cancel_delegation_token(self, token):
<span class="w"> </span>        &quot;&quot;&quot;Stop the token from being useful&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._call(&quot;CANCELDELEGATIONTOKEN&quot;, method=&quot;put&quot;, token=token)</span>

<span class="w"> </span>    def chmod(self, path, mod):
<span class="w"> </span>        &quot;&quot;&quot;Set the permission at path
<span class="gu">@@ -184,11 +337,16 @@ class WebHDFS(AbstractFileSystem):</span>
<span class="w"> </span>            posix epresentation or permission, give as oct string, e.g, &#39;777&#39;
<span class="w"> </span>            or 0o777
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._call(&quot;SETPERMISSION&quot;, method=&quot;put&quot;, path=path, permission=mod)</span>

<span class="w"> </span>    def chown(self, path, owner=None, group=None):
<span class="w"> </span>        &quot;&quot;&quot;Change owning user and/or group&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        kwargs = {}</span>
<span class="gi">+        if owner is not None:</span>
<span class="gi">+            kwargs[&quot;owner&quot;] = owner</span>
<span class="gi">+        if group is not None:</span>
<span class="gi">+            kwargs[&quot;group&quot;] = group</span>
<span class="gi">+        self._call(&quot;SETOWNER&quot;, method=&quot;put&quot;, path=path, **kwargs)</span>

<span class="w"> </span>    def set_replication(self, path, replication):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -202,7 +360,52 @@ class WebHDFS(AbstractFileSystem):</span>
<span class="w"> </span>            Number of copies of file on the cluster. Should be smaller than
<span class="w"> </span>            number of data nodes; normally 3 on most systems.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._call(&quot;SETREPLICATION&quot;, path=path, method=&quot;put&quot;, replication=replication)</span>
<span class="gi">+</span>
<span class="gi">+    def mkdir(self, path, **kwargs):</span>
<span class="gi">+        self._call(&quot;MKDIRS&quot;, method=&quot;put&quot;, path=path)</span>
<span class="gi">+</span>
<span class="gi">+    def makedirs(self, path, exist_ok=False):</span>
<span class="gi">+        if exist_ok is False and self.exists(path):</span>
<span class="gi">+            raise FileExistsError(path)</span>
<span class="gi">+        self.mkdir(path)</span>
<span class="gi">+</span>
<span class="gi">+    def mv(self, path1, path2, **kwargs):</span>
<span class="gi">+        self._call(&quot;RENAME&quot;, method=&quot;put&quot;, path=path1, destination=path2)</span>
<span class="gi">+</span>
<span class="gi">+    def rm(self, path, recursive=False, **kwargs):</span>
<span class="gi">+        self._call(</span>
<span class="gi">+            &quot;DELETE&quot;,</span>
<span class="gi">+            method=&quot;delete&quot;,</span>
<span class="gi">+            path=path,</span>
<span class="gi">+            recursive=&quot;true&quot; if recursive else &quot;false&quot;,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def rm_file(self, path, **kwargs):</span>
<span class="gi">+        self.rm(path)</span>
<span class="gi">+</span>
<span class="gi">+    def cp_file(self, lpath, rpath, **kwargs):</span>
<span class="gi">+        with self.open(lpath) as lstream:</span>
<span class="gi">+            tmp_fname = &quot;/&quot;.join([self._parent(rpath), f&quot;.tmp.{secrets.token_hex(16)}&quot;])</span>
<span class="gi">+            # Perform an atomic copy (stream to a temporary file and</span>
<span class="gi">+            # move it to the actual destination).</span>
<span class="gi">+            try:</span>
<span class="gi">+                with self.open(tmp_fname, &quot;wb&quot;) as rstream:</span>
<span class="gi">+                    shutil.copyfileobj(lstream, rstream)</span>
<span class="gi">+                self.mv(tmp_fname, rpath)</span>
<span class="gi">+            except BaseException:  # noqa</span>
<span class="gi">+                with suppress(FileNotFoundError):</span>
<span class="gi">+                    self.rm(tmp_fname)</span>
<span class="gi">+                raise</span>
<span class="gi">+</span>
<span class="gi">+    def _apply_proxy(self, location):</span>
<span class="gi">+        if self.proxy and callable(self.proxy):</span>
<span class="gi">+            location = self.proxy(location)</span>
<span class="gi">+        elif self.proxy:</span>
<span class="gi">+            # as a dict</span>
<span class="gi">+            for k, v in self.proxy.items():</span>
<span class="gi">+                location = location.replace(k, v, 1)</span>
<span class="gi">+        return location</span>


<span class="w"> </span>class WebHDFile(AbstractBufferedFile):
<span class="gu">@@ -211,13 +414,13 @@ class WebHDFile(AbstractBufferedFile):</span>
<span class="w"> </span>    def __init__(self, fs, path, **kwargs):
<span class="w"> </span>        super().__init__(fs, path, **kwargs)
<span class="w"> </span>        kwargs = kwargs.copy()
<span class="gd">-        if kwargs.get(&#39;permissions&#39;, None) is None:</span>
<span class="gd">-            kwargs.pop(&#39;permissions&#39;, None)</span>
<span class="gd">-        if kwargs.get(&#39;replication&#39;, None) is None:</span>
<span class="gd">-            kwargs.pop(&#39;replication&#39;, None)</span>
<span class="gd">-        self.permissions = kwargs.pop(&#39;permissions&#39;, 511)</span>
<span class="gd">-        tempdir = kwargs.pop(&#39;tempdir&#39;)</span>
<span class="gd">-        if kwargs.pop(&#39;autocommit&#39;, False) is False:</span>
<span class="gi">+        if kwargs.get(&quot;permissions&quot;, None) is None:</span>
<span class="gi">+            kwargs.pop(&quot;permissions&quot;, None)</span>
<span class="gi">+        if kwargs.get(&quot;replication&quot;, None) is None:</span>
<span class="gi">+            kwargs.pop(&quot;replication&quot;, None)</span>
<span class="gi">+        self.permissions = kwargs.pop(&quot;permissions&quot;, 511)</span>
<span class="gi">+        tempdir = kwargs.pop(&quot;tempdir&quot;)</span>
<span class="gi">+        if kwargs.pop(&quot;autocommit&quot;, False) is False:</span>
<span class="w"> </span>            self.target = self.path
<span class="w"> </span>            self.path = os.path.join(tempdir, str(uuid.uuid4()))

<span class="gu">@@ -230,8 +433,52 @@ class WebHDFile(AbstractBufferedFile):</span>
<span class="w"> </span>            This is the last block, so should complete file, if
<span class="w"> </span>            self.autocommit is True.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        out = self.fs.session.post(</span>
<span class="gi">+            self.location,</span>
<span class="gi">+            data=self.buffer.getvalue(),</span>
<span class="gi">+            headers={&quot;content-type&quot;: &quot;application/octet-stream&quot;},</span>
<span class="gi">+        )</span>
<span class="gi">+        out.raise_for_status()</span>
<span class="gi">+        return True</span>

<span class="w"> </span>    def _initiate_upload(self):
<span class="w"> </span>        &quot;&quot;&quot;Create remote file/upload&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        kwargs = self.kwargs.copy()</span>
<span class="gi">+        if &quot;a&quot; in self.mode:</span>
<span class="gi">+            op, method = &quot;APPEND&quot;, &quot;POST&quot;</span>
<span class="gi">+        else:</span>
<span class="gi">+            op, method = &quot;CREATE&quot;, &quot;PUT&quot;</span>
<span class="gi">+            kwargs[&quot;overwrite&quot;] = &quot;true&quot;</span>
<span class="gi">+        out = self.fs._call(op, method, self.path, redirect=False, **kwargs)</span>
<span class="gi">+        location = self.fs._apply_proxy(out.headers[&quot;Location&quot;])</span>
<span class="gi">+        if &quot;w&quot; in self.mode:</span>
<span class="gi">+            # create empty file to append to</span>
<span class="gi">+            out2 = self.fs.session.put(</span>
<span class="gi">+                location, headers={&quot;content-type&quot;: &quot;application/octet-stream&quot;}</span>
<span class="gi">+            )</span>
<span class="gi">+            out2.raise_for_status()</span>
<span class="gi">+            # after creating empty file, change location to append to</span>
<span class="gi">+            out2 = self.fs._call(&quot;APPEND&quot;, &quot;POST&quot;, self.path, redirect=False, **kwargs)</span>
<span class="gi">+            self.location = self.fs._apply_proxy(out2.headers[&quot;Location&quot;])</span>
<span class="gi">+</span>
<span class="gi">+    def _fetch_range(self, start, end):</span>
<span class="gi">+        start = max(start, 0)</span>
<span class="gi">+        end = min(self.size, end)</span>
<span class="gi">+        if start &gt;= end or start &gt;= self.size:</span>
<span class="gi">+            return b&quot;&quot;</span>
<span class="gi">+        out = self.fs._call(</span>
<span class="gi">+            &quot;OPEN&quot;, path=self.path, offset=start, length=end - start, redirect=False</span>
<span class="gi">+        )</span>
<span class="gi">+        out.raise_for_status()</span>
<span class="gi">+        if &quot;Location&quot; in out.headers:</span>
<span class="gi">+            location = out.headers[&quot;Location&quot;]</span>
<span class="gi">+            out2 = self.fs.session.get(self.fs._apply_proxy(location))</span>
<span class="gi">+            return out2.content</span>
<span class="gi">+        else:</span>
<span class="gi">+            return out.content</span>
<span class="gi">+</span>
<span class="gi">+    def commit(self):</span>
<span class="gi">+        self.fs.mv(self.path, self.target)</span>
<span class="gi">+</span>
<span class="gi">+    def discard(self):</span>
<span class="gi">+        self.fs.rm(self.path)</span>
<span class="gh">diff --git a/fsspec/implementations/zip.py b/fsspec/implementations/zip.py</span>
<span class="gh">index b37820c..9d9c046 100644</span>
<span class="gd">--- a/fsspec/implementations/zip.py</span>
<span class="gi">+++ b/fsspec/implementations/zip.py</span>
<span class="gu">@@ -1,4 +1,5 @@</span>
<span class="w"> </span>import zipfile
<span class="gi">+</span>
<span class="w"> </span>import fsspec
<span class="w"> </span>from fsspec.archive import AbstractArchiveFileSystem

<span class="gu">@@ -10,13 +11,22 @@ class ZipFileSystem(AbstractArchiveFileSystem):</span>

<span class="w"> </span>    This class is pickleable, but not necessarily thread-safe
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    root_marker = &#39;&#39;</span>
<span class="gd">-    protocol = &#39;zip&#39;</span>
<span class="gi">+</span>
<span class="gi">+    root_marker = &quot;&quot;</span>
<span class="gi">+    protocol = &quot;zip&quot;</span>
<span class="w"> </span>    cachable = False

<span class="gd">-    def __init__(self, fo=&#39;&#39;, mode=&#39;r&#39;, target_protocol=None,</span>
<span class="gd">-        target_options=None, compression=zipfile.ZIP_STORED, allowZip64=</span>
<span class="gd">-        True, compresslevel=None, **kwargs):</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        fo=&quot;&quot;,</span>
<span class="gi">+        mode=&quot;r&quot;,</span>
<span class="gi">+        target_protocol=None,</span>
<span class="gi">+        target_options=None,</span>
<span class="gi">+        compression=zipfile.ZIP_STORED,</span>
<span class="gi">+        allowZip64=True,</span>
<span class="gi">+        compresslevel=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Parameters
<span class="w"> </span>        ----------
<span class="gu">@@ -35,28 +45,90 @@ class ZipFileSystem(AbstractArchiveFileSystem):</span>
<span class="w"> </span>            Only relevant when creating a ZIP
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        super().__init__(self, **kwargs)
<span class="gd">-        if mode not in set(&#39;rwa&#39;):</span>
<span class="gi">+        if mode not in set(&quot;rwa&quot;):</span>
<span class="w"> </span>            raise ValueError(f&quot;mode &#39;{mode}&#39; no understood&quot;)
<span class="w"> </span>        self.mode = mode
<span class="w"> </span>        if isinstance(fo, str):
<span class="gd">-            if mode == &#39;a&#39;:</span>
<span class="gd">-                m = &#39;r+b&#39;</span>
<span class="gi">+            if mode == &quot;a&quot;:</span>
<span class="gi">+                m = &quot;r+b&quot;</span>
<span class="w"> </span>            else:
<span class="gd">-                m = mode + &#39;b&#39;</span>
<span class="gd">-            fo = fsspec.open(fo, mode=m, protocol=target_protocol, **</span>
<span class="gd">-                target_options or {})</span>
<span class="gi">+                m = mode + &quot;b&quot;</span>
<span class="gi">+            fo = fsspec.open(</span>
<span class="gi">+                fo, mode=m, protocol=target_protocol, **(target_options or {})</span>
<span class="gi">+            )</span>
<span class="w"> </span>        self.force_zip_64 = allowZip64
<span class="w"> </span>        self.of = fo
<span class="gd">-        self.fo = fo.__enter__()</span>
<span class="gd">-        self.zip = zipfile.ZipFile(self.fo, mode=mode, compression=</span>
<span class="gd">-            compression, allowZip64=allowZip64, compresslevel=compresslevel)</span>
<span class="gi">+        self.fo = fo.__enter__()  # the whole instance is a context</span>
<span class="gi">+        self.zip = zipfile.ZipFile(</span>
<span class="gi">+            self.fo,</span>
<span class="gi">+            mode=mode,</span>
<span class="gi">+            compression=compression,</span>
<span class="gi">+            allowZip64=allowZip64,</span>
<span class="gi">+            compresslevel=compresslevel,</span>
<span class="gi">+        )</span>
<span class="w"> </span>        self.dir_cache = None

<span class="gi">+    @classmethod</span>
<span class="gi">+    def _strip_protocol(cls, path):</span>
<span class="gi">+        # zip file paths are always relative to the archive root</span>
<span class="gi">+        return super()._strip_protocol(path).lstrip(&quot;/&quot;)</span>
<span class="gi">+</span>
<span class="w"> </span>    def __del__(self):
<span class="gd">-        if hasattr(self, &#39;zip&#39;):</span>
<span class="gi">+        if hasattr(self, &quot;zip&quot;):</span>
<span class="w"> </span>            self.close()
<span class="w"> </span>            del self.zip

<span class="w"> </span>    def close(self):
<span class="w"> </span>        &quot;&quot;&quot;Commits any write changes to the file. Done on ``del`` too.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.zip.close()</span>
<span class="gi">+</span>
<span class="gi">+    def _get_dirs(self):</span>
<span class="gi">+        if self.dir_cache is None or self.mode in set(&quot;wa&quot;):</span>
<span class="gi">+            # when writing, dir_cache is always in the ZipFile&#39;s attributes,</span>
<span class="gi">+            # not read from the file.</span>
<span class="gi">+            files = self.zip.infolist()</span>
<span class="gi">+            self.dir_cache = {</span>
<span class="gi">+                dirname.rstrip(&quot;/&quot;): {</span>
<span class="gi">+                    &quot;name&quot;: dirname.rstrip(&quot;/&quot;),</span>
<span class="gi">+                    &quot;size&quot;: 0,</span>
<span class="gi">+                    &quot;type&quot;: &quot;directory&quot;,</span>
<span class="gi">+                }</span>
<span class="gi">+                for dirname in self._all_dirnames(self.zip.namelist())</span>
<span class="gi">+            }</span>
<span class="gi">+            for z in files:</span>
<span class="gi">+                f = {s: getattr(z, s, None) for s in zipfile.ZipInfo.__slots__}</span>
<span class="gi">+                f.update(</span>
<span class="gi">+                    {</span>
<span class="gi">+                        &quot;name&quot;: z.filename.rstrip(&quot;/&quot;),</span>
<span class="gi">+                        &quot;size&quot;: z.file_size,</span>
<span class="gi">+                        &quot;type&quot;: (&quot;directory&quot; if z.is_dir() else &quot;file&quot;),</span>
<span class="gi">+                    }</span>
<span class="gi">+                )</span>
<span class="gi">+                self.dir_cache[f[&quot;name&quot;]] = f</span>
<span class="gi">+</span>
<span class="gi">+    def pipe_file(self, path, value, **kwargs):</span>
<span class="gi">+        # override upstream, because we know the exact file size in this case</span>
<span class="gi">+        self.zip.writestr(path, value, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def _open(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=None,</span>
<span class="gi">+        autocommit=True,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if &quot;r&quot; in mode and self.mode in set(&quot;wa&quot;):</span>
<span class="gi">+            if self.exists(path):</span>
<span class="gi">+                raise OSError(&quot;ZipFS can only be open for reading or writing, not both&quot;)</span>
<span class="gi">+            raise FileNotFoundError(path)</span>
<span class="gi">+        if &quot;r&quot; in self.mode and &quot;w&quot; in mode:</span>
<span class="gi">+            raise OSError(&quot;ZipFS can only be open for reading or writing, not both&quot;)</span>
<span class="gi">+        out = self.zip.open(path, mode.strip(&quot;b&quot;), force_zip64=self.force_zip_64)</span>
<span class="gi">+        if &quot;r&quot; in mode:</span>
<span class="gi">+            info = self.info(path)</span>
<span class="gi">+            out.size = info[&quot;size&quot;]</span>
<span class="gi">+            out.name = info[&quot;name&quot;]</span>
<span class="gi">+        return out</span>
<span class="gh">diff --git a/fsspec/json.py b/fsspec/json.py</span>
<span class="gh">index 54f0af3..69cead0 100644</span>
<span class="gd">--- a/fsspec/json.py</span>
<span class="gi">+++ b/fsspec/json.py</span>
<span class="gu">@@ -1,7 +1,18 @@</span>
<span class="w"> </span>import json
<span class="w"> </span>from contextlib import suppress
<span class="w"> </span>from pathlib import PurePath
<span class="gd">-from typing import Any, Callable, ClassVar, Dict, List, Mapping, Optional, Sequence, Tuple</span>
<span class="gi">+from typing import (</span>
<span class="gi">+    Any,</span>
<span class="gi">+    Callable,</span>
<span class="gi">+    ClassVar,</span>
<span class="gi">+    Dict,</span>
<span class="gi">+    List,</span>
<span class="gi">+    Mapping,</span>
<span class="gi">+    Optional,</span>
<span class="gi">+    Sequence,</span>
<span class="gi">+    Tuple,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="w"> </span>from .registry import _import_class, get_filesystem_class
<span class="w"> </span>from .spec import AbstractFileSystem

<span class="gu">@@ -9,30 +20,102 @@ from .spec import AbstractFileSystem</span>
<span class="w"> </span>class FilesystemJSONEncoder(json.JSONEncoder):
<span class="w"> </span>    include_password: ClassVar[bool] = True

<span class="gd">-    def make_serializable(self, obj: Any) -&gt;Any:</span>
<span class="gi">+    def default(self, o: Any) -&gt; Any:</span>
<span class="gi">+        if isinstance(o, AbstractFileSystem):</span>
<span class="gi">+            return o.to_dict(include_password=self.include_password)</span>
<span class="gi">+        if isinstance(o, PurePath):</span>
<span class="gi">+            cls = type(o)</span>
<span class="gi">+            return {&quot;cls&quot;: f&quot;{cls.__module__}.{cls.__name__}&quot;, &quot;str&quot;: str(o)}</span>
<span class="gi">+</span>
<span class="gi">+        return super().default(o)</span>
<span class="gi">+</span>
<span class="gi">+    def make_serializable(self, obj: Any) -&gt; Any:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Recursively converts an object so that it can be JSON serialized via
<span class="w"> </span>        :func:`json.dumps` and :func:`json.dump`, without actually calling
<span class="w"> </span>        said functions.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(obj, (str, int, float, bool)):</span>
<span class="gi">+            return obj</span>
<span class="gi">+        if isinstance(obj, Mapping):</span>
<span class="gi">+            return {k: self.make_serializable(v) for k, v in obj.items()}</span>
<span class="gi">+        if isinstance(obj, Sequence):</span>
<span class="gi">+            return [self.make_serializable(v) for v in obj]</span>

<span class="gi">+        return self.default(obj)</span>

<span class="gd">-class FilesystemJSONDecoder(json.JSONDecoder):</span>

<span class="gd">-    def __init__(self, *, object_hook: Optional[Callable[[Dict[str, Any]],</span>
<span class="gd">-        Any]]=None, parse_float: Optional[Callable[[str], Any]]=None,</span>
<span class="gd">-        parse_int: Optional[Callable[[str], Any]]=None, parse_constant:</span>
<span class="gd">-        Optional[Callable[[str], Any]]=None, strict: bool=True,</span>
<span class="gd">-        object_pairs_hook: Optional[Callable[[List[Tuple[str, Any]]], Any]]</span>
<span class="gd">-        =None) -&gt;None:</span>
<span class="gi">+class FilesystemJSONDecoder(json.JSONDecoder):</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        *,</span>
<span class="gi">+        object_hook: Optional[Callable[[Dict[str, Any]], Any]] = None,</span>
<span class="gi">+        parse_float: Optional[Callable[[str], Any]] = None,</span>
<span class="gi">+        parse_int: Optional[Callable[[str], Any]] = None,</span>
<span class="gi">+        parse_constant: Optional[Callable[[str], Any]] = None,</span>
<span class="gi">+        strict: bool = True,</span>
<span class="gi">+        object_pairs_hook: Optional[Callable[[List[Tuple[str, Any]]], Any]] = None,</span>
<span class="gi">+    ) -&gt; None:</span>
<span class="w"> </span>        self.original_object_hook = object_hook
<span class="gd">-        super().__init__(object_hook=self.custom_object_hook, parse_float=</span>
<span class="gd">-            parse_float, parse_int=parse_int, parse_constant=parse_constant,</span>
<span class="gd">-            strict=strict, object_pairs_hook=object_pairs_hook)</span>

<span class="gd">-    def unmake_serializable(self, obj: Any) -&gt;Any:</span>
<span class="gi">+        super().__init__(</span>
<span class="gi">+            object_hook=self.custom_object_hook,</span>
<span class="gi">+            parse_float=parse_float,</span>
<span class="gi">+            parse_int=parse_int,</span>
<span class="gi">+            parse_constant=parse_constant,</span>
<span class="gi">+            strict=strict,</span>
<span class="gi">+            object_pairs_hook=object_pairs_hook,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    @classmethod</span>
<span class="gi">+    def try_resolve_path_cls(cls, dct: Dict[str, Any]):</span>
<span class="gi">+        with suppress(Exception):</span>
<span class="gi">+            fqp = dct[&quot;cls&quot;]</span>
<span class="gi">+</span>
<span class="gi">+            path_cls = _import_class(fqp)</span>
<span class="gi">+</span>
<span class="gi">+            if issubclass(path_cls, PurePath):</span>
<span class="gi">+                return path_cls</span>
<span class="gi">+</span>
<span class="gi">+        return None</span>
<span class="gi">+</span>
<span class="gi">+    @classmethod</span>
<span class="gi">+    def try_resolve_fs_cls(cls, dct: Dict[str, Any]):</span>
<span class="gi">+        with suppress(Exception):</span>
<span class="gi">+            if &quot;cls&quot; in dct:</span>
<span class="gi">+                try:</span>
<span class="gi">+                    fs_cls = _import_class(dct[&quot;cls&quot;])</span>
<span class="gi">+                    if issubclass(fs_cls, AbstractFileSystem):</span>
<span class="gi">+                        return fs_cls</span>
<span class="gi">+                except Exception:</span>
<span class="gi">+                    if &quot;protocol&quot; in dct:  # Fallback if cls cannot be imported</span>
<span class="gi">+                        return get_filesystem_class(dct[&quot;protocol&quot;])</span>
<span class="gi">+</span>
<span class="gi">+                    raise</span>
<span class="gi">+</span>
<span class="gi">+        return None</span>
<span class="gi">+</span>
<span class="gi">+    def custom_object_hook(self, dct: Dict[str, Any]):</span>
<span class="gi">+        if &quot;cls&quot; in dct:</span>
<span class="gi">+            if (obj_cls := self.try_resolve_fs_cls(dct)) is not None:</span>
<span class="gi">+                return AbstractFileSystem.from_dict(dct)</span>
<span class="gi">+            if (obj_cls := self.try_resolve_path_cls(dct)) is not None:</span>
<span class="gi">+                return obj_cls(dct[&quot;str&quot;])</span>
<span class="gi">+</span>
<span class="gi">+        if self.original_object_hook is not None:</span>
<span class="gi">+            return self.original_object_hook(dct)</span>
<span class="gi">+</span>
<span class="gi">+        return dct</span>
<span class="gi">+</span>
<span class="gi">+    def unmake_serializable(self, obj: Any) -&gt; Any:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Inverse function of :meth:`FilesystemJSONEncoder.make_serializable`.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(obj, dict):</span>
<span class="gi">+            obj = self.custom_object_hook(obj)</span>
<span class="gi">+        if isinstance(obj, dict):</span>
<span class="gi">+            return {k: self.unmake_serializable(v) for k, v in obj.items()}</span>
<span class="gi">+        if isinstance(obj, (list, tuple)):</span>
<span class="gi">+            return [self.unmake_serializable(v) for v in obj]</span>
<span class="gi">+</span>
<span class="gi">+        return obj</span>
<span class="gh">diff --git a/fsspec/mapping.py b/fsspec/mapping.py</span>
<span class="gh">index 05bf237..93ebd1d 100644</span>
<span class="gd">--- a/fsspec/mapping.py</span>
<span class="gi">+++ b/fsspec/mapping.py</span>
<span class="gu">@@ -4,8 +4,10 @@ import posixpath</span>
<span class="w"> </span>import warnings
<span class="w"> </span>from collections.abc import MutableMapping
<span class="w"> </span>from functools import cached_property
<span class="gi">+</span>
<span class="w"> </span>from fsspec.core import url_to_fs
<span class="gd">-logger = logging.getLogger(&#39;fsspec.mapping&#39;)</span>
<span class="gi">+</span>
<span class="gi">+logger = logging.getLogger(&quot;fsspec.mapping&quot;)</span>


<span class="w"> </span>class FSMap(MutableMapping):
<span class="gu">@@ -36,15 +38,16 @@ class FSMap(MutableMapping):</span>
<span class="w"> </span>    b&#39;Hello World&#39;
<span class="w"> </span>    &quot;&quot;&quot;

<span class="gd">-    def __init__(self, root, fs, check=False, create=False,</span>
<span class="gd">-        missing_exceptions=None):</span>
<span class="gi">+    def __init__(self, root, fs, check=False, create=False, missing_exceptions=None):</span>
<span class="w"> </span>        self.fs = fs
<span class="w"> </span>        self.root = fs._strip_protocol(root)
<span class="gd">-        self._root_key_to_str = fs._strip_protocol(posixpath.join(root, &#39;x&#39;))[:</span>
<span class="gd">-            -1]</span>
<span class="gi">+        self._root_key_to_str = fs._strip_protocol(posixpath.join(root, &quot;x&quot;))[:-1]</span>
<span class="w"> </span>        if missing_exceptions is None:
<span class="gd">-            missing_exceptions = (FileNotFoundError, IsADirectoryError,</span>
<span class="gd">-                NotADirectoryError)</span>
<span class="gi">+            missing_exceptions = (</span>
<span class="gi">+                FileNotFoundError,</span>
<span class="gi">+                IsADirectoryError,</span>
<span class="gi">+                NotADirectoryError,</span>
<span class="gi">+            )</span>
<span class="w"> </span>        self.missing_exceptions = missing_exceptions
<span class="w"> </span>        self.check = check
<span class="w"> </span>        self.create = create
<span class="gu">@@ -54,21 +57,29 @@ class FSMap(MutableMapping):</span>
<span class="w"> </span>        if check:
<span class="w"> </span>            if not self.fs.exists(root):
<span class="w"> </span>                raise ValueError(
<span class="gd">-                    f&#39;Path {root} does not exist. Create  with the ``create=True`` keyword&#39;</span>
<span class="gd">-                    )</span>
<span class="gd">-            self.fs.touch(root + &#39;/a&#39;)</span>
<span class="gd">-            self.fs.rm(root + &#39;/a&#39;)</span>
<span class="gi">+                    f&quot;Path {root} does not exist. Create &quot;</span>
<span class="gi">+                    f&quot; with the ``create=True`` keyword&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+            self.fs.touch(root + &quot;/a&quot;)</span>
<span class="gi">+            self.fs.rm(root + &quot;/a&quot;)</span>

<span class="w"> </span>    @cached_property
<span class="w"> </span>    def dirfs(self):
<span class="w"> </span>        &quot;&quot;&quot;dirfs instance that can be used with the same keys as the mapper&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from .implementations.dirfs import DirFileSystem</span>
<span class="gi">+</span>
<span class="gi">+        return DirFileSystem(path=self._root_key_to_str, fs=self.fs)</span>

<span class="w"> </span>    def clear(self):
<span class="w"> </span>        &quot;&quot;&quot;Remove all keys below root - empties out mapping&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        logger.info(&quot;Clear mapping at %s&quot;, self.root)</span>
<span class="gi">+        try:</span>
<span class="gi">+            self.fs.rm(self.root, True)</span>
<span class="gi">+            self.fs.mkdir(self.root)</span>
<span class="gi">+        except:  # noqa: E722</span>
<span class="gi">+            pass</span>

<span class="gd">-    def getitems(self, keys, on_error=&#39;raise&#39;):</span>
<span class="gi">+    def getitems(self, keys, on_error=&quot;raise&quot;):</span>
<span class="w"> </span>        &quot;&quot;&quot;Fetch multiple items from the store

<span class="w"> </span>        If the backend is async-able, this might proceed concurrently
<span class="gu">@@ -88,7 +99,23 @@ class FSMap(MutableMapping):</span>
<span class="w"> </span>        -------
<span class="w"> </span>        dict(key, bytes|exception)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        keys2 = [self._key_to_str(k) for k in keys]</span>
<span class="gi">+        oe = on_error if on_error == &quot;raise&quot; else &quot;return&quot;</span>
<span class="gi">+        try:</span>
<span class="gi">+            out = self.fs.cat(keys2, on_error=oe)</span>
<span class="gi">+            if isinstance(out, bytes):</span>
<span class="gi">+                out = {keys2[0]: out}</span>
<span class="gi">+        except self.missing_exceptions as e:</span>
<span class="gi">+            raise KeyError from e</span>
<span class="gi">+        out = {</span>
<span class="gi">+            k: (KeyError() if isinstance(v, self.missing_exceptions) else v)</span>
<span class="gi">+            for k, v in out.items()</span>
<span class="gi">+        }</span>
<span class="gi">+        return {</span>
<span class="gi">+            key: out[k2]</span>
<span class="gi">+            for key, k2 in zip(keys, keys2)</span>
<span class="gi">+            if on_error == &quot;return&quot; or not isinstance(out[k2], BaseException)</span>
<span class="gi">+        }</span>

<span class="w"> </span>    def setitems(self, values_dict):
<span class="w"> </span>        &quot;&quot;&quot;Set the values of multiple items in the store
<span class="gu">@@ -97,19 +124,29 @@ class FSMap(MutableMapping):</span>
<span class="w"> </span>        ----------
<span class="w"> </span>        values_dict: dict(str, bytes)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        values = {self._key_to_str(k): maybe_convert(v) for k, v in values_dict.items()}</span>
<span class="gi">+        self.fs.pipe(values)</span>

<span class="w"> </span>    def delitems(self, keys):
<span class="w"> </span>        &quot;&quot;&quot;Remove multiple keys from the store&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.fs.rm([self._key_to_str(k) for k in keys])</span>

<span class="w"> </span>    def _key_to_str(self, key):
<span class="w"> </span>        &quot;&quot;&quot;Generate full path for the key&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if not isinstance(key, str):</span>
<span class="gi">+            # raise TypeError(&quot;key must be of type `str`, got `{type(key).__name__}`&quot;</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                &quot;from fsspec 2023.5 onward FSMap non-str keys will raise TypeError&quot;,</span>
<span class="gi">+                DeprecationWarning,</span>
<span class="gi">+            )</span>
<span class="gi">+            if isinstance(key, list):</span>
<span class="gi">+                key = tuple(key)</span>
<span class="gi">+            key = str(key)</span>
<span class="gi">+        return f&quot;{self._root_key_to_str}{key}&quot;.rstrip(&quot;/&quot;)</span>

<span class="w"> </span>    def _str_to_key(self, s):
<span class="w"> </span>        &quot;&quot;&quot;Strip path of to leave key name&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return s[len(self.root) :].lstrip(&quot;/&quot;)</span>

<span class="w"> </span>    def __getitem__(self, key, default=None):
<span class="w"> </span>        &quot;&quot;&quot;Retrieve data&quot;&quot;&quot;
<span class="gu">@@ -124,7 +161,12 @@ class FSMap(MutableMapping):</span>

<span class="w"> </span>    def pop(self, key, default=None):
<span class="w"> </span>        &quot;&quot;&quot;Pop data&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        result = self.__getitem__(key, default)</span>
<span class="gi">+        try:</span>
<span class="gi">+            del self[key]</span>
<span class="gi">+        except KeyError:</span>
<span class="gi">+            pass</span>
<span class="gi">+        return result</span>

<span class="w"> </span>    def __setitem__(self, key, value):
<span class="w"> </span>        &quot;&quot;&quot;Store value in key&quot;&quot;&quot;
<span class="gu">@@ -142,7 +184,7 @@ class FSMap(MutableMapping):</span>
<span class="w"> </span>        &quot;&quot;&quot;Remove key&quot;&quot;&quot;
<span class="w"> </span>        try:
<span class="w"> </span>            self.fs.rm(self._key_to_str(key))
<span class="gd">-        except:</span>
<span class="gi">+        except:  # noqa: E722</span>
<span class="w"> </span>            raise KeyError

<span class="w"> </span>    def __contains__(self, key):
<span class="gu">@@ -151,12 +193,28 @@ class FSMap(MutableMapping):</span>
<span class="w"> </span>        return self.fs.isfile(path)

<span class="w"> </span>    def __reduce__(self):
<span class="gd">-        return FSMap, (self.root, self.fs, False, False, self.</span>
<span class="gd">-            missing_exceptions)</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def get_mapper(url=&#39;&#39;, check=False, create=False, missing_exceptions=None,</span>
<span class="gd">-    alternate_root=None, **kwargs):</span>
<span class="gi">+        return FSMap, (self.root, self.fs, False, False, self.missing_exceptions)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def maybe_convert(value):</span>
<span class="gi">+    if isinstance(value, array.array) or hasattr(value, &quot;__array__&quot;):</span>
<span class="gi">+        # bytes-like things</span>
<span class="gi">+        if hasattr(value, &quot;dtype&quot;) and value.dtype.kind in &quot;Mm&quot;:</span>
<span class="gi">+            # The buffer interface doesn&#39;t support datetime64/timdelta64 numpy</span>
<span class="gi">+            # arrays</span>
<span class="gi">+            value = value.view(&quot;int64&quot;)</span>
<span class="gi">+        value = bytes(memoryview(value))</span>
<span class="gi">+    return value</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def get_mapper(</span>
<span class="gi">+    url=&quot;&quot;,</span>
<span class="gi">+    check=False,</span>
<span class="gi">+    create=False,</span>
<span class="gi">+    missing_exceptions=None,</span>
<span class="gi">+    alternate_root=None,</span>
<span class="gi">+    **kwargs,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;Create key-value interface for given URL and options

<span class="w"> </span>    The URL will be of the form &quot;protocol://location&quot; and point to the root
<span class="gu">@@ -187,4 +245,7 @@ def get_mapper(url=&#39;&#39;, check=False, create=False, missing_exceptions=None,</span>
<span class="w"> </span>    -------
<span class="w"> </span>    ``FSMap`` instance, the dict-like key-value store.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # Removing protocol here - could defer to each open() on the backend</span>
<span class="gi">+    fs, urlpath = url_to_fs(url, **kwargs)</span>
<span class="gi">+    root = alternate_root if alternate_root is not None else urlpath</span>
<span class="gi">+    return FSMap(root, fs, check, create, missing_exceptions=missing_exceptions)</span>
<span class="gh">diff --git a/fsspec/parquet.py b/fsspec/parquet.py</span>
<span class="gh">index be64f8a..5a0fb95 100644</span>
<span class="gd">--- a/fsspec/parquet.py</span>
<span class="gi">+++ b/fsspec/parquet.py</span>
<span class="gu">@@ -1,13 +1,34 @@</span>
<span class="w"> </span>import io
<span class="w"> </span>import json
<span class="w"> </span>import warnings
<span class="gi">+</span>
<span class="w"> </span>from .core import url_to_fs
<span class="w"> </span>from .utils import merge_offset_ranges

<span class="gi">+# Parquet-Specific Utilities for fsspec</span>
<span class="gi">+#</span>
<span class="gi">+# Most of the functions defined in this module are NOT</span>
<span class="gi">+# intended for public consumption. The only exception</span>
<span class="gi">+# to this is `open_parquet_file`, which should be used</span>
<span class="gi">+# place of `fs.open()` to open parquet-formatted files</span>
<span class="gi">+# on remote file systems.</span>
<span class="gi">+</span>

<span class="gd">-def open_parquet_file(path, mode=&#39;rb&#39;, fs=None, metadata=None, columns=None,</span>
<span class="gd">-    row_groups=None, storage_options=None, strict=False, engine=&#39;auto&#39;,</span>
<span class="gd">-    max_gap=64000, max_block=256000000, footer_sample_size=1000000, **kwargs):</span>
<span class="gi">+def open_parquet_file(</span>
<span class="gi">+    path,</span>
<span class="gi">+    mode=&quot;rb&quot;,</span>
<span class="gi">+    fs=None,</span>
<span class="gi">+    metadata=None,</span>
<span class="gi">+    columns=None,</span>
<span class="gi">+    row_groups=None,</span>
<span class="gi">+    storage_options=None,</span>
<span class="gi">+    strict=False,</span>
<span class="gi">+    engine=&quot;auto&quot;,</span>
<span class="gi">+    max_gap=64_000,</span>
<span class="gi">+    max_block=256_000_000,</span>
<span class="gi">+    footer_sample_size=1_000_000,</span>
<span class="gi">+    **kwargs,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Return a file-like object for a single Parquet file.

<span class="gu">@@ -71,40 +92,450 @@ def open_parquet_file(path, mode=&#39;rb&#39;, fs=None, metadata=None, columns=None,</span>
<span class="w"> </span>    **kwargs :
<span class="w"> </span>        Optional key-word arguments to pass to `fs.open`
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>

<span class="gi">+    # Make sure we have an `AbstractFileSystem` object</span>
<span class="gi">+    # to work with</span>
<span class="gi">+    if fs is None:</span>
<span class="gi">+        fs = url_to_fs(path, **(storage_options or {}))[0]</span>
<span class="gi">+</span>
<span class="gi">+    # For now, `columns == []` not supported. Just use</span>
<span class="gi">+    # default `open` command with `path` input</span>
<span class="gi">+    if columns is not None and len(columns) == 0:</span>
<span class="gi">+        return fs.open(path, mode=mode)</span>
<span class="gi">+</span>
<span class="gi">+    # Set the engine</span>
<span class="gi">+    engine = _set_engine(engine)</span>
<span class="gi">+</span>
<span class="gi">+    # Fetch the known byte ranges needed to read</span>
<span class="gi">+    # `columns` and/or `row_groups`</span>
<span class="gi">+    data = _get_parquet_byte_ranges(</span>
<span class="gi">+        [path],</span>
<span class="gi">+        fs,</span>
<span class="gi">+        metadata=metadata,</span>
<span class="gi">+        columns=columns,</span>
<span class="gi">+        row_groups=row_groups,</span>
<span class="gi">+        engine=engine,</span>
<span class="gi">+        max_gap=max_gap,</span>
<span class="gi">+        max_block=max_block,</span>
<span class="gi">+        footer_sample_size=footer_sample_size,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    # Extract file name from `data`</span>
<span class="gi">+    fn = next(iter(data)) if data else path</span>

<span class="gd">-def _get_parquet_byte_ranges(paths, fs, metadata=None, columns=None,</span>
<span class="gd">-    row_groups=None, max_gap=64000, max_block=256000000, footer_sample_size</span>
<span class="gd">-    =1000000, engine=&#39;auto&#39;):</span>
<span class="gi">+    # Call self.open with &quot;parts&quot; caching</span>
<span class="gi">+    options = kwargs.pop(&quot;cache_options&quot;, {}).copy()</span>
<span class="gi">+    return fs.open(</span>
<span class="gi">+        fn,</span>
<span class="gi">+        mode=mode,</span>
<span class="gi">+        cache_type=&quot;parts&quot;,</span>
<span class="gi">+        cache_options={</span>
<span class="gi">+            **options,</span>
<span class="gi">+            &quot;data&quot;: data.get(fn, {}),</span>
<span class="gi">+            &quot;strict&quot;: strict,</span>
<span class="gi">+        },</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _get_parquet_byte_ranges(</span>
<span class="gi">+    paths,</span>
<span class="gi">+    fs,</span>
<span class="gi">+    metadata=None,</span>
<span class="gi">+    columns=None,</span>
<span class="gi">+    row_groups=None,</span>
<span class="gi">+    max_gap=64_000,</span>
<span class="gi">+    max_block=256_000_000,</span>
<span class="gi">+    footer_sample_size=1_000_000,</span>
<span class="gi">+    engine=&quot;auto&quot;,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;Get a dictionary of the known byte ranges needed
<span class="w"> </span>    to read a specific column/row-group selection from a
<span class="w"> </span>    Parquet dataset. Each value in the output dictionary
<span class="w"> </span>    is intended for use as the `data` argument for the
<span class="w"> </span>    `KnownPartsOfAFile` caching strategy of a single path.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>

<span class="gi">+    # Set engine if necessary</span>
<span class="gi">+    if isinstance(engine, str):</span>
<span class="gi">+        engine = _set_engine(engine)</span>
<span class="gi">+</span>
<span class="gi">+    # Pass to specialized function if metadata is defined</span>
<span class="gi">+    if metadata is not None:</span>
<span class="gi">+        # Use the provided parquet metadata object</span>
<span class="gi">+        # to avoid transferring/parsing footer metadata</span>
<span class="gi">+        return _get_parquet_byte_ranges_from_metadata(</span>
<span class="gi">+            metadata,</span>
<span class="gi">+            fs,</span>
<span class="gi">+            engine,</span>
<span class="gi">+            columns=columns,</span>
<span class="gi">+            row_groups=row_groups,</span>
<span class="gi">+            max_gap=max_gap,</span>
<span class="gi">+            max_block=max_block,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    # Get file sizes asynchronously</span>
<span class="gi">+    file_sizes = fs.sizes(paths)</span>
<span class="gi">+</span>
<span class="gi">+    # Populate global paths, starts, &amp; ends</span>
<span class="gi">+    result = {}</span>
<span class="gi">+    data_paths = []</span>
<span class="gi">+    data_starts = []</span>
<span class="gi">+    data_ends = []</span>
<span class="gi">+    add_header_magic = True</span>
<span class="gi">+    if columns is None and row_groups is None:</span>
<span class="gi">+        # We are NOT selecting specific columns or row-groups.</span>
<span class="gi">+        #</span>
<span class="gi">+        # We can avoid sampling the footers, and just transfer</span>
<span class="gi">+        # all file data with cat_ranges</span>
<span class="gi">+        for i, path in enumerate(paths):</span>
<span class="gi">+            result[path] = {}</span>
<span class="gi">+            for b in range(0, file_sizes[i], max_block):</span>
<span class="gi">+                data_paths.append(path)</span>
<span class="gi">+                data_starts.append(b)</span>
<span class="gi">+                data_ends.append(min(b + max_block, file_sizes[i]))</span>
<span class="gi">+        add_header_magic = False  # &quot;Magic&quot; should already be included</span>
<span class="gi">+    else:</span>
<span class="gi">+        # We ARE selecting specific columns or row-groups.</span>
<span class="gi">+        #</span>
<span class="gi">+        # Gather file footers.</span>
<span class="gi">+        # We just take the last `footer_sample_size` bytes of each</span>
<span class="gi">+        # file (or the entire file if it is smaller than that)</span>
<span class="gi">+        footer_starts = []</span>
<span class="gi">+        footer_ends = []</span>
<span class="gi">+        for i, path in enumerate(paths):</span>
<span class="gi">+            footer_ends.append(file_sizes[i])</span>
<span class="gi">+            sample_size = max(0, file_sizes[i] - footer_sample_size)</span>
<span class="gi">+            footer_starts.append(sample_size)</span>
<span class="gi">+        footer_samples = fs.cat_ranges(paths, footer_starts, footer_ends)</span>
<span class="gi">+</span>
<span class="gi">+        # Check our footer samples and re-sample if necessary.</span>
<span class="gi">+        missing_footer_starts = footer_starts.copy()</span>
<span class="gi">+        large_footer = 0</span>
<span class="gi">+        for i, path in enumerate(paths):</span>
<span class="gi">+            footer_size = int.from_bytes(footer_samples[i][-8:-4], &quot;little&quot;)</span>
<span class="gi">+            real_footer_start = file_sizes[i] - (footer_size + 8)</span>
<span class="gi">+            if real_footer_start &lt; footer_starts[i]:</span>
<span class="gi">+                missing_footer_starts[i] = real_footer_start</span>
<span class="gi">+                large_footer = max(large_footer, (footer_size + 8))</span>
<span class="gi">+        if large_footer:</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                f&quot;Not enough data was used to sample the parquet footer. &quot;</span>
<span class="gi">+                f&quot;Try setting footer_sample_size &gt;= {large_footer}.&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+            for i, block in enumerate(</span>
<span class="gi">+                fs.cat_ranges(</span>
<span class="gi">+                    paths,</span>
<span class="gi">+                    missing_footer_starts,</span>
<span class="gi">+                    footer_starts,</span>
<span class="gi">+                )</span>
<span class="gi">+            ):</span>
<span class="gi">+                footer_samples[i] = block + footer_samples[i]</span>
<span class="gi">+                footer_starts[i] = missing_footer_starts[i]</span>

<span class="gd">-def _get_parquet_byte_ranges_from_metadata(metadata, fs, engine, columns=</span>
<span class="gd">-    None, row_groups=None, max_gap=64000, max_block=256000000):</span>
<span class="gi">+        # Calculate required byte ranges for each path</span>
<span class="gi">+        for i, path in enumerate(paths):</span>
<span class="gi">+            # Deal with small-file case.</span>
<span class="gi">+            # Just include all remaining bytes of the file</span>
<span class="gi">+            # in a single range.</span>
<span class="gi">+            if file_sizes[i] &lt; max_block:</span>
<span class="gi">+                if footer_starts[i] &gt; 0:</span>
<span class="gi">+                    # Only need to transfer the data if the</span>
<span class="gi">+                    # footer sample isn&#39;t already the whole file</span>
<span class="gi">+                    data_paths.append(path)</span>
<span class="gi">+                    data_starts.append(0)</span>
<span class="gi">+                    data_ends.append(footer_starts[i])</span>
<span class="gi">+                continue</span>
<span class="gi">+</span>
<span class="gi">+            # Use &quot;engine&quot; to collect data byte ranges</span>
<span class="gi">+            path_data_starts, path_data_ends = engine._parquet_byte_ranges(</span>
<span class="gi">+                columns,</span>
<span class="gi">+                row_groups=row_groups,</span>
<span class="gi">+                footer=footer_samples[i],</span>
<span class="gi">+                footer_start=footer_starts[i],</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            data_paths += [path] * len(path_data_starts)</span>
<span class="gi">+            data_starts += path_data_starts</span>
<span class="gi">+            data_ends += path_data_ends</span>
<span class="gi">+</span>
<span class="gi">+        # Merge adjacent offset ranges</span>
<span class="gi">+        data_paths, data_starts, data_ends = merge_offset_ranges(</span>
<span class="gi">+            data_paths,</span>
<span class="gi">+            data_starts,</span>
<span class="gi">+            data_ends,</span>
<span class="gi">+            max_gap=max_gap,</span>
<span class="gi">+            max_block=max_block,</span>
<span class="gi">+            sort=False,  # Should already be sorted</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        # Start by populating `result` with footer samples</span>
<span class="gi">+        for i, path in enumerate(paths):</span>
<span class="gi">+            result[path] = {(footer_starts[i], footer_ends[i]): footer_samples[i]}</span>
<span class="gi">+</span>
<span class="gi">+    # Transfer the data byte-ranges into local memory</span>
<span class="gi">+    _transfer_ranges(fs, result, data_paths, data_starts, data_ends)</span>
<span class="gi">+</span>
<span class="gi">+    # Add b&quot;PAR1&quot; to header if necessary</span>
<span class="gi">+    if add_header_magic:</span>
<span class="gi">+        _add_header_magic(result)</span>
<span class="gi">+</span>
<span class="gi">+    return result</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _get_parquet_byte_ranges_from_metadata(</span>
<span class="gi">+    metadata,</span>
<span class="gi">+    fs,</span>
<span class="gi">+    engine,</span>
<span class="gi">+    columns=None,</span>
<span class="gi">+    row_groups=None,</span>
<span class="gi">+    max_gap=64_000,</span>
<span class="gi">+    max_block=256_000_000,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;Simplified version of `_get_parquet_byte_ranges` for
<span class="w"> </span>    the case that an engine-specific `metadata` object is
<span class="w"> </span>    provided, and the remote footer metadata does not need to
<span class="w"> </span>    be transferred before calculating the required byte ranges.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    # Use &quot;engine&quot; to collect data byte ranges</span>
<span class="gi">+    data_paths, data_starts, data_ends = engine._parquet_byte_ranges(</span>
<span class="gi">+        columns,</span>
<span class="gi">+        row_groups=row_groups,</span>
<span class="gi">+        metadata=metadata,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    # Merge adjacent offset ranges</span>
<span class="gi">+    data_paths, data_starts, data_ends = merge_offset_ranges(</span>
<span class="gi">+        data_paths,</span>
<span class="gi">+        data_starts,</span>
<span class="gi">+        data_ends,</span>
<span class="gi">+        max_gap=max_gap,</span>
<span class="gi">+        max_block=max_block,</span>
<span class="gi">+        sort=False,  # Should be sorted</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    # Transfer the data byte-ranges into local memory</span>
<span class="gi">+    result = {fn: {} for fn in list(set(data_paths))}</span>
<span class="gi">+    _transfer_ranges(fs, result, data_paths, data_starts, data_ends)</span>
<span class="gi">+</span>
<span class="gi">+    # Add b&quot;PAR1&quot; to header</span>
<span class="gi">+    _add_header_magic(result)</span>
<span class="gi">+</span>
<span class="gi">+    return result</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _transfer_ranges(fs, blocks, paths, starts, ends):</span>
<span class="gi">+    # Use cat_ranges to gather the data byte_ranges</span>
<span class="gi">+    ranges = (paths, starts, ends)</span>
<span class="gi">+    for path, start, stop, data in zip(*ranges, fs.cat_ranges(*ranges)):</span>
<span class="gi">+        blocks[path][(start, stop)] = data</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _add_header_magic(data):</span>
<span class="gi">+    # Add b&quot;PAR1&quot; to file headers</span>
<span class="gi">+    for path in list(data.keys()):</span>
<span class="gi">+        add_magic = True</span>
<span class="gi">+        for k in data[path].keys():</span>
<span class="gi">+            if k[0] == 0 and k[1] &gt;= 4:</span>
<span class="gi">+                add_magic = False</span>
<span class="gi">+                break</span>
<span class="gi">+        if add_magic:</span>
<span class="gi">+            data[path][(0, 4)] = b&quot;PAR1&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _set_engine(engine_str):</span>
<span class="gi">+    # Define a list of parquet engines to try</span>
<span class="gi">+    if engine_str == &quot;auto&quot;:</span>
<span class="gi">+        try_engines = (&quot;fastparquet&quot;, &quot;pyarrow&quot;)</span>
<span class="gi">+    elif not isinstance(engine_str, str):</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &quot;Failed to set parquet engine! &quot;</span>
<span class="gi">+            &quot;Please pass &#39;fastparquet&#39;, &#39;pyarrow&#39;, or &#39;auto&#39;&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+    elif engine_str not in (&quot;fastparquet&quot;, &quot;pyarrow&quot;):</span>
<span class="gi">+        raise ValueError(f&quot;{engine_str} engine not supported by `fsspec.parquet`&quot;)</span>
<span class="gi">+    else:</span>
<span class="gi">+        try_engines = [engine_str]</span>
<span class="gi">+</span>
<span class="gi">+    # Try importing the engines in `try_engines`,</span>
<span class="gi">+    # and choose the first one that succeeds</span>
<span class="gi">+    for engine in try_engines:</span>
<span class="gi">+        try:</span>
<span class="gi">+            if engine == &quot;fastparquet&quot;:</span>
<span class="gi">+                return FastparquetEngine()</span>
<span class="gi">+            elif engine == &quot;pyarrow&quot;:</span>
<span class="gi">+                return PyarrowEngine()</span>
<span class="gi">+        except ImportError:</span>
<span class="gi">+            pass</span>
<span class="gi">+</span>
<span class="gi">+    # Raise an error if a supported parquet engine</span>
<span class="gi">+    # was not found</span>
<span class="gi">+    raise ImportError(</span>
<span class="gi">+        f&quot;The following parquet engines are not installed &quot;</span>
<span class="gi">+        f&quot;in your python environment: {try_engines}.&quot;</span>
<span class="gi">+        f&quot;Please install &#39;fastparquert&#39; or &#39;pyarrow&#39; to &quot;</span>
<span class="gi">+        f&quot;utilize the `fsspec.parquet` module.&quot;</span>
<span class="gi">+    )</span>


<span class="w"> </span>class FastparquetEngine:
<span class="gi">+    # The purpose of the FastparquetEngine class is</span>
<span class="gi">+    # to check if fastparquet can be imported (on initialization)</span>
<span class="gi">+    # and to define a `_parquet_byte_ranges` method. In the</span>
<span class="gi">+    # future, this class may also be used to define other</span>
<span class="gi">+    # methods/logic that are specific to fastparquet.</span>

<span class="w"> </span>    def __init__(self):
<span class="w"> </span>        import fastparquet as fp
<span class="gi">+</span>
<span class="w"> </span>        self.fp = fp

<span class="gi">+    def _row_group_filename(self, row_group, pf):</span>
<span class="gi">+        return pf.row_group_filename(row_group)</span>
<span class="gi">+</span>
<span class="gi">+    def _parquet_byte_ranges(</span>
<span class="gi">+        self,</span>
<span class="gi">+        columns,</span>
<span class="gi">+        row_groups=None,</span>
<span class="gi">+        metadata=None,</span>
<span class="gi">+        footer=None,</span>
<span class="gi">+        footer_start=None,</span>
<span class="gi">+    ):</span>
<span class="gi">+        # Initialize offset ranges and define ParqetFile metadata</span>
<span class="gi">+        pf = metadata</span>
<span class="gi">+        data_paths, data_starts, data_ends = [], [], []</span>
<span class="gi">+        if pf is None:</span>
<span class="gi">+            pf = self.fp.ParquetFile(io.BytesIO(footer))</span>
<span class="gi">+</span>
<span class="gi">+        # Convert columns to a set and add any index columns</span>
<span class="gi">+        # specified in the pandas metadata (just in case)</span>
<span class="gi">+        column_set = None if columns is None else set(columns)</span>
<span class="gi">+        if column_set is not None and hasattr(pf, &quot;pandas_metadata&quot;):</span>
<span class="gi">+            md_index = [</span>
<span class="gi">+                ind</span>
<span class="gi">+                for ind in pf.pandas_metadata.get(&quot;index_columns&quot;, [])</span>
<span class="gi">+                # Ignore RangeIndex information</span>
<span class="gi">+                if not isinstance(ind, dict)</span>
<span class="gi">+            ]</span>
<span class="gi">+            column_set |= set(md_index)</span>
<span class="gi">+</span>
<span class="gi">+        # Check if row_groups is a list of integers</span>
<span class="gi">+        # or a list of row-group metadata</span>
<span class="gi">+        if row_groups and not isinstance(row_groups[0], int):</span>
<span class="gi">+            # Input row_groups contains row-group metadata</span>
<span class="gi">+            row_group_indices = None</span>
<span class="gi">+        else:</span>
<span class="gi">+            # Input row_groups contains row-group indices</span>
<span class="gi">+            row_group_indices = row_groups</span>
<span class="gi">+            row_groups = pf.row_groups</span>
<span class="gi">+</span>
<span class="gi">+        # Loop through column chunks to add required byte ranges</span>
<span class="gi">+        for r, row_group in enumerate(row_groups):</span>
<span class="gi">+            # Skip this row-group if we are targeting</span>
<span class="gi">+            # specific row-groups</span>
<span class="gi">+            if row_group_indices is None or r in row_group_indices:</span>
<span class="gi">+                # Find the target parquet-file path for `row_group`</span>
<span class="gi">+                fn = self._row_group_filename(row_group, pf)</span>
<span class="gi">+</span>
<span class="gi">+                for column in row_group.columns:</span>
<span class="gi">+                    name = column.meta_data.path_in_schema[0]</span>
<span class="gi">+                    # Skip this column if we are targeting a</span>
<span class="gi">+                    # specific columns</span>
<span class="gi">+                    if column_set is None or name in column_set:</span>
<span class="gi">+                        file_offset0 = column.meta_data.dictionary_page_offset</span>
<span class="gi">+                        if file_offset0 is None:</span>
<span class="gi">+                            file_offset0 = column.meta_data.data_page_offset</span>
<span class="gi">+                        num_bytes = column.meta_data.total_compressed_size</span>
<span class="gi">+                        if footer_start is None or file_offset0 &lt; footer_start:</span>
<span class="gi">+                            data_paths.append(fn)</span>
<span class="gi">+                            data_starts.append(file_offset0)</span>
<span class="gi">+                            data_ends.append(</span>
<span class="gi">+                                min(</span>
<span class="gi">+                                    file_offset0 + num_bytes,</span>
<span class="gi">+                                    footer_start or (file_offset0 + num_bytes),</span>
<span class="gi">+                                )</span>
<span class="gi">+                            )</span>
<span class="gi">+</span>
<span class="gi">+        if metadata:</span>
<span class="gi">+            # The metadata in this call may map to multiple</span>
<span class="gi">+            # file paths. Need to include `data_paths`</span>
<span class="gi">+            return data_paths, data_starts, data_ends</span>
<span class="gi">+        return data_starts, data_ends</span>
<span class="gi">+</span>

<span class="w"> </span>class PyarrowEngine:
<span class="gi">+    # The purpose of the PyarrowEngine class is</span>
<span class="gi">+    # to check if pyarrow can be imported (on initialization)</span>
<span class="gi">+    # and to define a `_parquet_byte_ranges` method. In the</span>
<span class="gi">+    # future, this class may also be used to define other</span>
<span class="gi">+    # methods/logic that are specific to pyarrow.</span>

<span class="w"> </span>    def __init__(self):
<span class="w"> </span>        import pyarrow.parquet as pq
<span class="gi">+</span>
<span class="w"> </span>        self.pq = pq
<span class="gi">+</span>
<span class="gi">+    def _row_group_filename(self, row_group, metadata):</span>
<span class="gi">+        raise NotImplementedError</span>
<span class="gi">+</span>
<span class="gi">+    def _parquet_byte_ranges(</span>
<span class="gi">+        self,</span>
<span class="gi">+        columns,</span>
<span class="gi">+        row_groups=None,</span>
<span class="gi">+        metadata=None,</span>
<span class="gi">+        footer=None,</span>
<span class="gi">+        footer_start=None,</span>
<span class="gi">+    ):</span>
<span class="gi">+        if metadata is not None:</span>
<span class="gi">+            raise ValueError(&quot;metadata input not supported for PyarrowEngine&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        data_starts, data_ends = [], []</span>
<span class="gi">+        md = self.pq.ParquetFile(io.BytesIO(footer)).metadata</span>
<span class="gi">+</span>
<span class="gi">+        # Convert columns to a set and add any index columns</span>
<span class="gi">+        # specified in the pandas metadata (just in case)</span>
<span class="gi">+        column_set = None if columns is None else set(columns)</span>
<span class="gi">+        if column_set is not None:</span>
<span class="gi">+            schema = md.schema.to_arrow_schema()</span>
<span class="gi">+            has_pandas_metadata = (</span>
<span class="gi">+                schema.metadata is not None and b&quot;pandas&quot; in schema.metadata</span>
<span class="gi">+            )</span>
<span class="gi">+            if has_pandas_metadata:</span>
<span class="gi">+                md_index = [</span>
<span class="gi">+                    ind</span>
<span class="gi">+                    for ind in json.loads(</span>
<span class="gi">+                        schema.metadata[b&quot;pandas&quot;].decode(&quot;utf8&quot;)</span>
<span class="gi">+                    ).get(&quot;index_columns&quot;, [])</span>
<span class="gi">+                    # Ignore RangeIndex information</span>
<span class="gi">+                    if not isinstance(ind, dict)</span>
<span class="gi">+                ]</span>
<span class="gi">+                column_set |= set(md_index)</span>
<span class="gi">+</span>
<span class="gi">+        # Loop through column chunks to add required byte ranges</span>
<span class="gi">+        for r in range(md.num_row_groups):</span>
<span class="gi">+            # Skip this row-group if we are targeting</span>
<span class="gi">+            # specific row-groups</span>
<span class="gi">+            if row_groups is None or r in row_groups:</span>
<span class="gi">+                row_group = md.row_group(r)</span>
<span class="gi">+                for c in range(row_group.num_columns):</span>
<span class="gi">+                    column = row_group.column(c)</span>
<span class="gi">+                    name = column.path_in_schema</span>
<span class="gi">+                    # Skip this column if we are targeting a</span>
<span class="gi">+                    # specific columns</span>
<span class="gi">+                    split_name = name.split(&quot;.&quot;)[0]</span>
<span class="gi">+                    if (</span>
<span class="gi">+                        column_set is None</span>
<span class="gi">+                        or name in column_set</span>
<span class="gi">+                        or split_name in column_set</span>
<span class="gi">+                    ):</span>
<span class="gi">+                        file_offset0 = column.dictionary_page_offset</span>
<span class="gi">+                        if file_offset0 is None:</span>
<span class="gi">+                            file_offset0 = column.data_page_offset</span>
<span class="gi">+                        num_bytes = column.total_compressed_size</span>
<span class="gi">+                        if file_offset0 &lt; footer_start:</span>
<span class="gi">+                            data_starts.append(file_offset0)</span>
<span class="gi">+                            data_ends.append(</span>
<span class="gi">+                                min(file_offset0 + num_bytes, footer_start)</span>
<span class="gi">+                            )</span>
<span class="gi">+        return data_starts, data_ends</span>
<span class="gh">diff --git a/fsspec/registry.py b/fsspec/registry.py</span>
<span class="gh">index e2de702..c261b9b 100644</span>
<span class="gd">--- a/fsspec/registry.py</span>
<span class="gi">+++ b/fsspec/registry.py</span>
<span class="gu">@@ -1,11 +1,17 @@</span>
<span class="w"> </span>from __future__ import annotations
<span class="gi">+</span>
<span class="w"> </span>import importlib
<span class="w"> </span>import types
<span class="w"> </span>import warnings
<span class="gd">-__all__ = [&#39;registry&#39;, &#39;get_filesystem_class&#39;, &#39;default&#39;]</span>
<span class="gi">+</span>
<span class="gi">+__all__ = [&quot;registry&quot;, &quot;get_filesystem_class&quot;, &quot;default&quot;]</span>
<span class="gi">+</span>
<span class="gi">+# internal, mutable</span>
<span class="w"> </span>_registry: dict[str, type] = {}
<span class="gi">+</span>
<span class="gi">+# external, immutable</span>
<span class="w"> </span>registry = types.MappingProxyType(_registry)
<span class="gd">-default = &#39;file&#39;</span>
<span class="gi">+default = &quot;file&quot;</span>


<span class="w"> </span>def register_implementation(name, cls, clobber=False, errtxt=None):
<span class="gu">@@ -28,94 +34,189 @@ def register_implementation(name, cls, clobber=False, errtxt=None):</span>
<span class="w"> </span>        If given, then a failure to import the given class will result in this
<span class="w"> </span>        text being given.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-known_implementations = {&#39;abfs&#39;: {&#39;class&#39;: &#39;adlfs.AzureBlobFileSystem&#39;,</span>
<span class="gd">-    &#39;err&#39;:</span>
<span class="gd">-    &#39;Install adlfs to access Azure Datalake Gen2 and Azure Blob Storage&#39;},</span>
<span class="gd">-    &#39;adl&#39;: {&#39;class&#39;: &#39;adlfs.AzureDatalakeFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Install adlfs to access Azure Datalake Gen1&#39;}, &#39;arrow_hdfs&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;fsspec.implementations.arrow.HadoopFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;pyarrow and local java libraries required for HDFS&#39;}, &#39;asynclocal&#39;: {</span>
<span class="gd">-    &#39;class&#39;: &#39;morefs.asyn_local.AsyncLocalFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &quot;Install &#39;morefs[asynclocalfs]&#39; to use AsyncLocalFileSystem&quot;}, &#39;az&#39;: {</span>
<span class="gd">-    &#39;class&#39;: &#39;adlfs.AzureBlobFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Install adlfs to access Azure Datalake Gen2 and Azure Blob Storage&#39;},</span>
<span class="gd">-    &#39;blockcache&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;fsspec.implementations.cached.CachingFileSystem&#39;}, &#39;box&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;boxfs.BoxFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Please install boxfs to access BoxFileSystem&#39;}, &#39;cached&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;fsspec.implementations.cached.CachingFileSystem&#39;}, &#39;dask&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;fsspec.implementations.dask.DaskWorkerFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Install dask distributed to access worker file system&#39;}, &#39;data&#39;: {</span>
<span class="gd">-    &#39;class&#39;: &#39;fsspec.implementations.data.DataFileSystem&#39;}, &#39;dbfs&#39;: {</span>
<span class="gd">-    &#39;class&#39;: &#39;fsspec.implementations.dbfs.DatabricksFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Install the requests package to use the DatabricksFileSystem&#39;}, &#39;dir&#39;:</span>
<span class="gd">-    {&#39;class&#39;: &#39;fsspec.implementations.dirfs.DirFileSystem&#39;}, &#39;dropbox&#39;: {</span>
<span class="gd">-    &#39;class&#39;: &#39;dropboxdrivefs.DropboxDriveFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;DropboxFileSystem requires &quot;dropboxdrivefs&quot;,&quot;requests&quot; and &quot;&quot;dropbox&quot; to be installed&#39;</span>
<span class="gd">-    }, &#39;dvc&#39;: {&#39;class&#39;: &#39;dvc.api.DVCFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Install dvc to access DVCFileSystem&#39;}, &#39;file&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;fsspec.implementations.local.LocalFileSystem&#39;}, &#39;filecache&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;fsspec.implementations.cached.WholeFileCacheFileSystem&#39;}, &#39;ftp&#39;: {</span>
<span class="gd">-    &#39;class&#39;: &#39;fsspec.implementations.ftp.FTPFileSystem&#39;}, &#39;gcs&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;gcsfs.GCSFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Please install gcsfs to access Google Storage&#39;}, &#39;gdrive&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;gdrivefs.GoogleDriveFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Please install gdrivefs for access to Google Drive&#39;}, &#39;generic&#39;: {</span>
<span class="gd">-    &#39;class&#39;: &#39;fsspec.generic.GenericFileSystem&#39;}, &#39;git&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;fsspec.implementations.git.GitFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Install pygit2 to browse local git repos&#39;}, &#39;github&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;fsspec.implementations.github.GithubFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Install the requests package to use the github FS&#39;}, &#39;gs&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;gcsfs.GCSFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Please install gcsfs to access Google Storage&#39;}, &#39;hdfs&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;fsspec.implementations.arrow.HadoopFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;pyarrow and local java libraries required for HDFS&#39;}, &#39;hf&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;huggingface_hub.HfFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Install huggingface_hub to access HfFileSystem&#39;}, &#39;http&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;fsspec.implementations.http.HTTPFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;HTTPFileSystem requires &quot;requests&quot; and &quot;aiohttp&quot; to be installed&#39;},</span>
<span class="gd">-    &#39;https&#39;: {&#39;class&#39;: &#39;fsspec.implementations.http.HTTPFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;HTTPFileSystem requires &quot;requests&quot; and &quot;aiohttp&quot; to be installed&#39;},</span>
<span class="gd">-    &#39;jlab&#39;: {&#39;class&#39;: &#39;fsspec.implementations.jupyter.JupyterFileSystem&#39;,</span>
<span class="gd">-    &#39;err&#39;: &#39;Jupyter FS requires requests to be installed&#39;}, &#39;jupyter&#39;: {</span>
<span class="gd">-    &#39;class&#39;: &#39;fsspec.implementations.jupyter.JupyterFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Jupyter FS requires requests to be installed&#39;}, &#39;lakefs&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;lakefs_spec.LakeFSFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Please install lakefs-spec to access LakeFSFileSystem&#39;}, &#39;libarchive&#39;:</span>
<span class="gd">-    {&#39;class&#39;: &#39;fsspec.implementations.libarchive.LibArchiveFileSystem&#39;,</span>
<span class="gd">-    &#39;err&#39;: &#39;LibArchive requires to be installed&#39;}, &#39;local&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;fsspec.implementations.local.LocalFileSystem&#39;}, &#39;memory&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;fsspec.implementations.memory.MemoryFileSystem&#39;}, &#39;oci&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;ocifs.OCIFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Install ocifs to access OCI Object Storage&#39;}, &#39;ocilake&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;ocifs.OCIFileSystem&#39;, &#39;err&#39;: &#39;Install ocifs to access OCI Data Lake&#39;},</span>
<span class="gd">-    &#39;oss&#39;: {&#39;class&#39;: &#39;ossfs.OSSFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Install ossfs to access Alibaba Object Storage System&#39;}, &#39;reference&#39;:</span>
<span class="gd">-    {&#39;class&#39;: &#39;fsspec.implementations.reference.ReferenceFileSystem&#39;},</span>
<span class="gd">-    &#39;root&#39;: {&#39;class&#39;: &#39;fsspec_xrootd.XRootDFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &quot;Install fsspec-xrootd to access xrootd storage system. Note: &#39;root&#39; is the protocol name for xrootd storage systems, not referring to root directories&quot;</span>
<span class="gd">-    }, &#39;s3&#39;: {&#39;class&#39;: &#39;s3fs.S3FileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Install s3fs to access S3&#39;}, &#39;s3a&#39;: {&#39;class&#39;: &#39;s3fs.S3FileSystem&#39;,</span>
<span class="gd">-    &#39;err&#39;: &#39;Install s3fs to access S3&#39;}, &#39;sftp&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;fsspec.implementations.sftp.SFTPFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;SFTPFileSystem requires &quot;paramiko&quot; to be installed&#39;}, &#39;simplecache&#39;: {</span>
<span class="gd">-    &#39;class&#39;: &#39;fsspec.implementations.cached.SimpleCacheFileSystem&#39;}, &#39;smb&#39;:</span>
<span class="gd">-    {&#39;class&#39;: &#39;fsspec.implementations.smb.SMBFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;SMB requires &quot;smbprotocol&quot; or &quot;smbprotocol[kerberos]&quot; installed&#39;},</span>
<span class="gd">-    &#39;ssh&#39;: {&#39;class&#39;: &#39;fsspec.implementations.sftp.SFTPFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;SFTPFileSystem requires &quot;paramiko&quot; to be installed&#39;}, &#39;tar&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;fsspec.implementations.tar.TarFileSystem&#39;}, &#39;wandb&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;wandbfs.WandbFS&#39;, &#39;err&#39;: &#39;Install wandbfs to access wandb&#39;}, &#39;webdav&#39;:</span>
<span class="gd">-    {&#39;class&#39;: &#39;webdav4.fsspec.WebdavFileSystem&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;Install webdav4 to access WebDAV&#39;}, &#39;webhdfs&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;fsspec.implementations.webhdfs.WebHDFS&#39;, &#39;err&#39;:</span>
<span class="gd">-    &#39;webHDFS access requires &quot;requests&quot; to be installed&#39;}, &#39;zip&#39;: {&#39;class&#39;:</span>
<span class="gd">-    &#39;fsspec.implementations.zip.ZipFileSystem&#39;}}</span>
<span class="gd">-assert list(known_implementations) == sorted(known_implementations</span>
<span class="gd">-    ), &#39;Not in alphabetical order&#39;</span>
<span class="gi">+    if isinstance(cls, str):</span>
<span class="gi">+        if name in known_implementations and clobber is False:</span>
<span class="gi">+            if cls != known_implementations[name][&quot;class&quot;]:</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    f&quot;Name ({name}) already in the known_implementations and clobber &quot;</span>
<span class="gi">+                    f&quot;is False&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+        else:</span>
<span class="gi">+            known_implementations[name] = {</span>
<span class="gi">+                &quot;class&quot;: cls,</span>
<span class="gi">+                &quot;err&quot;: errtxt or f&quot;{cls} import failed for protocol {name}&quot;,</span>
<span class="gi">+            }</span>
<span class="gi">+</span>
<span class="gi">+    else:</span>
<span class="gi">+        if name in registry and clobber is False:</span>
<span class="gi">+            if _registry[name] is not cls:</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    f&quot;Name ({name}) already in the registry and clobber is False&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+        else:</span>
<span class="gi">+            _registry[name] = cls</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# protocols mapped to the class which implements them. This dict can be</span>
<span class="gi">+# updated with register_implementation</span>
<span class="gi">+known_implementations = {</span>
<span class="gi">+    &quot;abfs&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;adlfs.AzureBlobFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Install adlfs to access Azure Datalake Gen2 and Azure Blob Storage&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;adl&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;adlfs.AzureDatalakeFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Install adlfs to access Azure Datalake Gen1&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;arrow_hdfs&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;fsspec.implementations.arrow.HadoopFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;pyarrow and local java libraries required for HDFS&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;asynclocal&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;morefs.asyn_local.AsyncLocalFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Install &#39;morefs[asynclocalfs]&#39; to use AsyncLocalFileSystem&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;az&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;adlfs.AzureBlobFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Install adlfs to access Azure Datalake Gen2 and Azure Blob Storage&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;blockcache&quot;: {&quot;class&quot;: &quot;fsspec.implementations.cached.CachingFileSystem&quot;},</span>
<span class="gi">+    &quot;box&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;boxfs.BoxFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Please install boxfs to access BoxFileSystem&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;cached&quot;: {&quot;class&quot;: &quot;fsspec.implementations.cached.CachingFileSystem&quot;},</span>
<span class="gi">+    &quot;dask&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;fsspec.implementations.dask.DaskWorkerFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Install dask distributed to access worker file system&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;data&quot;: {&quot;class&quot;: &quot;fsspec.implementations.data.DataFileSystem&quot;},</span>
<span class="gi">+    &quot;dbfs&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;fsspec.implementations.dbfs.DatabricksFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Install the requests package to use the DatabricksFileSystem&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;dir&quot;: {&quot;class&quot;: &quot;fsspec.implementations.dirfs.DirFileSystem&quot;},</span>
<span class="gi">+    &quot;dropbox&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;dropboxdrivefs.DropboxDriveFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: (</span>
<span class="gi">+            &#39;DropboxFileSystem requires &quot;dropboxdrivefs&quot;,&quot;requests&quot; and &quot;&#39;</span>
<span class="gi">+            &#39;&quot;dropbox&quot; to be installed&#39;</span>
<span class="gi">+        ),</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;dvc&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;dvc.api.DVCFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Install dvc to access DVCFileSystem&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;file&quot;: {&quot;class&quot;: &quot;fsspec.implementations.local.LocalFileSystem&quot;},</span>
<span class="gi">+    &quot;filecache&quot;: {&quot;class&quot;: &quot;fsspec.implementations.cached.WholeFileCacheFileSystem&quot;},</span>
<span class="gi">+    &quot;ftp&quot;: {&quot;class&quot;: &quot;fsspec.implementations.ftp.FTPFileSystem&quot;},</span>
<span class="gi">+    &quot;gcs&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;gcsfs.GCSFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Please install gcsfs to access Google Storage&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;gdrive&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;gdrivefs.GoogleDriveFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Please install gdrivefs for access to Google Drive&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;generic&quot;: {&quot;class&quot;: &quot;fsspec.generic.GenericFileSystem&quot;},</span>
<span class="gi">+    &quot;git&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;fsspec.implementations.git.GitFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Install pygit2 to browse local git repos&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;github&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;fsspec.implementations.github.GithubFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Install the requests package to use the github FS&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;gs&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;gcsfs.GCSFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Please install gcsfs to access Google Storage&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;hdfs&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;fsspec.implementations.arrow.HadoopFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;pyarrow and local java libraries required for HDFS&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;hf&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;huggingface_hub.HfFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Install huggingface_hub to access HfFileSystem&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;http&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;fsspec.implementations.http.HTTPFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &#39;HTTPFileSystem requires &quot;requests&quot; and &quot;aiohttp&quot; to be installed&#39;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;https&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;fsspec.implementations.http.HTTPFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &#39;HTTPFileSystem requires &quot;requests&quot; and &quot;aiohttp&quot; to be installed&#39;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;jlab&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;fsspec.implementations.jupyter.JupyterFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Jupyter FS requires requests to be installed&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;jupyter&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;fsspec.implementations.jupyter.JupyterFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Jupyter FS requires requests to be installed&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;lakefs&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;lakefs_spec.LakeFSFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Please install lakefs-spec to access LakeFSFileSystem&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;libarchive&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;fsspec.implementations.libarchive.LibArchiveFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;LibArchive requires to be installed&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;local&quot;: {&quot;class&quot;: &quot;fsspec.implementations.local.LocalFileSystem&quot;},</span>
<span class="gi">+    &quot;memory&quot;: {&quot;class&quot;: &quot;fsspec.implementations.memory.MemoryFileSystem&quot;},</span>
<span class="gi">+    &quot;oci&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;ocifs.OCIFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Install ocifs to access OCI Object Storage&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;ocilake&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;ocifs.OCIFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Install ocifs to access OCI Data Lake&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;oss&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;ossfs.OSSFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Install ossfs to access Alibaba Object Storage System&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;reference&quot;: {&quot;class&quot;: &quot;fsspec.implementations.reference.ReferenceFileSystem&quot;},</span>
<span class="gi">+    &quot;root&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;fsspec_xrootd.XRootDFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: (</span>
<span class="gi">+            &quot;Install fsspec-xrootd to access xrootd storage system. &quot;</span>
<span class="gi">+            &quot;Note: &#39;root&#39; is the protocol name for xrootd storage systems, &quot;</span>
<span class="gi">+            &quot;not referring to root directories&quot;</span>
<span class="gi">+        ),</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;s3&quot;: {&quot;class&quot;: &quot;s3fs.S3FileSystem&quot;, &quot;err&quot;: &quot;Install s3fs to access S3&quot;},</span>
<span class="gi">+    &quot;s3a&quot;: {&quot;class&quot;: &quot;s3fs.S3FileSystem&quot;, &quot;err&quot;: &quot;Install s3fs to access S3&quot;},</span>
<span class="gi">+    &quot;sftp&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;fsspec.implementations.sftp.SFTPFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &#39;SFTPFileSystem requires &quot;paramiko&quot; to be installed&#39;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;simplecache&quot;: {&quot;class&quot;: &quot;fsspec.implementations.cached.SimpleCacheFileSystem&quot;},</span>
<span class="gi">+    &quot;smb&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;fsspec.implementations.smb.SMBFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &#39;SMB requires &quot;smbprotocol&quot; or &quot;smbprotocol[kerberos]&quot; installed&#39;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;ssh&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;fsspec.implementations.sftp.SFTPFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &#39;SFTPFileSystem requires &quot;paramiko&quot; to be installed&#39;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;tar&quot;: {&quot;class&quot;: &quot;fsspec.implementations.tar.TarFileSystem&quot;},</span>
<span class="gi">+    &quot;wandb&quot;: {&quot;class&quot;: &quot;wandbfs.WandbFS&quot;, &quot;err&quot;: &quot;Install wandbfs to access wandb&quot;},</span>
<span class="gi">+    &quot;webdav&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;webdav4.fsspec.WebdavFileSystem&quot;,</span>
<span class="gi">+        &quot;err&quot;: &quot;Install webdav4 to access WebDAV&quot;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;webhdfs&quot;: {</span>
<span class="gi">+        &quot;class&quot;: &quot;fsspec.implementations.webhdfs.WebHDFS&quot;,</span>
<span class="gi">+        &quot;err&quot;: &#39;webHDFS access requires &quot;requests&quot; to be installed&#39;,</span>
<span class="gi">+    },</span>
<span class="gi">+    &quot;zip&quot;: {&quot;class&quot;: &quot;fsspec.implementations.zip.ZipFileSystem&quot;},</span>
<span class="gi">+}</span>
<span class="gi">+</span>
<span class="gi">+assert list(known_implementations) == sorted(</span>
<span class="gi">+    known_implementations</span>
<span class="gi">+), &quot;Not in alphabetical order&quot;</span>


<span class="w"> </span>def get_filesystem_class(protocol):
<span class="gu">@@ -130,7 +231,22 @@ def get_filesystem_class(protocol):</span>
<span class="w"> </span>    import may fail. In this case, the string in the &quot;err&quot; field of the
<span class="w"> </span>    ``known_implementations`` will be given as the error message.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not protocol:</span>
<span class="gi">+        protocol = default</span>
<span class="gi">+</span>
<span class="gi">+    if protocol not in registry:</span>
<span class="gi">+        if protocol not in known_implementations:</span>
<span class="gi">+            raise ValueError(f&quot;Protocol not known: {protocol}&quot;)</span>
<span class="gi">+        bit = known_implementations[protocol]</span>
<span class="gi">+        try:</span>
<span class="gi">+            register_implementation(protocol, _import_class(bit[&quot;class&quot;]))</span>
<span class="gi">+        except ImportError as e:</span>
<span class="gi">+            raise ImportError(bit[&quot;err&quot;]) from e</span>
<span class="gi">+    cls = registry[protocol]</span>
<span class="gi">+    if getattr(cls, &quot;protocol&quot;, None) in (&quot;abstract&quot;, None):</span>
<span class="gi">+        cls.protocol = protocol</span>
<span class="gi">+</span>
<span class="gi">+    return cls</span>


<span class="w"> </span>s3_msg = &quot;&quot;&quot;Your installed version of s3fs is very old and known to cause
<span class="gu">@@ -152,7 +268,22 @@ def _import_class(fqp: str):</span>
<span class="w"> </span>    This can import arbitrary modules. Make sure you haven&#39;t installed any modules
<span class="w"> </span>    that may execute malicious code at import time.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if &quot;:&quot; in fqp:</span>
<span class="gi">+        mod, name = fqp.rsplit(&quot;:&quot;, 1)</span>
<span class="gi">+    else:</span>
<span class="gi">+        mod, name = fqp.rsplit(&quot;.&quot;, 1)</span>
<span class="gi">+</span>
<span class="gi">+    is_s3 = mod == &quot;s3fs&quot;</span>
<span class="gi">+    mod = importlib.import_module(mod)</span>
<span class="gi">+    if is_s3 and mod.__version__.split(&quot;.&quot;) &lt; [&quot;0&quot;, &quot;5&quot;]:</span>
<span class="gi">+        warnings.warn(s3_msg)</span>
<span class="gi">+    for part in name.split(&quot;.&quot;):</span>
<span class="gi">+        mod = getattr(mod, part)</span>
<span class="gi">+</span>
<span class="gi">+    if not isinstance(mod, type):</span>
<span class="gi">+        raise TypeError(f&quot;{fqp} is not a class&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    return mod</span>


<span class="w"> </span>def filesystem(protocol, **storage_options):
<span class="gu">@@ -161,7 +292,15 @@ def filesystem(protocol, **storage_options):</span>
<span class="w"> </span>    ``storage_options`` are specific to the protocol being chosen, and are
<span class="w"> </span>    passed directly to the class.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if protocol == &quot;arrow_hdfs&quot;:</span>
<span class="gi">+        warnings.warn(</span>
<span class="gi">+            &quot;The &#39;arrow_hdfs&#39; protocol has been deprecated and will be &quot;</span>
<span class="gi">+            &quot;removed in the future. Specify it as &#39;hdfs&#39;.&quot;,</span>
<span class="gi">+            DeprecationWarning,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    cls = get_filesystem_class(protocol)</span>
<span class="gi">+    return cls(**storage_options)</span>


<span class="w"> </span>def available_protocols():
<span class="gu">@@ -169,4 +308,4 @@ def available_protocols():</span>

<span class="w"> </span>    Note that any given protocol may require extra packages to be importable.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return list(known_implementations)</span>
<span class="gh">diff --git a/fsspec/spec.py b/fsspec/spec.py</span>
<span class="gh">index 106214a..1463a44 100644</span>
<span class="gd">--- a/fsspec/spec.py</span>
<span class="gi">+++ b/fsspec/spec.py</span>
<span class="gu">@@ -1,4 +1,5 @@</span>
<span class="w"> </span>from __future__ import annotations
<span class="gi">+</span>
<span class="w"> </span>import io
<span class="w"> </span>import json
<span class="w"> </span>import logging
<span class="gu">@@ -10,12 +11,26 @@ from errno import ESPIPE</span>
<span class="w"> </span>from glob import has_magic
<span class="w"> </span>from hashlib import sha256
<span class="w"> </span>from typing import Any, ClassVar, Dict, Tuple
<span class="gi">+</span>
<span class="w"> </span>from .callbacks import DEFAULT_CALLBACK
<span class="w"> </span>from .config import apply_config, conf
<span class="w"> </span>from .dircache import DirCache
<span class="w"> </span>from .transaction import Transaction
<span class="gd">-from .utils import _unstrip_protocol, glob_translate, isfilelike, other_paths, read_block, stringify_path, tokenize</span>
<span class="gd">-logger = logging.getLogger(&#39;fsspec&#39;)</span>
<span class="gi">+from .utils import (</span>
<span class="gi">+    _unstrip_protocol,</span>
<span class="gi">+    glob_translate,</span>
<span class="gi">+    isfilelike,</span>
<span class="gi">+    other_paths,</span>
<span class="gi">+    read_block,</span>
<span class="gi">+    stringify_path,</span>
<span class="gi">+    tokenize,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="gi">+logger = logging.getLogger(&quot;fsspec&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def make_instance(cls, args, kwargs):</span>
<span class="gi">+    return cls(*args, **kwargs)</span>


<span class="w"> </span>class _Cached(type):
<span class="gu">@@ -37,7 +52,11 @@ class _Cached(type):</span>

<span class="w"> </span>    def __init__(cls, *args, **kwargs):
<span class="w"> </span>        super().__init__(*args, **kwargs)
<span class="gd">-        if conf.get(&#39;weakref_instance_cache&#39;):</span>
<span class="gi">+        # Note: we intentionally create a reference here, to avoid garbage</span>
<span class="gi">+        # collecting instances when all other references are gone. To really</span>
<span class="gi">+        # delete a FileSystem, the cache must be cleared.</span>
<span class="gi">+        if conf.get(&quot;weakref_instance_cache&quot;):  # pragma: no cover</span>
<span class="gi">+            # debug option for analysing fork/spawn conditions</span>
<span class="w"> </span>            cls._cache = weakref.WeakValueDictionary()
<span class="w"> </span>        else:
<span class="w"> </span>            cls._cache = {}
<span class="gu">@@ -45,11 +64,13 @@ class _Cached(type):</span>

<span class="w"> </span>    def __call__(cls, *args, **kwargs):
<span class="w"> </span>        kwargs = apply_config(cls, kwargs)
<span class="gd">-        extra_tokens = tuple(getattr(cls, attr, None) for attr in cls.</span>
<span class="gd">-            _extra_tokenize_attributes)</span>
<span class="gd">-        token = tokenize(cls, cls._pid, threading.get_ident(), *args, *</span>
<span class="gd">-            extra_tokens, **kwargs)</span>
<span class="gd">-        skip = kwargs.pop(&#39;skip_instance_cache&#39;, False)</span>
<span class="gi">+        extra_tokens = tuple(</span>
<span class="gi">+            getattr(cls, attr, None) for attr in cls._extra_tokenize_attributes</span>
<span class="gi">+        )</span>
<span class="gi">+        token = tokenize(</span>
<span class="gi">+            cls, cls._pid, threading.get_ident(), *args, *extra_tokens, **kwargs</span>
<span class="gi">+        )</span>
<span class="gi">+        skip = kwargs.pop(&quot;skip_instance_cache&quot;, False)</span>
<span class="w"> </span>        if os.getpid() != cls._pid:
<span class="w"> </span>            cls._cache.clear()
<span class="w"> </span>            cls._pid = os.getpid()
<span class="gu">@@ -58,12 +79,15 @@ class _Cached(type):</span>
<span class="w"> </span>            return cls._cache[token]
<span class="w"> </span>        else:
<span class="w"> </span>            obj = super().__call__(*args, **kwargs)
<span class="gi">+            # Setting _fs_token here causes some static linters to complain.</span>
<span class="w"> </span>            obj._fs_token_ = token
<span class="w"> </span>            obj.storage_args = args
<span class="w"> </span>            obj.storage_options = kwargs
<span class="w"> </span>            if obj.async_impl and obj.mirror_sync_methods:
<span class="w"> </span>                from .asyn import mirror_sync_methods
<span class="gi">+</span>
<span class="w"> </span>                mirror_sync_methods(obj)
<span class="gi">+</span>
<span class="w"> </span>            if cls.cachable and not skip:
<span class="w"> </span>                cls._latest = token
<span class="w"> </span>                cls._cache[token] = obj
<span class="gu">@@ -77,17 +101,22 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>    Implementations are expected to be compatible with or, better, subclass
<span class="w"> </span>    from here.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    cachable = True</span>
<span class="gi">+</span>
<span class="gi">+    cachable = True  # this class can be cached, instances reused</span>
<span class="w"> </span>    _cached = False
<span class="gd">-    blocksize = 2 ** 22</span>
<span class="gd">-    sep = &#39;/&#39;</span>
<span class="gd">-    protocol: ClassVar[str | tuple[str, ...]] = &#39;abstract&#39;</span>
<span class="gi">+    blocksize = 2**22</span>
<span class="gi">+    sep = &quot;/&quot;</span>
<span class="gi">+    protocol: ClassVar[str | tuple[str, ...]] = &quot;abstract&quot;</span>
<span class="w"> </span>    _latest = None
<span class="w"> </span>    async_impl = False
<span class="w"> </span>    mirror_sync_methods = False
<span class="gd">-    root_marker = &#39;&#39;</span>
<span class="gi">+    root_marker = &quot;&quot;  # For some FSs, may require leading &#39;/&#39; or other character</span>
<span class="w"> </span>    transaction_type = Transaction
<span class="gi">+</span>
<span class="gi">+    #: Extra *class attributes* that should be considered when hashing.</span>
<span class="w"> </span>    _extra_tokenize_attributes = ()
<span class="gi">+</span>
<span class="gi">+    # Set by _Cached metaclass</span>
<span class="w"> </span>    storage_args: Tuple[Any, ...]
<span class="w"> </span>    storage_options: Dict[str, Any]

<span class="gu">@@ -116,16 +145,20 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        loop: asyncio-compatible IOLoop or None
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        if self._cached:
<span class="gi">+            # reusing instance, don&#39;t change</span>
<span class="w"> </span>            return
<span class="w"> </span>        self._cached = True
<span class="w"> </span>        self._intrans = False
<span class="w"> </span>        self._transaction = None
<span class="w"> </span>        self._invalidated_caches_in_transaction = []
<span class="w"> </span>        self.dircache = DirCache(**storage_options)
<span class="gd">-        if storage_options.pop(&#39;add_docs&#39;, None):</span>
<span class="gd">-            warnings.warn(&#39;add_docs is no longer supported.&#39;, FutureWarning)</span>
<span class="gd">-        if storage_options.pop(&#39;add_aliases&#39;, None):</span>
<span class="gd">-            warnings.warn(&#39;add_aliases has been removed.&#39;, FutureWarning)</span>
<span class="gi">+</span>
<span class="gi">+        if storage_options.pop(&quot;add_docs&quot;, None):</span>
<span class="gi">+            warnings.warn(&quot;add_docs is no longer supported.&quot;, FutureWarning)</span>
<span class="gi">+</span>
<span class="gi">+        if storage_options.pop(&quot;add_aliases&quot;, None):</span>
<span class="gi">+            warnings.warn(&quot;add_aliases has been removed.&quot;, FutureWarning)</span>
<span class="gi">+        # This is set in _Cached</span>
<span class="w"> </span>        self._fs_token_ = None

<span class="w"> </span>    @property
<span class="gu">@@ -133,7 +166,11 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        &quot;&quot;&quot;Persistent filesystem id that can be used to compare filesystems
<span class="w"> </span>        across sessions.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        raise NotImplementedError</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def _fs_token(self):</span>
<span class="gi">+        return self._fs_token_</span>

<span class="w"> </span>    def __dask_tokenize__(self):
<span class="w"> </span>        return self._fs_token
<span class="gu">@@ -142,12 +179,10 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        return int(self._fs_token, 16)

<span class="w"> </span>    def __eq__(self, other):
<span class="gd">-        return isinstance(other, type(self)</span>
<span class="gd">-            ) and self._fs_token == other._fs_token</span>
<span class="gi">+        return isinstance(other, type(self)) and self._fs_token == other._fs_token</span>

<span class="w"> </span>    def __reduce__(self):
<span class="gd">-        return make_instance, (type(self), self.storage_args, self.</span>
<span class="gd">-            storage_options)</span>
<span class="gi">+        return make_instance, (type(self), self.storage_args, self.storage_options)</span>

<span class="w"> </span>    @classmethod
<span class="w"> </span>    def _strip_protocol(cls, path):
<span class="gu">@@ -155,11 +190,26 @@ class AbstractFileSystem(metaclass=_Cached):</span>

<span class="w"> </span>        May require FS-specific handling, e.g., for relative paths or links.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def unstrip_protocol(self, name: str) -&gt;str:</span>
<span class="gi">+        if isinstance(path, list):</span>
<span class="gi">+            return [cls._strip_protocol(p) for p in path]</span>
<span class="gi">+        path = stringify_path(path)</span>
<span class="gi">+        protos = (cls.protocol,) if isinstance(cls.protocol, str) else cls.protocol</span>
<span class="gi">+        for protocol in protos:</span>
<span class="gi">+            if path.startswith(protocol + &quot;://&quot;):</span>
<span class="gi">+                path = path[len(protocol) + 3 :]</span>
<span class="gi">+            elif path.startswith(protocol + &quot;::&quot;):</span>
<span class="gi">+                path = path[len(protocol) + 2 :]</span>
<span class="gi">+        path = path.rstrip(&quot;/&quot;)</span>
<span class="gi">+        # use of root_marker to make minimum required path, e.g., &quot;/&quot;</span>
<span class="gi">+        return path or cls.root_marker</span>
<span class="gi">+</span>
<span class="gi">+    def unstrip_protocol(self, name: str) -&gt; str:</span>
<span class="w"> </span>        &quot;&quot;&quot;Format FS-specific path to generic, including protocol&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        protos = (self.protocol,) if isinstance(self.protocol, str) else self.protocol</span>
<span class="gi">+        for protocol in protos:</span>
<span class="gi">+            if name.startswith(f&quot;{protocol}://&quot;):</span>
<span class="gi">+                return name</span>
<span class="gi">+        return f&quot;{protos[0]}://{name}&quot;</span>

<span class="w"> </span>    @staticmethod
<span class="w"> </span>    def _get_kwargs_from_urls(path):
<span class="gu">@@ -171,7 +221,8 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        Examples may look like an sftp path &quot;sftp://user@host:/my/path&quot;, where
<span class="w"> </span>        the user and host should become kwargs and later get stripped.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # by default, nothing happens</span>
<span class="gi">+        return {}</span>

<span class="w"> </span>    @classmethod
<span class="w"> </span>    def current(cls):
<span class="gu">@@ -179,7 +230,9 @@ class AbstractFileSystem(metaclass=_Cached):</span>

<span class="w"> </span>        If no instance has been created, then create one with defaults
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if cls._latest in cls._cache:</span>
<span class="gi">+            return cls._cache[cls._latest]</span>
<span class="gi">+        return cls()</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def transaction(self):
<span class="gu">@@ -188,15 +241,24 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        Requires the file class to implement `.commit()` and `.discard()`
<span class="w"> </span>        for the normal and exception cases.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self._transaction is None:</span>
<span class="gi">+            self._transaction = self.transaction_type(self)</span>
<span class="gi">+        return self._transaction</span>

<span class="w"> </span>    def start_transaction(self):
<span class="w"> </span>        &quot;&quot;&quot;Begin write transaction for deferring files, non-context version&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._intrans = True</span>
<span class="gi">+        self._transaction = self.transaction_type(self)</span>
<span class="gi">+        return self.transaction</span>

<span class="w"> </span>    def end_transaction(self):
<span class="w"> </span>        &quot;&quot;&quot;Finish write transaction, non-context version&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.transaction.complete()</span>
<span class="gi">+        self._transaction = None</span>
<span class="gi">+        # The invalid cache must be cleared after the transaction is completed.</span>
<span class="gi">+        for path in self._invalidated_caches_in_transaction:</span>
<span class="gi">+            self.invalidate_cache(path)</span>
<span class="gi">+        self._invalidated_caches_in_transaction.clear()</span>

<span class="w"> </span>    def invalidate_cache(self, path=None):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -208,7 +270,12 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>            If None, clear all listings cached else listings at or under given
<span class="w"> </span>            path.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # Not necessary to implement invalidation mechanism, may have no cache.</span>
<span class="gi">+        # But if have, you should call this method of parent class from your</span>
<span class="gi">+        # subclass to ensure expiring caches after transacations correctly.</span>
<span class="gi">+        # See the implementation of FTPFileSystem in ftp.py</span>
<span class="gi">+        if self._intrans:</span>
<span class="gi">+            self._invalidated_caches_in_transaction.append(path)</span>

<span class="w"> </span>    def mkdir(self, path, create_parents=True, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -226,7 +293,7 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        kwargs:
<span class="w"> </span>            may be permissions, etc.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        pass  # not necessary to implement, may not have directories</span>

<span class="w"> </span>    def makedirs(self, path, exist_ok=False):
<span class="w"> </span>        &quot;&quot;&quot;Recursively make directories
<span class="gu">@@ -242,11 +309,11 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        exist_ok: bool (False)
<span class="w"> </span>            If False, will error if the target already exists
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        pass  # not necessary to implement, may not have directories</span>

<span class="w"> </span>    def rmdir(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Remove a directory, if empty&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        pass  # not necessary to implement, may not have directories</span>

<span class="w"> </span>    def ls(self, path, detail=True, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;List objects at path.
<span class="gu">@@ -287,7 +354,7 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        List of strings if detail is False, or list of directory information
<span class="w"> </span>        dicts if detail is True.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        raise NotImplementedError</span>

<span class="w"> </span>    def _ls_from_cache(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Check cache for listing
<span class="gu">@@ -295,10 +362,26 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        Returns listing, if found (may be empty list for a directly that exists
<span class="w"> </span>        but contains nothing), None if not in cache.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def walk(self, path, maxdepth=None, topdown=True, on_error=&#39;omit&#39;, **kwargs</span>
<span class="gd">-        ):</span>
<span class="gi">+        parent = self._parent(path)</span>
<span class="gi">+        try:</span>
<span class="gi">+            return self.dircache[path.rstrip(&quot;/&quot;)]</span>
<span class="gi">+        except KeyError:</span>
<span class="gi">+            pass</span>
<span class="gi">+        try:</span>
<span class="gi">+            files = [</span>
<span class="gi">+                f</span>
<span class="gi">+                for f in self.dircache[parent]</span>
<span class="gi">+                if f[&quot;name&quot;] == path</span>
<span class="gi">+                or (f[&quot;name&quot;] == path.rstrip(&quot;/&quot;) and f[&quot;type&quot;] == &quot;directory&quot;)</span>
<span class="gi">+            ]</span>
<span class="gi">+            if len(files) == 0:</span>
<span class="gi">+                # parent dir was listed but did not contain this file</span>
<span class="gi">+                raise FileNotFoundError(path)</span>
<span class="gi">+            return files</span>
<span class="gi">+        except KeyError:</span>
<span class="gi">+            pass</span>
<span class="gi">+</span>
<span class="gi">+    def walk(self, path, maxdepth=None, topdown=True, on_error=&quot;omit&quot;, **kwargs):</span>
<span class="w"> </span>        &quot;&quot;&quot;Return all files belows path

<span class="w"> </span>        List all files, recursing into subdirectories; output is iterator-style,
<span class="gu">@@ -331,10 +414,70 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>            if callable, it will be called with a single OSError instance as argument
<span class="w"> </span>        kwargs: passed to ``ls``
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def find(self, path, maxdepth=None, withdirs=False, detail=False, **kwargs</span>
<span class="gd">-        ):</span>
<span class="gi">+        if maxdepth is not None and maxdepth &lt; 1:</span>
<span class="gi">+            raise ValueError(&quot;maxdepth must be at least 1&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        full_dirs = {}</span>
<span class="gi">+        dirs = {}</span>
<span class="gi">+        files = {}</span>
<span class="gi">+</span>
<span class="gi">+        detail = kwargs.pop(&quot;detail&quot;, False)</span>
<span class="gi">+        try:</span>
<span class="gi">+            listing = self.ls(path, detail=True, **kwargs)</span>
<span class="gi">+        except (FileNotFoundError, OSError) as e:</span>
<span class="gi">+            if on_error == &quot;raise&quot;:</span>
<span class="gi">+                raise</span>
<span class="gi">+            elif callable(on_error):</span>
<span class="gi">+                on_error(e)</span>
<span class="gi">+            if detail:</span>
<span class="gi">+                return path, {}, {}</span>
<span class="gi">+            return path, [], []</span>
<span class="gi">+</span>
<span class="gi">+        for info in listing:</span>
<span class="gi">+            # each info name must be at least [path]/part , but here</span>
<span class="gi">+            # we check also for names like [path]/part/</span>
<span class="gi">+            pathname = info[&quot;name&quot;].rstrip(&quot;/&quot;)</span>
<span class="gi">+            name = pathname.rsplit(&quot;/&quot;, 1)[-1]</span>
<span class="gi">+            if info[&quot;type&quot;] == &quot;directory&quot; and pathname != path:</span>
<span class="gi">+                # do not include &quot;self&quot; path</span>
<span class="gi">+                full_dirs[name] = pathname</span>
<span class="gi">+                dirs[name] = info</span>
<span class="gi">+            elif pathname == path:</span>
<span class="gi">+                # file-like with same name as give path</span>
<span class="gi">+                files[&quot;&quot;] = info</span>
<span class="gi">+            else:</span>
<span class="gi">+                files[name] = info</span>
<span class="gi">+</span>
<span class="gi">+        if not detail:</span>
<span class="gi">+            dirs = list(dirs)</span>
<span class="gi">+            files = list(files)</span>
<span class="gi">+</span>
<span class="gi">+        if topdown:</span>
<span class="gi">+            # Yield before recursion if walking top down</span>
<span class="gi">+            yield path, dirs, files</span>
<span class="gi">+</span>
<span class="gi">+        if maxdepth is not None:</span>
<span class="gi">+            maxdepth -= 1</span>
<span class="gi">+            if maxdepth &lt; 1:</span>
<span class="gi">+                if not topdown:</span>
<span class="gi">+                    yield path, dirs, files</span>
<span class="gi">+                return</span>
<span class="gi">+</span>
<span class="gi">+        for d in dirs:</span>
<span class="gi">+            yield from self.walk(</span>
<span class="gi">+                full_dirs[d],</span>
<span class="gi">+                maxdepth=maxdepth,</span>
<span class="gi">+                detail=detail,</span>
<span class="gi">+                topdown=topdown,</span>
<span class="gi">+                **kwargs,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        if not topdown:</span>
<span class="gi">+            # Yield after recursion if walking bottom up</span>
<span class="gi">+            yield path, dirs, files</span>
<span class="gi">+</span>
<span class="gi">+    def find(self, path, maxdepth=None, withdirs=False, detail=False, **kwargs):</span>
<span class="w"> </span>        &quot;&quot;&quot;List all files below path.

<span class="w"> </span>        Like posix ``find`` command without conditions
<span class="gu">@@ -349,7 +492,28 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>            when used by glob, but users usually only want files.
<span class="w"> </span>        kwargs are passed to ``ls``.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # TODO: allow equivalent of -name parameter</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        out = {}</span>
<span class="gi">+</span>
<span class="gi">+        # Add the root directory if withdirs is requested</span>
<span class="gi">+        # This is needed for posix glob compliance</span>
<span class="gi">+        if withdirs and path != &quot;&quot; and self.isdir(path):</span>
<span class="gi">+            out[path] = self.info(path)</span>
<span class="gi">+</span>
<span class="gi">+        for _, dirs, files in self.walk(path, maxdepth, detail=True, **kwargs):</span>
<span class="gi">+            if withdirs:</span>
<span class="gi">+                files.update(dirs)</span>
<span class="gi">+            out.update({info[&quot;name&quot;]: info for name, info in files.items()})</span>
<span class="gi">+        if not out and self.isfile(path):</span>
<span class="gi">+            # walk works on directories, but find should also return [path]</span>
<span class="gi">+            # when path happens to be a file</span>
<span class="gi">+            out[path] = {}</span>
<span class="gi">+        names = sorted(out)</span>
<span class="gi">+        if not detail:</span>
<span class="gi">+            return names</span>
<span class="gi">+        else:</span>
<span class="gi">+            return {name: out[name] for name in names}</span>

<span class="w"> </span>    def du(self, path, total=True, maxdepth=None, withdirs=False, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Space used by files and optionally directories within a path
<span class="gu">@@ -372,7 +536,18 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        Dict of {path: size} if total=False, or int otherwise, where numbers
<span class="w"> </span>        refer to bytes used.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        sizes = {}</span>
<span class="gi">+        if withdirs and self.isdir(path):</span>
<span class="gi">+            # Include top-level directory in output</span>
<span class="gi">+            info = self.info(path)</span>
<span class="gi">+            sizes[info[&quot;name&quot;]] = info[&quot;size&quot;]</span>
<span class="gi">+        for f in self.find(path, maxdepth=maxdepth, withdirs=withdirs, **kwargs):</span>
<span class="gi">+            info = self.info(f)</span>
<span class="gi">+            sizes[info[&quot;name&quot;]] = info[&quot;size&quot;]</span>
<span class="gi">+        if total:</span>
<span class="gi">+            return sum(sizes.values())</span>
<span class="gi">+        else:</span>
<span class="gi">+            return sizes</span>

<span class="w"> </span>    def glob(self, path, maxdepth=None, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -387,16 +562,87 @@ class AbstractFileSystem(metaclass=_Cached):</span>

<span class="w"> </span>        kwargs are passed to ``ls``.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if maxdepth is not None and maxdepth &lt; 1:</span>
<span class="gi">+            raise ValueError(&quot;maxdepth must be at least 1&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        import re</span>
<span class="gi">+</span>
<span class="gi">+        seps = (os.path.sep, os.path.altsep) if os.path.altsep else (os.path.sep,)</span>
<span class="gi">+        ends_with_sep = path.endswith(seps)  # _strip_protocol strips trailing slash</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        append_slash_to_dirname = ends_with_sep or path.endswith(</span>
<span class="gi">+            tuple(sep + &quot;**&quot; for sep in seps)</span>
<span class="gi">+        )</span>
<span class="gi">+        idx_star = path.find(&quot;*&quot;) if path.find(&quot;*&quot;) &gt;= 0 else len(path)</span>
<span class="gi">+        idx_qmark = path.find(&quot;?&quot;) if path.find(&quot;?&quot;) &gt;= 0 else len(path)</span>
<span class="gi">+        idx_brace = path.find(&quot;[&quot;) if path.find(&quot;[&quot;) &gt;= 0 else len(path)</span>
<span class="gi">+</span>
<span class="gi">+        min_idx = min(idx_star, idx_qmark, idx_brace)</span>
<span class="gi">+</span>
<span class="gi">+        detail = kwargs.pop(&quot;detail&quot;, False)</span>
<span class="gi">+</span>
<span class="gi">+        if not has_magic(path):</span>
<span class="gi">+            if self.exists(path, **kwargs):</span>
<span class="gi">+                if not detail:</span>
<span class="gi">+                    return [path]</span>
<span class="gi">+                else:</span>
<span class="gi">+                    return {path: self.info(path, **kwargs)}</span>
<span class="gi">+            else:</span>
<span class="gi">+                if not detail:</span>
<span class="gi">+                    return []  # glob of non-existent returns empty</span>
<span class="gi">+                else:</span>
<span class="gi">+                    return {}</span>
<span class="gi">+        elif &quot;/&quot; in path[:min_idx]:</span>
<span class="gi">+            min_idx = path[:min_idx].rindex(&quot;/&quot;)</span>
<span class="gi">+            root = path[: min_idx + 1]</span>
<span class="gi">+            depth = path[min_idx + 1 :].count(&quot;/&quot;) + 1</span>
<span class="gi">+        else:</span>
<span class="gi">+            root = &quot;&quot;</span>
<span class="gi">+            depth = path[min_idx + 1 :].count(&quot;/&quot;) + 1</span>
<span class="gi">+</span>
<span class="gi">+        if &quot;**&quot; in path:</span>
<span class="gi">+            if maxdepth is not None:</span>
<span class="gi">+                idx_double_stars = path.find(&quot;**&quot;)</span>
<span class="gi">+                depth_double_stars = path[idx_double_stars:].count(&quot;/&quot;) + 1</span>
<span class="gi">+                depth = depth - depth_double_stars + maxdepth</span>
<span class="gi">+            else:</span>
<span class="gi">+                depth = None</span>
<span class="gi">+</span>
<span class="gi">+        allpaths = self.find(root, maxdepth=depth, withdirs=True, detail=True, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+        pattern = glob_translate(path + (&quot;/&quot; if ends_with_sep else &quot;&quot;))</span>
<span class="gi">+        pattern = re.compile(pattern)</span>
<span class="gi">+</span>
<span class="gi">+        out = {</span>
<span class="gi">+            p: info</span>
<span class="gi">+            for p, info in sorted(allpaths.items())</span>
<span class="gi">+            if pattern.match(</span>
<span class="gi">+                (</span>
<span class="gi">+                    p + &quot;/&quot;</span>
<span class="gi">+                    if append_slash_to_dirname and info[&quot;type&quot;] == &quot;directory&quot;</span>
<span class="gi">+                    else p</span>
<span class="gi">+                )</span>
<span class="gi">+            )</span>
<span class="gi">+        }</span>
<span class="gi">+</span>
<span class="gi">+        if detail:</span>
<span class="gi">+            return out</span>
<span class="gi">+        else:</span>
<span class="gi">+            return list(out)</span>

<span class="w"> </span>    def exists(self, path, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Is there a file at the given path&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        try:</span>
<span class="gi">+            self.info(path, **kwargs)</span>
<span class="gi">+            return True</span>
<span class="gi">+        except:  # noqa: E722</span>
<span class="gi">+            # any exception allowed bar FileNotFoundError?</span>
<span class="gi">+            return False</span>

<span class="w"> </span>    def lexists(self, path, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;If there is a file at the given path (including
<span class="w"> </span>        broken links)&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.exists(path)</span>

<span class="w"> </span>    def info(self, path, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Give details of entry at path
<span class="gu">@@ -415,7 +661,22 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        dict with keys: name (full path in the FS), size (in bytes), type (file,
<span class="w"> </span>        directory, or something else) and other FS-specific keys.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        out = self.ls(self._parent(path), detail=True, **kwargs)</span>
<span class="gi">+        out = [o for o in out if o[&quot;name&quot;].rstrip(&quot;/&quot;) == path]</span>
<span class="gi">+        if out:</span>
<span class="gi">+            return out[0]</span>
<span class="gi">+        out = self.ls(path, detail=True, **kwargs)</span>
<span class="gi">+        path = path.rstrip(&quot;/&quot;)</span>
<span class="gi">+        out1 = [o for o in out if o[&quot;name&quot;].rstrip(&quot;/&quot;) == path]</span>
<span class="gi">+        if len(out1) == 1:</span>
<span class="gi">+            if &quot;size&quot; not in out1[0]:</span>
<span class="gi">+                out1[0][&quot;size&quot;] = None</span>
<span class="gi">+            return out1[0]</span>
<span class="gi">+        elif len(out1) &gt; 1 or out:</span>
<span class="gi">+            return {&quot;name&quot;: path, &quot;size&quot;: 0, &quot;type&quot;: &quot;directory&quot;}</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise FileNotFoundError(path)</span>

<span class="w"> </span>    def checksum(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Unique value for current version of file
<span class="gu">@@ -428,26 +689,31 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        creation/modification timestamp (which would be good) or maybe
<span class="w"> </span>        access timestamp (which would be bad)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return int(tokenize(self.info(path)), 16)</span>

<span class="w"> </span>    def size(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Size in bytes of file&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.info(path).get(&quot;size&quot;, None)</span>

<span class="w"> </span>    def sizes(self, paths):
<span class="w"> </span>        &quot;&quot;&quot;Size in bytes of each file in a list of paths&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return [self.size(p) for p in paths]</span>

<span class="w"> </span>    def isdir(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Is this entry directory-like?&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        try:</span>
<span class="gi">+            return self.info(path)[&quot;type&quot;] == &quot;directory&quot;</span>
<span class="gi">+        except OSError:</span>
<span class="gi">+            return False</span>

<span class="w"> </span>    def isfile(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Is this entry file-like?&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        try:</span>
<span class="gi">+            return self.info(path)[&quot;type&quot;] == &quot;file&quot;</span>
<span class="gi">+        except:  # noqa: E722</span>
<span class="gi">+            return False</span>

<span class="gd">-    def read_text(self, path, encoding=None, errors=None, newline=None, **</span>
<span class="gd">-        kwargs):</span>
<span class="gi">+    def read_text(self, path, encoding=None, errors=None, newline=None, **kwargs):</span>
<span class="w"> </span>        &quot;&quot;&quot;Get the contents of the file as a string.

<span class="w"> </span>        Parameters
<span class="gu">@@ -456,10 +722,19 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>            URL of file on this filesystems
<span class="w"> </span>        encoding, errors, newline: same as `open`.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def write_text(self, path, value, encoding=None, errors=None, newline=</span>
<span class="gd">-        None, **kwargs):</span>
<span class="gi">+        with self.open(</span>
<span class="gi">+            path,</span>
<span class="gi">+            mode=&quot;r&quot;,</span>
<span class="gi">+            encoding=encoding,</span>
<span class="gi">+            errors=errors,</span>
<span class="gi">+            newline=newline,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        ) as f:</span>
<span class="gi">+            return f.read()</span>
<span class="gi">+</span>
<span class="gi">+    def write_text(</span>
<span class="gi">+        self, path, value, encoding=None, errors=None, newline=None, **kwargs</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Write the text to the given file.

<span class="w"> </span>        An existing file will be overwritten.
<span class="gu">@@ -472,7 +747,15 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>            Text to write.
<span class="w"> </span>        encoding, errors, newline: same as `open`.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with self.open(</span>
<span class="gi">+            path,</span>
<span class="gi">+            mode=&quot;w&quot;,</span>
<span class="gi">+            encoding=encoding,</span>
<span class="gi">+            errors=errors,</span>
<span class="gi">+            newline=newline,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        ) as f:</span>
<span class="gi">+            return f.write(value)</span>

<span class="w"> </span>    def cat_file(self, path, start=None, end=None, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Get the content of a file
<span class="gu">@@ -486,11 +769,23 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>            end of file, respectively
<span class="w"> </span>        kwargs: passed to ``open()``.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # explicitly set buffering off?</span>
<span class="gi">+        with self.open(path, &quot;rb&quot;, **kwargs) as f:</span>
<span class="gi">+            if start is not None:</span>
<span class="gi">+                if start &gt;= 0:</span>
<span class="gi">+                    f.seek(start)</span>
<span class="gi">+                else:</span>
<span class="gi">+                    f.seek(max(0, f.size + start))</span>
<span class="gi">+            if end is not None:</span>
<span class="gi">+                if end &lt; 0:</span>
<span class="gi">+                    end = f.size + end</span>
<span class="gi">+                return f.read(end - f.tell())</span>
<span class="gi">+            return f.read()</span>

<span class="w"> </span>    def pipe_file(self, path, value, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Set the bytes of given file&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with self.open(path, &quot;wb&quot;, **kwargs) as f:</span>
<span class="gi">+            f.write(value)</span>

<span class="w"> </span>    def pipe(self, path, value=None, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Put value into path
<span class="gu">@@ -506,10 +801,17 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>            If using a single path, these are the bytes to put there. Ignored if
<span class="w"> </span>            ``path`` is a dict
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(path, str):</span>
<span class="gi">+            self.pipe_file(self._strip_protocol(path), value, **kwargs)</span>
<span class="gi">+        elif isinstance(path, dict):</span>
<span class="gi">+            for k, v in path.items():</span>
<span class="gi">+                self.pipe_file(self._strip_protocol(k), v, **kwargs)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise ValueError(&quot;path must be str or dict&quot;)</span>

<span class="gd">-    def cat_ranges(self, paths, starts, ends, max_gap=None, on_error=</span>
<span class="gd">-        &#39;return&#39;, **kwargs):</span>
<span class="gi">+    def cat_ranges(</span>
<span class="gi">+        self, paths, starts, ends, max_gap=None, on_error=&quot;return&quot;, **kwargs</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Get the contents of byte ranges from one or more files

<span class="w"> </span>        Parameters
<span class="gu">@@ -520,9 +822,28 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>            Bytes limits of the read. If using a single int, the same value will be
<span class="w"> </span>            used to read all the specified files.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def cat(self, path, recursive=False, on_error=&#39;raise&#39;, **kwargs):</span>
<span class="gi">+        if max_gap is not None:</span>
<span class="gi">+            raise NotImplementedError</span>
<span class="gi">+        if not isinstance(paths, list):</span>
<span class="gi">+            raise TypeError</span>
<span class="gi">+        if not isinstance(starts, list):</span>
<span class="gi">+            starts = [starts] * len(paths)</span>
<span class="gi">+        if not isinstance(ends, list):</span>
<span class="gi">+            ends = [ends] * len(paths)</span>
<span class="gi">+        if len(starts) != len(paths) or len(ends) != len(paths):</span>
<span class="gi">+            raise ValueError</span>
<span class="gi">+        out = []</span>
<span class="gi">+        for p, s, e in zip(paths, starts, ends):</span>
<span class="gi">+            try:</span>
<span class="gi">+                out.append(self.cat_file(p, s, e))</span>
<span class="gi">+            except Exception as e:</span>
<span class="gi">+                if on_error == &quot;return&quot;:</span>
<span class="gi">+                    out.append(e)</span>
<span class="gi">+                else:</span>
<span class="gi">+                    raise</span>
<span class="gi">+        return out</span>
<span class="gi">+</span>
<span class="gi">+    def cat(self, path, recursive=False, on_error=&quot;raise&quot;, **kwargs):</span>
<span class="w"> </span>        &quot;&quot;&quot;Fetch (potentially multiple) paths&#39; contents

<span class="w"> </span>        Parameters
<span class="gu">@@ -543,15 +864,64 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        dict of {path: contents} if there are multiple paths
<span class="w"> </span>        or the path has been otherwise expanded
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        paths = self.expand_path(path, recursive=recursive)</span>
<span class="gi">+        if (</span>
<span class="gi">+            len(paths) &gt; 1</span>
<span class="gi">+            or isinstance(path, list)</span>
<span class="gi">+            or paths[0] != self._strip_protocol(path)</span>
<span class="gi">+        ):</span>
<span class="gi">+            out = {}</span>
<span class="gi">+            for path in paths:</span>
<span class="gi">+                try:</span>
<span class="gi">+                    out[path] = self.cat_file(path, **kwargs)</span>
<span class="gi">+                except Exception as e:</span>
<span class="gi">+                    if on_error == &quot;raise&quot;:</span>
<span class="gi">+                        raise</span>
<span class="gi">+                    if on_error == &quot;return&quot;:</span>
<span class="gi">+                        out[path] = e</span>
<span class="gi">+            return out</span>
<span class="gi">+        else:</span>
<span class="gi">+            return self.cat_file(paths[0], **kwargs)</span>

<span class="gd">-    def get_file(self, rpath, lpath, callback=DEFAULT_CALLBACK, outfile=</span>
<span class="gd">-        None, **kwargs):</span>
<span class="gi">+    def get_file(self, rpath, lpath, callback=DEFAULT_CALLBACK, outfile=None, **kwargs):</span>
<span class="w"> </span>        &quot;&quot;&quot;Copy single remote file to local&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def get(self, rpath, lpath, recursive=False, callback=DEFAULT_CALLBACK,</span>
<span class="gd">-        maxdepth=None, **kwargs):</span>
<span class="gi">+        from .implementations.local import LocalFileSystem</span>
<span class="gi">+</span>
<span class="gi">+        if isfilelike(lpath):</span>
<span class="gi">+            outfile = lpath</span>
<span class="gi">+        elif self.isdir(rpath):</span>
<span class="gi">+            os.makedirs(lpath, exist_ok=True)</span>
<span class="gi">+            return None</span>
<span class="gi">+</span>
<span class="gi">+        fs = LocalFileSystem(auto_mkdir=True)</span>
<span class="gi">+        fs.makedirs(fs._parent(lpath), exist_ok=True)</span>
<span class="gi">+</span>
<span class="gi">+        with self.open(rpath, &quot;rb&quot;, **kwargs) as f1:</span>
<span class="gi">+            if outfile is None:</span>
<span class="gi">+                outfile = open(lpath, &quot;wb&quot;)</span>
<span class="gi">+</span>
<span class="gi">+            try:</span>
<span class="gi">+                callback.set_size(getattr(f1, &quot;size&quot;, None))</span>
<span class="gi">+                data = True</span>
<span class="gi">+                while data:</span>
<span class="gi">+                    data = f1.read(self.blocksize)</span>
<span class="gi">+                    segment_len = outfile.write(data)</span>
<span class="gi">+                    if segment_len is None:</span>
<span class="gi">+                        segment_len = len(data)</span>
<span class="gi">+                    callback.relative_update(segment_len)</span>
<span class="gi">+            finally:</span>
<span class="gi">+                if not isfilelike(lpath):</span>
<span class="gi">+                    outfile.close()</span>
<span class="gi">+</span>
<span class="gi">+    def get(</span>
<span class="gi">+        self,</span>
<span class="gi">+        rpath,</span>
<span class="gi">+        lpath,</span>
<span class="gi">+        recursive=False,</span>
<span class="gi">+        callback=DEFAULT_CALLBACK,</span>
<span class="gi">+        maxdepth=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Copy file(s) to local.

<span class="w"> </span>        Copies a specific file or tree of files (if recursive=True). If lpath
<span class="gu">@@ -561,14 +931,79 @@ class AbstractFileSystem(metaclass=_Cached):</span>

<span class="w"> </span>        Calls get_file for each source.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(lpath, list) and isinstance(rpath, list):</span>
<span class="gi">+            # No need to expand paths when both source and destination</span>
<span class="gi">+            # are provided as lists</span>
<span class="gi">+            rpaths = rpath</span>
<span class="gi">+            lpaths = lpath</span>
<span class="gi">+        else:</span>
<span class="gi">+            from .implementations.local import (</span>
<span class="gi">+                LocalFileSystem,</span>
<span class="gi">+                make_path_posix,</span>
<span class="gi">+                trailing_sep,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            source_is_str = isinstance(rpath, str)</span>
<span class="gi">+            rpaths = self.expand_path(rpath, recursive=recursive, maxdepth=maxdepth)</span>
<span class="gi">+            if source_is_str and (not recursive or maxdepth is not None):</span>
<span class="gi">+                # Non-recursive glob does not copy directories</span>
<span class="gi">+                rpaths = [p for p in rpaths if not (trailing_sep(p) or self.isdir(p))]</span>
<span class="gi">+                if not rpaths:</span>
<span class="gi">+                    return</span>
<span class="gi">+</span>
<span class="gi">+            if isinstance(lpath, str):</span>
<span class="gi">+                lpath = make_path_posix(lpath)</span>
<span class="gi">+</span>
<span class="gi">+            source_is_file = len(rpaths) == 1</span>
<span class="gi">+            dest_is_dir = isinstance(lpath, str) and (</span>
<span class="gi">+                trailing_sep(lpath) or LocalFileSystem().isdir(lpath)</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            exists = source_is_str and (</span>
<span class="gi">+                (has_magic(rpath) and source_is_file)</span>
<span class="gi">+                or (not has_magic(rpath) and dest_is_dir and not trailing_sep(rpath))</span>
<span class="gi">+            )</span>
<span class="gi">+            lpaths = other_paths(</span>
<span class="gi">+                rpaths,</span>
<span class="gi">+                lpath,</span>
<span class="gi">+                exists=exists,</span>
<span class="gi">+                flatten=not source_is_str,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        callback.set_size(len(lpaths))</span>
<span class="gi">+        for lpath, rpath in callback.wrap(zip(lpaths, rpaths)):</span>
<span class="gi">+            with callback.branched(rpath, lpath) as child:</span>
<span class="gi">+                self.get_file(rpath, lpath, callback=child, **kwargs)</span>

<span class="w"> </span>    def put_file(self, lpath, rpath, callback=DEFAULT_CALLBACK, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Copy single file to remote&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def put(self, lpath, rpath, recursive=False, callback=DEFAULT_CALLBACK,</span>
<span class="gd">-        maxdepth=None, **kwargs):</span>
<span class="gi">+        if os.path.isdir(lpath):</span>
<span class="gi">+            self.makedirs(rpath, exist_ok=True)</span>
<span class="gi">+            return None</span>
<span class="gi">+</span>
<span class="gi">+        with open(lpath, &quot;rb&quot;) as f1:</span>
<span class="gi">+            size = f1.seek(0, 2)</span>
<span class="gi">+            callback.set_size(size)</span>
<span class="gi">+            f1.seek(0)</span>
<span class="gi">+</span>
<span class="gi">+            self.mkdirs(self._parent(os.fspath(rpath)), exist_ok=True)</span>
<span class="gi">+            with self.open(rpath, &quot;wb&quot;, **kwargs) as f2:</span>
<span class="gi">+                while f1.tell() &lt; size:</span>
<span class="gi">+                    data = f1.read(self.blocksize)</span>
<span class="gi">+                    segment_len = f2.write(data)</span>
<span class="gi">+                    if segment_len is None:</span>
<span class="gi">+                        segment_len = len(data)</span>
<span class="gi">+                    callback.relative_update(segment_len)</span>
<span class="gi">+</span>
<span class="gi">+    def put(</span>
<span class="gi">+        self,</span>
<span class="gi">+        lpath,</span>
<span class="gi">+        rpath,</span>
<span class="gi">+        recursive=False,</span>
<span class="gi">+        callback=DEFAULT_CALLBACK,</span>
<span class="gi">+        maxdepth=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Copy file(s) from local.

<span class="w"> </span>        Copies a specific file or tree of files (if recursive=True). If rpath
<span class="gu">@@ -577,18 +1012,72 @@ class AbstractFileSystem(metaclass=_Cached):</span>

<span class="w"> </span>        Calls put_file for each source.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(lpath, list) and isinstance(rpath, list):</span>
<span class="gi">+            # No need to expand paths when both source and destination</span>
<span class="gi">+            # are provided as lists</span>
<span class="gi">+            rpaths = rpath</span>
<span class="gi">+            lpaths = lpath</span>
<span class="gi">+        else:</span>
<span class="gi">+            from .implementations.local import (</span>
<span class="gi">+                LocalFileSystem,</span>
<span class="gi">+                make_path_posix,</span>
<span class="gi">+                trailing_sep,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            source_is_str = isinstance(lpath, str)</span>
<span class="gi">+            if source_is_str:</span>
<span class="gi">+                lpath = make_path_posix(lpath)</span>
<span class="gi">+            fs = LocalFileSystem()</span>
<span class="gi">+            lpaths = fs.expand_path(lpath, recursive=recursive, maxdepth=maxdepth)</span>
<span class="gi">+            if source_is_str and (not recursive or maxdepth is not None):</span>
<span class="gi">+                # Non-recursive glob does not copy directories</span>
<span class="gi">+                lpaths = [p for p in lpaths if not (trailing_sep(p) or fs.isdir(p))]</span>
<span class="gi">+                if not lpaths:</span>
<span class="gi">+                    return</span>
<span class="gi">+</span>
<span class="gi">+            source_is_file = len(lpaths) == 1</span>
<span class="gi">+            dest_is_dir = isinstance(rpath, str) and (</span>
<span class="gi">+                trailing_sep(rpath) or self.isdir(rpath)</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            rpath = (</span>
<span class="gi">+                self._strip_protocol(rpath)</span>
<span class="gi">+                if isinstance(rpath, str)</span>
<span class="gi">+                else [self._strip_protocol(p) for p in rpath]</span>
<span class="gi">+            )</span>
<span class="gi">+            exists = source_is_str and (</span>
<span class="gi">+                (has_magic(lpath) and source_is_file)</span>
<span class="gi">+                or (not has_magic(lpath) and dest_is_dir and not trailing_sep(lpath))</span>
<span class="gi">+            )</span>
<span class="gi">+            rpaths = other_paths(</span>
<span class="gi">+                lpaths,</span>
<span class="gi">+                rpath,</span>
<span class="gi">+                exists=exists,</span>
<span class="gi">+                flatten=not source_is_str,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        callback.set_size(len(rpaths))</span>
<span class="gi">+        for lpath, rpath in callback.wrap(zip(lpaths, rpaths)):</span>
<span class="gi">+            with callback.branched(lpath, rpath) as child:</span>
<span class="gi">+                self.put_file(lpath, rpath, callback=child, **kwargs)</span>

<span class="w"> </span>    def head(self, path, size=1024):
<span class="w"> </span>        &quot;&quot;&quot;Get the first ``size`` bytes from file&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with self.open(path, &quot;rb&quot;) as f:</span>
<span class="gi">+            return f.read(size)</span>

<span class="w"> </span>    def tail(self, path, size=1024):
<span class="w"> </span>        &quot;&quot;&quot;Get the last ``size`` bytes from file&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with self.open(path, &quot;rb&quot;) as f:</span>
<span class="gi">+            f.seek(max(-size, -f.size), 2)</span>
<span class="gi">+            return f.read()</span>
<span class="gi">+</span>
<span class="gi">+    def cp_file(self, path1, path2, **kwargs):</span>
<span class="gi">+        raise NotImplementedError</span>

<span class="gd">-    def copy(self, path1, path2, recursive=False, maxdepth=None, on_error=</span>
<span class="gd">-        None, **kwargs):</span>
<span class="gi">+    def copy(</span>
<span class="gi">+        self, path1, path2, recursive=False, maxdepth=None, on_error=None, **kwargs</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Copy within two locations in the filesystem

<span class="w"> </span>        on_error : &quot;raise&quot;, &quot;ignore&quot;
<span class="gu">@@ -596,7 +1085,49 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>            not-found exceptions will cause the path to be skipped; defaults to
<span class="w"> </span>            raise unless recursive is true, where the default is ignore
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if on_error is None and recursive:</span>
<span class="gi">+            on_error = &quot;ignore&quot;</span>
<span class="gi">+        elif on_error is None:</span>
<span class="gi">+            on_error = &quot;raise&quot;</span>
<span class="gi">+</span>
<span class="gi">+        if isinstance(path1, list) and isinstance(path2, list):</span>
<span class="gi">+            # No need to expand paths when both source and destination</span>
<span class="gi">+            # are provided as lists</span>
<span class="gi">+            paths1 = path1</span>
<span class="gi">+            paths2 = path2</span>
<span class="gi">+        else:</span>
<span class="gi">+            from .implementations.local import trailing_sep</span>
<span class="gi">+</span>
<span class="gi">+            source_is_str = isinstance(path1, str)</span>
<span class="gi">+            paths1 = self.expand_path(path1, recursive=recursive, maxdepth=maxdepth)</span>
<span class="gi">+            if source_is_str and (not recursive or maxdepth is not None):</span>
<span class="gi">+                # Non-recursive glob does not copy directories</span>
<span class="gi">+                paths1 = [p for p in paths1 if not (trailing_sep(p) or self.isdir(p))]</span>
<span class="gi">+                if not paths1:</span>
<span class="gi">+                    return</span>
<span class="gi">+</span>
<span class="gi">+            source_is_file = len(paths1) == 1</span>
<span class="gi">+            dest_is_dir = isinstance(path2, str) and (</span>
<span class="gi">+                trailing_sep(path2) or self.isdir(path2)</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            exists = source_is_str and (</span>
<span class="gi">+                (has_magic(path1) and source_is_file)</span>
<span class="gi">+                or (not has_magic(path1) and dest_is_dir and not trailing_sep(path1))</span>
<span class="gi">+            )</span>
<span class="gi">+            paths2 = other_paths(</span>
<span class="gi">+                paths1,</span>
<span class="gi">+                path2,</span>
<span class="gi">+                exists=exists,</span>
<span class="gi">+                flatten=not source_is_str,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        for p1, p2 in zip(paths1, paths2):</span>
<span class="gi">+            try:</span>
<span class="gi">+                self.cp_file(p1, p2, **kwargs)</span>
<span class="gi">+            except FileNotFoundError:</span>
<span class="gi">+                if on_error == &quot;raise&quot;:</span>
<span class="gi">+                    raise</span>

<span class="w"> </span>    def expand_path(self, path, recursive=False, maxdepth=None, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Turn one or more globs or directories into a list of all matching paths
<span class="gu">@@ -604,19 +1135,67 @@ class AbstractFileSystem(metaclass=_Cached):</span>

<span class="w"> </span>        kwargs are passed to ``glob`` or ``find``, which may in turn call ``ls``
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+</span>
<span class="gi">+        if maxdepth is not None and maxdepth &lt; 1:</span>
<span class="gi">+            raise ValueError(&quot;maxdepth must be at least 1&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        if isinstance(path, (str, os.PathLike)):</span>
<span class="gi">+            out = self.expand_path([path], recursive, maxdepth)</span>
<span class="gi">+        else:</span>
<span class="gi">+            out = set()</span>
<span class="gi">+            path = [self._strip_protocol(p) for p in path]</span>
<span class="gi">+            for p in path:</span>
<span class="gi">+                if has_magic(p):</span>
<span class="gi">+                    bit = set(self.glob(p, maxdepth=maxdepth, **kwargs))</span>
<span class="gi">+                    out |= bit</span>
<span class="gi">+                    if recursive:</span>
<span class="gi">+                        # glob call above expanded one depth so if maxdepth is defined</span>
<span class="gi">+                        # then decrement it in expand_path call below. If it is zero</span>
<span class="gi">+                        # after decrementing then avoid expand_path call.</span>
<span class="gi">+                        if maxdepth is not None and maxdepth &lt;= 1:</span>
<span class="gi">+                            continue</span>
<span class="gi">+                        out |= set(</span>
<span class="gi">+                            self.expand_path(</span>
<span class="gi">+                                list(bit),</span>
<span class="gi">+                                recursive=recursive,</span>
<span class="gi">+                                maxdepth=maxdepth - 1 if maxdepth is not None else None,</span>
<span class="gi">+                                **kwargs,</span>
<span class="gi">+                            )</span>
<span class="gi">+                        )</span>
<span class="gi">+                    continue</span>
<span class="gi">+                elif recursive:</span>
<span class="gi">+                    rec = set(</span>
<span class="gi">+                        self.find(</span>
<span class="gi">+                            p, maxdepth=maxdepth, withdirs=True, detail=False, **kwargs</span>
<span class="gi">+                        )</span>
<span class="gi">+                    )</span>
<span class="gi">+                    out |= rec</span>
<span class="gi">+                if p not in out and (recursive is False or self.exists(p)):</span>
<span class="gi">+                    # should only check once, for the root</span>
<span class="gi">+                    out.add(p)</span>
<span class="gi">+        if not out:</span>
<span class="gi">+            raise FileNotFoundError(path)</span>
<span class="gi">+        return sorted(out)</span>

<span class="w"> </span>    def mv(self, path1, path2, recursive=False, maxdepth=None, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Move file(s) from one location to another&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if path1 == path2:</span>
<span class="gi">+            logger.debug(&quot;%s mv: The paths are the same, so no files were moved.&quot;, self)</span>
<span class="gi">+        else:</span>
<span class="gi">+            # explicitly raise exception to prevent data corruption</span>
<span class="gi">+            self.copy(</span>
<span class="gi">+                path1, path2, recursive=recursive, maxdepth=maxdepth, onerror=&quot;raise&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+            self.rm(path1, recursive=recursive)</span>

<span class="w"> </span>    def rm_file(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Delete a file&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._rm(path)</span>

<span class="w"> </span>    def _rm(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Delete one file&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # this is the old name for the method, prefer rm_file</span>
<span class="gi">+        raise NotImplementedError</span>

<span class="w"> </span>    def rm(self, path, recursive=False, maxdepth=None):
<span class="w"> </span>        &quot;&quot;&quot;Delete files.
<span class="gu">@@ -633,15 +1212,48 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>            If None, there will be no limit and infinite recursion may be
<span class="w"> </span>            possible.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        path = self.expand_path(path, recursive=recursive, maxdepth=maxdepth)</span>
<span class="gi">+        for p in reversed(path):</span>
<span class="gi">+            self.rm_file(p)</span>

<span class="gd">-    def _open(self, path, mode=&#39;rb&#39;, block_size=None, autocommit=True,</span>
<span class="gd">-        cache_options=None, **kwargs):</span>
<span class="gi">+    @classmethod</span>
<span class="gi">+    def _parent(cls, path):</span>
<span class="gi">+        path = cls._strip_protocol(path)</span>
<span class="gi">+        if &quot;/&quot; in path:</span>
<span class="gi">+            parent = path.rsplit(&quot;/&quot;, 1)[0].lstrip(cls.root_marker)</span>
<span class="gi">+            return cls.root_marker + parent</span>
<span class="gi">+        else:</span>
<span class="gi">+            return cls.root_marker</span>
<span class="gi">+</span>
<span class="gi">+    def _open(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=None,</span>
<span class="gi">+        autocommit=True,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Return raw bytes-mode file-like from the file-system&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def open(self, path, mode=&#39;rb&#39;, block_size=None, cache_options=None,</span>
<span class="gd">-        compression=None, **kwargs):</span>
<span class="gi">+        return AbstractBufferedFile(</span>
<span class="gi">+            self,</span>
<span class="gi">+            path,</span>
<span class="gi">+            mode,</span>
<span class="gi">+            block_size,</span>
<span class="gi">+            autocommit,</span>
<span class="gi">+            cache_options=cache_options,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def open(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=None,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        compression=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Return a file-like object from the filesystem

<span class="gu">@@ -664,7 +1276,49 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>            compression from the filename suffix.
<span class="w"> </span>        encoding, errors, newline: passed on to TextIOWrapper for text mode
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        import io</span>
<span class="gi">+</span>
<span class="gi">+        path = self._strip_protocol(path)</span>
<span class="gi">+        if &quot;b&quot; not in mode:</span>
<span class="gi">+            mode = mode.replace(&quot;t&quot;, &quot;&quot;) + &quot;b&quot;</span>
<span class="gi">+</span>
<span class="gi">+            text_kwargs = {</span>
<span class="gi">+                k: kwargs.pop(k)</span>
<span class="gi">+                for k in [&quot;encoding&quot;, &quot;errors&quot;, &quot;newline&quot;]</span>
<span class="gi">+                if k in kwargs</span>
<span class="gi">+            }</span>
<span class="gi">+            return io.TextIOWrapper(</span>
<span class="gi">+                self.open(</span>
<span class="gi">+                    path,</span>
<span class="gi">+                    mode,</span>
<span class="gi">+                    block_size=block_size,</span>
<span class="gi">+                    cache_options=cache_options,</span>
<span class="gi">+                    compression=compression,</span>
<span class="gi">+                    **kwargs,</span>
<span class="gi">+                ),</span>
<span class="gi">+                **text_kwargs,</span>
<span class="gi">+            )</span>
<span class="gi">+        else:</span>
<span class="gi">+            ac = kwargs.pop(&quot;autocommit&quot;, not self._intrans)</span>
<span class="gi">+            f = self._open(</span>
<span class="gi">+                path,</span>
<span class="gi">+                mode=mode,</span>
<span class="gi">+                block_size=block_size,</span>
<span class="gi">+                autocommit=ac,</span>
<span class="gi">+                cache_options=cache_options,</span>
<span class="gi">+                **kwargs,</span>
<span class="gi">+            )</span>
<span class="gi">+            if compression is not None:</span>
<span class="gi">+                from fsspec.compression import compr</span>
<span class="gi">+                from fsspec.core import get_compression</span>
<span class="gi">+</span>
<span class="gi">+                compression = get_compression(path, compression)</span>
<span class="gi">+                compress = compr[compression]</span>
<span class="gi">+                f = compress(f, mode=mode[0])</span>
<span class="gi">+</span>
<span class="gi">+            if not ac and &quot;r&quot; not in mode:</span>
<span class="gi">+                self.transaction.files.append(f)</span>
<span class="gi">+            return f</span>

<span class="w"> </span>    def touch(self, path, truncate=True, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Create empty file, or update timestamp
<span class="gu">@@ -677,11 +1331,15 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>            If True, always set file size to 0; if False, update timestamp and
<span class="w"> </span>            leave file unchanged, if backend allows this
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if truncate or not self.exists(path):</span>
<span class="gi">+            with self.open(path, &quot;wb&quot;, **kwargs):</span>
<span class="gi">+                pass</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise NotImplementedError  # update timestamp, if possible</span>

<span class="w"> </span>    def ukey(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Hash of file properties, to tell if it has changed&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return sha256(str(self.info(path)).encode()).hexdigest()</span>

<span class="w"> </span>    def read_block(self, fn, offset, length, delimiter=None):
<span class="w"> </span>        &quot;&quot;&quot;Read a block of bytes from
<span class="gu">@@ -720,9 +1378,15 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        :func:`fsspec.utils.read_block`
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def to_json(self, *, include_password: bool=True) -&gt;str:</span>
<span class="gi">+        with self.open(fn, &quot;rb&quot;) as f:</span>
<span class="gi">+            size = f.size</span>
<span class="gi">+            if length is None:</span>
<span class="gi">+                length = size</span>
<span class="gi">+            if size is not None and offset + length &gt; size:</span>
<span class="gi">+                length = size - offset</span>
<span class="gi">+            return read_block(f, offset, length, delimiter)</span>
<span class="gi">+</span>
<span class="gi">+    def to_json(self, *, include_password: bool = True) -&gt; str:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        JSON representation of this filesystem instance.

<span class="gu">@@ -744,10 +1408,19 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        passed to the constructor, such as passwords and tokens. Make sure you
<span class="w"> </span>        store and send them in a secure environment!
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from .json import FilesystemJSONEncoder</span>
<span class="gi">+</span>
<span class="gi">+        return json.dumps(</span>
<span class="gi">+            self,</span>
<span class="gi">+            cls=type(</span>
<span class="gi">+                &quot;_FilesystemJSONEncoder&quot;,</span>
<span class="gi">+                (FilesystemJSONEncoder,),</span>
<span class="gi">+                {&quot;include_password&quot;: include_password},</span>
<span class="gi">+            ),</span>
<span class="gi">+        )</span>

<span class="w"> </span>    @staticmethod
<span class="gd">-    def from_json(blob: str) -&gt;AbstractFileSystem:</span>
<span class="gi">+    def from_json(blob: str) -&gt; AbstractFileSystem:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Recreate a filesystem instance from JSON representation.

<span class="gu">@@ -767,9 +1440,11 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        Make sure you haven&#39;t installed any modules that may execute malicious code
<span class="w"> </span>        at import time.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from .json import FilesystemJSONDecoder</span>
<span class="gi">+</span>
<span class="gi">+        return json.loads(blob, cls=FilesystemJSONDecoder)</span>

<span class="gd">-    def to_dict(self, *, include_password: bool=True) -&gt;Dict[str, Any]:</span>
<span class="gi">+    def to_dict(self, *, include_password: bool = True) -&gt; Dict[str, Any]:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        JSON-serializable dictionary representation of this filesystem instance.

<span class="gu">@@ -791,10 +1466,26 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        passed to the constructor, such as passwords and tokens. Make sure you
<span class="w"> </span>        store and send them in a secure environment!
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from .json import FilesystemJSONEncoder</span>
<span class="gi">+</span>
<span class="gi">+        json_encoder = FilesystemJSONEncoder()</span>
<span class="gi">+</span>
<span class="gi">+        cls = type(self)</span>
<span class="gi">+        proto = self.protocol</span>
<span class="gi">+</span>
<span class="gi">+        storage_options = dict(self.storage_options)</span>
<span class="gi">+        if not include_password:</span>
<span class="gi">+            storage_options.pop(&quot;password&quot;, None)</span>
<span class="gi">+</span>
<span class="gi">+        return dict(</span>
<span class="gi">+            cls=f&quot;{cls.__module__}:{cls.__name__}&quot;,</span>
<span class="gi">+            protocol=proto[0] if isinstance(proto, (tuple, list)) else proto,</span>
<span class="gi">+            args=json_encoder.make_serializable(self.storage_args),</span>
<span class="gi">+            **json_encoder.make_serializable(storage_options),</span>
<span class="gi">+        )</span>

<span class="w"> </span>    @staticmethod
<span class="gd">-    def from_dict(dct: Dict[str, Any]) -&gt;AbstractFileSystem:</span>
<span class="gi">+    def from_dict(dct: Dict[str, Any]) -&gt; AbstractFileSystem:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Recreate a filesystem instance from dictionary representation.

<span class="gu">@@ -814,22 +1505,46 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        Make sure you haven&#39;t installed any modules that may execute malicious code
<span class="w"> </span>        at import time.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from .json import FilesystemJSONDecoder</span>
<span class="gi">+</span>
<span class="gi">+        json_decoder = FilesystemJSONDecoder()</span>
<span class="gi">+</span>
<span class="gi">+        dct = dict(dct)  # Defensive copy</span>
<span class="gi">+</span>
<span class="gi">+        cls = FilesystemJSONDecoder.try_resolve_fs_cls(dct)</span>
<span class="gi">+        if cls is None:</span>
<span class="gi">+            raise ValueError(&quot;Not a serialized AbstractFileSystem&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        dct.pop(&quot;cls&quot;, None)</span>
<span class="gi">+        dct.pop(&quot;protocol&quot;, None)</span>
<span class="gi">+</span>
<span class="gi">+        return cls(</span>
<span class="gi">+            *json_decoder.unmake_serializable(dct.pop(&quot;args&quot;, ())),</span>
<span class="gi">+            **json_decoder.unmake_serializable(dct),</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def _get_pyarrow_filesystem(self):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Make a version of the FS instance which will be acceptable to pyarrow
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # all instances already also derive from pyarrow</span>
<span class="gi">+        return self</span>

<span class="gd">-    def get_mapper(self, root=&#39;&#39;, check=False, create=False,</span>
<span class="gd">-        missing_exceptions=None):</span>
<span class="gi">+    def get_mapper(self, root=&quot;&quot;, check=False, create=False, missing_exceptions=None):</span>
<span class="w"> </span>        &quot;&quot;&quot;Create key/value store based on this file-system

<span class="w"> </span>        Makes a MutableMapping interface to the FS at the given root path.
<span class="w"> </span>        See ``fsspec.mapping.FSMap`` for further details.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from .mapping import FSMap</span>
<span class="gi">+</span>
<span class="gi">+        return FSMap(</span>
<span class="gi">+            root,</span>
<span class="gi">+            self,</span>
<span class="gi">+            check=check,</span>
<span class="gi">+            create=create,</span>
<span class="gi">+            missing_exceptions=missing_exceptions,</span>
<span class="gi">+        )</span>

<span class="w"> </span>    @classmethod
<span class="w"> </span>    def clear_instance_cache(cls):
<span class="gu">@@ -844,67 +1559,70 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        since the instances refcount will not drop to zero until
<span class="w"> </span>        ``clear_instance_cache`` is called.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        cls._cache.clear()</span>

<span class="w"> </span>    def created(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Return the created timestamp of a file as a datetime.datetime&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        raise NotImplementedError</span>

<span class="w"> </span>    def modified(self, path):
<span class="w"> </span>        &quot;&quot;&quot;Return the modified timestamp of a file as a datetime.datetime&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        raise NotImplementedError</span>
<span class="gi">+</span>
<span class="gi">+    # ------------------------------------------------------------------------</span>
<span class="gi">+    # Aliases</span>

<span class="w"> </span>    def read_bytes(self, path, start=None, end=None, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Alias of `AbstractFileSystem.cat_file`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.cat_file(path, start=start, end=end, **kwargs)</span>

<span class="w"> </span>    def write_bytes(self, path, value, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Alias of `AbstractFileSystem.pipe_file`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.pipe_file(path, value, **kwargs)</span>

<span class="w"> </span>    def makedir(self, path, create_parents=True, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Alias of `AbstractFileSystem.mkdir`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.mkdir(path, create_parents=create_parents, **kwargs)</span>

<span class="w"> </span>    def mkdirs(self, path, exist_ok=False):
<span class="w"> </span>        &quot;&quot;&quot;Alias of `AbstractFileSystem.makedirs`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.makedirs(path, exist_ok=exist_ok)</span>

<span class="w"> </span>    def listdir(self, path, detail=True, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Alias of `AbstractFileSystem.ls`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.ls(path, detail=detail, **kwargs)</span>

<span class="w"> </span>    def cp(self, path1, path2, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Alias of `AbstractFileSystem.copy`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.copy(path1, path2, **kwargs)</span>

<span class="w"> </span>    def move(self, path1, path2, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Alias of `AbstractFileSystem.mv`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.mv(path1, path2, **kwargs)</span>

<span class="w"> </span>    def stat(self, path, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Alias of `AbstractFileSystem.info`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.info(path, **kwargs)</span>

<span class="w"> </span>    def disk_usage(self, path, total=True, maxdepth=None, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Alias of `AbstractFileSystem.du`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.du(path, total=total, maxdepth=maxdepth, **kwargs)</span>

<span class="w"> </span>    def rename(self, path1, path2, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Alias of `AbstractFileSystem.mv`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.mv(path1, path2, **kwargs)</span>

<span class="w"> </span>    def delete(self, path, recursive=False, maxdepth=None):
<span class="w"> </span>        &quot;&quot;&quot;Alias of `AbstractFileSystem.rm`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.rm(path, recursive=recursive, maxdepth=maxdepth)</span>

<span class="w"> </span>    def upload(self, lpath, rpath, recursive=False, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Alias of `AbstractFileSystem.put`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.put(lpath, rpath, recursive=recursive, **kwargs)</span>

<span class="w"> </span>    def download(self, rpath, lpath, recursive=False, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Alias of `AbstractFileSystem.get`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.get(rpath, lpath, recursive=recursive, **kwargs)</span>

<span class="w"> </span>    def sign(self, path, expiration=100, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Create a signed URL representing the given path
<span class="gu">@@ -928,7 +1646,14 @@ class AbstractFileSystem(metaclass=_Cached):</span>
<span class="w"> </span>        ------
<span class="w"> </span>        NotImplementedError : if method is not implemented for a filesystem
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        raise NotImplementedError(&quot;Sign is not implemented for this filesystem&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def _isfilestore(self):</span>
<span class="gi">+        # Originally inherited from pyarrow DaskFileSystem. Keeping this</span>
<span class="gi">+        # here for backwards compatibility as long as pyarrow uses its</span>
<span class="gi">+        # legacy fsspec-compatible filesystems and thus accepts fsspec</span>
<span class="gi">+        # filesystems as well</span>
<span class="gi">+        return False</span>


<span class="w"> </span>class AbstractBufferedFile(io.IOBase):
<span class="gu">@@ -939,12 +1664,22 @@ class AbstractBufferedFile(io.IOBase):</span>
<span class="w"> </span>    methods that need to be overridden are ``_upload_chunk``,
<span class="w"> </span>    ``_initiate_upload`` and ``_fetch_range``.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    DEFAULT_BLOCK_SIZE = 5 * 2 ** 20</span>
<span class="gi">+</span>
<span class="gi">+    DEFAULT_BLOCK_SIZE = 5 * 2**20</span>
<span class="w"> </span>    _details = None

<span class="gd">-    def __init__(self, fs, path, mode=&#39;rb&#39;, block_size=&#39;default&#39;,</span>
<span class="gd">-        autocommit=True, cache_type=&#39;readahead&#39;, cache_options=None, size=</span>
<span class="gd">-        None, **kwargs):</span>
<span class="gi">+    def __init__(</span>
<span class="gi">+        self,</span>
<span class="gi">+        fs,</span>
<span class="gi">+        path,</span>
<span class="gi">+        mode=&quot;rb&quot;,</span>
<span class="gi">+        block_size=&quot;default&quot;,</span>
<span class="gi">+        autocommit=True,</span>
<span class="gi">+        cache_type=&quot;readahead&quot;,</span>
<span class="gi">+        cache_options=None,</span>
<span class="gi">+        size=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Template for files with buffered reading and writing

<span class="gu">@@ -972,41 +1707,75 @@ class AbstractBufferedFile(io.IOBase):</span>
<span class="w"> </span>            Gets stored as self.kwargs
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        from .core import caches
<span class="gi">+</span>
<span class="w"> </span>        self.path = path
<span class="w"> </span>        self.fs = fs
<span class="w"> </span>        self.mode = mode
<span class="gd">-        self.blocksize = self.DEFAULT_BLOCK_SIZE if block_size in [&#39;default&#39;,</span>
<span class="gd">-            None] else block_size</span>
<span class="gi">+        self.blocksize = (</span>
<span class="gi">+            self.DEFAULT_BLOCK_SIZE if block_size in [&quot;default&quot;, None] else block_size</span>
<span class="gi">+        )</span>
<span class="w"> </span>        self.loc = 0
<span class="w"> </span>        self.autocommit = autocommit
<span class="w"> </span>        self.end = None
<span class="w"> </span>        self.start = None
<span class="w"> </span>        self.closed = False
<span class="gi">+</span>
<span class="w"> </span>        if cache_options is None:
<span class="w"> </span>            cache_options = {}
<span class="gd">-        if &#39;trim&#39; in kwargs:</span>
<span class="gi">+</span>
<span class="gi">+        if &quot;trim&quot; in kwargs:</span>
<span class="w"> </span>            warnings.warn(
<span class="gd">-                &quot;Passing &#39;trim&#39; to control the cache behavior has been deprecated. Specify it within the &#39;cache_options&#39; argument instead.&quot;</span>
<span class="gd">-                , FutureWarning)</span>
<span class="gd">-            cache_options[&#39;trim&#39;] = kwargs.pop(&#39;trim&#39;)</span>
<span class="gi">+                &quot;Passing &#39;trim&#39; to control the cache behavior has been deprecated. &quot;</span>
<span class="gi">+                &quot;Specify it within the &#39;cache_options&#39; argument instead.&quot;,</span>
<span class="gi">+                FutureWarning,</span>
<span class="gi">+            )</span>
<span class="gi">+            cache_options[&quot;trim&quot;] = kwargs.pop(&quot;trim&quot;)</span>
<span class="gi">+</span>
<span class="w"> </span>        self.kwargs = kwargs
<span class="gd">-        if mode not in {&#39;ab&#39;, &#39;rb&#39;, &#39;wb&#39;}:</span>
<span class="gd">-            raise NotImplementedError(&#39;File mode not supported&#39;)</span>
<span class="gd">-        if mode == &#39;rb&#39;:</span>
<span class="gi">+</span>
<span class="gi">+        if mode not in {&quot;ab&quot;, &quot;rb&quot;, &quot;wb&quot;}:</span>
<span class="gi">+            raise NotImplementedError(&quot;File mode not supported&quot;)</span>
<span class="gi">+        if mode == &quot;rb&quot;:</span>
<span class="w"> </span>            if size is not None:
<span class="w"> </span>                self.size = size
<span class="w"> </span>            else:
<span class="gd">-                self.size = self.details[&#39;size&#39;]</span>
<span class="gd">-            self.cache = caches[cache_type](self.blocksize, self.</span>
<span class="gd">-                _fetch_range, self.size, **cache_options)</span>
<span class="gi">+                self.size = self.details[&quot;size&quot;]</span>
<span class="gi">+            self.cache = caches[cache_type](</span>
<span class="gi">+                self.blocksize, self._fetch_range, self.size, **cache_options</span>
<span class="gi">+            )</span>
<span class="w"> </span>        else:
<span class="w"> </span>            self.buffer = io.BytesIO()
<span class="w"> </span>            self.offset = None
<span class="w"> </span>            self.forced = False
<span class="w"> </span>            self.location = None

<span class="gi">+    @property</span>
<span class="gi">+    def details(self):</span>
<span class="gi">+        if self._details is None:</span>
<span class="gi">+            self._details = self.fs.info(self.path)</span>
<span class="gi">+        return self._details</span>
<span class="gi">+</span>
<span class="gi">+    @details.setter</span>
<span class="gi">+    def details(self, value):</span>
<span class="gi">+        self._details = value</span>
<span class="gi">+        self.size = value[&quot;size&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def full_name(self):</span>
<span class="gi">+        return _unstrip_protocol(self.path, self.fs)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def closed(self):</span>
<span class="gi">+        # get around this attr being read-only in IOBase</span>
<span class="gi">+        # use getattr here, since this can be called during del</span>
<span class="gi">+        return getattr(self, &quot;_closed&quot;, True)</span>
<span class="gi">+</span>
<span class="gi">+    @closed.setter</span>
<span class="gi">+    def closed(self, c):</span>
<span class="gi">+        self._closed = c</span>
<span class="gi">+</span>
<span class="w"> </span>    def __hash__(self):
<span class="gd">-        if &#39;w&#39; in self.mode:</span>
<span class="gi">+        if &quot;w&quot; in self.mode:</span>
<span class="w"> </span>            return id(self)
<span class="w"> </span>        else:
<span class="w"> </span>            return int(tokenize(self.details), 16)
<span class="gu">@@ -1015,25 +1784,29 @@ class AbstractBufferedFile(io.IOBase):</span>
<span class="w"> </span>        &quot;&quot;&quot;Files are equal if they have the same checksum, only in read mode&quot;&quot;&quot;
<span class="w"> </span>        if self is other:
<span class="w"> </span>            return True
<span class="gd">-        return isinstance(other, type(self)</span>
<span class="gd">-            ) and self.mode == &#39;rb&#39; and other.mode == &#39;rb&#39; and hash(self</span>
<span class="gd">-            ) == hash(other)</span>
<span class="gi">+        return (</span>
<span class="gi">+            isinstance(other, type(self))</span>
<span class="gi">+            and self.mode == &quot;rb&quot;</span>
<span class="gi">+            and other.mode == &quot;rb&quot;</span>
<span class="gi">+            and hash(self) == hash(other)</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def commit(self):
<span class="w"> </span>        &quot;&quot;&quot;Move from temp to final destination&quot;&quot;&quot;
<span class="gd">-        pass</span>

<span class="w"> </span>    def discard(self):
<span class="w"> </span>        &quot;&quot;&quot;Throw away temporary file&quot;&quot;&quot;
<span class="gd">-        pass</span>

<span class="w"> </span>    def info(self):
<span class="w"> </span>        &quot;&quot;&quot;File information about this path&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if &quot;r&quot; in self.mode:</span>
<span class="gi">+            return self.details</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise ValueError(&quot;Info not available while writing&quot;)</span>

<span class="w"> </span>    def tell(self):
<span class="w"> </span>        &quot;&quot;&quot;Current file location&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.loc</span>

<span class="w"> </span>    def seek(self, loc, whence=0):
<span class="w"> </span>        &quot;&quot;&quot;Set current file location
<span class="gu">@@ -1045,7 +1818,21 @@ class AbstractBufferedFile(io.IOBase):</span>
<span class="w"> </span>        whence: {0, 1, 2}
<span class="w"> </span>            from start of file, current location or end of file, resp.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        loc = int(loc)</span>
<span class="gi">+        if not self.mode == &quot;rb&quot;:</span>
<span class="gi">+            raise OSError(ESPIPE, &quot;Seek only available in read mode&quot;)</span>
<span class="gi">+        if whence == 0:</span>
<span class="gi">+            nloc = loc</span>
<span class="gi">+        elif whence == 1:</span>
<span class="gi">+            nloc = self.loc + loc</span>
<span class="gi">+        elif whence == 2:</span>
<span class="gi">+            nloc = self.size + loc</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise ValueError(f&quot;invalid whence ({whence}, should be 0, 1 or 2)&quot;)</span>
<span class="gi">+        if nloc &lt; 0:</span>
<span class="gi">+            raise ValueError(&quot;Seek before start of file&quot;)</span>
<span class="gi">+        self.loc = nloc</span>
<span class="gi">+        return self.loc</span>

<span class="w"> </span>    def write(self, data):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -1059,7 +1846,17 @@ class AbstractBufferedFile(io.IOBase):</span>
<span class="w"> </span>        data: bytes
<span class="w"> </span>            Set of bytes to be written.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.mode not in {&quot;wb&quot;, &quot;ab&quot;}:</span>
<span class="gi">+            raise ValueError(&quot;File not in write mode&quot;)</span>
<span class="gi">+        if self.closed:</span>
<span class="gi">+            raise ValueError(&quot;I/O operation on closed file.&quot;)</span>
<span class="gi">+        if self.forced:</span>
<span class="gi">+            raise ValueError(&quot;This file has been force-flushed, can only close&quot;)</span>
<span class="gi">+        out = self.buffer.write(data)</span>
<span class="gi">+        self.loc += out</span>
<span class="gi">+        if self.buffer.tell() &gt;= self.blocksize:</span>
<span class="gi">+            self.flush()</span>
<span class="gi">+        return out</span>

<span class="w"> </span>    def flush(self, force=False):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -1074,7 +1871,34 @@ class AbstractBufferedFile(io.IOBase):</span>
<span class="w"> </span>            When closing, write the last block even if it is smaller than
<span class="w"> </span>            blocks are allowed to be. Disallows further writing to this file.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+</span>
<span class="gi">+        if self.closed:</span>
<span class="gi">+            raise ValueError(&quot;Flush on closed file&quot;)</span>
<span class="gi">+        if force and self.forced:</span>
<span class="gi">+            raise ValueError(&quot;Force flush cannot be called more than once&quot;)</span>
<span class="gi">+        if force:</span>
<span class="gi">+            self.forced = True</span>
<span class="gi">+</span>
<span class="gi">+        if self.mode not in {&quot;wb&quot;, &quot;ab&quot;}:</span>
<span class="gi">+            # no-op to flush on read-mode</span>
<span class="gi">+            return</span>
<span class="gi">+</span>
<span class="gi">+        if not force and self.buffer.tell() &lt; self.blocksize:</span>
<span class="gi">+            # Defer write on small block</span>
<span class="gi">+            return</span>
<span class="gi">+</span>
<span class="gi">+        if self.offset is None:</span>
<span class="gi">+            # Initialize a multipart upload</span>
<span class="gi">+            self.offset = 0</span>
<span class="gi">+            try:</span>
<span class="gi">+                self._initiate_upload()</span>
<span class="gi">+            except:  # noqa: E722</span>
<span class="gi">+                self.closed = True</span>
<span class="gi">+                raise</span>
<span class="gi">+</span>
<span class="gi">+        if self._upload_chunk(final=force) is not False:</span>
<span class="gi">+            self.offset += self.buffer.seek(0, 2)</span>
<span class="gi">+            self.buffer = io.BytesIO()</span>

<span class="w"> </span>    def _upload_chunk(self, final=False):
<span class="w"> </span>        &quot;&quot;&quot;Write one part of a multi-block file upload
<span class="gu">@@ -1085,7 +1909,7 @@ class AbstractBufferedFile(io.IOBase):</span>
<span class="w"> </span>            This is the last block, so should complete file, if
<span class="w"> </span>            self.autocommit is True.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # may not yet have been initialized, may need to call _initialize_upload</span>

<span class="w"> </span>    def _initiate_upload(self):
<span class="w"> </span>        &quot;&quot;&quot;Create remote file/upload&quot;&quot;&quot;
<span class="gu">@@ -1093,7 +1917,7 @@ class AbstractBufferedFile(io.IOBase):</span>

<span class="w"> </span>    def _fetch_range(self, start, end):
<span class="w"> </span>        &quot;&quot;&quot;Get the specified set of bytes from remote&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        raise NotImplementedError</span>

<span class="w"> </span>    def read(self, length=-1):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -1104,16 +1928,39 @@ class AbstractBufferedFile(io.IOBase):</span>
<span class="w"> </span>        length: int (-1)
<span class="w"> </span>            Number of bytes to read; if &lt;0, all remaining bytes.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        length = -1 if length is None else int(length)</span>
<span class="gi">+        if self.mode != &quot;rb&quot;:</span>
<span class="gi">+            raise ValueError(&quot;File not in read mode&quot;)</span>
<span class="gi">+        if length &lt; 0:</span>
<span class="gi">+            length = self.size - self.loc</span>
<span class="gi">+        if self.closed:</span>
<span class="gi">+            raise ValueError(&quot;I/O operation on closed file.&quot;)</span>
<span class="gi">+        if length == 0:</span>
<span class="gi">+            # don&#39;t even bother calling fetch</span>
<span class="gi">+            return b&quot;&quot;</span>
<span class="gi">+        out = self.cache._fetch(self.loc, self.loc + length)</span>
<span class="gi">+</span>
<span class="gi">+        logger.debug(</span>
<span class="gi">+            &quot;%s read: %i - %i %s&quot;,</span>
<span class="gi">+            self,</span>
<span class="gi">+            self.loc,</span>
<span class="gi">+            self.loc + length,</span>
<span class="gi">+            self.cache._log_stats(),</span>
<span class="gi">+        )</span>
<span class="gi">+        self.loc += len(out)</span>
<span class="gi">+        return out</span>

<span class="w"> </span>    def readinto(self, b):
<span class="w"> </span>        &quot;&quot;&quot;mirrors builtin file&#39;s readinto method

<span class="w"> </span>        https://docs.python.org/3/library/io.html#io.RawIOBase.readinto
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        out = memoryview(b).cast(&quot;B&quot;)</span>
<span class="gi">+        data = self.read(out.nbytes)</span>
<span class="gi">+        out[: len(data)] = data</span>
<span class="gi">+        return len(data)</span>

<span class="gd">-    def readuntil(self, char=b&#39;\n&#39;, blocks=None):</span>
<span class="gi">+    def readuntil(self, char=b&quot;\n&quot;, blocks=None):</span>
<span class="w"> </span>        &quot;&quot;&quot;Return data between current position and first occurrence of char

<span class="w"> </span>        char is included in the output, except if the end of the tile is
<span class="gu">@@ -1127,7 +1974,19 @@ class AbstractBufferedFile(io.IOBase):</span>
<span class="w"> </span>            How much to read in each go. Defaults to file blocksize - which may
<span class="w"> </span>            mean a new read on every call.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        out = []</span>
<span class="gi">+        while True:</span>
<span class="gi">+            start = self.tell()</span>
<span class="gi">+            part = self.read(blocks or self.blocksize)</span>
<span class="gi">+            if len(part) == 0:</span>
<span class="gi">+                break</span>
<span class="gi">+            found = part.find(char)</span>
<span class="gi">+            if found &gt; -1:</span>
<span class="gi">+                out.append(part[: found + len(char)])</span>
<span class="gi">+                self.seek(start + found + len(char))</span>
<span class="gi">+                break</span>
<span class="gi">+            out.append(part)</span>
<span class="gi">+        return b&quot;&quot;.join(out)</span>

<span class="w"> </span>    def readline(self):
<span class="w"> </span>        &quot;&quot;&quot;Read until first occurrence of newline character
<span class="gu">@@ -1135,7 +1994,7 @@ class AbstractBufferedFile(io.IOBase):</span>
<span class="w"> </span>        Note that, because of character encoding, this is not necessarily a
<span class="w"> </span>        true line ending.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.readuntil(b&quot;\n&quot;)</span>

<span class="w"> </span>    def __next__(self):
<span class="w"> </span>        out = self.readline()
<span class="gu">@@ -1148,33 +2007,58 @@ class AbstractBufferedFile(io.IOBase):</span>

<span class="w"> </span>    def readlines(self):
<span class="w"> </span>        &quot;&quot;&quot;Return all data, split by the newline character&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        data = self.read()</span>
<span class="gi">+        lines = data.split(b&quot;\n&quot;)</span>
<span class="gi">+        out = [l + b&quot;\n&quot; for l in lines[:-1]]</span>
<span class="gi">+        if data.endswith(b&quot;\n&quot;):</span>
<span class="gi">+            return out</span>
<span class="gi">+        else:</span>
<span class="gi">+            return out + [lines[-1]]</span>
<span class="gi">+        # return list(self)  ???</span>
<span class="gi">+</span>
<span class="gi">+    def readinto1(self, b):</span>
<span class="gi">+        return self.readinto(b)</span>

<span class="w"> </span>    def close(self):
<span class="w"> </span>        &quot;&quot;&quot;Close file

<span class="w"> </span>        Finalizes writes, discards cache
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if getattr(self, &quot;_unclosable&quot;, False):</span>
<span class="gi">+            return</span>
<span class="gi">+        if self.closed:</span>
<span class="gi">+            return</span>
<span class="gi">+        if self.mode == &quot;rb&quot;:</span>
<span class="gi">+            self.cache = None</span>
<span class="gi">+        else:</span>
<span class="gi">+            if not self.forced:</span>
<span class="gi">+                self.flush(force=True)</span>
<span class="gi">+</span>
<span class="gi">+            if self.fs is not None:</span>
<span class="gi">+                self.fs.invalidate_cache(self.path)</span>
<span class="gi">+                self.fs.invalidate_cache(self.fs._parent(self.path))</span>
<span class="gi">+</span>
<span class="gi">+        self.closed = True</span>

<span class="w"> </span>    def readable(self):
<span class="w"> </span>        &quot;&quot;&quot;Whether opened for reading&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.mode == &quot;rb&quot; and not self.closed</span>

<span class="w"> </span>    def seekable(self):
<span class="w"> </span>        &quot;&quot;&quot;Whether is seekable (only in read mode)&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.readable()</span>

<span class="w"> </span>    def writable(self):
<span class="w"> </span>        &quot;&quot;&quot;Whether opened for writing&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.mode in {&quot;wb&quot;, &quot;ab&quot;} and not self.closed</span>

<span class="w"> </span>    def __del__(self):
<span class="w"> </span>        if not self.closed:
<span class="w"> </span>            self.close()

<span class="w"> </span>    def __str__(self):
<span class="gd">-        return f&#39;&lt;File-like object {type(self.fs).__name__}, {self.path}&gt;&#39;</span>
<span class="gi">+        return f&quot;&lt;File-like object {type(self.fs).__name__}, {self.path}&gt;&quot;</span>
<span class="gi">+</span>
<span class="w"> </span>    __repr__ = __str__

<span class="w"> </span>    def __enter__(self):
<span class="gh">diff --git a/fsspec/transaction.py b/fsspec/transaction.py</span>
<span class="gh">index 9a060ac..77293f6 100644</span>
<span class="gd">--- a/fsspec/transaction.py</span>
<span class="gi">+++ b/fsspec/transaction.py</span>
<span class="gu">@@ -24,6 +24,7 @@ class Transaction:</span>

<span class="w"> </span>    def __exit__(self, exc_type, exc_val, exc_tb):
<span class="w"> </span>        &quot;&quot;&quot;End transaction and commit, if exit is not due to exception&quot;&quot;&quot;
<span class="gi">+        # only commit if there was no exception</span>
<span class="w"> </span>        self.complete(commit=exc_type is None)
<span class="w"> </span>        if self.fs:
<span class="w"> </span>            self.fs._intrans = False
<span class="gu">@@ -32,21 +33,41 @@ class Transaction:</span>

<span class="w"> </span>    def start(self):
<span class="w"> </span>        &quot;&quot;&quot;Start a transaction on this FileSystem&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.files = deque()  # clean up after previous failed completions</span>
<span class="gi">+        self.fs._intrans = True</span>

<span class="w"> </span>    def complete(self, commit=True):
<span class="w"> </span>        &quot;&quot;&quot;Finish transaction: commit or discard all deferred files&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        while self.files:</span>
<span class="gi">+            f = self.files.popleft()</span>
<span class="gi">+            if commit:</span>
<span class="gi">+                f.commit()</span>
<span class="gi">+            else:</span>
<span class="gi">+                f.discard()</span>
<span class="gi">+        self.fs._intrans = False</span>
<span class="gi">+        self.fs._transaction = None</span>
<span class="gi">+        self.fs = None</span>


<span class="w"> </span>class FileActor:
<span class="gd">-</span>
<span class="w"> </span>    def __init__(self):
<span class="w"> </span>        self.files = []

<span class="gi">+    def commit(self):</span>
<span class="gi">+        for f in self.files:</span>
<span class="gi">+            f.commit()</span>
<span class="gi">+        self.files.clear()</span>

<span class="gd">-class DaskTransaction(Transaction):</span>
<span class="gi">+    def discard(self):</span>
<span class="gi">+        for f in self.files:</span>
<span class="gi">+            f.discard()</span>
<span class="gi">+        self.files.clear()</span>
<span class="gi">+</span>
<span class="gi">+    def append(self, f):</span>
<span class="gi">+        self.files.append(f)</span>

<span class="gi">+</span>
<span class="gi">+class DaskTransaction(Transaction):</span>
<span class="w"> </span>    def __init__(self, fs):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Parameters
<span class="gu">@@ -54,10 +75,16 @@ class DaskTransaction(Transaction):</span>
<span class="w"> </span>        fs: FileSystem instance
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        import distributed
<span class="gi">+</span>
<span class="w"> </span>        super().__init__(fs)
<span class="w"> </span>        client = distributed.default_client()
<span class="w"> </span>        self.files = client.submit(FileActor, actor=True).result()

<span class="w"> </span>    def complete(self, commit=True):
<span class="w"> </span>        &quot;&quot;&quot;Finish transaction: commit or discard all deferred files&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if commit:</span>
<span class="gi">+            self.files.commit().result()</span>
<span class="gi">+        else:</span>
<span class="gi">+            self.files.discard().result()</span>
<span class="gi">+        self.fs._intrans = False</span>
<span class="gi">+        self.fs = None</span>
<span class="gh">diff --git a/fsspec/utils.py b/fsspec/utils.py</span>
<span class="gh">index 7257878..703d55f 100644</span>
<span class="gd">--- a/fsspec/utils.py</span>
<span class="gi">+++ b/fsspec/utils.py</span>
<span class="gu">@@ -1,4 +1,5 @@</span>
<span class="w"> </span>from __future__ import annotations
<span class="gi">+</span>
<span class="w"> </span>import contextlib
<span class="w"> </span>import logging
<span class="w"> </span>import math
<span class="gu">@@ -10,17 +11,32 @@ import tempfile</span>
<span class="w"> </span>from functools import partial
<span class="w"> </span>from hashlib import md5
<span class="w"> </span>from importlib.metadata import version
<span class="gd">-from typing import IO, TYPE_CHECKING, Any, Callable, Iterable, Iterator, Sequence, TypeVar</span>
<span class="gi">+from typing import (</span>
<span class="gi">+    IO,</span>
<span class="gi">+    TYPE_CHECKING,</span>
<span class="gi">+    Any,</span>
<span class="gi">+    Callable,</span>
<span class="gi">+    Iterable,</span>
<span class="gi">+    Iterator,</span>
<span class="gi">+    Sequence,</span>
<span class="gi">+    TypeVar,</span>
<span class="gi">+)</span>
<span class="w"> </span>from urllib.parse import urlsplit
<span class="gi">+</span>
<span class="w"> </span>if TYPE_CHECKING:
<span class="w"> </span>    from typing_extensions import TypeGuard
<span class="gi">+</span>
<span class="w"> </span>    from fsspec.spec import AbstractFileSystem
<span class="gd">-DEFAULT_BLOCK_SIZE = 5 * 2 ** 20</span>
<span class="gd">-T = TypeVar(&#39;T&#39;)</span>


<span class="gd">-def infer_storage_options(urlpath: str, inherit_storage_options: (dict[str,</span>
<span class="gd">-    Any] | None)=None) -&gt;dict[str, Any]:</span>
<span class="gi">+DEFAULT_BLOCK_SIZE = 5 * 2**20</span>
<span class="gi">+</span>
<span class="gi">+T = TypeVar(&quot;T&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def infer_storage_options(</span>
<span class="gi">+    urlpath: str, inherit_storage_options: dict[str, Any] | None = None</span>
<span class="gi">+) -&gt; dict[str, Any]:</span>
<span class="w"> </span>    &quot;&quot;&quot;Infer storage options from URL path and merge it with existing storage
<span class="w"> </span>    options.

<span class="gu">@@ -48,23 +64,94 @@ def infer_storage_options(urlpath: str, inherit_storage_options: (dict[str,</span>
<span class="w"> </span>    &quot;host&quot;: &quot;node&quot;, &quot;port&quot;: 123, &quot;path&quot;: &quot;/mnt/datasets/test.csv&quot;,
<span class="w"> </span>    &quot;url_query&quot;: &quot;q=1&quot;, &quot;extra&quot;: &quot;value&quot;}
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gi">+    # Handle Windows paths including disk name in this special case</span>
<span class="gi">+    if (</span>
<span class="gi">+        re.match(r&quot;^[a-zA-Z]:[\\/]&quot;, urlpath)</span>
<span class="gi">+        or re.match(r&quot;^[a-zA-Z0-9]+://&quot;, urlpath) is None</span>
<span class="gi">+    ):</span>
<span class="gi">+        return {&quot;protocol&quot;: &quot;file&quot;, &quot;path&quot;: urlpath}</span>
<span class="gi">+</span>
<span class="gi">+    parsed_path = urlsplit(urlpath)</span>
<span class="gi">+    protocol = parsed_path.scheme or &quot;file&quot;</span>
<span class="gi">+    if parsed_path.fragment:</span>
<span class="gi">+        path = &quot;#&quot;.join([parsed_path.path, parsed_path.fragment])</span>
<span class="gi">+    else:</span>
<span class="gi">+        path = parsed_path.path</span>
<span class="gi">+    if protocol == &quot;file&quot;:</span>
<span class="gi">+        # Special case parsing file protocol URL on Windows according to:</span>
<span class="gi">+        # https://msdn.microsoft.com/en-us/library/jj710207.aspx</span>
<span class="gi">+        windows_path = re.match(r&quot;^/([a-zA-Z])[:|]([\\/].*)$&quot;, path)</span>
<span class="gi">+        if windows_path:</span>
<span class="gi">+            path = &quot;%s:%s&quot; % windows_path.groups()</span>
<span class="gi">+</span>
<span class="gi">+    if protocol in [&quot;http&quot;, &quot;https&quot;]:</span>
<span class="gi">+        # for HTTP, we don&#39;t want to parse, as requests will anyway</span>
<span class="gi">+        return {&quot;protocol&quot;: protocol, &quot;path&quot;: urlpath}</span>
<span class="gi">+</span>
<span class="gi">+    options: dict[str, Any] = {&quot;protocol&quot;: protocol, &quot;path&quot;: path}</span>
<span class="gi">+</span>
<span class="gi">+    if parsed_path.netloc:</span>
<span class="gi">+        # Parse `hostname` from netloc manually because `parsed_path.hostname`</span>
<span class="gi">+        # lowercases the hostname which is not always desirable (e.g. in S3):</span>
<span class="gi">+        # https://github.com/dask/dask/issues/1417</span>
<span class="gi">+        options[&quot;host&quot;] = parsed_path.netloc.rsplit(&quot;@&quot;, 1)[-1].rsplit(&quot;:&quot;, 1)[0]</span>
<span class="gi">+</span>
<span class="gi">+        if protocol in (&quot;s3&quot;, &quot;s3a&quot;, &quot;gcs&quot;, &quot;gs&quot;):</span>
<span class="gi">+            options[&quot;path&quot;] = options[&quot;host&quot;] + options[&quot;path&quot;]</span>
<span class="gi">+        else:</span>
<span class="gi">+            options[&quot;host&quot;] = options[&quot;host&quot;]</span>
<span class="gi">+        if parsed_path.port:</span>
<span class="gi">+            options[&quot;port&quot;] = parsed_path.port</span>
<span class="gi">+        if parsed_path.username:</span>
<span class="gi">+            options[&quot;username&quot;] = parsed_path.username</span>
<span class="gi">+        if parsed_path.password:</span>
<span class="gi">+            options[&quot;password&quot;] = parsed_path.password</span>
<span class="gi">+</span>
<span class="gi">+    if parsed_path.query:</span>
<span class="gi">+        options[&quot;url_query&quot;] = parsed_path.query</span>
<span class="gi">+    if parsed_path.fragment:</span>
<span class="gi">+        options[&quot;url_fragment&quot;] = parsed_path.fragment</span>
<span class="gi">+</span>
<span class="gi">+    if inherit_storage_options:</span>
<span class="gi">+        update_storage_options(options, inherit_storage_options)</span>
<span class="gi">+</span>
<span class="gi">+    return options</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def update_storage_options(</span>
<span class="gi">+    options: dict[str, Any], inherited: dict[str, Any] | None = None</span>
<span class="gi">+) -&gt; None:</span>
<span class="gi">+    if not inherited:</span>
<span class="gi">+        inherited = {}</span>
<span class="gi">+    collisions = set(options) &amp; set(inherited)</span>
<span class="gi">+    if collisions:</span>
<span class="gi">+        for collision in collisions:</span>
<span class="gi">+            if options.get(collision) != inherited.get(collision):</span>
<span class="gi">+                raise KeyError(</span>
<span class="gi">+                    f&quot;Collision between inferred and specified storage &quot;</span>
<span class="gi">+                    f&quot;option:\n{collision}&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+    options.update(inherited)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# Compression extensions registered via fsspec.compression.register_compression</span>
<span class="w"> </span>compressions: dict[str, str] = {}


<span class="gd">-def infer_compression(filename: str) -&gt;(str | None):</span>
<span class="gi">+def infer_compression(filename: str) -&gt; str | None:</span>
<span class="w"> </span>    &quot;&quot;&quot;Infer compression, if available, from filename.

<span class="w"> </span>    Infer a named compression type, if registered and available, from filename
<span class="w"> </span>    extension. This includes builtin (gz, bz2, zip) compressions, as well as
<span class="w"> </span>    optional compressions. See fsspec.compression.register_compression.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    extension = os.path.splitext(filename)[-1].strip(&quot;.&quot;).lower()</span>
<span class="gi">+    if extension in compressions:</span>
<span class="gi">+        return compressions[extension]</span>
<span class="gi">+    return None</span>


<span class="gd">-def build_name_function(max_int: float) -&gt;Callable[[int], str]:</span>
<span class="gi">+def build_name_function(max_int: float) -&gt; Callable[[int], str]:</span>
<span class="w"> </span>    &quot;&quot;&quot;Returns a function that receives a single integer
<span class="w"> </span>    and returns it as a string padded by enough zero characters
<span class="w"> </span>    to align with maximum possible integer
<span class="gu">@@ -82,11 +169,19 @@ def build_name_function(max_int: float) -&gt;Callable[[int], str]:</span>
<span class="w"> </span>    &gt;&gt;&gt; build_name_function(0)(0)
<span class="w"> </span>    &#39;0&#39;
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # handle corner cases max_int is 0 or exact power of 10</span>
<span class="gi">+    max_int += 1e-8</span>
<span class="gi">+</span>
<span class="gi">+    pad_length = int(math.ceil(math.log10(max_int)))</span>
<span class="gi">+</span>
<span class="gi">+    def name_function(i: int) -&gt; str:</span>
<span class="gi">+        return str(i).zfill(pad_length)</span>

<span class="gi">+    return name_function</span>

<span class="gd">-def seek_delimiter(file: IO[bytes], delimiter: bytes, blocksize: int) -&gt;bool:</span>
<span class="gd">-    &quot;&quot;&quot;Seek current file to file start, file end, or byte after delimiter seq.</span>
<span class="gi">+</span>
<span class="gi">+def seek_delimiter(file: IO[bytes], delimiter: bytes, blocksize: int) -&gt; bool:</span>
<span class="gi">+    r&quot;&quot;&quot;Seek current file to file start, file end, or byte after delimiter seq.</span>

<span class="w"> </span>    Seeks file to next chunk delimiter, where chunks are defined on file start,
<span class="w"> </span>    a delimiting sequence, and file end. Use file.tell() to see location afterwards.
<span class="gu">@@ -97,7 +192,7 @@ def seek_delimiter(file: IO[bytes], delimiter: bytes, blocksize: int) -&gt;bool:</span>
<span class="w"> </span>    ----------
<span class="w"> </span>    file: a file
<span class="w"> </span>    delimiter: bytes
<span class="gd">-        a delimiter like ``b&#39;\\n&#39;`` or message sentinel, matching file .read() type</span>
<span class="gi">+        a delimiter like ``b&#39;\n&#39;`` or message sentinel, matching file .read() type</span>
<span class="w"> </span>    blocksize: int
<span class="w"> </span>        Number of bytes to read from the file at once.

<span class="gu">@@ -107,11 +202,40 @@ def seek_delimiter(file: IO[bytes], delimiter: bytes, blocksize: int) -&gt;bool:</span>
<span class="w"> </span>    Returns True if a delimiter was found, False if at file start or end.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>

<span class="gd">-def read_block(f: IO[bytes], offset: int, length: (int | None), delimiter:</span>
<span class="gd">-    (bytes | None)=None, split_before: bool=False) -&gt;bytes:</span>
<span class="gi">+    if file.tell() == 0:</span>
<span class="gi">+        # beginning-of-file, return without seek</span>
<span class="gi">+        return False</span>
<span class="gi">+</span>
<span class="gi">+    # Interface is for binary IO, with delimiter as bytes, but initialize last</span>
<span class="gi">+    # with result of file.read to preserve compatibility with text IO.</span>
<span class="gi">+    last: bytes | None = None</span>
<span class="gi">+    while True:</span>
<span class="gi">+        current = file.read(blocksize)</span>
<span class="gi">+        if not current:</span>
<span class="gi">+            # end-of-file without delimiter</span>
<span class="gi">+            return False</span>
<span class="gi">+        full = last + current if last else current</span>
<span class="gi">+        try:</span>
<span class="gi">+            if delimiter in full:</span>
<span class="gi">+                i = full.index(delimiter)</span>
<span class="gi">+                file.seek(file.tell() - (len(full) - i) + len(delimiter))</span>
<span class="gi">+                return True</span>
<span class="gi">+            elif len(current) &lt; blocksize:</span>
<span class="gi">+                # end-of-file without delimiter</span>
<span class="gi">+                return False</span>
<span class="gi">+        except (OSError, ValueError):</span>
<span class="gi">+            pass</span>
<span class="gi">+        last = full[-len(delimiter) :]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def read_block(</span>
<span class="gi">+    f: IO[bytes],</span>
<span class="gi">+    offset: int,</span>
<span class="gi">+    length: int | None,</span>
<span class="gi">+    delimiter: bytes | None = None,</span>
<span class="gi">+    split_before: bool = False,</span>
<span class="gi">+) -&gt; bytes:</span>
<span class="w"> </span>    &quot;&quot;&quot;Read a block of bytes from a file

<span class="w"> </span>    Parameters
<span class="gu">@@ -148,10 +272,38 @@ def read_block(f: IO[bytes], offset: int, length: (int | None), delimiter:</span>
<span class="w"> </span>    &gt;&gt;&gt; read_block(f, 10, 10, delimiter=b&#39;\\n&#39;)  # doctest: +SKIP
<span class="w"> </span>    b&#39;Bob, 200\\nCharlie, 300&#39;
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if delimiter:</span>
<span class="gi">+        f.seek(offset)</span>
<span class="gi">+        found_start_delim = seek_delimiter(f, delimiter, 2**16)</span>
<span class="gi">+        if length is None:</span>
<span class="gi">+            return f.read()</span>
<span class="gi">+        start = f.tell()</span>
<span class="gi">+        length -= start - offset</span>
<span class="gi">+</span>
<span class="gi">+        f.seek(start + length)</span>
<span class="gi">+        found_end_delim = seek_delimiter(f, delimiter, 2**16)</span>
<span class="gi">+        end = f.tell()</span>
<span class="gi">+</span>
<span class="gi">+        # Adjust split location to before delimiter if seek found the</span>
<span class="gi">+        # delimiter sequence, not start or end of file.</span>
<span class="gi">+        if found_start_delim and split_before:</span>
<span class="gi">+            start -= len(delimiter)</span>
<span class="gi">+</span>
<span class="gi">+        if found_end_delim and split_before:</span>
<span class="gi">+            end -= len(delimiter)</span>

<span class="gi">+        offset = start</span>
<span class="gi">+        length = end - start</span>

<span class="gd">-def tokenize(*args: Any, **kwargs: Any) -&gt;str:</span>
<span class="gi">+    f.seek(offset)</span>
<span class="gi">+</span>
<span class="gi">+    # TODO: allow length to be None and read to the end of the file?</span>
<span class="gi">+    assert length is not None</span>
<span class="gi">+    b = f.read(length)</span>
<span class="gi">+    return b</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def tokenize(*args: Any, **kwargs: Any) -&gt; str:</span>
<span class="w"> </span>    &quot;&quot;&quot;Deterministic token

<span class="w"> </span>    (modified from dask.base)
<span class="gu">@@ -162,10 +314,17 @@ def tokenize(*args: Any, **kwargs: Any) -&gt;str:</span>
<span class="w"> </span>    &gt;&gt;&gt; tokenize(&#39;Hello&#39;) == tokenize(&#39;Hello&#39;)
<span class="w"> </span>    True
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if kwargs:</span>
<span class="gi">+        args += (kwargs,)</span>
<span class="gi">+    try:</span>
<span class="gi">+        h = md5(str(args).encode())</span>
<span class="gi">+    except ValueError:</span>
<span class="gi">+        # FIPS systems: https://github.com/fsspec/filesystem_spec/issues/380</span>
<span class="gi">+        h = md5(str(args).encode(), usedforsecurity=False)</span>
<span class="gi">+    return h.hexdigest()</span>


<span class="gd">-def stringify_path(filepath: (str | os.PathLike[str] | pathlib.Path)) -&gt;str:</span>
<span class="gi">+def stringify_path(filepath: str | os.PathLike[str] | pathlib.Path) -&gt; str:</span>
<span class="w"> </span>    &quot;&quot;&quot;Attempt to convert a path-like object to a string.

<span class="w"> </span>    Parameters
<span class="gu">@@ -187,16 +346,43 @@ def stringify_path(filepath: (str | os.PathLike[str] | pathlib.Path)) -&gt;str:</span>
<span class="w"> </span>    Any other object is passed through unchanged, which includes bytes,
<span class="w"> </span>    strings, buffers, or anything else that&#39;s not even path-like.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(filepath, str):</span>
<span class="gi">+        return filepath</span>
<span class="gi">+    elif hasattr(filepath, &quot;__fspath__&quot;):</span>
<span class="gi">+        return filepath.__fspath__()</span>
<span class="gi">+    elif hasattr(filepath, &quot;path&quot;):</span>
<span class="gi">+        return filepath.path</span>
<span class="gi">+    else:</span>
<span class="gi">+        return filepath  # type: ignore[return-value]</span>


<span class="gd">-def common_prefix(paths: Iterable[str]) -&gt;str:</span>
<span class="gd">-    &quot;&quot;&quot;For a list of paths, find the shortest prefix common to all&quot;&quot;&quot;</span>
<span class="gd">-    pass</span>
<span class="gi">+def make_instance(</span>
<span class="gi">+    cls: Callable[..., T], args: Sequence[Any], kwargs: dict[str, Any]</span>
<span class="gi">+) -&gt; T:</span>
<span class="gi">+    inst = cls(*args, **kwargs)</span>
<span class="gi">+    inst._determine_worker()  # type: ignore[attr-defined]</span>
<span class="gi">+    return inst</span>


<span class="gd">-def other_paths(paths: list[str], path2: (str | list[str]), exists: bool=</span>
<span class="gd">-    False, flatten: bool=False) -&gt;list[str]:</span>
<span class="gi">+def common_prefix(paths: Iterable[str]) -&gt; str:</span>
<span class="gi">+    &quot;&quot;&quot;For a list of paths, find the shortest prefix common to all&quot;&quot;&quot;</span>
<span class="gi">+    parts = [p.split(&quot;/&quot;) for p in paths]</span>
<span class="gi">+    lmax = min(len(p) for p in parts)</span>
<span class="gi">+    end = 0</span>
<span class="gi">+    for i in range(lmax):</span>
<span class="gi">+        end = all(p[i] == parts[0][i] for p in parts)</span>
<span class="gi">+        if not end:</span>
<span class="gi">+            break</span>
<span class="gi">+    i += end</span>
<span class="gi">+    return &quot;/&quot;.join(parts[0][:i])</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def other_paths(</span>
<span class="gi">+    paths: list[str],</span>
<span class="gi">+    path2: str | list[str],</span>
<span class="gi">+    exists: bool = False,</span>
<span class="gi">+    flatten: bool = False,</span>
<span class="gi">+) -&gt; list[str]:</span>
<span class="w"> </span>    &quot;&quot;&quot;In bulk file operations, construct a new file tree from a list of files

<span class="w"> </span>    Parameters
<span class="gu">@@ -217,15 +403,56 @@ def other_paths(paths: list[str], path2: (str | list[str]), exists: bool=</span>
<span class="w"> </span>    -------
<span class="w"> </span>    list of str
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(path2, str):</span>
<span class="gi">+        path2 = path2.rstrip(&quot;/&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        if flatten:</span>
<span class="gi">+            path2 = [&quot;/&quot;.join((path2, p.split(&quot;/&quot;)[-1])) for p in paths]</span>
<span class="gi">+        else:</span>
<span class="gi">+            cp = common_prefix(paths)</span>
<span class="gi">+            if exists:</span>
<span class="gi">+                cp = cp.rsplit(&quot;/&quot;, 1)[0]</span>
<span class="gi">+            if not cp and all(not s.startswith(&quot;/&quot;) for s in paths):</span>
<span class="gi">+                path2 = [&quot;/&quot;.join([path2, p]) for p in paths]</span>
<span class="gi">+            else:</span>
<span class="gi">+                path2 = [p.replace(cp, path2, 1) for p in paths]</span>
<span class="gi">+    else:</span>
<span class="gi">+        assert len(paths) == len(path2)</span>
<span class="gi">+    return path2</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def is_exception(obj: Any) -&gt; bool:</span>
<span class="gi">+    return isinstance(obj, BaseException)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def isfilelike(f: Any) -&gt; TypeGuard[IO[bytes]]:</span>
<span class="gi">+    for attr in [&quot;read&quot;, &quot;close&quot;, &quot;tell&quot;]:</span>
<span class="gi">+        if not hasattr(f, attr):</span>
<span class="gi">+            return False</span>
<span class="gi">+    return True</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def get_protocol(url: str) -&gt; str:</span>
<span class="gi">+    url = stringify_path(url)</span>
<span class="gi">+    parts = re.split(r&quot;(\:\:|\://)&quot;, url, maxsplit=1)</span>
<span class="gi">+    if len(parts) &gt; 1:</span>
<span class="gi">+        return parts[0]</span>
<span class="gi">+    return &quot;file&quot;</span>


<span class="gd">-def can_be_local(path: str) -&gt;bool:</span>
<span class="gi">+def can_be_local(path: str) -&gt; bool:</span>
<span class="w"> </span>    &quot;&quot;&quot;Can the given URL be used with open_local?&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from fsspec import get_filesystem_class</span>

<span class="gi">+    try:</span>
<span class="gi">+        return getattr(get_filesystem_class(get_protocol(path)), &quot;local_file&quot;, False)</span>
<span class="gi">+    except (ValueError, ImportError):</span>
<span class="gi">+        # not in registry or import failed</span>
<span class="gi">+        return False</span>

<span class="gd">-def get_package_version_without_import(name: str) -&gt;(str | None):</span>
<span class="gi">+</span>
<span class="gi">+def get_package_version_without_import(name: str) -&gt; str | None:</span>
<span class="w"> </span>    &quot;&quot;&quot;For given package name, try to find the version without importing it

<span class="w"> </span>    Import and package.__version__ is still the backup here, so an import
<span class="gu">@@ -234,20 +461,81 @@ def get_package_version_without_import(name: str) -&gt;(str | None):</span>
<span class="w"> </span>    Returns either the version string, or None if the package
<span class="w"> </span>    or the version was not readily  found.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def mirror_from(origin_name: str, methods: Iterable[str]) -&gt;Callable[[type[</span>
<span class="gd">-    T]], type[T]]:</span>
<span class="gi">+    if name in sys.modules:</span>
<span class="gi">+        mod = sys.modules[name]</span>
<span class="gi">+        if hasattr(mod, &quot;__version__&quot;):</span>
<span class="gi">+            return mod.__version__</span>
<span class="gi">+    try:</span>
<span class="gi">+        return version(name)</span>
<span class="gi">+    except:  # noqa: E722</span>
<span class="gi">+        pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        import importlib</span>
<span class="gi">+</span>
<span class="gi">+        mod = importlib.import_module(name)</span>
<span class="gi">+        return mod.__version__</span>
<span class="gi">+    except (ImportError, AttributeError):</span>
<span class="gi">+        return None</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def setup_logging(</span>
<span class="gi">+    logger: logging.Logger | None = None,</span>
<span class="gi">+    logger_name: str | None = None,</span>
<span class="gi">+    level: str = &quot;DEBUG&quot;,</span>
<span class="gi">+    clear: bool = True,</span>
<span class="gi">+) -&gt; logging.Logger:</span>
<span class="gi">+    if logger is None and logger_name is None:</span>
<span class="gi">+        raise ValueError(&quot;Provide either logger object or logger name&quot;)</span>
<span class="gi">+    logger = logger or logging.getLogger(logger_name)</span>
<span class="gi">+    handle = logging.StreamHandler()</span>
<span class="gi">+    formatter = logging.Formatter(</span>
<span class="gi">+        &quot;%(asctime)s - %(name)s - %(levelname)s - %(funcName)s -- %(message)s&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    handle.setFormatter(formatter)</span>
<span class="gi">+    if clear:</span>
<span class="gi">+        logger.handlers.clear()</span>
<span class="gi">+    logger.addHandler(handle)</span>
<span class="gi">+    logger.setLevel(level)</span>
<span class="gi">+    return logger</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _unstrip_protocol(name: str, fs: AbstractFileSystem) -&gt; str:</span>
<span class="gi">+    return fs.unstrip_protocol(name)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def mirror_from(</span>
<span class="gi">+    origin_name: str, methods: Iterable[str]</span>
<span class="gi">+) -&gt; Callable[[type[T]], type[T]]:</span>
<span class="w"> </span>    &quot;&quot;&quot;Mirror attributes and methods from the given
<span class="w"> </span>    origin_name attribute of the instance to the
<span class="w"> </span>    decorated class&quot;&quot;&quot;
<span class="gd">-    pass</span>

<span class="gi">+    def origin_getter(method: str, self: Any) -&gt; Any:</span>
<span class="gi">+        origin = getattr(self, origin_name)</span>
<span class="gi">+        return getattr(origin, method)</span>
<span class="gi">+</span>
<span class="gi">+    def wrapper(cls: type[T]) -&gt; type[T]:</span>
<span class="gi">+        for method in methods:</span>
<span class="gi">+            wrapped_method = partial(origin_getter, method)</span>
<span class="gi">+            setattr(cls, method, property(wrapped_method))</span>
<span class="gi">+        return cls</span>
<span class="gi">+</span>
<span class="gi">+    return wrapper</span>

<span class="gd">-def merge_offset_ranges(paths: list[str], starts: (list[int] | int), ends:</span>
<span class="gd">-    (list[int] | int), max_gap: int=0, max_block: (int | None)=None, sort:</span>
<span class="gd">-    bool=True) -&gt;tuple[list[str], list[int], list[int]]:</span>
<span class="gi">+</span>
<span class="gi">+@contextlib.contextmanager</span>
<span class="gi">+def nullcontext(obj: T) -&gt; Iterator[T]:</span>
<span class="gi">+    yield obj</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def merge_offset_ranges(</span>
<span class="gi">+    paths: list[str],</span>
<span class="gi">+    starts: list[int] | int,</span>
<span class="gi">+    ends: list[int] | int,</span>
<span class="gi">+    max_gap: int = 0,</span>
<span class="gi">+    max_block: int | None = None,</span>
<span class="gi">+    sort: bool = True,</span>
<span class="gi">+) -&gt; tuple[list[str], list[int], list[int]]:</span>
<span class="w"> </span>    &quot;&quot;&quot;Merge adjacent byte-offset ranges when the inter-range
<span class="w"> </span>    gap is &lt;= `max_gap`, and when the merged byte range does not
<span class="w"> </span>    exceed `max_block` (if specified). By default, this function
<span class="gu">@@ -255,24 +543,198 @@ def merge_offset_ranges(paths: list[str], starts: (list[int] | int), ends:</span>
<span class="w"> </span>    order. If the user can guarantee that the inputs are already
<span class="w"> </span>    sorted, passing `sort=False` will skip the re-ordering.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def file_size(filelike: IO[bytes]) -&gt;int:</span>
<span class="gi">+    # Check input</span>
<span class="gi">+    if not isinstance(paths, list):</span>
<span class="gi">+        raise TypeError</span>
<span class="gi">+    if not isinstance(starts, list):</span>
<span class="gi">+        starts = [starts] * len(paths)</span>
<span class="gi">+    if not isinstance(ends, list):</span>
<span class="gi">+        ends = [ends] * len(paths)</span>
<span class="gi">+    if len(starts) != len(paths) or len(ends) != len(paths):</span>
<span class="gi">+        raise ValueError</span>
<span class="gi">+</span>
<span class="gi">+    # Early Return</span>
<span class="gi">+    if len(starts) &lt;= 1:</span>
<span class="gi">+        return paths, starts, ends</span>
<span class="gi">+</span>
<span class="gi">+    starts = [s or 0 for s in starts]</span>
<span class="gi">+    # Sort by paths and then ranges if `sort=True`</span>
<span class="gi">+    if sort:</span>
<span class="gi">+        paths, starts, ends = (</span>
<span class="gi">+            list(v)</span>
<span class="gi">+            for v in zip(</span>
<span class="gi">+                *sorted(</span>
<span class="gi">+                    zip(paths, starts, ends),</span>
<span class="gi">+                )</span>
<span class="gi">+            )</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    if paths:</span>
<span class="gi">+        # Loop through the coupled `paths`, `starts`, and</span>
<span class="gi">+        # `ends`, and merge adjacent blocks when appropriate</span>
<span class="gi">+        new_paths = paths[:1]</span>
<span class="gi">+        new_starts = starts[:1]</span>
<span class="gi">+        new_ends = ends[:1]</span>
<span class="gi">+        for i in range(1, len(paths)):</span>
<span class="gi">+            if paths[i] == paths[i - 1] and new_ends[-1] is None:</span>
<span class="gi">+                continue</span>
<span class="gi">+            elif (</span>
<span class="gi">+                paths[i] != paths[i - 1]</span>
<span class="gi">+                or ((starts[i] - new_ends[-1]) &gt; max_gap)</span>
<span class="gi">+                or (max_block is not None and (ends[i] - new_starts[-1]) &gt; max_block)</span>
<span class="gi">+            ):</span>
<span class="gi">+                # Cannot merge with previous block.</span>
<span class="gi">+                # Add new `paths`, `starts`, and `ends` elements</span>
<span class="gi">+                new_paths.append(paths[i])</span>
<span class="gi">+                new_starts.append(starts[i])</span>
<span class="gi">+                new_ends.append(ends[i])</span>
<span class="gi">+            else:</span>
<span class="gi">+                # Merge with previous block by updating the</span>
<span class="gi">+                # last element of `ends`</span>
<span class="gi">+                new_ends[-1] = ends[i]</span>
<span class="gi">+        return new_paths, new_starts, new_ends</span>
<span class="gi">+</span>
<span class="gi">+    # `paths` is empty. Just return input lists</span>
<span class="gi">+    return paths, starts, ends</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def file_size(filelike: IO[bytes]) -&gt; int:</span>
<span class="w"> </span>    &quot;&quot;&quot;Find length of any open read-mode file-like&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    pos = filelike.tell()</span>
<span class="gi">+    try:</span>
<span class="gi">+        return filelike.seek(0, 2)</span>
<span class="gi">+    finally:</span>
<span class="gi">+        filelike.seek(pos)</span>


<span class="w"> </span>@contextlib.contextmanager
<span class="gd">-def atomic_write(path: str, mode: str=&#39;wb&#39;):</span>
<span class="gi">+def atomic_write(path: str, mode: str = &quot;wb&quot;):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    A context manager that opens a temporary file next to `path` and, on exit,
<span class="w"> </span>    replaces `path` with the temporary file, thereby updating `path`
<span class="w"> </span>    atomically.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    fd, fn = tempfile.mkstemp(</span>
<span class="gi">+        dir=os.path.dirname(path), prefix=os.path.basename(path) + &quot;-&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    try:</span>
<span class="gi">+        with open(fd, mode) as fp:</span>
<span class="gi">+            yield fp</span>
<span class="gi">+    except BaseException:</span>
<span class="gi">+        with contextlib.suppress(FileNotFoundError):</span>
<span class="gi">+            os.unlink(fn)</span>
<span class="gi">+        raise</span>
<span class="gi">+    else:</span>
<span class="gi">+        os.replace(fn, path)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _translate(pat, STAR, QUESTION_MARK):</span>
<span class="gi">+    # Copied from: https://github.com/python/cpython/pull/106703.</span>
<span class="gi">+    res: list[str] = []</span>
<span class="gi">+    add = res.append</span>
<span class="gi">+    i, n = 0, len(pat)</span>
<span class="gi">+    while i &lt; n:</span>
<span class="gi">+        c = pat[i]</span>
<span class="gi">+        i = i + 1</span>
<span class="gi">+        if c == &quot;*&quot;:</span>
<span class="gi">+            # compress consecutive `*` into one</span>
<span class="gi">+            if (not res) or res[-1] is not STAR:</span>
<span class="gi">+                add(STAR)</span>
<span class="gi">+        elif c == &quot;?&quot;:</span>
<span class="gi">+            add(QUESTION_MARK)</span>
<span class="gi">+        elif c == &quot;[&quot;:</span>
<span class="gi">+            j = i</span>
<span class="gi">+            if j &lt; n and pat[j] == &quot;!&quot;:</span>
<span class="gi">+                j = j + 1</span>
<span class="gi">+            if j &lt; n and pat[j] == &quot;]&quot;:</span>
<span class="gi">+                j = j + 1</span>
<span class="gi">+            while j &lt; n and pat[j] != &quot;]&quot;:</span>
<span class="gi">+                j = j + 1</span>
<span class="gi">+            if j &gt;= n:</span>
<span class="gi">+                add(&quot;\\[&quot;)</span>
<span class="gi">+            else:</span>
<span class="gi">+                stuff = pat[i:j]</span>
<span class="gi">+                if &quot;-&quot; not in stuff:</span>
<span class="gi">+                    stuff = stuff.replace(&quot;\\&quot;, r&quot;\\&quot;)</span>
<span class="gi">+                else:</span>
<span class="gi">+                    chunks = []</span>
<span class="gi">+                    k = i + 2 if pat[i] == &quot;!&quot; else i + 1</span>
<span class="gi">+                    while True:</span>
<span class="gi">+                        k = pat.find(&quot;-&quot;, k, j)</span>
<span class="gi">+                        if k &lt; 0:</span>
<span class="gi">+                            break</span>
<span class="gi">+                        chunks.append(pat[i:k])</span>
<span class="gi">+                        i = k + 1</span>
<span class="gi">+                        k = k + 3</span>
<span class="gi">+                    chunk = pat[i:j]</span>
<span class="gi">+                    if chunk:</span>
<span class="gi">+                        chunks.append(chunk)</span>
<span class="gi">+                    else:</span>
<span class="gi">+                        chunks[-1] += &quot;-&quot;</span>
<span class="gi">+                    # Remove empty ranges -- invalid in RE.</span>
<span class="gi">+                    for k in range(len(chunks) - 1, 0, -1):</span>
<span class="gi">+                        if chunks[k - 1][-1] &gt; chunks[k][0]:</span>
<span class="gi">+                            chunks[k - 1] = chunks[k - 1][:-1] + chunks[k][1:]</span>
<span class="gi">+                            del chunks[k]</span>
<span class="gi">+                    # Escape backslashes and hyphens for set difference (--).</span>
<span class="gi">+                    # Hyphens that create ranges shouldn&#39;t be escaped.</span>
<span class="gi">+                    stuff = &quot;-&quot;.join(</span>
<span class="gi">+                        s.replace(&quot;\\&quot;, r&quot;\\&quot;).replace(&quot;-&quot;, r&quot;\-&quot;) for s in chunks</span>
<span class="gi">+                    )</span>
<span class="gi">+                # Escape set operations (&amp;&amp;, ~~ and ||).</span>
<span class="gi">+                stuff = re.sub(r&quot;([&amp;~|])&quot;, r&quot;\\\1&quot;, stuff)</span>
<span class="gi">+                i = j + 1</span>
<span class="gi">+                if not stuff:</span>
<span class="gi">+                    # Empty range: never match.</span>
<span class="gi">+                    add(&quot;(?!)&quot;)</span>
<span class="gi">+                elif stuff == &quot;!&quot;:</span>
<span class="gi">+                    # Negated empty range: match any character.</span>
<span class="gi">+                    add(&quot;.&quot;)</span>
<span class="gi">+                else:</span>
<span class="gi">+                    if stuff[0] == &quot;!&quot;:</span>
<span class="gi">+                        stuff = &quot;^&quot; + stuff[1:]</span>
<span class="gi">+                    elif stuff[0] in (&quot;^&quot;, &quot;[&quot;):</span>
<span class="gi">+                        stuff = &quot;\\&quot; + stuff</span>
<span class="gi">+                    add(f&quot;[{stuff}]&quot;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            add(re.escape(c))</span>
<span class="gi">+    assert i == n</span>
<span class="gi">+    return res</span>


<span class="w"> </span>def glob_translate(pat):
<span class="gi">+    # Copied from: https://github.com/python/cpython/pull/106703.</span>
<span class="gi">+    # The keyword parameters&#39; values are fixed to:</span>
<span class="gi">+    # recursive=True, include_hidden=True, seps=None</span>
<span class="w"> </span>    &quot;&quot;&quot;Translate a pathname with shell wildcards to a regular expression.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if os.path.altsep:</span>
<span class="gi">+        seps = os.path.sep + os.path.altsep</span>
<span class="gi">+    else:</span>
<span class="gi">+        seps = os.path.sep</span>
<span class="gi">+    escaped_seps = &quot;&quot;.join(map(re.escape, seps))</span>
<span class="gi">+    any_sep = f&quot;[{escaped_seps}]&quot; if len(seps) &gt; 1 else escaped_seps</span>
<span class="gi">+    not_sep = f&quot;[^{escaped_seps}]&quot;</span>
<span class="gi">+    one_last_segment = f&quot;{not_sep}+&quot;</span>
<span class="gi">+    one_segment = f&quot;{one_last_segment}{any_sep}&quot;</span>
<span class="gi">+    any_segments = f&quot;(?:.+{any_sep})?&quot;</span>
<span class="gi">+    any_last_segments = &quot;.*&quot;</span>
<span class="gi">+    results = []</span>
<span class="gi">+    parts = re.split(any_sep, pat)</span>
<span class="gi">+    last_part_idx = len(parts) - 1</span>
<span class="gi">+    for idx, part in enumerate(parts):</span>
<span class="gi">+        if part == &quot;*&quot;:</span>
<span class="gi">+            results.append(one_segment if idx &lt; last_part_idx else one_last_segment)</span>
<span class="gi">+            continue</span>
<span class="gi">+        if part == &quot;**&quot;:</span>
<span class="gi">+            results.append(any_segments if idx &lt; last_part_idx else any_last_segments)</span>
<span class="gi">+            continue</span>
<span class="gi">+        elif &quot;**&quot; in part:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;Invalid pattern: &#39;**&#39; can only be an entire path component&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        if part:</span>
<span class="gi">+            results.extend(_translate(part, f&quot;{not_sep}*&quot;, not_sep))</span>
<span class="gi">+        if idx &lt; last_part_idx:</span>
<span class="gi">+            results.append(any_sep)</span>
<span class="gi">+    res = &quot;&quot;.join(results)</span>
<span class="gi">+    return rf&quot;(?s:{res})\Z&quot;</span>
</code></pre></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.d6f25eb3.min.js"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../javascripts/tablesort.js"></script>
      
    
  </body>
</html>