
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.37">
    
    
      
        <title>Analysis commit0 all plain fillin xarray - Commit-0</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.8c3ca2c6.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#claude-sonnet-35-fill-in-xarray" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Commit-0" class="md-header__button md-logo" aria-label="Commit-0" data-md-component="logo">
      
  <img src="../logo2.webp" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Commit-0
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Analysis commit0 all plain fillin xarray
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Commit-0" class="md-nav__button md-logo" aria-label="Commit-0" data-md-component="logo">
      
  <img src="../logo2.webp" alt="logo">

    </a>
    Commit-0
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../setupdist/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Commit0
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Agent
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Leaderboard
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#failed-to-run-pytests-for-test-tests" class="md-nav__link">
    <span class="md-ellipsis">
      Failed to run pytests for test tests
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#patch-diff" class="md-nav__link">
    <span class="md-ellipsis">
      Patch diff
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<p><a href="/analysis_commit0-all-plain_fillin">back to Claude Sonnet 3.5 - Fill-in summary</a></p>
<h1 id="claude-sonnet-35-fill-in-xarray"><strong>Claude Sonnet 3.5 - Fill-in</strong>: xarray</h1>
<h2 id="failed-to-run-pytests-for-test-tests">Failed to run pytests for test <code>tests</code></h2>
<div class="highlight"><pre><span></span><code>ImportError while loading conftest &#39;/testbed/xarray/tests/conftest.py&#39;.
xarray/__init__.py:3: in &lt;module&gt;
    from xarray import groupers, testing, tutorial
xarray/groupers.py:13: in &lt;module&gt;
    from xarray.coding.cftime_offsets import _new_to_legacy_freq
xarray/coding/cftime_offsets.py:11: in &lt;module&gt;
    from xarray.coding.cftimeindex import CFTimeIndex, _parse_iso8601_with_reso
xarray/coding/cftimeindex.py:11: in &lt;module&gt;
    from xarray.coding.times import _STANDARD_CALENDARS, cftime_to_nptime, infer_calendar_name
xarray/coding/times.py:11: in &lt;module&gt;
    from xarray.coding.variables import SerializationWarning, VariableCoder, lazy_elemwise_func, pop_to, safe_setitem, unpack_for_decoding, unpack_for_encoding
xarray/coding/variables.py:9: in &lt;module&gt;
    from xarray.core import dtypes, duck_array_ops, indexing
xarray/core/dtypes.py:6: in &lt;module&gt;
    from xarray.core import array_api_compat, npcompat, utils
xarray/core/utils.py:19: in &lt;module&gt;
    from xarray.namedarray.utils import ReprObject, drop_missing_dims, either_dict_or_kwargs, infix_dims, is_dask_collection, is_dict_like, is_duck_array, is_duck_dask_array, module_available, to_0d_object_array
E   ImportError: cannot import name &#39;either_dict_or_kwargs&#39; from &#39;xarray.namedarray.utils&#39; (/testbed/xarray/namedarray/utils.py)
</code></pre></div>
<h2 id="patch-diff">Patch diff</h2>
<div class="highlight"><pre><span></span><code><span class="gh">diff --git a/xarray/backends/api.py b/xarray/backends/api.py</span>
<span class="gh">index 51972ac3..819d48f4 100644</span>
<span class="gd">--- a/xarray/backends/api.py</span>
<span class="gi">+++ b/xarray/backends/api.py</span>
<span class="gu">@@ -42,7 +42,9 @@ ENGINES = {&#39;netcdf4&#39;: backends.NetCDF4DataStore.open, &#39;scipy&#39;: backends.</span>

<span class="w"> </span>def _validate_dataset_names(dataset: Dataset) -&gt;None:
<span class="w"> </span>    &quot;&quot;&quot;DataArray.name and Dataset keys must be a string or None&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    for key in dataset.variables:</span>
<span class="gi">+        if not isinstance(key, str) and key is not None:</span>
<span class="gi">+            raise ValueError(f&quot;Invalid name for DataArray or Dataset key: {key}&quot;)</span>


<span class="w"> </span>def _validate_attrs(dataset, invalid_netcdf=False):
<span class="gu">@@ -54,12 +56,29 @@ def _validate_attrs(dataset, invalid_netcdf=False):</span>
<span class="w"> </span>    A numpy.bool_ is only allowed when using the h5netcdf engine with
<span class="w"> </span>    `invalid_netcdf=True`.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import numpy as np</span>
<span class="gi">+</span>
<span class="gi">+    valid_types = (str, int, float, np.number, np.ndarray, list, tuple)</span>
<span class="gi">+    </span>
<span class="gi">+    for key, value in dataset.attrs.items():</span>
<span class="gi">+        if not isinstance(key, str):</span>
<span class="gi">+            raise ValueError(f&quot;Attribute name {key} is not a string&quot;)</span>
<span class="gi">+        </span>
<span class="gi">+        if isinstance(value, np.bool_):</span>
<span class="gi">+            if not (invalid_netcdf and dataset.encoding.get(&#39;engine&#39;) == &#39;h5netcdf&#39;):</span>
<span class="gi">+                raise ValueError(f&quot;numpy.bool_ is only allowed with h5netcdf engine and invalid_netcdf=True&quot;)</span>
<span class="gi">+        elif not isinstance(value, valid_types):</span>
<span class="gi">+            if not (isinstance(value, (list, tuple)) and all(isinstance(v, (str, int, float, np.number)) for v in value)):</span>
<span class="gi">+                raise ValueError(f&quot;Invalid attribute value type for {key}: {type(value)}&quot;)</span>


<span class="w"> </span>def _finalize_store(write, store):
<span class="w"> </span>    &quot;&quot;&quot;Finalize this store by explicitly syncing and closing&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if write:</span>
<span class="gi">+        if hasattr(store, &#39;sync&#39;):</span>
<span class="gi">+            store.sync()</span>
<span class="gi">+    if hasattr(store, &#39;close&#39;):</span>
<span class="gi">+        store.close()</span>


<span class="w"> </span>def load_dataset(filename_or_obj, **kwargs) -&gt;Dataset:
<span class="gu">@@ -81,7 +100,8 @@ def load_dataset(filename_or_obj, **kwargs) -&gt;Dataset:</span>
<span class="w"> </span>    --------
<span class="w"> </span>    open_dataset
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    with open_dataset(filename_or_obj, **kwargs) as ds:</span>
<span class="gi">+        return ds.load()</span>


<span class="w"> </span>def load_dataarray(filename_or_obj, **kwargs):
<span class="gu">@@ -103,7 +123,8 @@ def load_dataarray(filename_or_obj, **kwargs):</span>
<span class="w"> </span>    --------
<span class="w"> </span>    open_dataarray
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    with open_dataarray(filename_or_obj, **kwargs) as da:</span>
<span class="gi">+        return da.load()</span>


<span class="w"> </span>def open_dataset(filename_or_obj: (str | os.PathLike[Any] | BufferedIOBase |
<span class="gh">diff --git a/xarray/backends/common.py b/xarray/backends/common.py</span>
<span class="gh">index e51d2a10..7b491b95 100644</span>
<span class="gd">--- a/xarray/backends/common.py</span>
<span class="gi">+++ b/xarray/backends/common.py</span>
<span class="gu">@@ -40,7 +40,7 @@ def _normalize_path(path):</span>
<span class="w"> </span>    &gt;&gt;&gt; print([type(p) for p in (paths_str,)])
<span class="w"> </span>    [&lt;class &#39;str&#39;&gt;]
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return str(path)</span>


<span class="w"> </span>def _find_absolute_paths(paths: (str | os.PathLike | NestedSequence[str |
<span class="gu">@@ -65,12 +65,26 @@ def _find_absolute_paths(paths: (str | os.PathLike | NestedSequence[str |</span>
<span class="w"> </span>    &gt;&gt;&gt; [Path(p).name for p in paths]
<span class="w"> </span>    [&#39;common.py&#39;]
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(paths, (str, os.PathLike)):</span>
<span class="gi">+        paths = [paths]</span>
<span class="gi">+    </span>
<span class="gi">+    absolute_paths = []</span>
<span class="gi">+    for path in paths:</span>
<span class="gi">+        normalized_path = _normalize_path(path)</span>
<span class="gi">+        if is_remote_uri(normalized_path):</span>
<span class="gi">+            absolute_paths.append(normalized_path)</span>
<span class="gi">+        else:</span>
<span class="gi">+            absolute_paths.extend(glob(os.path.abspath(normalized_path)))</span>
<span class="gi">+    </span>
<span class="gi">+    return absolute_paths</span>


<span class="w"> </span>def find_root_and_group(ds):
<span class="w"> </span>    &quot;&quot;&quot;Find the root and group name of a netCDF4/h5netcdf dataset.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    while ds.parent is not None:</span>
<span class="gi">+        ds = ds.parent</span>
<span class="gi">+    group = ds.path</span>
<span class="gi">+    return ds, group</span>


<span class="w"> </span>def robust_getitem(array, key, catch=Exception, max_retries=6,
<span class="gu">@@ -82,7 +96,13 @@ def robust_getitem(array, key, catch=Exception, max_retries=6,</span>
<span class="w"> </span>    With the default settings, the maximum delay will be in the range of 32-64
<span class="w"> </span>    seconds.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    for n in range(max_retries):</span>
<span class="gi">+        try:</span>
<span class="gi">+            return array[key]</span>
<span class="gi">+        except catch:</span>
<span class="gi">+            if n == max_retries - 1:</span>
<span class="gi">+                raise</span>
<span class="gi">+            time.sleep(initial_delay * 2**n / 1000.0)</span>


<span class="w"> </span>class BackendArray(NdimSizeLenMixin, indexing.ExplicitlyIndexed):
<span class="gu">@@ -113,7 +133,7 @@ class AbstractDataStore:</span>
<span class="w"> </span>        This function will be called anytime variables or attributes
<span class="w"> </span>        are requested, so care should be taken to make sure its fast.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        raise NotImplementedError(&quot;Abstract method&quot;)</span>

<span class="w"> </span>    def __enter__(self):
<span class="w"> </span>        return self
<span class="gu">@@ -152,15 +172,17 @@ class AbstractWritableDataStore(AbstractDataStore):</span>
<span class="w"> </span>        attributes : dict-like

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        encoded_variables = {k: self.encode_variable(v) for k, v in variables.items()}</span>
<span class="gi">+        encoded_attributes = {k: self.encode_attribute(v) for k, v in attributes.items()}</span>
<span class="gi">+        return encoded_variables, encoded_attributes</span>

<span class="w"> </span>    def encode_variable(self, v):
<span class="w"> </span>        &quot;&quot;&quot;encode one variable&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return v</span>

<span class="w"> </span>    def encode_attribute(self, a):
<span class="w"> </span>        &quot;&quot;&quot;encode one attribute&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return a</span>

<span class="w"> </span>    def store_dataset(self, dataset):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -169,7 +191,7 @@ class AbstractWritableDataStore(AbstractDataStore):</span>
<span class="w"> </span>        so here we pass the whole dataset in instead of doing
<span class="w"> </span>        dataset.variables
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.store(dataset.variables, dataset.attrs)</span>

<span class="w"> </span>    def store(self, variables, attributes, check_encoding_set=frozenset(),
<span class="w"> </span>        writer=None, unlimited_dims=None):
<span class="gu">@@ -193,7 +215,10 @@ class AbstractWritableDataStore(AbstractDataStore):</span>
<span class="w"> </span>            List of dimension names that should be treated as unlimited
<span class="w"> </span>            dimensions.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        variables, attributes = self.encode(variables, attributes)</span>
<span class="gi">+        self.set_dimensions(variables, unlimited_dims)</span>
<span class="gi">+        self.set_attributes(attributes)</span>
<span class="gi">+        self.set_variables(variables, check_encoding_set, writer, unlimited_dims)</span>

<span class="w"> </span>    def set_attributes(self, attributes):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -205,7 +230,7 @@ class AbstractWritableDataStore(AbstractDataStore):</span>
<span class="w"> </span>        attributes : dict-like
<span class="w"> </span>            Dictionary of key/value (attribute name / attribute) pairs
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        raise NotImplementedError</span>

<span class="w"> </span>    def set_variables(self, variables, check_encoding_set, writer,
<span class="w"> </span>        unlimited_dims=None):
<span class="gu">@@ -225,7 +250,7 @@ class AbstractWritableDataStore(AbstractDataStore):</span>
<span class="w"> </span>            List of dimension names that should be treated as unlimited
<span class="w"> </span>            dimensions.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        raise NotImplementedError</span>

<span class="w"> </span>    def set_dimensions(self, variables, unlimited_dims=None):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -240,7 +265,7 @@ class AbstractWritableDataStore(AbstractDataStore):</span>
<span class="w"> </span>            List of dimension names that should be treated as unlimited
<span class="w"> </span>            dimensions.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        raise NotImplementedError</span>


<span class="w"> </span>class WritableCFDataStore(AbstractWritableDataStore):
<span class="gh">diff --git a/xarray/backends/file_manager.py b/xarray/backends/file_manager.py</span>
<span class="gh">index 5058fcac..9cb7cb67 100644</span>
<span class="gd">--- a/xarray/backends/file_manager.py</span>
<span class="gi">+++ b/xarray/backends/file_manager.py</span>
<span class="gu">@@ -134,12 +134,16 @@ class CachingFileManager(FileManager):</span>

<span class="w"> </span>    def _make_key(self):
<span class="w"> </span>        &quot;&quot;&quot;Make a key for caching files in the LRU cache.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _HashedSequence((self._manager_id, self._opener, self._args, self._mode, tuple(sorted(self._kwargs.items()))))</span>

<span class="w"> </span>    @contextlib.contextmanager
<span class="w"> </span>    def _optional_lock(self, needs_lock):
<span class="w"> </span>        &quot;&quot;&quot;Context manager for optionally acquiring a lock.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if needs_lock and self._lock is not None:</span>
<span class="gi">+            with self._lock:</span>
<span class="gi">+                yield</span>
<span class="gi">+        else:</span>
<span class="gi">+            yield</span>

<span class="w"> </span>    def acquire(self, needs_lock=True):
<span class="w"> </span>        &quot;&quot;&quot;Acquire a file object from the manager.
<span class="gu">@@ -156,20 +160,44 @@ class CachingFileManager(FileManager):</span>
<span class="w"> </span>        file-like
<span class="w"> </span>            An open file object, as returned by ``opener(*args, **kwargs)``.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with self._optional_lock(needs_lock):</span>
<span class="gi">+            file, _ = self._acquire_with_cache_info(needs_lock=False)</span>
<span class="gi">+        return file</span>

<span class="w"> </span>    @contextlib.contextmanager
<span class="w"> </span>    def acquire_context(self, needs_lock=True):
<span class="w"> </span>        &quot;&quot;&quot;Context manager for acquiring a file.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with self._optional_lock(needs_lock):</span>
<span class="gi">+            file, cached = self._acquire_with_cache_info(needs_lock=False)</span>
<span class="gi">+            try:</span>
<span class="gi">+                yield file</span>
<span class="gi">+            finally:</span>
<span class="gi">+                if not cached:</span>
<span class="gi">+                    del self._cache[self._key]</span>

<span class="w"> </span>    def _acquire_with_cache_info(self, needs_lock=True):
<span class="w"> </span>        &quot;&quot;&quot;Acquire a file, returning the file and whether it was cached.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with self._optional_lock(needs_lock):</span>
<span class="gi">+            try:</span>
<span class="gi">+                file = self._cache[self._key]</span>
<span class="gi">+                cached = True</span>
<span class="gi">+            except KeyError:</span>
<span class="gi">+                kwargs = self._kwargs.copy()</span>
<span class="gi">+                if self._mode is not _DEFAULT_MODE:</span>
<span class="gi">+                    kwargs[&#39;mode&#39;] = self._mode</span>
<span class="gi">+                file = self._opener(*self._args, **kwargs)</span>
<span class="gi">+                self._cache[self._key] = file</span>
<span class="gi">+                cached = False</span>
<span class="gi">+                if self._mode == &#39;w&#39;:</span>
<span class="gi">+                    self._mode = &#39;a&#39;</span>
<span class="gi">+            return file, cached</span>

<span class="w"> </span>    def close(self, needs_lock=True):
<span class="w"> </span>        &quot;&quot;&quot;Explicitly close any associated file object (if necessary).&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with self._optional_lock(needs_lock):</span>
<span class="gi">+            if self._key in self._cache:</span>
<span class="gi">+                file = self._cache.pop(self._key)</span>
<span class="gi">+                file.close()</span>

<span class="w"> </span>    def __del__(self) -&gt;None:
<span class="w"> </span>        ref_count = self._ref_counter.decrement(self._key)
<span class="gh">diff --git a/xarray/backends/locks.py b/xarray/backends/locks.py</span>
<span class="gh">index cf8cb06f..55a47be1 100644</span>
<span class="gd">--- a/xarray/backends/locks.py</span>
<span class="gi">+++ b/xarray/backends/locks.py</span>
<span class="gu">@@ -83,7 +83,17 @@ def _get_lock_maker(scheduler=None):</span>
<span class="w"> </span>    --------
<span class="w"> </span>    dask.utils.get_scheduler_lock
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if scheduler is None:</span>
<span class="gi">+        return threading.Lock</span>
<span class="gi">+    elif scheduler == &#39;synchronous&#39;:</span>
<span class="gi">+        return threading.Lock</span>
<span class="gi">+    elif scheduler == &#39;threads&#39;:</span>
<span class="gi">+        return threading.Lock</span>
<span class="gi">+    elif scheduler == &#39;processes&#39;:</span>
<span class="gi">+        return multiprocessing.Lock</span>
<span class="gi">+    else:</span>
<span class="gi">+        from dask.utils import get_scheduler_lock</span>
<span class="gi">+        return get_scheduler_lock(scheduler)</span>


<span class="w"> </span>def _get_scheduler(get=None, collection=None) -&gt;(str | None):
<span class="gu">@@ -95,7 +105,11 @@ def _get_scheduler(get=None, collection=None) -&gt;(str | None):</span>
<span class="w"> </span>    --------
<span class="w"> </span>    dask.base.get_scheduler
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        from dask.base import get_scheduler</span>
<span class="gi">+        return get_scheduler(get, collection)</span>
<span class="gi">+    except ImportError:</span>
<span class="gi">+        return None</span>


<span class="w"> </span>def get_write_lock(key):
<span class="gu">@@ -110,7 +124,12 @@ def get_write_lock(key):</span>
<span class="w"> </span>    -------
<span class="w"> </span>    Lock object that can be used like a threading.Lock object.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    scheduler = _get_scheduler()</span>
<span class="gi">+    lock_maker = _get_lock_maker(scheduler)</span>
<span class="gi">+    </span>
<span class="gi">+    if key not in _FILE_LOCKS:</span>
<span class="gi">+        _FILE_LOCKS[key] = lock_maker()</span>
<span class="gi">+    return _FILE_LOCKS[key]</span>


<span class="w"> </span>def acquire(lock, blocking=True):
<span class="gu">@@ -119,7 +138,14 @@ def acquire(lock, blocking=True):</span>
<span class="w"> </span>    Includes backwards compatibility hacks for old versions of Python, dask
<span class="w"> </span>    and dask-distributed.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        return lock.acquire(blocking=blocking)</span>
<span class="gi">+    except TypeError:</span>
<span class="gi">+        # Some older versions of Python don&#39;t support the blocking keyword</span>
<span class="gi">+        if blocking:</span>
<span class="gi">+            return lock.acquire()</span>
<span class="gi">+        else:</span>
<span class="gi">+            return lock.acquire(False)</span>


<span class="w"> </span>class CombinedLock:
<span class="gu">@@ -156,9 +182,20 @@ class DummyLock:</span>

<span class="w"> </span>def combine_locks(locks):
<span class="w"> </span>    &quot;&quot;&quot;Combine a sequence of locks into a single lock.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    locks = [lock for lock in locks if not isinstance(lock, DummyLock)]</span>
<span class="gi">+    if len(locks) == 0:</span>
<span class="gi">+        return DummyLock()</span>
<span class="gi">+    elif len(locks) == 1:</span>
<span class="gi">+        return locks[0]</span>
<span class="gi">+    else:</span>
<span class="gi">+        return CombinedLock(locks)</span>


<span class="w"> </span>def ensure_lock(lock):
<span class="w"> </span>    &quot;&quot;&quot;Ensure that the given object is a lock.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if lock is None:</span>
<span class="gi">+        return DummyLock()</span>
<span class="gi">+    elif isinstance(lock, (threading.Lock, multiprocessing.Lock, CombinedLock, DummyLock)):</span>
<span class="gi">+        return lock</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(f&quot;Expected a lock object, got {type(lock)}&quot;)</span>
<span class="gh">diff --git a/xarray/backends/lru_cache.py b/xarray/backends/lru_cache.py</span>
<span class="gh">index 81212837..078b4124 100644</span>
<span class="gd">--- a/xarray/backends/lru_cache.py</span>
<span class="gi">+++ b/xarray/backends/lru_cache.py</span>
<span class="gu">@@ -55,7 +55,10 @@ class LRUCache(MutableMapping[K, V]):</span>

<span class="w"> </span>    def _enforce_size_limit(self, capacity: int) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;Shrink the cache if necessary, evicting the oldest items.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        while len(self._cache) &gt; capacity:</span>
<span class="gi">+            key, value = self._cache.popitem(last=False)</span>
<span class="gi">+            if self._on_evict is not None:</span>
<span class="gi">+                self._on_evict(key, value)</span>

<span class="w"> </span>    def __setitem__(self, key: K, value: V) -&gt;None:
<span class="w"> </span>        with self._lock:
<span class="gu">@@ -80,9 +83,15 @@ class LRUCache(MutableMapping[K, V]):</span>
<span class="w"> </span>    @property
<span class="w"> </span>    def maxsize(self) -&gt;int:
<span class="w"> </span>        &quot;&quot;&quot;Maximum number of items can be held in the cache.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._maxsize</span>

<span class="w"> </span>    @maxsize.setter
<span class="w"> </span>    def maxsize(self, size: int) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;Resize the cache, evicting the oldest items if necessary.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if not isinstance(size, int):</span>
<span class="gi">+            raise TypeError(&#39;maxsize must be an integer&#39;)</span>
<span class="gi">+        if size &lt; 0:</span>
<span class="gi">+            raise ValueError(&#39;maxsize must be non-negative&#39;)</span>
<span class="gi">+        with self._lock:</span>
<span class="gi">+            self._maxsize = size</span>
<span class="gi">+            self._enforce_size_limit(size)</span>
<span class="gh">diff --git a/xarray/backends/netCDF4_.py b/xarray/backends/netCDF4_.py</span>
<span class="gh">index 065e118c..8061b4ac 100644</span>
<span class="gd">--- a/xarray/backends/netCDF4_.py</span>
<span class="gi">+++ b/xarray/backends/netCDF4_.py</span>
<span class="gu">@@ -91,7 +91,20 @@ class NetCDF4DataStore(WritableCFDataStore):</span>
<span class="w"> </span>        The return type should be ``netCDF4.EnumType``,
<span class="w"> </span>        but we avoid importing netCDF4 globally for performances.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        import netCDF4</span>
<span class="gi">+</span>
<span class="gi">+        # Check if the enum already exists in the dataset</span>
<span class="gi">+        existing_enum = self.ds.enumtypes.get(enum_name)</span>
<span class="gi">+        if existing_enum is not None:</span>
<span class="gi">+            return existing_enum</span>
<span class="gi">+</span>
<span class="gi">+        # Create a new enum type</span>
<span class="gi">+        enum_type = netCDF4.EnumType(dtype, enum_dict, enum_name)</span>
<span class="gi">+</span>
<span class="gi">+        # Add the enum type to the dataset</span>
<span class="gi">+        self.ds.createEnumType(dtype, enum_name, enum_dict)</span>
<span class="gi">+</span>
<span class="gi">+        return enum_type</span>


<span class="w"> </span>class NetCDF4BackendEntrypoint(BackendEntrypoint):
<span class="gh">diff --git a/xarray/backends/netcdf3.py b/xarray/backends/netcdf3.py</span>
<span class="gh">index e42acafc..1de9b1a8 100644</span>
<span class="gd">--- a/xarray/backends/netcdf3.py</span>
<span class="gi">+++ b/xarray/backends/netcdf3.py</span>
<span class="gu">@@ -29,7 +29,20 @@ def coerce_nc3_dtype(arr):</span>
<span class="w"> </span>    Data is checked for equality, or equivalence (non-NaN values) using the
<span class="w"> </span>    ``(cast_array == original_array).all()``.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    dtype = arr.dtype</span>
<span class="gi">+    new_dtype = _nc3_dtype_coercions.get(dtype.name)</span>
<span class="gi">+    </span>
<span class="gi">+    if new_dtype is None:</span>
<span class="gi">+        return arr</span>
<span class="gi">+    </span>
<span class="gi">+    cast_arr = arr.astype(new_dtype)</span>
<span class="gi">+    if np.issubdtype(dtype, np.floating):</span>
<span class="gi">+        if not np.allclose(cast_arr, arr, equal_nan=True):</span>
<span class="gi">+            raise ValueError(COERCION_VALUE_ERROR.format(dtype=dtype, new_dtype=new_dtype))</span>
<span class="gi">+    elif not (cast_arr == arr).all():</span>
<span class="gi">+        raise ValueError(COERCION_VALUE_ERROR.format(dtype=dtype, new_dtype=new_dtype))</span>
<span class="gi">+    </span>
<span class="gi">+    return cast_arr</span>


<span class="w"> </span>def _isalnumMUTF8(c):
<span class="gu">@@ -38,7 +51,7 @@ def _isalnumMUTF8(c):</span>

<span class="w"> </span>    Input is not checked!
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return c.isalnum() or len(c.encode(&#39;utf-8&#39;)) &gt; 1</span>


<span class="w"> </span>def is_valid_nc3_name(s):
<span class="gu">@@ -58,4 +71,21 @@ def is_valid_nc3_name(s):</span>
<span class="w"> </span>    names. Names that have trailing space characters are also not
<span class="w"> </span>    permitted.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not isinstance(s, str):</span>
<span class="gi">+        return False</span>
<span class="gi">+    </span>
<span class="gi">+    if s in _reserved_names:</span>
<span class="gi">+        return False</span>
<span class="gi">+    </span>
<span class="gi">+    if not s or s.endswith(&#39; &#39;):</span>
<span class="gi">+        return False</span>
<span class="gi">+    </span>
<span class="gi">+    first_char = s[0]</span>
<span class="gi">+    if not (_isalnumMUTF8(first_char) or first_char == &#39;_&#39;):</span>
<span class="gi">+        return False</span>
<span class="gi">+    </span>
<span class="gi">+    for c in s[1:]:</span>
<span class="gi">+        if not (_isalnumMUTF8(c) or c in _specialchars):</span>
<span class="gi">+            return False</span>
<span class="gi">+    </span>
<span class="gi">+    return &#39;/&#39; not in s</span>
<span class="gh">diff --git a/xarray/backends/plugins.py b/xarray/backends/plugins.py</span>
<span class="gh">index 4ebd98d2..c26e7fa7 100644</span>
<span class="gd">--- a/xarray/backends/plugins.py</span>
<span class="gi">+++ b/xarray/backends/plugins.py</span>
<span class="gu">@@ -36,14 +36,40 @@ def list_engines() -&gt;dict[str, BackendEntrypoint]:</span>

<span class="w"> </span>    # New selection mechanism introduced with Python 3.10. See GH6514.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    engines = {}</span>
<span class="gi">+    if sys.version_info &gt;= (3, 10):</span>
<span class="gi">+        eps = entry_points(group=BACKEND_ENTRYPOINTS)</span>
<span class="gi">+    else:</span>
<span class="gi">+        eps = entry_points().get(BACKEND_ENTRYPOINTS, [])</span>
<span class="gi">+    </span>
<span class="gi">+    for entry_point in eps:</span>
<span class="gi">+        try:</span>
<span class="gi">+            backend = entry_point.load()</span>
<span class="gi">+            engines[entry_point.name] = backend</span>
<span class="gi">+        except Exception:</span>
<span class="gi">+            warnings.warn(f&quot;Failed to load {entry_point.name} backend.&quot;)</span>
<span class="gi">+    </span>
<span class="gi">+    # Add standard backends in the specified order</span>
<span class="gi">+    for backend in STANDARD_BACKENDS_ORDER:</span>
<span class="gi">+        if backend not in engines and module_available(backend):</span>
<span class="gi">+            engines[backend] = BackendEntrypoint(backend)</span>
<span class="gi">+    </span>
<span class="gi">+    return engines</span>


<span class="w"> </span>def refresh_engines() -&gt;None:
<span class="w"> </span>    &quot;&quot;&quot;Refreshes the backend engines based on installed packages.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    list_engines.cache_clear()</span>


<span class="w"> </span>def get_backend(engine: (str | type[BackendEntrypoint])) -&gt;BackendEntrypoint:
<span class="w"> </span>    &quot;&quot;&quot;Select open_dataset method based on current engine.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(engine, str):</span>
<span class="gi">+        engines = list_engines()</span>
<span class="gi">+        if engine not in engines:</span>
<span class="gi">+            raise ValueError(f&quot;Unrecognized engine {engine}&quot;)</span>
<span class="gi">+        return engines[engine]</span>
<span class="gi">+    elif isinstance(engine, type) and issubclass(engine, BackendEntrypoint):</span>
<span class="gi">+        return engine()</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(&quot;Engine must be a string or a BackendEntrypoint subclass&quot;)</span>
<span class="gh">diff --git a/xarray/backends/zarr.py b/xarray/backends/zarr.py</span>
<span class="gh">index bf3f1484..1b76dbaa 100644</span>
<span class="gd">--- a/xarray/backends/zarr.py</span>
<span class="gi">+++ b/xarray/backends/zarr.py</span>
<span class="gu">@@ -34,7 +34,14 @@ def encode_zarr_attr_value(value):</span>
<span class="w"> </span>    scalar array -&gt; scalar
<span class="w"> </span>    other -&gt; other (no change)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(value, np.ndarray):</span>
<span class="gi">+        if value.ndim == 0:</span>
<span class="gi">+            # scalar array</span>
<span class="gi">+            return value.item()</span>
<span class="gi">+        else:</span>
<span class="gi">+            # multi-dimensional array</span>
<span class="gi">+            return value.tolist()</span>
<span class="gi">+    return value</span>


<span class="w"> </span>class ZarrArrayWrapper(BackendArray):
<span class="gu">@@ -67,11 +74,23 @@ def _determine_zarr_chunks(enc_chunks, var_chunks, ndim, name, safe_chunks):</span>
<span class="w"> </span>    Given encoding chunks (possibly None or []) and variable chunks
<span class="w"> </span>    (possibly None or []).
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if enc_chunks is not None:</span>
<span class="gi">+        if isinstance(enc_chunks, dict):</span>
<span class="gi">+            return tuple(enc_chunks.get(dim, None) for dim in range(ndim))</span>
<span class="gi">+        else:</span>
<span class="gi">+            if len(enc_chunks) != ndim:</span>
<span class="gi">+                raise ValueError(f&quot;zarr_chunks {enc_chunks} must have length equal to {ndim}&quot;)</span>
<span class="gi">+            return tuple(enc_chunks)</span>
<span class="gi">+    elif var_chunks is not None:</span>
<span class="gi">+        if safe_chunks:</span>
<span class="gi">+            return tuple(min(chunk, 1024 * 1024) for chunk in var_chunks)</span>
<span class="gi">+        else:</span>
<span class="gi">+            return tuple(var_chunks)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return None</span>


<span class="gd">-def extract_zarr_variable_encoding(variable, raise_on_invalid=False, name=</span>
<span class="gd">-    None, safe_chunks=True):</span>
<span class="gi">+def extract_zarr_variable_encoding(variable, raise_on_invalid=False, name=None, safe_chunks=True):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Extract zarr encoding dictionary from xarray Variable

<span class="gu">@@ -79,13 +98,34 @@ def extract_zarr_variable_encoding(variable, raise_on_invalid=False, name=</span>
<span class="w"> </span>    ----------
<span class="w"> </span>    variable : Variable
<span class="w"> </span>    raise_on_invalid : bool, optional
<span class="gi">+    name : str, optional</span>
<span class="gi">+    safe_chunks : bool, optional</span>

<span class="w"> </span>    Returns
<span class="w"> </span>    -------
<span class="w"> </span>    encoding : dict
<span class="w"> </span>        Zarr encoding for `variable`
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    encoding = variable.encoding.copy()</span>
<span class="gi">+</span>
<span class="gi">+    valid_encodings = {&#39;chunks&#39;, &#39;compressor&#39;, &#39;filters&#39;, &#39;dtype&#39;, &#39;fill_value&#39;, &#39;order&#39;}</span>
<span class="gi">+    for k in list(encoding):</span>
<span class="gi">+        if k not in valid_encodings:</span>
<span class="gi">+            del encoding[k]</span>
<span class="gi">+            if raise_on_invalid:</span>
<span class="gi">+                raise ValueError(f&quot;invalid encoding for zarr variable: {k}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    chunks = _determine_zarr_chunks(encoding.get(&#39;chunks&#39;), variable.chunks, variable.ndim, name, safe_chunks)</span>
<span class="gi">+    if chunks is not None:</span>
<span class="gi">+        encoding[&#39;chunks&#39;] = chunks</span>
<span class="gi">+</span>
<span class="gi">+    dtype = encoding.get(&#39;dtype&#39;, variable.dtype)</span>
<span class="gi">+    if np.issubdtype(dtype, np.datetime64):</span>
<span class="gi">+        encoding.setdefault(&#39;fill_value&#39;, np.datetime64(&#39;NaT&#39;).astype(dtype))</span>
<span class="gi">+    elif np.issubdtype(dtype, np.timedelta64):</span>
<span class="gi">+        encoding.setdefault(&#39;fill_value&#39;, np.timedelta64(&#39;NaT&#39;).astype(dtype))</span>
<span class="gi">+</span>
<span class="gi">+    return encoding</span>


<span class="w"> </span>def encode_zarr_variable(var, needs_copy=True, name=None):
<span class="gu">@@ -108,14 +148,46 @@ def encode_zarr_variable(var, needs_copy=True, name=None):</span>
<span class="w"> </span>    out : Variable
<span class="w"> </span>        A variable which has been encoded as described above.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import xarray as xr</span>
<span class="gi">+    </span>
<span class="gi">+    # Extract zarr encoding</span>
<span class="gi">+    encoding = extract_zarr_variable_encoding(var, name=name)</span>
<span class="gi">+    </span>
<span class="gi">+    # Create a new variable with the extracted encoding</span>
<span class="gi">+    data = var.data</span>
<span class="gi">+    if needs_copy:</span>
<span class="gi">+        data = data.copy()</span>
<span class="gi">+    </span>
<span class="gi">+    encoded_var = xr.Variable(var.dims, data, var.attrs.copy(), encoding=encoding)</span>
<span class="gi">+    </span>
<span class="gi">+    # Apply CF conventions</span>
<span class="gi">+    if np.issubdtype(var.dtype, np.floating):</span>
<span class="gi">+        encoded_var.attrs.setdefault(&#39;_FillValue&#39;, np.nan)</span>
<span class="gi">+    elif np.issubdtype(var.dtype, np.datetime64):</span>
<span class="gi">+        encoded_var = xr.coding.times.encode_cf_datetime(encoded_var)</span>
<span class="gi">+    elif np.issubdtype(var.dtype, np.timedelta64):</span>
<span class="gi">+        encoded_var = xr.coding.times.encode_cf_timedelta(encoded_var)</span>
<span class="gi">+    </span>
<span class="gi">+    # Apply scale_factor and add_offset if present</span>
<span class="gi">+    if &#39;scale_factor&#39; in encoded_var.attrs or &#39;add_offset&#39; in encoded_var.attrs:</span>
<span class="gi">+        encoded_var = xr.coding.variables.scale_offset_encoder(encoded_var)</span>
<span class="gi">+    </span>
<span class="gi">+    return encoded_var</span>


<span class="w"> </span>def _validate_datatypes_for_zarr_append(vname, existing_var, new_var):
<span class="w"> </span>    &quot;&quot;&quot;If variable exists in the store, confirm dtype of the data to append is compatible with
<span class="w"> </span>    existing dtype.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if existing_var.dtype != new_var.dtype:</span>
<span class="gi">+        raise ValueError(f&quot;Dtype mismatch for variable {vname}. &quot;</span>
<span class="gi">+                         f&quot;Existing dtype: {existing_var.dtype}, &quot;</span>
<span class="gi">+                         f&quot;new dtype: {new_var.dtype}&quot;)</span>
<span class="gi">+    </span>
<span class="gi">+    if existing_var.shape[1:] != new_var.shape[1:]:</span>
<span class="gi">+        raise ValueError(f&quot;Shape mismatch for variable {vname}. &quot;</span>
<span class="gi">+                         f&quot;Existing shape: {existing_var.shape}, &quot;</span>
<span class="gi">+                         f&quot;new shape: {new_var.shape}&quot;)</span>


<span class="w"> </span>def _put_attrs(zarr_obj, attrs):
<span class="gh">diff --git a/xarray/coding/calendar_ops.py b/xarray/coding/calendar_ops.py</span>
<span class="gh">index 7de8fc94..6bc7ae2b 100644</span>
<span class="gd">--- a/xarray/coding/calendar_ops.py</span>
<span class="gi">+++ b/xarray/coding/calendar_ops.py</span>
<span class="gu">@@ -15,133 +15,72 @@ _CALENDARS_WITHOUT_YEAR_ZERO = [&#39;gregorian&#39;, &#39;proleptic_gregorian&#39;,</span>

<span class="w"> </span>def _days_in_year(year, calendar, use_cftime=True):
<span class="w"> </span>    &quot;&quot;&quot;Return the number of days in the input year according to the input calendar.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if use_cftime and cftime is not None:</span>
<span class="gi">+        date_type = get_date_type(calendar)</span>
<span class="gi">+        return date_type(year, 12, 31).dayofyear</span>
<span class="gi">+    elif calendar in [&#39;noleap&#39;, &#39;365_day&#39;]:</span>
<span class="gi">+        return 365</span>
<span class="gi">+    elif calendar == &#39;360_day&#39;:</span>
<span class="gi">+        return 360</span>
<span class="gi">+    else:</span>
<span class="gi">+        return 366 if pd.Timestamp(year, 1, 1).is_leap_year else 365</span>


<span class="w"> </span>def convert_calendar(obj, calendar, dim=&#39;time&#39;, align_on=None, missing=None,
<span class="w"> </span>    use_cftime=None):
<span class="gd">-    &quot;&quot;&quot;Transform a time-indexed Dataset or DataArray to one that uses another calendar.</span>
<span class="gd">-</span>
<span class="gd">-    This function only converts the individual timestamps; it does not modify any</span>
<span class="gd">-    data except in dropping invalid/surplus dates, or inserting values for missing dates.</span>
<span class="gd">-</span>
<span class="gd">-    If the source and target calendars are both from a standard type, only the</span>
<span class="gd">-    type of the time array is modified. When converting to a calendar with a</span>
<span class="gd">-    leap year from to a calendar without a leap year, the 29th of February will</span>
<span class="gd">-    be removed from the array. In the other direction the 29th of February will</span>
<span class="gd">-    be missing in the output, unless `missing` is specified, in which case that</span>
<span class="gd">-    value is inserted. For conversions involving the `360_day` calendar, see Notes.</span>
<span class="gd">-</span>
<span class="gd">-    This method is safe to use with sub-daily data as it doesn&#39;t touch the time</span>
<span class="gd">-    part of the timestamps.</span>
<span class="gd">-</span>
<span class="gd">-    Parameters</span>
<span class="gd">-    ----------</span>
<span class="gd">-    obj : DataArray or Dataset</span>
<span class="gd">-      Input DataArray or Dataset with a time coordinate of a valid dtype</span>
<span class="gd">-      (:py:class:`numpy.datetime64`  or :py:class:`cftime.datetime`).</span>
<span class="gd">-    calendar : str</span>
<span class="gd">-      The target calendar name.</span>
<span class="gd">-    dim : str</span>
<span class="gd">-      Name of the time coordinate in the input DataArray or Dataset.</span>
<span class="gd">-    align_on : {None, &#39;date&#39;, &#39;year&#39;, &#39;random&#39;}</span>
<span class="gd">-      Must be specified when either the source or target is a `&quot;360_day&quot;`</span>
<span class="gd">-      calendar; ignored otherwise. See Notes.</span>
<span class="gd">-    missing : any, optional</span>
<span class="gd">-      By default, i.e. if the value is None, this method will simply attempt</span>
<span class="gd">-      to convert the dates in the source calendar to the same dates in the</span>
<span class="gd">-      target calendar, and drop any of those that are not possible to</span>
<span class="gd">-      represent.  If a value is provided, a new time coordinate will be</span>
<span class="gd">-      created in the target calendar with the same frequency as the original</span>
<span class="gd">-      time coordinate; for any dates that are not present in the source, the</span>
<span class="gd">-      data will be filled with this value.  Note that using this mode requires</span>
<span class="gd">-      that the source data have an inferable frequency; for more information</span>
<span class="gd">-      see :py:func:`xarray.infer_freq`.  For certain frequency, source, and</span>
<span class="gd">-      target calendar combinations, this could result in many missing values, see notes.</span>
<span class="gd">-    use_cftime : bool, optional</span>
<span class="gd">-      Whether to use cftime objects in the output, only used if `calendar` is</span>
<span class="gd">-      one of {&quot;proleptic_gregorian&quot;, &quot;gregorian&quot; or &quot;standard&quot;}.</span>
<span class="gd">-      If True, the new time axis uses cftime objects.</span>
<span class="gd">-      If None (default), it uses :py:class:`numpy.datetime64` values if the date</span>
<span class="gd">-          range permits it, and :py:class:`cftime.datetime` objects if not.</span>
<span class="gd">-      If False, it uses :py:class:`numpy.datetime64`  or fails.</span>
<span class="gd">-</span>
<span class="gd">-    Returns</span>
<span class="gd">-    -------</span>
<span class="gd">-      Copy of source with the time coordinate converted to the target calendar.</span>
<span class="gd">-      If `missing` was None (default), invalid dates in the new calendar are</span>
<span class="gd">-      dropped, but missing dates are not inserted.</span>
<span class="gd">-      If `missing` was given, the new data is reindexed to have a time axis</span>
<span class="gd">-      with the same frequency as the source, but in the new calendar; any</span>
<span class="gd">-      missing datapoints are filled with `missing`.</span>
<span class="gd">-</span>
<span class="gd">-    Notes</span>
<span class="gd">-    -----</span>
<span class="gd">-    Passing a value to `missing` is only usable if the source&#39;s time coordinate as an</span>
<span class="gd">-    inferable frequencies (see :py:func:`~xarray.infer_freq`) and is only appropriate</span>
<span class="gd">-    if the target coordinate, generated from this frequency, has dates equivalent to the</span>
<span class="gd">-    source. It is usually **not** appropriate to use this mode with:</span>
<span class="gd">-</span>
<span class="gd">-    - Period-end frequencies: &#39;A&#39;, &#39;Y&#39;, &#39;Q&#39; or &#39;M&#39;, in opposition to &#39;AS&#39; &#39;YS&#39;, &#39;QS&#39; and &#39;MS&#39;</span>
<span class="gd">-    - Sub-monthly frequencies that do not divide a day evenly: &#39;W&#39;, &#39;nD&#39; where `n != 1`</span>
<span class="gd">-      or &#39;mH&#39; where 24 % m != 0).</span>
<span class="gd">-</span>
<span class="gd">-    If one of the source or target calendars is `&quot;360_day&quot;`, `align_on` must</span>
<span class="gd">-    be specified and two options are offered.</span>
<span class="gd">-</span>
<span class="gd">-    &quot;year&quot;</span>
<span class="gd">-      The dates are translated according to their relative position in the year,</span>
<span class="gd">-      ignoring their original month and day information, meaning that the</span>
<span class="gd">-      missing/surplus days are added/removed at regular intervals.</span>
<span class="gd">-</span>
<span class="gd">-      From a `360_day` to a standard calendar, the output will be missing the</span>
<span class="gd">-      following dates (day of year in parentheses):</span>
<span class="gd">-        To a leap year:</span>
<span class="gd">-          January 31st (31), March 31st (91), June 1st (153), July 31st (213),</span>
<span class="gd">-          September 31st (275) and November 30th (335).</span>
<span class="gd">-        To a non-leap year:</span>
<span class="gd">-          February 6th (36), April 19th (109), July 2nd (183),</span>
<span class="gd">-          September 12th (255), November 25th (329).</span>
<span class="gd">-</span>
<span class="gd">-      From a standard calendar to a `&quot;360_day&quot;`, the following dates in the</span>
<span class="gd">-      source array will be dropped:</span>
<span class="gd">-        From a leap year:</span>
<span class="gd">-          January 31st (31), April 1st (92), June 1st (153), August 1st (214),</span>
<span class="gd">-          September 31st (275), December 1st (336)</span>
<span class="gd">-        From a non-leap year:</span>
<span class="gd">-          February 6th (37), April 20th (110), July 2nd (183),</span>
<span class="gd">-          September 13th (256), November 25th (329)</span>
<span class="gd">-</span>
<span class="gd">-      This option is best used on daily and subdaily data.</span>
<span class="gd">-</span>
<span class="gd">-    &quot;date&quot;</span>
<span class="gd">-      The month/day information is conserved and invalid dates are dropped</span>
<span class="gd">-      from the output. This means that when converting from a `&quot;360_day&quot;` to a</span>
<span class="gd">-      standard calendar, all 31sts (Jan, March, May, July, August, October and</span>
<span class="gd">-      December) will be missing as there is no equivalent dates in the</span>
<span class="gd">-      `&quot;360_day&quot;` calendar and the 29th (on non-leap years) and 30th of February</span>
<span class="gd">-      will be dropped as there are no equivalent dates in a standard calendar.</span>
<span class="gd">-</span>
<span class="gd">-      This option is best used with data on a frequency coarser than daily.</span>
<span class="gd">-</span>
<span class="gd">-    &quot;random&quot;</span>
<span class="gd">-      Similar to &quot;year&quot;, each day of year of the source is mapped to another day of year</span>
<span class="gd">-      of the target. However, instead of having always the same missing days according</span>
<span class="gd">-      the source and target years, here 5 days are chosen randomly, one for each fifth</span>
<span class="gd">-      of the year. However, February 29th is always missing when converting to a leap year,</span>
<span class="gd">-      or its value is dropped when converting from a leap year. This is similar to the method</span>
<span class="gd">-      used in the LOCA dataset (see Pierce, Cayan, and Thrasher (2014). doi:10.1175/JHM-D-14-0082.1).</span>
<span class="gd">-</span>
<span class="gd">-      This option is best used on daily data.</span>
<span class="gd">-    &quot;&quot;&quot;</span>
<span class="gd">-    pass</span>
<span class="gi">+    &quot;&quot;&quot;Transform a time-indexed Dataset or DataArray to one that uses another calendar.&quot;&quot;&quot;</span>
<span class="gi">+    if not _contains_datetime_like_objects(obj[dim]):</span>
<span class="gi">+        raise ValueError(&quot;Input must have datetime-like values&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    source_calendar = getattr(obj[dim].dtype, &#39;calendar&#39;, &#39;standard&#39;)</span>
<span class="gi">+    if source_calendar == calendar:</span>
<span class="gi">+        return obj</span>
<span class="gi">+</span>
<span class="gi">+    if align_on not in [None, &#39;date&#39;, &#39;year&#39;, &#39;random&#39;]:</span>
<span class="gi">+        raise ValueError(&quot;align_on must be one of None, &#39;date&#39;, &#39;year&#39;, or &#39;random&#39;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if (source_calendar == &#39;360_day&#39; or calendar == &#39;360_day&#39;) and align_on is None:</span>
<span class="gi">+        raise ValueError(&quot;align_on must be specified when converting to or from &#39;360_day&#39; calendar&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if use_cftime is None:</span>
<span class="gi">+        use_cftime = _should_cftime_be_used(obj[dim], calendar)</span>
<span class="gi">+</span>
<span class="gi">+    if missing is None:</span>
<span class="gi">+        new_times = convert_times(obj[dim], calendar, use_cftime=use_cftime)</span>
<span class="gi">+        return obj.sel({dim: new_times})</span>
<span class="gi">+    else:</span>
<span class="gi">+        freq = pd.infer_freq(obj[dim])</span>
<span class="gi">+        if freq is None:</span>
<span class="gi">+            raise ValueError(&quot;Cannot infer frequency from input times&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        start, end = obj[dim].min(), obj[dim].max()</span>
<span class="gi">+        new_times = date_range_like(start, end, freq, calendar, use_cftime=use_cftime)</span>
<span class="gi">+</span>
<span class="gi">+        if align_on == &#39;date&#39;:</span>
<span class="gi">+            new_obj = obj.reindex({dim: new_times}, fill_value=missing)</span>
<span class="gi">+        elif align_on in [&#39;year&#39;, &#39;random&#39;]:</span>
<span class="gi">+            if align_on == &#39;year&#39;:</span>
<span class="gi">+                new_days = _interpolate_day_of_year(obj[dim], calendar, use_cftime)</span>
<span class="gi">+            else:  # &#39;random&#39;</span>
<span class="gi">+                new_days = _random_day_of_year(obj[dim], calendar, use_cftime)</span>
<span class="gi">+            </span>
<span class="gi">+            new_times = [_convert_to_new_calendar_with_new_day_of_year(t, d, calendar, use_cftime)</span>
<span class="gi">+                         for t, d in zip(obj[dim], new_days)]</span>
<span class="gi">+            new_obj = obj.assign_coords({dim: new_times}).reindex({dim: new_times}, fill_value=missing)</span>
<span class="gi">+        else:</span>
<span class="gi">+            new_obj = obj.reindex({dim: new_times}, fill_value=missing)</span>
<span class="gi">+</span>
<span class="gi">+        return new_obj</span>


<span class="w"> </span>def _interpolate_day_of_year(time, target_calendar, use_cftime):
<span class="w"> </span>    &quot;&quot;&quot;Returns the nearest day in the target calendar of the corresponding
<span class="w"> </span>    &quot;decimal year&quot; in the source calendar.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    decimal_years = _datetime_to_decimal_year(time)</span>
<span class="gi">+    target_days = np.array([_days_in_year(int(year), target_calendar, use_cftime)</span>
<span class="gi">+                            for year in decimal_years.astype(int)])</span>
<span class="gi">+    return np.round(decimal_years % 1 * target_days).astype(int)</span>


<span class="w"> </span>def _random_day_of_year(time, target_calendar, use_cftime):
<span class="gu">@@ -149,7 +88,26 @@ def _random_day_of_year(time, target_calendar, use_cftime):</span>

<span class="w"> </span>    Removes Feb 29th and five other days chosen randomly within five sections of 72 days.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    np.random.seed(0)  # for reproducibility</span>
<span class="gi">+    source_days = _interpolate_day_of_year(time, time.dtype.calendar, use_cftime)</span>
<span class="gi">+    target_days = np.zeros_like(source_days)</span>
<span class="gi">+    </span>
<span class="gi">+    for year in np.unique(time.dt.year):</span>
<span class="gi">+        mask = time.dt.year == year</span>
<span class="gi">+        year_days = source_days[mask]</span>
<span class="gi">+        </span>
<span class="gi">+        if _days_in_year(year, target_calendar, use_cftime) == 366:</span>
<span class="gi">+            year_days = year_days[year_days != 60]  # Remove Feb 29th</span>
<span class="gi">+        </span>
<span class="gi">+        sections = np.array_split(year_days, 5)</span>
<span class="gi">+        for i, section in enumerate(sections):</span>
<span class="gi">+            if len(section) &gt; 0:</span>
<span class="gi">+                remove_idx = np.random.choice(len(section))</span>
<span class="gi">+                sections[i] = np.delete(section, remove_idx)</span>
<span class="gi">+        </span>
<span class="gi">+        target_days[mask] = np.concatenate(sections)</span>
<span class="gi">+    </span>
<span class="gi">+    return target_days</span>


<span class="w"> </span>def _convert_to_new_calendar_with_new_day_of_year(date, day_of_year,
<span class="gu">@@ -160,7 +118,16 @@ def _convert_to_new_calendar_with_new_day_of_year(date, day_of_year,</span>
<span class="w"> </span>    from the source datetime).
<span class="w"> </span>    Nanosecond information is lost as cftime.datetime doesn&#39;t support it.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    year = date.year</span>
<span class="gi">+    date_type = get_date_type(calendar)</span>
<span class="gi">+    </span>
<span class="gi">+    if use_cftime:</span>
<span class="gi">+        new_date = date_type(year, 1, 1) + pd.Timedelta(days=day_of_year - 1)</span>
<span class="gi">+    else:</span>
<span class="gi">+        new_date = pd.Timestamp(year, 1, 1) + pd.Timedelta(days=day_of_year - 1)</span>
<span class="gi">+    </span>
<span class="gi">+    return new_date.replace(hour=date.hour, minute=date.minute, second=date.second,</span>
<span class="gi">+                            microsecond=date.microsecond)</span>


<span class="w"> </span>def _datetime_to_decimal_year(times, dim=&#39;time&#39;, calendar=None):
<span class="gu">@@ -171,7 +138,16 @@ def _datetime_to_decimal_year(times, dim=&#39;time&#39;, calendar=None):</span>
<span class="w"> </span>    Ex: &#39;2000-03-01 12:00&#39; is 2000.1653 in a standard calendar,
<span class="w"> </span>      2000.16301 in a &quot;noleap&quot; or 2000.16806 in a &quot;360_day&quot;.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if calendar is None:</span>
<span class="gi">+        calendar = getattr(times.dtype, &#39;calendar&#39;, &#39;standard&#39;)</span>
<span class="gi">+    </span>
<span class="gi">+    years = times.dt.year</span>
<span class="gi">+    days_in_year = np.vectorize(lambda y: _days_in_year(y, calendar))(years)</span>
<span class="gi">+    </span>
<span class="gi">+    year_start = times.dt.to_pandas().astype(&#39;datetime64[Y]&#39;)</span>
<span class="gi">+    days_since_year_start = (times - year_start).dt.total_seconds() / (24 * 3600)</span>
<span class="gi">+    </span>
<span class="gi">+    return years + days_since_year_start / days_in_year</span>


<span class="w"> </span>def interp_calendar(source, target, dim=&#39;time&#39;):
<span class="gu">@@ -202,4 +178,7 @@ def interp_calendar(source, target, dim=&#39;time&#39;):</span>
<span class="w"> </span>    DataArray or Dataset
<span class="w"> </span>      The source interpolated on the decimal years of target,
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    source_decimal = _datetime_to_decimal_year(source[dim])</span>
<span class="gi">+    target_decimal = _datetime_to_decimal_year(target)</span>
<span class="gi">+    </span>
<span class="gi">+    return source.interp({dim: target_decimal}, method=&#39;linear&#39;, kwargs={&#39;fill_value&#39;: &#39;extrapolate&#39;})</span>
<span class="gh">diff --git a/xarray/coding/cftime_offsets.py b/xarray/coding/cftime_offsets.py</span>
<span class="gh">index a1176778..c243a1e4 100644</span>
<span class="gd">--- a/xarray/coding/cftime_offsets.py</span>
<span class="gi">+++ b/xarray/coding/cftime_offsets.py</span>
<span class="gu">@@ -24,7 +24,15 @@ DayOption: TypeAlias = Literal[&#39;start&#39;, &#39;end&#39;]</span>

<span class="w"> </span>def get_date_type(calendar, use_cftime=True):
<span class="w"> </span>    &quot;&quot;&quot;Return the cftime date type for a given calendar name.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if cftime is None:</span>
<span class="gi">+        raise ImportError(&quot;cftime is required for this functionality&quot;)</span>
<span class="gi">+    calendar = calendar.lower()</span>
<span class="gi">+    if use_cftime:</span>
<span class="gi">+        return cftime._cftime.DATE_TYPES.get(calendar)</span>
<span class="gi">+    elif calendar in {&quot;proleptic_gregorian&quot;, &quot;gregorian&quot;, &quot;standard&quot;}:</span>
<span class="gi">+        return datetime</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(f&quot;Calendar &#39;{calendar}&#39; is not supported without cftime&quot;)</span>


<span class="w"> </span>class BaseCFTimeOffset:
<span class="gu">@@ -87,7 +95,7 @@ class BaseCFTimeOffset:</span>
<span class="w"> </span>    def onOffset(self, date) -&gt;bool:
<span class="w"> </span>        &quot;&quot;&quot;Check if the given date is in the set of possible dates created
<span class="w"> </span>        using a length-one version of this offset class.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.n == 1 and self.__class__(1).rollback(date) == date</span>

<span class="w"> </span>    def __str__(self):
<span class="w"> </span>        return f&#39;&lt;{type(self).__name__}: n={self.n}&gt;&#39;
<span class="gu">@@ -130,30 +138,61 @@ def _get_day_of_month(other, day_option: DayOption) -&gt;int:</span>
<span class="w"> </span>    day_of_month : int

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if day_option == &#39;start&#39;:</span>
<span class="gi">+        return 1</span>
<span class="gi">+    elif day_option == &#39;end&#39;:</span>
<span class="gi">+        return _days_in_month(other)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(&quot;day_option must be &#39;start&#39; or &#39;end&#39;&quot;)</span>


<span class="w"> </span>def _days_in_month(date):
<span class="w"> </span>    &quot;&quot;&quot;The number of days in the month of the given date&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if hasattr(date, &#39;daysinmonth&#39;):</span>
<span class="gi">+        return date.daysinmonth</span>
<span class="gi">+    else:</span>
<span class="gi">+        year = date.year</span>
<span class="gi">+        month = date.month</span>
<span class="gi">+        if month == 12:</span>
<span class="gi">+            next_month = date.replace(year=year + 1, month=1, day=1)</span>
<span class="gi">+        else:</span>
<span class="gi">+            next_month = date.replace(month=month + 1, day=1)</span>
<span class="gi">+        return (next_month - date).days</span>


<span class="w"> </span>def _adjust_n_months(other_day, n, reference_day):
<span class="w"> </span>    &quot;&quot;&quot;Adjust the number of times a monthly offset is applied based
<span class="w"> </span>    on the day of a given date, and the reference day provided.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if n &gt; 0 and other_day &lt; reference_day:</span>
<span class="gi">+        return n - 1</span>
<span class="gi">+    elif n &lt;= 0 and other_day &gt; reference_day:</span>
<span class="gi">+        return n + 1</span>
<span class="gi">+    return n</span>


<span class="w"> </span>def _adjust_n_years(other, n, month, reference_day):
<span class="w"> </span>    &quot;&quot;&quot;Adjust the number of times an annual offset is applied based on
<span class="w"> </span>    another date, and the reference day provided&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if n &gt; 0:</span>
<span class="gi">+        if other.month &lt; month or (other.month == month and other.day &lt; reference_day):</span>
<span class="gi">+            return n - 1</span>
<span class="gi">+    elif n &lt; 0:</span>
<span class="gi">+        if other.month &gt; month or (other.month == month and other.day &gt; reference_day):</span>
<span class="gi">+            return n + 1</span>
<span class="gi">+    return n</span>


<span class="w"> </span>def _shift_month(date, months, day_option: DayOption=&#39;start&#39;):
<span class="w"> </span>    &quot;&quot;&quot;Shift the date to a month start or end a given number of months away.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    year = date.year + (date.month + months - 1) // 12</span>
<span class="gi">+    month = (date.month + months - 1) % 12 + 1</span>
<span class="gi">+    if day_option == &#39;start&#39;:</span>
<span class="gi">+        return date.replace(year=year, month=month, day=1)</span>
<span class="gi">+    elif day_option == &#39;end&#39;:</span>
<span class="gi">+        return date.replace(year=year, month=month, day=_days_in_month(date.replace(year=year, month=month)))</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(&quot;day_option must be &#39;start&#39; or &#39;end&#39;&quot;)</span>


<span class="w"> </span>def roll_qtrday(other, n: int, month: int, day_option: DayOption, modby: int=3
<span class="gu">@@ -179,7 +218,16 @@ def roll_qtrday(other, n: int, month: int, day_option: DayOption, modby: int=3</span>
<span class="w"> </span>    --------
<span class="w"> </span>    _get_day_of_month : Find the day in a month provided an offset.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    months_since = other.month % modby - month % modby</span>
<span class="gi">+    reference_day = _get_day_of_month(other, day_option)</span>
<span class="gi">+    </span>
<span class="gi">+    if n &gt; 0:</span>
<span class="gi">+        if months_since &lt; 0 or (months_since == 0 and other.day &lt; reference_day):</span>
<span class="gi">+            return n - 1</span>
<span class="gi">+    elif n &lt; 0:</span>
<span class="gi">+        if months_since &gt; 0 or (months_since == 0 and other.day &gt; reference_day):</span>
<span class="gi">+            return n + 1</span>
<span class="gi">+    return n</span>


<span class="w"> </span>class MonthBegin(BaseCFTimeOffset):
<span class="gu">@@ -192,7 +240,7 @@ class MonthBegin(BaseCFTimeOffset):</span>
<span class="w"> </span>    def onOffset(self, date) -&gt;bool:
<span class="w"> </span>        &quot;&quot;&quot;Check if the given date is in the set of possible dates created
<span class="w"> </span>        using a length-one version of this offset class.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return date.day == 1</span>


<span class="w"> </span>class MonthEnd(BaseCFTimeOffset):
<span class="gu">@@ -205,7 +253,7 @@ class MonthEnd(BaseCFTimeOffset):</span>
<span class="w"> </span>    def onOffset(self, date) -&gt;bool:
<span class="w"> </span>        &quot;&quot;&quot;Check if the given date is in the set of possible dates created
<span class="w"> </span>        using a length-one version of this offset class.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return date.day == _days_in_month(date)</span>


<span class="w"> </span>_MONTH_ABBREVIATIONS = {(1): &#39;JAN&#39;, (2): &#39;FEB&#39;, (3): &#39;MAR&#39;, (4): &#39;APR&#39;, (5):
<span class="gu">@@ -232,7 +280,7 @@ class QuarterOffset(BaseCFTimeOffset):</span>
<span class="w"> </span>    def onOffset(self, date) -&gt;bool:
<span class="w"> </span>        &quot;&quot;&quot;Check if the given date is in the set of possible dates created
<span class="w"> </span>        using a length-one version of this offset class.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return (date.month == self.month and date.day == 1)</span>

<span class="w"> </span>    def __sub__(self, other: Self) -&gt;Self:
<span class="w"> </span>        if cftime is None:
<span class="gu">@@ -259,11 +307,21 @@ class QuarterBegin(QuarterOffset):</span>

<span class="w"> </span>    def rollforward(self, date):
<span class="w"> </span>        &quot;&quot;&quot;Roll date forward to nearest start of quarter&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        months_since = date.month % 3 - self.month % 3</span>
<span class="gi">+        if months_since &lt; 0 or (months_since == 0 and date.day &gt; 1):</span>
<span class="gi">+            months_to_shift = 3 - months_since</span>
<span class="gi">+        else:</span>
<span class="gi">+            months_to_shift = -months_since</span>
<span class="gi">+        return _shift_month(date, months_to_shift, &#39;start&#39;)</span>

<span class="w"> </span>    def rollback(self, date):
<span class="w"> </span>        &quot;&quot;&quot;Roll date backward to nearest start of quarter&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        months_since = date.month % 3 - self.month % 3</span>
<span class="gi">+        if months_since &gt; 0 or (months_since == 0 and date.day &gt; 1):</span>
<span class="gi">+            months_to_shift = -months_since</span>
<span class="gi">+        else:</span>
<span class="gi">+            months_to_shift = -(3 + months_since)</span>
<span class="gi">+        return _shift_month(date, months_to_shift, &#39;start&#39;)</span>


<span class="w"> </span>class QuarterEnd(QuarterOffset):
<span class="gu">@@ -273,11 +331,21 @@ class QuarterEnd(QuarterOffset):</span>

<span class="w"> </span>    def rollforward(self, date):
<span class="w"> </span>        &quot;&quot;&quot;Roll date forward to nearest end of quarter&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        months_since = date.month % 3 - self.month % 3</span>
<span class="gi">+        if months_since &lt; 0 or (months_since == 0 and date.day &lt; _days_in_month(date)):</span>
<span class="gi">+            months_to_shift = 2 - months_since</span>
<span class="gi">+        else:</span>
<span class="gi">+            months_to_shift = -1 - months_since</span>
<span class="gi">+        return _shift_month(date, months_to_shift, &#39;end&#39;)</span>

<span class="w"> </span>    def rollback(self, date):
<span class="w"> </span>        &quot;&quot;&quot;Roll date backward to nearest end of quarter&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        months_since = date.month % 3 - self.month % 3</span>
<span class="gi">+        if months_since &gt; 0 or (months_since == 0 and date.day == _days_in_month(date)):</span>
<span class="gi">+            months_to_shift = -months_since</span>
<span class="gi">+        else:</span>
<span class="gi">+            months_to_shift = -(3 + months_since)</span>
<span class="gi">+        return _shift_month(date, months_to_shift, &#39;end&#39;)</span>


<span class="w"> </span>class YearOffset(BaseCFTimeOffset):
<span class="gu">@@ -321,15 +389,21 @@ class YearBegin(YearOffset):</span>
<span class="w"> </span>    def onOffset(self, date) -&gt;bool:
<span class="w"> </span>        &quot;&quot;&quot;Check if the given date is in the set of possible dates created
<span class="w"> </span>        using a length-one version of this offset class.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return (date.month == self.month and date.day == _days_in_month(date))</span>

<span class="w"> </span>    def rollforward(self, date):
<span class="w"> </span>        &quot;&quot;&quot;Roll date forward to nearest start of year&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if (date.month, date.day) &lt; (self.month, 1):</span>
<span class="gi">+            return date.replace(year=date.year, month=self.month, day=1)</span>
<span class="gi">+        else:</span>
<span class="gi">+            return date.replace(year=date.year + 1, month=self.month, day=1)</span>

<span class="w"> </span>    def rollback(self, date):
<span class="w"> </span>        &quot;&quot;&quot;Roll date backward to nearest start of year&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if (date.month, date.day) &gt; (self.month, 1):</span>
<span class="gi">+            return date.replace(year=date.year, month=self.month, day=1)</span>
<span class="gi">+        else:</span>
<span class="gi">+            return date.replace(year=date.year - 1, month=self.month, day=1)</span>


<span class="w"> </span>class YearEnd(YearOffset):
<span class="gu">@@ -344,11 +418,17 @@ class YearEnd(YearOffset):</span>

<span class="w"> </span>    def rollforward(self, date):
<span class="w"> </span>        &quot;&quot;&quot;Roll date forward to nearest end of year&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if (date.month, date.day) &lt; (self.month, _days_in_month(date.replace(month=self.month))):</span>
<span class="gi">+            return date.replace(year=date.year, month=self.month, day=_days_in_month(date.replace(month=self.month)))</span>
<span class="gi">+        else:</span>
<span class="gi">+            return date.replace(year=date.year + 1, month=self.month, day=_days_in_month(date.replace(year=date.year + 1, month=self.month)))</span>

<span class="w"> </span>    def rollback(self, date):
<span class="w"> </span>        &quot;&quot;&quot;Roll date backward to nearest end of year&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if (date.month, date.day) &gt; (self.month, _days_in_month(date.replace(month=self.month))):</span>
<span class="gi">+            return date.replace(year=date.year, month=self.month, day=_days_in_month(date.replace(month=self.month)))</span>
<span class="gi">+        else:</span>
<span class="gi">+            return date.replace(year=date.year - 1, month=self.month, day=_days_in_month(date.replace(year=date.year - 1, month=self.month)))</span>


<span class="w"> </span>class Day(Tick):
<span class="gh">diff --git a/xarray/coding/cftimeindex.py b/xarray/coding/cftimeindex.py</span>
<span class="gh">index 674e36be..d4c5201b 100644</span>
<span class="gd">--- a/xarray/coding/cftimeindex.py</span>
<span class="gi">+++ b/xarray/coding/cftimeindex.py</span>
<span class="gu">@@ -40,33 +40,101 @@ def _parsed_string_to_bounds(date_type, resolution, parsed):</span>
<span class="w"> </span>    for use with non-standard calendars and cftime.datetime
<span class="w"> </span>    objects.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if resolution == &#39;year&#39;:</span>
<span class="gi">+        return (</span>
<span class="gi">+            date_type(*parsed[:1], 1, 1),</span>
<span class="gi">+            date_type(*parsed[:1], 12, 31, 23, 59, 59, 999999)</span>
<span class="gi">+        )</span>
<span class="gi">+    elif resolution == &#39;month&#39;:</span>
<span class="gi">+        year, month = parsed[:2]</span>
<span class="gi">+        last_day = date_type(year, month, 1).daysinmonth</span>
<span class="gi">+        return (</span>
<span class="gi">+            date_type(year, month, 1),</span>
<span class="gi">+            date_type(year, month, last_day, 23, 59, 59, 999999)</span>
<span class="gi">+        )</span>
<span class="gi">+    elif resolution == &#39;day&#39;:</span>
<span class="gi">+        return (</span>
<span class="gi">+            date_type(*parsed[:3]),</span>
<span class="gi">+            date_type(*parsed[:3], 23, 59, 59, 999999)</span>
<span class="gi">+        )</span>
<span class="gi">+    elif resolution == &#39;hour&#39;:</span>
<span class="gi">+        return (</span>
<span class="gi">+            date_type(*parsed[:4]),</span>
<span class="gi">+            date_type(*parsed[:4], 59, 59, 999999)</span>
<span class="gi">+        )</span>
<span class="gi">+    elif resolution == &#39;minute&#39;:</span>
<span class="gi">+        return (</span>
<span class="gi">+            date_type(*parsed[:5]),</span>
<span class="gi">+            date_type(*parsed[:5], 59, 999999)</span>
<span class="gi">+        )</span>
<span class="gi">+    elif resolution == &#39;second&#39;:</span>
<span class="gi">+        return (</span>
<span class="gi">+            date_type(*parsed[:6]),</span>
<span class="gi">+            date_type(*parsed[:6], 999999)</span>
<span class="gi">+        )</span>
<span class="gi">+    else:</span>
<span class="gi">+        return (date_type(*parsed), date_type(*parsed))</span>


<span class="w"> </span>def get_date_field(datetimes, field):
<span class="w"> </span>    &quot;&quot;&quot;Adapted from pandas.tslib.get_date_field&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return np.array([getattr(dt, field) for dt in datetimes])</span>


<span class="w"> </span>def _field_accessor(name, docstring=None, min_cftime_version=&#39;0.0&#39;):
<span class="w"> </span>    &quot;&quot;&quot;Adapted from pandas.tseries.index._field_accessor&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    def accessor(self):</span>
<span class="gi">+        if cftime is None:</span>
<span class="gi">+            raise ImportError(&quot;cftime is required for this functionality&quot;)</span>
<span class="gi">+        if Version(cftime.__version__) &lt; Version(min_cftime_version):</span>
<span class="gi">+            raise ImportError(f&quot;cftime &gt;={min_cftime_version} is required for this functionality&quot;)</span>
<span class="gi">+        return get_date_field(self, name)</span>
<span class="gi">+    </span>
<span class="gi">+    accessor.__name__ = name</span>
<span class="gi">+    accessor.__doc__ = docstring</span>
<span class="gi">+    return property(accessor)</span>


<span class="w"> </span>def format_row(times, indent=0, separator=&#39;, &#39;, row_end=&#39;,\n&#39;):
<span class="w"> </span>    &quot;&quot;&quot;Format a single row from format_times.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    formatted = separator.join(str(t)[:CFTIME_REPR_LENGTH] for t in times)</span>
<span class="gi">+    return f&quot;{&#39; &#39; * indent}{formatted}{row_end}&quot;</span>


<span class="w"> </span>def format_times(index, max_width, offset, separator=&#39;, &#39;, first_row_offset
<span class="w"> </span>    =0, intermediate_row_end=&#39;,\n&#39;, last_row_end=&#39;&#39;):
<span class="w"> </span>    &quot;&quot;&quot;Format values of cftimeindex as pd.Index.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    times = index.values</span>
<span class="gi">+    rows = []</span>
<span class="gi">+    row_times = []</span>
<span class="gi">+    row_width = first_row_offset</span>
<span class="gi">+</span>
<span class="gi">+    for t in times:</span>
<span class="gi">+        time_width = len(str(t)[:CFTIME_REPR_LENGTH]) + len(separator)</span>
<span class="gi">+        if row_width + time_width &gt; max_width:</span>
<span class="gi">+            rows.append(format_row(row_times, offset, separator, intermediate_row_end))</span>
<span class="gi">+            row_times = []</span>
<span class="gi">+            row_width = offset</span>
<span class="gi">+</span>
<span class="gi">+        row_times.append(t)</span>
<span class="gi">+        row_width += time_width</span>
<span class="gi">+</span>
<span class="gi">+    if row_times:</span>
<span class="gi">+        rows.append(format_row(row_times, offset, separator, last_row_end))</span>
<span class="gi">+</span>
<span class="gi">+    return &#39;&#39;.join(rows)</span>


<span class="w"> </span>def format_attrs(index, separator=&#39;, &#39;):
<span class="w"> </span>    &quot;&quot;&quot;Format attributes of CFTimeIndex for __repr__.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    attrs = []</span>
<span class="gi">+    if index.name is not None:</span>
<span class="gi">+        attrs.append(f&quot;name=&#39;{index.name}&#39;&quot;)</span>
<span class="gi">+    attrs.append(f&quot;length={len(index)}&quot;)</span>
<span class="gi">+    attrs.append(f&quot;calendar=&#39;{index.calendar}&#39;&quot;)</span>
<span class="gi">+    if index.freq is not None:</span>
<span class="gi">+        attrs.append(f&quot;freq=&#39;{index.freq}&#39;&quot;)</span>
<span class="gi">+    return separator.join(attrs)</span>


<span class="w"> </span>class CFTimeIndex(pd.Index):
<span class="gu">@@ -181,19 +249,49 @@ class CFTimeIndex(pd.Index):</span>
<span class="w"> </span>        Coordinates:
<span class="w"> </span>          * time     (time) datetime64[ns] 8B 2001-01-01T01:00:00
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        start, end = _parsed_string_to_bounds(self.date_type, resolution, parsed)</span>
<span class="gi">+        lhs_mask = (self.asi8 &gt;= start.timestamp() * 1e6)</span>
<span class="gi">+        rhs_mask = (self.asi8 &lt;= end.timestamp() * 1e6)</span>
<span class="gi">+        return lhs_mask &amp; rhs_mask</span>

<span class="w"> </span>    def _get_string_slice(self, key):
<span class="w"> </span>        &quot;&quot;&quot;Adapted from pandas.tseries.index.DatetimeIndex._get_string_slice&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        parsed, resolution = parse_datetime_string(key, self.date_type)</span>
<span class="gi">+        return self._partial_date_slice(resolution, parsed)</span>

<span class="w"> </span>    def _get_nearest_indexer(self, target, limit, tolerance):
<span class="w"> </span>        &quot;&quot;&quot;Adapted from pandas.Index._get_nearest_indexer&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        target = np.asarray(target)</span>
<span class="gi">+        target = target.astype(&#39;int64&#39;)</span>
<span class="gi">+        indexer = self.asi8.searchsorted(target, side=&#39;left&#39;)</span>
<span class="gi">+</span>
<span class="gi">+        left_indexer = np.clip(indexer - 1, 0, len(self) - 1)</span>
<span class="gi">+        right_indexer = np.clip(indexer, 0, len(self) - 1)</span>
<span class="gi">+</span>
<span class="gi">+        left_distances = target - self.asi8[left_indexer]</span>
<span class="gi">+        right_distances = self.asi8[right_indexer] - target</span>
<span class="gi">+</span>
<span class="gi">+        indexer = np.where(left_distances &lt; right_distances, left_indexer, right_indexer)</span>
<span class="gi">+        distances = np.minimum(left_distances, right_distances)</span>
<span class="gi">+</span>
<span class="gi">+        if tolerance is not None:</span>
<span class="gi">+            tolerance = tolerance.total_seconds() * 1e6</span>
<span class="gi">+            indexer = np.where(distances &lt;= tolerance, indexer, -1)</span>
<span class="gi">+</span>
<span class="gi">+        if limit is not None:</span>
<span class="gi">+            outside_tolerance_mask = distances &gt; limit</span>
<span class="gi">+            indexer[outside_tolerance_mask] = -1</span>
<span class="gi">+</span>
<span class="gi">+        return indexer</span>

<span class="w"> </span>    def _filter_indexer_tolerance(self, target, indexer, tolerance):
<span class="w"> </span>        &quot;&quot;&quot;Adapted from pandas.Index._filter_indexer_tolerance&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if tolerance is not None:</span>
<span class="gi">+            tolerance = tolerance.total_seconds() * 1e6</span>
<span class="gi">+            target = target.astype(&#39;int64&#39;)</span>
<span class="gi">+            distance = np.abs(self.asi8[indexer] - target)</span>
<span class="gi">+            indexer = indexer[distance &lt;= tolerance]</span>
<span class="gi">+        return indexer</span>

<span class="w"> </span>    def get_loc(self, key):
<span class="w"> </span>        &quot;&quot;&quot;Adapted from pandas.tseries.index.DatetimeIndex.get_loc&quot;&quot;&quot;
<span class="gh">diff --git a/xarray/coding/frequencies.py b/xarray/coding/frequencies.py</span>
<span class="gh">index 1ea6ec74..3b213c0b 100644</span>
<span class="gd">--- a/xarray/coding/frequencies.py</span>
<span class="gi">+++ b/xarray/coding/frequencies.py</span>
<span class="gu">@@ -35,7 +35,16 @@ def infer_freq(index):</span>
<span class="w"> </span>    ValueError
<span class="w"> </span>        If there are fewer than three values or the index is not 1D.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(index, CFTimeIndex):</span>
<span class="gi">+        return _CFTimeFrequencyInferer(index).get_freq()</span>
<span class="gi">+    elif isinstance(index, (pd.DatetimeIndex, pd.TimedeltaIndex)):</span>
<span class="gi">+        return pd.infer_freq(index)</span>
<span class="gi">+    elif isinstance(index, (pd.Series, xr.DataArray)):</span>
<span class="gi">+        return pd.infer_freq(index.values)</span>
<span class="gi">+    elif _contains_datetime_like_objects(index):</span>
<span class="gi">+        return pd.infer_freq(index)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(&quot;Index must be datetime-like&quot;)</span>


<span class="w"> </span>class _CFTimeFrequencyInferer:
<span class="gu">@@ -60,37 +69,102 @@ class _CFTimeFrequencyInferer:</span>
<span class="w"> </span>        -------
<span class="w"> </span>        str or None
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if not self.is_monotonic:</span>
<span class="gi">+            return None</span>
<span class="gi">+</span>
<span class="gi">+        delta = self.deltas[0]</span>
<span class="gi">+        if _is_multiple(delta, _ONE_DAY):</span>
<span class="gi">+            return self._infer_daily_freq()</span>
<span class="gi">+        elif _is_multiple(delta, _ONE_HOUR):</span>
<span class="gi">+            return self._infer_hourly_freq()</span>
<span class="gi">+        elif _is_multiple(delta, _ONE_MINUTE):</span>
<span class="gi">+            return self._infer_minute_freq()</span>
<span class="gi">+        elif _is_multiple(delta, _ONE_SECOND):</span>
<span class="gi">+            return self._infer_second_freq()</span>
<span class="gi">+        elif _is_multiple(delta, _ONE_MILLI):</span>
<span class="gi">+            return self._infer_milli_freq()</span>
<span class="gi">+        elif _is_multiple(delta, _ONE_MICRO):</span>
<span class="gi">+            return self._infer_micro_freq()</span>
<span class="gi">+        else:</span>
<span class="gi">+            return None</span>
<span class="gi">+</span>
<span class="gi">+    def _infer_daily_freq(self):</span>
<span class="gi">+        days = self.deltas[0] // _ONE_DAY</span>
<span class="gi">+        if days == 7:</span>
<span class="gi">+            return &#39;W&#39;</span>
<span class="gi">+        elif days in [28, 29, 30, 31]:</span>
<span class="gi">+            return self._infer_monthly_freq()</span>
<span class="gi">+        else:</span>
<span class="gi">+            return _maybe_add_count(&#39;D&#39;, days)</span>
<span class="gi">+</span>
<span class="gi">+    def _infer_monthly_freq(self):</span>
<span class="gi">+        anchor = month_anchor_check(self.index)</span>
<span class="gi">+        if anchor:</span>
<span class="gi">+            return f&#39;M{anchor}&#39;</span>
<span class="gi">+        else:</span>
<span class="gi">+            months = self.month_deltas[0]</span>
<span class="gi">+            return _maybe_add_count(&#39;M&#39;, months)</span>
<span class="gi">+</span>
<span class="gi">+    def _infer_hourly_freq(self):</span>
<span class="gi">+        hours = self.deltas[0] // _ONE_HOUR</span>
<span class="gi">+        return _maybe_add_count(&#39;H&#39;, hours)</span>
<span class="gi">+</span>
<span class="gi">+    def _infer_minute_freq(self):</span>
<span class="gi">+        minutes = self.deltas[0] // _ONE_MINUTE</span>
<span class="gi">+        return _maybe_add_count(&#39;T&#39;, minutes)</span>
<span class="gi">+</span>
<span class="gi">+    def _infer_second_freq(self):</span>
<span class="gi">+        seconds = self.deltas[0] // _ONE_SECOND</span>
<span class="gi">+        return _maybe_add_count(&#39;S&#39;, seconds)</span>
<span class="gi">+</span>
<span class="gi">+    def _infer_milli_freq(self):</span>
<span class="gi">+        millis = self.deltas[0] // _ONE_MILLI</span>
<span class="gi">+        return _maybe_add_count(&#39;L&#39;, millis)</span>
<span class="gi">+</span>
<span class="gi">+    def _infer_micro_freq(self):</span>
<span class="gi">+        micros = self.deltas[0] // _ONE_MICRO</span>
<span class="gi">+        return _maybe_add_count(&#39;U&#39;, micros)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def deltas(self):
<span class="w"> </span>        &quot;&quot;&quot;Sorted unique timedeltas as microseconds.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self._deltas is None:</span>
<span class="gi">+            deltas = np.diff(self.values)</span>
<span class="gi">+            self._deltas = _unique_deltas(deltas)</span>
<span class="gi">+        return self._deltas</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def year_deltas(self):
<span class="w"> </span>        &quot;&quot;&quot;Sorted unique year deltas.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self._year_deltas is None:</span>
<span class="gi">+            years = np.array([d.year for d in self.index])</span>
<span class="gi">+            self._year_deltas = _unique_deltas(np.diff(years))</span>
<span class="gi">+        return self._year_deltas</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def month_deltas(self):
<span class="w"> </span>        &quot;&quot;&quot;Sorted unique month deltas.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self._month_deltas is None:</span>
<span class="gi">+            months = np.array([d.year * 12 + d.month for d in self.index])</span>
<span class="gi">+            self._month_deltas = _unique_deltas(np.diff(months))</span>
<span class="gi">+        return self._month_deltas</span>


<span class="w"> </span>def _unique_deltas(arr):
<span class="w"> </span>    &quot;&quot;&quot;Sorted unique deltas of numpy array&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return np.unique(arr)</span>


<span class="w"> </span>def _is_multiple(us, mult: int):
<span class="w"> </span>    &quot;&quot;&quot;Whether us is a multiple of mult&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return us % mult == 0</span>


<span class="w"> </span>def _maybe_add_count(base: str, count: float):
<span class="w"> </span>    &quot;&quot;&quot;If count is greater than 1, add it to the base offset string&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if count == 1:</span>
<span class="gi">+        return base</span>
<span class="gi">+    return f&quot;{count}{base}&quot;</span>


<span class="w"> </span>def month_anchor_check(dates):
<span class="gu">@@ -103,4 +177,9 @@ def month_anchor_check(dates):</span>
<span class="w"> </span>    Replicated pandas._libs.tslibs.resolution.month_position_check
<span class="w"> </span>    but without business offset handling.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if all(d.day == 1 for d in dates):</span>
<span class="gi">+        return &quot;cs&quot;</span>
<span class="gi">+    elif all(d.day == pd.Timestamp(d).days_in_month for d in dates):</span>
<span class="gi">+        return &quot;ce&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        return None</span>
<span class="gh">diff --git a/xarray/coding/strings.py b/xarray/coding/strings.py</span>
<span class="gh">index 8a99b2a2..1d3d497f 100644</span>
<span class="gd">--- a/xarray/coding/strings.py</span>
<span class="gi">+++ b/xarray/coding/strings.py</span>
<span class="gu">@@ -20,7 +20,15 @@ class EncodedStringCoder(VariableCoder):</span>

<span class="w"> </span>def ensure_fixed_length_bytes(var: Variable) -&gt;Variable:
<span class="w"> </span>    &quot;&quot;&quot;Ensure that a variable with vlen bytes is converted to fixed width.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if var.dtype.kind == &#39;O&#39;:</span>
<span class="gi">+        # Variable-length bytes, need to convert to fixed-width</span>
<span class="gi">+        max_length = max(len(x) for x in var.data.ravel() if x is not None)</span>
<span class="gi">+        new_values = np.zeros(var.shape + (max_length,), dtype=&#39;S1&#39;)</span>
<span class="gi">+        for i, x in np.ndenumerate(var.data):</span>
<span class="gi">+            if x is not None:</span>
<span class="gi">+                new_values[i][:len(x)] = list(x)</span>
<span class="gi">+        return Variable(var.dims + (&#39;string&#39;,), new_values)</span>
<span class="gi">+    return var</span>


<span class="w"> </span>class CharacterArrayCoder(VariableCoder):
<span class="gu">@@ -29,22 +37,60 @@ class CharacterArrayCoder(VariableCoder):</span>

<span class="w"> </span>def bytes_to_char(arr):
<span class="w"> </span>    &quot;&quot;&quot;Convert numpy/dask arrays from fixed width bytes to characters.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(arr, np.ndarray):</span>
<span class="gi">+        return _numpy_bytes_to_char(arr)</span>
<span class="gi">+    elif is_chunked_array(arr):</span>
<span class="gi">+        ChunkedArray = get_chunked_array_type(arr)</span>
<span class="gi">+        return ChunkedArray(arr.chunks, bytes_to_char, dtype=&#39;S1&#39;,</span>
<span class="gi">+                            meta=_numpy_bytes_to_char(arr._meta))</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(f&quot;Unsupported array type: {type(arr)}&quot;)</span>


<span class="w"> </span>def _numpy_bytes_to_char(arr):
<span class="w"> </span>    &quot;&quot;&quot;Like netCDF4.stringtochar, but faster and more flexible.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # Ensure the input is a numpy array</span>
<span class="gi">+    arr = np.asarray(arr)</span>
<span class="gi">+    </span>
<span class="gi">+    if arr.dtype.kind == &#39;S&#39;:</span>
<span class="gi">+        # Convert bytes to characters</span>
<span class="gi">+        return arr.view(&#39;S1&#39;).reshape(arr.shape + (-1,))</span>
<span class="gi">+    elif arr.dtype == object:</span>
<span class="gi">+        # Handle object arrays (e.g., arrays of Python strings)</span>
<span class="gi">+        max_len = max(len(s) for s in arr.flat)</span>
<span class="gi">+        char_arr = np.zeros(arr.shape + (max_len,), dtype=&#39;S1&#39;)</span>
<span class="gi">+        for i, s in np.ndenumerate(arr):</span>
<span class="gi">+            char_arr[i][:len(s)] = list(s.encode(&#39;ascii&#39;))</span>
<span class="gi">+        return char_arr</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(f&quot;Unsupported dtype: {arr.dtype}&quot;)</span>


<span class="w"> </span>def char_to_bytes(arr):
<span class="w"> </span>    &quot;&quot;&quot;Convert numpy/dask arrays from characters to fixed width bytes.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(arr, np.ndarray):</span>
<span class="gi">+        return _numpy_char_to_bytes(arr)</span>
<span class="gi">+    elif is_chunked_array(arr):</span>
<span class="gi">+        ChunkedArray = get_chunked_array_type(arr)</span>
<span class="gi">+        return ChunkedArray(arr.chunks, char_to_bytes, dtype=&#39;S&#39; + str(arr.shape[-1]),</span>
<span class="gi">+                            meta=_numpy_char_to_bytes(arr._meta))</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(f&quot;Unsupported array type: {type(arr)}&quot;)</span>


<span class="w"> </span>def _numpy_char_to_bytes(arr):
<span class="w"> </span>    &quot;&quot;&quot;Like netCDF4.chartostring, but faster and more flexible.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # Ensure the input is a numpy array</span>
<span class="gi">+    arr = np.asarray(arr)</span>
<span class="gi">+    </span>
<span class="gi">+    if arr.dtype.kind == &#39;S&#39; and arr.dtype.itemsize == 1:</span>
<span class="gi">+        # Convert characters to bytes</span>
<span class="gi">+        return arr.view(&#39;S&#39; + str(arr.shape[-1])).squeeze(axis=-1)</span>
<span class="gi">+    elif arr.dtype.kind in (&#39;U&#39;, &#39;O&#39;):</span>
<span class="gi">+        # Handle Unicode strings or object arrays</span>
<span class="gi">+        return np.char.encode(arr.astype(&#39;U&#39;), encoding=&#39;ascii&#39;)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(f&quot;Unsupported dtype: {arr.dtype}&quot;)</span>


<span class="w"> </span>class StackedBytesArray(indexing.ExplicitlyIndexedNDArrayMixin):
<span class="gh">diff --git a/xarray/coding/times.py b/xarray/coding/times.py</span>
<span class="gh">index 956c93ca..d7dc93c4 100644</span>
<span class="gd">--- a/xarray/coding/times.py</span>
<span class="gi">+++ b/xarray/coding/times.py</span>
<span class="gu">@@ -55,19 +55,63 @@ def decode_cf_datetime(num_dates, units: str, calendar: (str | None)=None,</span>
<span class="w"> </span>    --------
<span class="w"> </span>    cftime.num2date
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    num_dates = np.asarray(num_dates)</span>
<span class="gi">+    units = units.strip()</span>
<span class="gi">+</span>
<span class="gi">+    if calendar is None:</span>
<span class="gi">+        calendar = &#39;standard&#39;</span>
<span class="gi">+</span>
<span class="gi">+    if calendar.lower() in _STANDARD_CALENDARS and use_cftime is not True:</span>
<span class="gi">+        return decode_cf_datetime_numpy(num_dates, units)</span>
<span class="gi">+    else:</span>
<span class="gi">+        if cftime is None:</span>
<span class="gi">+            raise ImportError(&quot;cftime is required for non-standard calendars.&quot;)</span>
<span class="gi">+        return cftime.num2date(num_dates, units, calendar, only_use_cftime_datetimes=True)</span>
<span class="gi">+</span>
<span class="gi">+def decode_cf_datetime_numpy(num_dates, units):</span>
<span class="gi">+    &quot;&quot;&quot;Helper function to decode CF datetimes using numpy for standard calendars.&quot;&quot;&quot;</span>
<span class="gi">+    units_split = units.split(&#39; since &#39;)</span>
<span class="gi">+    if len(units_split) != 2:</span>
<span class="gi">+        raise ValueError(f&quot;Invalid units string: {units}&quot;)</span>
<span class="gi">+    </span>
<span class="gi">+    unit, reference_date_string = units_split</span>
<span class="gi">+    reference_date = pd.Timestamp(reference_date_string)</span>
<span class="gi">+    </span>
<span class="gi">+    if unit not in _NS_PER_TIME_DELTA:</span>
<span class="gi">+        raise ValueError(f&quot;Unsupported time unit: {unit}&quot;)</span>
<span class="gi">+    </span>
<span class="gi">+    time_delta = np.timedelta64(num_dates.astype(&#39;timedelta64[ns]&#39;) * _NS_PER_TIME_DELTA[unit])</span>
<span class="gi">+    return reference_date + time_delta</span>


<span class="w"> </span>def decode_cf_timedelta(num_timedeltas, units: str) -&gt;np.ndarray:
<span class="w"> </span>    &quot;&quot;&quot;Given an array of numeric timedeltas in netCDF format, convert it into a
<span class="w"> </span>    numpy timedelta64[ns] array.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    num_timedeltas = np.asarray(num_timedeltas)</span>
<span class="gi">+    units = units.strip()</span>
<span class="gi">+</span>
<span class="gi">+    if units not in _NS_PER_TIME_DELTA:</span>
<span class="gi">+        raise ValueError(f&quot;Unsupported time unit for timedelta: {units}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    return (num_timedeltas * _NS_PER_TIME_DELTA[units]).astype(&#39;timedelta64[ns]&#39;)</span>


<span class="w"> </span>def infer_calendar_name(dates) -&gt;CFCalendar:
<span class="w"> </span>    &quot;&quot;&quot;Given an array of datetimes, infer the CF calendar name&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(dates, np.ndarray) and np.issubdtype(dates.dtype, np.datetime64):</span>
<span class="gi">+        return &#39;proleptic_gregorian&#39;</span>
<span class="gi">+    elif cftime and isinstance(dates[0], cftime.datetime):</span>
<span class="gi">+        return dates[0].calendar</span>
<span class="gi">+    else:</span>
<span class="gi">+        try:</span>
<span class="gi">+            import pandas as pd</span>
<span class="gi">+            if isinstance(dates, pd.DatetimeIndex):</span>
<span class="gi">+                return &#39;proleptic_gregorian&#39;</span>
<span class="gi">+        except ImportError:</span>
<span class="gi">+            pass</span>
<span class="gi">+    </span>
<span class="gi">+    raise ValueError(&quot;Unable to infer calendar name from input dates.&quot;)</span>


<span class="w"> </span>def infer_datetime_units(dates) -&gt;str:
<span class="gu">@@ -76,7 +120,18 @@ def infer_datetime_units(dates) -&gt;str:</span>
<span class="w"> </span>    &#39;hours&#39;, &#39;minutes&#39; or &#39;seconds&#39; (the first one that can evenly divide all
<span class="w"> </span>    unique time deltas in `dates`)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    dates = np.asarray(dates)</span>
<span class="gi">+    if len(dates) &lt; 2:</span>
<span class="gi">+        return &quot;seconds since &quot; + format_timestamp(dates[0])</span>
<span class="gi">+</span>
<span class="gi">+    deltas = np.diff(dates)</span>
<span class="gi">+    unique_deltas = np.unique(deltas)</span>
<span class="gi">+</span>
<span class="gi">+    for unit in [&#39;days&#39;, &#39;hours&#39;, &#39;minutes&#39;, &#39;seconds&#39;]:</span>
<span class="gi">+        if np.all(unique_deltas % np.timedelta64(1, unit[0].upper()) == np.timedelta64(0, &#39;ns&#39;)):</span>
<span class="gi">+            return f&quot;{unit} since {format_timestamp(dates[0])}&quot;</span>
<span class="gi">+</span>
<span class="gi">+    return f&quot;seconds since {format_timestamp(dates[0])}&quot;</span>


<span class="w"> </span>def format_cftime_datetime(date) -&gt;str:
<span class="gh">diff --git a/xarray/coding/variables.py b/xarray/coding/variables.py</span>
<span class="gh">index efe7890c..7d47ccf0 100644</span>
<span class="gd">--- a/xarray/coding/variables.py</span>
<span class="gi">+++ b/xarray/coding/variables.py</span>
<span class="gu">@@ -138,7 +138,11 @@ def lazy_elemwise_func(array, func: Callable, dtype: np.typing.DTypeLike):</span>
<span class="w"> </span>    -------
<span class="w"> </span>    Either a dask.array.Array or _ElementwiseFunctionArray.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    chunked_array_type = get_chunked_array_type(array)</span>
<span class="gi">+    if chunked_array_type is not None:</span>
<span class="gi">+        return chunked_array_type.map_overlap(array, func, dtype=dtype)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return _ElementwiseFunctionArray(array, func, dtype)</span>


<span class="w"> </span>def pop_to(source: MutableMapping, dest: MutableMapping, key: Hashable,
<span class="gu">@@ -148,23 +152,52 @@ def pop_to(source: MutableMapping, dest: MutableMapping, key: Hashable,</span>
<span class="w"> </span>    None values are not passed on.  If k already exists in dest an
<span class="w"> </span>    error is raised.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    value = source.pop(key, None)</span>
<span class="gi">+    if value is not None:</span>
<span class="gi">+        if key in dest:</span>
<span class="gi">+            raise ValueError(f&quot;&#39;{key}&#39; already exists in dest&quot;)</span>
<span class="gi">+        dest[key] = value</span>
<span class="gi">+    return value</span>


<span class="w"> </span>def _apply_mask(data: np.ndarray, encoded_fill_values: list,
<span class="w"> </span>    decoded_fill_value: Any, dtype: np.typing.DTypeLike) -&gt;np.ndarray:
<span class="w"> </span>    &quot;&quot;&quot;Mask all matching values in a NumPy arrays.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if encoded_fill_values:</span>
<span class="gi">+        cond = False</span>
<span class="gi">+        for fv in encoded_fill_values:</span>
<span class="gi">+            cond |= data == fv</span>
<span class="gi">+        data = np.where(cond, decoded_fill_value, data)</span>
<span class="gi">+    </span>
<span class="gi">+    return data.astype(dtype)</span>


<span class="w"> </span>def _check_fill_values(attrs, name, dtype):
<span class="gd">-    &quot;&quot;&quot; &quot;Check _FillValue and missing_value if available.</span>
<span class="gi">+    &quot;&quot;&quot;Check _FillValue and missing_value if available.</span>

<span class="w"> </span>    Return dictionary with raw fill values and set with encoded fill values.

<span class="w"> </span>    Issue SerializationWarning if appropriate.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    fill_values = {}</span>
<span class="gi">+    encoded_fill_values = set()</span>
<span class="gi">+</span>
<span class="gi">+    for attr in [&#39;_FillValue&#39;, &#39;missing_value&#39;]:</span>
<span class="gi">+        value = attrs.get(attr)</span>
<span class="gi">+        if value is not None:</span>
<span class="gi">+            fill_values[attr] = value</span>
<span class="gi">+            encoded_fill_values.add(duck_array_ops.asarray(value).item())</span>
<span class="gi">+</span>
<span class="gi">+    if len(fill_values) &gt; 1:</span>
<span class="gi">+        if fill_values[&#39;_FillValue&#39;] != fill_values[&#39;missing_value&#39;]:</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                f&quot;Variable &#39;{name}&#39; has multiple fill values {fill_values}, &quot;</span>
<span class="gi">+                &quot;decoding all values to NaN.&quot;,</span>
<span class="gi">+                SerializationWarning,</span>
<span class="gi">+                stacklevel=3,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    return fill_values, encoded_fill_values</span>


<span class="w"> </span>class CFMaskCoder(VariableCoder):
<span class="gu">@@ -174,7 +207,15 @@ class CFMaskCoder(VariableCoder):</span>
<span class="w"> </span>def _choose_float_dtype(dtype: np.dtype, mapping: MutableMapping) -&gt;type[np
<span class="w"> </span>    .floating[Any]]:
<span class="w"> </span>    &quot;&quot;&quot;Return a float dtype that can losslessly represent `dtype` values.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if np.issubdtype(dtype, np.floating):</span>
<span class="gi">+        return dtype.type</span>
<span class="gi">+    elif np.issubdtype(dtype, np.integer):</span>
<span class="gi">+        if dtype.itemsize &lt;= 2:</span>
<span class="gi">+            return np.float32</span>
<span class="gi">+        else:</span>
<span class="gi">+            return np.float64</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(f&quot;Unsupported dtype: {dtype}&quot;)</span>


<span class="w"> </span>class CFScaleOffsetCoder(VariableCoder):
<span class="gh">diff --git a/xarray/conventions.py b/xarray/conventions.py</span>
<span class="gh">index de83ae8f..0e5e5b13 100644</span>
<span class="gd">--- a/xarray/conventions.py</span>
<span class="gi">+++ b/xarray/conventions.py</span>
<span class="gu">@@ -28,7 +28,19 @@ if TYPE_CHECKING:</span>

<span class="w"> </span>def _infer_dtype(array, name=None):
<span class="w"> </span>    &quot;&quot;&quot;Given an object array with no missing values, infer its dtype from all elements.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if len(array) == 0:</span>
<span class="gi">+        return np.dtype(object)</span>
<span class="gi">+    </span>
<span class="gi">+    sample = array[0]</span>
<span class="gi">+    if isinstance(sample, (np.ndarray, list)):</span>
<span class="gi">+        first_dtype = np.array(sample).dtype</span>
<span class="gi">+        if all(np.array(item).dtype == first_dtype for item in array):</span>
<span class="gi">+            return np.dtype(object)</span>
<span class="gi">+    </span>
<span class="gi">+    try:</span>
<span class="gi">+        return np.array(array).dtype</span>
<span class="gi">+    except (ValueError, TypeError):</span>
<span class="gi">+        return np.dtype(object)</span>


<span class="w"> </span>def _copy_with_dtype(data, dtype: np.typing.DTypeLike):
<span class="gu">@@ -37,7 +49,10 @@ def _copy_with_dtype(data, dtype: np.typing.DTypeLike):</span>
<span class="w"> </span>    We use this instead of np.array() to ensure that custom object dtypes end
<span class="w"> </span>    up on the resulting array.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    result = np.array(data, dtype=dtype, copy=True)</span>
<span class="gi">+    if dtype == object:</span>
<span class="gi">+        result[:] = data</span>
<span class="gi">+    return result</span>


<span class="w"> </span>def encode_cf_variable(var: Variable, needs_copy: bool=True, name: T_Name=None
<span class="gu">@@ -61,7 +76,38 @@ def encode_cf_variable(var: Variable, needs_copy: bool=True, name: T_Name=None</span>
<span class="w"> </span>    out : Variable
<span class="w"> </span>        A variable which has been encoded as described above.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    original_dtype = var.dtype</span>
<span class="gi">+    encoded_dtype = var.encoding.get(&#39;dtype&#39;, original_dtype)</span>
<span class="gi">+    </span>
<span class="gi">+    if needs_copy:</span>
<span class="gi">+        var = var.copy(deep=True)</span>
<span class="gi">+    </span>
<span class="gi">+    if np.issubdtype(original_dtype, np.datetime64):</span>
<span class="gi">+        var = times.encode_cf_datetime(var)</span>
<span class="gi">+    elif np.issubdtype(original_dtype, np.timedelta64):</span>
<span class="gi">+        var = times.encode_cf_timedelta(var)</span>
<span class="gi">+    </span>
<span class="gi">+    if var.dtype != encoded_dtype:</span>
<span class="gi">+        var = var.astype(encoded_dtype)</span>
<span class="gi">+    </span>
<span class="gi">+    # Apply scale_factor and add_offset</span>
<span class="gi">+    scale_factor = var.encoding.get(&#39;scale_factor&#39;)</span>
<span class="gi">+    add_offset = var.encoding.get(&#39;add_offset&#39;)</span>
<span class="gi">+    if scale_factor is not None or add_offset is not None:</span>
<span class="gi">+        data = var.values</span>
<span class="gi">+        if scale_factor is not None:</span>
<span class="gi">+            data = data / scale_factor</span>
<span class="gi">+        if add_offset is not None:</span>
<span class="gi">+            data = data - add_offset</span>
<span class="gi">+        var = Variable(var.dims, data, var.attrs, var.encoding)</span>
<span class="gi">+    </span>
<span class="gi">+    # Handle _FillValue and missing_value</span>
<span class="gi">+    fill_value = var.encoding.get(&#39;_FillValue&#39;, var.attrs.get(&#39;_FillValue&#39;))</span>
<span class="gi">+    if fill_value is not None:</span>
<span class="gi">+        var.encoding[&#39;_FillValue&#39;] = fill_value</span>
<span class="gi">+        var.values[np.isnan(var.values)] = fill_value</span>
<span class="gi">+    </span>
<span class="gi">+    return var</span>


<span class="w"> </span>def decode_cf_variable(name: Hashable, var: Variable, concat_characters:
<span class="gu">@@ -113,7 +159,42 @@ def decode_cf_variable(name: Hashable, var: Variable, concat_characters:</span>
<span class="w"> </span>    out : Variable
<span class="w"> </span>        A variable holding the decoded equivalent of var.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # Handle endianness</span>
<span class="gi">+    if decode_endianness and var.dtype.byteorder not in (&#39;=&#39;, &#39;|&#39;):</span>
<span class="gi">+        var = Variable(var.dims, var.values.byteswap().newbyteorder(), var.attrs, var.encoding)</span>
<span class="gi">+</span>
<span class="gi">+    # Handle masking and scaling</span>
<span class="gi">+    if mask_and_scale:</span>
<span class="gi">+        scale_factor = var.attrs.get(&#39;scale_factor&#39;) or var.encoding.get(&#39;scale_factor&#39;)</span>
<span class="gi">+        add_offset = var.attrs.get(&#39;add_offset&#39;) or var.encoding.get(&#39;add_offset&#39;)</span>
<span class="gi">+        fill_value = var.attrs.get(&#39;_FillValue&#39;) or var.encoding.get(&#39;_FillValue&#39;)</span>
<span class="gi">+</span>
<span class="gi">+        if scale_factor is not None or add_offset is not None:</span>
<span class="gi">+            data = var.values</span>
<span class="gi">+            if scale_factor is not None:</span>
<span class="gi">+                data = data * scale_factor</span>
<span class="gi">+            if add_offset is not None:</span>
<span class="gi">+                data = data + add_offset</span>
<span class="gi">+            var = Variable(var.dims, data, var.attrs, var.encoding)</span>
<span class="gi">+</span>
<span class="gi">+        if fill_value is not None:</span>
<span class="gi">+            var = Variable(var.dims, np.ma.masked_equal(var.values, fill_value), var.attrs, var.encoding)</span>
<span class="gi">+</span>
<span class="gi">+    # Handle time decoding</span>
<span class="gi">+    if decode_times:</span>
<span class="gi">+        if &#39;units&#39; in var.attrs and &#39;since&#39; in var.attrs[&#39;units&#39;]:</span>
<span class="gi">+            var = times.decode_cf_datetime(var, use_cftime=use_cftime)</span>
<span class="gi">+        elif decode_timedelta is not None and &#39;units&#39; in var.attrs:</span>
<span class="gi">+            var = times.decode_cf_timedelta(var)</span>
<span class="gi">+</span>
<span class="gi">+    # Handle character concatenation</span>
<span class="gi">+    if concat_characters and var.dtype.kind == &#39;S&#39;:</span>
<span class="gi">+        if stack_char_dim:</span>
<span class="gi">+            var = strings.CharacterArrayCoder().decode(var)</span>
<span class="gi">+        else:</span>
<span class="gi">+            var = strings.EncodedStringCoder().decode(var)</span>
<span class="gi">+</span>
<span class="gi">+    return var</span>


<span class="w"> </span>def _update_bounds_attributes(variables: T_Variables) -&gt;None:
<span class="gh">diff --git a/xarray/convert.py b/xarray/convert.py</span>
<span class="gh">index d29fc8f6..13bcddf4 100644</span>
<span class="gd">--- a/xarray/convert.py</span>
<span class="gi">+++ b/xarray/convert.py</span>
<span class="gu">@@ -19,32 +19,69 @@ cell_methods_strings = {&#39;point&#39;, &#39;sum&#39;, &#39;maximum&#39;, &#39;median&#39;, &#39;mid_range&#39;,</span>

<span class="w"> </span>def _filter_attrs(attrs, ignored_attrs):
<span class="w"> </span>    &quot;&quot;&quot;Return attrs that are not in ignored_attrs&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return {k: v for k, v in attrs.items() if k not in ignored_attrs}</span>


<span class="w"> </span>def _pick_attrs(attrs, keys):
<span class="w"> </span>    &quot;&quot;&quot;Return attrs with keys in keys list&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return {k: attrs[k] for k in keys if k in attrs}</span>


<span class="w"> </span>def _get_iris_args(attrs):
<span class="w"> </span>    &quot;&quot;&quot;Converts the xarray attrs into args that can be passed into Iris&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    iris_args = {}</span>
<span class="gi">+    for key in [&#39;standard_name&#39;, &#39;long_name&#39;, &#39;units&#39;, &#39;bounds&#39;]:</span>
<span class="gi">+        if key in attrs:</span>
<span class="gi">+            iris_args[key] = attrs[key]</span>
<span class="gi">+    return iris_args</span>


<span class="w"> </span>def to_iris(dataarray):
<span class="w"> </span>    &quot;&quot;&quot;Convert a DataArray into a Iris Cube&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import iris</span>
<span class="gi">+    </span>
<span class="gi">+    # Create the cube</span>
<span class="gi">+    cube = iris.cube.Cube(dataarray.values)</span>
<span class="gi">+    </span>
<span class="gi">+    # Set the dimensions</span>
<span class="gi">+    for dim, coord in dataarray.coords.items():</span>
<span class="gi">+        if dim in dataarray.dims:</span>
<span class="gi">+            iris_coord = iris.coords.DimCoord(coord.values, **_get_iris_args(coord.attrs))</span>
<span class="gi">+            cube.add_dim_coord(iris_coord, dataarray.get_axis_num(dim))</span>
<span class="gi">+        else:</span>
<span class="gi">+            iris_coord = iris.coords.AuxCoord(coord.values, **_get_iris_args(coord.attrs))</span>
<span class="gi">+            cube.add_aux_coord(iris_coord)</span>
<span class="gi">+    </span>
<span class="gi">+    # Set the attributes</span>
<span class="gi">+    filtered_attrs = _filter_attrs(dataarray.attrs, iris_forbidden_keys)</span>
<span class="gi">+    cube.attributes.update(filtered_attrs)</span>
<span class="gi">+    </span>
<span class="gi">+    # Set the name</span>
<span class="gi">+    cube.var_name = dataarray.name</span>
<span class="gi">+    </span>
<span class="gi">+    return cube</span>


<span class="w"> </span>def _iris_obj_to_attrs(obj):
<span class="w"> </span>    &quot;&quot;&quot;Return a dictionary of attrs when given a Iris object&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    attrs = {}</span>
<span class="gi">+    for key in [&#39;standard_name&#39;, &#39;long_name&#39;, &#39;units&#39;, &#39;bounds&#39;]:</span>
<span class="gi">+        value = getattr(obj, key, None)</span>
<span class="gi">+        if value is not None:</span>
<span class="gi">+            attrs[key] = value</span>
<span class="gi">+    attrs.update(obj.attributes)</span>
<span class="gi">+    return attrs</span>


<span class="w"> </span>def _iris_cell_methods_to_str(cell_methods_obj):
<span class="w"> </span>    &quot;&quot;&quot;Converts a Iris cell methods into a string&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    cell_methods = []</span>
<span class="gi">+    for cm in cell_methods_obj:</span>
<span class="gi">+        method = f&quot;{cm.coord_names[0]}: {cm.method}&quot;</span>
<span class="gi">+        if cm.intervals:</span>
<span class="gi">+            method += f&quot; (interval: {cm.intervals[0]})&quot;</span>
<span class="gi">+        cell_methods.append(method)</span>
<span class="gi">+    return &quot; &quot;.join(cell_methods)</span>


<span class="w"> </span>def _name(iris_obj, default=&#39;unknown&#39;):
<span class="gu">@@ -53,9 +90,38 @@ def _name(iris_obj, default=&#39;unknown&#39;):</span>
<span class="w"> </span>    Similar to iris_obj.name() method, but using iris_obj.var_name first to
<span class="w"> </span>    enable roundtripping.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return (</span>
<span class="gi">+        iris_obj.var_name</span>
<span class="gi">+        or iris_obj.standard_name</span>
<span class="gi">+        or iris_obj.long_name</span>
<span class="gi">+        or default</span>
<span class="gi">+    )</span>


<span class="w"> </span>def from_iris(cube):
<span class="w"> </span>    &quot;&quot;&quot;Convert a Iris cube into an DataArray&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import iris</span>
<span class="gi">+    </span>
<span class="gi">+    # Create coordinates</span>
<span class="gi">+    coords = {}</span>
<span class="gi">+    for coord in cube.coords():</span>
<span class="gi">+        coord_attrs = _iris_obj_to_attrs(coord)</span>
<span class="gi">+        if isinstance(coord, iris.coords.DimCoord):</span>
<span class="gi">+            coords[coord.name()] = (coord.name(), coord.points, coord_attrs)</span>
<span class="gi">+        else:</span>
<span class="gi">+            coords[coord.name()] = ([], coord.points, coord_attrs)</span>
<span class="gi">+    </span>
<span class="gi">+    # Create attributes</span>
<span class="gi">+    attrs = _iris_obj_to_attrs(cube)</span>
<span class="gi">+    if cube.cell_methods:</span>
<span class="gi">+        attrs[&#39;cell_methods&#39;] = _iris_cell_methods_to_str(cube.cell_methods)</span>
<span class="gi">+    </span>
<span class="gi">+    # Create DataArray</span>
<span class="gi">+    da = DataArray(</span>
<span class="gi">+        data=cube.data,</span>
<span class="gi">+        coords=coords,</span>
<span class="gi">+        attrs=attrs,</span>
<span class="gi">+        name=_name(cube)</span>
<span class="gi">+    )</span>
<span class="gi">+    </span>
<span class="gi">+    return da</span>
<span class="gh">diff --git a/xarray/core/accessor_dt.py b/xarray/core/accessor_dt.py</span>
<span class="gh">index 87474ec9..fec61818 100644</span>
<span class="gd">--- a/xarray/core/accessor_dt.py</span>
<span class="gi">+++ b/xarray/core/accessor_dt.py</span>
<span class="gu">@@ -18,21 +18,26 @@ if TYPE_CHECKING:</span>

<span class="w"> </span>def _season_from_months(months):
<span class="w"> </span>    &quot;&quot;&quot;Compute season (DJF, MAM, JJA, SON) from month ordinal&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    seasons = {1: &#39;DJF&#39;, 2: &#39;DJF&#39;, 3: &#39;MAM&#39;, 4: &#39;MAM&#39;, 5: &#39;MAM&#39;, 6: &#39;JJA&#39;,</span>
<span class="gi">+               7: &#39;JJA&#39;, 8: &#39;JJA&#39;, 9: &#39;SON&#39;, 10: &#39;SON&#39;, 11: &#39;SON&#39;, 12: &#39;DJF&#39;}</span>
<span class="gi">+    return np.vectorize(seasons.get)(months)</span>


<span class="w"> </span>def _access_through_cftimeindex(values, name):
<span class="w"> </span>    &quot;&quot;&quot;Coerce an array of datetime-like values to a CFTimeIndex
<span class="w"> </span>    and access requested datetime component
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from xarray.core.indexes import CFTimeIndex</span>
<span class="gi">+    index = CFTimeIndex(values)</span>
<span class="gi">+    return getattr(index, name)</span>


<span class="w"> </span>def _access_through_series(values, name):
<span class="w"> </span>    &quot;&quot;&quot;Coerce an array of datetime-like values to a pandas Series and
<span class="w"> </span>    access requested datetime component
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    series = pd.Series(values)</span>
<span class="gi">+    return getattr(series.dt, name)</span>


<span class="w"> </span>def _get_date_field(values, name, dtype):
<span class="gu">@@ -54,14 +59,23 @@ def _get_date_field(values, name, dtype):</span>
<span class="w"> </span>        Array-like of datetime fields accessed for each element in values

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if is_duck_dask_array(values):</span>
<span class="gi">+        import dask.array as da</span>
<span class="gi">+        return da.map_overlap(_access_through_series, values, name=name, dtype=dtype)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return _access_through_series(values, name).astype(dtype)</span>


<span class="w"> </span>def _round_through_series_or_index(values, name, freq):
<span class="w"> </span>    &quot;&quot;&quot;Coerce an array of datetime-like values to a pandas Series or xarray
<span class="w"> </span>    CFTimeIndex and apply requested rounding
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from xarray.core.indexes import CFTimeIndex</span>
<span class="gi">+    if isinstance(values, CFTimeIndex):</span>
<span class="gi">+        index = values</span>
<span class="gi">+    else:</span>
<span class="gi">+        index = pd.Series(values)</span>
<span class="gi">+    return getattr(index, name)(freq)</span>


<span class="w"> </span>def _round_field(values, name, freq):
<span class="gu">@@ -83,21 +97,28 @@ def _round_field(values, name, freq):</span>
<span class="w"> </span>        Array-like of datetime fields accessed for each element in values

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if is_duck_dask_array(values):</span>
<span class="gi">+        import dask.array as da</span>
<span class="gi">+        return da.map_overlap(_round_through_series_or_index, values, name=name, freq=freq)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return _round_through_series_or_index(values, name, freq)</span>


<span class="w"> </span>def _strftime_through_cftimeindex(values, date_format: str):
<span class="w"> </span>    &quot;&quot;&quot;Coerce an array of cftime-like values to a CFTimeIndex
<span class="w"> </span>    and access requested datetime component
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from xarray.core.indexes import CFTimeIndex</span>
<span class="gi">+    index = CFTimeIndex(values)</span>
<span class="gi">+    return index.strftime(date_format)</span>


<span class="w"> </span>def _strftime_through_series(values, date_format: str):
<span class="w"> </span>    &quot;&quot;&quot;Coerce an array of datetime-like values to a pandas Series and
<span class="w"> </span>    apply string formatting
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    series = pd.Series(values)</span>
<span class="gi">+    return series.dt.strftime(date_format)</span>


<span class="w"> </span>class TimeAccessor(Generic[T_DataArray]):
<span class="gu">@@ -120,7 +141,7 @@ class TimeAccessor(Generic[T_DataArray]):</span>
<span class="w"> </span>        floor-ed timestamps : same type as values
<span class="w"> </span>            Array-like of datetime fields accessed for each element in values
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_round_field(self._obj.data, &quot;floor&quot;, freq))</span>

<span class="w"> </span>    def ceil(self, freq: str) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -136,7 +157,7 @@ class TimeAccessor(Generic[T_DataArray]):</span>
<span class="w"> </span>        ceil-ed timestamps : same type as values
<span class="w"> </span>            Array-like of datetime fields accessed for each element in values
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_round_field(self._obj.data, &quot;ceil&quot;, freq))</span>

<span class="w"> </span>    def round(self, freq: str) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -152,7 +173,7 @@ class TimeAccessor(Generic[T_DataArray]):</span>
<span class="w"> </span>        rounded timestamps : same type as values
<span class="w"> </span>            Array-like of datetime fields accessed for each element in values
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_round_field(self._obj.data, &quot;round&quot;, freq))</span>


<span class="w"> </span>class DatetimeAccessor(TimeAccessor[T_DataArray]):
<span class="gu">@@ -215,7 +236,11 @@ class DatetimeAccessor(TimeAccessor[T_DataArray]):</span>
<span class="w"> </span>        &lt;xarray.DataArray &#39;strftime&#39; ()&gt; Size: 8B
<span class="w"> </span>        array(&#39;January 01, 2000, 12:00:00 AM&#39;, dtype=object)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        values = self._obj.data</span>
<span class="gi">+        if is_np_datetime_like(self._obj.dtype):</span>
<span class="gi">+            return self._obj.copy(data=_strftime_through_series(values, date_format))</span>
<span class="gi">+        else:</span>
<span class="gi">+            return self._obj.copy(data=_strftime_through_cftimeindex(values, date_format))</span>

<span class="w"> </span>    def isocalendar(self) -&gt;Dataset:
<span class="w"> </span>        &quot;&quot;&quot;Dataset containing ISO year, week number, and weekday.
<span class="gu">@@ -224,125 +249,131 @@ class DatetimeAccessor(TimeAccessor[T_DataArray]):</span>
<span class="w"> </span>        -----
<span class="w"> </span>        The iso year and weekday differ from the nominal year and weekday.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from xarray import Dataset</span>
<span class="gi">+        iso_calendar = _access_through_series(self._obj.data, &#39;isocalendar&#39;)</span>
<span class="gi">+        return Dataset({</span>
<span class="gi">+            &#39;year&#39;: (&#39;time&#39;, iso_calendar.year),</span>
<span class="gi">+            &#39;week&#39;: (&#39;time&#39;, iso_calendar.week),</span>
<span class="gi">+            &#39;weekday&#39;: (&#39;time&#39;, iso_calendar.day),</span>
<span class="gi">+        }, coords={&#39;time&#39;: self._obj.coords[&#39;time&#39;]})</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def year(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;The year of the datetime&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;year&#39;, &#39;int64&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def month(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;The month as January=1, December=12&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;month&#39;, &#39;int64&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def day(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;The days of the datetime&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;day&#39;, &#39;int64&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def hour(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;The hours of the datetime&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;hour&#39;, &#39;int64&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def minute(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;The minutes of the datetime&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;minute&#39;, &#39;int64&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def second(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;The seconds of the datetime&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;second&#39;, &#39;int64&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def microsecond(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;The microseconds of the datetime&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;microsecond&#39;, &#39;int64&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def nanosecond(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;The nanoseconds of the datetime&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;nanosecond&#39;, &#39;int64&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def weekofyear(self) -&gt;DataArray:
<span class="w"> </span>        &quot;&quot;&quot;The week ordinal of the year&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;weekofyear&#39;, &#39;int64&#39;))</span>
<span class="w"> </span>    week = weekofyear

<span class="w"> </span>    @property
<span class="w"> </span>    def dayofweek(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;The day of the week with Monday=0, Sunday=6&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;dayofweek&#39;, &#39;int64&#39;))</span>
<span class="w"> </span>    weekday = dayofweek

<span class="w"> </span>    @property
<span class="w"> </span>    def dayofyear(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;The ordinal day of the year&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;dayofyear&#39;, &#39;int64&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def quarter(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;The quarter of the date&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;quarter&#39;, &#39;int64&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def days_in_month(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;The number of days in the month&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;days_in_month&#39;, &#39;int64&#39;))</span>
<span class="w"> </span>    daysinmonth = days_in_month

<span class="w"> </span>    @property
<span class="w"> </span>    def season(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Season of the year&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_season_from_months(_get_date_field(self._obj.data, &#39;month&#39;, &#39;int64&#39;)))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def time(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Timestamps corresponding to datetimes&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_access_through_series(self._obj.data, &#39;time&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def date(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Date corresponding to datetimes&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_access_through_series(self._obj.data, &#39;date&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def is_month_start(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Indicate whether the date is the first day of the month&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;is_month_start&#39;, &#39;bool&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def is_month_end(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Indicate whether the date is the last day of the month&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;is_month_end&#39;, &#39;bool&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def is_quarter_start(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Indicate whether the date is the first day of a quarter&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;is_quarter_start&#39;, &#39;bool&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def is_quarter_end(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Indicate whether the date is the last day of a quarter&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;is_quarter_end&#39;, &#39;bool&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def is_year_start(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Indicate whether the date is the first day of a year&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;is_year_start&#39;, &#39;bool&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def is_year_end(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Indicate whether the date is the last day of the year&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;is_year_end&#39;, &#39;bool&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def is_leap_year(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Indicate if the date belongs to a leap year&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;is_leap_year&#39;, &#39;bool&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def calendar(self) -&gt;CFCalendar:
<span class="gu">@@ -351,7 +382,10 @@ class DatetimeAccessor(TimeAccessor[T_DataArray]):</span>
<span class="w"> </span>        Only relevant for arrays of :py:class:`cftime.datetime` objects,
<span class="w"> </span>        returns &quot;proleptic_gregorian&quot; for arrays of :py:class:`numpy.datetime64` values.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if is_np_datetime_like(self._obj.dtype):</span>
<span class="gi">+            return &quot;proleptic_gregorian&quot;</span>
<span class="gi">+        else:</span>
<span class="gi">+            return infer_calendar_name(self._obj.data)</span>


<span class="w"> </span>class TimedeltaAccessor(TimeAccessor[T_DataArray]):
<span class="gu">@@ -404,26 +438,26 @@ class TimedeltaAccessor(TimeAccessor[T_DataArray]):</span>
<span class="w"> </span>    @property
<span class="w"> </span>    def days(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Number of days for each element&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;days&#39;, &#39;int64&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def seconds(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Number of seconds (&gt;= 0 and less than 1 day) for each element&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;seconds&#39;, &#39;int64&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def microseconds(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Number of microseconds (&gt;= 0 and less than 1 second) for each element&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;microseconds&#39;, &#39;int64&#39;))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def nanoseconds(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Number of nanoseconds (&gt;= 0 and less than 1 microsecond) for each element&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_get_date_field(self._obj.data, &#39;nanoseconds&#39;, &#39;int64&#39;))</span>

<span class="w"> </span>    def total_seconds(self) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Total duration of each element expressed in seconds.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.copy(data=_access_through_series(self._obj.data, &#39;total_seconds&#39;))</span>


<span class="w"> </span>class CombinedDatetimelikeAccessor(DatetimeAccessor[T_DataArray],
<span class="gh">diff --git a/xarray/core/alignment.py b/xarray/core/alignment.py</span>
<span class="gh">index 3ec2a057..7818ce17 100644</span>
<span class="gd">--- a/xarray/core/alignment.py</span>
<span class="gi">+++ b/xarray/core/alignment.py</span>
<span class="gu">@@ -27,7 +27,18 @@ def reindex_variables(variables: Mapping[Any, Variable], dim_pos_indexers:</span>
<span class="w"> </span>    Not public API.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    new_variables = {}</span>
<span class="gi">+    for name, var in variables.items():</span>
<span class="gi">+        indexers = {k: v for k, v in dim_pos_indexers.items() if k in var.dims}</span>
<span class="gi">+        if indexers:</span>
<span class="gi">+            new_variables[name] = var.reindex(</span>
<span class="gi">+                indexers, copy=copy, fill_value=fill_value, sparse=sparse</span>
<span class="gi">+            )</span>
<span class="gi">+        elif copy:</span>
<span class="gi">+            new_variables[name] = var.copy(deep=False)</span>
<span class="gi">+        else:</span>
<span class="gi">+            new_variables[name] = var</span>
<span class="gi">+    return new_variables</span>


<span class="w"> </span>CoordNamesAndDims = tuple[tuple[Hashable, tuple[Hashable, ...]], ...]
<span class="gu">@@ -110,7 +121,24 @@ class Aligner(Generic[T_Alignable]):</span>
<span class="w"> </span>        such that we can group matching indexes based on the dictionary keys.

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        normalized_indexes = {}</span>
<span class="gi">+        normalized_index_vars = {}</span>
<span class="gi">+</span>
<span class="gi">+        for key, idx in indexes.items():</span>
<span class="gi">+            if isinstance(idx, Index):</span>
<span class="gi">+                index = idx</span>
<span class="gi">+                index_vars = idx.to_variables()</span>
<span class="gi">+            else:</span>
<span class="gi">+                index = PandasIndex(idx, name=key)</span>
<span class="gi">+                index_vars = {key: Variable((key,), idx)}</span>
<span class="gi">+</span>
<span class="gi">+            coord_names_and_dims = tuple((name, var.dims) for name, var in index_vars.items())</span>
<span class="gi">+            matching_key = (coord_names_and_dims, type(index))</span>
<span class="gi">+</span>
<span class="gi">+            normalized_indexes[matching_key] = index</span>
<span class="gi">+            normalized_index_vars[matching_key] = index_vars</span>
<span class="gi">+</span>
<span class="gi">+        return normalized_indexes, normalized_index_vars</span>

<span class="w"> </span>    def assert_no_index_conflict(self) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;Check for uniqueness of both coordinate and dimension names across all sets
<span class="gu">@@ -126,7 +154,20 @@ class Aligner(Generic[T_Alignable]):</span>
<span class="w"> </span>        (ref: https://github.com/pydata/xarray/issues/1603#issuecomment-442965602)

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        all_coord_names = set()</span>
<span class="gi">+        all_dim_names = set()</span>
<span class="gi">+</span>
<span class="gi">+        for (coord_names_and_dims, _), index in self.indexes.items():</span>
<span class="gi">+            coord_names = {name for name, _ in coord_names_and_dims}</span>
<span class="gi">+            dim_names = set(index.dims)</span>
<span class="gi">+</span>
<span class="gi">+            if not coord_names.isdisjoint(all_coord_names):</span>
<span class="gi">+                raise ValueError(&quot;Conflicting coordinate names found.&quot;)</span>
<span class="gi">+            if not dim_names.isdisjoint(all_dim_names):</span>
<span class="gi">+                raise ValueError(&quot;Conflicting dimension names found.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+            all_coord_names.update(coord_names)</span>
<span class="gi">+            all_dim_names.update(dim_names)</span>

<span class="w"> </span>    def _need_reindex(self, dim, cmp_indexes) -&gt;bool:
<span class="w"> </span>        &quot;&quot;&quot;Whether or not we need to reindex variables for a set of
<span class="gu">@@ -139,11 +180,44 @@ class Aligner(Generic[T_Alignable]):</span>
<span class="w"> </span>          pandas). This is useful, e.g., for overwriting such duplicate indexes.

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if dim in self.exclude_dims:</span>
<span class="gi">+            return False</span>
<span class="gi">+</span>
<span class="gi">+        if self.join == &quot;override&quot;:</span>
<span class="gi">+            return False</span>
<span class="gi">+</span>
<span class="gi">+        if self.join == &quot;exact&quot;:</span>
<span class="gi">+            return not indexes_all_equal(cmp_indexes)</span>
<span class="gi">+</span>
<span class="gi">+        if len(cmp_indexes) == 1:</span>
<span class="gi">+            return False</span>
<span class="gi">+</span>
<span class="gi">+        first_index = cmp_indexes[0]</span>
<span class="gi">+        return any(not first_index.equals(other) for other in cmp_indexes[1:])</span>

<span class="w"> </span>    def align_indexes(self) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;Compute all aligned indexes and their corresponding coordinate variables.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        for key, cmp_indexes in self.all_indexes.items():</span>
<span class="gi">+            dim = cmp_indexes[0].dim</span>
<span class="gi">+            if self._need_reindex(dim, cmp_indexes):</span>
<span class="gi">+                aligned_index = self._align_index(key, cmp_indexes)</span>
<span class="gi">+                self.aligned_indexes[key] = aligned_index</span>
<span class="gi">+                self.aligned_index_vars[key] = aligned_index.to_variables()</span>
<span class="gi">+                self.reindex[key] = True</span>
<span class="gi">+            else:</span>
<span class="gi">+                self.aligned_indexes[key] = cmp_indexes[0]</span>
<span class="gi">+                self.aligned_index_vars[key] = self.all_index_vars[key][0]</span>
<span class="gi">+                self.reindex[key] = False</span>
<span class="gi">+</span>
<span class="gi">+    def _align_index(self, key, cmp_indexes):</span>
<span class="gi">+        if self.join == &quot;outer&quot;:</span>
<span class="gi">+            return Index.union(cmp_indexes)</span>
<span class="gi">+        elif self.join == &quot;inner&quot;:</span>
<span class="gi">+            return Index.intersection(cmp_indexes)</span>
<span class="gi">+        elif self.join in [&quot;left&quot;, &quot;right&quot;]:</span>
<span class="gi">+            return cmp_indexes[0 if self.join == &quot;left&quot; else -1]</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise ValueError(f&quot;Invalid join option: {self.join}&quot;)</span>


<span class="w"> </span>T_Obj1 = TypeVar(&#39;T_Obj1&#39;, bound=&#39;Alignable&#39;)
<span class="gh">diff --git a/xarray/core/combine.py b/xarray/core/combine.py</span>
<span class="gh">index d78cb540..675036b6 100644</span>
<span class="gd">--- a/xarray/core/combine.py</span>
<span class="gi">+++ b/xarray/core/combine.py</span>
<span class="gu">@@ -35,7 +35,11 @@ def _infer_tile_ids_from_nested_list(entry, current_pos):</span>
<span class="w"> </span>    -------
<span class="w"> </span>    combined_tile_ids : dict[tuple(int, ...), obj]
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(entry, list):</span>
<span class="gi">+        for i, item in enumerate(entry):</span>
<span class="gi">+            yield from _infer_tile_ids_from_nested_list(item, current_pos + (i,))</span>
<span class="gi">+    else:</span>
<span class="gi">+        yield current_pos, entry</span>


<span class="w"> </span>def _check_dimension_depth_tile_ids(combined_tile_ids):
<span class="gu">@@ -43,12 +47,24 @@ def _check_dimension_depth_tile_ids(combined_tile_ids):</span>
<span class="w"> </span>    Check all tuples are the same length, i.e. check that all lists are
<span class="w"> </span>    nested to the same depth.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    depths = {len(key) for key in combined_tile_ids.keys()}</span>
<span class="gi">+    if len(depths) != 1:</span>
<span class="gi">+        raise ValueError(&quot;All lists must be nested to the same depth.&quot;)</span>


<span class="w"> </span>def _check_shape_tile_ids(combined_tile_ids):
<span class="w"> </span>    &quot;&quot;&quot;Check all lists along one dimension are same length.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not combined_tile_ids:</span>
<span class="gi">+        return</span>
<span class="gi">+</span>
<span class="gi">+    depths = max(len(key) for key in combined_tile_ids.keys())</span>
<span class="gi">+    for dim in range(depths):</span>
<span class="gi">+        lengths = set()</span>
<span class="gi">+        for key in combined_tile_ids.keys():</span>
<span class="gi">+            if len(key) &gt; dim:</span>
<span class="gi">+                lengths.add(max(k[dim] for k in combined_tile_ids.keys() if len(k) &gt; dim) + 1)</span>
<span class="gi">+        if len(lengths) != 1:</span>
<span class="gi">+            raise ValueError(f&quot;Lists along dimension {dim} have inconsistent lengths.&quot;)</span>


<span class="w"> </span>def _combine_nd(combined_ids, concat_dims, data_vars=&#39;all&#39;, coords=
<span class="gu">@@ -76,7 +92,25 @@ def _combine_nd(combined_ids, concat_dims, data_vars=&#39;all&#39;, coords=</span>
<span class="w"> </span>    -------
<span class="w"> </span>    combined_ds : xarray.Dataset
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if len(combined_ids) == 1:</span>
<span class="gi">+        return next(iter(combined_ids.values()))</span>
<span class="gi">+</span>
<span class="gi">+    dims = len(next(iter(combined_ids.keys())))</span>
<span class="gi">+    if len(concat_dims) != dims:</span>
<span class="gi">+        raise ValueError(&quot;Length of concat_dims must match the number of dimensions in combined_ids&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    for dim in range(dims - 1, -1, -1):</span>
<span class="gi">+        if concat_dims[dim] is None:</span>
<span class="gi">+            combined_ids = {k[:-1]: merge([combined_ids[k[:-1] + (i,)] for i in range(max(k[dim] for k in combined_ids.keys()) + 1)],</span>
<span class="gi">+                                          compat=compat, join=join, fill_value=fill_value, combine_attrs=combine_attrs)</span>
<span class="gi">+                            for k in combined_ids.keys() if k[dim] == 0}</span>
<span class="gi">+        else:</span>
<span class="gi">+            combined_ids = {k[:-1]: concat([combined_ids[k[:-1] + (i,)] for i in range(max(k[dim] for k in combined_ids.keys()) + 1)],</span>
<span class="gi">+                                           dim=concat_dims[dim], data_vars=data_vars, coords=coords,</span>
<span class="gi">+                                           compat=compat, fill_value=fill_value, join=join, combine_attrs=combine_attrs)</span>
<span class="gi">+                            for k in combined_ids.keys() if k[dim] == 0}</span>
<span class="gi">+</span>
<span class="gi">+    return next(iter(combined_ids.values()))</span>


<span class="w"> </span>def _combine_1d(datasets, concat_dim, compat: CompatOptions=&#39;no_conflicts&#39;,
<span class="gu">@@ -86,7 +120,11 @@ def _combine_1d(datasets, concat_dim, compat: CompatOptions=&#39;no_conflicts&#39;,</span>
<span class="w"> </span>    Applies either concat or merge to 1D list of datasets depending on value
<span class="w"> </span>    of concat_dim
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if concat_dim is None:</span>
<span class="gi">+        return merge(datasets, compat=compat, join=join, fill_value=fill_value, combine_attrs=combine_attrs)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return concat(datasets, dim=concat_dim, data_vars=data_vars, coords=coords,</span>
<span class="gi">+                      compat=compat, fill_value=fill_value, join=join, combine_attrs=combine_attrs)</span>


<span class="w"> </span>DATASET_HYPERCUBE = Union[Dataset, Iterable[&#39;DATASET_HYPERCUBE&#39;]]
<span class="gu">@@ -276,7 +314,15 @@ def combine_nested(datasets: DATASET_HYPERCUBE, concat_dim: (str |</span>
<span class="w"> </span>    concat
<span class="w"> </span>    merge
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not isinstance(concat_dim, (list, tuple)):</span>
<span class="gi">+        concat_dim = [concat_dim]</span>
<span class="gi">+</span>
<span class="gi">+    combined_ids = dict(_infer_tile_ids_from_nested_list(datasets, ()))</span>
<span class="gi">+    _check_dimension_depth_tile_ids(combined_ids)</span>
<span class="gi">+    _check_shape_tile_ids(combined_ids)</span>
<span class="gi">+</span>
<span class="gi">+    return _combine_nd(combined_ids, concat_dim, data_vars=data_vars, coords=coords,</span>
<span class="gi">+                       compat=compat, fill_value=fill_value, join=join, combine_attrs=combine_attrs)</span>


<span class="w"> </span>def _combine_single_variable_hypercube(datasets, fill_value=dtypes.NA,
<span class="gu">@@ -293,7 +339,38 @@ def _combine_single_variable_hypercube(datasets, fill_value=dtypes.NA,</span>

<span class="w"> </span>    This function is NOT part of the public API.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not datasets:</span>
<span class="gi">+        return Dataset()</span>
<span class="gi">+</span>
<span class="gi">+    first = datasets[0]</span>
<span class="gi">+    coords = set(first.coords)</span>
<span class="gi">+    dim_coords = {dim: coord for dim, coord in first.coords.items() if dim in first.dims}</span>
<span class="gi">+</span>
<span class="gi">+    # Determine the shape of the hypercube</span>
<span class="gi">+    hypercube_shape = {}</span>
<span class="gi">+    for ds in datasets:</span>
<span class="gi">+        for dim, coord in ds.coords.items():</span>
<span class="gi">+            if dim in dim_coords and not coord.equals(dim_coords[dim]):</span>
<span class="gi">+                if dim not in hypercube_shape:</span>
<span class="gi">+                    hypercube_shape[dim] = set()</span>
<span class="gi">+                hypercube_shape[dim].add(coord.values.tolist()[0])</span>
<span class="gi">+</span>
<span class="gi">+    # Create a new coordinate for each dimension of the hypercube</span>
<span class="gi">+    new_coords = {}</span>
<span class="gi">+    concat_dims = []</span>
<span class="gi">+    for dim, values in hypercube_shape.items():</span>
<span class="gi">+        new_coords[dim] = sorted(values)</span>
<span class="gi">+        concat_dims.append(dim)</span>
<span class="gi">+</span>
<span class="gi">+    # Assign each dataset to its position in the hypercube</span>
<span class="gi">+    positioned_datasets = {}</span>
<span class="gi">+    for ds in datasets:</span>
<span class="gi">+        position = tuple(new_coords[dim].index(ds.coords[dim].values.tolist()[0]) for dim in concat_dims)</span>
<span class="gi">+        positioned_datasets[position] = ds</span>
<span class="gi">+</span>
<span class="gi">+    # Combine the datasets</span>
<span class="gi">+    return _combine_nd(positioned_datasets, concat_dims, data_vars=data_vars, coords=coords,</span>
<span class="gi">+                       compat=compat, fill_value=fill_value, join=join, combine_attrs=combine_attrs)</span>


<span class="w"> </span>def combine_by_coords(data_objects: Iterable[Dataset | DataArray]=[],
<span class="gu">@@ -551,4 +628,35 @@ def combine_by_coords(data_objects: Iterable[Dataset | DataArray]=[],</span>
<span class="w"> </span>    Finally, if you attempt to combine a mix of unnamed DataArrays with either named
<span class="w"> </span>    DataArrays or Datasets, a ValueError will be raised (as this is an ambiguous operation).
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not data_objects:</span>
<span class="gi">+        return Dataset()</span>
<span class="gi">+</span>
<span class="gi">+    if all(isinstance(obj, DataArray) for obj in data_objects):</span>
<span class="gi">+        if all(obj.name is not None for obj in data_objects):</span>
<span class="gi">+            data_objects = [obj.to_dataset() for obj in data_objects]</span>
<span class="gi">+        elif any(obj.name is not None for obj in data_objects):</span>
<span class="gi">+            raise ValueError(&quot;Cannot combine mix of named and unnamed DataArrays.&quot;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            return _combine_single_variable_hypercube(data_objects, fill_value=fill_value,</span>
<span class="gi">+                                                      data_vars=data_vars, coords=coords,</span>
<span class="gi">+                                                      compat=compat, join=join,</span>
<span class="gi">+                                                      combine_attrs=combine_attrs)</span>
<span class="gi">+</span>
<span class="gi">+    datasets = [obj if isinstance(obj, Dataset) else obj.to_dataset() for obj in data_objects]</span>
<span class="gi">+</span>
<span class="gi">+    # Identify the dimensions to concatenate along</span>
<span class="gi">+    concat_dims = set()</span>
<span class="gi">+    for ds in datasets:</span>
<span class="gi">+        for dim, coord in ds.coords.items():</span>
<span class="gi">+            if dim in ds.dims and not all(coord.equals(other_ds[dim]) for other_ds in datasets if dim in other_ds.dims):</span>
<span class="gi">+                concat_dims.add(dim)</span>
<span class="gi">+</span>
<span class="gi">+    # Sort datasets based on their coordinate values</span>
<span class="gi">+    sorted_datasets = sorted(datasets, key=lambda ds: tuple(ds[dim].values[0] for dim in concat_dims if dim in ds.dims))</span>
<span class="gi">+</span>
<span class="gi">+    # Combine the datasets</span>
<span class="gi">+    combined = _combine_nd({tuple(ds[dim].values[0] for dim in concat_dims if dim in ds.dims): ds for ds in sorted_datasets},</span>
<span class="gi">+                           list(concat_dims), data_vars=data_vars, coords=coords,</span>
<span class="gi">+                           compat=compat, fill_value=fill_value, join=join, combine_attrs=combine_attrs)</span>
<span class="gi">+</span>
<span class="gi">+    return combined</span>
<span class="gh">diff --git a/xarray/core/common.py b/xarray/core/common.py</span>
<span class="gh">index c819d798..042f0e97 100644</span>
<span class="gd">--- a/xarray/core/common.py</span>
<span class="gi">+++ b/xarray/core/common.py</span>
<span class="gu">@@ -127,7 +127,10 @@ class AbstractArray:</span>
<span class="w"> </span>        int or tuple of int
<span class="w"> </span>            Axis number or numbers corresponding to the given dimensions.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(dim, Iterable) and not isinstance(dim, str):</span>
<span class="gi">+            return tuple(self.get_axis_num(d) for d in dim)</span>
<span class="gi">+        else:</span>
<span class="gi">+            return self.dims.index(dim)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def sizes(self: Any) -&gt;Mapping[Hashable, int]:
<span class="gu">@@ -139,7 +142,7 @@ class AbstractArray:</span>
<span class="w"> </span>        --------
<span class="w"> </span>        Dataset.sizes
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return Frozen(dict(zip(self.dims, self.shape)))</span>


<span class="w"> </span>class AttrAccessMixin:
<span class="gu">@@ -166,12 +169,12 @@ class AttrAccessMixin:</span>
<span class="w"> </span>    @property
<span class="w"> </span>    def _attr_sources(self) -&gt;Iterable[Mapping[Hashable, Any]]:
<span class="w"> </span>        &quot;&quot;&quot;Places to look-up items for attribute-style access&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return [self.attrs, self.coords, self.data_vars]</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def _item_sources(self) -&gt;Iterable[Mapping[Hashable, Any]]:
<span class="w"> </span>        &quot;&quot;&quot;Places to look-up items for key-autocompletion&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return [self.coords, self.data_vars]</span>

<span class="w"> </span>    def __getattr__(self, name: str) -&gt;Any:
<span class="w"> </span>        if name not in {&#39;__dict__&#39;, &#39;__setstate__&#39;}:
<span class="gu">@@ -213,7 +216,7 @@ class AttrAccessMixin:</span>
<span class="w"> </span>        See http://ipython.readthedocs.io/en/stable/config/integrating.html#tab-completion
<span class="w"> </span>        For the details.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return list(itertools.chain.from_iterable(source.keys() for source in self._item_sources))</span>


<span class="w"> </span>class TreeAttrAccessMixin(AttrAccessMixin):
<span class="gu">@@ -233,7 +236,21 @@ class TreeAttrAccessMixin(AttrAccessMixin):</span>
<span class="w"> </span>def get_squeeze_dims(xarray_obj, dim: (Hashable | Iterable[Hashable] | None
<span class="w"> </span>    )=None, axis: (int | Iterable[int] | None)=None) -&gt;list[Hashable]:
<span class="w"> </span>    &quot;&quot;&quot;Get a list of dimensions to squeeze out.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if dim is not None and axis is not None:</span>
<span class="gi">+        raise ValueError(&quot;Cannot specify both &#39;dim&#39; and &#39;axis&#39;&quot;)</span>
<span class="gi">+    </span>
<span class="gi">+    if dim is None and axis is None:</span>
<span class="gi">+        return [d for d, s in xarray_obj.sizes.items() if s == 1]</span>
<span class="gi">+    </span>
<span class="gi">+    if isinstance(dim, Hashable) and not isinstance(dim, Iterable):</span>
<span class="gi">+        dim = [dim]</span>
<span class="gi">+    if isinstance(axis, int):</span>
<span class="gi">+        axis = [axis]</span>
<span class="gi">+    </span>
<span class="gi">+    if axis is not None:</span>
<span class="gi">+        dim = [xarray_obj.dims[i] for i in axis]</span>
<span class="gi">+    </span>
<span class="gi">+    return [d for d in dim if xarray_obj.sizes[d] == 1]</span>


<span class="w"> </span>class DataWithCoords(AttrAccessMixin):
<span class="gu">@@ -1194,14 +1211,42 @@ def full_like(other: (Dataset | DataArray | Variable), fill_value: Any,</span>
<span class="w"> </span>    ones_like

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(other, Dataset):</span>
<span class="gi">+        data_vars = {}</span>
<span class="gi">+        for name, da in other.data_vars.items():</span>
<span class="gi">+            if isinstance(fill_value, dict):</span>
<span class="gi">+                value = fill_value.get(name, np.nan)</span>
<span class="gi">+            else:</span>
<span class="gi">+                value = fill_value</span>
<span class="gi">+            data_vars[name] = _full_like_variable(da.variable, value, dtype, chunks, chunked_array_type, from_array_kwargs)</span>
<span class="gi">+        return Dataset(data_vars, coords=other.coords, attrs=other.attrs)</span>
<span class="gi">+    elif isinstance(other, DataArray):</span>
<span class="gi">+        return DataArray(_full_like_variable(other.variable, fill_value, dtype, chunks, chunked_array_type, from_array_kwargs),</span>
<span class="gi">+                         dims=other.dims, coords=other.coords, attrs=other.attrs, name=other.name)</span>
<span class="gi">+    elif isinstance(other, Variable):</span>
<span class="gi">+        return _full_like_variable(other, fill_value, dtype, chunks, chunked_array_type, from_array_kwargs)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(f&quot;Expected DataArray, Dataset, or Variable, got {type(other)}&quot;)</span>


<span class="w"> </span>def _full_like_variable(other: Variable, fill_value: Any, dtype: (DTypeLike |
<span class="w"> </span>    None)=None, chunks: T_Chunks=None, chunked_array_type: (str | None)=
<span class="w"> </span>    None, from_array_kwargs: (dict[str, Any] | None)=None) -&gt;Variable:
<span class="w"> </span>    &quot;&quot;&quot;Inner function of full_like, where other must be a variable&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if dtype is None:</span>
<span class="gi">+        dtype = other.dtype</span>
<span class="gi">+    shape = other.shape</span>
<span class="gi">+    </span>
<span class="gi">+    if chunks is None and chunked_array_type is None and is_chunked_array(other.data):</span>
<span class="gi">+        chunks = other.chunks</span>
<span class="gi">+    </span>
<span class="gi">+    if chunks is not None or chunked_array_type is not None:</span>
<span class="gi">+        chunkmanager = guess_chunkmanager(chunked_array_type)</span>
<span class="gi">+        data = chunkmanager.full(shape, fill_value, dtype=dtype, chunks=chunks, **(from_array_kwargs or {}))</span>
<span class="gi">+    else:</span>
<span class="gi">+        data = np.full(shape, fill_value, dtype=dtype)</span>
<span class="gi">+    </span>
<span class="gi">+    return Variable(dims=other.dims, data=data, attrs=other.attrs)</span>


<span class="w"> </span>def zeros_like(other: (Dataset | DataArray | Variable), dtype: (
<span class="gu">@@ -1272,7 +1317,7 @@ def zeros_like(other: (Dataset | DataArray | Variable), dtype: (</span>
<span class="w"> </span>    full_like

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return full_like(other, 0, dtype, chunks=chunks, chunked_array_type=chunked_array_type, from_array_kwargs=from_array_kwargs)</span>


<span class="w"> </span>def ones_like(other: (Dataset | DataArray | Variable), dtype: (
<span class="gu">@@ -1335,31 +1380,41 @@ def ones_like(other: (Dataset | DataArray | Variable), dtype: (</span>
<span class="w"> </span>    full_like

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return full_like(other, 1, dtype, chunks=chunks, chunked_array_type=chunked_array_type, from_array_kwargs=from_array_kwargs)</span>


<span class="w"> </span>def is_np_datetime_like(dtype: DTypeLike) -&gt;bool:
<span class="w"> </span>    &quot;&quot;&quot;Check if a dtype is a subclass of the numpy datetime types&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return np.issubdtype(dtype, np.datetime64) or np.issubdtype(dtype, np.timedelta64)</span>


<span class="w"> </span>def is_np_timedelta_like(dtype: DTypeLike) -&gt;bool:
<span class="w"> </span>    &quot;&quot;&quot;Check whether dtype is of the timedelta64 dtype.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return np.issubdtype(dtype, np.timedelta64)</span>


<span class="w"> </span>def _contains_cftime_datetimes(array: Any) -&gt;bool:
<span class="w"> </span>    &quot;&quot;&quot;Check if a array inside a Variable contains cftime.datetime objects&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if cftime is None:</span>
<span class="gi">+        return False</span>
<span class="gi">+    return (</span>
<span class="gi">+        array.dtype == object</span>
<span class="gi">+        and isinstance(array, (np.ndarray, pd.Index))</span>
<span class="gi">+        and array.size &gt; 0</span>
<span class="gi">+        and isinstance(array.flat[0], cftime.datetime)</span>
<span class="gi">+    )</span>


<span class="w"> </span>def contains_cftime_datetimes(var: T_Variable) -&gt;bool:
<span class="w"> </span>    &quot;&quot;&quot;Check if an xarray.Variable contains cftime.datetime objects&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return _contains_cftime_datetimes(var.data)</span>


<span class="w"> </span>def _contains_datetime_like_objects(var: T_Variable) -&gt;bool:
<span class="w"> </span>    &quot;&quot;&quot;Check if a variable contains datetime like objects (either
<span class="w"> </span>    np.datetime64, np.timedelta64, or cftime.datetime)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return (</span>
<span class="gi">+        is_np_datetime_like(var.dtype)</span>
<span class="gi">+        or (var.dtype == object and contains_cftime_datetimes(var))</span>
<span class="gi">+    )</span>
<span class="gh">diff --git a/xarray/core/computation.py b/xarray/core/computation.py</span>
<span class="gh">index fd8f4fb2..0503eb18 100644</span>
<span class="gd">--- a/xarray/core/computation.py</span>
<span class="gi">+++ b/xarray/core/computation.py</span>
<span class="gu">@@ -37,12 +37,15 @@ _JOINS_WITHOUT_FILL_VALUES = frozenset({&#39;inner&#39;, &#39;exact&#39;})</span>

<span class="w"> </span>def _first_of_type(args, kind):
<span class="w"> </span>    &quot;&quot;&quot;Return either first object of type &#39;kind&#39; or raise if not found.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    for arg in args:</span>
<span class="gi">+        if isinstance(arg, kind):</span>
<span class="gi">+            return arg</span>
<span class="gi">+    raise ValueError(f&quot;No object of type {kind} found in arguments&quot;)</span>


<span class="w"> </span>def _all_of_type(args, kind):
<span class="w"> </span>    &quot;&quot;&quot;Return all objects of type &#39;kind&#39;&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return [arg for arg in args if isinstance(arg, kind)]</span>


<span class="w"> </span>class _UFuncSignature:
<span class="gu">@@ -136,7 +139,39 @@ def build_output_coords_and_indexes(args: Iterable[Any], signature:</span>
<span class="w"> </span>    -------
<span class="w"> </span>    Dictionaries of Variable and Index objects with merged coordinates.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from xarray.core.coordinates import Coordinates</span>
<span class="gi">+    from xarray.core.dataarray import DataArray</span>
<span class="gi">+    from xarray.core.dataset import Dataset</span>
<span class="gi">+    </span>
<span class="gi">+    datasets = _all_of_type(args, Dataset)</span>
<span class="gi">+    dataarrays = _all_of_type(args, DataArray)</span>
<span class="gi">+    </span>
<span class="gi">+    all_coords = []</span>
<span class="gi">+    all_indexes = []</span>
<span class="gi">+    </span>
<span class="gi">+    for obj in itertools.chain(datasets, dataarrays):</span>
<span class="gi">+        coords = obj.coords.copy()</span>
<span class="gi">+        indexes = obj.xindexes.copy()</span>
<span class="gi">+        </span>
<span class="gi">+        # Drop excluded dimensions</span>
<span class="gi">+        for dim in exclude_dims:</span>
<span class="gi">+            coords = coords.drop(dim) if dim in coords else coords</span>
<span class="gi">+            indexes = {k: v for k, v in indexes.items() if k != dim}</span>
<span class="gi">+        </span>
<span class="gi">+        all_coords.append(coords)</span>
<span class="gi">+        all_indexes.append(indexes)</span>
<span class="gi">+    </span>
<span class="gi">+    # Merge coordinates</span>
<span class="gi">+    merged_coords = Coordinates.merge(all_coords, combine_attrs=combine_attrs)</span>
<span class="gi">+    </span>
<span class="gi">+    # Merge indexes</span>
<span class="gi">+    merged_indexes = {}</span>
<span class="gi">+    for dim in set().union(*[set(idx.keys()) for idx in all_indexes]):</span>
<span class="gi">+        indexes = [idx[dim] for idx in all_indexes if dim in idx]</span>
<span class="gi">+        if indexes:</span>
<span class="gi">+            merged_indexes[dim] = indexes[0].merge(indexes[1:])</span>
<span class="gi">+    </span>
<span class="gi">+    return [merged_coords], [merged_indexes]</span>


<span class="w"> </span>def apply_dataarray_vfunc(func, *args, signature: _UFuncSignature, join:
<span class="gu">@@ -145,7 +180,36 @@ def apply_dataarray_vfunc(func, *args, signature: _UFuncSignature, join:</span>
<span class="w"> </span>    &quot;&quot;&quot;Apply a variable level function over DataArray, Variable and/or ndarray
<span class="w"> </span>    objects.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from xarray.core.dataarray import DataArray</span>
<span class="gi">+    from xarray.core.variable import Variable</span>
<span class="gi">+    </span>
<span class="gi">+    # Extract DataArrays from args</span>
<span class="gi">+    dataarrays = _all_of_type(args, DataArray)</span>
<span class="gi">+    </span>
<span class="gi">+    # Align DataArrays</span>
<span class="gi">+    aligned = align(*dataarrays, join=join, exclude=exclude_dims, copy=False)</span>
<span class="gi">+    </span>
<span class="gi">+    # Replace DataArrays in args with their data</span>
<span class="gi">+    new_args = [</span>
<span class="gi">+        arg.data if isinstance(arg, DataArray) else arg for arg in args</span>
<span class="gi">+    ]</span>
<span class="gi">+    </span>
<span class="gi">+    # Apply the function</span>
<span class="gi">+    result_data = func(*new_args)</span>
<span class="gi">+    </span>
<span class="gi">+    # Build output coordinates and indexes</span>
<span class="gi">+    coords, indexes = build_output_coords_and_indexes(</span>
<span class="gi">+        aligned, signature, exclude_dims, keep_attrs</span>
<span class="gi">+    )</span>
<span class="gi">+    </span>
<span class="gi">+    # Create output DataArray(s)</span>
<span class="gi">+    if isinstance(result_data, tuple):</span>
<span class="gi">+        return tuple(</span>
<span class="gi">+            DataArray(data, coords=coords[0], indexes=indexes[0])</span>
<span class="gi">+            for data in result_data</span>
<span class="gi">+        )</span>
<span class="gi">+    else:</span>
<span class="gi">+        return DataArray(result_data, coords=coords[0], indexes=indexes[0])</span>


<span class="w"> </span>_JOINERS: dict[str, Callable] = {&#39;inner&#39;: ordered_set_intersection, &#39;outer&#39;:
<span class="gu">@@ -170,7 +234,42 @@ def apply_dict_of_variables_vfunc(func, *args, signature: _UFuncSignature,</span>
<span class="w"> </span>    &quot;&quot;&quot;Apply a variable level function over dicts of DataArray, DataArray,
<span class="w"> </span>    Variable and ndarray objects.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from xarray.core.dataarray import DataArray</span>
<span class="gi">+    from xarray.core.dataset import Dataset</span>
<span class="gi">+    from xarray.core.variable import Variable</span>
<span class="gi">+    </span>
<span class="gi">+    # Extract datasets and convert other arguments to datasets</span>
<span class="gi">+    datasets = []</span>
<span class="gi">+    for arg in args:</span>
<span class="gi">+        if isinstance(arg, Dataset):</span>
<span class="gi">+            datasets.append(arg)</span>
<span class="gi">+        elif isinstance(arg, dict):</span>
<span class="gi">+            datasets.append(Dataset(arg))</span>
<span class="gi">+        elif isinstance(arg, (DataArray, Variable)):</span>
<span class="gi">+            datasets.append(Dataset({getattr(arg, &#39;name&#39;, &#39;unnamed&#39;): arg}))</span>
<span class="gi">+        else:</span>
<span class="gi">+            datasets.append(Dataset({&#39;unnamed&#39;: Variable((), arg)}))</span>
<span class="gi">+    </span>
<span class="gi">+    # Align datasets</span>
<span class="gi">+    aligned = align(*datasets, join=join, copy=False, fill_value=fill_value)</span>
<span class="gi">+    </span>
<span class="gi">+    # Apply function to each variable</span>
<span class="gi">+    result_vars = {}</span>
<span class="gi">+    for var_name in aligned[0].data_vars:</span>
<span class="gi">+        var_args = [ds[var_name].variable for ds in aligned if var_name in ds]</span>
<span class="gi">+        if len(var_args) &lt; len(aligned) and on_missing_core_dim == &#39;raise&#39;:</span>
<span class="gi">+            raise ValueError(f&quot;Variable {var_name} missing from some datasets&quot;)</span>
<span class="gi">+        elif len(var_args) &lt; len(aligned) and on_missing_core_dim == &#39;drop&#39;:</span>
<span class="gi">+            continue</span>
<span class="gi">+        </span>
<span class="gi">+        result = func(*var_args)</span>
<span class="gi">+        if isinstance(result, tuple):</span>
<span class="gi">+            for i, res in enumerate(result):</span>
<span class="gi">+                result_vars[f&quot;{var_name}_{i}&quot;] = res</span>
<span class="gi">+        else:</span>
<span class="gi">+            result_vars[var_name] = result</span>
<span class="gi">+    </span>
<span class="gi">+    return Dataset(result_vars)</span>


<span class="w"> </span>def _fast_dataset(variables: dict[Hashable, Variable], coord_variables:
<span class="gu">@@ -179,7 +278,11 @@ def _fast_dataset(variables: dict[Hashable, Variable], coord_variables:</span>

<span class="w"> </span>    Beware: the `variables` dict is modified INPLACE.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from xarray.core.dataset import Dataset</span>
<span class="gi">+    </span>
<span class="gi">+    variables.update(coord_variables)</span>
<span class="gi">+    coords = set(coord_variables)</span>
<span class="gi">+    return Dataset._construct_direct(variables, coords, indexes)</span>


<span class="w"> </span>def apply_dataset_vfunc(func, *args, signature: _UFuncSignature, join=
<span class="gu">@@ -189,19 +292,80 @@ def apply_dataset_vfunc(func, *args, signature: _UFuncSignature, join=</span>
<span class="w"> </span>    &quot;&quot;&quot;Apply a variable level function over Dataset, dict of DataArray,
<span class="w"> </span>    DataArray, Variable and/or ndarray objects.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from xarray.core.dataset import Dataset</span>
<span class="gi">+    from xarray.core.dataarray import DataArray</span>
<span class="gi">+    from xarray.core.variable import Variable</span>
<span class="gi">+    </span>
<span class="gi">+    datasets = []</span>
<span class="gi">+    for arg in args:</span>
<span class="gi">+        if isinstance(arg, Dataset):</span>
<span class="gi">+            datasets.append(arg)</span>
<span class="gi">+        elif isinstance(arg, dict):</span>
<span class="gi">+            datasets.append(Dataset(arg))</span>
<span class="gi">+        elif isinstance(arg, (DataArray, Variable)):</span>
<span class="gi">+            datasets.append(Dataset({getattr(arg, &#39;name&#39;, &#39;unnamed&#39;): arg}))</span>
<span class="gi">+        else:</span>
<span class="gi">+            datasets.append(Dataset({&#39;unnamed&#39;: Variable((), arg)}))</span>
<span class="gi">+    </span>
<span class="gi">+    aligned = align(*datasets, join=join, copy=False, exclude=exclude_dims,</span>
<span class="gi">+                    fill_value=fill_value)</span>
<span class="gi">+    </span>
<span class="gi">+    result_vars = {}</span>
<span class="gi">+    for var_name in aligned[0].data_vars:</span>
<span class="gi">+        var_args = [ds[var_name].variable for ds in aligned if var_name in ds]</span>
<span class="gi">+        if len(var_args) &lt; len(aligned):</span>
<span class="gi">+            if on_missing_core_dim == &#39;raise&#39;:</span>
<span class="gi">+                raise ValueError(f&quot;Variable {var_name} missing from some datasets&quot;)</span>
<span class="gi">+            elif on_missing_core_dim == &#39;drop&#39;:</span>
<span class="gi">+                continue</span>
<span class="gi">+        </span>
<span class="gi">+        result = func(*var_args)</span>
<span class="gi">+        if isinstance(result, tuple):</span>
<span class="gi">+            for i, res in enumerate(result):</span>
<span class="gi">+                result_vars[f&quot;{var_name}_{i}&quot;] = res</span>
<span class="gi">+        else:</span>
<span class="gi">+            result_vars[var_name] = result</span>
<span class="gi">+    </span>
<span class="gi">+    coords, indexes = build_output_coords_and_indexes(</span>
<span class="gi">+        aligned, signature, exclude_dims, keep_attrs</span>
<span class="gi">+    )</span>
<span class="gi">+    </span>
<span class="gi">+    result_dataset = _fast_dataset(result_vars, coords[0], indexes[0])</span>
<span class="gi">+    </span>
<span class="gi">+    if keep_attrs != &#39;drop&#39;:</span>
<span class="gi">+        result_dataset.attrs = aligned[0].attrs</span>
<span class="gi">+    </span>
<span class="gi">+    return result_dataset</span>


<span class="w"> </span>def _iter_over_selections(obj, dim, values):
<span class="w"> </span>    &quot;&quot;&quot;Iterate over selections of an xarray object in the provided order.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    for value in values:</span>
<span class="gi">+        yield obj.isel({dim: value})</span>


<span class="w"> </span>def apply_groupby_func(func, *args):
<span class="w"> </span>    &quot;&quot;&quot;Apply a dataset or datarray level function over GroupBy, Dataset,
<span class="w"> </span>    DataArray, Variable and/or ndarray objects.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from xarray.core.groupby import GroupBy</span>
<span class="gi">+    </span>
<span class="gi">+    groupbys = [arg for arg in args if isinstance(arg, GroupBy)]</span>
<span class="gi">+    if not groupbys:</span>
<span class="gi">+        return func(*args)</span>
<span class="gi">+    </span>
<span class="gi">+    grouped = groupbys[0]</span>
<span class="gi">+    other_args = [arg for arg in args if not isinstance(arg, GroupBy)]</span>
<span class="gi">+    </span>
<span class="gi">+    applied = []</span>
<span class="gi">+    for labels, group in grouped:</span>
<span class="gi">+        group_args = [group] + [</span>
<span class="gi">+            arg.sel(group.coords) if hasattr(arg, &#39;sel&#39;) else arg</span>
<span class="gi">+            for arg in other_args</span>
<span class="gi">+        ]</span>
<span class="gi">+        applied.append(func(*group_args))</span>
<span class="gi">+    </span>
<span class="gi">+    return grouped._combine(applied)</span>


<span class="w"> </span>SLICE_NONE = slice(None)
<span class="gu">@@ -212,12 +376,55 @@ def apply_variable_ufunc(func, *args, signature: _UFuncSignature,</span>
<span class="w"> </span>    vectorize=False, keep_attrs=&#39;override&#39;, dask_gufunc_kwargs=None) -&gt;(
<span class="w"> </span>    Variable | tuple[Variable, ...]):
<span class="w"> </span>    &quot;&quot;&quot;Apply a ndarray level function over Variable and/or ndarray objects.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from xarray.core.variable import Variable</span>
<span class="gi">+    import numpy as np</span>
<span class="gi">+    </span>
<span class="gi">+    if vectorize:</span>
<span class="gi">+        func = np.vectorize(func)</span>
<span class="gi">+    </span>
<span class="gi">+    input_core_dims = signature.input_core_dims</span>
<span class="gi">+    output_core_dims = signature.output_core_dims</span>
<span class="gi">+    </span>
<span class="gi">+    if dask == &#39;forbidden&#39;:</span>
<span class="gi">+        arrays = [arg.data if isinstance(arg, Variable) else arg for arg in args]</span>
<span class="gi">+        result_data = func(*arrays)</span>
<span class="gi">+    elif dask == &#39;allowed&#39;:</span>
<span class="gi">+        arrays = [arg.data if isinstance(arg, Variable) else arg for arg in args]</span>
<span class="gi">+        result_data = func(*arrays)</span>
<span class="gi">+    elif dask == &#39;parallelized&#39;:</span>
<span class="gi">+        import dask.array as da</span>
<span class="gi">+        arrays = [arg.data if isinstance(arg, Variable) else arg for arg in args]</span>
<span class="gi">+        result_data = da.apply_gufunc(func, signature, *arrays, </span>
<span class="gi">+                                      output_dtypes=output_dtypes, </span>
<span class="gi">+                                      **dask_gufunc_kwargs)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(&quot;dask must be &#39;forbidden&#39;, &#39;allowed&#39; or &#39;parallelized&#39;&quot;)</span>
<span class="gi">+    </span>
<span class="gi">+    if isinstance(result_data, tuple):</span>
<span class="gi">+        results = []</span>
<span class="gi">+        for data, out_core_dims in zip(result_data, output_core_dims):</span>
<span class="gi">+            dims = [d for d in args[0].dims if d not in exclude_dims] + list(out_core_dims)</span>
<span class="gi">+            results.append(Variable(dims, data))</span>
<span class="gi">+        return tuple(results)</span>
<span class="gi">+    else:</span>
<span class="gi">+        dims = [d for d in args[0].dims if d not in exclude_dims] + list(output_core_dims[0])</span>
<span class="gi">+        return Variable(dims, result_data)</span>


<span class="w"> </span>def apply_array_ufunc(func, *args, dask=&#39;forbidden&#39;):
<span class="w"> </span>    &quot;&quot;&quot;Apply a ndarray level function over ndarray objects.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import numpy as np</span>
<span class="gi">+    </span>
<span class="gi">+    if dask == &#39;forbidden&#39;:</span>
<span class="gi">+        return func(*args)</span>
<span class="gi">+    elif dask == &#39;allowed&#39;:</span>
<span class="gi">+        return func(*args)</span>
<span class="gi">+    elif dask == &#39;parallelized&#39;:</span>
<span class="gi">+        import dask.array as da</span>
<span class="gi">+        dask_args = [da.from_array(arg) if isinstance(arg, np.ndarray) else arg for arg in args]</span>
<span class="gi">+        return da.map_overlap(func, *dask_args)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(&quot;dask must be &#39;forbidden&#39;, &#39;allowed&#39; or &#39;parallelized&#39;&quot;)</span>


<span class="w"> </span>def apply_ufunc(func: Callable, *args: Any, input_core_dims: (Sequence[
<span class="gh">diff --git a/xarray/core/concat.py b/xarray/core/concat.py</span>
<span class="gh">index 636b3856..04f109a6 100644</span>
<span class="gd">--- a/xarray/core/concat.py</span>
<span class="gi">+++ b/xarray/core/concat.py</span>
<span class="gu">@@ -189,7 +189,24 @@ def concat(objs, dim, data_vars: T_DataVars=&#39;all&#39;, coords=&#39;different&#39;,</span>
<span class="w"> </span>    Indexes:
<span class="w"> </span>        *empty*
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    dim_name, dim_index = _calc_concat_dim_index(dim)</span>
<span class="gi">+    </span>
<span class="gi">+    if isinstance(objs[0], T_DataArray):</span>
<span class="gi">+        return _dataarray_concat(</span>
<span class="gi">+            objs, dim=dim_name, dim_index=dim_index,</span>
<span class="gi">+            data_vars=data_vars, coords=coords, compat=compat,</span>
<span class="gi">+            positions=positions, fill_value=fill_value, join=join,</span>
<span class="gi">+            combine_attrs=combine_attrs,</span>
<span class="gi">+            create_index_for_new_dim=create_index_for_new_dim</span>
<span class="gi">+        )</span>
<span class="gi">+    else:</span>
<span class="gi">+        return _dataset_concat(</span>
<span class="gi">+            objs, dim=dim_name, dim_index=dim_index,</span>
<span class="gi">+            data_vars=data_vars, coords=coords, compat=compat,</span>
<span class="gi">+            positions=positions, fill_value=fill_value, join=join,</span>
<span class="gi">+            combine_attrs=combine_attrs,</span>
<span class="gi">+            create_index_for_new_dim=create_index_for_new_dim</span>
<span class="gi">+        )</span>


<span class="w"> </span>def _calc_concat_dim_index(dim_or_data: (Hashable | Any)) -&gt;tuple[Hashable,
<span class="gu">@@ -198,7 +215,14 @@ def _calc_concat_dim_index(dim_or_data: (Hashable | Any)) -&gt;tuple[Hashable,</span>
<span class="w"> </span>    for concatenating along the new dimension.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(dim_or_data, str):</span>
<span class="gi">+        return dim_or_data, None</span>
<span class="gi">+    elif isinstance(dim_or_data, pd.Index):</span>
<span class="gi">+        return dim_or_data.name, PandasIndex(dim_or_data)</span>
<span class="gi">+    elif isinstance(dim_or_data, (Variable, DataArray)):</span>
<span class="gi">+        return dim_or_data.name, PandasIndex(dim_or_data.values)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return dim_or_data, None</span>


<span class="w"> </span>def _calc_concat_over(datasets, dim, dim_names, data_vars: T_DataVars,
<span class="gu">@@ -206,7 +230,39 @@ def _calc_concat_over(datasets, dim, dim_names, data_vars: T_DataVars,</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Determine which dataset variables need to be concatenated in the result,
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    concat_over = set()</span>
<span class="gi">+    </span>
<span class="gi">+    if isinstance(data_vars, str):</span>
<span class="gi">+        if data_vars == &#39;all&#39;:</span>
<span class="gi">+            concat_over.update(set().union(*[ds.data_vars for ds in datasets]))</span>
<span class="gi">+        elif data_vars == &#39;minimal&#39;:</span>
<span class="gi">+            concat_over.update(dim_names)</span>
<span class="gi">+        elif data_vars == &#39;different&#39;:</span>
<span class="gi">+            def differs(vname):</span>
<span class="gi">+                return any(not utils.dict_equiv(ds[vname].attrs, datasets[0][vname].attrs)</span>
<span class="gi">+                           or not utils.array_equiv(ds[vname], datasets[0][vname])</span>
<span class="gi">+                           for ds in datasets[1:])</span>
<span class="gi">+            concat_over.update(v for v in set().union(*[ds.data_vars for ds in datasets])</span>
<span class="gi">+                               if differs(v))</span>
<span class="gi">+    elif isinstance(data_vars, list):</span>
<span class="gi">+        concat_over.update(data_vars)</span>
<span class="gi">+    </span>
<span class="gi">+    if isinstance(coords, str):</span>
<span class="gi">+        if coords == &#39;minimal&#39;:</span>
<span class="gi">+            concat_over.update(k for k in dim_names if k in datasets[0].coords)</span>
<span class="gi">+        elif coords == &#39;different&#39;:</span>
<span class="gi">+            def differs(vname):</span>
<span class="gi">+                return any(not utils.dict_equiv(ds[vname].attrs, datasets[0][vname].attrs)</span>
<span class="gi">+                           or not utils.array_equiv(ds[vname], datasets[0][vname])</span>
<span class="gi">+                           for ds in datasets[1:])</span>
<span class="gi">+            concat_over.update(v for v in set().union(*[ds.coords for ds in datasets])</span>
<span class="gi">+                               if differs(v))</span>
<span class="gi">+        elif coords == &#39;all&#39;:</span>
<span class="gi">+            concat_over.update(set().union(*[ds.coords for ds in datasets]))</span>
<span class="gi">+    elif isinstance(coords, list):</span>
<span class="gi">+        concat_over.update(coords)</span>
<span class="gi">+    </span>
<span class="gi">+    return concat_over</span>


<span class="w"> </span>def _dataset_concat(datasets: Iterable[T_Dataset], dim: (str | T_Variable |
<span class="gu">@@ -218,4 +274,31 @@ def _dataset_concat(datasets: Iterable[T_Dataset], dim: (str | T_Variable |</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Concatenate a sequence of datasets along a new or existing dimension
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    datasets = list(datasets)</span>
<span class="gi">+    if not datasets:</span>
<span class="gi">+        raise ValueError(&quot;Need at least one dataset to concatenate&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    dim_name, dim_index = _calc_concat_dim_index(dim)</span>
<span class="gi">+    dim_names = [dim_name] if dim_name not in datasets[0].dims else []</span>
<span class="gi">+    concat_over = _calc_concat_over(datasets, dim, dim_names, data_vars, coords, compat)</span>
<span class="gi">+</span>
<span class="gi">+    def process_variable(name, variables):</span>
<span class="gi">+        if name in concat_over:</span>
<span class="gi">+            return concat_vars(variables, dim=dim, positions=positions, fill_value=fill_value)</span>
<span class="gi">+        else:</span>
<span class="gi">+            return variables[0]</span>
<span class="gi">+</span>
<span class="gi">+    variables = {}</span>
<span class="gi">+    for name in set().union(*[ds.variables for ds in datasets]):</span>
<span class="gi">+        variables[name] = process_variable(name, [ds[name] for ds in datasets if name in ds])</span>
<span class="gi">+</span>
<span class="gi">+    coord_names = set().union(*[ds.coords for ds in datasets])</span>
<span class="gi">+    attrs = merge_attrs([ds.attrs for ds in datasets], combine_attrs)</span>
<span class="gi">+</span>
<span class="gi">+    result = Dataset(variables, attrs=attrs)</span>
<span class="gi">+    result = result.set_coords(coord_names.intersection(variables))</span>
<span class="gi">+</span>
<span class="gi">+    if create_index_for_new_dim and dim_index is not None:</span>
<span class="gi">+        result = result.assign_coords({dim_name: dim_index})</span>
<span class="gi">+</span>
<span class="gi">+    return result</span>
<span class="gh">diff --git a/xarray/core/coordinates.py b/xarray/core/coordinates.py</span>
<span class="gh">index 2740e51a..16773592 100644</span>
<span class="gd">--- a/xarray/core/coordinates.py</span>
<span class="gi">+++ b/xarray/core/coordinates.py</span>
<span class="gu">@@ -36,14 +36,14 @@ class AbstractCoordinates(Mapping[Hashable, &#39;T_DataArray&#39;]):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        Coordinates.xindexes
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return Indexes({k: v.to_pandas_index() for k, v in self.xindexes.items()})</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def xindexes(self) -&gt;Indexes[Index]:
<span class="w"> </span>        &quot;&quot;&quot;Mapping of :py:class:`~xarray.indexes.Index` objects
<span class="w"> </span>        used for label based indexing.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._data.xindexes</span>

<span class="w"> </span>    def __iter__(self) -&gt;Iterator[Hashable]:
<span class="w"> </span>        for k in self.variables:
<span class="gu">@@ -76,7 +76,12 @@ class AbstractCoordinates(Mapping[Hashable, &#39;T_DataArray&#39;]):</span>
<span class="w"> </span>            coordinates. This will be a MultiIndex if this object is has more
<span class="w"> </span>            than more dimension.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if ordered_dims is None:</span>
<span class="gi">+            ordered_dims = list(self.dims)</span>
<span class="gi">+        indexes = [self.indexes[dim] for dim in ordered_dims]</span>
<span class="gi">+        if len(indexes) == 1:</span>
<span class="gi">+            return indexes[0]</span>
<span class="gi">+        return pd.MultiIndex.from_product(indexes, names=ordered_dims)</span>


<span class="w"> </span>class Coordinates(AbstractCoordinates):
<span class="gu">@@ -228,17 +233,23 @@ class Coordinates(AbstractCoordinates):</span>
<span class="w"> </span>            A collection of Xarray indexed coordinates created from the multi-index.

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        coords = {}</span>
<span class="gi">+        coords[dim] = midx</span>
<span class="gi">+        for i, name in enumerate(midx.names):</span>
<span class="gi">+            if name is None:</span>
<span class="gi">+                name = f&quot;{dim}_level_{i}&quot;</span>
<span class="gi">+            coords[name] = (dim, midx.get_level_values(i))</span>
<span class="gi">+        return cls(coords)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def dims(self) -&gt;(Frozen[Hashable, int] | tuple[Hashable, ...]):
<span class="w"> </span>        &quot;&quot;&quot;Mapping from dimension names to lengths or tuple of dimension names.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._data.dims</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def sizes(self) -&gt;Frozen[Hashable, int]:
<span class="w"> </span>        &quot;&quot;&quot;Mapping from dimension names to lengths.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return Frozen(self._data.sizes)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def dtypes(self) -&gt;Frozen[Hashable, np.dtype]:
<span class="gu">@@ -250,7 +261,7 @@ class Coordinates(AbstractCoordinates):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        Dataset.dtypes
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return Frozen({k: v.dtype for k, v in self.variables.items()})</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def variables(self) -&gt;Mapping[Hashable, Variable]:
<span class="gu">@@ -262,7 +273,7 @@ class Coordinates(AbstractCoordinates):</span>

<span class="w"> </span>    def to_dataset(self) -&gt;Dataset:
<span class="w"> </span>        &quot;&quot;&quot;Convert these coordinates into a new Dataset.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._data.copy()</span>

<span class="w"> </span>    def __getitem__(self, key: Hashable) -&gt;DataArray:
<span class="w"> </span>        return self._data[key]
<span class="gu">@@ -278,7 +289,7 @@ class Coordinates(AbstractCoordinates):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        Coordinates.identical
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._data.equals(other._data)</span>

<span class="w"> </span>    def identical(self, other: Self) -&gt;bool:
<span class="w"> </span>        &quot;&quot;&quot;Like equals, but also checks all variable attributes.
<span class="gu">@@ -287,7 +298,7 @@ class Coordinates(AbstractCoordinates):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        Coordinates.equals
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._data.identical(other._data)</span>

<span class="w"> </span>    def _merge_raw(self, other, reflexive):
<span class="w"> </span>        &quot;&quot;&quot;For use with binary arithmetic.&quot;&quot;&quot;
<span class="gh">diff --git a/xarray/core/dask_array_ops.py b/xarray/core/dask_array_ops.py</span>
<span class="gh">index e551b759..10321660 100644</span>
<span class="gd">--- a/xarray/core/dask_array_ops.py</span>
<span class="gi">+++ b/xarray/core/dask_array_ops.py</span>
<span class="gu">@@ -4,11 +4,29 @@ from xarray.core import dtypes, nputils</span>

<span class="w"> </span>def dask_rolling_wrapper(moving_func, a, window, min_count=None, axis=-1):
<span class="w"> </span>    &quot;&quot;&quot;Wrapper to apply bottleneck moving window funcs on dask arrays&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import dask.array as da</span>
<span class="gi">+    import numpy as np</span>
<span class="gi">+</span>
<span class="gi">+    if min_count is None:</span>
<span class="gi">+        min_count = window</span>
<span class="gi">+</span>
<span class="gi">+    def wrapped_func(x):</span>
<span class="gi">+        return moving_func(x, window, min_count=min_count, axis=axis)</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(a, da.Array):</span>
<span class="gi">+        return a.map_overlap(wrapped_func, depth={axis: window - 1}, boundary=&#39;reflect&#39;)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return wrapped_func(np.asarray(a))</span>


<span class="w"> </span>def push(array, n, axis):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Dask-aware bottleneck.push
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import dask.array as da</span>
<span class="gi">+    import bottleneck as bn</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(array, da.Array):</span>
<span class="gi">+        return da.map_overlap(bn.push, array, n=n, axis=axis, depth={axis: n}, boundary=&#39;reflect&#39;)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return bn.push(array, n=n, axis=axis)</span>
<span class="gh">diff --git a/xarray/core/datatree.py b/xarray/core/datatree.py</span>
<span class="gh">index 397a6531..60a91748 100644</span>
<span class="gd">--- a/xarray/core/datatree.py</span>
<span class="gi">+++ b/xarray/core/datatree.py</span>
<span class="gu">@@ -384,7 +384,10 @@ class DataTree(NamedNode, MappedDatasetMethodsMixin, MappedDataWithCoords,</span>
<span class="w"> </span>        xarray.Dataset.copy
<span class="w"> </span>        pandas.DataFrame.copy
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        new_tree = self._copy_node(deep)</span>
<span class="gi">+        for child_name, child_node in self._children.items():</span>
<span class="gi">+            new_tree._children[child_name] = child_node.copy(deep)</span>
<span class="gi">+        return new_tree</span>

<span class="w"> </span>    def _copy_subtree(self: DataTree, deep: bool=False, memo: (dict[int,
<span class="w"> </span>        Any] | None)=None) -&gt;DataTree:
<span class="gu">@@ -393,7 +396,15 @@ class DataTree(NamedNode, MappedDatasetMethodsMixin, MappedDataWithCoords,</span>

<span class="w"> </span>    def _copy_node(self: DataTree, deep: bool=False) -&gt;DataTree:
<span class="w"> </span>        &quot;&quot;&quot;Copy just one node of a tree&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        new_node = DataTree(name=self._name)</span>
<span class="gi">+        new_node._data_variables = self._data_variables.copy(deep=deep)</span>
<span class="gi">+        new_node._node_coord_variables = self._node_coord_variables.copy(deep=deep)</span>
<span class="gi">+        new_node._node_dims = self._node_dims.copy()</span>
<span class="gi">+        new_node._node_indexes = self._node_indexes.copy()</span>
<span class="gi">+        new_node._attrs = self._attrs.copy() if self._attrs is not None else None</span>
<span class="gi">+        new_node._encoding = self._encoding.copy() if self._encoding is not None else None</span>
<span class="gi">+        new_node._close = self._close</span>
<span class="gi">+        return new_node</span>

<span class="w"> </span>    def __copy__(self: DataTree) -&gt;DataTree:
<span class="w"> </span>        return self._copy_subtree(deep=False)
<span class="gu">@@ -417,7 +428,14 @@ class DataTree(NamedNode, MappedDatasetMethodsMixin, MappedDataWithCoords,</span>
<span class="w"> </span>        default : DataTree | DataArray | None, optional
<span class="w"> </span>            A value to return if the specified key does not exist. Default return value is None.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if key in self._children:</span>
<span class="gi">+            return self._children[key]</span>
<span class="gi">+        elif key in self._data_variables:</span>
<span class="gi">+            return DataArray(self._data_variables[key])</span>
<span class="gi">+        elif key in self._node_coord_variables:</span>
<span class="gi">+            return DataArray(self._node_coord_variables[key])</span>
<span class="gi">+        else:</span>
<span class="gi">+            return default</span>

<span class="w"> </span>    def __getitem__(self: DataTree, key: str) -&gt;(DataTree | DataArray):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -472,6 +490,24 @@ class DataTree(NamedNode, MappedDatasetMethodsMixin, MappedDataWithCoords,</span>
<span class="w"> </span>        else:
<span class="w"> </span>            raise ValueError(&#39;Invalid format for key&#39;)

<span class="gi">+    def _set_item(self, path: NodePath, value: Any, new_nodes_along_path: bool = False) -&gt; None:</span>
<span class="gi">+        if len(path) == 1:</span>
<span class="gi">+            if isinstance(value, DataTree):</span>
<span class="gi">+                self._children[path[0]] = value</span>
<span class="gi">+            elif isinstance(value, Dataset):</span>
<span class="gi">+                self._children[path[0]] = DataTree(value)</span>
<span class="gi">+            elif isinstance(value, DataArray):</span>
<span class="gi">+                self._data_variables[path[0]] = value.variable</span>
<span class="gi">+            else:</span>
<span class="gi">+                self._data_variables[path[0]] = Variable((), value)</span>
<span class="gi">+        else:</span>
<span class="gi">+            if path[0] not in self._children:</span>
<span class="gi">+                if new_nodes_along_path:</span>
<span class="gi">+                    self._children[path[0]] = DataTree()</span>
<span class="gi">+                else:</span>
<span class="gi">+                    raise KeyError(f&quot;Node &#39;{path[0]}&#39; does not exist&quot;)</span>
<span class="gi">+            self._children[path[0]]._set_item(path[1:], value, new_nodes_along_path)</span>
<span class="gi">+</span>
<span class="w"> </span>    def update(self, other: (Dataset | Mapping[Hashable, DataArray |
<span class="w"> </span>        Variable] | Mapping[str, DataTree | DataArray | Variable])) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gh">diff --git a/xarray/core/datatree_io.py b/xarray/core/datatree_io.py</span>
<span class="gh">index ac9c6ad9..c1f715e6 100644</span>
<span class="gd">--- a/xarray/core/datatree_io.py</span>
<span class="gi">+++ b/xarray/core/datatree_io.py</span>
<span class="gu">@@ -18,7 +18,34 @@ def _datatree_to_netcdf(dt: DataTree, filepath: (str | PathLike), mode:</span>

<span class="w"> </span>    See `DataTree.to_netcdf` for full API docs.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import xarray as xr</span>
<span class="gi">+    from xarray.backends.api import to_netcdf</span>
<span class="gi">+</span>
<span class="gi">+    # Create a new Dataset to hold all the data from the DataTree</span>
<span class="gi">+    combined_dataset = xr.Dataset()</span>
<span class="gi">+</span>
<span class="gi">+    def add_to_dataset(node, path):</span>
<span class="gi">+        for var_name, var in node.data_vars.items():</span>
<span class="gi">+            full_name = f&quot;{path}/{var_name}&quot; if path else var_name</span>
<span class="gi">+            combined_dataset[full_name] = var</span>
<span class="gi">+        for child_name, child_node in node.children.items():</span>
<span class="gi">+            add_to_dataset(child_node, f&quot;{path}/{child_name}&quot; if path else child_name)</span>
<span class="gi">+</span>
<span class="gi">+    add_to_dataset(dt, &quot;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # Use xarray&#39;s to_netcdf function to write the combined dataset</span>
<span class="gi">+    to_netcdf(</span>
<span class="gi">+        combined_dataset,</span>
<span class="gi">+        filepath,</span>
<span class="gi">+        mode=mode,</span>
<span class="gi">+        encoding=encoding,</span>
<span class="gi">+        unlimited_dims=unlimited_dims,</span>
<span class="gi">+        format=format,</span>
<span class="gi">+        engine=engine,</span>
<span class="gi">+        group=group,</span>
<span class="gi">+        compute=compute,</span>
<span class="gi">+        **kwargs</span>
<span class="gi">+    )</span>


<span class="w"> </span>def _datatree_to_zarr(dt: DataTree, store: (MutableMapping | str | PathLike
<span class="gu">@@ -30,4 +57,39 @@ def _datatree_to_zarr(dt: DataTree, store: (MutableMapping | str | PathLike</span>

<span class="w"> </span>    See `DataTree.to_zarr` for full API docs.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import zarr</span>
<span class="gi">+    from xarray.backends.api import to_zarr</span>
<span class="gi">+</span>
<span class="gi">+    def write_node(node, group):</span>
<span class="gi">+        # Write the current node&#39;s data to the group</span>
<span class="gi">+        to_zarr(</span>
<span class="gi">+            node,</span>
<span class="gi">+            store=group,</span>
<span class="gi">+            mode=&#39;w&#39;,</span>
<span class="gi">+            encoding=encoding,</span>
<span class="gi">+            consolidated=consolidated,</span>
<span class="gi">+            compute=compute,</span>
<span class="gi">+            **kwargs</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        # Recursively write child nodes</span>
<span class="gi">+        for child_name, child_node in node.children.items():</span>
<span class="gi">+            child_group = group.create_group(child_name)</span>
<span class="gi">+            write_node(child_node, child_group)</span>
<span class="gi">+</span>
<span class="gi">+    # Create or open the root group</span>
<span class="gi">+    if isinstance(store, (str, PathLike)):</span>
<span class="gi">+        root = zarr.open_group(store, mode=mode)</span>
<span class="gi">+    else:</span>
<span class="gi">+        root = zarr.group(store=store)</span>
<span class="gi">+</span>
<span class="gi">+    # If a specific group is specified, create or get it</span>
<span class="gi">+    if group:</span>
<span class="gi">+        root = root.create_group(group) if group not in root else root[group]</span>
<span class="gi">+</span>
<span class="gi">+    # Start the recursive writing process</span>
<span class="gi">+    write_node(dt, root)</span>
<span class="gi">+</span>
<span class="gi">+    # Consolidate metadata if requested</span>
<span class="gi">+    if consolidated:</span>
<span class="gi">+        zarr.consolidate_metadata(store)</span>
<span class="gh">diff --git a/xarray/core/datatree_mapping.py b/xarray/core/datatree_mapping.py</span>
<span class="gh">index bb01488b..74de38c0 100644</span>
<span class="gd">--- a/xarray/core/datatree_mapping.py</span>
<span class="gi">+++ b/xarray/core/datatree_mapping.py</span>
<span class="gu">@@ -47,7 +47,24 @@ def check_isomorphic(a: DataTree, b: DataTree, require_names_equal: bool=</span>
<span class="w"> </span>        Also optionally raised if their structure is isomorphic, but the names of any two
<span class="w"> </span>        respective nodes are not equal.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not isinstance(a, TreeNode) or not isinstance(b, TreeNode):</span>
<span class="gi">+        raise TypeError(&quot;Both arguments must be tree objects.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if check_from_root:</span>
<span class="gi">+        a = a.root</span>
<span class="gi">+        b = b.root</span>
<span class="gi">+</span>
<span class="gi">+    def check_nodes(node_a, node_b):</span>
<span class="gi">+        if len(node_a.children) != len(node_b.children):</span>
<span class="gi">+            raise TreeIsomorphismError(&quot;Trees are not isomorphic: different number of children.&quot;)</span>
<span class="gi">+        </span>
<span class="gi">+        if require_names_equal and node_a.name != node_b.name:</span>
<span class="gi">+            raise TreeIsomorphismError(f&quot;Node names do not match: {node_a.name} != {node_b.name}&quot;)</span>
<span class="gi">+        </span>
<span class="gi">+        for child_a, child_b in zip(node_a.children.values(), node_b.children.values()):</span>
<span class="gi">+            check_nodes(child_a, child_b)</span>
<span class="gi">+</span>
<span class="gi">+    check_nodes(a, b)</span>


<span class="w"> </span>def map_over_subtree(func: Callable) -&gt;Callable:
<span class="gu">@@ -94,20 +111,87 @@ def map_over_subtree(func: Callable) -&gt;Callable:</span>
<span class="w"> </span>    DataTree.map_over_subtree_inplace
<span class="w"> </span>    DataTree.subtree
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    @functools.wraps(func)</span>
<span class="gi">+    def wrapper(*args, **kwargs):</span>
<span class="gi">+        if not args:</span>
<span class="gi">+            raise ValueError(&quot;At least one DataTree argument is required.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        trees = [arg for arg in args if isinstance(arg, DataTree)]</span>
<span class="gi">+        if not trees:</span>
<span class="gi">+            raise ValueError(&quot;At least one argument must be a DataTree.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        check_isomorphic(*trees)</span>
<span class="gi">+</span>
<span class="gi">+        def apply_to_node(node, *node_args):</span>
<span class="gi">+            if node.ds is not None:</span>
<span class="gi">+                node_args = [arg.ds if isinstance(arg, DataTree) else arg for arg in node_args]</span>
<span class="gi">+                result = func(*node_args, **kwargs)</span>
<span class="gi">+                return result</span>
<span class="gi">+            return None</span>
<span class="gi">+</span>
<span class="gi">+        def map_tree(tree, *other_trees):</span>
<span class="gi">+            new_tree = type(tree)()</span>
<span class="gi">+            for name, node in tree.children.items():</span>
<span class="gi">+                other_nodes = [other_tree[name] for other_tree in other_trees]</span>
<span class="gi">+                result = apply_to_node(node, *other_nodes)</span>
<span class="gi">+                if result is not None:</span>
<span class="gi">+                    new_tree[name] = result</span>
<span class="gi">+                child_result = map_tree(node, *other_nodes)</span>
<span class="gi">+                if child_result.children:</span>
<span class="gi">+                    new_tree[name] = child_result</span>
<span class="gi">+            return new_tree</span>
<span class="gi">+</span>
<span class="gi">+        return map_tree(*trees)</span>
<span class="gi">+</span>
<span class="gi">+    return wrapper</span>


<span class="w"> </span>def _handle_errors_with_path_context(path: str):
<span class="w"> </span>    &quot;&quot;&quot;Wraps given function so that if it fails it also raises path to node on which it failed.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    def decorator(func):</span>
<span class="gi">+        @functools.wraps(func)</span>
<span class="gi">+        def wrapper(*args, **kwargs):</span>
<span class="gi">+            try:</span>
<span class="gi">+                return func(*args, **kwargs)</span>
<span class="gi">+            except Exception as e:</span>
<span class="gi">+                raise type(e)(f&quot;Error at path &#39;{path}&#39;: {str(e)}&quot;) from e</span>
<span class="gi">+        return wrapper</span>
<span class="gi">+    return decorator</span>


<span class="w"> </span>def _check_single_set_return_values(path_to_node: str, obj: (Dataset |
<span class="w"> </span>    DataArray | tuple[Dataset | DataArray])):
<span class="w"> </span>    &quot;&quot;&quot;Check types returned from single evaluation of func, and return number of return values received from func.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(obj, (Dataset, DataArray)):</span>
<span class="gi">+        return 1</span>
<span class="gi">+    elif isinstance(obj, tuple):</span>
<span class="gi">+        if all(isinstance(item, (Dataset, DataArray)) for item in obj):</span>
<span class="gi">+            return len(obj)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise TypeError(f&quot;At path &#39;{path_to_node}&#39;: All items in the returned tuple must be Dataset or DataArray.&quot;)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(f&quot;At path &#39;{path_to_node}&#39;: Return value must be Dataset, DataArray, or tuple of these types.&quot;)</span>


<span class="w"> </span>def _check_all_return_values(returned_objects):
<span class="w"> </span>    &quot;&quot;&quot;Walk through all values returned by mapping func over subtrees, raising on any invalid or inconsistent types.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not returned_objects:</span>
<span class="gi">+        return</span>
<span class="gi">+</span>
<span class="gi">+    first_item = next(iter(returned_objects.values()))</span>
<span class="gi">+    expected_type = type(first_item)</span>
<span class="gi">+    expected_length = len(first_item) if isinstance(first_item, tuple) else 1</span>
<span class="gi">+</span>
<span class="gi">+    for path, obj in returned_objects.items():</span>
<span class="gi">+        if not isinstance(obj, expected_type):</span>
<span class="gi">+            raise TypeError(f&quot;Inconsistent return types: expected {expected_type}, got {type(obj)} at path &#39;{path}&#39;&quot;)</span>
<span class="gi">+        </span>
<span class="gi">+        if isinstance(obj, tuple):</span>
<span class="gi">+            if len(obj) != expected_length:</span>
<span class="gi">+                raise ValueError(f&quot;Inconsistent number of return values: expected {expected_length}, got {len(obj)} at path &#39;{path}&#39;&quot;)</span>
<span class="gi">+            </span>
<span class="gi">+            for item in obj:</span>
<span class="gi">+                if not isinstance(item, (Dataset, DataArray)):</span>
<span class="gi">+                    raise TypeError(f&quot;Invalid return type in tuple: expected Dataset or DataArray, got {type(item)} at path &#39;{path}&#39;&quot;)</span>
<span class="gi">+        elif not isinstance(obj, (Dataset, DataArray)):</span>
<span class="gi">+            raise TypeError(f&quot;Invalid return type: expected Dataset or DataArray, got {type(obj)} at path &#39;{path}&#39;&quot;)</span>
<span class="gh">diff --git a/xarray/core/datatree_ops.py b/xarray/core/datatree_ops.py</span>
<span class="gh">index 77c69078..e7dee3da 100644</span>
<span class="gd">--- a/xarray/core/datatree_ops.py</span>
<span class="gi">+++ b/xarray/core/datatree_ops.py</span>
<span class="gu">@@ -73,7 +73,14 @@ def _wrap_then_attach_to_cls(target_cls_dict, source_cls, methods_to_set,</span>
<span class="w"> </span>    wrap_func : callable, optional
<span class="w"> </span>        Function to decorate each method with. Must have the same return type as the method.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    for method_name, method in methods_to_set:</span>
<span class="gi">+        if hasattr(source_cls, method_name):</span>
<span class="gi">+            source_method = getattr(source_cls, method_name)</span>
<span class="gi">+            if wrap_func:</span>
<span class="gi">+                wrapped_method = wrap_func(source_method)</span>
<span class="gi">+            else:</span>
<span class="gi">+                wrapped_method = source_method</span>
<span class="gi">+            target_cls_dict[method_name] = wrapped_method</span>


<span class="w"> </span>def insert_doc_addendum(docstring: (str | None), addendum: str) -&gt;(str | None):
<span class="gu">@@ -86,7 +93,18 @@ def insert_doc_addendum(docstring: (str | None), addendum: str) -&gt;(str | None):</span>
<span class="w"> </span>    don&#39;t, just have the addendum appeneded after. None values are returned.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if docstring is None:</span>
<span class="gi">+        return None</span>
<span class="gi">+</span>
<span class="gi">+    lines = docstring.split(&#39;\n&#39;)</span>
<span class="gi">+    first_empty_line = next((i for i, line in enumerate(lines) if not line.strip()), len(lines))</span>
<span class="gi">+</span>
<span class="gi">+    if first_empty_line == len(lines):</span>
<span class="gi">+        # No empty line found, append addendum at the end</span>
<span class="gi">+        return f&quot;{docstring}\n\n{addendum}&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        # Insert addendum after the first paragraph</span>
<span class="gi">+        return &#39;\n&#39;.join(lines[:first_empty_line] + [&#39;&#39;, addendum] + lines[first_empty_line:])</span>


<span class="w"> </span>class MappedDatasetMethodsMixin:
<span class="gh">diff --git a/xarray/core/datatree_render.py b/xarray/core/datatree_render.py</span>
<span class="gh">index 184464bb..38bfee48 100644</span>
<span class="gd">--- a/xarray/core/datatree_render.py</span>
<span class="gi">+++ b/xarray/core/datatree_render.py</span>
<span class="gu">@@ -34,7 +34,7 @@ class AbstractStyle:</span>
<span class="w"> </span>    @property
<span class="w"> </span>    def empty(self) -&gt;str:
<span class="w"> </span>        &quot;&quot;&quot;Empty string as placeholder.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return &quot; &quot; * len(self.vertical)</span>

<span class="w"> </span>    def __repr__(self) -&gt;str:
<span class="w"> </span>        return f&#39;{self.__class__.__name__}()&#39;
<span class="gu">@@ -195,4 +195,9 @@ class RenderDataTree:</span>
<span class="w"> </span>            └── sub1C
<span class="w"> </span>                └── sub1Ca
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        lines = []</span>
<span class="gi">+        for pre, _, node in self:</span>
<span class="gi">+            attr = getattr(node, attrname, None)</span>
<span class="gi">+            if attr is not None:</span>
<span class="gi">+                lines.append(f&quot;{pre}{attr}&quot;)</span>
<span class="gi">+        return &quot;\n&quot;.join(lines)</span>
<span class="gh">diff --git a/xarray/core/dtypes.py b/xarray/core/dtypes.py</span>
<span class="gh">index 217e8240..2809313c 100644</span>
<span class="gd">--- a/xarray/core/dtypes.py</span>
<span class="gi">+++ b/xarray/core/dtypes.py</span>
<span class="gu">@@ -45,7 +45,16 @@ def maybe_promote(dtype: np.dtype) -&gt;tuple[np.dtype, Any]:</span>
<span class="w"> </span>    dtype : Promoted dtype that can hold missing values.
<span class="w"> </span>    fill_value : Valid missing value for the promoted dtype.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if dtype.kind in &quot;mM&quot;:</span>
<span class="gi">+        return dtype, np.datetime64(&quot;NaT&quot;)</span>
<span class="gi">+    elif dtype.kind == &quot;f&quot;:</span>
<span class="gi">+        return dtype, np.nan</span>
<span class="gi">+    elif dtype.kind in &quot;iu&quot;:</span>
<span class="gi">+        return np.dtype(&quot;float64&quot;), np.nan</span>
<span class="gi">+    elif dtype.kind == &quot;b&quot;:</span>
<span class="gi">+        return np.dtype(&quot;object&quot;), NA</span>
<span class="gi">+    else:</span>
<span class="gi">+        return np.dtype(&quot;object&quot;), NA</span>


<span class="w"> </span>NAT_TYPES = {np.datetime64(&#39;NaT&#39;).dtype, np.timedelta64(&#39;NaT&#39;).dtype}
<span class="gu">@@ -62,7 +71,17 @@ def get_fill_value(dtype):</span>
<span class="w"> </span>    -------
<span class="w"> </span>    fill_value : Missing value corresponding to this dtype.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    dtype = np.dtype(dtype)</span>
<span class="gi">+    if dtype.kind in &quot;mM&quot;:</span>
<span class="gi">+        return np.datetime64(&quot;NaT&quot;)</span>
<span class="gi">+    elif dtype.kind == &quot;f&quot;:</span>
<span class="gi">+        return np.nan</span>
<span class="gi">+    elif dtype.kind in &quot;iu&quot;:</span>
<span class="gi">+        return np.iinfo(dtype).min</span>
<span class="gi">+    elif dtype.kind == &quot;b&quot;:</span>
<span class="gi">+        return False</span>
<span class="gi">+    else:</span>
<span class="gi">+        return NA</span>


<span class="w"> </span>def get_pos_infinity(dtype, max_for_int=False):
<span class="gu">@@ -78,11 +97,19 @@ def get_pos_infinity(dtype, max_for_int=False):</span>
<span class="w"> </span>    -------
<span class="w"> </span>    fill_value : positive infinity value corresponding to this dtype.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    dtype = np.dtype(dtype)</span>
<span class="gi">+    if dtype.kind == &quot;f&quot;:</span>
<span class="gi">+        return np.inf</span>
<span class="gi">+    elif dtype.kind in &quot;iu&quot;:</span>
<span class="gi">+        return np.iinfo(dtype).max if max_for_int else np.inf</span>
<span class="gi">+    elif dtype.kind in &quot;mM&quot;:</span>
<span class="gi">+        return INF</span>
<span class="gi">+    else:</span>
<span class="gi">+        return INF</span>


<span class="w"> </span>def get_neg_infinity(dtype, min_for_int=False):
<span class="gd">-    &quot;&quot;&quot;Return an appropriate positive infinity for this dtype.</span>
<span class="gi">+    &quot;&quot;&quot;Return an appropriate negative infinity for this dtype.</span>

<span class="w"> </span>    Parameters
<span class="w"> </span>    ----------
<span class="gu">@@ -92,24 +119,32 @@ def get_neg_infinity(dtype, min_for_int=False):</span>

<span class="w"> </span>    Returns
<span class="w"> </span>    -------
<span class="gd">-    fill_value : positive infinity value corresponding to this dtype.</span>
<span class="gi">+    fill_value : negative infinity value corresponding to this dtype.</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    dtype = np.dtype(dtype)</span>
<span class="gi">+    if dtype.kind == &quot;f&quot;:</span>
<span class="gi">+        return -np.inf</span>
<span class="gi">+    elif dtype.kind in &quot;iu&quot;:</span>
<span class="gi">+        return np.iinfo(dtype).min if min_for_int else -np.inf</span>
<span class="gi">+    elif dtype.kind in &quot;mM&quot;:</span>
<span class="gi">+        return NINF</span>
<span class="gi">+    else:</span>
<span class="gi">+        return NINF</span>


<span class="w"> </span>def is_datetime_like(dtype) -&gt;bool:
<span class="w"> </span>    &quot;&quot;&quot;Check if a dtype is a subclass of the numpy datetime types&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return np.issubdtype(dtype, np.datetime64) or np.issubdtype(dtype, np.timedelta64)</span>


<span class="w"> </span>def is_object(dtype) -&gt;bool:
<span class="w"> </span>    &quot;&quot;&quot;Check if a dtype is object&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return np.issubdtype(dtype, np.object_)</span>


<span class="w"> </span>def is_string(dtype) -&gt;bool:
<span class="w"> </span>    &quot;&quot;&quot;Check if a dtype is a string dtype&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return np.issubdtype(dtype, np.str_) or np.issubdtype(dtype, np.bytes_)</span>


<span class="w"> </span>def isdtype(dtype, kind: (str | tuple[str, ...]), xp=None) -&gt;bool:
<span class="gu">@@ -117,7 +152,13 @@ def isdtype(dtype, kind: (str | tuple[str, ...]), xp=None) -&gt;bool:</span>

<span class="w"> </span>    Unlike xp.isdtype(), kind must be a string.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if xp is None:</span>
<span class="gi">+        xp = array_api_compat.get_namespace(dtype)</span>
<span class="gi">+    </span>
<span class="gi">+    if isinstance(kind, str):</span>
<span class="gi">+        kind = (kind,)</span>
<span class="gi">+    </span>
<span class="gi">+    return any(xp.isdtype(dtype, k) for k in kind)</span>


<span class="w"> </span>def result_type(*arrays_and_dtypes: (np.typing.ArrayLike | np.typing.
<span class="gu">@@ -137,4 +178,23 @@ def result_type(*arrays_and_dtypes: (np.typing.ArrayLike | np.typing.</span>
<span class="w"> </span>    -------
<span class="w"> </span>    numpy.dtype for the result.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if xp is None:</span>
<span class="gi">+        xp = array_api_compat.get_namespace(*arrays_and_dtypes)</span>
<span class="gi">+</span>
<span class="gi">+    dtypes = []</span>
<span class="gi">+    for arg in arrays_and_dtypes:</span>
<span class="gi">+        if hasattr(arg, &quot;dtype&quot;):</span>
<span class="gi">+            dtypes.append(arg.dtype)</span>
<span class="gi">+        else:</span>
<span class="gi">+            dtypes.append(np.dtype(arg))</span>
<span class="gi">+</span>
<span class="gi">+    result = np.result_type(*dtypes)</span>
<span class="gi">+</span>
<span class="gi">+    # Apply pandas-like promotion rules</span>
<span class="gi">+    if any(is_string(dt) for dt in dtypes):</span>
<span class="gi">+        if any(dt.kind in &quot;iufc&quot; for dt in dtypes):</span>
<span class="gi">+            return np.dtype(&quot;O&quot;)</span>
<span class="gi">+    if any(dt.kind == &quot;S&quot; for dt in dtypes) and any(dt.kind == &quot;U&quot; for dt in dtypes):</span>
<span class="gi">+        return np.dtype(&quot;O&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    return result</span>
<span class="gh">diff --git a/xarray/core/duck_array_ops.py b/xarray/core/duck_array_ops.py</span>
<span class="gh">index 872667f1..a7222257 100644</span>
<span class="gd">--- a/xarray/core/duck_array_ops.py</span>
<span class="gi">+++ b/xarray/core/duck_array_ops.py</span>
<span class="gu">@@ -34,7 +34,17 @@ dask_available = module_available(&#39;dask&#39;)</span>

<span class="w"> </span>def _dask_or_eager_func(name, eager_module=np, dask_module=&#39;dask.array&#39;):
<span class="w"> </span>    &quot;&quot;&quot;Create a function that dispatches to dask for dask array inputs.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    def wrapper(*args, **kwargs):</span>
<span class="gi">+        if any(is_duck_dask_array(arg) for arg in args):</span>
<span class="gi">+            if isinstance(dask_module, str):</span>
<span class="gi">+                module = import_module(dask_module)</span>
<span class="gi">+            else:</span>
<span class="gi">+                module = dask_module</span>
<span class="gi">+            func = getattr(module, name)</span>
<span class="gi">+        else:</span>
<span class="gi">+            func = getattr(eager_module, name)</span>
<span class="gi">+        return func(*args, **kwargs)</span>
<span class="gi">+    return wrapper</span>


<span class="w"> </span>pandas_isnull = _dask_or_eager_func(&#39;isnull&#39;, eager_module=pd, dask_module=
<span class="gu">@@ -59,7 +69,14 @@ masked_invalid = _dask_or_eager_func(&#39;masked_invalid&#39;, eager_module=np.ma,</span>

<span class="w"> </span>def as_shared_dtype(scalars_or_arrays, xp=None):
<span class="w"> </span>    &quot;&quot;&quot;Cast a arrays to a shared dtype using xarray&#39;s type promotion rules.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if xp is None:</span>
<span class="gi">+        xp = np</span>
<span class="gi">+    arrays = [xp.asarray(x) for x in scalars_or_arrays]</span>
<span class="gi">+    dtypes = [x.dtype for x in arrays]</span>
<span class="gi">+    result_type = dtypes[0]</span>
<span class="gi">+    for dtype in dtypes[1:]:</span>
<span class="gi">+        result_type = np.promote_types(result_type, dtype)</span>
<span class="gi">+    return [xp.asarray(x, dtype=result_type) for x in arrays]</span>


<span class="w"> </span>def lazy_array_equiv(arr1, arr2):
<span class="gu">@@ -69,44 +86,85 @@ def lazy_array_equiv(arr1, arr2):</span>
<span class="w"> </span>    Returns None when equality cannot determined: one or both of arr1, arr2 are numpy arrays;
<span class="w"> </span>    or their dask tokens are not equal
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if arr1 is arr2:</span>
<span class="gi">+        return True</span>
<span class="gi">+    if hasattr(arr1, &#39;shape&#39;) and hasattr(arr2, &#39;shape&#39;):</span>
<span class="gi">+        if arr1.shape != arr2.shape:</span>
<span class="gi">+            return False</span>
<span class="gi">+    if dask_available:</span>
<span class="gi">+        import dask.array as da</span>
<span class="gi">+        if isinstance(arr1, da.Array) and isinstance(arr2, da.Array):</span>
<span class="gi">+            return arr1.name == arr2.name</span>
<span class="gi">+    return None</span>


<span class="w"> </span>def allclose_or_equiv(arr1, arr2, rtol=1e-05, atol=1e-08):
<span class="w"> </span>    &quot;&quot;&quot;Like np.allclose, but also allows values to be NaN in both arrays&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    arr1, arr2 = as_shared_dtype([arr1, arr2])</span>
<span class="gi">+    if array_equiv(arr1, arr2):</span>
<span class="gi">+        return True</span>
<span class="gi">+    with warnings.catch_warnings():</span>
<span class="gi">+        warnings.filterwarnings(&#39;ignore&#39;, r&#39;invalid value encountered in isnan&#39;)</span>
<span class="gi">+        return bool(isclose(arr1, arr2, rtol=rtol, atol=atol, equal_nan=True).all())</span>


<span class="w"> </span>def array_equiv(arr1, arr2):
<span class="w"> </span>    &quot;&quot;&quot;Like np.array_equal, but also allows values to be NaN in both arrays&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    arr1, arr2 = as_shared_dtype([arr1, arr2])</span>
<span class="gi">+    if arr1.shape != arr2.shape:</span>
<span class="gi">+        return False</span>
<span class="gi">+    with warnings.catch_warnings():</span>
<span class="gi">+        warnings.filterwarnings(&#39;ignore&#39;, r&#39;invalid value encountered in isnan&#39;)</span>
<span class="gi">+        return bool(((arr1 == arr2) | (isnan(arr1) &amp; isnan(arr2))).all())</span>


<span class="w"> </span>def array_notnull_equiv(arr1, arr2):
<span class="w"> </span>    &quot;&quot;&quot;Like np.array_equal, but also allows values to be NaN in either or both
<span class="w"> </span>    arrays
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    arr1, arr2 = as_shared_dtype([arr1, arr2])</span>
<span class="gi">+    if arr1.shape != arr2.shape:</span>
<span class="gi">+        return False</span>
<span class="gi">+    with warnings.catch_warnings():</span>
<span class="gi">+        warnings.filterwarnings(&#39;ignore&#39;, r&#39;invalid value encountered in isnan&#39;)</span>
<span class="gi">+        return bool(((arr1 == arr2) | isnan(arr1) | isnan(arr2)).all())</span>


<span class="w"> </span>def count(data, axis=None):
<span class="w"> </span>    &quot;&quot;&quot;Count the number of non-NA in this array along the given axis or axes&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return sum(~pandas_isnull(data), axis=axis)</span>


<span class="w"> </span>def where(condition, x, y):
<span class="w"> </span>    &quot;&quot;&quot;Three argument where() with better dtype promotion rules.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return _where(condition, *as_shared_dtype([x, y]))</span>
<span class="gi">+</span>
<span class="gi">+def _where(condition, x, y):</span>
<span class="gi">+    if hasattr(x, &#39;where&#39;):</span>
<span class="gi">+        return x.where(condition, y)</span>
<span class="gi">+    return np.where(condition, x, y)</span>


<span class="w"> </span>def concatenate(arrays, axis=0):
<span class="w"> </span>    &quot;&quot;&quot;concatenate() with better dtype promotion rules.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    arrays = as_shared_dtype(arrays)</span>
<span class="gi">+    if all(isinstance(arr, np.ndarray) for arr in arrays):</span>
<span class="gi">+        return _concatenate(arrays, axis=axis)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return get_chunked_array_type(arrays)(</span>
<span class="gi">+            _concatenate, arrays, axis=axis</span>
<span class="gi">+        )</span>


<span class="w"> </span>def stack(arrays, axis=0):
<span class="w"> </span>    &quot;&quot;&quot;stack() with better dtype promotion rules.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    arrays = as_shared_dtype(arrays)</span>
<span class="gi">+    if all(isinstance(arr, np.ndarray) for arr in arrays):</span>
<span class="gi">+        return np.stack(arrays, axis=axis)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return get_chunked_array_type(arrays)(</span>
<span class="gi">+            np.stack, arrays, axis=axis</span>
<span class="gi">+        )</span>


<span class="w"> </span>argmax = _create_nan_agg_method(&#39;argmax&#39;, coerce_strings=True)
<span class="gh">diff --git a/xarray/core/extension_array.py b/xarray/core/extension_array.py</span>
<span class="gh">index cf1511fe..aaa71b52 100644</span>
<span class="gd">--- a/xarray/core/extension_array.py</span>
<span class="gi">+++ b/xarray/core/extension_array.py</span>
<span class="gu">@@ -10,7 +10,10 @@ HANDLED_EXTENSION_ARRAY_FUNCTIONS: dict[Callable, Callable] = {}</span>

<span class="w"> </span>def implements(numpy_function):
<span class="w"> </span>    &quot;&quot;&quot;Register an __array_function__ implementation for MyArray objects.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    def decorator(func):</span>
<span class="gi">+        HANDLED_EXTENSION_ARRAY_FUNCTIONS[numpy_function] = func</span>
<span class="gi">+        return func</span>
<span class="gi">+    return decorator</span>


<span class="w"> </span>class PandasExtensionArray(Generic[T_ExtensionArray]):
<span class="gh">diff --git a/xarray/core/extensions.py b/xarray/core/extensions.py</span>
<span class="gh">index c7897a61..c74a1ba3 100644</span>
<span class="gd">--- a/xarray/core/extensions.py</span>
<span class="gi">+++ b/xarray/core/extensions.py</span>
<span class="gu">@@ -48,7 +48,16 @@ def register_dataarray_accessor(name):</span>
<span class="w"> </span>    --------
<span class="w"> </span>    register_dataset_accessor
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    def decorator(accessor):</span>
<span class="gi">+        if hasattr(DataArray, name):</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                f&quot;registration of accessor {name!r} under name {name!r} for type {DataArray.__name__!r} is overriding a preexisting attribute with the same name.&quot;,</span>
<span class="gi">+                AccessorRegistrationWarning,</span>
<span class="gi">+                stacklevel=2</span>
<span class="gi">+            )</span>
<span class="gi">+        setattr(DataArray, name, _CachedAccessor(name, accessor))</span>
<span class="gi">+        return accessor</span>
<span class="gi">+    return decorator</span>


<span class="w"> </span>def register_dataset_accessor(name):
<span class="gu">@@ -94,7 +103,16 @@ def register_dataset_accessor(name):</span>
<span class="w"> </span>    --------
<span class="w"> </span>    register_dataarray_accessor
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    def decorator(accessor):</span>
<span class="gi">+        if hasattr(Dataset, name):</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                f&quot;registration of accessor {name!r} under name {name!r} for type {Dataset.__name__!r} is overriding a preexisting attribute with the same name.&quot;,</span>
<span class="gi">+                AccessorRegistrationWarning,</span>
<span class="gi">+                stacklevel=2</span>
<span class="gi">+            )</span>
<span class="gi">+        setattr(Dataset, name, _CachedAccessor(name, accessor))</span>
<span class="gi">+        return accessor</span>
<span class="gi">+    return decorator</span>


<span class="w"> </span>def register_datatree_accessor(name):
<span class="gu">@@ -111,4 +129,13 @@ def register_datatree_accessor(name):</span>
<span class="w"> </span>    xarray.register_dataarray_accessor
<span class="w"> </span>    xarray.register_dataset_accessor
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    def decorator(accessor):</span>
<span class="gi">+        if hasattr(DataTree, name):</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                f&quot;registration of accessor {name!r} under name {name!r} for type {DataTree.__name__!r} is overriding a preexisting attribute with the same name.&quot;,</span>
<span class="gi">+                AccessorRegistrationWarning,</span>
<span class="gi">+                stacklevel=2</span>
<span class="gi">+            )</span>
<span class="gi">+        setattr(DataTree, name, _CachedAccessor(name, accessor))</span>
<span class="gi">+        return accessor</span>
<span class="gi">+    return decorator</span>
<span class="gh">diff --git a/xarray/core/formatting.py b/xarray/core/formatting.py</span>
<span class="gh">index 8c1f8e0c..2b8a613e 100644</span>
<span class="gd">--- a/xarray/core/formatting.py</span>
<span class="gi">+++ b/xarray/core/formatting.py</span>
<span class="gu">@@ -32,59 +32,99 @@ def pretty_print(x, numchars: int):</span>
<span class="w"> </span>    that it is numchars long, padding with trailing spaces or truncating with
<span class="w"> </span>    ellipses as necessary
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    s = str(x)</span>
<span class="gi">+    if len(s) &gt; numchars:</span>
<span class="gi">+        return s[:(numchars - 3)] + &#39;...&#39;</span>
<span class="gi">+    else:</span>
<span class="gi">+        return s.ljust(numchars)</span>


<span class="w"> </span>def first_n_items(array, n_desired):
<span class="w"> </span>    &quot;&quot;&quot;Returns the first n_desired items of an array&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return array[:n_desired]</span>


<span class="w"> </span>def last_n_items(array, n_desired):
<span class="w"> </span>    &quot;&quot;&quot;Returns the last n_desired items of an array&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return array[-n_desired:]</span>


<span class="w"> </span>def last_item(array):
<span class="w"> </span>    &quot;&quot;&quot;Returns the last item of an array in a list or an empty list.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return [array[-1]] if len(array) &gt; 0 else []</span>


<span class="w"> </span>def calc_max_rows_first(max_rows: int) -&gt;int:
<span class="w"> </span>    &quot;&quot;&quot;Calculate the first rows to maintain the max number of rows.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return max(1, (max_rows + 1) // 2)</span>


<span class="w"> </span>def calc_max_rows_last(max_rows: int) -&gt;int:
<span class="w"> </span>    &quot;&quot;&quot;Calculate the last rows to maintain the max number of rows.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return max(1, max_rows // 2)</span>


<span class="w"> </span>def format_timestamp(t):
<span class="w"> </span>    &quot;&quot;&quot;Cast given object to a Timestamp and return a nicely formatted string&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        timestamp = pd.Timestamp(t)</span>
<span class="gi">+        return timestamp.isoformat(sep=&#39; &#39;)</span>
<span class="gi">+    except (ValueError, TypeError):</span>
<span class="gi">+        return str(t)</span>


<span class="w"> </span>def format_timedelta(t, timedelta_format=None):
<span class="gd">-    &quot;&quot;&quot;Cast given object to a Timestamp and return a nicely formatted string&quot;&quot;&quot;</span>
<span class="gd">-    pass</span>
<span class="gi">+    &quot;&quot;&quot;Cast given object to a Timedelta and return a nicely formatted string&quot;&quot;&quot;</span>
<span class="gi">+    try:</span>
<span class="gi">+        delta = pd.Timedelta(t)</span>
<span class="gi">+        if timedelta_format is None:</span>
<span class="gi">+            return str(delta)</span>
<span class="gi">+        else:</span>
<span class="gi">+            return delta.isoformat()</span>
<span class="gi">+    except (ValueError, TypeError):</span>
<span class="gi">+        return str(t)</span>


<span class="w"> </span>def format_item(x, timedelta_format=None, quote_strings=True):
<span class="w"> </span>    &quot;&quot;&quot;Returns a succinct summary of an object as a string&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(x, (pd.Timestamp, datetime)):</span>
<span class="gi">+        return format_timestamp(x)</span>
<span class="gi">+    elif isinstance(x, (pd.Timedelta, timedelta)):</span>
<span class="gi">+        return format_timedelta(x, timedelta_format)</span>
<span class="gi">+    elif isinstance(x, str):</span>
<span class="gi">+        return f&quot;&#39;{x}&#39;&quot; if quote_strings else x</span>
<span class="gi">+    else:</span>
<span class="gi">+        return str(x)</span>


<span class="w"> </span>def format_items(x):
<span class="w"> </span>    &quot;&quot;&quot;Returns a succinct summaries of all items in a sequence as strings&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return [format_item(item) for item in x]</span>


<span class="w"> </span>def format_array_flat(array, max_width: int):
<span class="w"> </span>    &quot;&quot;&quot;Return a formatted string for as many items in the flattened version of
<span class="w"> </span>    array that will fit within max_width characters.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    flat = array.flatten()</span>
<span class="gi">+    formatted = format_items(flat)</span>
<span class="gi">+    </span>
<span class="gi">+    cumulative_width = 0</span>
<span class="gi">+    truncate_at = len(formatted)</span>
<span class="gi">+    </span>
<span class="gi">+    for i, item in enumerate(formatted):</span>
<span class="gi">+        item_width = len(item) + 2  # +2 for separator &#39;, &#39;</span>
<span class="gi">+        if cumulative_width + item_width &gt; max_width:</span>
<span class="gi">+            truncate_at = i</span>
<span class="gi">+            break</span>
<span class="gi">+        cumulative_width += item_width</span>
<span class="gi">+    </span>
<span class="gi">+    truncated = formatted[:truncate_at]</span>
<span class="gi">+    </span>
<span class="gi">+    if truncate_at &lt; len(formatted):</span>
<span class="gi">+        return f&quot;[{&#39;, &#39;.join(truncated)}, ...]&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        return f&quot;[{&#39;, &#39;.join(truncated)}]&quot;</span>


<span class="w"> </span>_KNOWN_TYPE_REPRS = {(&#39;numpy&#39;, &#39;ndarray&#39;): &#39;np.ndarray&#39;, (
<span class="gh">diff --git a/xarray/core/formatting_html.py b/xarray/core/formatting_html.py</span>
<span class="gh">index a85cdfc5..6b36f379 100644</span>
<span class="gd">--- a/xarray/core/formatting_html.py</span>
<span class="gi">+++ b/xarray/core/formatting_html.py</span>
<span class="gu">@@ -17,12 +17,16 @@ if TYPE_CHECKING:</span>
<span class="w"> </span>@lru_cache(None)
<span class="w"> </span>def _load_static_files():
<span class="w"> </span>    &quot;&quot;&quot;Lazily load the resource files into memory the first time they are needed&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    static_files = {}</span>
<span class="gi">+    for package, filename in STATIC_FILES:</span>
<span class="gi">+        content = files(package).joinpath(filename).read_text()</span>
<span class="gi">+        static_files[filename] = content</span>
<span class="gi">+    return static_files</span>


<span class="w"> </span>def short_data_repr_html(array) -&gt;str:
<span class="w"> </span>    &quot;&quot;&quot;Format &quot;data&quot; for DataArray and Variable.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return f&#39;&lt;pre&gt;{escape(short_data_repr(array))}&lt;/pre&gt;&#39;</span>


<span class="w"> </span>coord_section = partial(_mapping_section, name=&#39;Coordinates&#39;, details_func=
<span class="gu">@@ -45,7 +49,23 @@ def _obj_repr(obj, header_components, sections):</span>
<span class="w"> </span>    If CSS is not injected (untrusted notebook), fallback to the plain text repr.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    static_files = _load_static_files()</span>
<span class="gi">+    css_styles = static_files[&#39;style.css&#39;]</span>
<span class="gi">+    icons = static_files[&#39;icons-svg-inline.html&#39;]</span>
<span class="gi">+</span>
<span class="gi">+    obj_type = type(obj).__name__</span>
<span class="gi">+    obj_name = getattr(obj, &#39;name&#39;, None)</span>
<span class="gi">+    name_str = f&#39; {escape(str(obj_name))}&#39; if obj_name is not None else &#39;&#39;</span>
<span class="gi">+</span>
<span class="gi">+    header = f&#39;&lt;div class=&quot;xr-header&quot;&gt;&lt;div class=&quot;xr-obj-type&quot;&gt;{obj_type}&lt;/div&gt;: {name_str}&lt;/div&gt;&#39;</span>
<span class="gi">+    </span>
<span class="gi">+    components = [icons, f&#39;&lt;style&gt;{css_styles}&lt;/style&gt;&#39;, header]</span>
<span class="gi">+    components.extend(header_components)</span>
<span class="gi">+    </span>
<span class="gi">+    for section in sections:</span>
<span class="gi">+        components.append(section(obj))</span>
<span class="gi">+</span>
<span class="gi">+    return &#39;&#39;.join(components)</span>


<span class="w"> </span>children_section = partial(_mapping_section, name=&#39;Groups&#39;, details_func=
<span class="gu">@@ -90,4 +110,21 @@ def _wrap_datatree_repr(r: str, end: bool=False) -&gt;str:</span>

<span class="w"> </span>        Tee color is set to the variable :code:`--xr-border-color`.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    tee = &#39;└─&#39; if end else &#39;|─&#39;</span>
<span class="gi">+    padding = &#39;&amp;nbsp;&amp;nbsp;&#39; if end else &#39;|&amp;nbsp;&#39;</span>
<span class="gi">+    </span>
<span class="gi">+    wrapped = f&#39;&#39;&#39;</span>
<span class="gi">+    &lt;div style=&quot;display: inline-grid; grid-template-columns: auto 1fr; grid-gap: 0;&quot;&gt;</span>
<span class="gi">+        &lt;div style=&quot;color: var(--xr-border-color);&quot;&gt;</span>
<span class="gi">+            {tee}</span>
<span class="gi">+        &lt;/div&gt;</span>
<span class="gi">+        &lt;div&gt;</span>
<span class="gi">+            {r}</span>
<span class="gi">+        &lt;/div&gt;</span>
<span class="gi">+        &lt;div style=&quot;color: var(--xr-border-color);&quot;&gt;</span>
<span class="gi">+            {padding}</span>
<span class="gi">+        &lt;/div&gt;</span>
<span class="gi">+        &lt;div&gt;&lt;/div&gt;</span>
<span class="gi">+    &lt;/div&gt;</span>
<span class="gi">+    &#39;&#39;&#39;</span>
<span class="gi">+    return wrapped.strip()</span>
<span class="gh">diff --git a/xarray/core/groupby.py b/xarray/core/groupby.py</span>
<span class="gh">index 8807366d..6c59652f 100644</span>
<span class="gd">--- a/xarray/core/groupby.py</span>
<span class="gi">+++ b/xarray/core/groupby.py</span>
<span class="gu">@@ -32,7 +32,18 @@ if TYPE_CHECKING:</span>

<span class="w"> </span>def _consolidate_slices(slices: list[slice]) -&gt;list[slice]:
<span class="w"> </span>    &quot;&quot;&quot;Consolidate adjacent slices in a list of slices.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not slices:</span>
<span class="gi">+        return []</span>
<span class="gi">+    </span>
<span class="gi">+    consolidated = [slices[0]]</span>
<span class="gi">+    for current in slices[1:]:</span>
<span class="gi">+        previous = consolidated[-1]</span>
<span class="gi">+        if previous.stop == current.start and previous.step == current.step:</span>
<span class="gi">+            consolidated[-1] = slice(previous.start, current.stop, previous.step)</span>
<span class="gi">+        else:</span>
<span class="gi">+            consolidated.append(current)</span>
<span class="gi">+    </span>
<span class="gi">+    return consolidated</span>


<span class="w"> </span>def _inverse_permutation_indices(positions, N: (int | None)=None) -&gt;(np.
<span class="gu">@@ -48,7 +59,25 @@ def _inverse_permutation_indices(positions, N: (int | None)=None) -&gt;(np.</span>
<span class="w"> </span>    -------
<span class="w"> </span>    np.ndarray of indices or None, if no permutation is necessary.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not positions:</span>
<span class="gi">+        return None</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(positions[0], slice):</span>
<span class="gi">+        if N is None:</span>
<span class="gi">+            raise ValueError(&quot;N must be provided when positions are slices&quot;)</span>
<span class="gi">+        indices = np.full(N, -1, dtype=int)</span>
<span class="gi">+        for i, slc in enumerate(positions):</span>
<span class="gi">+            indices[slc] = i</span>
<span class="gi">+        return indices if (indices != np.arange(N)).any() else None</span>
<span class="gi">+    else:</span>
<span class="gi">+        indices = np.concatenate(positions)</span>
<span class="gi">+        if len(indices) == 0:</span>
<span class="gi">+            return None</span>
<span class="gi">+        if not np.array_equal(np.sort(indices), np.arange(len(indices))):</span>
<span class="gi">+            raise ValueError(&quot;Invalid positions for permutation&quot;)</span>
<span class="gi">+        inverse = np.full_like(indices, -1)</span>
<span class="gi">+        inverse[indices] = np.arange(len(indices))</span>
<span class="gi">+        return inverse if (inverse != np.arange(len(inverse))).any() else None</span>


<span class="w"> </span>class _DummyGroup(Generic[T_Xarray]):
<span class="gu">@@ -229,23 +258,63 @@ class GroupBy(Generic[T_Xarray]):</span>

<span class="w"> </span>    def _iter_grouped(self) -&gt;Iterator[T_Xarray]:
<span class="w"> </span>        &quot;&quot;&quot;Iterate over each element in this group&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        for indices in self._group_indices:</span>
<span class="gi">+            yield self._obj.isel({self._group_dim: indices})</span>

<span class="w"> </span>    def _maybe_restore_empty_groups(self, combined):
<span class="w"> </span>        &quot;&quot;&quot;Our index contained empty groups (e.g., from a resampling or binning). If we
<span class="w"> </span>        reduced on that dimension, we want to restore the full index.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        grouper, = self.groupers</span>
<span class="gi">+        if grouper.name not in combined.dims:</span>
<span class="gi">+            return combined</span>
<span class="gi">+</span>
<span class="gi">+        size = grouper.size</span>
<span class="gi">+        if size == len(combined[grouper.name]):</span>
<span class="gi">+            return combined</span>
<span class="gi">+</span>
<span class="gi">+        template = self._obj.isel({self._group_dim: 0}).drop_vars(self._group_dim)</span>
<span class="gi">+        template = template._replace_maybe_drop_dims({var: combined[var] for var in combined.data_vars})</span>
<span class="gi">+        </span>
<span class="gi">+        if isinstance(template, type(combined)):</span>
<span class="gi">+            return template.reindex({grouper.name: grouper.unique_coord})</span>
<span class="gi">+        else:</span>
<span class="gi">+            return combined</span>

<span class="w"> </span>    def _maybe_unstack(self, obj):
<span class="w"> </span>        &quot;&quot;&quot;This gets called if we are applying on an array with a
<span class="w"> </span>        multidimensional group.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        grouper, = self.groupers</span>
<span class="gi">+        if grouper.stacked_dim is not None:</span>
<span class="gi">+            obj = obj.unstack(grouper.stacked_dim)</span>
<span class="gi">+            for dim in grouper.inserted_dims:</span>
<span class="gi">+                if dim in obj.coords:</span>
<span class="gi">+                    obj.coords[dim] = grouper.group[dim]</span>
<span class="gi">+        return obj</span>

<span class="w"> </span>    def _flox_reduce(self, dim: Dims, keep_attrs: (bool | None)=None, **
<span class="w"> </span>        kwargs: Any):
<span class="w"> </span>        &quot;&quot;&quot;Adaptor function that translates our groupby API to that of flox.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from flox.xarray import xarray_reduce</span>
<span class="gi">+        </span>
<span class="gi">+        grouper, = self.groupers</span>
<span class="gi">+        if dim is None or dim is ...:</span>
<span class="gi">+            dim = list(self._obj.dims)</span>
<span class="gi">+        elif isinstance(dim, str):</span>
<span class="gi">+            dim = [dim]</span>
<span class="gi">+        </span>
<span class="gi">+        if grouper.name not in dim:</span>
<span class="gi">+            dim = list(dim) + [grouper.name]</span>
<span class="gi">+        </span>
<span class="gi">+        result = xarray_reduce(</span>
<span class="gi">+            self._obj,</span>
<span class="gi">+            dim=dim,</span>
<span class="gi">+            group=grouper.group,</span>
<span class="gi">+            keep_attrs=keep_attrs,</span>
<span class="gi">+            **kwargs</span>
<span class="gi">+        )</span>
<span class="gi">+        </span>
<span class="gi">+        return self._maybe_restore_empty_groups(result)</span>

<span class="w"> </span>    def fillna(self, value: Any) -&gt;T_Xarray:
<span class="w"> </span>        &quot;&quot;&quot;Fill missing values in this object by group.
<span class="gu">@@ -271,7 +340,7 @@ class GroupBy(Generic[T_Xarray]):</span>
<span class="w"> </span>        Dataset.fillna
<span class="w"> </span>        DataArray.fillna
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.map(lambda x: x.fillna(value))</span>

<span class="w"> </span>    @_deprecate_positional_args(&#39;v2023.10.0&#39;)
<span class="w"> </span>    def quantile(self, q: ArrayLike, dim: Dims=None, *, method:
<span class="gh">diff --git a/xarray/core/indexes.py b/xarray/core/indexes.py</span>
<span class="gh">index 78726197..04c02219 100644</span>
<span class="gd">--- a/xarray/core/indexes.py</span>
<span class="gi">+++ b/xarray/core/indexes.py</span>
<span class="gu">@@ -376,7 +376,16 @@ def safe_cast_to_index(array: Any) -&gt;pd.Index:</span>
<span class="w"> </span>    this function will not attempt to do automatic type conversion but will
<span class="w"> </span>    always return an index with dtype=object.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(array, pd.Index):</span>
<span class="gi">+        return array</span>
<span class="gi">+    if hasattr(array, &#39;to_index&#39;):</span>
<span class="gi">+        array = array.to_index()</span>
<span class="gi">+    if isinstance(array, pd.Index):</span>
<span class="gi">+        return array</span>
<span class="gi">+    kwargs = {}</span>
<span class="gi">+    if hasattr(array, &#39;dtype&#39;) and array.dtype.kind in [&#39;O&#39;, &#39;m&#39;]:</span>
<span class="gi">+        kwargs[&#39;dtype&#39;] = object</span>
<span class="gi">+    return pd.Index(array, **kwargs)</span>


<span class="w"> </span>def _asarray_tuplesafe(values):
<span class="gu">@@ -386,7 +395,15 @@ def _asarray_tuplesafe(values):</span>

<span class="w"> </span>    Adapted from pandas.core.common._asarray_tuplesafe
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(values, tuple):</span>
<span class="gi">+        result = utils.to_0d_object_array(values)</span>
<span class="gi">+    else:</span>
<span class="gi">+        result = np.asarray(values)</span>
<span class="gi">+        if result.ndim == 2:</span>
<span class="gi">+            result = np.empty(len(values), dtype=object)</span>
<span class="gi">+            result[:] = values</span>
<span class="gi">+</span>
<span class="gi">+    return result</span>


<span class="w"> </span>def get_indexer_nd(index: pd.Index, labels, method=None, tolerance=None
<span class="gu">@@ -394,7 +411,9 @@ def get_indexer_nd(index: pd.Index, labels, method=None, tolerance=None</span>
<span class="w"> </span>    &quot;&quot;&quot;Wrapper around :meth:`pandas.Index.get_indexer` supporting n-dimensional
<span class="w"> </span>    labels
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    flat_labels = np.ravel(labels)</span>
<span class="gi">+    flat_indexer = index.get_indexer(flat_labels, method=method, tolerance=tolerance)</span>
<span class="gi">+    return flat_indexer.reshape(labels.shape)</span>


<span class="w"> </span>T_PandasIndex = TypeVar(&#39;T_PandasIndex&#39;, bound=&#39;PandasIndex&#39;)
<span class="gu">@@ -435,7 +454,18 @@ def _check_dim_compat(variables: Mapping[Any, Variable], all_dims: str=&#39;equal&#39;</span>
<span class="w"> </span>    either share the same (single) dimension or each have a different dimension.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    dims = [var.dims for var in variables.values()]</span>
<span class="gi">+    if not all(len(d) == 1 for d in dims):</span>
<span class="gi">+        raise ValueError(&quot;Multi-index variables must be 1-dimensional&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if all_dims == &#39;equal&#39;:</span>
<span class="gi">+        if not all(d == dims[0] for d in dims[1:]):</span>
<span class="gi">+            raise ValueError(&quot;Multi-index variables must share the same dimension&quot;)</span>
<span class="gi">+    elif all_dims == &#39;different&#39;:</span>
<span class="gi">+        if len(set(d[0] for d in dims)) != len(dims):</span>
<span class="gi">+            raise ValueError(&quot;Multi-index variables must have different dimensions&quot;)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(&quot;Invalid value for all_dims. Must be &#39;equal&#39; or &#39;different&#39;&quot;)</span>


<span class="w"> </span>T_PDIndex = TypeVar(&#39;T_PDIndex&#39;, bound=pd.Index)
<span class="gu">@@ -445,7 +475,12 @@ def remove_unused_levels_categories(index: T_PDIndex) -&gt;T_PDIndex:</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Remove unused levels from MultiIndex and unused categories from CategoricalIndex
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(index, pd.MultiIndex):</span>
<span class="gi">+        return index.remove_unused_levels()</span>
<span class="gi">+    elif isinstance(index, pd.CategoricalIndex):</span>
<span class="gi">+        return index.remove_unused_categories()</span>
<span class="gi">+    else:</span>
<span class="gi">+        return index</span>


<span class="w"> </span>class PandasMultiIndex(PandasIndex):
<span class="gu">@@ -485,7 +520,11 @@ class PandasMultiIndex(PandasIndex):</span>
<span class="w"> </span>        labels after a stack/unstack roundtrip.

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        _check_dim_compat(variables, all_dims=&#39;different&#39;)</span>
<span class="gi">+        names = list(variables.keys())</span>
<span class="gi">+        levels = [var.values for var in variables.values()]</span>
<span class="gi">+        product = pd.MultiIndex.from_product(levels, names=names)</span>
<span class="gi">+        return cls(product, dim)</span>

<span class="w"> </span>    @classmethod
<span class="w"> </span>    def from_variables_maybe_expand(cls, dim: Hashable, current_variables:
<span class="gu">@@ -496,7 +535,17 @@ class PandasMultiIndex(PandasIndex):</span>

<span class="w"> </span>        The index and its corresponding coordinates may be created along a new dimension.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        all_variables = {**current_variables, **variables}</span>
<span class="gi">+        _check_dim_compat(all_variables, all_dims=&#39;equal&#39;)</span>
<span class="gi">+        </span>
<span class="gi">+        names = list(all_variables.keys())</span>
<span class="gi">+        levels = [var.values for var in all_variables.values()]</span>
<span class="gi">+        product = pd.MultiIndex.from_product(levels, names=names)</span>
<span class="gi">+        </span>
<span class="gi">+        index = cls(product, dim)</span>
<span class="gi">+        index_vars = {name: Variable((dim,), level) for name, level in zip(names, levels)}</span>
<span class="gi">+        </span>
<span class="gi">+        return index, index_vars</span>

<span class="w"> </span>    def keep_levels(self, level_variables: Mapping[Any, Variable]) -&gt;(
<span class="w"> </span>        PandasMultiIndex | PandasIndex):
<span class="gu">@@ -524,7 +573,17 @@ def create_default_index_implicit(dim_variable: Variable, all_variables: (</span>
<span class="w"> </span>    depreciate implicitly passing a pandas.MultiIndex as a coordinate).

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    dim = dim_variable.dims[0]</span>
<span class="gi">+    data = dim_variable.values</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(data, pd.MultiIndex):</span>
<span class="gi">+        index = PandasMultiIndex(data, dim)</span>
<span class="gi">+        index_vars = {name: Variable((dim,), level) for name, level in zip(data.names, data.levels)}</span>
<span class="gi">+    else:</span>
<span class="gi">+        index = PandasIndex(data, dim)</span>
<span class="gi">+        index_vars = {dim: dim_variable}</span>
<span class="gi">+</span>
<span class="gi">+    return index, index_vars</span>


<span class="w"> </span>T_PandasOrXarrayIndex = TypeVar(&#39;T_PandasOrXarrayIndex&#39;, Index, pd.Index)
<span class="gu">@@ -698,7 +757,14 @@ def default_indexes(coords: Mapping[Any, Variable], dims: Iterable) -&gt;dict[</span>
<span class="w"> </span>    Mapping from indexing keys (levels/dimension names) to indexes used for
<span class="w"> </span>    indexing along that dimension.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    indexes = {}</span>
<span class="gi">+    for dim in dims:</span>
<span class="gi">+        if dim in coords:</span>
<span class="gi">+            index, _ = create_default_index_implicit(coords[dim])</span>
<span class="gi">+            indexes[dim] = index</span>
<span class="gi">+        else:</span>
<span class="gi">+            indexes[dim] = PandasIndex(pd.RangeIndex(coords[dim].size), dim)</span>
<span class="gi">+    return indexes</span>


<span class="w"> </span>def indexes_equal(index: Index, other_index: Index, variable: Variable,
<span class="gh">diff --git a/xarray/core/indexing.py b/xarray/core/indexing.py</span>
<span class="gh">index d02970b0..195ead0c 100644</span>
<span class="gd">--- a/xarray/core/indexing.py</span>
<span class="gi">+++ b/xarray/core/indexing.py</span>
<span class="gu">@@ -68,7 +68,11 @@ class IndexSelResult:</span>
<span class="w"> </span>def group_indexers_by_index(obj: T_Xarray, indexers: Mapping[Any, Any],
<span class="w"> </span>    options: Mapping[str, Any]) -&gt;list[tuple[Index, dict[Any, Any]]]:
<span class="w"> </span>    &quot;&quot;&quot;Returns a list of unique indexes and their corresponding indexers.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    grouped_indexers = defaultdict(dict)</span>
<span class="gi">+    for key, value in indexers.items():</span>
<span class="gi">+        index = obj.indexes[key]</span>
<span class="gi">+        grouped_indexers[index][key] = value</span>
<span class="gi">+    return list(grouped_indexers.items())</span>


<span class="w"> </span>def map_index_queries(obj: T_Xarray, indexers: Mapping[Any, Any], method=
<span class="gu">@@ -78,7 +82,21 @@ def map_index_queries(obj: T_Xarray, indexers: Mapping[Any, Any], method=</span>
<span class="w"> </span>    and return the (merged) query results.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    grouped_indexers = group_indexers_by_index(obj, indexers, indexers_kwargs)</span>
<span class="gi">+    dim_indexers = {}</span>
<span class="gi">+    new_indexes = {}</span>
<span class="gi">+    variables = {}</span>
<span class="gi">+    for index, these_indexers in grouped_indexers:</span>
<span class="gi">+        query_results = index.sel(these_indexers, method=method, tolerance=tolerance)</span>
<span class="gi">+        dim_indexers.update(query_results.dim_indexers)</span>
<span class="gi">+        new_indexes.update(query_results.indexes)</span>
<span class="gi">+        variables.update(query_results.variables)</span>
<span class="gi">+    </span>
<span class="gi">+    return IndexSelResult(</span>
<span class="gi">+        dim_indexers=dim_indexers,</span>
<span class="gi">+        indexes=new_indexes,</span>
<span class="gi">+        variables=variables</span>
<span class="gi">+    )</span>


<span class="w"> </span>def expanded_indexer(key, ndim):
<span class="gu">@@ -89,7 +107,28 @@ def expanded_indexer(key, ndim):</span>
<span class="w"> </span>    number of full slices and then padding the key with full slices so that it
<span class="w"> </span>    reaches the appropriate dimensionality.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not isinstance(key, tuple):</span>
<span class="gi">+        key = (key,)</span>
<span class="gi">+    </span>
<span class="gi">+    new_key = []</span>
<span class="gi">+    ellipsis_count = sum(1 for k in key if k is Ellipsis)</span>
<span class="gi">+    </span>
<span class="gi">+    if ellipsis_count &gt; 1:</span>
<span class="gi">+        raise IndexError(&quot;an index can only have a single ellipsis (&#39;...&#39;)&quot;)</span>
<span class="gi">+    elif ellipsis_count == 1:</span>
<span class="gi">+        ellipsis_index = key.index(Ellipsis)</span>
<span class="gi">+        key = key[:ellipsis_index] + (slice(None),) * (ndim - len(key) + 1) + key[ellipsis_index + 1:]</span>
<span class="gi">+    </span>
<span class="gi">+    for k in key:</span>
<span class="gi">+        if k is Ellipsis:</span>
<span class="gi">+            new_key.extend([slice(None)] * (ndim - len(new_key)))</span>
<span class="gi">+        else:</span>
<span class="gi">+            new_key.append(k)</span>
<span class="gi">+    </span>
<span class="gi">+    if len(new_key) &lt; ndim:</span>
<span class="gi">+        new_key.extend([slice(None)] * (ndim - len(new_key)))</span>
<span class="gi">+    </span>
<span class="gi">+    return tuple(new_key)</span>


<span class="w"> </span>def _normalize_slice(sl: slice, size: int) -&gt;slice:
<span class="gu">@@ -104,7 +143,25 @@ def _normalize_slice(sl: slice, size: int) -&gt;slice:</span>
<span class="w"> </span>    &gt;&gt;&gt; _normalize_slice(slice(0, -1), 10)
<span class="w"> </span>    slice(0, 9, 1)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    start, stop, step = sl.start, sl.stop, sl.step</span>
<span class="gi">+</span>
<span class="gi">+    if step is None:</span>
<span class="gi">+        step = 1</span>
<span class="gi">+</span>
<span class="gi">+    if start is None:</span>
<span class="gi">+        start = 0 if step &gt; 0 else size - 1</span>
<span class="gi">+    elif start &lt; 0:</span>
<span class="gi">+        start += size</span>
<span class="gi">+</span>
<span class="gi">+    if stop is None:</span>
<span class="gi">+        stop = size if step &gt; 0 else -1</span>
<span class="gi">+    elif stop &lt; 0:</span>
<span class="gi">+        stop += size</span>
<span class="gi">+</span>
<span class="gi">+    if step &gt; 0 and stop == -1:</span>
<span class="gi">+        stop = size</span>
<span class="gi">+</span>
<span class="gi">+    return slice(start, stop, step)</span>


<span class="w"> </span>def _expand_slice(slice_: slice, size: int) -&gt;np.ndarray[Any, np.dtype[np.
<span class="gu">@@ -119,7 +176,8 @@ def _expand_slice(slice_: slice, size: int) -&gt;np.ndarray[Any, np.dtype[np.</span>
<span class="w"> </span>    &gt;&gt;&gt; _expand_slice(slice(0, -1), 10)
<span class="w"> </span>    array([0, 1, 2, 3, 4, 5, 6, 7, 8])
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    normalized_slice = _normalize_slice(slice_, size)</span>
<span class="gi">+    return np.arange(normalized_slice.start, normalized_slice.stop, normalized_slice.step)</span>


<span class="w"> </span>def slice_slice(old_slice: slice, applied_slice: slice, size: int) -&gt;slice:
<span class="gu">@@ -127,7 +185,16 @@ def slice_slice(old_slice: slice, applied_slice: slice, size: int) -&gt;slice:</span>
<span class="w"> </span>    index it with another slice to return a new slice equivalent to applying
<span class="w"> </span>    the slices sequentially
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    old_slice = _normalize_slice(old_slice, size)</span>
<span class="gi">+    old_range = range(old_slice.start, old_slice.stop, old_slice.step)</span>
<span class="gi">+    </span>
<span class="gi">+    applied_range = range(len(old_range))[applied_slice]</span>
<span class="gi">+    </span>
<span class="gi">+    new_start = old_range[applied_range.start] if applied_range.start is not None else None</span>
<span class="gi">+    new_stop = old_range[applied_range.stop - 1] + 1 if applied_range.stop is not None else None</span>
<span class="gi">+    new_step = old_slice.step * applied_slice.step if applied_slice.step is not None else None</span>
<span class="gi">+    </span>
<span class="gi">+    return slice(new_start, new_stop, new_step)</span>


<span class="w"> </span>class ExplicitIndexer:
<span class="gh">diff --git a/xarray/core/merge.py b/xarray/core/merge.py</span>
<span class="gh">index eb888a66..b1778652 100644</span>
<span class="gd">--- a/xarray/core/merge.py</span>
<span class="gi">+++ b/xarray/core/merge.py</span>
<span class="gu">@@ -40,7 +40,15 @@ def broadcast_dimension_size(variables: list[Variable]) -&gt;dict[Hashable, int]:</span>

<span class="w"> </span>    Raises ValueError if any dimensions have different sizes.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    dim_sizes = {}</span>
<span class="gi">+    for var in variables:</span>
<span class="gi">+        for dim, size in var.sizes.items():</span>
<span class="gi">+            if dim in dim_sizes:</span>
<span class="gi">+                if dim_sizes[dim] != size:</span>
<span class="gi">+                    raise ValueError(f&quot;Inconsistent dimension size for {dim}: {dim_sizes[dim]} != {size}&quot;)</span>
<span class="gi">+            else:</span>
<span class="gi">+                dim_sizes[dim] = size</span>
<span class="gi">+    return dim_sizes</span>


<span class="w"> </span>class MergeError(ValueError):
<span class="gu">@@ -71,7 +79,30 @@ def unique_variable(name: Hashable, variables: list[Variable], compat:</span>
<span class="w"> </span>    ------
<span class="w"> </span>    MergeError: if any of the variables are not equal.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if len(variables) == 1:</span>
<span class="gi">+        return variables[0]</span>
<span class="gi">+    </span>
<span class="gi">+    first_var = variables[0]</span>
<span class="gi">+    if compat == &quot;override&quot;:</span>
<span class="gi">+        return first_var</span>
<span class="gi">+    </span>
<span class="gi">+    for var in variables[1:]:</span>
<span class="gi">+        if compat == &quot;identical&quot;:</span>
<span class="gi">+            if not first_var.identical(var):</span>
<span class="gi">+                raise MergeError(f&quot;Conflict for variable {name}&quot;)</span>
<span class="gi">+        elif compat == &quot;equals&quot;:</span>
<span class="gi">+            if not first_var.equals(var):</span>
<span class="gi">+                raise MergeError(f&quot;Conflict for variable {name}&quot;)</span>
<span class="gi">+        elif compat == &quot;broadcast_equals&quot;:</span>
<span class="gi">+            if not first_var.broadcast_equals(var):</span>
<span class="gi">+                raise MergeError(f&quot;Conflict for variable {name}&quot;)</span>
<span class="gi">+        elif compat == &quot;no_conflicts&quot;:</span>
<span class="gi">+            if not first_var.no_conflicts(var):</span>
<span class="gi">+                raise MergeError(f&quot;Conflict for variable {name}&quot;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise ValueError(f&quot;Unsupported compat option: {compat}&quot;)</span>
<span class="gi">+    </span>
<span class="gi">+    return first_var</span>


<span class="w"> </span>MergeElement = tuple[Variable, Optional[Index]]
<span class="gu">@@ -82,7 +113,14 @@ def _assert_prioritized_valid(grouped: dict[Hashable, list[MergeElement]],</span>
<span class="w"> </span>    &quot;&quot;&quot;Make sure that elements given in prioritized will not corrupt any
<span class="w"> </span>    index given in grouped.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    for name, (var, index) in prioritized.items():</span>
<span class="gi">+        if name in grouped:</span>
<span class="gi">+            grouped_var, grouped_index = grouped[name][0]</span>
<span class="gi">+            if index is not None and grouped_index is not None:</span>
<span class="gi">+                if not indexes_equal(index, grouped_index):</span>
<span class="gi">+                    raise ValueError(f&quot;Incompatible indexes for variable {name}&quot;)</span>
<span class="gi">+            elif index is not None or grouped_index is not None:</span>
<span class="gi">+                raise ValueError(f&quot;Inconsistent presence of index for variable {name}&quot;)</span>


<span class="w"> </span>def merge_collected(grouped: dict[Any, list[MergeElement]], prioritized: (
<span class="gu">@@ -122,7 +160,36 @@ def merge_collected(grouped: dict[Any, list[MergeElement]], prioritized: (</span>
<span class="w"> </span>    and Variable values corresponding to those that should be found on the
<span class="w"> </span>    merged result.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if prioritized is None:</span>
<span class="gi">+        prioritized = {}</span>
<span class="gi">+    </span>
<span class="gi">+    _assert_prioritized_valid(grouped, prioritized)</span>
<span class="gi">+    </span>
<span class="gi">+    result_vars = {}</span>
<span class="gi">+    result_indexes = {}</span>
<span class="gi">+    </span>
<span class="gi">+    for name, elements in grouped.items():</span>
<span class="gi">+        if name in prioritized:</span>
<span class="gi">+            var, index = prioritized[name]</span>
<span class="gi">+        else:</span>
<span class="gi">+            variables = [elem[0] for elem in elements]</span>
<span class="gi">+            var = unique_variable(name, variables, compat)</span>
<span class="gi">+            index = elements[0][1]  # Use the first index</span>
<span class="gi">+        </span>
<span class="gi">+        result_vars[name] = var</span>
<span class="gi">+        if index is not None:</span>
<span class="gi">+            result_indexes[name] = index</span>
<span class="gi">+    </span>
<span class="gi">+    # Combine attributes</span>
<span class="gi">+    if callable(combine_attrs):</span>
<span class="gi">+        attrs = combine_attrs([var.attrs for var in result_vars.values()], Context(merge_collected))</span>
<span class="gi">+    else:</span>
<span class="gi">+        attrs = merge_attrs([var.attrs for var in result_vars.values()], combine_attrs)</span>
<span class="gi">+    </span>
<span class="gi">+    for var in result_vars.values():</span>
<span class="gi">+        var.attrs.update(attrs)</span>
<span class="gi">+    </span>
<span class="gi">+    return result_vars, result_indexes</span>


<span class="w"> </span>def collect_variables_and_indexes(list_of_mappings: Iterable[DatasetLike],
<span class="gh">diff --git a/xarray/core/missing.py b/xarray/core/missing.py</span>
<span class="gh">index e589337e..0837f746 100644</span>
<span class="gd">--- a/xarray/core/missing.py</span>
<span class="gi">+++ b/xarray/core/missing.py</span>
<span class="gu">@@ -28,7 +28,36 @@ def _get_nan_block_lengths(obj: (Dataset | DataArray | Variable), dim:</span>
<span class="w"> </span>    Return an object where each NaN element in &#39;obj&#39; is replaced by the
<span class="w"> </span>    length of the gap the element is in.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import numpy as np</span>
<span class="gi">+    from xarray.core.duck_array_ops import isnull</span>
<span class="gi">+</span>
<span class="gi">+    def _nan_block_lengths(arr):</span>
<span class="gi">+        mask = isnull(arr)</span>
<span class="gi">+        if not np.any(mask):</span>
<span class="gi">+            return np.zeros_like(arr)</span>
<span class="gi">+</span>
<span class="gi">+        diff = np.diff(mask.astype(int))</span>
<span class="gi">+        start = np.where(diff == 1)[0] + 1</span>
<span class="gi">+        end = np.where(diff == -1)[0] + 1</span>
<span class="gi">+</span>
<span class="gi">+        if mask[0]:</span>
<span class="gi">+            start = np.r_[0, start]</span>
<span class="gi">+        if mask[-1]:</span>
<span class="gi">+            end = np.r_[end, len(mask)]</span>
<span class="gi">+</span>
<span class="gi">+        lengths = end - start</span>
<span class="gi">+        result = np.zeros_like(arr)</span>
<span class="gi">+        for s, e, l in zip(start, end, lengths):</span>
<span class="gi">+            result[s:e] = l</span>
<span class="gi">+</span>
<span class="gi">+        return result</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(obj, Variable):</span>
<span class="gi">+        return obj.copy(data=_nan_block_lengths(obj.data))</span>
<span class="gi">+    elif isinstance(obj, (Dataset, DataArray)):</span>
<span class="gi">+        return obj.map(_nan_block_lengths, keep_attrs=True)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(f&quot;Unsupported type for obj: {type(obj)}&quot;)</span>


<span class="w"> </span>class BaseInterpolator:
<span class="gu">@@ -137,7 +166,20 @@ class SplineInterpolator(BaseInterpolator):</span>

<span class="w"> </span>def _apply_over_vars_with_dim(func, self, dim=None, **kwargs):
<span class="w"> </span>    &quot;&quot;&quot;Wrapper for datasets&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from xarray.core.dataset import Dataset</span>
<span class="gi">+    from xarray.core.dataarray import DataArray</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(self, Dataset):</span>
<span class="gi">+        variables = {</span>
<span class="gi">+            k: func(v, dim=dim, **kwargs)</span>
<span class="gi">+            for k, v in self.data_vars.items()</span>
<span class="gi">+            if dim in v.dims</span>
<span class="gi">+        }</span>
<span class="gi">+        return Dataset(variables, coords=self.coords, attrs=self.attrs)</span>
<span class="gi">+    elif isinstance(self, DataArray):</span>
<span class="gi">+        return func(self, dim=dim, **kwargs)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(f&quot;Unsupported type for self: {type(self)}&quot;)</span>


<span class="w"> </span>def get_clean_interp_index(arr, dim: Hashable, use_coordinate: (str | bool)
<span class="gu">@@ -167,7 +209,29 @@ def get_clean_interp_index(arr, dim: Hashable, use_coordinate: (str | bool)</span>
<span class="w"> </span>    If indexing is along the time dimension, datetime coordinates are converted
<span class="w"> </span>    to time deltas with respect to 1970-01-01.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from xarray.core.variable import Variable</span>
<span class="gi">+    from xarray.core.duck_array_ops import datetime_to_numeric</span>
<span class="gi">+    import numpy as np</span>
<span class="gi">+    import pandas as pd</span>
<span class="gi">+</span>
<span class="gi">+    if use_coordinate:</span>
<span class="gi">+        if isinstance(use_coordinate, str):</span>
<span class="gi">+            index = arr.coords[use_coordinate]</span>
<span class="gi">+        else:</span>
<span class="gi">+            index = arr.coords[dim]</span>
<span class="gi">+    else:</span>
<span class="gi">+        index = Variable(dim, np.arange(arr.sizes[dim]))</span>
<span class="gi">+</span>
<span class="gi">+    if _contains_datetime_like_objects(index):</span>
<span class="gi">+        index = datetime_to_numeric(index)</span>
<span class="gi">+</span>
<span class="gi">+    if strict:</span>
<span class="gi">+        if not index.to_index().is_unique:</span>
<span class="gi">+            raise ValueError(&quot;Index must be unique&quot;)</span>
<span class="gi">+        if not index.to_index().is_monotonic_increasing:</span>
<span class="gi">+            raise ValueError(&quot;Index must be monotonically increasing&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    return index</span>


<span class="w"> </span>def interp_na(self, dim: (Hashable | None)=None, use_coordinate: (bool |
<span class="gu">@@ -175,7 +239,69 @@ def interp_na(self, dim: (Hashable | None)=None, use_coordinate: (bool |</span>
<span class="w"> </span>    max_gap: (int | float | str | pd.Timedelta | np.timedelta64 | dt.
<span class="w"> </span>    timedelta | None)=None, keep_attrs: (bool | None)=None, **kwargs):
<span class="w"> </span>    &quot;&quot;&quot;Interpolate values according to different methods.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from xarray.core.dataarray import DataArray</span>
<span class="gi">+    from xarray.core.dataset import Dataset</span>
<span class="gi">+    from xarray.core.duck_array_ops import isnull</span>
<span class="gi">+    import numpy as np</span>
<span class="gi">+    import pandas as pd</span>
<span class="gi">+</span>
<span class="gi">+    if dim is None:</span>
<span class="gi">+        raise ValueError(&quot;Must specify &#39;dim&#39; argument&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if keep_attrs is None:</span>
<span class="gi">+        keep_attrs = _get_keep_attrs(default=True)</span>
<span class="gi">+</span>
<span class="gi">+    index = get_clean_interp_index(self, dim, use_coordinate)</span>
<span class="gi">+</span>
<span class="gi">+    if max_gap is not None:</span>
<span class="gi">+        if isinstance(max_gap, str):</span>
<span class="gi">+            max_gap = pd.Timedelta(max_gap)</span>
<span class="gi">+        elif isinstance(max_gap, (np.timedelta64, dt.timedelta)):</span>
<span class="gi">+            max_gap = pd.Timedelta(max_gap)</span>
<span class="gi">+        elif not isinstance(max_gap, (int, float)):</span>
<span class="gi">+            raise TypeError(&quot;max_gap must be a number or a timedelta-like object&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        if _contains_datetime_like_objects(index):</span>
<span class="gi">+            max_gap = pd.Timedelta(max_gap).total_seconds()</span>
<span class="gi">+        </span>
<span class="gi">+        gaps = _get_nan_block_lengths(self, dim, index)</span>
<span class="gi">+        mask = gaps &lt;= max_gap</span>
<span class="gi">+</span>
<span class="gi">+    else:</span>
<span class="gi">+        mask = np.ones_like(self, dtype=bool)</span>
<span class="gi">+</span>
<span class="gi">+    obj = self.where(mask)</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(obj, Dataset):</span>
<span class="gi">+        return _apply_over_vars_with_dim(</span>
<span class="gi">+            interp_na,</span>
<span class="gi">+            obj,</span>
<span class="gi">+            dim=dim,</span>
<span class="gi">+            use_coordinate=use_coordinate,</span>
<span class="gi">+            method=method,</span>
<span class="gi">+            limit=limit,</span>
<span class="gi">+            keep_attrs=keep_attrs,</span>
<span class="gi">+            **kwargs</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    if not isnull(obj).any():</span>
<span class="gi">+        return obj</span>
<span class="gi">+</span>
<span class="gi">+    if limit is not None:</span>
<span class="gi">+        valid = _get_valid_fill_mask(obj, dim, limit)</span>
<span class="gi">+        obj = obj.where(valid)</span>
<span class="gi">+</span>
<span class="gi">+    indexer = {dim: index}</span>
<span class="gi">+    interpolator = _get_interpolator(method, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    return obj.interpolate_na(</span>
<span class="gi">+        dim=dim,</span>
<span class="gi">+        method=interpolator,</span>
<span class="gi">+        limit=limit,</span>
<span class="gi">+        use_coordinate=use_coordinate,</span>
<span class="gi">+        keep_attrs=keep_attrs,</span>
<span class="gi">+        **kwargs</span>
<span class="gi">+    )</span>


<span class="w"> </span>def func_interpolate_na(interpolator, y, x, **kwargs):
<span class="gh">diff --git a/xarray/core/nanops.py b/xarray/core/nanops.py</span>
<span class="gh">index 78ecefc3..b0766099 100644</span>
<span class="gd">--- a/xarray/core/nanops.py</span>
<span class="gi">+++ b/xarray/core/nanops.py</span>
<span class="gu">@@ -9,21 +9,60 @@ def _maybe_null_out(result, axis, mask, min_count=1):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    xarray version of pandas.core.nanops._maybe_null_out
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if axis is not None and isinstance(axis, (tuple, list)):</span>
<span class="gi">+        raise ValueError(&quot;axis must be a single integer, not a tuple or list&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if mask is None:</span>
<span class="gi">+        return result</span>
<span class="gi">+</span>
<span class="gi">+    null_mask = ~mask.all(axis=axis)</span>
<span class="gi">+</span>
<span class="gi">+    if min_count &gt; 1:</span>
<span class="gi">+        count = mask.sum(axis=axis)</span>
<span class="gi">+        null_mask |= (count &lt; min_count)</span>
<span class="gi">+</span>
<span class="gi">+    if null_mask.any():</span>
<span class="gi">+        result = result.copy()</span>
<span class="gi">+        result[null_mask] = np.nan</span>
<span class="gi">+</span>
<span class="gi">+    return result</span>


<span class="w"> </span>def _nan_argminmax_object(func, fill_value, value, axis=None, **kwargs):
<span class="w"> </span>    &quot;&quot;&quot;In house nanargmin, nanargmax for object arrays. Always return integer
<span class="w"> </span>    type
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    valid_count = count(value, axis=axis)</span>
<span class="gi">+    value = fillna(value, fill_value)</span>
<span class="gi">+    result = func(value, axis=axis, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(result, tuple):</span>
<span class="gi">+        # In case func returns both values and indices</span>
<span class="gi">+        result = result[1]</span>
<span class="gi">+</span>
<span class="gi">+    return where(valid_count == 0, -1, result).astype(int)</span>


<span class="w"> </span>def _nan_minmax_object(func, fill_value, value, axis=None, **kwargs):
<span class="w"> </span>    &quot;&quot;&quot;In house nanmin and nanmax for object array&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    valid_count = count(value, axis=axis)</span>
<span class="gi">+    value = fillna(value, fill_value)</span>
<span class="gi">+    result = func(value, axis=axis, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    return where(valid_count == 0, np.nan, result)</span>


<span class="w"> </span>def _nanmean_ddof_object(ddof, value, axis=None, dtype=None, **kwargs):
<span class="w"> </span>    &quot;&quot;&quot;In house nanmean. ddof argument will be used in _nanvar method&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    mask = ~isnull(value)</span>
<span class="gi">+    value = astype(value, dtype=dtype) if dtype is not None else value</span>
<span class="gi">+</span>
<span class="gi">+    count = mask.sum(axis=axis)</span>
<span class="gi">+    sum_value = sum_where(value, mask, axis=axis, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(count, np.ndarray):</span>
<span class="gi">+        count = count.astype(&#39;float64&#39;)</span>
<span class="gi">+    else:</span>
<span class="gi">+        count = float(count)</span>
<span class="gi">+</span>
<span class="gi">+    return sum_value / np.maximum(count - ddof, 1)</span>
<span class="gh">diff --git a/xarray/core/nputils.py b/xarray/core/nputils.py</span>
<span class="gh">index abe87b99..b4e3d0ee 100644</span>
<span class="gd">--- a/xarray/core/nputils.py</span>
<span class="gi">+++ b/xarray/core/nputils.py</span>
<span class="gu">@@ -40,17 +40,39 @@ def inverse_permutation(indices: np.ndarray, N: (int | None)=None</span>
<span class="w"> </span>        Integer indices to take from the original array to create the
<span class="w"> </span>        permutation.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if N is None:</span>
<span class="gi">+        N = len(indices)</span>
<span class="gi">+    inverse = np.empty(N, dtype=int)</span>
<span class="gi">+    inverse[indices] = np.arange(len(indices))</span>
<span class="gi">+    return inverse</span>


<span class="w"> </span>def _is_contiguous(positions):
<span class="w"> </span>    &quot;&quot;&quot;Given a non-empty list, does it consist of contiguous integers?&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if len(positions) &lt;= 1:</span>
<span class="gi">+        return True</span>
<span class="gi">+    return np.all(np.diff(positions) == 1)</span>


<span class="w"> </span>def _advanced_indexer_subspaces(key):
<span class="w"> </span>    &quot;&quot;&quot;Indices of the advanced indexes subspaces for mixed indexing and vindex.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not isinstance(key, tuple):</span>
<span class="gi">+        key = (key,)</span>
<span class="gi">+    </span>
<span class="gi">+    advanced_indexes = [</span>
<span class="gi">+        i for i, k in enumerate(key)</span>
<span class="gi">+        if isinstance(k, (np.ndarray, list)) and (</span>
<span class="gi">+            isinstance(k, np.ndarray) or isinstance(k[0], (int, np.integer))</span>
<span class="gi">+        )</span>
<span class="gi">+    ]</span>
<span class="gi">+    </span>
<span class="gi">+    if not advanced_indexes:</span>
<span class="gi">+        return [], []</span>
<span class="gi">+    </span>
<span class="gi">+    mixed_positions = advanced_indexes</span>
<span class="gi">+    vindex_positions = list(range(len(advanced_indexes)))</span>
<span class="gi">+    </span>
<span class="gi">+    return mixed_positions, vindex_positions</span>


<span class="w"> </span>class NumpyVIndexAdapter:
<span class="gh">diff --git a/xarray/core/ops.py b/xarray/core/ops.py</span>
<span class="gh">index f0f8e050..bdb83c8e 100644</span>
<span class="gd">--- a/xarray/core/ops.py</span>
<span class="gi">+++ b/xarray/core/ops.py</span>
<span class="gu">@@ -101,7 +101,15 @@ def fillna(data, other, join=&#39;left&#39;, dataset_join=&#39;left&#39;):</span>
<span class="w"> </span>        - &quot;left&quot;: take only variables from the first object
<span class="w"> </span>        - &quot;right&quot;: take only variables from the last object
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if hasattr(data, &#39;fillna&#39;):</span>
<span class="gi">+        return data.fillna(other, join=join, dataset_join=dataset_join)</span>
<span class="gi">+    elif isinstance(data, np.ndarray):</span>
<span class="gi">+        if np.isscalar(other) or isinstance(other, np.ndarray):</span>
<span class="gi">+            return np.where(np.isnan(data), other, data)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise TypeError(&quot;&#39;other&#39; must be a scalar or numpy array&quot;)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(&quot;&#39;data&#39; must be a xarray object or numpy array&quot;)</span>


<span class="w"> </span>def where_method(self, cond, other=dtypes.NA):
<span class="gu">@@ -119,7 +127,14 @@ def where_method(self, cond, other=dtypes.NA):</span>
<span class="w"> </span>    -------
<span class="w"> </span>    Same type as caller.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if hasattr(self, &#39;where&#39;):</span>
<span class="gi">+        return self.where(cond, other)</span>
<span class="gi">+    elif isinstance(self, np.ndarray):</span>
<span class="gi">+        if other is dtypes.NA:</span>
<span class="gi">+            other = np.nan</span>
<span class="gi">+        return np.where(cond, self, other)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(&quot;&#39;self&#39; must be a xarray object or numpy array&quot;)</span>


<span class="w"> </span>NON_INPLACE_OP = {get_op(&#39;i&#39; + name): get_op(name) for name in NUM_BINARY_OPS}
<span class="gh">diff --git a/xarray/core/options.py b/xarray/core/options.py</span>
<span class="gh">index ca162668..8408eb90 100644</span>
<span class="gd">--- a/xarray/core/options.py</span>
<span class="gi">+++ b/xarray/core/options.py</span>
<span class="gu">@@ -224,9 +224,14 @@ def get_options():</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Get options for xarray.

<span class="gi">+    Returns</span>
<span class="gi">+    -------</span>
<span class="gi">+    dict</span>
<span class="gi">+        A dictionary containing the current options for xarray.</span>
<span class="gi">+</span>
<span class="w"> </span>    See Also
<span class="w"> </span>    ----------
<span class="w"> </span>    set_options

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return dict(OPTIONS)</span>
<span class="gh">diff --git a/xarray/core/parallel.py b/xarray/core/parallel.py</span>
<span class="gh">index 9f983816..f4635477 100644</span>
<span class="gd">--- a/xarray/core/parallel.py</span>
<span class="gi">+++ b/xarray/core/parallel.py</span>
<span class="gu">@@ -30,20 +30,32 @@ def make_meta(obj):</span>
<span class="w"> </span>    backend.
<span class="w"> </span>    If obj is neither a DataArray nor Dataset, return it unaltered.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(obj, (DataArray, Dataset)):</span>
<span class="gi">+        new_obj = obj.copy()</span>
<span class="gi">+        for var_name, var in new_obj.variables.items():</span>
<span class="gi">+            new_obj[var_name] = Variable(var.dims, np.array([], dtype=var.dtype))</span>
<span class="gi">+        return new_obj</span>
<span class="gi">+    return obj</span>


<span class="w"> </span>def infer_template(func: Callable[..., T_Xarray], obj: (DataArray | Dataset
<span class="w"> </span>    ), *args, **kwargs) -&gt;T_Xarray:
<span class="w"> </span>    &quot;&quot;&quot;Infer return object by running the function on meta objects.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    meta_obj = make_meta(obj)</span>
<span class="gi">+    meta_args = tuple(make_meta(arg) if isinstance(arg, (DataArray, Dataset)) else arg for arg in args)</span>
<span class="gi">+    return func(meta_obj, *meta_args, **kwargs)</span>


<span class="w"> </span>def make_dict(x: (DataArray | Dataset)) -&gt;dict[Hashable, Any]:
<span class="w"> </span>    &quot;&quot;&quot;Map variable name to numpy(-like) data
<span class="w"> </span>    (Dataset.to_dict() is too complicated).
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(x, DataArray):</span>
<span class="gi">+        return {x.name: x.data}</span>
<span class="gi">+    elif isinstance(x, Dataset):</span>
<span class="gi">+        return {name: var.data for name, var in x.variables.items()}</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(f&quot;Expected DataArray or Dataset, got {type(x)}&quot;)</span>


<span class="w"> </span>def subset_dataset_to_block(graph: dict, gname: str, dataset: Dataset,
<span class="gu">@@ -53,7 +65,20 @@ def subset_dataset_to_block(graph: dict, gname: str, dataset: Dataset,</span>
<span class="w"> </span>    Block extents are determined by input_chunk_bounds.
<span class="w"> </span>    Also subtasks that subset the constituent variables of a dataset.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    def subset_variable(var, bounds):</span>
<span class="gi">+        slices = tuple(slice(start, stop) for start, stop in bounds)</span>
<span class="gi">+        return var[slices]</span>
<span class="gi">+</span>
<span class="gi">+    subset_tasks = {}</span>
<span class="gi">+    for name, var in dataset.variables.items():</span>
<span class="gi">+        bounds = [input_chunk_bounds[dim][i] for dim, i in zip(var.dims, chunk_index)]</span>
<span class="gi">+        subset_tasks[name] = (subset_variable, var, bounds)</span>
<span class="gi">+</span>
<span class="gi">+    def reconstruct_dataset(subsets):</span>
<span class="gi">+        return Dataset(subsets)</span>
<span class="gi">+</span>
<span class="gi">+    graph[gname] = (reconstruct_dataset, subset_tasks)</span>
<span class="gi">+    return graph[gname]</span>


<span class="w"> </span>def map_blocks(func: Callable[..., T_Xarray], obj: (DataArray | Dataset),
<span class="gu">@@ -156,4 +181,34 @@ def map_blocks(func: Callable[..., T_Xarray], obj: (DataArray | Dataset),</span>
<span class="w"> </span>      * time     (time) object 192B 1990-01-31 00:00:00 ... 1991-12-31 00:00:00
<span class="w"> </span>        month    (time) int64 192B dask.array&lt;chunksize=(24,), meta=np.ndarray&gt;
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if kwargs is None:</span>
<span class="gi">+        kwargs = {}</span>
<span class="gi">+</span>
<span class="gi">+    if not is_dask_collection(obj):</span>
<span class="gi">+        return func(obj, *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    if template is None:</span>
<span class="gi">+        template = infer_template(func, obj, *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def wrapped_func(block, *block_args):</span>
<span class="gi">+        result = func(block, *block_args, **kwargs)</span>
<span class="gi">+        if isinstance(result, (DataArray, Dataset)):</span>
<span class="gi">+            result = make_dict(result)</span>
<span class="gi">+        return result</span>
<span class="gi">+</span>
<span class="gi">+    dask_args = [</span>
<span class="gi">+        arg.data if isinstance(arg, (DataArray, Dataset)) else arg</span>
<span class="gi">+        for arg in args</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(obj, DataArray):</span>
<span class="gi">+        data = obj.data.map_blocks(wrapped_func, *dask_args, dtype=template.dtype)</span>
<span class="gi">+        return DataArray(data, dims=template.dims, coords=template.coords, attrs=template.attrs)</span>
<span class="gi">+    elif isinstance(obj, Dataset):</span>
<span class="gi">+        data = {</span>
<span class="gi">+            name: var.data.map_blocks(wrapped_func, *dask_args, dtype=template[name].dtype)</span>
<span class="gi">+            for name, var in obj.data_vars.items()</span>
<span class="gi">+        }</span>
<span class="gi">+        return Dataset(data, coords=template.coords, attrs=template.attrs)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(f&quot;Expected DataArray or Dataset, got {type(obj)}&quot;)</span>
<span class="gh">diff --git a/xarray/core/pdcompat.py b/xarray/core/pdcompat.py</span>
<span class="gh">index cecf4d90..349c36c8 100644</span>
<span class="gd">--- a/xarray/core/pdcompat.py</span>
<span class="gi">+++ b/xarray/core/pdcompat.py</span>
<span class="gu">@@ -10,7 +10,7 @@ def count_not_none(*args) -&gt;int:</span>

<span class="w"> </span>    Copied from pandas.core.common.count_not_none (not part of the public API)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return sum(arg is not None for arg in args)</span>


<span class="w"> </span>class _NoDefault(Enum):
<span class="gu">@@ -39,4 +39,5 @@ def nanosecond_precision_timestamp(*args, **kwargs) -&gt;pd.Timestamp:</span>
<span class="w"> </span>    Note this function should no longer be needed after addressing GitHub issue
<span class="w"> </span>    #7493.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    ts = pd.Timestamp(*args, **kwargs)</span>
<span class="gi">+    return ts.round(&#39;ns&#39;)</span>
<span class="gh">diff --git a/xarray/core/resample.py b/xarray/core/resample.py</span>
<span class="gh">index 147ca143..c8b38651 100644</span>
<span class="gd">--- a/xarray/core/resample.py</span>
<span class="gi">+++ b/xarray/core/resample.py</span>
<span class="gu">@@ -36,7 +36,9 @@ class Resample(GroupBy[T_Xarray]):</span>

<span class="w"> </span>    def _drop_coords(self) -&gt;T_Xarray:
<span class="w"> </span>        &quot;&quot;&quot;Drop non-dimension coordinates along the resampled dimension.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        obj = self._obj</span>
<span class="gi">+        dim = self._dim or self.dim</span>
<span class="gi">+        return obj.drop_vars([c for c in obj.coords if c != dim and dim in obj[c].dims])</span>

<span class="w"> </span>    def pad(self, tolerance: (float | Iterable[float] | str | None)=None
<span class="w"> </span>        ) -&gt;T_Xarray:
<span class="gu">@@ -56,7 +58,11 @@ class Resample(GroupBy[T_Xarray]):</span>
<span class="w"> </span>        -------
<span class="w"> </span>        padded : DataArray or Dataset
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.reindex(</span>
<span class="gi">+            {self._dim: self.grouper.full_index},</span>
<span class="gi">+            method=&quot;pad&quot;,</span>
<span class="gi">+            tolerance=tolerance</span>
<span class="gi">+        )</span>
<span class="w"> </span>    ffill = pad

<span class="w"> </span>    def backfill(self, tolerance: (float | Iterable[float] | str | None)=None
<span class="gu">@@ -77,7 +83,11 @@ class Resample(GroupBy[T_Xarray]):</span>
<span class="w"> </span>        -------
<span class="w"> </span>        backfilled : DataArray or Dataset
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.reindex(</span>
<span class="gi">+            {self._dim: self.grouper.full_index},</span>
<span class="gi">+            method=&quot;backfill&quot;,</span>
<span class="gi">+            tolerance=tolerance</span>
<span class="gi">+        )</span>
<span class="w"> </span>    bfill = backfill

<span class="w"> </span>    def nearest(self, tolerance: (float | Iterable[float] | str | None)=None
<span class="gu">@@ -99,7 +109,11 @@ class Resample(GroupBy[T_Xarray]):</span>
<span class="w"> </span>        -------
<span class="w"> </span>        upsampled : DataArray or Dataset
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.reindex(</span>
<span class="gi">+            {self._dim: self.grouper.full_index},</span>
<span class="gi">+            method=&quot;nearest&quot;,</span>
<span class="gi">+            tolerance=tolerance</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def interpolate(self, kind: InterpOptions=&#39;linear&#39;, **kwargs) -&gt;T_Xarray:
<span class="w"> </span>        &quot;&quot;&quot;Interpolate up-sampled data using the original data as knots.
<span class="gu">@@ -128,11 +142,21 @@ class Resample(GroupBy[T_Xarray]):</span>
<span class="w"> </span>        scipy.interpolate.interp1d

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._interpolate(kind=kind, **kwargs)</span>

<span class="w"> </span>    def _interpolate(self, kind=&#39;linear&#39;, **kwargs) -&gt;T_Xarray:
<span class="w"> </span>        &quot;&quot;&quot;Apply scipy.interpolate.interp1d along resampling dimension.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from scipy import interpolate</span>
<span class="gi">+</span>
<span class="gi">+        obj = self._obj</span>
<span class="gi">+        dim = self._dim or self.dim</span>
<span class="gi">+        index = obj.get_index(dim)</span>
<span class="gi">+        target_index = self.grouper.full_index</span>
<span class="gi">+</span>
<span class="gi">+        interpolator = interpolate.interp1d(index, obj.values, kind=kind, axis=obj.get_axis_num(dim), **kwargs)</span>
<span class="gi">+        interpolated_values = interpolator(target_index)</span>
<span class="gi">+</span>
<span class="gi">+        return obj.copy(data=interpolated_values).reindex({dim: target_index})</span>


<span class="w"> </span>class DataArrayResample(Resample[&#39;DataArray&#39;], DataArrayGroupByBase,
<span class="gu">@@ -168,7 +192,15 @@ class DataArrayResample(Resample[&#39;DataArray&#39;], DataArrayGroupByBase,</span>
<span class="w"> </span>            Array with summarized data and the indicated dimension(s)
<span class="w"> </span>            removed.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.groupby(self.grouper.group_indices).reduce(</span>
<span class="gi">+            func,</span>
<span class="gi">+            dim=dim,</span>
<span class="gi">+            axis=axis,</span>
<span class="gi">+            keep_attrs=keep_attrs,</span>
<span class="gi">+            keepdims=keepdims,</span>
<span class="gi">+            shortcut=shortcut,</span>
<span class="gi">+            **kwargs</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def map(self, func: Callable[..., Any], args: tuple[Any, ...]=(),
<span class="w"> </span>        shortcut: (bool | None)=False, **kwargs: Any) -&gt;DataArray:
<span class="gu">@@ -213,7 +245,12 @@ class DataArrayResample(Resample[&#39;DataArray&#39;], DataArrayGroupByBase,</span>
<span class="w"> </span>        applied : DataArray
<span class="w"> </span>            The result of splitting, applying and combining this array.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.groupby(self.grouper.group_indices).map(</span>
<span class="gi">+            func,</span>
<span class="gi">+            args=args,</span>
<span class="gi">+            shortcut=shortcut,</span>
<span class="gi">+            **kwargs</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def apply(self, func, args=(), shortcut=None, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -233,7 +270,7 @@ class DataArrayResample(Resample[&#39;DataArray&#39;], DataArrayGroupByBase,</span>
<span class="w"> </span>        -------
<span class="w"> </span>        resampled : DataArray
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.reindex({self._dim: self.grouper.full_index})</span>


<span class="w"> </span>class DatasetResample(Resample[&#39;Dataset&#39;], DatasetGroupByBase,
<span class="gu">@@ -271,7 +308,12 @@ class DatasetResample(Resample[&#39;Dataset&#39;], DatasetGroupByBase,</span>
<span class="w"> </span>        applied : Dataset
<span class="w"> </span>            The result of splitting, applying and combining this dataset.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.groupby(self.grouper.group_indices).map(</span>
<span class="gi">+            func,</span>
<span class="gi">+            args=args,</span>
<span class="gi">+            shortcut=shortcut,</span>
<span class="gi">+            **kwargs</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def apply(self, func, args=(), shortcut=None, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -310,7 +352,15 @@ class DatasetResample(Resample[&#39;Dataset&#39;], DatasetGroupByBase,</span>
<span class="w"> </span>            Array with summarized data and the indicated dimension(s)
<span class="w"> </span>            removed.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.groupby(self.grouper.group_indices).reduce(</span>
<span class="gi">+            func,</span>
<span class="gi">+            dim=dim,</span>
<span class="gi">+            axis=axis,</span>
<span class="gi">+            keep_attrs=keep_attrs,</span>
<span class="gi">+            keepdims=keepdims,</span>
<span class="gi">+            shortcut=shortcut,</span>
<span class="gi">+            **kwargs</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def asfreq(self) -&gt;Dataset:
<span class="w"> </span>        &quot;&quot;&quot;Return values of original object at the new up-sampling frequency;
<span class="gu">@@ -320,4 +370,4 @@ class DatasetResample(Resample[&#39;Dataset&#39;], DatasetGroupByBase,</span>
<span class="w"> </span>        -------
<span class="w"> </span>        resampled : Dataset
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._obj.reindex({self._dim: self.grouper.full_index})</span>
<span class="gh">diff --git a/xarray/core/resample_cftime.py b/xarray/core/resample_cftime.py</span>
<span class="gh">index c819839a..46e65c38 100644</span>
<span class="gd">--- a/xarray/core/resample_cftime.py</span>
<span class="gi">+++ b/xarray/core/resample_cftime.py</span>
<span class="gu">@@ -74,7 +74,10 @@ class CFTimeGrouper:</span>

<span class="w"> </span>        with index being a CFTimeIndex instead of a DatetimeIndex.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        bins = _get_time_bins(index, self.freq, self.closed, self.label, self.origin, self.offset)</span>
<span class="gi">+        grouper = pd.Grouper(freq=self.freq, closed=self.closed, label=self.label)</span>
<span class="gi">+        series = pd.Series(np.arange(len(index)), index=index)</span>
<span class="gi">+        return series.groupby(grouper).first()</span>


<span class="w"> </span>def _get_time_bins(index: CFTimeIndex, freq: BaseCFTimeOffset, closed:
<span class="gu">@@ -119,7 +122,15 @@ def _get_time_bins(index: CFTimeIndex, freq: BaseCFTimeOffset, closed:</span>
<span class="w"> </span>    labels : CFTimeIndex
<span class="w"> </span>        Define what the user actually sees the bins labeled as.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    start, end = _get_range_edges(index[0], index[-1], freq, closed, origin, offset)</span>
<span class="gi">+    datetime_bins = cftime_range(start, end, freq=freq)</span>
<span class="gi">+    </span>
<span class="gi">+    if isinstance(freq, (MonthEnd, QuarterEnd, YearEnd)):</span>
<span class="gi">+        datetime_bins, labels = _adjust_bin_edges(datetime_bins, freq, closed, index, datetime_bins)</span>
<span class="gi">+    else:</span>
<span class="gi">+        labels = datetime_bins</span>
<span class="gi">+</span>
<span class="gi">+    return datetime_bins, labels</span>


<span class="w"> </span>def _adjust_bin_edges(datetime_bins: CFTimeIndex, freq: BaseCFTimeOffset,
<span class="gu">@@ -155,7 +166,17 @@ def _adjust_bin_edges(datetime_bins: CFTimeIndex, freq: BaseCFTimeOffset,</span>

<span class="w"> </span>    CFTimeIndex([2000-01-31 00:00:00, 2000-02-29 00:00:00], dtype=&#39;object&#39;)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    adjusted_bins = CFTimeIndex([</span>
<span class="gi">+        bin_edge + datetime.timedelta(days=1, microseconds=-1)</span>
<span class="gi">+        for bin_edge in datetime_bins</span>
<span class="gi">+    ])</span>
<span class="gi">+    </span>
<span class="gi">+    if closed == &#39;right&#39;:</span>
<span class="gi">+        labels = adjusted_bins[1:]</span>
<span class="gi">+    else:</span>
<span class="gi">+        labels = adjusted_bins[:-1]</span>
<span class="gi">+    </span>
<span class="gi">+    return adjusted_bins, labels</span>


<span class="w"> </span>def _get_range_edges(first: CFTimeDatetime, last: CFTimeDatetime, freq:
<span class="gu">@@ -198,7 +219,23 @@ def _get_range_edges(first: CFTimeDatetime, last: CFTimeDatetime, freq:</span>
<span class="w"> </span>    last : cftime.datetime
<span class="w"> </span>        Corrected ending datetime object for resampled CFTimeIndex range.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(freq, Tick):</span>
<span class="gi">+        first, last = _adjust_dates_anchored(first, last, freq, closed, origin, offset)</span>
<span class="gi">+    else:</span>
<span class="gi">+        if closed == &#39;left&#39;:</span>
<span class="gi">+            first = normalize_date(first)</span>
<span class="gi">+        else:</span>
<span class="gi">+            first = first + freq</span>
<span class="gi">+            first = normalize_date(first) - datetime.timedelta(microseconds=1)</span>
<span class="gi">+</span>
<span class="gi">+        last = last + freq</span>
<span class="gi">+        last = normalize_date(last) - datetime.timedelta(microseconds=1)</span>
<span class="gi">+</span>
<span class="gi">+    if offset:</span>
<span class="gi">+        first += offset</span>
<span class="gi">+        last += offset</span>
<span class="gi">+</span>
<span class="gi">+    return first, last</span>


<span class="w"> </span>def _adjust_dates_anchored(first: CFTimeDatetime, last: CFTimeDatetime,
<span class="gu">@@ -243,7 +280,36 @@ def _adjust_dates_anchored(first: CFTimeDatetime, last: CFTimeDatetime,</span>
<span class="w"> </span>        A datetime object representing the end of a date range that has been
<span class="w"> </span>        adjusted to fix resampling errors.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if origin == &#39;epoch&#39;:</span>
<span class="gi">+        origin = first.replace(year=1970, month=1, day=1, hour=0, minute=0, second=0, microsecond=0)</span>
<span class="gi">+    elif origin == &#39;start&#39;:</span>
<span class="gi">+        origin = first</span>
<span class="gi">+    elif origin == &#39;start_day&#39;:</span>
<span class="gi">+        origin = first.replace(hour=0, minute=0, second=0, microsecond=0)</span>
<span class="gi">+    elif origin == &#39;end&#39;:</span>
<span class="gi">+        origin = last</span>
<span class="gi">+    elif origin == &#39;end_day&#39;:</span>
<span class="gi">+        origin = last.replace(hour=23, minute=59, second=59, microsecond=999999)</span>
<span class="gi">+    elif isinstance(origin, CFTimeDatetime):</span>
<span class="gi">+        pass</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(&quot;origin must be one of &#39;epoch&#39;, &#39;start&#39;, &#39;start_day&#39;, &#39;end&#39;, &#39;end_day&#39; or a cftime.datetime&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if offset:</span>
<span class="gi">+        origin += offset</span>
<span class="gi">+</span>
<span class="gi">+    delta = exact_cftime_datetime_difference(origin, first)</span>
<span class="gi">+    n = int(delta / freq.delta)</span>
<span class="gi">+    if closed == &#39;left&#39;:</span>
<span class="gi">+        fresult = origin + n * freq.delta</span>
<span class="gi">+    else:</span>
<span class="gi">+        fresult = origin + (n + 1) * freq.delta</span>
<span class="gi">+</span>
<span class="gi">+    delta = exact_cftime_datetime_difference(origin, last)</span>
<span class="gi">+    n = int(delta / freq.delta)</span>
<span class="gi">+    lresult = origin + (n + 1) * freq.delta</span>
<span class="gi">+</span>
<span class="gi">+    return fresult, lresult</span>


<span class="w"> </span>def exact_cftime_datetime_difference(a: CFTimeDatetime, b: CFTimeDatetime):
<span class="gu">@@ -280,4 +346,10 @@ def exact_cftime_datetime_difference(a: CFTimeDatetime, b: CFTimeDatetime):</span>
<span class="w"> </span>    -------
<span class="w"> </span>    datetime.timedelta
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    a_0 = a.replace(microsecond=0)</span>
<span class="gi">+    b_0 = b.replace(microsecond=0)</span>
<span class="gi">+    </span>
<span class="gi">+    delta_seconds = (b_0 - a_0).total_seconds()</span>
<span class="gi">+    delta_microseconds = b.microsecond - a.microsecond</span>
<span class="gi">+    </span>
<span class="gi">+    return datetime.timedelta(seconds=delta_seconds, microseconds=delta_microseconds)</span>
<span class="gh">diff --git a/xarray/core/rolling.py b/xarray/core/rolling.py</span>
<span class="gh">index 5a608958..7674818f 100644</span>
<span class="gd">--- a/xarray/core/rolling.py</span>
<span class="gi">+++ b/xarray/core/rolling.py</span>
<span class="gu">@@ -124,7 +124,15 @@ class Rolling(Generic[T_Xarray]):</span>
<span class="w"> </span>        need context of xarray options, of the functions each library offers, of
<span class="w"> </span>        the array (e.g. dtype).
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        def func(self, keep_attrs=None, **kwargs):</span>
<span class="gi">+            return self.reduce(</span>
<span class="gi">+                lambda x, axis: getattr(np, name)(x, axis=axis),</span>
<span class="gi">+                keep_attrs=keep_attrs,</span>
<span class="gi">+                **kwargs</span>
<span class="gi">+            )</span>
<span class="gi">+        func.__name__ = name</span>
<span class="gi">+        func.__doc__ = _ROLLING_REDUCE_DOCSTRING_TEMPLATE.format(name=name)</span>
<span class="gi">+        return func</span>
<span class="w"> </span>    _mean.__doc__ = _ROLLING_REDUCE_DOCSTRING_TEMPLATE.format(name=&#39;mean&#39;)
<span class="w"> </span>    argmax = _reduce_method(&#39;argmax&#39;, dtypes.NINF)
<span class="w"> </span>    argmin = _reduce_method(&#39;argmin&#39;, dtypes.INF)
<span class="gu">@@ -254,7 +262,51 @@ class DataArrayRolling(Rolling[&#39;DataArray&#39;]):</span>
<span class="w"> </span>        Dimensions without coordinates: a, b, window_dim

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from xarray.core.dataarray import DataArray</span>
<span class="gi">+</span>
<span class="gi">+        window_dim = either_dict_or_kwargs(window_dim, window_dim_kwargs, &quot;construct&quot;)</span>
<span class="gi">+        if len(window_dim) != len(self.dim):</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                f&quot;window_dim must be specified for all dimensions in rolling object: {self.dim}&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        window = {d: self.window[i] for i, d in enumerate(self.dim)}</span>
<span class="gi">+        center = {d: self.center[i] for i, d in enumerate(self.dim)}</span>
<span class="gi">+</span>
<span class="gi">+        data = self.obj.data</span>
<span class="gi">+        dims = self.obj.dims</span>
<span class="gi">+        coords = self.obj.coords.copy()</span>
<span class="gi">+</span>
<span class="gi">+        for dim, new_dim in window_dim.items():</span>
<span class="gi">+            axis = self.obj.get_axis_num(dim)</span>
<span class="gi">+            shape = list(data.shape)</span>
<span class="gi">+            if isinstance(stride, Mapping):</span>
<span class="gi">+                dim_stride = stride.get(dim, 1)</span>
<span class="gi">+            else:</span>
<span class="gi">+                dim_stride = stride</span>
<span class="gi">+</span>
<span class="gi">+            if center[dim]:</span>
<span class="gi">+                pad_left = (window[dim] - 1) // 2</span>
<span class="gi">+                pad_right = window[dim] - 1 - pad_left</span>
<span class="gi">+                shape[axis] = max(0, (shape[axis] - window[dim]) // dim_stride + 1)</span>
<span class="gi">+                data = np.pad(data, [(0, 0)] * axis + [(pad_left, pad_right)] + [(0, 0)] * (data.ndim - axis - 1), mode=&quot;constant&quot;, constant_values=fill_value)</span>
<span class="gi">+            else:</span>
<span class="gi">+                shape[axis] = max(0, (shape[axis] - window[dim]) // dim_stride + 1)</span>
<span class="gi">+</span>
<span class="gi">+            strides = list(data.strides)</span>
<span class="gi">+            strides[axis] = strides[axis] * dim_stride</span>
<span class="gi">+</span>
<span class="gi">+            data = np.lib.stride_tricks.as_strided(data, shape=shape + [window[dim]], strides=strides + [data.strides[axis]])</span>
<span class="gi">+</span>
<span class="gi">+            dims = dims[:axis] + (dims[axis], new_dim) + dims[axis + 1:]</span>
<span class="gi">+            coords[new_dim] = DataArray(np.arange(window[dim]), dims=new_dim)</span>
<span class="gi">+</span>
<span class="gi">+        result = DataArray(data, dims=dims, coords=coords)</span>
<span class="gi">+        if keep_attrs is None:</span>
<span class="gi">+            keep_attrs = _get_keep_attrs(default=True)</span>
<span class="gi">+        if keep_attrs:</span>
<span class="gi">+            result.attrs = self.obj.attrs</span>
<span class="gi">+        return result</span>

<span class="w"> </span>    def reduce(self, func: Callable, keep_attrs: (bool | None)=None, **
<span class="w"> </span>        kwargs: Any) -&gt;DataArray:
<span class="gu">@@ -309,11 +361,37 @@ class DataArrayRolling(Rolling[&#39;DataArray&#39;]):</span>
<span class="w"> </span>               [ 4.,  9., 15., 18.]])
<span class="w"> </span>        Dimensions without coordinates: a, b
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from xarray.core.dataarray import DataArray</span>
<span class="gi">+</span>
<span class="gi">+        rolling_dim = self.obj.dims[self.obj.get_axis_num(self.dim[0])]</span>
<span class="gi">+        windows = self.obj.rolling_window(rolling_dim, self.window[0])</span>
<span class="gi">+        </span>
<span class="gi">+        if keep_attrs is None:</span>
<span class="gi">+            keep_attrs = _get_keep_attrs(default=True)</span>
<span class="gi">+</span>
<span class="gi">+        result = windows.reduce(func, dim=&quot;window&quot;, keep_attrs=keep_attrs, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+        if self.min_periods is not None:</span>
<span class="gi">+            count = windows.count(dim=&quot;window&quot;)</span>
<span class="gi">+            result = result.where(count &gt;= self.min_periods)</span>
<span class="gi">+</span>
<span class="gi">+        return result</span>

<span class="w"> </span>    def _counts(self, keep_attrs: (bool | None)) -&gt;DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Number of non-nan entries in each rolling window.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from xarray.core.dataarray import DataArray</span>
<span class="gi">+</span>
<span class="gi">+        rolling_dim = self.obj.dims[self.obj.get_axis_num(self.dim[0])]</span>
<span class="gi">+        windows = self.obj.rolling_window(rolling_dim, self.window[0])</span>
<span class="gi">+</span>
<span class="gi">+        counts = windows.count(dim=&quot;window&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        if keep_attrs is None:</span>
<span class="gi">+            keep_attrs = _get_keep_attrs(default=True)</span>
<span class="gi">+        if keep_attrs:</span>
<span class="gi">+            counts.attrs = self.obj.attrs</span>
<span class="gi">+</span>
<span class="gi">+        return counts</span>


<span class="w"> </span>class DatasetRolling(Rolling[&#39;Dataset&#39;]):
<span class="gu">@@ -366,7 +444,7 @@ class DatasetRolling(Rolling[&#39;Dataset&#39;]):</span>
<span class="w"> </span>                    center)

<span class="w"> </span>    def reduce(self, func: Callable, keep_attrs: (bool | None)=None, **
<span class="gd">-        kwargs: Any) -&gt;DataArray:</span>
<span class="gi">+        kwargs: Any) -&gt;Dataset:</span>
<span class="w"> </span>        &quot;&quot;&quot;Reduce the items in this group by applying `func` along some
<span class="w"> </span>        dimension(s).

<span class="gu">@@ -385,10 +463,26 @@ class DatasetRolling(Rolling[&#39;Dataset&#39;]):</span>

<span class="w"> </span>        Returns
<span class="w"> </span>        -------
<span class="gd">-        reduced : DataArray</span>
<span class="gd">-            Array with summarized data.</span>
<span class="gi">+        reduced : Dataset</span>
<span class="gi">+            Dataset with summarized data.</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from xarray.core.dataset import Dataset</span>
<span class="gi">+</span>
<span class="gi">+        reduced = {}</span>
<span class="gi">+        for key, da in self.obj.data_vars.items():</span>
<span class="gi">+            if key in self.rollings:</span>
<span class="gi">+                reduced[key] = self.rollings[key].reduce(func, keep_attrs=keep_attrs, **kwargs)</span>
<span class="gi">+            else:</span>
<span class="gi">+                reduced[key] = da</span>
<span class="gi">+</span>
<span class="gi">+        result = Dataset(reduced)</span>
<span class="gi">+</span>
<span class="gi">+        if keep_attrs is None:</span>
<span class="gi">+            keep_attrs = _get_keep_attrs(default=True)</span>
<span class="gi">+        if keep_attrs:</span>
<span class="gi">+            result.attrs = self.obj.attrs</span>
<span class="gi">+</span>
<span class="gi">+        return result</span>

<span class="w"> </span>    def construct(self, window_dim: (Hashable | Mapping[Any, Hashable] |
<span class="w"> </span>        None)=None, stride: (int | Mapping[Any, int])=1, fill_value: Any=
<span class="gu">@@ -414,7 +508,31 @@ class DatasetRolling(Rolling[&#39;Dataset&#39;]):</span>
<span class="w"> </span>        -------
<span class="w"> </span>        Dataset with variables converted from rolling object.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from xarray.core.dataset import Dataset</span>
<span class="gi">+</span>
<span class="gi">+        window_dim = either_dict_or_kwargs(window_dim, window_dim_kwargs, &quot;construct&quot;)</span>
<span class="gi">+        if len(window_dim) != len(self.dim):</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                f&quot;window_dim must be specified for all dimensions in rolling object: {self.dim}&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        dataset = {}</span>
<span class="gi">+        for key, da in self.obj.data_vars.items():</span>
<span class="gi">+            if key in self.rollings:</span>
<span class="gi">+                dataset[key] = self.rollings[key].construct(</span>
<span class="gi">+                    window_dim, stride, fill_value, keep_attrs</span>
<span class="gi">+                )</span>
<span class="gi">+            else:</span>
<span class="gi">+                dataset[key] = da</span>
<span class="gi">+</span>
<span class="gi">+        result = Dataset(dataset)</span>
<span class="gi">+</span>
<span class="gi">+        if keep_attrs is None:</span>
<span class="gi">+            keep_attrs = _get_keep_attrs(default=True)</span>
<span class="gi">+        if keep_attrs:</span>
<span class="gi">+            result.attrs = self.obj.attrs</span>
<span class="gi">+</span>
<span class="gi">+        return result</span>


<span class="w"> </span>class Coarsen(CoarsenArithmetic, Generic[T_Xarray]):
<span class="gh">diff --git a/xarray/core/rolling_exp.py b/xarray/core/rolling_exp.py</span>
<span class="gh">index a86a17a1..37d9ed7d 100644</span>
<span class="gd">--- a/xarray/core/rolling_exp.py</span>
<span class="gi">+++ b/xarray/core/rolling_exp.py</span>
<span class="gu">@@ -16,7 +16,27 @@ def _get_alpha(com: (float | None)=None, span: (float | None)=None,</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Convert com, span, halflife to alpha.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if count_not_none(com, span, halflife, alpha) != 1:</span>
<span class="gi">+        raise ValueError(&quot;Must specify exactly one of com, span, halflife, or alpha&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if alpha is not None:</span>
<span class="gi">+        if not 0 &lt; alpha &lt;= 1:</span>
<span class="gi">+            raise ValueError(&quot;alpha must be in (0, 1]&quot;)</span>
<span class="gi">+        return alpha</span>
<span class="gi">+    elif com is not None:</span>
<span class="gi">+        if com &lt; 0:</span>
<span class="gi">+            raise ValueError(&quot;com must be &gt;= 0&quot;)</span>
<span class="gi">+        return 1 / (1 + com)</span>
<span class="gi">+    elif span is not None:</span>
<span class="gi">+        if span &lt; 1:</span>
<span class="gi">+            raise ValueError(&quot;span must be &gt;= 1&quot;)</span>
<span class="gi">+        return 2 / (span + 1)</span>
<span class="gi">+    elif halflife is not None:</span>
<span class="gi">+        if halflife &lt;= 0:</span>
<span class="gi">+            raise ValueError(&quot;halflife must be &gt; 0&quot;)</span>
<span class="gi">+        return 1 - np.exp(np.log(0.5) / halflife)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(&quot;Must specify exactly one of com, span, halflife, or alpha&quot;)</span>


<span class="w"> </span>class RollingExp(Generic[T_DataWithCoords]):
<span class="gu">@@ -85,7 +105,16 @@ class RollingExp(Generic[T_DataWithCoords]):</span>
<span class="w"> </span>        array([1.        , 1.        , 1.69230769, 1.9       , 1.96694215])
<span class="w"> </span>        Dimensions without coordinates: x
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        import numbagg</span>
<span class="gi">+        keep_attrs = _get_keep_attrs(keep_attrs)</span>
<span class="gi">+        return apply_ufunc(</span>
<span class="gi">+            numbagg.move_exp_mean,</span>
<span class="gi">+            self.obj,</span>
<span class="gi">+            input_core_dims=[[self.dim]],</span>
<span class="gi">+            kwargs=self.kwargs,</span>
<span class="gi">+            keep_attrs=keep_attrs,</span>
<span class="gi">+            dask=&quot;allowed&quot;,</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def sum(self, keep_attrs: (bool | None)=None) -&gt;T_DataWithCoords:
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -106,7 +135,16 @@ class RollingExp(Generic[T_DataWithCoords]):</span>
<span class="w"> </span>        array([1.        , 1.33333333, 2.44444444, 2.81481481, 2.9382716 ])
<span class="w"> </span>        Dimensions without coordinates: x
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        import numbagg</span>
<span class="gi">+        keep_attrs = _get_keep_attrs(keep_attrs)</span>
<span class="gi">+        return apply_ufunc(</span>
<span class="gi">+            numbagg.move_exp_sum,</span>
<span class="gi">+            self.obj,</span>
<span class="gi">+            input_core_dims=[[self.dim]],</span>
<span class="gi">+            kwargs=self.kwargs,</span>
<span class="gi">+            keep_attrs=keep_attrs,</span>
<span class="gi">+            dask=&quot;allowed&quot;,</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def std(self) -&gt;T_DataWithCoords:
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -122,7 +160,15 @@ class RollingExp(Generic[T_DataWithCoords]):</span>
<span class="w"> </span>        array([       nan, 0.        , 0.67936622, 0.42966892, 0.25389527])
<span class="w"> </span>        Dimensions without coordinates: x
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        import numbagg</span>
<span class="gi">+        return apply_ufunc(</span>
<span class="gi">+            numbagg.move_exp_std,</span>
<span class="gi">+            self.obj,</span>
<span class="gi">+            input_core_dims=[[self.dim]],</span>
<span class="gi">+            kwargs=self.kwargs,</span>
<span class="gi">+            keep_attrs=True,</span>
<span class="gi">+            dask=&quot;allowed&quot;,</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def var(self) -&gt;T_DataWithCoords:
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -138,7 +184,15 @@ class RollingExp(Generic[T_DataWithCoords]):</span>
<span class="w"> </span>        array([       nan, 0.        , 0.46153846, 0.18461538, 0.06446281])
<span class="w"> </span>        Dimensions without coordinates: x
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        import numbagg</span>
<span class="gi">+        return apply_ufunc(</span>
<span class="gi">+            numbagg.move_exp_var,</span>
<span class="gi">+            self.obj,</span>
<span class="gi">+            input_core_dims=[[self.dim]],</span>
<span class="gi">+            kwargs=self.kwargs,</span>
<span class="gi">+            keep_attrs=True,</span>
<span class="gi">+            dask=&quot;allowed&quot;,</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def cov(self, other: T_DataWithCoords) -&gt;T_DataWithCoords:
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -154,7 +208,16 @@ class RollingExp(Generic[T_DataWithCoords]):</span>
<span class="w"> </span>        array([       nan, 0.        , 1.38461538, 0.55384615, 0.19338843])
<span class="w"> </span>        Dimensions without coordinates: x
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        import numbagg</span>
<span class="gi">+        return apply_ufunc(</span>
<span class="gi">+            numbagg.move_exp_cov,</span>
<span class="gi">+            self.obj,</span>
<span class="gi">+            other,</span>
<span class="gi">+            input_core_dims=[[self.dim], [self.dim]],</span>
<span class="gi">+            kwargs=self.kwargs,</span>
<span class="gi">+            keep_attrs=True,</span>
<span class="gi">+            dask=&quot;allowed&quot;,</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def corr(self, other: T_DataWithCoords) -&gt;T_DataWithCoords:
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -170,4 +233,13 @@ class RollingExp(Generic[T_DataWithCoords]):</span>
<span class="w"> </span>        array([       nan,        nan,        nan, 0.4330127 , 0.48038446])
<span class="w"> </span>        Dimensions without coordinates: x
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        import numbagg</span>
<span class="gi">+        return apply_ufunc(</span>
<span class="gi">+            numbagg.move_exp_corr,</span>
<span class="gi">+            self.obj,</span>
<span class="gi">+            other,</span>
<span class="gi">+            input_core_dims=[[self.dim], [self.dim]],</span>
<span class="gi">+            kwargs=self.kwargs,</span>
<span class="gi">+            keep_attrs=True,</span>
<span class="gi">+            dask=&quot;allowed&quot;,</span>
<span class="gi">+        )</span>
<span class="gh">diff --git a/xarray/core/treenode.py b/xarray/core/treenode.py</span>
<span class="gh">index 30d6e6d1..503f2d68 100644</span>
<span class="gd">--- a/xarray/core/treenode.py</span>
<span class="gi">+++ b/xarray/core/treenode.py</span>
<span class="gu">@@ -74,77 +74,101 @@ class TreeNode(Generic[Tree]):</span>
<span class="w"> </span>    @property
<span class="w"> </span>    def parent(self) -&gt;(Tree | None):
<span class="w"> </span>        &quot;&quot;&quot;Parent of this node.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._parent</span>

<span class="w"> </span>    def _check_loop(self, new_parent: (Tree | None)) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;Checks that assignment of this new parent will not create a cycle.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if new_parent is not None:</span>
<span class="gi">+            if new_parent is self:</span>
<span class="gi">+                raise InvalidTreeError(&quot;Cannot set a node as its own parent&quot;)</span>
<span class="gi">+            if new_parent in self.descendants:</span>
<span class="gi">+                raise InvalidTreeError(&quot;Cannot set a descendant as parent&quot;)</span>

<span class="w"> </span>    def orphan(self) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;Detach this node from its parent.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self._parent is not None:</span>
<span class="gi">+            self._pre_detach(self._parent)</span>
<span class="gi">+            del self._parent._children[self.name]</span>
<span class="gi">+            self._parent = None</span>
<span class="gi">+            self._post_detach(self._parent)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def children(self: Tree) -&gt;Mapping[str, Tree]:
<span class="w"> </span>        &quot;&quot;&quot;Child nodes of this node, stored under a mapping via their names.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return Frozen(self._children)</span>

<span class="w"> </span>    @staticmethod
<span class="w"> </span>    def _check_children(children: Mapping[str, Tree]) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;Check children for correct types and for any duplicates.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if not is_dict_like(children):</span>
<span class="gi">+            raise TypeError(&quot;Children must be a mapping&quot;)</span>
<span class="gi">+        for name, child in children.items():</span>
<span class="gi">+            if not isinstance(name, str):</span>
<span class="gi">+                raise TypeError(&quot;Child names must be strings&quot;)</span>
<span class="gi">+            if not isinstance(child, TreeNode):</span>
<span class="gi">+                raise TypeError(&quot;Children must be TreeNode instances&quot;)</span>

<span class="w"> </span>    def __repr__(self) -&gt;str:
<span class="w"> </span>        return f&#39;TreeNode(children={dict(self._children)})&#39;

<span class="w"> </span>    def _pre_detach_children(self: Tree, children: Mapping[str, Tree]) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;Method call before detaching `children`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        for child in children.values():</span>
<span class="gi">+            child._pre_detach(self)</span>

<span class="w"> </span>    def _post_detach_children(self: Tree, children: Mapping[str, Tree]) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;Method call after detaching `children`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        for child in children.values():</span>
<span class="gi">+            child._post_detach(self)</span>

<span class="w"> </span>    def _pre_attach_children(self: Tree, children: Mapping[str, Tree]) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;Method call before attaching `children`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        for name, child in children.items():</span>
<span class="gi">+            child._pre_attach(self, name)</span>

<span class="w"> </span>    def _post_attach_children(self: Tree, children: Mapping[str, Tree]) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;Method call after attaching `children`.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        for name, child in children.items():</span>
<span class="gi">+            child._post_attach(self, name)</span>

<span class="w"> </span>    def _iter_parents(self: Tree) -&gt;Iterator[Tree]:
<span class="w"> </span>        &quot;&quot;&quot;Iterate up the tree, starting from the current node&#39;s parent.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        node = self.parent</span>
<span class="gi">+        while node is not None:</span>
<span class="gi">+            yield node</span>
<span class="gi">+            node = node.parent</span>

<span class="w"> </span>    def iter_lineage(self: Tree) -&gt;tuple[Tree, ...]:
<span class="w"> </span>        &quot;&quot;&quot;Iterate up the tree, starting from the current node.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return (self,) + tuple(self._iter_parents())</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def lineage(self: Tree) -&gt;tuple[Tree, ...]:
<span class="w"> </span>        &quot;&quot;&quot;All parent nodes and their parent nodes, starting with the closest.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.iter_lineage()</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def parents(self: Tree) -&gt;tuple[Tree, ...]:
<span class="w"> </span>        &quot;&quot;&quot;All parent nodes and their parent nodes, starting with the closest.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return tuple(self._iter_parents())</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def ancestors(self: Tree) -&gt;tuple[Tree, ...]:
<span class="w"> </span>        &quot;&quot;&quot;All parent nodes and their parent nodes, starting with the most distant.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return tuple(reversed(self.parents))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def root(self: Tree) -&gt;Tree:
<span class="w"> </span>        &quot;&quot;&quot;Root node of the tree&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        node = self</span>
<span class="gi">+        while node.parent is not None:</span>
<span class="gi">+            node = node.parent</span>
<span class="gi">+        return node</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def is_root(self) -&gt;bool:
<span class="w"> </span>        &quot;&quot;&quot;Whether this node is the tree root.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.parent is None</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def is_leaf(self) -&gt;bool:
<span class="gu">@@ -153,7 +177,7 @@ class TreeNode(Generic[Tree]):</span>

<span class="w"> </span>        Leaf nodes are defined as nodes which have no children.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return len(self.children) == 0</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def leaves(self: Tree) -&gt;tuple[Tree, ...]:
<span class="gu">@@ -162,14 +186,16 @@ class TreeNode(Generic[Tree]):</span>

<span class="w"> </span>        Leaf nodes are defined as nodes which have no children.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return tuple(node for node in self.subtree if node.is_leaf)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def siblings(self: Tree) -&gt;dict[str, Tree]:
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Nodes with the same parent as this node.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.parent is None:</span>
<span class="gi">+            return {}</span>
<span class="gi">+        return {name: child for name, child in self.parent.children.items() if child is not self}</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def subtree(self: Tree) -&gt;Iterator[Tree]:
<span class="gu">@@ -182,7 +208,9 @@ class TreeNode(Generic[Tree]):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        DataTree.descendants
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        yield self</span>
<span class="gi">+        for child in self.children.values():</span>
<span class="gi">+            yield from child.subtree</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def descendants(self: Tree) -&gt;tuple[Tree, ...]:
<span class="gu">@@ -195,7 +223,7 @@ class TreeNode(Generic[Tree]):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        DataTree.subtree
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return tuple(node for node in self.subtree if node is not self)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def level(self: Tree) -&gt;int:
<span class="gu">@@ -214,7 +242,7 @@ class TreeNode(Generic[Tree]):</span>
<span class="w"> </span>        depth
<span class="w"> </span>        width
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return len(self.parents)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def depth(self: Tree) -&gt;int:
<span class="gu">@@ -232,7 +260,7 @@ class TreeNode(Generic[Tree]):</span>
<span class="w"> </span>        level
<span class="w"> </span>        width
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return max(node.level for node in self.subtree)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def width(self: Tree) -&gt;int:
<span class="gu">@@ -250,7 +278,7 @@ class TreeNode(Generic[Tree]):</span>
<span class="w"> </span>        level
<span class="w"> </span>        depth
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return sum(1 for node in self.root.subtree if node.level == self.level)</span>

<span class="w"> </span>    def _pre_detach(self: Tree, parent: Tree) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;Method call before detaching from `parent`.&quot;&quot;&quot;
<span class="gu">@@ -275,7 +303,7 @@ class TreeNode(Generic[Tree]):</span>
<span class="w"> </span>        Only looks for the node within the immediate children of this node,
<span class="w"> </span>        not in other nodes of the tree.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.children.get(key, default)</span>

<span class="w"> </span>    def _get_item(self: Tree, path: (str | NodePath)) -&gt;(Tree | T_DataArray):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -283,7 +311,23 @@ class TreeNode(Generic[Tree]):</span>

<span class="w"> </span>        Raises a KeyError if there is no object at the given path.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(path, str):</span>
<span class="gi">+            path = NodePath(path)</span>
<span class="gi">+        </span>
<span class="gi">+        current = self</span>
<span class="gi">+        for part in path.parts:</span>
<span class="gi">+            if part == &#39;..&#39;:</span>
<span class="gi">+                if current.parent is None:</span>
<span class="gi">+                    raise KeyError(f&quot;Cannot go up from root node: {path}&quot;)</span>
<span class="gi">+                current = current.parent</span>
<span class="gi">+            elif part == &#39;.&#39;:</span>
<span class="gi">+                continue</span>
<span class="gi">+            else:</span>
<span class="gi">+                try:</span>
<span class="gi">+                    current = current.children[part]</span>
<span class="gi">+                except KeyError:</span>
<span class="gi">+                    raise KeyError(f&quot;No such child: {part} in path {path}&quot;)</span>
<span class="gi">+        return current</span>

<span class="w"> </span>    def _set(self: Tree, key: str, val: Tree) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -291,7 +335,13 @@ class TreeNode(Generic[Tree]):</span>

<span class="w"> </span>        Counterpart to the public .get method, and also only works on the immediate node, not other nodes in the tree.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if not isinstance(val, TreeNode):</span>
<span class="gi">+            raise TypeError(&quot;Child must be a TreeNode instance&quot;)</span>
<span class="gi">+        if key in self._children:</span>
<span class="gi">+            self._children[key].orphan()</span>
<span class="gi">+        self._children[key] = val</span>
<span class="gi">+        val._parent = self</span>
<span class="gi">+        val._name = key</span>

<span class="w"> </span>    def _set_item(self: Tree, path: (str | NodePath), item: (Tree |
<span class="w"> </span>        T_DataArray), new_nodes_along_path: bool=False, allow_overwrite:
<span class="gu">@@ -319,20 +369,39 @@ class TreeNode(Generic[Tree]):</span>
<span class="w"> </span>            If node cannot be reached, and new_nodes_along_path=False.
<span class="w"> </span>            Or if a node already exists at the specified path, and allow_overwrite=False.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def __delitem__(self: Tree, key: str):</span>
<span class="gd">-        &quot;&quot;&quot;Remove a child node from this tree object.&quot;&quot;&quot;</span>
<span class="gd">-        if key in self.children:</span>
<span class="gd">-            child = self._children[key]</span>
<span class="gd">-            del self._children[key]</span>
<span class="gd">-            child.orphan()</span>
<span class="gd">-        else:</span>
<span class="gd">-            raise KeyError(&#39;Cannot delete&#39;)</span>
<span class="gi">+        if isinstance(path, str):</span>
<span class="gi">+            path = NodePath(path)</span>
<span class="gi">+        </span>
<span class="gi">+        current = self</span>
<span class="gi">+        for i, part in enumerate(path.parts[:-1]):</span>
<span class="gi">+            if part == &#39;..&#39;:</span>
<span class="gi">+                if current.parent is None:</span>
<span class="gi">+                    raise KeyError(f&quot;Cannot go up from root node: {path}&quot;)</span>
<span class="gi">+                current = current.parent</span>
<span class="gi">+            elif part == &#39;.&#39;:</span>
<span class="gi">+                continue</span>
<span class="gi">+            else:</span>
<span class="gi">+                if part not in current.children:</span>
<span class="gi">+                    if new_nodes_along_path:</span>
<span class="gi">+                        new_node = type(self)(name=part)</span>
<span class="gi">+                        current._set(part, new_node)</span>
<span class="gi">+                        current = new_node</span>
<span class="gi">+                    else:</span>
<span class="gi">+                        raise KeyError(f&quot;No such child: {part} in path {path}&quot;)</span>
<span class="gi">+                else:</span>
<span class="gi">+                    current = current.children[part]</span>
<span class="gi">+        </span>
<span class="gi">+        last_part = path.parts[-1]</span>
<span class="gi">+        if last_part in current.children:</span>
<span class="gi">+            if not allow_overwrite:</span>
<span class="gi">+                raise KeyError(f&quot;Node already exists at path: {path}&quot;)</span>
<span class="gi">+            current._children[last_part].orphan()</span>
<span class="gi">+        </span>
<span class="gi">+        current._set(last_part, item)</span>

<span class="w"> </span>    def same_tree(self, other: Tree) -&gt;bool:
<span class="w"> </span>        &quot;&quot;&quot;True if other node is in the same tree as this node.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.root is other.root</span>


<span class="w"> </span>AnyNamedNode = TypeVar(&#39;AnyNamedNode&#39;, bound=&#39;NamedNode&#39;)
<span class="gh">diff --git a/xarray/core/utils.py b/xarray/core/utils.py</span>
<span class="gh">index fb70a0c1..20b3e753 100644</span>
<span class="gd">--- a/xarray/core/utils.py</span>
<span class="gi">+++ b/xarray/core/utils.py</span>
<span class="gu">@@ -31,7 +31,12 @@ def get_valid_numpy_dtype(array: (np.ndarray | pd.Index)) -&gt;np.dtype:</span>
<span class="w"> </span>    Used for wrapping a pandas.Index as an xarray.Variable.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(array, pd.Index):</span>
<span class="gi">+        dtype = array.dtype</span>
<span class="gi">+        if isinstance(dtype, pd.CategoricalDtype):</span>
<span class="gi">+            return np.dtype(object)</span>
<span class="gi">+        return dtype</span>
<span class="gi">+    return array.dtype</span>


<span class="w"> </span>def maybe_coerce_to_str(index, original_coords):
<span class="gu">@@ -39,7 +44,10 @@ def maybe_coerce_to_str(index, original_coords):</span>

<span class="w"> </span>    pd.Index uses object-dtype to store str - try to avoid this for coords
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(index, pd.Index) and index.dtype == object:</span>
<span class="gi">+        if original_coords is not None and isinstance(original_coords, np.ndarray) and original_coords.dtype.kind == &#39;U&#39;:</span>
<span class="gi">+            return index.values.astype(original_coords.dtype)</span>
<span class="gi">+    return index</span>


<span class="w"> </span>def maybe_wrap_array(original, new_array):
<span class="gu">@@ -48,7 +56,10 @@ def maybe_wrap_array(original, new_array):</span>
<span class="w"> </span>    This lets us treat arbitrary functions that take and return ndarray objects
<span class="w"> </span>    like ufuncs, as long as they return an array with the same shape.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if hasattr(original, &#39;__array_wrap__&#39;):</span>
<span class="gi">+        if new_array.shape == original.shape:</span>
<span class="gi">+            return original.__array_wrap__(new_array)</span>
<span class="gi">+    return new_array</span>


<span class="w"> </span>def equivalent(first: T, second: T) -&gt;bool:
<span class="gu">@@ -56,14 +67,25 @@ def equivalent(first: T, second: T) -&gt;bool:</span>
<span class="w"> </span>    array_equiv if either object is an ndarray. If both objects are lists,
<span class="w"> </span>    equivalent is sequentially called on all the elements.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if first is second:</span>
<span class="gi">+        return True</span>
<span class="gi">+    if isinstance(first, np.ndarray) or isinstance(second, np.ndarray):</span>
<span class="gi">+        return np.array_equiv(first, second)</span>
<span class="gi">+    if isinstance(first, list) and isinstance(second, list):</span>
<span class="gi">+        return len(first) == len(second) and all(equivalent(i, j) for i, j in zip(first, second))</span>
<span class="gi">+    return first == second</span>


<span class="w"> </span>def peek_at(iterable: Iterable[T]) -&gt;tuple[T, Iterator[T]]:
<span class="w"> </span>    &quot;&quot;&quot;Returns the first value from iterable, as well as a new iterator with
<span class="w"> </span>    the same content as the original iterable
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    iterator = iter(iterable)</span>
<span class="gi">+    try:</span>
<span class="gi">+        first_value = next(iterator)</span>
<span class="gi">+    except StopIteration:</span>
<span class="gi">+        return None, iter([])</span>
<span class="gi">+    return first_value, itertools.chain([first_value], iterator)</span>


<span class="w"> </span>def update_safety_check(first_dict: Mapping[K, V], second_dict: Mapping[K,
<span class="gh">diff --git a/xarray/core/weighted.py b/xarray/core/weighted.py</span>
<span class="gh">index b93a079c..2233699a 100644</span>
<span class="gd">--- a/xarray/core/weighted.py</span>
<span class="gi">+++ b/xarray/core/weighted.py</span>
<span class="gu">@@ -167,7 +167,10 @@ class Weighted(Generic[T_Xarray]):</span>

<span class="w"> </span>    def _check_dim(self, dim: Dims):
<span class="w"> </span>        &quot;&quot;&quot;raise an error if any dimension is missing&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(dim, str):</span>
<span class="gi">+            dim = [dim]</span>
<span class="gi">+        if any(d not in self.obj.dims for d in dim):</span>
<span class="gi">+            raise ValueError(f&quot;Dimensions {dim} not found in {self.obj.dims}&quot;)</span>

<span class="w"> </span>    @staticmethod
<span class="w"> </span>    def _reduce(da: T_DataArray, weights: T_DataArray, dim: Dims=None,
<span class="gu">@@ -176,41 +179,77 @@ class Weighted(Generic[T_Xarray]):</span>

<span class="w"> </span>        for internal use only
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return dot(da, weights, dims=dim)</span>

<span class="w"> </span>    def _sum_of_weights(self, da: T_DataArray, dim: Dims=None) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Calculate the sum of weights, accounting for missing values&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        weights = self.weights.where(da.notnull())</span>
<span class="gi">+        return weights.sum(dim=dim)</span>

<span class="w"> </span>    def _sum_of_squares(self, da: T_DataArray, dim: Dims=None, skipna: (
<span class="w"> </span>        bool | None)=None) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Reduce a DataArray by a weighted ``sum_of_squares`` along some dimension(s).&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._reduce(da ** 2, self.weights, dim=dim, skipna=skipna)</span>

<span class="w"> </span>    def _weighted_sum(self, da: T_DataArray, dim: Dims=None, skipna: (bool |
<span class="w"> </span>        None)=None) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Reduce a DataArray by a weighted ``sum`` along some dimension(s).&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._reduce(da, self.weights, dim=dim, skipna=skipna)</span>

<span class="w"> </span>    def _weighted_mean(self, da: T_DataArray, dim: Dims=None, skipna: (bool |
<span class="w"> </span>        None)=None) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Reduce a DataArray by a weighted ``mean`` along some dimension(s).&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        sum_of_weights = self._sum_of_weights(da, dim=dim)</span>
<span class="gi">+        weighted_sum = self._weighted_sum(da, dim=dim, skipna=skipna)</span>
<span class="gi">+        return weighted_sum / sum_of_weights</span>

<span class="w"> </span>    def _weighted_var(self, da: T_DataArray, dim: Dims=None, skipna: (bool |
<span class="w"> </span>        None)=None) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Reduce a DataArray by a weighted ``var`` along some dimension(s).&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        mean = self._weighted_mean(da, dim=dim, skipna=skipna)</span>
<span class="gi">+        dev = (da - mean) ** 2</span>
<span class="gi">+        return self._reduce(dev, self.weights, dim=dim, skipna=skipna) / self._sum_of_weights(da, dim=dim)</span>

<span class="w"> </span>    def _weighted_std(self, da: T_DataArray, dim: Dims=None, skipna: (bool |
<span class="w"> </span>        None)=None) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Reduce a DataArray by a weighted ``std`` along some dimension(s).&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return np.sqrt(self._weighted_var(da, dim=dim, skipna=skipna))</span>

<span class="w"> </span>    def _weighted_quantile(self, da: T_DataArray, q: ArrayLike, dim: Dims=
<span class="w"> </span>        None, skipna: (bool | None)=None) -&gt;T_DataArray:
<span class="w"> </span>        &quot;&quot;&quot;Apply a weighted ``quantile`` to a DataArray along some dimension(s).&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if skipna is None:</span>
<span class="gi">+            skipna = False</span>
<span class="gi">+</span>
<span class="gi">+        if dim is None:</span>
<span class="gi">+            dim = da.dims</span>
<span class="gi">+</span>
<span class="gi">+        q = np.asarray(q)</span>
<span class="gi">+        if np.any(q &lt; 0) or np.any(q &gt; 1):</span>
<span class="gi">+            raise ValueError(&quot;Quantiles must be between 0 and 1&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        weights = self.weights</span>
<span class="gi">+        if skipna:</span>
<span class="gi">+            mask = da.notnull()</span>
<span class="gi">+            da = da.where(mask, drop=True)</span>
<span class="gi">+            weights = weights.where(mask, drop=True)</span>
<span class="gi">+</span>
<span class="gi">+        sorted_idx = da.argsort(dim=dim)</span>
<span class="gi">+        sorted_data = da.isel({d: sorted_idx for d in dim})</span>
<span class="gi">+        sorted_weights = weights.isel({d: sorted_idx for d in dim})</span>
<span class="gi">+</span>
<span class="gi">+        cumulative_weights = sorted_weights.cumsum(dim=dim)</span>
<span class="gi">+        total_weights = cumulative_weights.isel({d: -1 for d in dim})</span>
<span class="gi">+</span>
<span class="gi">+        # Normalize cumulative weights</span>
<span class="gi">+        cumulative_weights /= total_weights</span>
<span class="gi">+</span>
<span class="gi">+        # Calculate quantiles</span>
<span class="gi">+        result = sorted_data.interp({d: xr.DataArray(q, dims=&#39;quantile&#39;) for d in dim}, </span>
<span class="gi">+                                    xi=cumulative_weights, </span>
<span class="gi">+                                    method=&#39;linear&#39;)</span>
<span class="gi">+</span>
<span class="gi">+        return result.transpose(&#39;quantile&#39;, ...)</span>

<span class="w"> </span>    def __repr__(self) -&gt;str:
<span class="w"> </span>        &quot;&quot;&quot;provide a nice str repr of our Weighted object&quot;&quot;&quot;
<span class="gh">diff --git a/xarray/datatree_/docs/source/conf.py b/xarray/datatree_/docs/source/conf.py</span>
<span class="gh">index 2084912d..579f07dc 100644</span>
<span class="gd">--- a/xarray/datatree_/docs/source/conf.py</span>
<span class="gi">+++ b/xarray/datatree_/docs/source/conf.py</span>
<span class="gu">@@ -88,4 +88,40 @@ def linkcode_resolve(domain, info):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Determine the URL corresponding to Python object
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if domain != &#39;py&#39;:</span>
<span class="gi">+        return None</span>
<span class="gi">+</span>
<span class="gi">+    modname = info[&#39;module&#39;]</span>
<span class="gi">+    fullname = info[&#39;fullname&#39;]</span>
<span class="gi">+</span>
<span class="gi">+    submod = sys.modules.get(modname)</span>
<span class="gi">+    if submod is None:</span>
<span class="gi">+        return None</span>
<span class="gi">+</span>
<span class="gi">+    obj = submod</span>
<span class="gi">+    for part in fullname.split(&#39;.&#39;):</span>
<span class="gi">+        try:</span>
<span class="gi">+            obj = getattr(obj, part)</span>
<span class="gi">+        except AttributeError:</span>
<span class="gi">+            return None</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        fn = inspect.getsourcefile(inspect.unwrap(obj))</span>
<span class="gi">+    except TypeError:</span>
<span class="gi">+        fn = None</span>
<span class="gi">+    if not fn:</span>
<span class="gi">+        return None</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        source, lineno = inspect.getsourcelines(obj)</span>
<span class="gi">+    except OSError:</span>
<span class="gi">+        lineno = None</span>
<span class="gi">+</span>
<span class="gi">+    if lineno:</span>
<span class="gi">+        linespec = f&quot;#L{lineno}-L{lineno + len(source) - 1}&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        linespec = &quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+    fn = os.path.relpath(fn, start=os.path.dirname(datatree.__file__))</span>
<span class="gi">+</span>
<span class="gi">+    return f&quot;{srclink_project}/blob/{srclink_branch}/datatree/{fn}{linespec}&quot;</span>
<span class="gh">diff --git a/xarray/groupers.py b/xarray/groupers.py</span>
<span class="gh">index dcb05c0a..d9542873 100644</span>
<span class="gd">--- a/xarray/groupers.py</span>
<span class="gi">+++ b/xarray/groupers.py</span>
<span class="gu">@@ -94,7 +94,9 @@ class UniqueGrouper(Grouper):</span>
<span class="w"> </span>    @property
<span class="w"> </span>    def group_as_index(self) -&gt;pd.Index:
<span class="w"> </span>        &quot;&quot;&quot;Caches the group DataArray as a pandas Index.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self._group_as_index is None:</span>
<span class="gi">+            self._group_as_index = safe_cast_to_index(self._group)</span>
<span class="gi">+        return self._group_as_index</span>


<span class="w"> </span>@dataclass
<span class="gu">@@ -205,4 +207,16 @@ def unique_value_groups(ar, sort: bool=True) -&gt;tuple[np.ndarray | pd.Index,</span>
<span class="w"> </span>        Each element provides the integer indices in `ar` with values given by
<span class="w"> </span>        the corresponding value in `unique_values`.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    ar = np.asarray(ar).flatten()</span>
<span class="gi">+    values, inverse = np.unique(ar, return_inverse=True, return_counts=False)</span>
<span class="gi">+</span>
<span class="gi">+    if sort:</span>
<span class="gi">+        sort_order = np.argsort(values)</span>
<span class="gi">+        values = values[sort_order]</span>
<span class="gi">+        inverse = np.argsort(sort_order)[inverse]</span>
<span class="gi">+</span>
<span class="gi">+    indices = [[] for _ in range(len(values))]</span>
<span class="gi">+    for n, g in enumerate(inverse):</span>
<span class="gi">+        indices[g].append(n)</span>
<span class="gi">+</span>
<span class="gi">+    return values, indices</span>
<span class="gh">diff --git a/xarray/namedarray/_aggregations.py b/xarray/namedarray/_aggregations.py</span>
<span class="gh">index c8843d3a..91481d8d 100644</span>
<span class="gd">--- a/xarray/namedarray/_aggregations.py</span>
<span class="gi">+++ b/xarray/namedarray/_aggregations.py</span>
<span class="gu">@@ -53,7 +53,7 @@ class NamedArrayAggregations:</span>
<span class="w"> </span>        &lt;xarray.NamedArray ()&gt; Size: 8B
<span class="w"> </span>        array(5)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.reduce(duck_array_ops.count, dim=dim, **kwargs)</span>

<span class="w"> </span>    def all(self, dim: Dims=None, **kwargs: Any) -&gt;Self:
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -99,7 +99,7 @@ class NamedArrayAggregations:</span>
<span class="w"> </span>        &lt;xarray.NamedArray ()&gt; Size: 1B
<span class="w"> </span>        array(False)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.reduce(duck_array_ops.all, dim=dim, **kwargs)</span>

<span class="w"> </span>    def any(self, dim: Dims=None, **kwargs: Any) -&gt;Self:
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -145,7 +145,7 @@ class NamedArrayAggregations:</span>
<span class="w"> </span>        &lt;xarray.NamedArray ()&gt; Size: 1B
<span class="w"> </span>        array(True)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.reduce(duck_array_ops.any, dim=dim, **kwargs)</span>

<span class="w"> </span>    def max(self, dim: Dims=None, *, skipna: (bool | None)=None, **kwargs: Any
<span class="w"> </span>        ) -&gt;Self:
<span class="gu">@@ -203,7 +203,7 @@ class NamedArrayAggregations:</span>
<span class="w"> </span>        &lt;xarray.NamedArray ()&gt; Size: 8B
<span class="w"> </span>        array(nan)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.reduce(duck_array_ops.max, dim=dim, skipna=skipna, **kwargs)</span>

<span class="w"> </span>    def min(self, dim: Dims=None, *, skipna: (bool | None)=None, **kwargs: Any
<span class="w"> </span>        ) -&gt;Self:
<span class="gu">@@ -261,7 +261,7 @@ class NamedArrayAggregations:</span>
<span class="w"> </span>        &lt;xarray.NamedArray ()&gt; Size: 8B
<span class="w"> </span>        array(nan)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.reduce(duck_array_ops.min, dim=dim, skipna=skipna, **kwargs)</span>

<span class="w"> </span>    def mean(self, dim: Dims=None, *, skipna: (bool | None)=None, **kwargs: Any
<span class="w"> </span>        ) -&gt;Self:
<span class="gu">@@ -323,7 +323,7 @@ class NamedArrayAggregations:</span>
<span class="w"> </span>        &lt;xarray.NamedArray ()&gt; Size: 8B
<span class="w"> </span>        array(nan)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.reduce(duck_array_ops.mean, dim=dim, skipna=skipna, **kwargs)</span>

<span class="w"> </span>    def prod(self, dim: Dims=None, *, skipna: (bool | None)=None, min_count:
<span class="w"> </span>        (int | None)=None, **kwargs: Any) -&gt;Self:
<span class="gu">@@ -397,7 +397,7 @@ class NamedArrayAggregations:</span>
<span class="w"> </span>        &lt;xarray.NamedArray ()&gt; Size: 8B
<span class="w"> </span>        array(0.)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.reduce(duck_array_ops.prod, dim=dim, skipna=skipna, min_count=min_count, **kwargs)</span>

<span class="w"> </span>    def sum(self, dim: Dims=None, *, skipna: (bool | None)=None, min_count:
<span class="w"> </span>        (int | None)=None, **kwargs: Any) -&gt;Self:
<span class="gu">@@ -471,7 +471,7 @@ class NamedArrayAggregations:</span>
<span class="w"> </span>        &lt;xarray.NamedArray ()&gt; Size: 8B
<span class="w"> </span>        array(8.)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.reduce(duck_array_ops.sum, dim=dim, skipna=skipna, min_count=min_count, **kwargs)</span>

<span class="w"> </span>    def std(self, dim: Dims=None, *, skipna: (bool | None)=None, ddof: int=
<span class="w"> </span>        0, **kwargs: Any) -&gt;Self:
<span class="gu">@@ -675,7 +675,7 @@ class NamedArrayAggregations:</span>
<span class="w"> </span>        &lt;xarray.NamedArray ()&gt; Size: 8B
<span class="w"> </span>        array(nan)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.reduce(duck_array_ops.median, dim=dim, skipna=skipna, **kwargs)</span>

<span class="w"> </span>    def cumsum(self, dim: Dims=None, *, skipna: (bool | None)=None, **
<span class="w"> </span>        kwargs: Any) -&gt;Self:
<span class="gu">@@ -737,7 +737,7 @@ class NamedArrayAggregations:</span>
<span class="w"> </span>        &lt;xarray.NamedArray (x: 6)&gt; Size: 48B
<span class="w"> </span>        array([ 1.,  3.,  6.,  6.,  8., nan])
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.reduce(duck_array_ops.cumsum, dim=dim, skipna=skipna, **kwargs)</span>

<span class="w"> </span>    def cumprod(self, dim: Dims=None, *, skipna: (bool | None)=None, **
<span class="w"> </span>        kwargs: Any) -&gt;Self:
<span class="gu">@@ -799,4 +799,4 @@ class NamedArrayAggregations:</span>
<span class="w"> </span>        &lt;xarray.NamedArray (x: 6)&gt; Size: 48B
<span class="w"> </span>        array([ 1.,  2.,  6.,  0.,  0., nan])
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.reduce(duck_array_ops.cumprod, dim=dim, skipna=skipna, **kwargs)</span>
<span class="gh">diff --git a/xarray/namedarray/_array_api.py b/xarray/namedarray/_array_api.py</span>
<span class="gh">index b9c696ab..27ad2299 100644</span>
<span class="gd">--- a/xarray/namedarray/_array_api.py</span>
<span class="gi">+++ b/xarray/namedarray/_array_api.py</span>
<span class="gu">@@ -41,7 +41,9 @@ def astype(x: NamedArray[_ShapeType, Any], dtype: _DType, /, *, copy: bool=True</span>
<span class="w"> </span>    &lt;xarray.NamedArray (x: 2)&gt; Size: 8B
<span class="w"> </span>    array([1, 2], dtype=int32)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not copy and x.dtype == dtype:</span>
<span class="gi">+        return x</span>
<span class="gi">+    return NamedArray(x.dims, x.data.astype(dtype))</span>


<span class="w"> </span>def imag(x: NamedArray[_ShapeType, np.dtype[_SupportsImag[_ScalarType]]], /
<span class="gu">@@ -70,7 +72,7 @@ def imag(x: NamedArray[_ShapeType, np.dtype[_SupportsImag[_ScalarType]]], /</span>
<span class="w"> </span>    &lt;xarray.NamedArray (x: 2)&gt; Size: 16B
<span class="w"> </span>    array([2., 4.])
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return NamedArray(x.dims, np.imag(x.data))</span>


<span class="w"> </span>def real(x: NamedArray[_ShapeType, np.dtype[_SupportsReal[_ScalarType]]], /
<span class="gu">@@ -99,7 +101,7 @@ def real(x: NamedArray[_ShapeType, np.dtype[_SupportsReal[_ScalarType]]], /</span>
<span class="w"> </span>    &lt;xarray.NamedArray (x: 2)&gt; Size: 16B
<span class="w"> </span>    array([1., 2.])
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return NamedArray(x.dims, np.real(x.data))</span>


<span class="w"> </span>def expand_dims(x: NamedArray[Any, _DType], /, *, dim: (_Dim | Default)=
<span class="gu">@@ -134,7 +136,11 @@ def expand_dims(x: NamedArray[Any, _DType], /, *, dim: (_Dim | Default)=</span>
<span class="w"> </span>    array([[[1., 2.],
<span class="w"> </span>            [3., 4.]]])
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    new_data = np.expand_dims(x.data, axis=axis)</span>
<span class="gi">+    new_dims = list(x.dims)</span>
<span class="gi">+    new_dim = dim if dim is not _default else f&quot;dim_{len(x.dims)}&quot;</span>
<span class="gi">+    new_dims.insert(axis, new_dim)</span>
<span class="gi">+    return NamedArray(tuple(new_dims), new_data)</span>


<span class="w"> </span>def permute_dims(x: NamedArray[Any, _DType], axes: _Axes) -&gt;NamedArray[Any,
<span class="gu">@@ -156,4 +162,6 @@ def permute_dims(x: NamedArray[Any, _DType], axes: _Axes) -&gt;NamedArray[Any,</span>
<span class="w"> </span>        data type as x.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    new_data = np.transpose(x.data, axes)</span>
<span class="gi">+    new_dims = tuple(x.dims[i] for i in axes)</span>
<span class="gi">+    return NamedArray(new_dims, new_data)</span>
<span class="gh">diff --git a/xarray/namedarray/core.py b/xarray/namedarray/core.py</span>
<span class="gh">index 881d23bb..a51584c6 100644</span>
<span class="gd">--- a/xarray/namedarray/core.py</span>
<span class="gi">+++ b/xarray/namedarray/core.py</span>
<span class="gu">@@ -274,7 +274,7 @@ class NamedArray(NamedArrayAggregations, Generic[_ShapeType_co, _DType_co]):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        numpy.ndarray.shape
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._data.shape</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def nbytes(self) -&gt;_IntOrUnknown:
<span class="gu">@@ -284,17 +284,21 @@ class NamedArray(NamedArrayAggregations, Generic[_ShapeType_co, _DType_co]):</span>
<span class="w"> </span>        If the underlying data array does not include ``nbytes``, estimates
<span class="w"> </span>        the bytes consumed based on the ``size`` and ``dtype``.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if hasattr(self._data, &#39;nbytes&#39;):</span>
<span class="gi">+            return self._data.nbytes</span>
<span class="gi">+        return self.size * self.dtype.itemsize</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def dims(self) -&gt;_Dims:
<span class="w"> </span>        &quot;&quot;&quot;Tuple of dimension names with which this NamedArray is associated.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._dims</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def attrs(self) -&gt;dict[Any, Any]:
<span class="w"> </span>        &quot;&quot;&quot;Dictionary of local attributes on this NamedArray.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self._attrs is None:</span>
<span class="gi">+            self._attrs = {}</span>
<span class="gi">+        return self._attrs</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def data(self) -&gt;duckarray[Any, _DType_co]:
<span class="gu">@@ -303,7 +307,7 @@ class NamedArray(NamedArrayAggregations, Generic[_ShapeType_co, _DType_co]):</span>
<span class="w"> </span>        (e.g. dask, sparse, pint) is preserved.

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._data</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def imag(self: NamedArray[_ShapeType, np.dtype[_SupportsImag[_ScalarType]]]
<span class="gu">@@ -404,7 +408,9 @@ class NamedArray(NamedArrayAggregations, Generic[_ShapeType_co, _DType_co]):</span>
<span class="w"> </span>        int or tuple of int
<span class="w"> </span>            Axis number or numbers corresponding to the given dimensions.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(dim, Iterable) and not isinstance(dim, str):</span>
<span class="gi">+            return tuple(self._dims.index(d) for d in dim)</span>
<span class="gi">+        return self._dims.index(dim)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def chunks(self) -&gt;(_Chunks | None):
<span class="gu">@@ -418,7 +424,9 @@ class NamedArray(NamedArrayAggregations, Generic[_ShapeType_co, _DType_co]):</span>
<span class="w"> </span>        NamedArray.chunksizes
<span class="w"> </span>        xarray.unify_chunks
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if hasattr(self._data, &#39;chunks&#39;):</span>
<span class="gi">+            return self._data.chunks</span>
<span class="gi">+        return None</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def chunksizes(self) -&gt;Mapping[_Dim, _Shape]:
<span class="gu">@@ -436,12 +444,14 @@ class NamedArray(NamedArrayAggregations, Generic[_ShapeType_co, _DType_co]):</span>
<span class="w"> </span>        NamedArray.chunks
<span class="w"> </span>        xarray.unify_chunks
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.chunks is None:</span>
<span class="gi">+            return {}</span>
<span class="gi">+        return dict(zip(self._dims, self.chunks))</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def sizes(self) -&gt;dict[_Dim, _IntOrUnknown]:
<span class="w"> </span>        &quot;&quot;&quot;Ordered mapping from dimension names to lengths.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return dict(zip(self._dims, self.shape))</span>

<span class="w"> </span>    def chunk(self, chunks: T_Chunks={}, chunked_array_type: (str |
<span class="w"> </span>        ChunkManagerEntrypoint[Any] | None)=None, from_array_kwargs: Any=
<span class="gu">@@ -489,11 +499,11 @@ class NamedArray(NamedArrayAggregations, Generic[_ShapeType_co, _DType_co]):</span>

<span class="w"> </span>    def to_numpy(self) -&gt;np.ndarray[Any, Any]:
<span class="w"> </span>        &quot;&quot;&quot;Coerces wrapped data to numpy and returns a numpy.ndarray&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return np.asarray(self._data)</span>

<span class="w"> </span>    def as_numpy(self) -&gt;Self:
<span class="w"> </span>        &quot;&quot;&quot;Coerces wrapped data into a numpy array, returning a Variable.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._replace(data=self.to_numpy())</span>

<span class="w"> </span>    def reduce(self, func: Callable[..., Any], dim: Dims=None, axis: (int |
<span class="w"> </span>        Sequence[int] | None)=None, keepdims: bool=False, **kwargs: Any
<span class="gu">@@ -526,11 +536,32 @@ class NamedArray(NamedArrayAggregations, Generic[_ShapeType_co, _DType_co]):</span>
<span class="w"> </span>            Array with summarized data and the indicated dimension(s)
<span class="w"> </span>            removed.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if dim is not None and axis is not None:</span>
<span class="gi">+            raise ValueError(&quot;Cannot supply both &#39;dim&#39; and &#39;axis&#39;&quot;)</span>
<span class="gi">+        </span>
<span class="gi">+        if dim is not None:</span>
<span class="gi">+            if dim == &quot;...&quot;:</span>
<span class="gi">+                axis = tuple(range(self.ndim))</span>
<span class="gi">+            elif isinstance(dim, str):</span>
<span class="gi">+                axis = self.get_axis_num(dim)</span>
<span class="gi">+            else:</span>
<span class="gi">+                axis = tuple(self.get_axis_num(d) for d in dim)</span>
<span class="gi">+        </span>
<span class="gi">+        result = func(self._data, axis=axis, keepdims=keepdims, **kwargs)</span>
<span class="gi">+        </span>
<span class="gi">+        if keepdims:</span>
<span class="gi">+            new_dims = self._dims</span>
<span class="gi">+        elif axis is None:</span>
<span class="gi">+            new_dims = ()</span>
<span class="gi">+        else:</span>
<span class="gi">+            new_dims = tuple(d for i, d in enumerate(self._dims) if i not in (axis if isinstance(axis, tuple) else (axis,)))</span>
<span class="gi">+        </span>
<span class="gi">+        return self._new(dims=new_dims, data=result)</span>

<span class="w"> </span>    def _nonzero(self: T_NamedArrayInteger) -&gt;tuple[T_NamedArrayInteger, ...]:
<span class="w"> </span>        &quot;&quot;&quot;Equivalent numpy&#39;s nonzero but returns a tuple of NamedArrays.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        indices = np.nonzero(self._data)</span>
<span class="gi">+        return tuple(self._new(dims=(f&#39;dim_{i}&#39;,), data=idx) for i, idx in enumerate(indices))</span>

<span class="w"> </span>    def __repr__(self) -&gt;str:
<span class="w"> </span>        return formatting.array_repr(self)
<span class="gh">diff --git a/xarray/namedarray/daskmanager.py b/xarray/namedarray/daskmanager.py</span>
<span class="gh">index cfbd1e84..f9e3917b 100644</span>
<span class="gd">--- a/xarray/namedarray/daskmanager.py</span>
<span class="gi">+++ b/xarray/namedarray/daskmanager.py</span>
<span class="gu">@@ -28,4 +28,5 @@ class DaskManager(ChunkManagerEntrypoint[&#39;DaskArray&#39;]):</span>
<span class="w"> </span>        dtype: (_DType_co | None)=None, previous_chunks: (_NormalizedChunks |
<span class="w"> </span>        None)=None) -&gt;Any:
<span class="w"> </span>        &quot;&quot;&quot;Called by open_dataset&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from dask.array.core import normalize_chunks as dask_normalize_chunks</span>
<span class="gi">+        return dask_normalize_chunks(chunks, shape, limit, dtype, previous_chunks)</span>
<span class="gh">diff --git a/xarray/namedarray/dtypes.py b/xarray/namedarray/dtypes.py</span>
<span class="gh">index 5bebd041..a578e7bc 100644</span>
<span class="gd">--- a/xarray/namedarray/dtypes.py</span>
<span class="gi">+++ b/xarray/namedarray/dtypes.py</span>
<span class="gu">@@ -50,7 +50,16 @@ def maybe_promote(dtype: np.dtype[np.generic]) -&gt;tuple[np.dtype[np.generic],</span>
<span class="w"> </span>    dtype : Promoted dtype that can hold missing values.
<span class="w"> </span>    fill_value : Valid missing value for the promoted dtype.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if dtype.kind in [&#39;i&#39;, &#39;u&#39;]:</span>
<span class="gi">+        return np.dtype(&#39;float64&#39;), np.nan</span>
<span class="gi">+    elif dtype.kind == &#39;f&#39;:</span>
<span class="gi">+        return dtype, np.nan</span>
<span class="gi">+    elif dtype.kind in [&#39;M&#39;, &#39;m&#39;]:</span>
<span class="gi">+        return dtype, np.datetime64(&#39;NaT&#39;)</span>
<span class="gi">+    elif dtype.kind == &#39;b&#39;:</span>
<span class="gi">+        return np.dtype(&#39;object&#39;), NA</span>
<span class="gi">+    else:</span>
<span class="gi">+        return np.dtype(&#39;object&#39;), NA</span>


<span class="w"> </span>NAT_TYPES = {np.datetime64(&#39;NaT&#39;).dtype, np.timedelta64(&#39;NaT&#39;).dtype}
<span class="gu">@@ -67,7 +76,14 @@ def get_fill_value(dtype: np.dtype[np.generic]) -&gt;Any:</span>
<span class="w"> </span>    -------
<span class="w"> </span>    fill_value : Missing value corresponding to this dtype.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if dtype.kind in [&#39;i&#39;, &#39;u&#39;, &#39;f&#39;]:</span>
<span class="gi">+        return np.nan</span>
<span class="gi">+    elif dtype.kind in [&#39;M&#39;, &#39;m&#39;]:</span>
<span class="gi">+        return np.datetime64(&#39;NaT&#39;)</span>
<span class="gi">+    elif dtype.kind == &#39;b&#39;:</span>
<span class="gi">+        return NA</span>
<span class="gi">+    else:</span>
<span class="gi">+        return NA</span>


<span class="w"> </span>def get_pos_infinity(dtype: np.dtype[np.generic], max_for_int: bool=False) -&gt;(
<span class="gu">@@ -84,12 +100,19 @@ def get_pos_infinity(dtype: np.dtype[np.generic], max_for_int: bool=False) -&gt;(</span>
<span class="w"> </span>    -------
<span class="w"> </span>    fill_value : positive infinity value corresponding to this dtype.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if dtype.kind in [&#39;i&#39;, &#39;u&#39;]:</span>
<span class="gi">+        return np.iinfo(dtype).max if max_for_int else np.inf</span>
<span class="gi">+    elif dtype.kind == &#39;f&#39;:</span>
<span class="gi">+        return np.inf</span>
<span class="gi">+    elif dtype.kind == &#39;c&#39;:</span>
<span class="gi">+        return complex(np.inf, np.inf)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return INF</span>


<span class="w"> </span>def get_neg_infinity(dtype: np.dtype[np.generic], min_for_int: bool=False) -&gt;(
<span class="w"> </span>    float | complex | AlwaysLessThan):
<span class="gd">-    &quot;&quot;&quot;Return an appropriate positive infinity for this dtype.</span>
<span class="gi">+    &quot;&quot;&quot;Return an appropriate negative infinity for this dtype.</span>

<span class="w"> </span>    Parameters
<span class="w"> </span>    ----------
<span class="gu">@@ -99,15 +122,22 @@ def get_neg_infinity(dtype: np.dtype[np.generic], min_for_int: bool=False) -&gt;(</span>

<span class="w"> </span>    Returns
<span class="w"> </span>    -------
<span class="gd">-    fill_value : positive infinity value corresponding to this dtype.</span>
<span class="gi">+    fill_value : negative infinity value corresponding to this dtype.</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if dtype.kind in [&#39;i&#39;, &#39;u&#39;]:</span>
<span class="gi">+        return np.iinfo(dtype).min if min_for_int else -np.inf</span>
<span class="gi">+    elif dtype.kind == &#39;f&#39;:</span>
<span class="gi">+        return -np.inf</span>
<span class="gi">+    elif dtype.kind == &#39;c&#39;:</span>
<span class="gi">+        return complex(-np.inf, -np.inf)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return NINF</span>


<span class="w"> </span>def is_datetime_like(dtype: np.dtype[np.generic]) -&gt;TypeGuard[np.datetime64 |
<span class="w"> </span>    np.timedelta64]:
<span class="w"> </span>    &quot;&quot;&quot;Check if a dtype is a subclass of the numpy datetime types&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return dtype.kind in [&#39;M&#39;, &#39;m&#39;]</span>


<span class="w"> </span>def result_type(*arrays_and_dtypes: (np.typing.ArrayLike | np.typing.DTypeLike)
<span class="gu">@@ -127,4 +157,17 @@ def result_type(*arrays_and_dtypes: (np.typing.ArrayLike | np.typing.DTypeLike)</span>
<span class="w"> </span>    -------
<span class="w"> </span>    numpy.dtype for the result.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    dtypes = []</span>
<span class="gi">+    for array_or_dtype in arrays_and_dtypes:</span>
<span class="gi">+        if hasattr(array_or_dtype, &#39;dtype&#39;):</span>
<span class="gi">+            dtypes.append(array_or_dtype.dtype)</span>
<span class="gi">+        else:</span>
<span class="gi">+            dtypes.append(np.dtype(array_or_dtype))</span>
<span class="gi">+</span>
<span class="gi">+    result = np.result_type(*dtypes)</span>
<span class="gi">+</span>
<span class="gi">+    for t1, t2 in PROMOTE_TO_OBJECT:</span>
<span class="gi">+        if any(isinstance(dtype.type, t1) for dtype in dtypes) and any(isinstance(dtype.type, t2) for dtype in dtypes):</span>
<span class="gi">+            return np.dtype(&#39;object&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    return result</span>
<span class="gh">diff --git a/xarray/namedarray/parallelcompat.py b/xarray/namedarray/parallelcompat.py</span>
<span class="gh">index edcc83cd..e415a8f8 100644</span>
<span class="gd">--- a/xarray/namedarray/parallelcompat.py</span>
<span class="gi">+++ b/xarray/namedarray/parallelcompat.py</span>
<span class="gu">@@ -39,13 +39,25 @@ def list_chunkmanagers() -&gt;dict[str, ChunkManagerEntrypoint[Any]]:</span>
<span class="w"> </span>    -----
<span class="w"> </span>    # New selection mechanism introduced with Python 3.10. See GH6514.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    chunkmanagers = {}</span>
<span class="gi">+    for ep in entry_points(group=&#39;xarray.chunkmanagers&#39;):</span>
<span class="gi">+        try:</span>
<span class="gi">+            chunkmanagers[ep.name] = ep.load()()</span>
<span class="gi">+        except Exception:</span>
<span class="gi">+            emit_user_level_warning(f&quot;Failed to load chunkmanager {ep.name}&quot;)</span>
<span class="gi">+    return chunkmanagers</span>


<span class="w"> </span>def load_chunkmanagers(entrypoints: Sequence[EntryPoint]) -&gt;dict[str,
<span class="w"> </span>    ChunkManagerEntrypoint[Any]]:
<span class="w"> </span>    &quot;&quot;&quot;Load entrypoints and instantiate chunkmanagers only once.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    chunkmanagers = {}</span>
<span class="gi">+    for ep in entrypoints:</span>
<span class="gi">+        try:</span>
<span class="gi">+            chunkmanagers[ep.name] = ep.load()()</span>
<span class="gi">+        except Exception:</span>
<span class="gi">+            emit_user_level_warning(f&quot;Failed to load chunkmanager {ep.name}&quot;)</span>
<span class="gi">+    return chunkmanagers</span>


<span class="w"> </span>def guess_chunkmanager(manager: (str | ChunkManagerEntrypoint[Any] | None)
<span class="gu">@@ -56,7 +68,25 @@ def guess_chunkmanager(manager: (str | ChunkManagerEntrypoint[Any] | None)</span>
<span class="w"> </span>    If the name of a specific ChunkManager is given (e.g. &quot;dask&quot;), then use that.
<span class="w"> </span>    Else use whatever is installed, defaulting to dask if there are multiple options.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    chunkmanagers = list_chunkmanagers()</span>
<span class="gi">+    </span>
<span class="gi">+    if isinstance(manager, str):</span>
<span class="gi">+        if manager not in chunkmanagers:</span>
<span class="gi">+            raise ValueError(f&quot;Chunk manager &#39;{manager}&#39; not found.&quot;)</span>
<span class="gi">+        return chunkmanagers[manager]</span>
<span class="gi">+    elif isinstance(manager, ChunkManagerEntrypoint):</span>
<span class="gi">+        return manager</span>
<span class="gi">+    elif manager is None:</span>
<span class="gi">+        if &quot;dask&quot; in chunkmanagers:</span>
<span class="gi">+            return chunkmanagers[&quot;dask&quot;]</span>
<span class="gi">+        elif len(chunkmanagers) == 1:</span>
<span class="gi">+            return next(iter(chunkmanagers.values()))</span>
<span class="gi">+        elif len(chunkmanagers) &gt; 1:</span>
<span class="gi">+            raise ValueError(&quot;Multiple chunk managers available. Please specify one.&quot;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise ValueError(&quot;No chunk managers available.&quot;)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(f&quot;Invalid manager type: {type(manager)}&quot;)</span>


<span class="w"> </span>def get_chunked_array_type(*args: Any) -&gt;ChunkManagerEntrypoint[Any]:
<span class="gu">@@ -65,7 +95,21 @@ def get_chunked_array_type(*args: Any) -&gt;ChunkManagerEntrypoint[Any]:</span>

<span class="w"> </span>    Also checks that all arrays are of same chunking type (i.e. not a mix of cubed and dask).
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    chunkmanagers = list_chunkmanagers()</span>
<span class="gi">+    detected_managers = set()</span>
<span class="gi">+</span>
<span class="gi">+    for arg in args:</span>
<span class="gi">+        for manager in chunkmanagers.values():</span>
<span class="gi">+            if manager.is_chunked_array(arg):</span>
<span class="gi">+                detected_managers.add(manager)</span>
<span class="gi">+                break</span>
<span class="gi">+</span>
<span class="gi">+    if len(detected_managers) == 0:</span>
<span class="gi">+        raise ValueError(&quot;No chunked arrays detected.&quot;)</span>
<span class="gi">+    elif len(detected_managers) &gt; 1:</span>
<span class="gi">+        raise ValueError(&quot;Mixed chunked array types detected. All arrays must use the same chunking backend.&quot;)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return detected_managers.pop()</span>


<span class="w"> </span>class ChunkManagerEntrypoint(ABC, Generic[T_ChunkedArray]):
<span class="gu">@@ -112,7 +156,7 @@ class ChunkManagerEntrypoint(ABC, Generic[T_ChunkedArray]):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        dask.is_dask_collection
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return isinstance(data, self.array_cls)</span>

<span class="w"> </span>    @abstractmethod
<span class="w"> </span>    def chunks(self, data: T_ChunkedArray) -&gt;_NormalizedChunks:
<span class="gh">diff --git a/xarray/namedarray/pycompat.py b/xarray/namedarray/pycompat.py</span>
<span class="gh">index c632ef6f..bc8f13d8 100644</span>
<span class="gd">--- a/xarray/namedarray/pycompat.py</span>
<span class="gi">+++ b/xarray/namedarray/pycompat.py</span>
<span class="gu">@@ -61,9 +61,13 @@ _cached_duck_array_modules: dict[ModType, DuckArrayModule] = {}</span>

<span class="w"> </span>def array_type(mod: ModType) -&gt;DuckArrayTypes:
<span class="w"> </span>    &quot;&quot;&quot;Quick wrapper to get the array class of the module.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if mod not in _cached_duck_array_modules:</span>
<span class="gi">+        _cached_duck_array_modules[mod] = DuckArrayModule(mod)</span>
<span class="gi">+    return _cached_duck_array_modules[mod].type</span>


<span class="w"> </span>def mod_version(mod: ModType) -&gt;Version:
<span class="w"> </span>    &quot;&quot;&quot;Quick wrapper to get the version of the module.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if mod not in _cached_duck_array_modules:</span>
<span class="gi">+        _cached_duck_array_modules[mod] = DuckArrayModule(mod)</span>
<span class="gi">+    return _cached_duck_array_modules[mod].version</span>
<span class="gh">diff --git a/xarray/namedarray/utils.py b/xarray/namedarray/utils.py</span>
<span class="gh">index 04211ef3..a7f32094 100644</span>
<span class="gd">--- a/xarray/namedarray/utils.py</span>
<span class="gi">+++ b/xarray/namedarray/utils.py</span>
<span class="gu">@@ -44,12 +44,18 @@ def module_available(module: str, minversion: (str | None)=None) -&gt;bool:</span>
<span class="w"> </span>    available : bool
<span class="w"> </span>        Whether the module is installed.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        mod = importlib.import_module(module)</span>
<span class="gi">+        if minversion is not None:</span>
<span class="gi">+            return Version(mod.__version__) &gt;= Version(minversion)</span>
<span class="gi">+        return True</span>
<span class="gi">+    except ImportError:</span>
<span class="gi">+        return False</span>


<span class="w"> </span>def to_0d_object_array(value: object) -&gt;NDArray[np.object_]:
<span class="w"> </span>    &quot;&quot;&quot;Given a value, wrap it in a 0-D numpy.ndarray with dtype=object.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return np.array(value, dtype=object)</span>


<span class="w"> </span>def drop_missing_dims(supplied_dims: Iterable[_Dim], dims: Iterable[_Dim],
<span class="gu">@@ -63,7 +69,17 @@ def drop_missing_dims(supplied_dims: Iterable[_Dim], dims: Iterable[_Dim],</span>
<span class="w"> </span>    dims : Iterable of Hashable
<span class="w"> </span>    missing_dims : {&quot;raise&quot;, &quot;warn&quot;, &quot;ignore&quot;}
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    dims_set = set(dims)</span>
<span class="gi">+    result = []</span>
<span class="gi">+    for dim in supplied_dims:</span>
<span class="gi">+        if dim in dims_set:</span>
<span class="gi">+            result.append(dim)</span>
<span class="gi">+        elif missing_dims == &quot;raise&quot;:</span>
<span class="gi">+            raise ValueError(f&quot;Dimension &#39;{dim}&#39; not found in dims&quot;)</span>
<span class="gi">+        elif missing_dims == &quot;warn&quot;:</span>
<span class="gi">+            warnings.warn(f&quot;Dimension &#39;{dim}&#39; not found in dims&quot;, UserWarning)</span>
<span class="gi">+    </span>
<span class="gi">+    return tuple(result)</span>


<span class="w"> </span>def infix_dims(dims_supplied: Iterable[_Dim], dims_all: Iterable[_Dim],
<span class="gu">@@ -72,7 +88,26 @@ def infix_dims(dims_supplied: Iterable[_Dim], dims_all: Iterable[_Dim],</span>
<span class="w"> </span>    Resolves a supplied list containing an ellipsis representing other items, to
<span class="w"> </span>    a generator with the &#39;realized&#39; list of all items
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    dims_supplied = list(dims_supplied)</span>
<span class="gi">+    dims_all = list(dims_all)</span>
<span class="gi">+    </span>
<span class="gi">+    if Ellipsis not in dims_supplied:</span>
<span class="gi">+        for dim in drop_missing_dims(dims_supplied, dims_all, missing_dims):</span>
<span class="gi">+            yield dim</span>
<span class="gi">+    else:</span>
<span class="gi">+        ellipsis_index = dims_supplied.index(Ellipsis)</span>
<span class="gi">+        before_ellipsis = dims_supplied[:ellipsis_index]</span>
<span class="gi">+        after_ellipsis = dims_supplied[ellipsis_index + 1:]</span>
<span class="gi">+        </span>
<span class="gi">+        for dim in drop_missing_dims(before_ellipsis, dims_all, missing_dims):</span>
<span class="gi">+            yield dim</span>
<span class="gi">+        </span>
<span class="gi">+        for dim in dims_all:</span>
<span class="gi">+            if dim not in before_ellipsis and dim not in after_ellipsis:</span>
<span class="gi">+                yield dim</span>
<span class="gi">+        </span>
<span class="gi">+        for dim in drop_missing_dims(after_ellipsis, dims_all, missing_dims):</span>
<span class="gi">+            yield dim</span>


<span class="w"> </span>class ReprObject:
<span class="gh">diff --git a/xarray/plot/dataarray_plot.py b/xarray/plot/dataarray_plot.py</span>
<span class="gh">index f56da420..d4235c25 100644</span>
<span class="gd">--- a/xarray/plot/dataarray_plot.py</span>
<span class="gi">+++ b/xarray/plot/dataarray_plot.py</span>
<span class="gu">@@ -61,7 +61,32 @@ def _prepare_plot1d_data(darray: T_DataArray, coords_to_plot:</span>
<span class="w"> </span>    &gt;&gt;&gt; print({k: v.name for k, v in plts.items()})
<span class="w"> </span>    {&#39;y&#39;: &#39;a&#39;, &#39;x&#39;: 1}
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    plts = {}</span>
<span class="gi">+    </span>
<span class="gi">+    # Handle y-axis data</span>
<span class="gi">+    plts[&#39;y&#39;] = darray</span>
<span class="gi">+</span>
<span class="gi">+    # Handle x-axis data</span>
<span class="gi">+    x_coord = coords_to_plot.get(&#39;x&#39;)</span>
<span class="gi">+    if x_coord is not None:</span>
<span class="gi">+        if isinstance(x_coord, str):</span>
<span class="gi">+            plts[&#39;x&#39;] = darray[x_coord]</span>
<span class="gi">+        else:</span>
<span class="gi">+            plts[&#39;x&#39;] = darray.coords[x_coord]</span>
<span class="gi">+    else:</span>
<span class="gi">+        plts[&#39;x&#39;] = darray.coords[darray.dims[0]]</span>
<span class="gi">+</span>
<span class="gi">+    # Handle hue data</span>
<span class="gi">+    hue_coord = coords_to_plot.get(&#39;hue&#39;)</span>
<span class="gi">+    if hue_coord is not None:</span>
<span class="gi">+        plts[&#39;hue&#39;] = darray.coords[hue_coord]</span>
<span class="gi">+</span>
<span class="gi">+    # Handle size data</span>
<span class="gi">+    size_coord = coords_to_plot.get(&#39;size&#39;)</span>
<span class="gi">+    if size_coord is not None:</span>
<span class="gi">+        plts[&#39;size&#39;] = darray.coords[size_coord]</span>
<span class="gi">+</span>
<span class="gi">+    return plts</span>


<span class="w"> </span>def plot(darray: DataArray, *, row: (Hashable | None)=None, col: (Hashable |
<span class="gu">@@ -106,7 +131,15 @@ def plot(darray: DataArray, *, row: (Hashable | None)=None, col: (Hashable |</span>
<span class="w"> </span>    --------
<span class="w"> </span>    xarray.DataArray.squeeze
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    darray = darray.squeeze()</span>
<span class="gi">+    ndims = len(darray.dims)</span>
<span class="gi">+</span>
<span class="gi">+    if ndims == 1:</span>
<span class="gi">+        return line(darray, row=row, col=col, col_wrap=col_wrap, ax=ax, hue=hue, subplot_kws=subplot_kws, **kwargs)</span>
<span class="gi">+    elif ndims == 2:</span>
<span class="gi">+        return pcolormesh(darray, row=row, col=col, col_wrap=col_wrap, ax=ax, subplot_kws=subplot_kws, **kwargs)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return hist(darray, row=row, col=col, col_wrap=col_wrap, ax=ax, subplot_kws=subplot_kws, **kwargs)</span>


<span class="w"> </span>def line(darray: T_DataArray, *args: Any, row: (Hashable | None)=None, col:
<span class="gu">@@ -175,7 +208,38 @@ def line(darray: T_DataArray, *args: Any, row: (Hashable | None)=None, col:</span>
<span class="w"> </span>        When either col or row is given, returns a FacetGrid, otherwise
<span class="w"> </span>        a list of matplotlib Line3D objects.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # Prepare the data</span>
<span class="gi">+    plotter = _LinePlotter(</span>
<span class="gi">+        darray,</span>
<span class="gi">+        x=x,</span>
<span class="gi">+        y=y,</span>
<span class="gi">+        hue=hue,</span>
<span class="gi">+        row=row,</span>
<span class="gi">+        col=col,</span>
<span class="gi">+        ax=ax,</span>
<span class="gi">+        figsize=figsize,</span>
<span class="gi">+        aspect=aspect,</span>
<span class="gi">+        size=size,</span>
<span class="gi">+        xincrease=xincrease,</span>
<span class="gi">+        yincrease=yincrease,</span>
<span class="gi">+        xscale=xscale,</span>
<span class="gi">+        yscale=yscale,</span>
<span class="gi">+        xticks=xticks,</span>
<span class="gi">+        yticks=yticks,</span>
<span class="gi">+        xlim=xlim,</span>
<span class="gi">+        ylim=ylim,</span>
<span class="gi">+        add_legend=add_legend,</span>
<span class="gi">+        _labels=_labels,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    # Plot the data</span>
<span class="gi">+    primitives = plotter.plot(*args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    # Return the result</span>
<span class="gi">+    if plotter.facets is not None:</span>
<span class="gi">+        return plotter.facets</span>
<span class="gi">+    else:</span>
<span class="gi">+        return primitives</span>


<span class="w"> </span>def step(darray: DataArray, *args: Any, where: Literal[&#39;pre&#39;, &#39;post&#39;, &#39;mid&#39;
<span class="gu">@@ -219,7 +283,16 @@ def step(darray: DataArray, *args: Any, where: Literal[&#39;pre&#39;, &#39;post&#39;, &#39;mid&#39;</span>
<span class="w"> </span>        When either col or row is given, returns a FacetGrid, otherwise
<span class="w"> </span>        a list of matplotlib Line3D objects.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # Set the drawstyle based on the &#39;where&#39; parameter</span>
<span class="gi">+    if drawstyle is None and ds is None:</span>
<span class="gi">+        drawstyle = f&#39;steps-{where}&#39;</span>
<span class="gi">+    elif drawstyle is not None and ds is not None:</span>
<span class="gi">+        raise ValueError(&quot;Only specify one of &#39;drawstyle&#39; and &#39;ds&#39;&quot;)</span>
<span class="gi">+    elif ds is not None:</span>
<span class="gi">+        drawstyle = ds</span>
<span class="gi">+</span>
<span class="gi">+    # Call the line function with the updated drawstyle</span>
<span class="gi">+    return line(darray, *args, row=row, col=col, drawstyle=drawstyle, **kwargs)</span>


<span class="w"> </span>def hist(darray: DataArray, *args: Any, figsize: (Iterable[float] | None)=
<span class="gu">@@ -268,7 +341,56 @@ def hist(darray: DataArray, *args: Any, figsize: (Iterable[float] | None)=</span>
<span class="w"> </span>        Additional keyword arguments to :py:func:`matplotlib:matplotlib.pyplot.hist`.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import matplotlib.pyplot as plt</span>
<span class="gi">+</span>
<span class="gi">+    # Get the current axes if not provided</span>
<span class="gi">+    if ax is None:</span>
<span class="gi">+        ax = plt.gca()</span>
<span class="gi">+</span>
<span class="gi">+    # Create a new figure if size or figsize is provided</span>
<span class="gi">+    if size is not None or figsize is not None:</span>
<span class="gi">+        if ax is not None:</span>
<span class="gi">+            raise ValueError(&quot;Cannot specify both `ax` and `size`/`figsize`&quot;)</span>
<span class="gi">+        fig, ax = plt.subplots(figsize=figsize)</span>
<span class="gi">+</span>
<span class="gi">+    # Flatten the DataArray</span>
<span class="gi">+    data = darray.values.flatten()</span>
<span class="gi">+</span>
<span class="gi">+    # Plot the histogram</span>
<span class="gi">+    n, bins, patches = ax.hist(data, *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    # Set the scales</span>
<span class="gi">+    if xscale is not None:</span>
<span class="gi">+        ax.set_xscale(xscale)</span>
<span class="gi">+    if yscale is not None:</span>
<span class="gi">+        ax.set_yscale(yscale)</span>
<span class="gi">+</span>
<span class="gi">+    # Set the ticks</span>
<span class="gi">+    if xticks is not None:</span>
<span class="gi">+        ax.set_xticks(xticks)</span>
<span class="gi">+    if yticks is not None:</span>
<span class="gi">+        ax.set_yticks(yticks)</span>
<span class="gi">+</span>
<span class="gi">+    # Set the limits</span>
<span class="gi">+    if xlim is not None:</span>
<span class="gi">+        ax.set_xlim(xlim)</span>
<span class="gi">+    if ylim is not None:</span>
<span class="gi">+        ax.set_ylim(ylim)</span>
<span class="gi">+</span>
<span class="gi">+    # Set the axis direction</span>
<span class="gi">+    if xincrease is not None:</span>
<span class="gi">+        ax.invert_xaxis() if not xincrease else None</span>
<span class="gi">+    if yincrease is not None:</span>
<span class="gi">+        ax.invert_yaxis() if not yincrease else None</span>
<span class="gi">+</span>
<span class="gi">+    # Set labels</span>
<span class="gi">+    ax.set_xlabel(darray.name or &#39;&#39;)</span>
<span class="gi">+    ax.set_ylabel(&#39;Frequency&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    # Set title</span>
<span class="gi">+    ax.set_title(f&#39;Histogram of {darray.name or &quot;Data&quot;}&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    return n, bins, patches</span>


<span class="w"> </span>def _plot1d(plotfunc):
<span class="gh">diff --git a/xarray/plot/dataset_plot.py b/xarray/plot/dataset_plot.py</span>
<span class="gh">index 458a594d..8b3904e6 100644</span>
<span class="gd">--- a/xarray/plot/dataset_plot.py</span>
<span class="gi">+++ b/xarray/plot/dataset_plot.py</span>
<span class="gu">@@ -27,7 +27,22 @@ def quiver(ds: Dataset, x: Hashable, y: Hashable, ax: Axes, u: Hashable, v:</span>

<span class="w"> </span>    Wraps :py:func:`matplotlib:matplotlib.pyplot.quiver`.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    x_data = ds[x].values</span>
<span class="gi">+    y_data = ds[y].values</span>
<span class="gi">+    u_data = ds[u].values</span>
<span class="gi">+    v_data = ds[v].values</span>
<span class="gi">+</span>
<span class="gi">+    # Calculate a nice quiver key magnitude</span>
<span class="gi">+    magnitude = _get_nice_quiver_magnitude(u_data, v_data)</span>
<span class="gi">+</span>
<span class="gi">+    # Create the quiver plot</span>
<span class="gi">+    q = ax.quiver(x_data, y_data, u_data, v_data, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    # Add a key for scale</span>
<span class="gi">+    ax.quiverkey(q, X=0.85, Y=1.05, U=magnitude,</span>
<span class="gi">+                 label=f&#39;{magnitude} {ds[u].units}&#39;, labelpos=&#39;E&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    return q</span>


<span class="w"> </span>@_dsplot
<span class="gu">@@ -37,7 +52,15 @@ def streamplot(ds: Dataset, x: Hashable, y: Hashable, ax: Axes, u: Hashable,</span>

<span class="w"> </span>    Wraps :py:func:`matplotlib:matplotlib.pyplot.streamplot`.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    x_data = ds[x].values</span>
<span class="gi">+    y_data = ds[y].values</span>
<span class="gi">+    u_data = ds[u].values</span>
<span class="gi">+    v_data = ds[v].values</span>
<span class="gi">+</span>
<span class="gi">+    # Create the streamplot</span>
<span class="gi">+    streams = ax.streamplot(x_data, y_data, u_data, v_data, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    return streams.lines</span>


<span class="w"> </span>F = TypeVar(&#39;F&#39;, bound=Callable)
<span class="gu">@@ -60,13 +83,30 @@ def _update_doc_to_dataset(dataarray_plotfunc: Callable) -&gt;Callable[[F], F]:</span>
<span class="w"> </span>    dataarray_plotfunc : Callable
<span class="w"> </span>        Function that returns a finished plot primitive.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    def wrapper(func: F) -&gt;F:</span>
<span class="gi">+        func.__doc__ = f&quot;&quot;&quot;</span>
<span class="gi">+        Dataset-specific wrapper for :py:func:`xarray.plot.dataarray_plot.{dataarray_plotfunc.__name__}`.</span>
<span class="gi">+</span>
<span class="gi">+        This function works similarly to the DataArray version, but operates on</span>
<span class="gi">+        Dataset variables instead. The first argument should be a Dataset, and</span>
<span class="gi">+        variable names should be passed as strings for the x, y, and other</span>
<span class="gi">+        relevant parameters.</span>
<span class="gi">+</span>
<span class="gi">+        {dataarray_plotfunc.__doc__}</span>
<span class="gi">+        &quot;&quot;&quot;</span>
<span class="gi">+        return func</span>
<span class="gi">+    return wrapper</span>


<span class="w"> </span>def _temp_dataarray(ds: Dataset, y: Hashable, locals_: dict[str, Any]
<span class="w"> </span>    ) -&gt;DataArray:
<span class="w"> </span>    &quot;&quot;&quot;Create a temporary datarray with extra coords.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    da = ds[y]</span>
<span class="gi">+    coords = {}</span>
<span class="gi">+    for key, value in locals_.items():</span>
<span class="gi">+        if isinstance(value, Hashable) and value in ds.variables:</span>
<span class="gi">+            coords[key] = ds[value]</span>
<span class="gi">+    return da.assign_coords(coords)</span>


<span class="w"> </span>@_update_doc_to_dataset(dataarray_plot.scatter)
<span class="gu">@@ -88,4 +128,45 @@ def scatter(ds: Dataset, *args: Any, x: (Hashable | None)=None, y: (</span>
<span class="w"> </span>    (ArrayLike | None)=None, **kwargs: Any) -&gt;(PathCollection | FacetGrid[
<span class="w"> </span>    DataArray]):
<span class="w"> </span>    &quot;&quot;&quot;Scatter plot Dataset data variables against each other.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    locals_ = locals()</span>
<span class="gi">+    if y is None:</span>
<span class="gi">+        raise ValueError(&quot;y must be specified for scatter plots of Datasets&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    da = _temp_dataarray(ds, y, locals_)</span>
<span class="gi">+</span>
<span class="gi">+    return dataarray_plot.scatter(</span>
<span class="gi">+        da,</span>
<span class="gi">+        *args,</span>
<span class="gi">+        x=x,</span>
<span class="gi">+        hue=hue,</span>
<span class="gi">+        hue_style=hue_style,</span>
<span class="gi">+        markersize=markersize,</span>
<span class="gi">+        linewidth=linewidth,</span>
<span class="gi">+        figsize=figsize,</span>
<span class="gi">+        size=size,</span>
<span class="gi">+        aspect=aspect,</span>
<span class="gi">+        ax=ax,</span>
<span class="gi">+        row=row,</span>
<span class="gi">+        col=col,</span>
<span class="gi">+        col_wrap=col_wrap,</span>
<span class="gi">+        xincrease=xincrease,</span>
<span class="gi">+        yincrease=yincrease,</span>
<span class="gi">+        add_legend=add_legend,</span>
<span class="gi">+        add_colorbar=add_colorbar,</span>
<span class="gi">+        add_labels=add_labels,</span>
<span class="gi">+        add_title=add_title,</span>
<span class="gi">+        subplot_kws=subplot_kws,</span>
<span class="gi">+        xscale=xscale,</span>
<span class="gi">+        yscale=yscale,</span>
<span class="gi">+        xticks=xticks,</span>
<span class="gi">+        yticks=yticks,</span>
<span class="gi">+        xlim=xlim,</span>
<span class="gi">+        ylim=ylim,</span>
<span class="gi">+        cmap=cmap,</span>
<span class="gi">+        vmin=vmin,</span>
<span class="gi">+        vmax=vmax,</span>
<span class="gi">+        norm=norm,</span>
<span class="gi">+        extend=extend,</span>
<span class="gi">+        levels=levels,</span>
<span class="gi">+        **kwargs</span>
<span class="gi">+    )</span>
<span class="gh">diff --git a/xarray/plot/facetgrid.py b/xarray/plot/facetgrid.py</span>
<span class="gh">index af73de2d..92014ec8 100644</span>
<span class="gd">--- a/xarray/plot/facetgrid.py</span>
<span class="gi">+++ b/xarray/plot/facetgrid.py</span>
<span class="gu">@@ -25,7 +25,10 @@ def _nicetitle(coord, value, maxchar, template):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Put coord, value in template and truncate at maxchar
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    title = template.format(coord=coord, value=format_item(value))</span>
<span class="gi">+    if len(title) &gt; maxchar:</span>
<span class="gi">+        title = title[:(maxchar - 3)] + &#39;...&#39;</span>
<span class="gi">+    return title</span>


<span class="w"> </span>T_FacetGrid = TypeVar(&#39;T_FacetGrid&#39;, bound=&#39;FacetGrid&#39;)
<span class="gu">@@ -222,7 +225,15 @@ class FacetGrid(Generic[T_DataArrayOrSet]):</span>
<span class="w"> </span>        self : FacetGrid object

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._finalize_grid = functools.partial(self._finalize_grid, x, y)</span>
<span class="gi">+        </span>
<span class="gi">+        for ax, name_dict in zip(self.axs.flat, self.name_dicts.flat):</span>
<span class="gi">+            if name_dict is not None:</span>
<span class="gi">+                subset = self.data.loc[name_dict]</span>
<span class="gi">+                mappable = func(subset, x, y, ax=ax, **kwargs)</span>
<span class="gi">+                self._mappables.append(mappable)</span>
<span class="gi">+</span>
<span class="gi">+        return self</span>

<span class="w"> </span>    def map_plot1d(self: T_FacetGrid, func: Callable, x: (Hashable | None),
<span class="w"> </span>        y: (Hashable | None), *, z: (Hashable | None)=None, hue: (Hashable |
<span class="gu">@@ -248,15 +259,38 @@ class FacetGrid(Generic[T_DataArrayOrSet]):</span>
<span class="w"> </span>        self : FacetGrid object

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self._finalize_grid = functools.partial(self._finalize_grid, x, y)</span>
<span class="gi">+        </span>
<span class="gi">+        for ax, name_dict in zip(self.axs.flat, self.name_dicts.flat):</span>
<span class="gi">+            if name_dict is not None:</span>
<span class="gi">+                subset = self.data.loc[name_dict]</span>
<span class="gi">+                mappable = func(subset, x, y, ax=ax, z=z, hue=hue, </span>
<span class="gi">+                                markersize=markersize, linewidth=linewidth, **kwargs)</span>
<span class="gi">+                self._mappables.append(mappable)</span>
<span class="gi">+</span>
<span class="gi">+        return self</span>

<span class="w"> </span>    def _finalize_grid(self, *axlabels: Hashable) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;Finalize the annotations and layout.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if not self._finalized:</span>
<span class="gi">+            self.set_axis_labels(*axlabels)</span>
<span class="gi">+            self.set_titles()</span>
<span class="gi">+            self.set_ticks()</span>
<span class="gi">+            self.fig.tight_layout()</span>
<span class="gi">+</span>
<span class="gi">+            for ax in self.axs.flat:</span>
<span class="gi">+                ax.margins(0.05)</span>
<span class="gi">+</span>
<span class="gi">+            self._finalized = True</span>

<span class="w"> </span>    def add_colorbar(self, **kwargs: Any) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;Draw a colorbar.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self._mappables:</span>
<span class="gi">+            import matplotlib.pyplot as plt</span>
<span class="gi">+            </span>
<span class="gi">+            cbar_ax = self.fig.add_axes([0.92, 0.25, 0.02, 0.5])</span>
<span class="gi">+            cbar = plt.colorbar(self._mappables[-1], cax=cbar_ax, **kwargs)</span>
<span class="gi">+            self.cbar = cbar</span>

<span class="w"> </span>    def _get_largest_lims(self) -&gt;dict[str, tuple[float, float]]:
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -274,7 +308,19 @@ class FacetGrid(Generic[T_DataArrayOrSet]):</span>
<span class="w"> </span>        &gt;&gt;&gt; round(fg._get_largest_lims()[&quot;x&quot;][0], 3)
<span class="w"> </span>        np.float64(-0.334)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        lims_largest = {}</span>
<span class="gi">+        for ax in self.axs.flat:</span>
<span class="gi">+            for axis in [&#39;x&#39;, &#39;y&#39;]:</span>
<span class="gi">+                get_lim = getattr(ax, f&#39;get_{axis}lim&#39;)</span>
<span class="gi">+                lims = get_lim()</span>
<span class="gi">+                if axis not in lims_largest:</span>
<span class="gi">+                    lims_largest[axis] = lims</span>
<span class="gi">+                else:</span>
<span class="gi">+                    lims_largest[axis] = (</span>
<span class="gi">+                        min(lims_largest[axis][0], lims[0]),</span>
<span class="gi">+                        max(lims_largest[axis][1], lims[1])</span>
<span class="gi">+                    )</span>
<span class="gi">+        return lims_largest</span>

<span class="w"> </span>    def _set_lims(self, x: (tuple[float, float] | None)=None, y: (tuple[
<span class="w"> </span>        float, float] | None)=None, z: (tuple[float, float] | None)=None
<span class="gu">@@ -299,7 +345,13 @@ class FacetGrid(Generic[T_DataArrayOrSet]):</span>
<span class="w"> </span>        &gt;&gt;&gt; fg.axs[0, 0].get_xlim(), fg.axs[0, 0].get_ylim()
<span class="w"> </span>        ((np.float64(-0.3), np.float64(0.3)), (np.float64(0.0), np.float64(2.0)))
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        for ax in self.axs.flat:</span>
<span class="gi">+            if x is not None:</span>
<span class="gi">+                ax.set_xlim(x)</span>
<span class="gi">+            if y is not None:</span>
<span class="gi">+                ax.set_ylim(y)</span>
<span class="gi">+            if z is not None and hasattr(ax, &#39;set_zlim&#39;):</span>
<span class="gi">+                ax.set_zlim(z)</span>

<span class="w"> </span>    def set_axis_labels(self, *axlabels: Hashable) -&gt;None:
<span class="w"> </span>        &quot;&quot;&quot;Set axis labels on the left column and bottom row of the grid.&quot;&quot;&quot;
<span class="gu">@@ -397,4 +449,37 @@ def _easy_facetgrid(data: T_DataArrayOrSet, plotfunc: Callable, kind:</span>

<span class="w"> </span>    kwargs are the arguments to 2d plotting method
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if ax is not None:</span>
<span class="gi">+        raise ValueError(&quot;Can&#39;t use axes when making faceted plots.&quot;)</span>
<span class="gi">+    </span>
<span class="gi">+    if figsize is not None:</span>
<span class="gi">+        kwargs[&#39;figsize&#39;] = figsize</span>
<span class="gi">+    </span>
<span class="gi">+    if aspect is None:</span>
<span class="gi">+        aspect = 1</span>
<span class="gi">+    if size is None:</span>
<span class="gi">+        size = 3</span>
<span class="gi">+    </span>
<span class="gi">+    facet_kwargs = dict(</span>
<span class="gi">+        data=data,</span>
<span class="gi">+        row=row,</span>
<span class="gi">+        col=col,</span>
<span class="gi">+        col_wrap=col_wrap,</span>
<span class="gi">+        sharex=sharex,</span>
<span class="gi">+        sharey=sharey,</span>
<span class="gi">+        figsize=figsize,</span>
<span class="gi">+        aspect=aspect,</span>
<span class="gi">+        size=size,</span>
<span class="gi">+        subplot_kws=subplot_kws,</span>
<span class="gi">+    )</span>
<span class="gi">+    </span>
<span class="gi">+    g = FacetGrid(**facet_kwargs)</span>
<span class="gi">+    </span>
<span class="gi">+    if kind == &#39;dataarray&#39;:</span>
<span class="gi">+        return g.map_dataarray(plotfunc, x, y, **kwargs)</span>
<span class="gi">+    elif kind == &#39;dataset&#39;:</span>
<span class="gi">+        return g.map_dataset(plotfunc, x, y, **kwargs)</span>
<span class="gi">+    elif kind in [&#39;line&#39;, &#39;plot1d&#39;]:</span>
<span class="gi">+        return g.map_plot1d(plotfunc, x, y, **kwargs)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(f&quot;Unsupported plot kind: {kind}&quot;)</span>
<span class="gh">diff --git a/xarray/plot/utils.py b/xarray/plot/utils.py</span>
<span class="gh">index 6309e4c6..5e76fc0a 100644</span>
<span class="gd">--- a/xarray/plot/utils.py</span>
<span class="gi">+++ b/xarray/plot/utils.py</span>
<span class="gu">@@ -38,7 +38,28 @@ def _build_discrete_cmap(cmap, levels, extend, filled):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Build a discrete colormap and normalization of the data.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import matplotlib.pyplot as plt</span>
<span class="gi">+    import matplotlib.colors as mcolors</span>
<span class="gi">+    </span>
<span class="gi">+    if not filled:</span>
<span class="gi">+        # non-filled contour plots</span>
<span class="gi">+        extend = &#39;max&#39;</span>
<span class="gi">+    </span>
<span class="gi">+    if extend == &#39;both&#39;:</span>
<span class="gi">+        ext_n = 2</span>
<span class="gi">+    elif extend in [&#39;min&#39;, &#39;max&#39;]:</span>
<span class="gi">+        ext_n = 1</span>
<span class="gi">+    else:</span>
<span class="gi">+        ext_n = 0</span>
<span class="gi">+    </span>
<span class="gi">+    n_colors = len(levels) + ext_n - 1</span>
<span class="gi">+    pal = _color_palette(cmap, n_colors)</span>
<span class="gi">+    </span>
<span class="gi">+    new_cmap, norm = mcolors.from_levels_and_colors(levels, pal, extend=extend)</span>
<span class="gi">+    # copy the old cmap name, for easier testing</span>
<span class="gi">+    new_cmap.name = getattr(cmap, &#39;name&#39;, cmap)</span>
<span class="gi">+    </span>
<span class="gi">+    return new_cmap, norm</span>


<span class="w"> </span>def _determine_cmap_params(plot_data, vmin=None, vmax=None, cmap=None,
<span class="gu">@@ -57,7 +78,40 @@ def _determine_cmap_params(plot_data, vmin=None, vmax=None, cmap=None,</span>
<span class="w"> </span>    cmap_params : dict
<span class="w"> </span>        Use depends on the type of the plotting function
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import numpy as np</span>
<span class="gi">+    import matplotlib.pyplot as plt</span>
<span class="gi">+    </span>
<span class="gi">+    calc_data = np.ravel(plot_data)</span>
<span class="gi">+    calc_data = calc_data[~np.isnan(calc_data)]</span>
<span class="gi">+    </span>
<span class="gi">+    if vmin is None:</span>
<span class="gi">+        vmin = np.min(calc_data)</span>
<span class="gi">+    if vmax is None:</span>
<span class="gi">+        vmax = np.max(calc_data)</span>
<span class="gi">+    </span>
<span class="gi">+    # Choose default extend based on vmin, vmax</span>
<span class="gi">+    if extend is None:</span>
<span class="gi">+        extend = _determine_extend(calc_data, vmin, vmax)</span>
<span class="gi">+    </span>
<span class="gi">+    if levels is None:</span>
<span class="gi">+        levels = _determine_levels(vmin, vmax, center, robust)</span>
<span class="gi">+    </span>
<span class="gi">+    if cmap is None:</span>
<span class="gi">+        cmap = plt.get_cmap()</span>
<span class="gi">+    </span>
<span class="gi">+    if norm is None:</span>
<span class="gi">+        norm = plt.Normalize(vmin, vmax)</span>
<span class="gi">+    </span>
<span class="gi">+    cmap_params = {</span>
<span class="gi">+        &#39;vmin&#39;: vmin,</span>
<span class="gi">+        &#39;vmax&#39;: vmax,</span>
<span class="gi">+        &#39;cmap&#39;: cmap,</span>
<span class="gi">+        &#39;extend&#39;: extend,</span>
<span class="gi">+        &#39;levels&#39;: levels,</span>
<span class="gi">+        &#39;norm&#39;: norm,</span>
<span class="gi">+    }</span>
<span class="gi">+    </span>
<span class="gi">+    return cmap_params</span>


<span class="w"> </span>def _infer_xy_labels_3d(darray: (DataArray | Dataset), x: (Hashable | None),
<span class="gu">@@ -68,7 +122,23 @@ def _infer_xy_labels_3d(darray: (DataArray | Dataset), x: (Hashable | None),</span>
<span class="w"> </span>    Attempts to infer which dimension is RGB/RGBA by size and order of dims.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    dims = list(darray.dims)</span>
<span class="gi">+    if rgb is None:</span>
<span class="gi">+        # Assume the last dimension is RGB</span>
<span class="gi">+        rgb = dims[-1]</span>
<span class="gi">+        dims = dims[:-1]</span>
<span class="gi">+    </span>
<span class="gi">+    if len(dims) != 2:</span>
<span class="gi">+        raise ValueError(&quot;DataArray must be 3D&quot;)</span>
<span class="gi">+    </span>
<span class="gi">+    if x is None and y is None:</span>
<span class="gi">+        x, y = dims</span>
<span class="gi">+    elif x is None:</span>
<span class="gi">+        x = [d for d in dims if d != y][0]</span>
<span class="gi">+    elif y is None:</span>
<span class="gi">+        y = [d for d in dims if d != x][0]</span>
<span class="gi">+    </span>
<span class="gi">+    return x, y</span>


<span class="w"> </span>def _infer_xy_labels(darray: (DataArray | Dataset), x: (Hashable | None), y:
<span class="gu">@@ -79,7 +149,22 @@ def _infer_xy_labels(darray: (DataArray | Dataset), x: (Hashable | None), y:</span>

<span class="w"> </span>    darray must be a 2 dimensional data array, or 3d for imshow only.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if imshow and darray.ndim == 3:</span>
<span class="gi">+        return _infer_xy_labels_3d(darray, x, y, rgb)</span>
<span class="gi">+    </span>
<span class="gi">+    if darray.ndim != 2:</span>
<span class="gi">+        raise ValueError(&#39;DataArray must be 2D&#39;)</span>
<span class="gi">+    </span>
<span class="gi">+    dims = list(darray.dims)</span>
<span class="gi">+    </span>
<span class="gi">+    if x is None and y is None:</span>
<span class="gi">+        x, y = dims</span>
<span class="gi">+    elif x is None:</span>
<span class="gi">+        x = [d for d in dims if d != y][0]</span>
<span class="gi">+    elif y is None:</span>
<span class="gi">+        y = [d for d in dims if d != x][0]</span>
<span class="gi">+    </span>
<span class="gi">+    return x, y</span>


<span class="w"> </span>def _assert_valid_xy(darray: (DataArray | Dataset), xy: (Hashable | None),
<span class="gu">@@ -87,18 +172,47 @@ def _assert_valid_xy(darray: (DataArray | Dataset), xy: (Hashable | None),</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    make sure x and y passed to plotting functions are valid
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if xy is not None:</span>
<span class="gi">+        if isinstance(darray, DataArray):</span>
<span class="gi">+            valid_dims = darray.dims</span>
<span class="gi">+        else:</span>
<span class="gi">+            valid_dims = darray.coords</span>
<span class="gi">+</span>
<span class="gi">+        if xy not in valid_dims:</span>
<span class="gi">+            raise ValueError(f&quot;{name} must be one of {valid_dims}&quot;)</span>


<span class="w"> </span>def _get_units_from_attrs(da: DataArray) -&gt;str:
<span class="w"> </span>    &quot;&quot;&quot;Extracts and formats the unit/units from a attributes.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    units = da.attrs.get(&#39;units&#39;, da.attrs.get(&#39;unit&#39;, &#39;&#39;))</span>
<span class="gi">+    if units:</span>
<span class="gi">+        return f&quot; [{units}]&quot;</span>
<span class="gi">+    return &quot;&quot;</span>


<span class="w"> </span>def label_from_attrs(da: (DataArray | None), extra: str=&#39;&#39;) -&gt;str:
<span class="w"> </span>    &quot;&quot;&quot;Makes informative labels if variable metadata (attrs) follows
<span class="w"> </span>    CF conventions.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if da is None:</span>
<span class="gi">+        return &#39;&#39;</span>
<span class="gi">+    </span>
<span class="gi">+    name = da.name</span>
<span class="gi">+    standard_name = da.attrs.get(&#39;standard_name&#39;, &#39;&#39;)</span>
<span class="gi">+    long_name = da.attrs.get(&#39;long_name&#39;, &#39;&#39;)</span>
<span class="gi">+    units = _get_units_from_attrs(da)</span>
<span class="gi">+    </span>
<span class="gi">+    if standard_name and long_name:</span>
<span class="gi">+        label = f&quot;{standard_name.capitalize()} ({long_name}){units}&quot;</span>
<span class="gi">+    elif long_name:</span>
<span class="gi">+        label = f&quot;{long_name.capitalize()}{units}&quot;</span>
<span class="gi">+    elif standard_name:</span>
<span class="gi">+        label = f&quot;{standard_name.capitalize()}{units}&quot;</span>
<span class="gi">+    elif name:</span>
<span class="gi">+        label = f&quot;{name.capitalize()}{units}&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        label = &#39;&#39;</span>
<span class="gi">+    </span>
<span class="gi">+    return f&quot;{label}{extra}&quot;</span>


<span class="w"> </span>def _interval_to_mid_points(array: Iterable[pd.Interval]) -&gt;np.ndarray:
<span class="gh">diff --git a/xarray/testing/assertions.py b/xarray/testing/assertions.py</span>
<span class="gh">index 678f4a45..e48709fd 100644</span>
<span class="gd">--- a/xarray/testing/assertions.py</span>
<span class="gi">+++ b/xarray/testing/assertions.py</span>
<span class="gu">@@ -44,12 +44,29 @@ def assert_isomorphic(a: DataTree, b: DataTree, from_root: bool=False):</span>
<span class="w"> </span>    assert_equal
<span class="w"> </span>    assert_identical
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if from_root:</span>
<span class="gi">+        a = a.root</span>
<span class="gi">+        b = b.root</span>
<span class="gi">+    </span>
<span class="gi">+    def check_isomorphic(node_a, node_b):</span>
<span class="gi">+        if len(node_a.children) != len(node_b.children):</span>
<span class="gi">+            return False</span>
<span class="gi">+        for child_a, child_b in zip(node_a.children.values(), node_b.children.values()):</span>
<span class="gi">+            if not check_isomorphic(child_a, child_b):</span>
<span class="gi">+                return False</span>
<span class="gi">+        return True</span>
<span class="gi">+    </span>
<span class="gi">+    if not check_isomorphic(a, b):</span>
<span class="gi">+        raise AssertionError(&quot;DataTrees are not isomorphic&quot;)</span>


<span class="w"> </span>def maybe_transpose_dims(a, b, check_dim_order: bool):
<span class="w"> </span>    &quot;&quot;&quot;Helper for assert_equal/allclose/identical&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not check_dim_order:</span>
<span class="gi">+        if isinstance(a, (DataArray, Dataset)) and isinstance(b, (DataArray, Dataset)):</span>
<span class="gi">+            if set(a.dims) == set(b.dims) and a.dims != b.dims:</span>
<span class="gi">+                b = b.transpose(*a.dims)</span>
<span class="gi">+    return a, b</span>


<span class="w"> </span>@ensure_warnings
<span class="gu">@@ -84,7 +101,14 @@ def assert_equal(a, b, from_root=True, check_dim_order: bool=True):</span>
<span class="w"> </span>    assert_identical, assert_allclose, Dataset.equals, DataArray.equals
<span class="w"> </span>    numpy.testing.assert_array_equal
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(a, DataTree) and isinstance(b, DataTree):</span>
<span class="gi">+        assert_isomorphic(a, b, from_root=from_root)</span>
<span class="gi">+        for node_a, node_b in zip(a.subtree.values(), b.subtree.values()):</span>
<span class="gi">+            assert_equal(node_a.ds, node_b.ds, check_dim_order=check_dim_order)</span>
<span class="gi">+    else:</span>
<span class="gi">+        a, b = maybe_transpose_dims(a, b, check_dim_order)</span>
<span class="gi">+        if not a.equals(b):</span>
<span class="gi">+            raise AssertionError(f&quot;Objects are not equal:\n\n{a}\n\n{b}&quot;)</span>


<span class="w"> </span>@ensure_warnings
<span class="gu">@@ -115,7 +139,13 @@ def assert_identical(a, b, from_root=True):</span>
<span class="w"> </span>    --------
<span class="w"> </span>    assert_equal, assert_allclose, Dataset.equals, DataArray.equals
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(a, DataTree) and isinstance(b, DataTree):</span>
<span class="gi">+        assert_isomorphic(a, b, from_root=from_root)</span>
<span class="gi">+        for node_a, node_b in zip(a.subtree.values(), b.subtree.values()):</span>
<span class="gi">+            assert_identical(node_a.ds, node_b.ds)</span>
<span class="gi">+    else:</span>
<span class="gi">+        if not a.identical(b):</span>
<span class="gi">+            raise AssertionError(f&quot;Objects are not identical:\n\n{a}\n\n{b}&quot;)</span>


<span class="w"> </span>@ensure_warnings
<span class="gu">@@ -147,20 +177,60 @@ def assert_allclose(a, b, rtol=1e-05, atol=1e-08, decode_bytes=True,</span>
<span class="w"> </span>    --------
<span class="w"> </span>    assert_identical, assert_equal, numpy.testing.assert_allclose
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    a, b = maybe_transpose_dims(a, b, check_dim_order)</span>
<span class="gi">+    </span>
<span class="gi">+    if decode_bytes:</span>
<span class="gi">+        a = a.copy(deep=True)</span>
<span class="gi">+        b = b.copy(deep=True)</span>
<span class="gi">+        for obj in [a, b]:</span>
<span class="gi">+            for var in obj.variables.values():</span>
<span class="gi">+                if var.dtype.kind == &#39;S&#39;:</span>
<span class="gi">+                    var.values = var.values.astype(&#39;U&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(a, (Dataset, DataArray)) and isinstance(b, (Dataset, DataArray)):</span>
<span class="gi">+        assert a.dims == b.dims, f&quot;Dimensions do not match: {a.dims} != {b.dims}&quot;</span>
<span class="gi">+        assert a.coords.keys() == b.coords.keys(), f&quot;Coordinates do not match: {a.coords.keys()} != {b.coords.keys()}&quot;</span>
<span class="gi">+        </span>
<span class="gi">+        for var in a.variables:</span>
<span class="gi">+            assert_allclose(a[var], b[var], rtol=rtol, atol=atol)</span>
<span class="gi">+    else:</span>
<span class="gi">+        assert_duckarray_allclose(a.values, b.values, rtol=rtol, atol=atol)</span>


<span class="w"> </span>@ensure_warnings
<span class="w"> </span>def assert_duckarray_allclose(actual, desired, rtol=1e-07, atol=0, err_msg=
<span class="w"> </span>    &#39;&#39;, verbose=True):
<span class="w"> </span>    &quot;&quot;&quot;Like `np.testing.assert_allclose`, but for duckarrays.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import numpy as np</span>
<span class="gi">+    </span>
<span class="gi">+    def allclose(a, b):</span>
<span class="gi">+        return np.all(np.abs(a - b) &lt;= atol + rtol * np.abs(b))</span>
<span class="gi">+    </span>
<span class="gi">+    if not allclose(actual, desired):</span>
<span class="gi">+        if err_msg:</span>
<span class="gi">+            raise AssertionError(err_msg)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise AssertionError(</span>
<span class="gi">+                f&quot;Arrays are not close (rtol={rtol}, atol={atol}):\n&quot;</span>
<span class="gi">+                f&quot;Actual:\n{actual}\n&quot;</span>
<span class="gi">+                f&quot;Desired:\n{desired}&quot;</span>
<span class="gi">+            )</span>


<span class="w"> </span>@ensure_warnings
<span class="w"> </span>def assert_duckarray_equal(x, y, err_msg=&#39;&#39;, verbose=True):
<span class="w"> </span>    &quot;&quot;&quot;Like `np.testing.assert_array_equal`, but for duckarrays&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import numpy as np</span>
<span class="gi">+    </span>
<span class="gi">+    if not np.array_equal(x, y):</span>
<span class="gi">+        if err_msg:</span>
<span class="gi">+            raise AssertionError(err_msg)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise AssertionError(</span>
<span class="gi">+                f&quot;Arrays are not equal:\n&quot;</span>
<span class="gi">+                f&quot;x:\n{x}\n&quot;</span>
<span class="gi">+                f&quot;y:\n{y}&quot;</span>
<span class="gi">+            )</span>


<span class="w"> </span>def assert_chunks_equal(a, b):
<span class="gu">@@ -174,7 +244,19 @@ def assert_chunks_equal(a, b):</span>
<span class="w"> </span>    b : xarray.Dataset or xarray.DataArray
<span class="w"> </span>        The second object to compare.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    def get_chunks(obj):</span>
<span class="gi">+        if isinstance(obj, Dataset):</span>
<span class="gi">+            return {var: obj[var].chunks for var in obj.variables if obj[var].chunks is not None}</span>
<span class="gi">+        elif isinstance(obj, DataArray):</span>
<span class="gi">+            return obj.chunks</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise TypeError(f&quot;Expected Dataset or DataArray, got {type(obj)}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    chunks_a = get_chunks(a)</span>
<span class="gi">+    chunks_b = get_chunks(b)</span>
<span class="gi">+</span>
<span class="gi">+    if chunks_a != chunks_b:</span>
<span class="gi">+        raise AssertionError(f&quot;Chunks are not equal:\na: {chunks_a}\nb: {chunks_b}&quot;)</span>


<span class="w"> </span>def _assert_internal_invariants(xarray_obj: Union[DataArray, Dataset,
<span class="gu">@@ -185,4 +267,20 @@ def _assert_internal_invariants(xarray_obj: Union[DataArray, Dataset,</span>
<span class="w"> </span>    in external projects if they (ill-advisedly) create objects using xarray&#39;s
<span class="w"> </span>    private APIs.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(xarray_obj, DataArray):</span>
<span class="gi">+        assert set(xarray_obj.dims) == set(xarray_obj.coords.keys())</span>
<span class="gi">+        assert set(xarray_obj.dims) == set(xarray_obj.indexes.keys())</span>
<span class="gi">+        assert xarray_obj.name == xarray_obj.variable.name</span>
<span class="gi">+    elif isinstance(xarray_obj, Dataset):</span>
<span class="gi">+        assert set(xarray_obj.dims) == set(xarray_obj.coords.keys())</span>
<span class="gi">+        assert set(xarray_obj.dims) == set(xarray_obj.indexes.keys())</span>
<span class="gi">+        for var in xarray_obj.variables.values():</span>
<span class="gi">+            assert set(var.dims).issubset(xarray_obj.dims)</span>
<span class="gi">+    elif isinstance(xarray_obj, Variable):</span>
<span class="gi">+        assert xarray_obj.dims == xarray_obj.data.shape</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(f&quot;Expected DataArray, Dataset, or Variable, got {type(xarray_obj)}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if check_default_indexes:</span>
<span class="gi">+        for dim, index in xarray_obj.indexes.items():</span>
<span class="gi">+            assert isinstance(index, (PandasIndex, PandasMultiIndex))</span>
<span class="gh">diff --git a/xarray/testing/strategies.py b/xarray/testing/strategies.py</span>
<span class="gh">index 11355cbf..cf548644 100644</span>
<span class="gd">--- a/xarray/testing/strategies.py</span>
<span class="gi">+++ b/xarray/testing/strategies.py</span>
<span class="gu">@@ -38,7 +38,12 @@ def supported_dtypes() -&gt;st.SearchStrategy[np.dtype]:</span>
<span class="w"> </span>    --------
<span class="w"> </span>    :ref:`testing.hypothesis`_
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return st.one_of(</span>
<span class="gi">+        npst.integer_dtypes(endianness=&quot;=&quot;),</span>
<span class="gi">+        npst.floating_dtypes(endianness=&quot;=&quot;),</span>
<span class="gi">+        npst.complex_number_dtypes(endianness=&quot;=&quot;),</span>
<span class="gi">+        st.just(np.dtype(&quot;bool&quot;))</span>
<span class="gi">+    )</span>


<span class="w"> </span>def pandas_index_dtypes() -&gt;st.SearchStrategy[np.dtype]:
<span class="gu">@@ -46,7 +51,13 @@ def pandas_index_dtypes() -&gt;st.SearchStrategy[np.dtype]:</span>
<span class="w"> </span>    Dtypes supported by pandas indexes.
<span class="w"> </span>    Restrict datetime64 and timedelta64 to ns frequency till Xarray relaxes that.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return st.one_of(</span>
<span class="gi">+        npst.integer_dtypes(endianness=&quot;=&quot;),</span>
<span class="gi">+        npst.floating_dtypes(endianness=&quot;=&quot;),</span>
<span class="gi">+        st.just(np.dtype(&quot;datetime64[ns]&quot;)),</span>
<span class="gi">+        st.just(np.dtype(&quot;timedelta64[ns]&quot;)),</span>
<span class="gi">+        st.just(np.dtype(&quot;object&quot;))</span>
<span class="gi">+    )</span>


<span class="w"> </span>_readable_characters = st.characters(categories=[&#39;L&#39;, &#39;N&#39;], max_codepoint=383)
<span class="gu">@@ -62,7 +73,7 @@ def names() -&gt;st.SearchStrategy[str]:</span>
<span class="w"> </span>    --------
<span class="w"> </span>    :ref:`testing.hypothesis`_
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return st.text(_readable_characters, min_size=1, max_size=10)</span>


<span class="w"> </span>def dimension_names(*, name_strategy=names(), min_dims: int=0, max_dims: int=3
<span class="gu">@@ -81,7 +92,7 @@ def dimension_names(*, name_strategy=names(), min_dims: int=0, max_dims: int=3</span>
<span class="w"> </span>    max_dims
<span class="w"> </span>        Maximum number of dimensions in generated list.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return st.lists(name_strategy, min_size=min_dims, max_size=max_dims, unique=True)</span>


<span class="w"> </span>def dimension_sizes(*, dim_names: st.SearchStrategy[Hashable]=names(),
<span class="gu">@@ -114,7 +125,15 @@ def dimension_sizes(*, dim_names: st.SearchStrategy[Hashable]=names(),</span>
<span class="w"> </span>    --------
<span class="w"> </span>    :ref:`testing.hypothesis`_
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if max_side is None:</span>
<span class="gi">+        max_side = min_side + 5</span>
<span class="gi">+    </span>
<span class="gi">+    return st.dictionaries(</span>
<span class="gi">+        keys=dim_names,</span>
<span class="gi">+        values=st.integers(min_value=min_side, max_value=max_side),</span>
<span class="gi">+        min_size=min_dims,</span>
<span class="gi">+        max_size=max_dims</span>
<span class="gi">+    )</span>


<span class="w"> </span>_readable_strings = st.text(_readable_characters, max_size=5)
<span class="gu">@@ -138,7 +157,11 @@ def attrs() -&gt;st.SearchStrategy[Mapping[Hashable, Any]]:</span>
<span class="w"> </span>    --------
<span class="w"> </span>    :ref:`testing.hypothesis`_
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return st.recursive(</span>
<span class="gi">+        simple_attrs,</span>
<span class="gi">+        lambda children: st.dictionaries(_attr_keys, children | _attr_values),</span>
<span class="gi">+        max_leaves=5</span>
<span class="gi">+    )</span>


<span class="w"> </span>@st.composite
<span class="gu">@@ -268,4 +291,9 @@ def unique_subset_of(draw: st.DrawFn, objs: Union[Sequence[Hashable],</span>
<span class="w"> </span>    --------
<span class="w"> </span>    :ref:`testing.hypothesis`_
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(objs, Mapping):</span>
<span class="gi">+        keys = list(objs.keys())</span>
<span class="gi">+        subset_keys = draw(st.sets(st.sampled_from(keys), min_size=min_size, max_size=max_size))</span>
<span class="gi">+        return {k: objs[k] for k in subset_keys}</span>
<span class="gi">+    else:</span>
<span class="gi">+        return draw(st.sets(st.sampled_from(objs), min_size=min_size, max_size=max_size))</span>
<span class="gh">diff --git a/xarray/tests/test_coding_strings.py b/xarray/tests/test_coding_strings.py</span>
<span class="gh">index 17179a44..da5e4f56 100644</span>
<span class="gd">--- a/xarray/tests/test_coding_strings.py</span>
<span class="gi">+++ b/xarray/tests/test_coding_strings.py</span>
<span class="gu">@@ -209,6 +209,20 @@ def test_char_to_bytes_size_zero() -&gt; None:</span>
<span class="w"> </span>    assert_array_equal(actual, expected)


<span class="gi">+def test_ensure_fixed_length_bytes() -&gt; None:</span>
<span class="gi">+    var = Variable((&quot;x&quot;,), np.array([b&quot;a&quot;, b&quot;bb&quot;, b&quot;ccc&quot;], dtype=object))</span>
<span class="gi">+    result = strings.ensure_fixed_length_bytes(var)</span>
<span class="gi">+    expected = Variable((&quot;x&quot;, &quot;string&quot;), np.array([[b&quot;a&quot;, b&quot;&quot;, b&quot;&quot;], </span>
<span class="gi">+                                                   [b&quot;b&quot;, b&quot;b&quot;, b&quot;&quot;],</span>
<span class="gi">+                                                   [b&quot;c&quot;, b&quot;c&quot;, b&quot;c&quot;]]))</span>
<span class="gi">+    assert_identical(result, expected)</span>
<span class="gi">+</span>
<span class="gi">+    # Test with already fixed-length bytes</span>
<span class="gi">+    fixed_var = Variable((&quot;x&quot;,), np.array([b&quot;a&quot;, b&quot;b&quot;, b&quot;c&quot;], dtype=&quot;S1&quot;))</span>
<span class="gi">+    result = strings.ensure_fixed_length_bytes(fixed_var)</span>
<span class="gi">+    assert_identical(result, fixed_var)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>@requires_dask
<span class="w"> </span>def test_char_to_bytes_dask() -&gt; None:
<span class="w"> </span>    numpy_array = np.array([[b&quot;a&quot;, b&quot;b&quot;, b&quot;c&quot;], [b&quot;d&quot;, b&quot;e&quot;, b&quot;f&quot;]])
<span class="gu">@@ -224,6 +238,40 @@ def test_char_to_bytes_dask() -&gt; None:</span>
<span class="w"> </span>        strings.char_to_bytes(array.rechunk(1))


<span class="gi">+def test_numpy_bytes_to_char() -&gt; None:</span>
<span class="gi">+    # Test with regular byte strings</span>
<span class="gi">+    arr = np.array([b&quot;abc&quot;, b&quot;def&quot;])</span>
<span class="gi">+    result = strings._numpy_bytes_to_char(arr)</span>
<span class="gi">+    expected = np.array([[b&quot;a&quot;, b&quot;b&quot;, b&quot;c&quot;], [b&quot;d&quot;, b&quot;e&quot;, b&quot;f&quot;]])</span>
<span class="gi">+    assert_array_equal(result, expected)</span>
<span class="gi">+</span>
<span class="gi">+    # Test with object array of strings</span>
<span class="gi">+    arr = np.array([&quot;abc&quot;, &quot;def&quot;], dtype=object)</span>
<span class="gi">+    result = strings._numpy_bytes_to_char(arr)</span>
<span class="gi">+    assert_array_equal(result, expected)</span>
<span class="gi">+</span>
<span class="gi">+    # Test with invalid dtype</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;Unsupported dtype&quot;):</span>
<span class="gi">+        strings._numpy_bytes_to_char(np.array([1, 2, 3]))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_numpy_char_to_bytes() -&gt; None:</span>
<span class="gi">+    # Test with character array</span>
<span class="gi">+    arr = np.array([[b&quot;a&quot;, b&quot;b&quot;, b&quot;c&quot;], [b&quot;d&quot;, b&quot;e&quot;, b&quot;f&quot;]])</span>
<span class="gi">+    result = strings._numpy_char_to_bytes(arr)</span>
<span class="gi">+    expected = np.array([b&quot;abc&quot;, b&quot;def&quot;])</span>
<span class="gi">+    assert_array_equal(result, expected)</span>
<span class="gi">+</span>
<span class="gi">+    # Test with Unicode strings</span>
<span class="gi">+    arr = np.array([&quot;abc&quot;, &quot;def&quot;])</span>
<span class="gi">+    result = strings._numpy_char_to_bytes(arr)</span>
<span class="gi">+    assert_array_equal(result, expected)</span>
<span class="gi">+</span>
<span class="gi">+    # Test with invalid dtype</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;Unsupported dtype&quot;):</span>
<span class="gi">+        strings._numpy_char_to_bytes(np.array([1, 2, 3]))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>def test_bytes_to_char() -&gt; None:
<span class="w"> </span>    array = np.array([[b&quot;ab&quot;, b&quot;cd&quot;], [b&quot;ef&quot;, b&quot;gh&quot;]])
<span class="w"> </span>    expected = np.array([[[b&quot;a&quot;, b&quot;b&quot;], [b&quot;c&quot;, b&quot;d&quot;]], [[b&quot;e&quot;, b&quot;f&quot;], [b&quot;g&quot;, b&quot;h&quot;]]])
<span class="gh">diff --git a/xarray/tutorial.py b/xarray/tutorial.py</span>
<span class="gh">index 9e891efe..db3b9334 100644</span>
<span class="gd">--- a/xarray/tutorial.py</span>
<span class="gi">+++ b/xarray/tutorial.py</span>
<span class="gu">@@ -62,7 +62,28 @@ def open_dataset(name: str, cache: bool=True, cache_dir: (None | str | os.</span>
<span class="w"> </span>    open_dataset
<span class="w"> </span>    load_dataset
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if cache_dir is None:</span>
<span class="gi">+        cache_dir = pathlib.Path.home() / _default_cache_dir_name</span>
<span class="gi">+    else:</span>
<span class="gi">+        cache_dir = pathlib.Path(cache_dir)</span>
<span class="gi">+</span>
<span class="gi">+    if name in external_urls:</span>
<span class="gi">+        url = external_urls[name]</span>
<span class="gi">+    else:</span>
<span class="gi">+        url = f&quot;{base_url}/raw/{version}/{name}&quot;</span>
<span class="gi">+        if name in file_formats:</span>
<span class="gi">+            url += f&quot;.{file_formats[name]}&quot;</span>
<span class="gi">+</span>
<span class="gi">+    cache_file = cache_dir / name</span>
<span class="gi">+    if cache_file.exists():</span>
<span class="gi">+        return _open_dataset(cache_file, engine=engine, **kws)</span>
<span class="gi">+</span>
<span class="gi">+    if cache:</span>
<span class="gi">+        cache_dir.mkdir(parents=True, exist_ok=True)</span>
<span class="gi">+        _open_dataset(url, engine=engine, **kws).to_netcdf(cache_file)</span>
<span class="gi">+        return _open_dataset(cache_file, engine=engine, **kws)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return _open_dataset(url, engine=engine, **kws)</span>


<span class="w"> </span>def load_dataset(*args, **kwargs) -&gt;Dataset:
<span class="gu">@@ -102,7 +123,8 @@ def load_dataset(*args, **kwargs) -&gt;Dataset:</span>
<span class="w"> </span>    open_dataset
<span class="w"> </span>    load_dataset
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    with open_dataset(*args, **kwargs) as ds:</span>
<span class="gi">+        return ds.load()</span>


<span class="w"> </span>def scatter_example_dataset(*, seed: (None | int)=None) -&gt;Dataset:
<span class="gu">@@ -114,4 +136,24 @@ def scatter_example_dataset(*, seed: (None | int)=None) -&gt;Dataset:</span>
<span class="w"> </span>    seed : int, optional
<span class="w"> </span>        Seed for the random number generation.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    rng = np.random.default_rng(seed)</span>
<span class="gi">+    </span>
<span class="gi">+    n = 1000</span>
<span class="gi">+    x = rng.normal(size=n)</span>
<span class="gi">+    y = rng.normal(size=n)</span>
<span class="gi">+    z = rng.normal(size=n)</span>
<span class="gi">+    </span>
<span class="gi">+    da = DataArray(</span>
<span class="gi">+        data=np.column_stack([x, y, z]),</span>
<span class="gi">+        dims=[&quot;sample&quot;, &quot;dimension&quot;],</span>
<span class="gi">+        coords={</span>
<span class="gi">+            &quot;sample&quot;: range(n),</span>
<span class="gi">+            &quot;dimension&quot;: [&quot;x&quot;, &quot;y&quot;, &quot;z&quot;]</span>
<span class="gi">+        },</span>
<span class="gi">+        name=&quot;position&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    </span>
<span class="gi">+    ds = Dataset({&quot;position&quot;: da})</span>
<span class="gi">+    ds[&quot;distance&quot;] = np.sqrt((da**2).sum(dim=&quot;dimension&quot;))</span>
<span class="gi">+    </span>
<span class="gi">+    return ds</span>
<span class="gh">diff --git a/xarray/util/deprecation_helpers.py b/xarray/util/deprecation_helpers.py</span>
<span class="gh">index 65af5b80..78bcda00 100644</span>
<span class="gd">--- a/xarray/util/deprecation_helpers.py</span>
<span class="gi">+++ b/xarray/util/deprecation_helpers.py</span>
<span class="gu">@@ -39,7 +39,25 @@ def _deprecate_positional_args(version) -&gt;Callable[[T], T]:</span>
<span class="w"> </span>    This function is adapted from scikit-learn under the terms of its license. See
<span class="w"> </span>    licences/SCIKIT_LEARN_LICENSE
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    def decorator(func):</span>
<span class="gi">+        @wraps(func)</span>
<span class="gi">+        def wrapper(*args, **kwargs):</span>
<span class="gi">+            sig = inspect.signature(func)</span>
<span class="gi">+            params = list(sig.parameters.values())</span>
<span class="gi">+            keyword_params = [p for p in params if p.kind == KEYWORD_ONLY]</span>
<span class="gi">+</span>
<span class="gi">+            if len(args) &gt; len(params) - len(keyword_params):</span>
<span class="gi">+                warnings.warn(</span>
<span class="gi">+                    f&quot;From version {version}, passing these arguments to &quot;</span>
<span class="gi">+                    f&quot;{func.__name__} will be deprecated, and in future &quot;</span>
<span class="gi">+                    &quot;may raise an error. Please use keyword arguments &quot;</span>
<span class="gi">+                    &quot;instead.&quot;,</span>
<span class="gi">+                    FutureWarning,</span>
<span class="gi">+                    stacklevel=2,</span>
<span class="gi">+                )</span>
<span class="gi">+            return func(*args, **kwargs)</span>
<span class="gi">+        return wrapper</span>
<span class="gi">+    return decorator</span>


<span class="w"> </span>def deprecate_dims(func: T, old_name=&#39;dims&#39;) -&gt;T:
<span class="gu">@@ -48,4 +66,14 @@ def deprecate_dims(func: T, old_name=&#39;dims&#39;) -&gt;T:</span>
<span class="w"> </span>    `dim`. This decorator will issue a warning if `dims` is passed while forwarding it
<span class="w"> </span>    to `dim`.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    @wraps(func)</span>
<span class="gi">+    def wrapper(*args, **kwargs):</span>
<span class="gi">+        if old_name in kwargs:</span>
<span class="gi">+            emit_user_level_warning(</span>
<span class="gi">+                f&quot;The `{old_name}` argument has been deprecated and will be removed in a future version. &quot;</span>
<span class="gi">+                f&quot;Please use `dim` instead.&quot;,</span>
<span class="gi">+                FutureWarning,</span>
<span class="gi">+            )</span>
<span class="gi">+            kwargs[&#39;dim&#39;] = kwargs.pop(old_name)</span>
<span class="gi">+        return func(*args, **kwargs)</span>
<span class="gi">+    return wrapper</span>
<span class="gh">diff --git a/xarray/util/generate_aggregations.py b/xarray/util/generate_aggregations.py</span>
<span class="gh">index b2eadf0c..9120cc12 100644</span>
<span class="gd">--- a/xarray/util/generate_aggregations.py</span>
<span class="gi">+++ b/xarray/util/generate_aggregations.py</span>
<span class="gu">@@ -360,6 +360,14 @@ NAMED_ARRAY_GENERATOR = GenericAggregationGenerator(cls=&#39;&#39;, datastructure=</span>
<span class="w"> </span>    docref_description=&#39;reduction or aggregation operations&#39;,
<span class="w"> </span>    example_call_preamble=&#39;&#39;, definition_preamble=
<span class="w"> </span>    NAMED_ARRAY_AGGREGATIONS_PREAMBLE, has_keep_attrs=False)
<span class="gi">+def write_methods(filepath, generators, preamble):</span>
<span class="gi">+    with open(filepath, &quot;w&quot;) as f:</span>
<span class="gi">+        f.write(preamble)</span>
<span class="gi">+        for generator in generators:</span>
<span class="gi">+            f.write(generator.preamble)</span>
<span class="gi">+            for method in generator.methods:</span>
<span class="gi">+                f.write(generate_method(generator, method))</span>
<span class="gi">+</span>
<span class="w"> </span>if __name__ == &#39;__main__&#39;:
<span class="w"> </span>    import os
<span class="w"> </span>    from pathlib import Path
<span class="gu">@@ -372,3 +380,50 @@ if __name__ == &#39;__main__&#39;:</span>
<span class="w"> </span>    write_methods(filepath=p.parent / &#39;xarray&#39; / &#39;xarray&#39; / &#39;namedarray&#39; /
<span class="w"> </span>        &#39;_aggregations.py&#39;, generators=[NAMED_ARRAY_GENERATOR], preamble=
<span class="w"> </span>        NAMED_ARRAY_MODULE_PREAMBLE)
<span class="gi">+def generate_method(generator, method):</span>
<span class="gi">+    signature = generator._template_signature.format(</span>
<span class="gi">+        method=method.name,</span>
<span class="gi">+        kw_only=&quot;*,&quot; if generator.has_keep_attrs else &quot;&quot;,</span>
<span class="gi">+        extra_kwargs=&quot;&quot;.join(f&quot;\n        {kwarg.kwarg}&quot; for kwarg in method.extra_kwargs),</span>
<span class="gi">+        keep_attrs=&quot;\n        keep_attrs: bool | None = None,&quot; if generator.has_keep_attrs else &quot;&quot;,</span>
<span class="gi">+        obj=generator.datastructure.name,</span>
<span class="gi">+    )</span>
<span class="gi">+    </span>
<span class="gi">+    docstring = f&#39;&quot;&quot;&quot;{method.name}&#39;</span>
<span class="gi">+    docstring += generator._dim_docstring.format(method=method.name, cls=generator.cls)</span>
<span class="gi">+    </span>
<span class="gi">+    for kwarg in method.extra_kwargs:</span>
<span class="gi">+        docstring += f&quot;\n        {kwarg.docs}&quot;</span>
<span class="gi">+    </span>
<span class="gi">+    if generator.has_keep_attrs:</span>
<span class="gi">+        docstring += f&quot;\n        {_KEEP_ATTRS_DOCSTRING}&quot;</span>
<span class="gi">+    </span>
<span class="gi">+    docstring += f&quot;\n        {_KWARGS_DOCSTRING.format(method=method.name)}&quot;</span>
<span class="gi">+    </span>
<span class="gi">+    docstring += TEMPLATE_RETURNS.format(obj=generator.datastructure.name, method=method.name)</span>
<span class="gi">+    </span>
<span class="gi">+    see_also_methods = &quot;\n&quot;.join(f&quot;        {module}.{method.name}&quot; for module in method.see_also_modules)</span>
<span class="gi">+    docstring += TEMPLATE_SEE_ALSO.format(</span>
<span class="gi">+        see_also_methods=see_also_methods,</span>
<span class="gi">+        docref=generator.docref,</span>
<span class="gi">+        docref_description=generator.docref_description,</span>
<span class="gi">+    )</span>
<span class="gi">+    </span>
<span class="gi">+    if generator.notes or (method.numeric_only and generator.datastructure.numeric_only):</span>
<span class="gi">+        docstring += TEMPLATE_NOTES.format(notes=generator.notes)</span>
<span class="gi">+        if method.numeric_only and generator.datastructure.numeric_only:</span>
<span class="gi">+            docstring += f&quot;\n        {_NUMERIC_ONLY_NOTES}&quot;</span>
<span class="gi">+    </span>
<span class="gi">+    docstring += f&#39;\n        &quot;&quot;&quot;&#39;</span>
<span class="gi">+    </span>
<span class="gi">+    method_body = f&quot;&quot;&quot;</span>
<span class="gi">+        return self.reduce(</span>
<span class="gi">+            duck_array_ops.{method.array_method},</span>
<span class="gi">+            dim=dim,</span>
<span class="gi">+            skipna=skipna,</span>
<span class="gi">+            keep_attrs=keep_attrs,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>
<span class="gi">+    &quot;&quot;&quot;</span>
<span class="gi">+    </span>
<span class="gi">+    return f&quot;{signature}{docstring}{method_body}&quot;</span>
<span class="gh">diff --git a/xarray/util/generate_ops.py b/xarray/util/generate_ops.py</span>
<span class="gh">index 9818559a..8608cf41 100644</span>
<span class="gd">--- a/xarray/util/generate_ops.py</span>
<span class="gi">+++ b/xarray/util/generate_ops.py</span>
<span class="gu">@@ -74,6 +74,39 @@ unhashable = &quot;&quot;&quot;</span>
<span class="w"> </span>    __hash__: None  # type:ignore[assignment]&quot;&quot;&quot;
<span class="w"> </span>FuncType = Sequence[tuple[Optional[str], Optional[str]]]
<span class="w"> </span>OpsType = tuple[FuncType, str, dict[str, str]]
<span class="gi">+</span>
<span class="gi">+def binops(other_type: str, return_type: str = &#39;Self&#39;) -&gt; list[OpsType]:</span>
<span class="gi">+    return [</span>
<span class="gi">+        (BINOPS_EQNE + BINOPS_CMP + BINOPS_NUM, required_method_binary, {&#39;other_type&#39;: other_type, &#39;return_type&#39;: return_type}),</span>
<span class="gi">+        (BINOPS_REFLEXIVE, required_method_binary, {&#39;other_type&#39;: other_type, &#39;return_type&#39;: return_type, &#39;reflexive&#39;: True})</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+def binops_overload(other_type: str, overload_type: str, return_type: str = &#39;Self&#39;, type_ignore: str = &#39;&#39;) -&gt; list[OpsType]:</span>
<span class="gi">+    return [</span>
<span class="gi">+        (BINOPS_EQNE + BINOPS_CMP + BINOPS_NUM, required_method_binary, {</span>
<span class="gi">+            &#39;other_type&#39;: other_type,</span>
<span class="gi">+            &#39;return_type&#39;: return_type,</span>
<span class="gi">+            &#39;overload_type&#39;: overload_type,</span>
<span class="gi">+            &#39;type_ignore&#39;: f&#39;  # type: ignore[{type_ignore}]&#39; if type_ignore else &#39;&#39;,</span>
<span class="gi">+            &#39;overload_type_ignore&#39;: f&#39;  # type: ignore[{type_ignore}]&#39; if type_ignore else &#39;&#39;</span>
<span class="gi">+        }),</span>
<span class="gi">+        (BINOPS_REFLEXIVE, required_method_binary, {&#39;other_type&#39;: other_type, &#39;return_type&#39;: return_type, &#39;reflexive&#39;: True})</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+def inplace(other_type: str, type_ignore: str = &#39;&#39;) -&gt; list[OpsType]:</span>
<span class="gi">+    return [</span>
<span class="gi">+        (BINOPS_INPLACE, required_method_inplace, {</span>
<span class="gi">+            &#39;other_type&#39;: other_type,</span>
<span class="gi">+            &#39;type_ignore&#39;: f&#39;  # type: ignore[{type_ignore}]&#39; if type_ignore else &#39;&#39;</span>
<span class="gi">+        })</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+def unops() -&gt; list[OpsType]:</span>
<span class="gi">+    return [</span>
<span class="gi">+        (UNARY_OPS, required_method_unary, {&#39;unary&#39;: True}),</span>
<span class="gi">+        (OTHER_UNARY_METHODS, required_method_unary, {&#39;other_unary&#39;: True})</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="w"> </span>ops_info = {}
<span class="w"> </span>ops_info[&#39;DatasetOpsMixin&#39;] = binops(other_type=&#39;DsCompatible&#39;) + inplace(
<span class="w"> </span>    other_type=&#39;DsCompatible&#39;) + unops()
<span class="gu">@@ -116,7 +149,35 @@ COPY_DOCSTRING = &#39;    {method}.__doc__ = {func}.__doc__&#39;</span>

<span class="w"> </span>def render(ops_info: dict[str, list[OpsType]]) -&gt;Iterator[str]:
<span class="w"> </span>    &quot;&quot;&quot;Render the module or stub file.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    yield MODULE_PREAMBLE</span>
<span class="gi">+</span>
<span class="gi">+    for cls_name, ops in ops_info.items():</span>
<span class="gi">+        yield CLASS_PREAMBLE.format(cls_name=cls_name, newline=&#39;\n&#39; if cls_name != &#39;DatasetOpsMixin&#39; else &#39;&#39;)</span>
<span class="gi">+</span>
<span class="gi">+        for funcs, required_method, kwargs in ops:</span>
<span class="gi">+            yield required_method.format(**kwargs)</span>
<span class="gi">+</span>
<span class="gi">+            for method, func in funcs:</span>
<span class="gi">+                if method is None or func is None:</span>
<span class="gi">+                    continue</span>
<span class="gi">+</span>
<span class="gi">+                if &#39;overload&#39; in kwargs:</span>
<span class="gi">+                    yield template_binop_overload.format(method=method, func=func, **kwargs)</span>
<span class="gi">+                elif &#39;reflexive&#39; in kwargs:</span>
<span class="gi">+                    yield template_reflexive.format(method=method, func=func, **kwargs)</span>
<span class="gi">+                elif &#39;inplace&#39; in kwargs:</span>
<span class="gi">+                    yield template_inplace.format(method=method, func=func, **kwargs)</span>
<span class="gi">+                elif &#39;unary&#39; in kwargs:</span>
<span class="gi">+                    yield template_unary.format(method=method, func=func)</span>
<span class="gi">+                elif &#39;other_unary&#39; in kwargs:</span>
<span class="gi">+                    yield template_other_unary.format(method=method, func=func)</span>
<span class="gi">+                else:</span>
<span class="gi">+                    yield template_binop.format(method=method, func=func, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+                yield COPY_DOCSTRING.format(method=method, func=func)</span>
<span class="gi">+</span>
<span class="gi">+        if cls_name in (&#39;DatasetOpsMixin&#39;, &#39;DataArrayOpsMixin&#39;, &#39;VariableOpsMixin&#39;):</span>
<span class="gi">+            yield unhashable</span>


<span class="w"> </span>if __name__ == &#39;__main__&#39;:
<span class="gh">diff --git a/xarray/util/print_versions.py b/xarray/util/print_versions.py</span>
<span class="gh">index 586848d2..f202bdee 100755</span>
<span class="gd">--- a/xarray/util/print_versions.py</span>
<span class="gi">+++ b/xarray/util/print_versions.py</span>
<span class="gu">@@ -10,7 +10,53 @@ import sys</span>

<span class="w"> </span>def get_sys_info():
<span class="w"> </span>    &quot;&quot;&quot;Returns system information as a dict&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    blob = []</span>
<span class="gi">+</span>
<span class="gi">+    # System information</span>
<span class="gi">+    blob.append((&quot;Python&quot;, sys.version))</span>
<span class="gi">+    blob.append((&quot;Python executable&quot;, sys.executable))</span>
<span class="gi">+    blob.append((&quot;Machine&quot;, platform.platform()))</span>
<span class="gi">+    blob.append((&quot;Processor&quot;, platform.processor()))</span>
<span class="gi">+    blob.append((&quot;Byte-ordering&quot;, sys.byteorder))</span>
<span class="gi">+    blob.append((&quot;Default encoding&quot;, sys.getdefaultencoding()))</span>
<span class="gi">+    blob.append((&quot;filesystemencoding&quot;, sys.getfilesystemencoding()))</span>
<span class="gi">+</span>
<span class="gi">+    # Python dependencies</span>
<span class="gi">+    dependencies = [</span>
<span class="gi">+        &quot;xarray&quot;,</span>
<span class="gi">+        &quot;numpy&quot;,</span>
<span class="gi">+        &quot;pandas&quot;,</span>
<span class="gi">+        &quot;matplotlib&quot;,</span>
<span class="gi">+        &quot;dask&quot;,</span>
<span class="gi">+        &quot;distributed&quot;,</span>
<span class="gi">+        &quot;scipy&quot;,</span>
<span class="gi">+        &quot;netCDF4&quot;,</span>
<span class="gi">+        &quot;h5netcdf&quot;,</span>
<span class="gi">+        &quot;h5py&quot;,</span>
<span class="gi">+        &quot;Nio&quot;,</span>
<span class="gi">+        &quot;zarr&quot;,</span>
<span class="gi">+        &quot;cftime&quot;,</span>
<span class="gi">+        &quot;nc_time_axis&quot;,</span>
<span class="gi">+        &quot;bottleneck&quot;,</span>
<span class="gi">+        &quot;sparse&quot;,</span>
<span class="gi">+        &quot;pydap&quot;,</span>
<span class="gi">+        &quot;numbagg&quot;,</span>
<span class="gi">+        &quot;fsspec&quot;,</span>
<span class="gi">+        &quot;pooch&quot;,</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+    for modname in dependencies:</span>
<span class="gi">+        try:</span>
<span class="gi">+            if modname in sys.modules:</span>
<span class="gi">+                mod = sys.modules[modname]</span>
<span class="gi">+            else:</span>
<span class="gi">+                mod = importlib.import_module(modname)</span>
<span class="gi">+            ver = getattr(mod, &quot;__version__&quot;, &quot;installed&quot;)</span>
<span class="gi">+        except ImportError:</span>
<span class="gi">+            ver = &quot;not installed&quot;</span>
<span class="gi">+        blob.append((modname, ver))</span>
<span class="gi">+</span>
<span class="gi">+    return dict(blob)</span>


<span class="w"> </span>def show_versions(file=sys.stdout):
<span class="gu">@@ -21,7 +67,13 @@ def show_versions(file=sys.stdout):</span>
<span class="w"> </span>    file : file-like, optional
<span class="w"> </span>        print to the given file-like object. Defaults to sys.stdout.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    sys_info = get_sys_info()</span>
<span class="gi">+</span>
<span class="gi">+    file.write(&quot;INSTALLED VERSIONS\n&quot;)</span>
<span class="gi">+    file.write(&quot;------------------\n&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    for k, v in sys_info.items():</span>
<span class="gi">+        file.write(f&quot;{k}: {v}\n&quot;)</span>


<span class="w"> </span>if __name__ == &#39;__main__&#39;:
</code></pre></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.d6f25eb3.min.js"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../javascripts/tablesort.js"></script>
      
        <script src="../javascripts/tablesort.number.js"></script>
      
    
  </body>
</html>