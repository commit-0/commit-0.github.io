
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.37">
    
    
      
        <title>Analysis commit0 all reference geopandas - Commit-0</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.8c3ca2c6.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#reference-gold-geopandas" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Commit-0" class="md-header__button md-logo" aria-label="Commit-0" data-md-component="logo">
      
  <img src="../logo2.webp" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Commit-0
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Analysis commit0 all reference geopandas
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Commit-0" class="md-nav__button md-logo" aria-label="Commit-0" data-md-component="logo">
      
  <img src="../logo2.webp" alt="logo">

    </a>
    Commit-0
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../setupdist/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Commit0
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Agent
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Leaderboard
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pytest-summary-for-test-tests" class="md-nav__link">
    <span class="md-ellipsis">
      Pytest Summary for test tests
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#failed-pytests" class="md-nav__link">
    <span class="md-ellipsis">
      Failed pytests:
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Failed pytests:">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#test_extension_arraypytestgetitemtest_getitem_series_integer_with_missing_raiseslist" class="md-nav__link">
    <span class="md-ellipsis">
      test_extension_array.py::TestGetitem::test_getitem_series_integer_with_missing_raises[list]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_extension_arraypytestgetitemtest_getitem_series_integer_with_missing_raisesinteger-array" class="md-nav__link">
    <span class="md-ellipsis">
      test_extension_array.py::TestGetitem::test_getitem_series_integer_with_missing_raises[integer-array]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_extension_arraypytestsetitemtest_setitem_integer_with_missing_raiseslist-true" class="md-nav__link">
    <span class="md-ellipsis">
      test_extension_array.py::TestSetitem::test_setitem_integer_with_missing_raises[list-True]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_op_output_typespytest_loc_add_rowgeom" class="md-nav__link">
    <span class="md-ellipsis">
      test_op_output_types.py::test_loc_add_row[geom]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_pandas_methodspytest_drop_duplicates_series" class="md-nav__link">
    <span class="md-ellipsis">
      test_pandas_methods.py::test_drop_duplicates_series
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_pandas_methodspytest_drop_duplicates_frame" class="md-nav__link">
    <span class="md-ellipsis">
      test_pandas_methods.py::test_drop_duplicates_frame
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_sindexpytestshapelyinterfacetest_query_sortingfalse-expected1" class="md-nav__link">
    <span class="md-ellipsis">
      test_sindex.py::TestShapelyInterface::test_query_sorting[False-expected1]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_sindexpytestshapelyinterfacetest_query_bulk_sortingfalse-expected1" class="md-nav__link">
    <span class="md-ellipsis">
      test_sindex.py::TestShapelyInterface::test_query_bulk_sorting[False-expected1]
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#patch-diff" class="md-nav__link">
    <span class="md-ellipsis">
      Patch diff
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<p><a href="/analysis_commit0_all_reference">back to Reference (Gold) summary</a></p>
<h1 id="reference-gold-geopandas"><strong>Reference (Gold)</strong>: geopandas</h1>
<h2 id="pytest-summary-for-test-tests">Pytest Summary for test <code>tests</code></h2>
<table>
<thead>
<tr>
<th style="text-align: left;">status</th>
<th style="text-align: center;">count</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">passed</td>
<td style="text-align: center;">1517</td>
</tr>
<tr>
<td style="text-align: left;">xfailed</td>
<td style="text-align: center;">6</td>
</tr>
<tr>
<td style="text-align: left;">skipped</td>
<td style="text-align: center;">65</td>
</tr>
<tr>
<td style="text-align: left;">xpassed</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: left;">total</td>
<td style="text-align: center;">1590</td>
</tr>
<tr>
<td style="text-align: left;">collected</td>
<td style="text-align: center;">1590</td>
</tr>
</tbody>
</table>
<h2 id="failed-pytests">Failed pytests:</h2>
<h3 id="test_extension_arraypytestgetitemtest_getitem_series_integer_with_missing_raiseslist">test_extension_array.py::TestGetitem::test_getitem_series_integer_with_missing_raises[list]</h3>
<details><summary> <pre>test_extension_array.py::TestGetitem::test_getitem_series_integer_with_missing_raises[list]</pre></summary><pre>
[gw4] linux -- Python 3.10.12 /testbed/.venv/bin/python3
</pre>
</details>
<h3 id="test_extension_arraypytestgetitemtest_getitem_series_integer_with_missing_raisesinteger-array">test_extension_array.py::TestGetitem::test_getitem_series_integer_with_missing_raises[integer-array]</h3>
<details><summary> <pre>test_extension_array.py::TestGetitem::test_getitem_series_integer_with_missing_raises[integer-array]</pre></summary><pre>
[gw4] linux -- Python 3.10.12 /testbed/.venv/bin/python3
</pre>
</details>
<h3 id="test_extension_arraypytestsetitemtest_setitem_integer_with_missing_raiseslist-true">test_extension_array.py::TestSetitem::test_setitem_integer_with_missing_raises[list-True]</h3>
<details><summary> <pre>test_extension_array.py::TestSetitem::test_setitem_integer_with_missing_raises[list-True]</pre></summary><pre>
[gw4] linux -- Python 3.10.12 /testbed/.venv/bin/python3
</pre>
</details>
<h3 id="test_op_output_typespytest_loc_add_rowgeom">test_op_output_types.py::test_loc_add_row[geom]</h3>
<details><summary> <pre>test_op_output_types.py::test_loc_add_row[geom]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3
</pre>
</details>
<h3 id="test_pandas_methodspytest_drop_duplicates_series">test_pandas_methods.py::test_drop_duplicates_series</h3>
<details><summary> <pre>test_pandas_methods.py::test_drop_duplicates_series</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3
</pre>
</details>
<h3 id="test_pandas_methodspytest_drop_duplicates_frame">test_pandas_methods.py::test_drop_duplicates_frame</h3>
<details><summary> <pre>test_pandas_methods.py::test_drop_duplicates_frame</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3
</pre>
</details>
<h3 id="test_sindexpytestshapelyinterfacetest_query_sortingfalse-expected1">test_sindex.py::TestShapelyInterface::test_query_sorting[False-expected1]</h3>
<details><summary> <pre>test_sindex.py::TestShapelyInterface::test_query_sorting[False-expected1]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3
</pre>
</details>
<h3 id="test_sindexpytestshapelyinterfacetest_query_bulk_sortingfalse-expected1">test_sindex.py::TestShapelyInterface::test_query_bulk_sorting[False-expected1]</h3>
<details><summary> <pre>test_sindex.py::TestShapelyInterface::test_query_bulk_sorting[False-expected1]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3
</pre>
</details>

<h2 id="patch-diff">Patch diff</h2>
<div class="highlight"><pre><span></span><code><span class="gh">diff --git a/geopandas/_compat.py b/geopandas/_compat.py</span>
<span class="gh">index 2c7e74f0..3d582bdc 100644</span>
<span class="gd">--- a/geopandas/_compat.py</span>
<span class="gi">+++ b/geopandas/_compat.py</span>
<span class="gu">@@ -1,21 +1,35 @@</span>
<span class="w"> </span>import importlib
<span class="w"> </span>from packaging.version import Version
<span class="gi">+</span>
<span class="w"> </span>import pandas as pd
<span class="gi">+</span>
<span class="w"> </span>import shapely
<span class="w"> </span>import shapely.geos
<span class="gd">-PANDAS_GE_14 = Version(pd.__version__) &gt;= Version(&#39;1.4.0rc0&#39;)</span>
<span class="gd">-PANDAS_GE_15 = Version(pd.__version__) &gt;= Version(&#39;1.5.0&#39;)</span>
<span class="gd">-PANDAS_GE_20 = Version(pd.__version__) &gt;= Version(&#39;2.0.0&#39;)</span>
<span class="gd">-PANDAS_GE_202 = Version(pd.__version__) &gt;= Version(&#39;2.0.2&#39;)</span>
<span class="gd">-PANDAS_GE_21 = Version(pd.__version__) &gt;= Version(&#39;2.1.0&#39;)</span>
<span class="gd">-PANDAS_GE_22 = Version(pd.__version__) &gt;= Version(&#39;2.2.0&#39;)</span>
<span class="gd">-PANDAS_GE_30 = Version(pd.__version__) &gt;= Version(&#39;3.0.0.dev0&#39;)</span>
<span class="gd">-SHAPELY_GE_204 = Version(shapely.__version__) &gt;= Version(&#39;2.0.4&#39;)</span>
<span class="gi">+</span>
<span class="gi">+# -----------------------------------------------------------------------------</span>
<span class="gi">+# pandas compat</span>
<span class="gi">+# -----------------------------------------------------------------------------</span>
<span class="gi">+</span>
<span class="gi">+PANDAS_GE_14 = Version(pd.__version__) &gt;= Version(&quot;1.4.0rc0&quot;)</span>
<span class="gi">+PANDAS_GE_15 = Version(pd.__version__) &gt;= Version(&quot;1.5.0&quot;)</span>
<span class="gi">+PANDAS_GE_20 = Version(pd.__version__) &gt;= Version(&quot;2.0.0&quot;)</span>
<span class="gi">+PANDAS_GE_202 = Version(pd.__version__) &gt;= Version(&quot;2.0.2&quot;)</span>
<span class="gi">+PANDAS_GE_21 = Version(pd.__version__) &gt;= Version(&quot;2.1.0&quot;)</span>
<span class="gi">+PANDAS_GE_22 = Version(pd.__version__) &gt;= Version(&quot;2.2.0&quot;)</span>
<span class="gi">+PANDAS_GE_30 = Version(pd.__version__) &gt;= Version(&quot;3.0.0.dev0&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# -----------------------------------------------------------------------------</span>
<span class="gi">+# Shapely / GEOS compat</span>
<span class="gi">+# -----------------------------------------------------------------------------</span>
<span class="gi">+</span>
<span class="gi">+SHAPELY_GE_204 = Version(shapely.__version__) &gt;= Version(&quot;2.0.4&quot;)</span>
<span class="gi">+</span>
<span class="w"> </span>GEOS_GE_390 = shapely.geos.geos_version &gt;= (3, 9, 0)
<span class="w"> </span>GEOS_GE_310 = shapely.geos.geos_version &gt;= (3, 10, 0)


<span class="gd">-def import_optional_dependency(name: str, extra: str=&#39;&#39;):</span>
<span class="gi">+def import_optional_dependency(name: str, extra: str = &quot;&quot;):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Import an optional dependency.

<span class="gu">@@ -33,12 +47,46 @@ def import_optional_dependency(name: str, extra: str=&#39;&#39;):</span>
<span class="w"> </span>    -------
<span class="w"> </span>    module
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    msg = &quot;&quot;&quot;Missing optional dependency &#39;{name}&#39;. {extra}  &quot;</span>
<span class="gi">+        &quot;Use pip or conda to install {name}.&quot;&quot;&quot;.format(</span>
<span class="gi">+        name=name, extra=extra</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    if not isinstance(name, str):</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &quot;Invalid module name: &#39;{name}&#39;; must be a string&quot;.format(name=name)</span>
<span class="gi">+        )</span>

<span class="gi">+    try:</span>
<span class="gi">+        module = importlib.import_module(name)</span>

<span class="gi">+    except ImportError:</span>
<span class="gi">+        raise ImportError(msg) from None</span>
<span class="gi">+</span>
<span class="gi">+    return module</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# -----------------------------------------------------------------------------</span>
<span class="gi">+# pyproj compat</span>
<span class="gi">+# -----------------------------------------------------------------------------</span>
<span class="w"> </span>try:
<span class="gd">-    import pyproj</span>
<span class="gi">+    import pyproj  # noqa: F401</span>
<span class="gi">+</span>
<span class="w"> </span>    HAS_PYPROJ = True
<span class="gi">+</span>
<span class="w"> </span>except ImportError as err:
<span class="w"> </span>    HAS_PYPROJ = False
<span class="w"> </span>    pyproj_import_error = str(err)
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def requires_pyproj(func):</span>
<span class="gi">+    def wrapper(*args, **kwargs):</span>
<span class="gi">+        if not HAS_PYPROJ:</span>
<span class="gi">+            raise ImportError(</span>
<span class="gi">+                f&quot;The &#39;pyproj&#39; package is required for {func.__name__} to work. &quot;</span>
<span class="gi">+                &quot;Install it and initialize the object with a CRS before using it.&quot;</span>
<span class="gi">+                f&quot;\nImporting pyproj resulted in: {pyproj_import_error}&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        return func(*args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    return wrapper</span>
<span class="gh">diff --git a/geopandas/_config.py b/geopandas/_config.py</span>
<span class="gh">index a27f8854..d92882a7 100644</span>
<span class="gd">--- a/geopandas/_config.py</span>
<span class="gi">+++ b/geopandas/_config.py</span>
<span class="gu">@@ -5,23 +5,28 @@ Based on https://github.com/topper-123/optioneer, but simplified (don&#39;t deal</span>
<span class="w"> </span>with nested options, deprecated options, ..), just the attribute-style dict
<span class="w"> </span>like holding the options and giving a nice repr.
<span class="w"> </span>&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>import textwrap
<span class="w"> </span>import warnings
<span class="w"> </span>from collections import namedtuple
<span class="gd">-Option = namedtuple(&#39;Option&#39;, &#39;key default_value doc validator callback&#39;)</span>
<span class="gi">+</span>
<span class="gi">+Option = namedtuple(&quot;Option&quot;, &quot;key default_value doc validator callback&quot;)</span>


<span class="w"> </span>class Options(object):
<span class="w"> </span>    &quot;&quot;&quot;Provide attribute-style access to configuration dict.&quot;&quot;&quot;

<span class="w"> </span>    def __init__(self, options):
<span class="gd">-        super().__setattr__(&#39;_options&#39;, options)</span>
<span class="gi">+        super().__setattr__(&quot;_options&quot;, options)</span>
<span class="gi">+        # populate with default values</span>
<span class="w"> </span>        config = {}
<span class="w"> </span>        for key, option in options.items():
<span class="w"> </span>            config[key] = option.default_value
<span class="gd">-        super().__setattr__(&#39;_config&#39;, config)</span>
<span class="gi">+</span>
<span class="gi">+        super().__setattr__(&quot;_config&quot;, config)</span>

<span class="w"> </span>    def __setattr__(self, key, value):
<span class="gi">+        # you can&#39;t set new keys</span>
<span class="w"> </span>        if key in self._config:
<span class="w"> </span>            option = self._options[key]
<span class="w"> </span>            if option.validator:
<span class="gu">@@ -30,45 +35,99 @@ class Options(object):</span>
<span class="w"> </span>            if option.callback:
<span class="w"> </span>                option.callback(key, value)
<span class="w"> </span>        else:
<span class="gd">-            msg = &#39;You can only set the value of existing options&#39;</span>
<span class="gi">+            msg = &quot;You can only set the value of existing options&quot;</span>
<span class="w"> </span>            raise AttributeError(msg)

<span class="w"> </span>    def __getattr__(self, key):
<span class="w"> </span>        try:
<span class="w"> </span>            return self._config[key]
<span class="w"> </span>        except KeyError:
<span class="gd">-            raise AttributeError(&#39;No such option&#39;)</span>
<span class="gi">+            raise AttributeError(&quot;No such option&quot;)</span>

<span class="w"> </span>    def __dir__(self):
<span class="w"> </span>        return list(self._config.keys())

<span class="w"> </span>    def __repr__(self):
<span class="w"> </span>        cls = self.__class__.__name__
<span class="gd">-        description = &#39;&#39;</span>
<span class="gi">+        description = &quot;&quot;</span>
<span class="w"> </span>        for key, option in self._options.items():
<span class="gd">-            descr = &#39;{key}: {cur!r} [default: {default!r}]\n&#39;.format(key=</span>
<span class="gd">-                key, cur=self._config[key], default=option.default_value)</span>
<span class="gi">+            descr = &quot;{key}: {cur!r} [default: {default!r}]\n&quot;.format(</span>
<span class="gi">+                key=key, cur=self._config[key], default=option.default_value</span>
<span class="gi">+            )</span>
<span class="w"> </span>            description += descr
<span class="gi">+</span>
<span class="w"> </span>            if option.doc:
<span class="gd">-                doc_text = &#39;\n&#39;.join(textwrap.wrap(option.doc, width=70))</span>
<span class="gi">+                doc_text = &quot;\n&quot;.join(textwrap.wrap(option.doc, width=70))</span>
<span class="w"> </span>            else:
<span class="gd">-                doc_text = &#39;No description available.&#39;</span>
<span class="gd">-            doc_text = textwrap.indent(doc_text, prefix=&#39;    &#39;)</span>
<span class="gd">-            description += doc_text + &#39;\n&#39;</span>
<span class="gd">-        space = &#39;\n  &#39;</span>
<span class="gd">-        description = description.replace(&#39;\n&#39;, space)</span>
<span class="gd">-        return &#39;{}({}{})&#39;.format(cls, space, description)</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-display_precision = Option(key=&#39;display_precision&#39;, default_value=None, doc</span>
<span class="gd">-    =</span>
<span class="gd">-    &#39;The precision (maximum number of decimals) of the coordinates in the WKT representation in the Series/DataFrame display. By default (None), it tries to infer and use 3 decimals for projected coordinates and 5 decimals for geographic coordinates.&#39;</span>
<span class="gd">-    , validator=_validate_display_precision, callback=None)</span>
<span class="gd">-io_engine = Option(key=&#39;io_engine&#39;, default_value=None, doc=</span>
<span class="gd">-    &quot;The default engine for ``read_file`` and ``to_file``. Options are &#39;pyogrio&#39; and &#39;fiona&#39;.&quot;</span>
<span class="gd">-    , validator=_validate_io_engine, callback=None)</span>
<span class="gd">-use_pygeos = Option(key=&#39;use_pygeos&#39;, default_value=False, doc=</span>
<span class="gd">-    &#39;Deprecated option previously used to enable PyGEOS. It will be removed in GeoPandas 1.1.&#39;</span>
<span class="gd">-    , validator=_warn_use_pygeos_deprecated, callback=None)</span>
<span class="gd">-options = Options({&#39;display_precision&#39;: display_precision, &#39;use_pygeos&#39;:</span>
<span class="gd">-    use_pygeos, &#39;io_engine&#39;: io_engine})</span>
<span class="gi">+                doc_text = &quot;No description available.&quot;</span>
<span class="gi">+            doc_text = textwrap.indent(doc_text, prefix=&quot;    &quot;)</span>
<span class="gi">+            description += doc_text + &quot;\n&quot;</span>
<span class="gi">+        space = &quot;\n  &quot;</span>
<span class="gi">+        description = description.replace(&quot;\n&quot;, space)</span>
<span class="gi">+        return &quot;{}({}{})&quot;.format(cls, space, description)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _validate_display_precision(value):</span>
<span class="gi">+    if value is not None:</span>
<span class="gi">+        if not isinstance(value, int) or not (0 &lt;= value &lt;= 16):</span>
<span class="gi">+            raise ValueError(&quot;Invalid value, needs to be an integer [0-16]&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+display_precision = Option(</span>
<span class="gi">+    key=&quot;display_precision&quot;,</span>
<span class="gi">+    default_value=None,</span>
<span class="gi">+    doc=(</span>
<span class="gi">+        &quot;The precision (maximum number of decimals) of the coordinates in &quot;</span>
<span class="gi">+        &quot;the WKT representation in the Series/DataFrame display. &quot;</span>
<span class="gi">+        &quot;By default (None), it tries to infer and use 3 decimals for projected &quot;</span>
<span class="gi">+        &quot;coordinates and 5 decimals for geographic coordinates.&quot;</span>
<span class="gi">+    ),</span>
<span class="gi">+    validator=_validate_display_precision,</span>
<span class="gi">+    callback=None,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _warn_use_pygeos_deprecated(_value):</span>
<span class="gi">+    warnings.warn(</span>
<span class="gi">+        &quot;pygeos support was removed in 1.0. &quot;</span>
<span class="gi">+        &quot;geopandas.use_pygeos is a no-op and will be removed in geopandas 1.1.&quot;,</span>
<span class="gi">+        stacklevel=3,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _validate_io_engine(value):</span>
<span class="gi">+    if value is not None:</span>
<span class="gi">+        if value not in (&quot;pyogrio&quot;, &quot;fiona&quot;):</span>
<span class="gi">+            raise ValueError(f&quot;Expected &#39;pyogrio&#39; or &#39;fiona&#39;, got &#39;{value}&#39;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+io_engine = Option(</span>
<span class="gi">+    key=&quot;io_engine&quot;,</span>
<span class="gi">+    default_value=None,</span>
<span class="gi">+    doc=(</span>
<span class="gi">+        &quot;The default engine for ``read_file`` and ``to_file``. &quot;</span>
<span class="gi">+        &quot;Options are &#39;pyogrio&#39; and &#39;fiona&#39;.&quot;</span>
<span class="gi">+    ),</span>
<span class="gi">+    validator=_validate_io_engine,</span>
<span class="gi">+    callback=None,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="gi">+# TODO: deprecate this</span>
<span class="gi">+use_pygeos = Option(</span>
<span class="gi">+    key=&quot;use_pygeos&quot;,</span>
<span class="gi">+    default_value=False,</span>
<span class="gi">+    doc=(</span>
<span class="gi">+        &quot;Deprecated option previously used to enable PyGEOS. &quot;</span>
<span class="gi">+        &quot;It will be removed in GeoPandas 1.1.&quot;</span>
<span class="gi">+    ),</span>
<span class="gi">+    validator=_warn_use_pygeos_deprecated,</span>
<span class="gi">+    callback=None,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="gi">+options = Options(</span>
<span class="gi">+    {</span>
<span class="gi">+        &quot;display_precision&quot;: display_precision,</span>
<span class="gi">+        &quot;use_pygeos&quot;: use_pygeos,</span>
<span class="gi">+        &quot;io_engine&quot;: io_engine,</span>
<span class="gi">+    }</span>
<span class="gi">+)</span>
<span class="gh">diff --git a/geopandas/_decorator.py b/geopandas/_decorator.py</span>
<span class="gh">index d242f705..dee8e17c 100644</span>
<span class="gd">--- a/geopandas/_decorator.py</span>
<span class="gi">+++ b/geopandas/_decorator.py</span>
<span class="gu">@@ -1,8 +1,11 @@</span>
<span class="w"> </span>from textwrap import dedent
<span class="w"> </span>from typing import Callable, Union

<span class="gi">+# doc decorator function ported with modifications from Pandas</span>
<span class="gi">+# https://github.com/pandas-dev/pandas/blob/master/pandas/util/_decorators.py</span>

<span class="gd">-def doc(*docstrings: Union[str, Callable], **params) -&gt;Callable:</span>
<span class="gi">+</span>
<span class="gi">+def doc(*docstrings: Union[str, Callable], **params) -&gt; Callable:</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    A decorator take docstring templates, concatenate them and perform string
<span class="w"> </span>    substitution on it.
<span class="gu">@@ -20,4 +23,30 @@ def doc(*docstrings: Union[str, Callable], **params) -&gt;Callable:</span>
<span class="w"> </span>    **params
<span class="w"> </span>        The string which would be used to format docstring template.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    def decorator(decorated: Callable) -&gt; Callable:</span>
<span class="gi">+        # collecting docstring and docstring templates</span>
<span class="gi">+        docstring_components: list[Union[str, Callable]] = []</span>
<span class="gi">+        if decorated.__doc__:</span>
<span class="gi">+            docstring_components.append(dedent(decorated.__doc__))</span>
<span class="gi">+</span>
<span class="gi">+        for docstring in docstrings:</span>
<span class="gi">+            if hasattr(docstring, &quot;_docstring_components&quot;):</span>
<span class="gi">+                docstring_components.extend(docstring._docstring_components)</span>
<span class="gi">+            elif isinstance(docstring, str) or docstring.__doc__:</span>
<span class="gi">+                docstring_components.append(docstring)</span>
<span class="gi">+</span>
<span class="gi">+        # formatting templates and concatenating docstring</span>
<span class="gi">+        decorated.__doc__ = &quot;&quot;.join(</span>
<span class="gi">+            (</span>
<span class="gi">+                component.format(**params)</span>
<span class="gi">+                if isinstance(component, str)</span>
<span class="gi">+                else dedent(component.__doc__ or &quot;&quot;)</span>
<span class="gi">+            )</span>
<span class="gi">+            for component in docstring_components</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        decorated._docstring_components = docstring_components</span>
<span class="gi">+        return decorated</span>
<span class="gi">+</span>
<span class="gi">+    return decorator</span>
<span class="gh">diff --git a/geopandas/_version.py b/geopandas/_version.py</span>
<span class="gh">index 61aaa9f6..4639f7c3 100644</span>
<span class="gd">--- a/geopandas/_version.py</span>
<span class="gi">+++ b/geopandas/_version.py</span>
<span class="gu">@@ -1,4 +1,15 @@</span>
<span class="gi">+# This file helps to compute a version number in source trees obtained from</span>
<span class="gi">+# git-archive tarball (such as those provided by githubs download-from-tag</span>
<span class="gi">+# feature). Distribution tarballs (built by setup.py sdist) and build</span>
<span class="gi">+# directories (produced by setup.py build) will contain a much shorter file</span>
<span class="gi">+# that just contains the computed version number.</span>
<span class="gi">+</span>
<span class="gi">+# This file is released into the public domain.</span>
<span class="gi">+# Generated by versioneer-0.29</span>
<span class="gi">+# https://github.com/python-versioneer/python-versioneer</span>
<span class="gi">+</span>
<span class="w"> </span>&quot;&quot;&quot;Git implementation of _version.py.&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>import errno
<span class="w"> </span>import os
<span class="w"> </span>import re
<span class="gu">@@ -8,13 +19,22 @@ from typing import Any, Callable, Dict, List, Optional, Tuple</span>
<span class="w"> </span>import functools


<span class="gd">-def get_keywords() -&gt;Dict[str, str]:</span>
<span class="gi">+def get_keywords() -&gt; Dict[str, str]:</span>
<span class="w"> </span>    &quot;&quot;&quot;Get the keywords needed to look up the version information.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # these strings will be replaced by git during git-archive.</span>
<span class="gi">+    # setup.py/versioneer.py will grep for the variable names, so they must</span>
<span class="gi">+    # each be defined on a line of their own. _version.py will just call</span>
<span class="gi">+    # get_keywords().</span>
<span class="gi">+    git_refnames = &quot;$Format:%d$&quot;</span>
<span class="gi">+    git_full = &quot;$Format:%H$&quot;</span>
<span class="gi">+    git_date = &quot;$Format:%ci$&quot;</span>
<span class="gi">+    keywords = {&quot;refnames&quot;: git_refnames, &quot;full&quot;: git_full, &quot;date&quot;: git_date}</span>
<span class="gi">+    return keywords</span>


<span class="w"> </span>class VersioneerConfig:
<span class="w"> </span>    &quot;&quot;&quot;Container for Versioneer configuration parameters.&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>    VCS: str
<span class="w"> </span>    style: str
<span class="w"> </span>    tag_prefix: str
<span class="gu">@@ -23,9 +43,18 @@ class VersioneerConfig:</span>
<span class="w"> </span>    verbose: bool


<span class="gd">-def get_config() -&gt;VersioneerConfig:</span>
<span class="gi">+def get_config() -&gt; VersioneerConfig:</span>
<span class="w"> </span>    &quot;&quot;&quot;Create, populate and return the VersioneerConfig() object.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # these strings are filled in when &#39;setup.py versioneer&#39; creates</span>
<span class="gi">+    # _version.py</span>
<span class="gi">+    cfg = VersioneerConfig()</span>
<span class="gi">+    cfg.VCS = &quot;git&quot;</span>
<span class="gi">+    cfg.style = &quot;pep440&quot;</span>
<span class="gi">+    cfg.tag_prefix = &quot;v&quot;</span>
<span class="gi">+    cfg.parentdir_prefix = &quot;geopandas-&quot;</span>
<span class="gi">+    cfg.versionfile_source = &quot;geopandas/_version.py&quot;</span>
<span class="gi">+    cfg.verbose = False</span>
<span class="gi">+    return cfg</span>


<span class="w"> </span>class NotThisMethod(Exception):
<span class="gu">@@ -36,60 +65,359 @@ LONG_VERSION_PY: Dict[str, str] = {}</span>
<span class="w"> </span>HANDLERS: Dict[str, Dict[str, Callable]] = {}


<span class="gd">-def register_vcs_handler(vcs: str, method: str) -&gt;Callable:</span>
<span class="gi">+def register_vcs_handler(vcs: str, method: str) -&gt; Callable:  # decorator</span>
<span class="w"> </span>    &quot;&quot;&quot;Create decorator to mark a method as the handler of a VCS.&quot;&quot;&quot;
<span class="gd">-    pass</span>

<span class="gi">+    def decorate(f: Callable) -&gt; Callable:</span>
<span class="gi">+        &quot;&quot;&quot;Store f in HANDLERS[vcs][method].&quot;&quot;&quot;</span>
<span class="gi">+        if vcs not in HANDLERS:</span>
<span class="gi">+            HANDLERS[vcs] = {}</span>
<span class="gi">+        HANDLERS[vcs][method] = f</span>
<span class="gi">+        return f</span>

<span class="gd">-def run_command(commands: List[str], args: List[str], cwd: Optional[str]=</span>
<span class="gd">-    None, verbose: bool=False, hide_stderr: bool=False, env: Optional[Dict[</span>
<span class="gd">-    str, str]]=None) -&gt;Tuple[Optional[str], Optional[int]]:</span>
<span class="gd">-    &quot;&quot;&quot;Call the given command(s).&quot;&quot;&quot;</span>
<span class="gd">-    pass</span>
<span class="gi">+    return decorate</span>


<span class="gd">-def versions_from_parentdir(parentdir_prefix: str, root: str, verbose: bool</span>
<span class="gd">-    ) -&gt;Dict[str, Any]:</span>
<span class="gi">+def run_command(</span>
<span class="gi">+    commands: List[str],</span>
<span class="gi">+    args: List[str],</span>
<span class="gi">+    cwd: Optional[str] = None,</span>
<span class="gi">+    verbose: bool = False,</span>
<span class="gi">+    hide_stderr: bool = False,</span>
<span class="gi">+    env: Optional[Dict[str, str]] = None,</span>
<span class="gi">+) -&gt; Tuple[Optional[str], Optional[int]]:</span>
<span class="gi">+    &quot;&quot;&quot;Call the given command(s).&quot;&quot;&quot;</span>
<span class="gi">+    assert isinstance(commands, list)</span>
<span class="gi">+    process = None</span>
<span class="gi">+</span>
<span class="gi">+    popen_kwargs: Dict[str, Any] = {}</span>
<span class="gi">+    if sys.platform == &quot;win32&quot;:</span>
<span class="gi">+        # This hides the console window if pythonw.exe is used</span>
<span class="gi">+        startupinfo = subprocess.STARTUPINFO()</span>
<span class="gi">+        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW</span>
<span class="gi">+        popen_kwargs[&quot;startupinfo&quot;] = startupinfo</span>
<span class="gi">+</span>
<span class="gi">+    for command in commands:</span>
<span class="gi">+        try:</span>
<span class="gi">+            dispcmd = str([command] + args)</span>
<span class="gi">+            # remember shell=False, so use git.cmd on windows, not just git</span>
<span class="gi">+            process = subprocess.Popen(</span>
<span class="gi">+                [command] + args,</span>
<span class="gi">+                cwd=cwd,</span>
<span class="gi">+                env=env,</span>
<span class="gi">+                stdout=subprocess.PIPE,</span>
<span class="gi">+                stderr=(subprocess.PIPE if hide_stderr else None),</span>
<span class="gi">+                **popen_kwargs,</span>
<span class="gi">+            )</span>
<span class="gi">+            break</span>
<span class="gi">+        except OSError as e:</span>
<span class="gi">+            if e.errno == errno.ENOENT:</span>
<span class="gi">+                continue</span>
<span class="gi">+            if verbose:</span>
<span class="gi">+                print(&quot;unable to run %s&quot; % dispcmd)</span>
<span class="gi">+                print(e)</span>
<span class="gi">+            return None, None</span>
<span class="gi">+    else:</span>
<span class="gi">+        if verbose:</span>
<span class="gi">+            print(&quot;unable to find command, tried %s&quot; % (commands,))</span>
<span class="gi">+        return None, None</span>
<span class="gi">+    stdout = process.communicate()[0].strip().decode()</span>
<span class="gi">+    if process.returncode != 0:</span>
<span class="gi">+        if verbose:</span>
<span class="gi">+            print(&quot;unable to run %s (error)&quot; % dispcmd)</span>
<span class="gi">+            print(&quot;stdout was %s&quot; % stdout)</span>
<span class="gi">+        return None, process.returncode</span>
<span class="gi">+    return stdout, process.returncode</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def versions_from_parentdir(</span>
<span class="gi">+    parentdir_prefix: str,</span>
<span class="gi">+    root: str,</span>
<span class="gi">+    verbose: bool,</span>
<span class="gi">+) -&gt; Dict[str, Any]:</span>
<span class="w"> </span>    &quot;&quot;&quot;Try to determine the version from the parent directory name.

<span class="w"> </span>    Source tarballs conventionally unpack into a directory that includes both
<span class="w"> </span>    the project name and a version string. We will also support searching up
<span class="w"> </span>    two directory levels for an appropriately named parent directory
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-@register_vcs_handler(&#39;git&#39;, &#39;get_keywords&#39;)</span>
<span class="gd">-def git_get_keywords(versionfile_abs: str) -&gt;Dict[str, str]:</span>
<span class="gi">+    rootdirs = []</span>
<span class="gi">+</span>
<span class="gi">+    for _ in range(3):</span>
<span class="gi">+        dirname = os.path.basename(root)</span>
<span class="gi">+        if dirname.startswith(parentdir_prefix):</span>
<span class="gi">+            return {</span>
<span class="gi">+                &quot;version&quot;: dirname[len(parentdir_prefix) :],</span>
<span class="gi">+                &quot;full-revisionid&quot;: None,</span>
<span class="gi">+                &quot;dirty&quot;: False,</span>
<span class="gi">+                &quot;error&quot;: None,</span>
<span class="gi">+                &quot;date&quot;: None,</span>
<span class="gi">+            }</span>
<span class="gi">+        rootdirs.append(root)</span>
<span class="gi">+        root = os.path.dirname(root)  # up a level</span>
<span class="gi">+</span>
<span class="gi">+    if verbose:</span>
<span class="gi">+        print(</span>
<span class="gi">+            &quot;Tried directories %s but none started with prefix %s&quot;</span>
<span class="gi">+            % (str(rootdirs), parentdir_prefix)</span>
<span class="gi">+        )</span>
<span class="gi">+    raise NotThisMethod(&quot;rootdir doesn&#39;t start with parentdir_prefix&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@register_vcs_handler(&quot;git&quot;, &quot;get_keywords&quot;)</span>
<span class="gi">+def git_get_keywords(versionfile_abs: str) -&gt; Dict[str, str]:</span>
<span class="w"> </span>    &quot;&quot;&quot;Extract version information from the given file.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-@register_vcs_handler(&#39;git&#39;, &#39;keywords&#39;)</span>
<span class="gd">-def git_versions_from_keywords(keywords: Dict[str, str], tag_prefix: str,</span>
<span class="gd">-    verbose: bool) -&gt;Dict[str, Any]:</span>
<span class="gi">+    # the code embedded in _version.py can just fetch the value of these</span>
<span class="gi">+    # keywords. When used from setup.py, we don&#39;t want to import _version.py,</span>
<span class="gi">+    # so we do it with a regexp instead. This function is not used from</span>
<span class="gi">+    # _version.py.</span>
<span class="gi">+    keywords: Dict[str, str] = {}</span>
<span class="gi">+    try:</span>
<span class="gi">+        with open(versionfile_abs, &quot;r&quot;) as fobj:</span>
<span class="gi">+            for line in fobj:</span>
<span class="gi">+                if line.strip().startswith(&quot;git_refnames =&quot;):</span>
<span class="gi">+                    mo = re.search(r&#39;=\s*&quot;(.*)&quot;&#39;, line)</span>
<span class="gi">+                    if mo:</span>
<span class="gi">+                        keywords[&quot;refnames&quot;] = mo.group(1)</span>
<span class="gi">+                if line.strip().startswith(&quot;git_full =&quot;):</span>
<span class="gi">+                    mo = re.search(r&#39;=\s*&quot;(.*)&quot;&#39;, line)</span>
<span class="gi">+                    if mo:</span>
<span class="gi">+                        keywords[&quot;full&quot;] = mo.group(1)</span>
<span class="gi">+                if line.strip().startswith(&quot;git_date =&quot;):</span>
<span class="gi">+                    mo = re.search(r&#39;=\s*&quot;(.*)&quot;&#39;, line)</span>
<span class="gi">+                    if mo:</span>
<span class="gi">+                        keywords[&quot;date&quot;] = mo.group(1)</span>
<span class="gi">+    except OSError:</span>
<span class="gi">+        pass</span>
<span class="gi">+    return keywords</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@register_vcs_handler(&quot;git&quot;, &quot;keywords&quot;)</span>
<span class="gi">+def git_versions_from_keywords(</span>
<span class="gi">+    keywords: Dict[str, str],</span>
<span class="gi">+    tag_prefix: str,</span>
<span class="gi">+    verbose: bool,</span>
<span class="gi">+) -&gt; Dict[str, Any]:</span>
<span class="w"> </span>    &quot;&quot;&quot;Get version information from git keywords.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-@register_vcs_handler(&#39;git&#39;, &#39;pieces_from_vcs&#39;)</span>
<span class="gd">-def git_pieces_from_vcs(tag_prefix: str, root: str, verbose: bool, runner:</span>
<span class="gd">-    Callable=run_command) -&gt;Dict[str, Any]:</span>
<span class="gi">+    if &quot;refnames&quot; not in keywords:</span>
<span class="gi">+        raise NotThisMethod(&quot;Short version file found&quot;)</span>
<span class="gi">+    date = keywords.get(&quot;date&quot;)</span>
<span class="gi">+    if date is not None:</span>
<span class="gi">+        # Use only the last line.  Previous lines may contain GPG signature</span>
<span class="gi">+        # information.</span>
<span class="gi">+        date = date.splitlines()[-1]</span>
<span class="gi">+</span>
<span class="gi">+        # git-2.2.0 added &quot;%cI&quot;, which expands to an ISO-8601 -compliant</span>
<span class="gi">+        # datestamp. However we prefer &quot;%ci&quot; (which expands to an &quot;ISO-8601</span>
<span class="gi">+        # -like&quot; string, which we must then edit to make compliant), because</span>
<span class="gi">+        # it&#39;s been around since git-1.5.3, and it&#39;s too difficult to</span>
<span class="gi">+        # discover which version we&#39;re using, or to work around using an</span>
<span class="gi">+        # older one.</span>
<span class="gi">+        date = date.strip().replace(&quot; &quot;, &quot;T&quot;, 1).replace(&quot; &quot;, &quot;&quot;, 1)</span>
<span class="gi">+    refnames = keywords[&quot;refnames&quot;].strip()</span>
<span class="gi">+    if refnames.startswith(&quot;$Format&quot;):</span>
<span class="gi">+        if verbose:</span>
<span class="gi">+            print(&quot;keywords are unexpanded, not using&quot;)</span>
<span class="gi">+        raise NotThisMethod(&quot;unexpanded keywords, not a git-archive tarball&quot;)</span>
<span class="gi">+    refs = {r.strip() for r in refnames.strip(&quot;()&quot;).split(&quot;,&quot;)}</span>
<span class="gi">+    # starting in git-1.8.3, tags are listed as &quot;tag: foo-1.0&quot; instead of</span>
<span class="gi">+    # just &quot;foo-1.0&quot;. If we see a &quot;tag: &quot; prefix, prefer those.</span>
<span class="gi">+    TAG = &quot;tag: &quot;</span>
<span class="gi">+    tags = {r[len(TAG) :] for r in refs if r.startswith(TAG)}</span>
<span class="gi">+    if not tags:</span>
<span class="gi">+        # Either we&#39;re using git &lt; 1.8.3, or there really are no tags. We use</span>
<span class="gi">+        # a heuristic: assume all version tags have a digit. The old git %d</span>
<span class="gi">+        # expansion behaves like git log --decorate=short and strips out the</span>
<span class="gi">+        # refs/heads/ and refs/tags/ prefixes that would let us distinguish</span>
<span class="gi">+        # between branches and tags. By ignoring refnames without digits, we</span>
<span class="gi">+        # filter out many common branch names like &quot;release&quot; and</span>
<span class="gi">+        # &quot;stabilization&quot;, as well as &quot;HEAD&quot; and &quot;master&quot;.</span>
<span class="gi">+        tags = {r for r in refs if re.search(r&quot;\d&quot;, r)}</span>
<span class="gi">+        if verbose:</span>
<span class="gi">+            print(&quot;discarding &#39;%s&#39;, no digits&quot; % &quot;,&quot;.join(refs - tags))</span>
<span class="gi">+    if verbose:</span>
<span class="gi">+        print(&quot;likely tags: %s&quot; % &quot;,&quot;.join(sorted(tags)))</span>
<span class="gi">+    for ref in sorted(tags):</span>
<span class="gi">+        # sorting will prefer e.g. &quot;2.0&quot; over &quot;2.0rc1&quot;</span>
<span class="gi">+        if ref.startswith(tag_prefix):</span>
<span class="gi">+            r = ref[len(tag_prefix) :]</span>
<span class="gi">+            # Filter out refs that exactly match prefix or that don&#39;t start</span>
<span class="gi">+            # with a number once the prefix is stripped (mostly a concern</span>
<span class="gi">+            # when prefix is &#39;&#39;)</span>
<span class="gi">+            if not re.match(r&quot;\d&quot;, r):</span>
<span class="gi">+                continue</span>
<span class="gi">+            if verbose:</span>
<span class="gi">+                print(&quot;picking %s&quot; % r)</span>
<span class="gi">+            return {</span>
<span class="gi">+                &quot;version&quot;: r,</span>
<span class="gi">+                &quot;full-revisionid&quot;: keywords[&quot;full&quot;].strip(),</span>
<span class="gi">+                &quot;dirty&quot;: False,</span>
<span class="gi">+                &quot;error&quot;: None,</span>
<span class="gi">+                &quot;date&quot;: date,</span>
<span class="gi">+            }</span>
<span class="gi">+    # no suitable tags, so version is &quot;0+unknown&quot;, but full hex is still there</span>
<span class="gi">+    if verbose:</span>
<span class="gi">+        print(&quot;no suitable tags, using unknown + full revision id&quot;)</span>
<span class="gi">+    return {</span>
<span class="gi">+        &quot;version&quot;: &quot;0+unknown&quot;,</span>
<span class="gi">+        &quot;full-revisionid&quot;: keywords[&quot;full&quot;].strip(),</span>
<span class="gi">+        &quot;dirty&quot;: False,</span>
<span class="gi">+        &quot;error&quot;: &quot;no suitable tags&quot;,</span>
<span class="gi">+        &quot;date&quot;: None,</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@register_vcs_handler(&quot;git&quot;, &quot;pieces_from_vcs&quot;)</span>
<span class="gi">+def git_pieces_from_vcs(</span>
<span class="gi">+    tag_prefix: str, root: str, verbose: bool, runner: Callable = run_command</span>
<span class="gi">+) -&gt; Dict[str, Any]:</span>
<span class="w"> </span>    &quot;&quot;&quot;Get version from &#39;git describe&#39; in the root of the source tree.

<span class="w"> </span>    This only gets called if the git-archive &#39;subst&#39; keywords were *not*
<span class="w"> </span>    expanded, and _version.py hasn&#39;t already been rewritten with a short
<span class="w"> </span>    version string, meaning we&#39;re inside a checked out source tree.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def plus_or_dot(pieces: Dict[str, Any]) -&gt;str:</span>
<span class="gi">+    GITS = [&quot;git&quot;]</span>
<span class="gi">+    if sys.platform == &quot;win32&quot;:</span>
<span class="gi">+        GITS = [&quot;git.cmd&quot;, &quot;git.exe&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    # GIT_DIR can interfere with correct operation of Versioneer.</span>
<span class="gi">+    # It may be intended to be passed to the Versioneer-versioned project,</span>
<span class="gi">+    # but that should not change where we get our version from.</span>
<span class="gi">+    env = os.environ.copy()</span>
<span class="gi">+    env.pop(&quot;GIT_DIR&quot;, None)</span>
<span class="gi">+    runner = functools.partial(runner, env=env)</span>
<span class="gi">+</span>
<span class="gi">+    _, rc = runner(GITS, [&quot;rev-parse&quot;, &quot;--git-dir&quot;], cwd=root, hide_stderr=not verbose)</span>
<span class="gi">+    if rc != 0:</span>
<span class="gi">+        if verbose:</span>
<span class="gi">+            print(&quot;Directory %s not under git control&quot; % root)</span>
<span class="gi">+        raise NotThisMethod(&quot;&#39;git rev-parse --git-dir&#39; returned error&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]</span>
<span class="gi">+    # if there isn&#39;t one, this yields HEX[-dirty] (no NUM)</span>
<span class="gi">+    describe_out, rc = runner(</span>
<span class="gi">+        GITS,</span>
<span class="gi">+        [</span>
<span class="gi">+            &quot;describe&quot;,</span>
<span class="gi">+            &quot;--tags&quot;,</span>
<span class="gi">+            &quot;--dirty&quot;,</span>
<span class="gi">+            &quot;--always&quot;,</span>
<span class="gi">+            &quot;--long&quot;,</span>
<span class="gi">+            &quot;--match&quot;,</span>
<span class="gi">+            f&quot;{tag_prefix}[[:digit:]]*&quot;,</span>
<span class="gi">+        ],</span>
<span class="gi">+        cwd=root,</span>
<span class="gi">+    )</span>
<span class="gi">+    # --long was added in git-1.5.5</span>
<span class="gi">+    if describe_out is None:</span>
<span class="gi">+        raise NotThisMethod(&quot;&#39;git describe&#39; failed&quot;)</span>
<span class="gi">+    describe_out = describe_out.strip()</span>
<span class="gi">+    full_out, rc = runner(GITS, [&quot;rev-parse&quot;, &quot;HEAD&quot;], cwd=root)</span>
<span class="gi">+    if full_out is None:</span>
<span class="gi">+        raise NotThisMethod(&quot;&#39;git rev-parse&#39; failed&quot;)</span>
<span class="gi">+    full_out = full_out.strip()</span>
<span class="gi">+</span>
<span class="gi">+    pieces: Dict[str, Any] = {}</span>
<span class="gi">+    pieces[&quot;long&quot;] = full_out</span>
<span class="gi">+    pieces[&quot;short&quot;] = full_out[:7]  # maybe improved later</span>
<span class="gi">+    pieces[&quot;error&quot;] = None</span>
<span class="gi">+</span>
<span class="gi">+    branch_name, rc = runner(GITS, [&quot;rev-parse&quot;, &quot;--abbrev-ref&quot;, &quot;HEAD&quot;], cwd=root)</span>
<span class="gi">+    # --abbrev-ref was added in git-1.6.3</span>
<span class="gi">+    if rc != 0 or branch_name is None:</span>
<span class="gi">+        raise NotThisMethod(&quot;&#39;git rev-parse --abbrev-ref&#39; returned error&quot;)</span>
<span class="gi">+    branch_name = branch_name.strip()</span>
<span class="gi">+</span>
<span class="gi">+    if branch_name == &quot;HEAD&quot;:</span>
<span class="gi">+        # If we aren&#39;t exactly on a branch, pick a branch which represents</span>
<span class="gi">+        # the current commit. If all else fails, we are on a branchless</span>
<span class="gi">+        # commit.</span>
<span class="gi">+        branches, rc = runner(GITS, [&quot;branch&quot;, &quot;--contains&quot;], cwd=root)</span>
<span class="gi">+        # --contains was added in git-1.5.4</span>
<span class="gi">+        if rc != 0 or branches is None:</span>
<span class="gi">+            raise NotThisMethod(&quot;&#39;git branch --contains&#39; returned error&quot;)</span>
<span class="gi">+        branches = branches.split(&quot;\n&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        # Remove the first line if we&#39;re running detached</span>
<span class="gi">+        if &quot;(&quot; in branches[0]:</span>
<span class="gi">+            branches.pop(0)</span>
<span class="gi">+</span>
<span class="gi">+        # Strip off the leading &quot;* &quot; from the list of branches.</span>
<span class="gi">+        branches = [branch[2:] for branch in branches]</span>
<span class="gi">+        if &quot;master&quot; in branches:</span>
<span class="gi">+            branch_name = &quot;master&quot;</span>
<span class="gi">+        elif not branches:</span>
<span class="gi">+            branch_name = None</span>
<span class="gi">+        else:</span>
<span class="gi">+            # Pick the first branch that is returned. Good or bad.</span>
<span class="gi">+            branch_name = branches[0]</span>
<span class="gi">+</span>
<span class="gi">+    pieces[&quot;branch&quot;] = branch_name</span>
<span class="gi">+</span>
<span class="gi">+    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]</span>
<span class="gi">+    # TAG might have hyphens.</span>
<span class="gi">+    git_describe = describe_out</span>
<span class="gi">+</span>
<span class="gi">+    # look for -dirty suffix</span>
<span class="gi">+    dirty = git_describe.endswith(&quot;-dirty&quot;)</span>
<span class="gi">+    pieces[&quot;dirty&quot;] = dirty</span>
<span class="gi">+    if dirty:</span>
<span class="gi">+        git_describe = git_describe[: git_describe.rindex(&quot;-dirty&quot;)]</span>
<span class="gi">+</span>
<span class="gi">+    # now we have TAG-NUM-gHEX or HEX</span>
<span class="gi">+</span>
<span class="gi">+    if &quot;-&quot; in git_describe:</span>
<span class="gi">+        # TAG-NUM-gHEX</span>
<span class="gi">+        mo = re.search(r&quot;^(.+)-(\d+)-g([0-9a-f]+)$&quot;, git_describe)</span>
<span class="gi">+        if not mo:</span>
<span class="gi">+            # unparsable. Maybe git-describe is misbehaving?</span>
<span class="gi">+            pieces[&quot;error&quot;] = &quot;unable to parse git-describe output: &#39;%s&#39;&quot; % describe_out</span>
<span class="gi">+            return pieces</span>
<span class="gi">+</span>
<span class="gi">+        # tag</span>
<span class="gi">+        full_tag = mo.group(1)</span>
<span class="gi">+        if not full_tag.startswith(tag_prefix):</span>
<span class="gi">+            if verbose:</span>
<span class="gi">+                fmt = &quot;tag &#39;%s&#39; doesn&#39;t start with prefix &#39;%s&#39;&quot;</span>
<span class="gi">+                print(fmt % (full_tag, tag_prefix))</span>
<span class="gi">+            pieces[&quot;error&quot;] = &quot;tag &#39;%s&#39; doesn&#39;t start with prefix &#39;%s&#39;&quot; % (</span>
<span class="gi">+                full_tag,</span>
<span class="gi">+                tag_prefix,</span>
<span class="gi">+            )</span>
<span class="gi">+            return pieces</span>
<span class="gi">+        pieces[&quot;closest-tag&quot;] = full_tag[len(tag_prefix) :]</span>
<span class="gi">+</span>
<span class="gi">+        # distance: number of commits since tag</span>
<span class="gi">+        pieces[&quot;distance&quot;] = int(mo.group(2))</span>
<span class="gi">+</span>
<span class="gi">+        # commit: short hex revision ID</span>
<span class="gi">+        pieces[&quot;short&quot;] = mo.group(3)</span>
<span class="gi">+</span>
<span class="gi">+    else:</span>
<span class="gi">+        # HEX: no tags</span>
<span class="gi">+        pieces[&quot;closest-tag&quot;] = None</span>
<span class="gi">+        out, rc = runner(GITS, [&quot;rev-list&quot;, &quot;HEAD&quot;, &quot;--left-right&quot;], cwd=root)</span>
<span class="gi">+        pieces[&quot;distance&quot;] = len(out.split())  # total number of commits</span>
<span class="gi">+</span>
<span class="gi">+    # commit date: see ISO-8601 comment in git_versions_from_keywords()</span>
<span class="gi">+    date = runner(GITS, [&quot;show&quot;, &quot;-s&quot;, &quot;--format=%ci&quot;, &quot;HEAD&quot;], cwd=root)[0].strip()</span>
<span class="gi">+    # Use only the last line.  Previous lines may contain GPG signature</span>
<span class="gi">+    # information.</span>
<span class="gi">+    date = date.splitlines()[-1]</span>
<span class="gi">+    pieces[&quot;date&quot;] = date.strip().replace(&quot; &quot;, &quot;T&quot;, 1).replace(&quot; &quot;, &quot;&quot;, 1)</span>
<span class="gi">+</span>
<span class="gi">+    return pieces</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def plus_or_dot(pieces: Dict[str, Any]) -&gt; str:</span>
<span class="w"> </span>    &quot;&quot;&quot;Return a + if we don&#39;t already have one, else return a .&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if &quot;+&quot; in pieces.get(&quot;closest-tag&quot;, &quot;&quot;):</span>
<span class="gi">+        return &quot;.&quot;</span>
<span class="gi">+    return &quot;+&quot;</span>


<span class="gd">-def render_pep440(pieces: Dict[str, Any]) -&gt;str:</span>
<span class="gi">+def render_pep440(pieces: Dict[str, Any]) -&gt; str:</span>
<span class="w"> </span>    &quot;&quot;&quot;Build up version string, with post-release &quot;local version identifier&quot;.

<span class="w"> </span>    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you
<span class="gu">@@ -98,10 +426,22 @@ def render_pep440(pieces: Dict[str, Any]) -&gt;str:</span>
<span class="w"> </span>    Exceptions:
<span class="w"> </span>    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def render_pep440_branch(pieces: Dict[str, Any]) -&gt;str:</span>
<span class="gi">+    if pieces[&quot;closest-tag&quot;]:</span>
<span class="gi">+        rendered = pieces[&quot;closest-tag&quot;]</span>
<span class="gi">+        if pieces[&quot;distance&quot;] or pieces[&quot;dirty&quot;]:</span>
<span class="gi">+            rendered += plus_or_dot(pieces)</span>
<span class="gi">+            rendered += &quot;%d.g%s&quot; % (pieces[&quot;distance&quot;], pieces[&quot;short&quot;])</span>
<span class="gi">+            if pieces[&quot;dirty&quot;]:</span>
<span class="gi">+                rendered += &quot;.dirty&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        # exception #1</span>
<span class="gi">+        rendered = &quot;0+untagged.%d.g%s&quot; % (pieces[&quot;distance&quot;], pieces[&quot;short&quot;])</span>
<span class="gi">+        if pieces[&quot;dirty&quot;]:</span>
<span class="gi">+            rendered += &quot;.dirty&quot;</span>
<span class="gi">+    return rendered</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def render_pep440_branch(pieces: Dict[str, Any]) -&gt; str:</span>
<span class="w"> </span>    &quot;&quot;&quot;TAG[[.dev0]+DISTANCE.gHEX[.dirty]] .

<span class="w"> </span>    The &quot;.dev0&quot; means not master branch. Note that .dev0 sorts backwards
<span class="gu">@@ -110,28 +450,61 @@ def render_pep440_branch(pieces: Dict[str, Any]) -&gt;str:</span>
<span class="w"> </span>    Exceptions:
<span class="w"> </span>    1: no tags. 0[.dev0]+untagged.DISTANCE.gHEX[.dirty]
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def pep440_split_post(ver: str) -&gt;Tuple[str, Optional[int]]:</span>
<span class="gi">+    if pieces[&quot;closest-tag&quot;]:</span>
<span class="gi">+        rendered = pieces[&quot;closest-tag&quot;]</span>
<span class="gi">+        if pieces[&quot;distance&quot;] or pieces[&quot;dirty&quot;]:</span>
<span class="gi">+            if pieces[&quot;branch&quot;] != &quot;master&quot;:</span>
<span class="gi">+                rendered += &quot;.dev0&quot;</span>
<span class="gi">+            rendered += plus_or_dot(pieces)</span>
<span class="gi">+            rendered += &quot;%d.g%s&quot; % (pieces[&quot;distance&quot;], pieces[&quot;short&quot;])</span>
<span class="gi">+            if pieces[&quot;dirty&quot;]:</span>
<span class="gi">+                rendered += &quot;.dirty&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        # exception #1</span>
<span class="gi">+        rendered = &quot;0&quot;</span>
<span class="gi">+        if pieces[&quot;branch&quot;] != &quot;master&quot;:</span>
<span class="gi">+            rendered += &quot;.dev0&quot;</span>
<span class="gi">+        rendered += &quot;+untagged.%d.g%s&quot; % (pieces[&quot;distance&quot;], pieces[&quot;short&quot;])</span>
<span class="gi">+        if pieces[&quot;dirty&quot;]:</span>
<span class="gi">+            rendered += &quot;.dirty&quot;</span>
<span class="gi">+    return rendered</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def pep440_split_post(ver: str) -&gt; Tuple[str, Optional[int]]:</span>
<span class="w"> </span>    &quot;&quot;&quot;Split pep440 version string at the post-release segment.

<span class="w"> </span>    Returns the release segments before the post-release and the
<span class="w"> </span>    post-release version number (or -1 if no post-release segment is present).
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    vc = str.split(ver, &quot;.post&quot;)</span>
<span class="gi">+    return vc[0], int(vc[1] or 0) if len(vc) == 2 else None</span>


<span class="gd">-def render_pep440_pre(pieces: Dict[str, Any]) -&gt;str:</span>
<span class="gi">+def render_pep440_pre(pieces: Dict[str, Any]) -&gt; str:</span>
<span class="w"> </span>    &quot;&quot;&quot;TAG[.postN.devDISTANCE] -- No -dirty.

<span class="w"> </span>    Exceptions:
<span class="w"> </span>    1: no tags. 0.post0.devDISTANCE
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def render_pep440_post(pieces: Dict[str, Any]) -&gt;str:</span>
<span class="gi">+    if pieces[&quot;closest-tag&quot;]:</span>
<span class="gi">+        if pieces[&quot;distance&quot;]:</span>
<span class="gi">+            # update the post release segment</span>
<span class="gi">+            tag_version, post_version = pep440_split_post(pieces[&quot;closest-tag&quot;])</span>
<span class="gi">+            rendered = tag_version</span>
<span class="gi">+            if post_version is not None:</span>
<span class="gi">+                rendered += &quot;.post%d.dev%d&quot; % (post_version + 1, pieces[&quot;distance&quot;])</span>
<span class="gi">+            else:</span>
<span class="gi">+                rendered += &quot;.post0.dev%d&quot; % (pieces[&quot;distance&quot;])</span>
<span class="gi">+        else:</span>
<span class="gi">+            # no commits, use the tag as the version</span>
<span class="gi">+            rendered = pieces[&quot;closest-tag&quot;]</span>
<span class="gi">+    else:</span>
<span class="gi">+        # exception #1</span>
<span class="gi">+        rendered = &quot;0.post0.dev%d&quot; % pieces[&quot;distance&quot;]</span>
<span class="gi">+    return rendered</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def render_pep440_post(pieces: Dict[str, Any]) -&gt; str:</span>
<span class="w"> </span>    &quot;&quot;&quot;TAG[.postDISTANCE[.dev0]+gHEX] .

<span class="w"> </span>    The &quot;.dev0&quot; means dirty. Note that .dev0 sorts backwards
<span class="gu">@@ -141,10 +514,24 @@ def render_pep440_post(pieces: Dict[str, Any]) -&gt;str:</span>
<span class="w"> </span>    Exceptions:
<span class="w"> </span>    1: no tags. 0.postDISTANCE[.dev0]
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def render_pep440_post_branch(pieces: Dict[str, Any]) -&gt;str:</span>
<span class="gi">+    if pieces[&quot;closest-tag&quot;]:</span>
<span class="gi">+        rendered = pieces[&quot;closest-tag&quot;]</span>
<span class="gi">+        if pieces[&quot;distance&quot;] or pieces[&quot;dirty&quot;]:</span>
<span class="gi">+            rendered += &quot;.post%d&quot; % pieces[&quot;distance&quot;]</span>
<span class="gi">+            if pieces[&quot;dirty&quot;]:</span>
<span class="gi">+                rendered += &quot;.dev0&quot;</span>
<span class="gi">+            rendered += plus_or_dot(pieces)</span>
<span class="gi">+            rendered += &quot;g%s&quot; % pieces[&quot;short&quot;]</span>
<span class="gi">+    else:</span>
<span class="gi">+        # exception #1</span>
<span class="gi">+        rendered = &quot;0.post%d&quot; % pieces[&quot;distance&quot;]</span>
<span class="gi">+        if pieces[&quot;dirty&quot;]:</span>
<span class="gi">+            rendered += &quot;.dev0&quot;</span>
<span class="gi">+        rendered += &quot;+g%s&quot; % pieces[&quot;short&quot;]</span>
<span class="gi">+    return rendered</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def render_pep440_post_branch(pieces: Dict[str, Any]) -&gt; str:</span>
<span class="w"> </span>    &quot;&quot;&quot;TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .

<span class="w"> </span>    The &quot;.dev0&quot; means not master branch.
<span class="gu">@@ -152,10 +539,28 @@ def render_pep440_post_branch(pieces: Dict[str, Any]) -&gt;str:</span>
<span class="w"> </span>    Exceptions:
<span class="w"> </span>    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def render_pep440_old(pieces: Dict[str, Any]) -&gt;str:</span>
<span class="gi">+    if pieces[&quot;closest-tag&quot;]:</span>
<span class="gi">+        rendered = pieces[&quot;closest-tag&quot;]</span>
<span class="gi">+        if pieces[&quot;distance&quot;] or pieces[&quot;dirty&quot;]:</span>
<span class="gi">+            rendered += &quot;.post%d&quot; % pieces[&quot;distance&quot;]</span>
<span class="gi">+            if pieces[&quot;branch&quot;] != &quot;master&quot;:</span>
<span class="gi">+                rendered += &quot;.dev0&quot;</span>
<span class="gi">+            rendered += plus_or_dot(pieces)</span>
<span class="gi">+            rendered += &quot;g%s&quot; % pieces[&quot;short&quot;]</span>
<span class="gi">+            if pieces[&quot;dirty&quot;]:</span>
<span class="gi">+                rendered += &quot;.dirty&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        # exception #1</span>
<span class="gi">+        rendered = &quot;0.post%d&quot; % pieces[&quot;distance&quot;]</span>
<span class="gi">+        if pieces[&quot;branch&quot;] != &quot;master&quot;:</span>
<span class="gi">+            rendered += &quot;.dev0&quot;</span>
<span class="gi">+        rendered += &quot;+g%s&quot; % pieces[&quot;short&quot;]</span>
<span class="gi">+        if pieces[&quot;dirty&quot;]:</span>
<span class="gi">+            rendered += &quot;.dirty&quot;</span>
<span class="gi">+    return rendered</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def render_pep440_old(pieces: Dict[str, Any]) -&gt; str:</span>
<span class="w"> </span>    &quot;&quot;&quot;TAG[.postDISTANCE[.dev0]] .

<span class="w"> </span>    The &quot;.dev0&quot; means dirty.
<span class="gu">@@ -163,10 +568,21 @@ def render_pep440_old(pieces: Dict[str, Any]) -&gt;str:</span>
<span class="w"> </span>    Exceptions:
<span class="w"> </span>    1: no tags. 0.postDISTANCE[.dev0]
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def render_git_describe(pieces: Dict[str, Any]) -&gt;str:</span>
<span class="gi">+    if pieces[&quot;closest-tag&quot;]:</span>
<span class="gi">+        rendered = pieces[&quot;closest-tag&quot;]</span>
<span class="gi">+        if pieces[&quot;distance&quot;] or pieces[&quot;dirty&quot;]:</span>
<span class="gi">+            rendered += &quot;.post%d&quot; % pieces[&quot;distance&quot;]</span>
<span class="gi">+            if pieces[&quot;dirty&quot;]:</span>
<span class="gi">+                rendered += &quot;.dev0&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        # exception #1</span>
<span class="gi">+        rendered = &quot;0.post%d&quot; % pieces[&quot;distance&quot;]</span>
<span class="gi">+        if pieces[&quot;dirty&quot;]:</span>
<span class="gi">+            rendered += &quot;.dev0&quot;</span>
<span class="gi">+    return rendered</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def render_git_describe(pieces: Dict[str, Any]) -&gt; str:</span>
<span class="w"> </span>    &quot;&quot;&quot;TAG[-DISTANCE-gHEX][-dirty].

<span class="w"> </span>    Like &#39;git describe --tags --dirty --always&#39;.
<span class="gu">@@ -174,10 +590,19 @@ def render_git_describe(pieces: Dict[str, Any]) -&gt;str:</span>
<span class="w"> </span>    Exceptions:
<span class="w"> </span>    1: no tags. HEX[-dirty]  (note: no &#39;g&#39; prefix)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def render_git_describe_long(pieces: Dict[str, Any]) -&gt;str:</span>
<span class="gi">+    if pieces[&quot;closest-tag&quot;]:</span>
<span class="gi">+        rendered = pieces[&quot;closest-tag&quot;]</span>
<span class="gi">+        if pieces[&quot;distance&quot;]:</span>
<span class="gi">+            rendered += &quot;-%d-g%s&quot; % (pieces[&quot;distance&quot;], pieces[&quot;short&quot;])</span>
<span class="gi">+    else:</span>
<span class="gi">+        # exception #1</span>
<span class="gi">+        rendered = pieces[&quot;short&quot;]</span>
<span class="gi">+    if pieces[&quot;dirty&quot;]:</span>
<span class="gi">+        rendered += &quot;-dirty&quot;</span>
<span class="gi">+    return rendered</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def render_git_describe_long(pieces: Dict[str, Any]) -&gt; str:</span>
<span class="w"> </span>    &quot;&quot;&quot;TAG-DISTANCE-gHEX[-dirty].

<span class="w"> </span>    Like &#39;git describe --tags --dirty --always -long&#39;.
<span class="gu">@@ -186,14 +611,106 @@ def render_git_describe_long(pieces: Dict[str, Any]) -&gt;str:</span>
<span class="w"> </span>    Exceptions:
<span class="w"> </span>    1: no tags. HEX[-dirty]  (note: no &#39;g&#39; prefix)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def render(pieces: Dict[str, Any], style: str) -&gt;Dict[str, Any]:</span>
<span class="gi">+    if pieces[&quot;closest-tag&quot;]:</span>
<span class="gi">+        rendered = pieces[&quot;closest-tag&quot;]</span>
<span class="gi">+        rendered += &quot;-%d-g%s&quot; % (pieces[&quot;distance&quot;], pieces[&quot;short&quot;])</span>
<span class="gi">+    else:</span>
<span class="gi">+        # exception #1</span>
<span class="gi">+        rendered = pieces[&quot;short&quot;]</span>
<span class="gi">+    if pieces[&quot;dirty&quot;]:</span>
<span class="gi">+        rendered += &quot;-dirty&quot;</span>
<span class="gi">+    return rendered</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def render(pieces: Dict[str, Any], style: str) -&gt; Dict[str, Any]:</span>
<span class="w"> </span>    &quot;&quot;&quot;Render the given version pieces into the requested style.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def get_versions() -&gt;Dict[str, Any]:</span>
<span class="gi">+    if pieces[&quot;error&quot;]:</span>
<span class="gi">+        return {</span>
<span class="gi">+            &quot;version&quot;: &quot;unknown&quot;,</span>
<span class="gi">+            &quot;full-revisionid&quot;: pieces.get(&quot;long&quot;),</span>
<span class="gi">+            &quot;dirty&quot;: None,</span>
<span class="gi">+            &quot;error&quot;: pieces[&quot;error&quot;],</span>
<span class="gi">+            &quot;date&quot;: None,</span>
<span class="gi">+        }</span>
<span class="gi">+</span>
<span class="gi">+    if not style or style == &quot;default&quot;:</span>
<span class="gi">+        style = &quot;pep440&quot;  # the default</span>
<span class="gi">+</span>
<span class="gi">+    if style == &quot;pep440&quot;:</span>
<span class="gi">+        rendered = render_pep440(pieces)</span>
<span class="gi">+    elif style == &quot;pep440-branch&quot;:</span>
<span class="gi">+        rendered = render_pep440_branch(pieces)</span>
<span class="gi">+    elif style == &quot;pep440-pre&quot;:</span>
<span class="gi">+        rendered = render_pep440_pre(pieces)</span>
<span class="gi">+    elif style == &quot;pep440-post&quot;:</span>
<span class="gi">+        rendered = render_pep440_post(pieces)</span>
<span class="gi">+    elif style == &quot;pep440-post-branch&quot;:</span>
<span class="gi">+        rendered = render_pep440_post_branch(pieces)</span>
<span class="gi">+    elif style == &quot;pep440-old&quot;:</span>
<span class="gi">+        rendered = render_pep440_old(pieces)</span>
<span class="gi">+    elif style == &quot;git-describe&quot;:</span>
<span class="gi">+        rendered = render_git_describe(pieces)</span>
<span class="gi">+    elif style == &quot;git-describe-long&quot;:</span>
<span class="gi">+        rendered = render_git_describe_long(pieces)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(&quot;unknown style &#39;%s&#39;&quot; % style)</span>
<span class="gi">+</span>
<span class="gi">+    return {</span>
<span class="gi">+        &quot;version&quot;: rendered,</span>
<span class="gi">+        &quot;full-revisionid&quot;: pieces[&quot;long&quot;],</span>
<span class="gi">+        &quot;dirty&quot;: pieces[&quot;dirty&quot;],</span>
<span class="gi">+        &quot;error&quot;: None,</span>
<span class="gi">+        &quot;date&quot;: pieces.get(&quot;date&quot;),</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def get_versions() -&gt; Dict[str, Any]:</span>
<span class="w"> </span>    &quot;&quot;&quot;Get version information or return default if unable to do so.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have</span>
<span class="gi">+    # __file__, we can work backwards from there to the root. Some</span>
<span class="gi">+    # py2exe/bbfreeze/non-CPython implementations don&#39;t do __file__, in which</span>
<span class="gi">+    # case we can only use expanded keywords.</span>
<span class="gi">+</span>
<span class="gi">+    cfg = get_config()</span>
<span class="gi">+    verbose = cfg.verbose</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix, verbose)</span>
<span class="gi">+    except NotThisMethod:</span>
<span class="gi">+        pass</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        root = os.path.realpath(__file__)</span>
<span class="gi">+        # versionfile_source is the relative path from the top of the source</span>
<span class="gi">+        # tree (where the .git directory might live) to this file. Invert</span>
<span class="gi">+        # this to find the root from __file__.</span>
<span class="gi">+        for _ in cfg.versionfile_source.split(&quot;/&quot;):</span>
<span class="gi">+            root = os.path.dirname(root)</span>
<span class="gi">+    except NameError:</span>
<span class="gi">+        return {</span>
<span class="gi">+            &quot;version&quot;: &quot;0+unknown&quot;,</span>
<span class="gi">+            &quot;full-revisionid&quot;: None,</span>
<span class="gi">+            &quot;dirty&quot;: None,</span>
<span class="gi">+            &quot;error&quot;: &quot;unable to find root of source tree&quot;,</span>
<span class="gi">+            &quot;date&quot;: None,</span>
<span class="gi">+        }</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)</span>
<span class="gi">+        return render(pieces, cfg.style)</span>
<span class="gi">+    except NotThisMethod:</span>
<span class="gi">+        pass</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        if cfg.parentdir_prefix:</span>
<span class="gi">+            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)</span>
<span class="gi">+    except NotThisMethod:</span>
<span class="gi">+        pass</span>
<span class="gi">+</span>
<span class="gi">+    return {</span>
<span class="gi">+        &quot;version&quot;: &quot;0+unknown&quot;,</span>
<span class="gi">+        &quot;full-revisionid&quot;: None,</span>
<span class="gi">+        &quot;dirty&quot;: None,</span>
<span class="gi">+        &quot;error&quot;: &quot;unable to compute version&quot;,</span>
<span class="gi">+        &quot;date&quot;: None,</span>
<span class="gi">+    }</span>
<span class="gh">diff --git a/geopandas/array.py b/geopandas/array.py</span>
<span class="gh">index 3f1cc54a..32f338a7 100644</span>
<span class="gd">--- a/geopandas/array.py</span>
<span class="gi">+++ b/geopandas/array.py</span>
<span class="gu">@@ -3,24 +3,44 @@ import numbers</span>
<span class="w"> </span>import operator
<span class="w"> </span>import warnings
<span class="w"> </span>from functools import lru_cache
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>import pandas as pd
<span class="gd">-from pandas.api.extensions import ExtensionArray, ExtensionDtype, register_extension_dtype</span>
<span class="gi">+from pandas.api.extensions import (</span>
<span class="gi">+    ExtensionArray,</span>
<span class="gi">+    ExtensionDtype,</span>
<span class="gi">+    register_extension_dtype,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="w"> </span>import shapely
<span class="w"> </span>import shapely.affinity
<span class="w"> </span>import shapely.geometry
<span class="w"> </span>import shapely.ops
<span class="w"> </span>import shapely.wkt
<span class="w"> </span>from shapely.geometry.base import BaseGeometry
<span class="gi">+</span>
<span class="w"> </span>from ._compat import HAS_PYPROJ, requires_pyproj
<span class="w"> </span>from .sindex import SpatialIndex
<span class="gi">+</span>
<span class="w"> </span>if HAS_PYPROJ:
<span class="w"> </span>    from pyproj import Transformer
<span class="gi">+</span>
<span class="w"> </span>    TransformerFromCRS = lru_cache(Transformer.from_crs)
<span class="gd">-_names = {&#39;MISSING&#39;: None, &#39;NAG&#39;: None, &#39;POINT&#39;: &#39;Point&#39;, &#39;LINESTRING&#39;:</span>
<span class="gd">-    &#39;LineString&#39;, &#39;LINEARRING&#39;: &#39;LinearRing&#39;, &#39;POLYGON&#39;: &#39;Polygon&#39;,</span>
<span class="gd">-    &#39;MULTIPOINT&#39;: &#39;MultiPoint&#39;, &#39;MULTILINESTRING&#39;: &#39;MultiLineString&#39;,</span>
<span class="gd">-    &#39;MULTIPOLYGON&#39;: &#39;MultiPolygon&#39;, &#39;GEOMETRYCOLLECTION&#39;: &#39;GeometryCollection&#39;}</span>
<span class="gi">+</span>
<span class="gi">+_names = {</span>
<span class="gi">+    &quot;MISSING&quot;: None,</span>
<span class="gi">+    &quot;NAG&quot;: None,</span>
<span class="gi">+    &quot;POINT&quot;: &quot;Point&quot;,</span>
<span class="gi">+    &quot;LINESTRING&quot;: &quot;LineString&quot;,</span>
<span class="gi">+    &quot;LINEARRING&quot;: &quot;LinearRing&quot;,</span>
<span class="gi">+    &quot;POLYGON&quot;: &quot;Polygon&quot;,</span>
<span class="gi">+    &quot;MULTIPOINT&quot;: &quot;MultiPoint&quot;,</span>
<span class="gi">+    &quot;MULTILINESTRING&quot;: &quot;MultiLineString&quot;,</span>
<span class="gi">+    &quot;MULTIPOLYGON&quot;: &quot;MultiPolygon&quot;,</span>
<span class="gi">+    &quot;GEOMETRYCOLLECTION&quot;: &quot;GeometryCollection&quot;,</span>
<span class="gi">+}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>type_mapping = {p.value: _names[p.name] for p in shapely.GeometryType}
<span class="w"> </span>geometry_type_ids = list(type_mapping.keys())
<span class="w"> </span>geometry_type_values = np.array(list(type_mapping.values()), dtype=object)
<span class="gu">@@ -28,9 +48,26 @@ geometry_type_values = np.array(list(type_mapping.values()), dtype=object)</span>

<span class="w"> </span>class GeometryDtype(ExtensionDtype):
<span class="w"> </span>    type = BaseGeometry
<span class="gd">-    name = &#39;geometry&#39;</span>
<span class="gi">+    name = &quot;geometry&quot;</span>
<span class="w"> </span>    na_value = np.nan

<span class="gi">+    @classmethod</span>
<span class="gi">+    def construct_from_string(cls, string):</span>
<span class="gi">+        if not isinstance(string, str):</span>
<span class="gi">+            raise TypeError(</span>
<span class="gi">+                &quot;&#39;construct_from_string&#39; expects a string, got {}&quot;.format(type(string))</span>
<span class="gi">+            )</span>
<span class="gi">+        elif string == cls.name:</span>
<span class="gi">+            return cls()</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise TypeError(</span>
<span class="gi">+                &quot;Cannot construct a &#39;{}&#39; from &#39;{}&#39;&quot;.format(cls.__name__, string)</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    @classmethod</span>
<span class="gi">+    def construct_array_type(cls):</span>
<span class="gi">+        return GeometryArray</span>
<span class="gi">+</span>

<span class="w"> </span>register_extension_dtype(GeometryDtype)

<span class="gu">@@ -41,14 +78,42 @@ def _check_crs(left, right, allow_none=False):</span>

<span class="w"> </span>    If allow_none is True, empty CRS is treated as the same.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if allow_none:</span>
<span class="gi">+        if not left.crs or not right.crs:</span>
<span class="gi">+            return True</span>
<span class="gi">+    if not left.crs == right.crs:</span>
<span class="gi">+        return False</span>
<span class="gi">+    return True</span>


<span class="w"> </span>def _crs_mismatch_warn(left, right, stacklevel=3):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Raise a CRS mismatch warning with the information on the assigned CRS.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if left.crs:</span>
<span class="gi">+        left_srs = left.crs.to_string()</span>
<span class="gi">+        left_srs = left_srs if len(left_srs) &lt;= 50 else &quot; &quot;.join([left_srs[:50], &quot;...&quot;])</span>
<span class="gi">+    else:</span>
<span class="gi">+        left_srs = None</span>
<span class="gi">+</span>
<span class="gi">+    if right.crs:</span>
<span class="gi">+        right_srs = right.crs.to_string()</span>
<span class="gi">+        right_srs = (</span>
<span class="gi">+            right_srs if len(right_srs) &lt;= 50 else &quot; &quot;.join([right_srs[:50], &quot;...&quot;])</span>
<span class="gi">+        )</span>
<span class="gi">+    else:</span>
<span class="gi">+        right_srs = None</span>
<span class="gi">+</span>
<span class="gi">+    warnings.warn(</span>
<span class="gi">+        &quot;CRS mismatch between the CRS of left geometries &quot;</span>
<span class="gi">+        &quot;and the CRS of right geometries.\n&quot;</span>
<span class="gi">+        &quot;Use `to_crs()` to reproject one of &quot;</span>
<span class="gi">+        &quot;the input geometries to match the CRS of the other.\n\n&quot;</span>
<span class="gi">+        &quot;Left CRS: {0}\n&quot;</span>
<span class="gi">+        &quot;Right CRS: {1}\n&quot;.format(left_srs, right_srs),</span>
<span class="gi">+        UserWarning,</span>
<span class="gi">+        stacklevel=stacklevel,</span>
<span class="gi">+    )</span>


<span class="w"> </span>def isna(value):
<span class="gu">@@ -58,7 +123,23 @@ def isna(value):</span>
<span class="w"> </span>    Custom version that only works for scalars (returning True or False),
<span class="w"> </span>    as `pd.isna` also works for array-like input returning a boolean array.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if value is None:</span>
<span class="gi">+        return True</span>
<span class="gi">+    elif isinstance(value, float) and np.isnan(value):</span>
<span class="gi">+        return True</span>
<span class="gi">+    elif value is pd.NA:</span>
<span class="gi">+        return True</span>
<span class="gi">+    else:</span>
<span class="gi">+        return False</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# -----------------------------------------------------------------------------</span>
<span class="gi">+# Constructors / converters to other formats</span>
<span class="gi">+# -----------------------------------------------------------------------------</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _is_scalar_geometry(geom):</span>
<span class="gi">+    return isinstance(geom, BaseGeometry)</span>


<span class="w"> </span>def from_shapely(data, crs=None):
<span class="gu">@@ -77,17 +158,42 @@ def from_shapely(data, crs=None):</span>
<span class="w"> </span>        such as an authority string (eg &quot;EPSG:4326&quot;) or a WKT string.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not isinstance(data, np.ndarray):</span>
<span class="gi">+        arr = np.empty(len(data), dtype=object)</span>
<span class="gi">+        arr[:] = data</span>
<span class="gi">+    else:</span>
<span class="gi">+        arr = data</span>
<span class="gi">+</span>
<span class="gi">+    if not shapely.is_valid_input(arr).all():</span>
<span class="gi">+        out = []</span>
<span class="gi">+</span>
<span class="gi">+        for geom in data:</span>
<span class="gi">+            if isinstance(geom, BaseGeometry):</span>
<span class="gi">+                out.append(geom)</span>
<span class="gi">+            elif hasattr(geom, &quot;__geo_interface__&quot;):</span>
<span class="gi">+                geom = shapely.geometry.shape(geom)</span>
<span class="gi">+                out.append(geom)</span>
<span class="gi">+            elif isna(geom):</span>
<span class="gi">+                out.append(None)</span>
<span class="gi">+            else:</span>
<span class="gi">+                raise TypeError(</span>
<span class="gi">+                    &quot;Input must be valid geometry objects: {0}&quot;.format(geom)</span>
<span class="gi">+                )</span>
<span class="gi">+        arr = np.array(out, dtype=object)</span>
<span class="gi">+</span>
<span class="gi">+    return GeometryArray(arr, crs=crs)</span>


<span class="w"> </span>def to_shapely(geoms):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Convert GeometryArray to numpy object array of shapely objects.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not isinstance(geoms, GeometryArray):</span>
<span class="gi">+        raise ValueError(&quot;&#39;geoms&#39; must be a GeometryArray&quot;)</span>
<span class="gi">+    return geoms._data</span>


<span class="gd">-def from_wkb(data, crs=None, on_invalid=&#39;raise&#39;):</span>
<span class="gi">+def from_wkb(data, crs=None, on_invalid=&quot;raise&quot;):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Convert a list or array of WKB objects to a GeometryArray.

<span class="gu">@@ -106,17 +212,19 @@ def from_wkb(data, crs=None, on_invalid=&#39;raise&#39;):</span>
<span class="w"> </span>        - ignore: invalid WKB geometries will be returned as None without a warning.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return GeometryArray(shapely.from_wkb(data, on_invalid=on_invalid), crs=crs)</span>


<span class="w"> </span>def to_wkb(geoms, hex=False, **kwargs):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Convert GeometryArray to a numpy object array of WKB objects.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not isinstance(geoms, GeometryArray):</span>
<span class="gi">+        raise ValueError(&quot;&#39;geoms&#39; must be a GeometryArray&quot;)</span>
<span class="gi">+    return shapely.to_wkb(geoms, hex=hex, **kwargs)</span>


<span class="gd">-def from_wkt(data, crs=None, on_invalid=&#39;raise&#39;):</span>
<span class="gi">+def from_wkt(data, crs=None, on_invalid=&quot;raise&quot;):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Convert a list or array of WKT objects to a GeometryArray.

<span class="gu">@@ -135,14 +243,16 @@ def from_wkt(data, crs=None, on_invalid=&#39;raise&#39;):</span>
<span class="w"> </span>        - ignore: invalid WKT geometries will be returned as ``None`` without a warning.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return GeometryArray(shapely.from_wkt(data, on_invalid=on_invalid), crs=crs)</span>


<span class="w"> </span>def to_wkt(geoms, **kwargs):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Convert GeometryArray to a numpy object array of WKT objects.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not isinstance(geoms, GeometryArray):</span>
<span class="gi">+        raise ValueError(&quot;&#39;geoms&#39; must be a GeometryArray&quot;)</span>
<span class="gi">+    return shapely.to_wkt(geoms, **kwargs)</span>


<span class="w"> </span>def points_from_xy(x, y, z=None, crs=None):
<span class="gu">@@ -188,7 +298,12 @@ def points_from_xy(x, y, z=None, crs=None):</span>
<span class="w"> </span>    -------
<span class="w"> </span>    output : GeometryArray
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    x = np.asarray(x, dtype=&quot;float64&quot;)</span>
<span class="gi">+    y = np.asarray(y, dtype=&quot;float64&quot;)</span>
<span class="gi">+    if z is not None:</span>
<span class="gi">+        z = np.asarray(z, dtype=&quot;float64&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    return GeometryArray(shapely.points(x, y, z), crs=crs)</span>


<span class="w"> </span>class GeometryArray(ExtensionArray):
<span class="gu">@@ -196,6 +311,7 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>    Class wrapping a numpy array of Shapely objects and
<span class="w"> </span>    holding the array-based implementations.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>    _dtype = GeometryDtype()

<span class="w"> </span>    def __init__(self, data, crs=None):
<span class="gu">@@ -205,16 +321,25 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>            data = data._data
<span class="w"> </span>        elif not isinstance(data, np.ndarray):
<span class="w"> </span>            raise TypeError(
<span class="gd">-                &quot;&#39;data&#39; should be array of geometry objects. Use from_shapely, from_wkb, from_wkt functions to construct a GeometryArray.&quot;</span>
<span class="gd">-                )</span>
<span class="gi">+                &quot;&#39;data&#39; should be array of geometry objects. Use from_shapely, &quot;</span>
<span class="gi">+                &quot;from_wkb, from_wkt functions to construct a GeometryArray.&quot;</span>
<span class="gi">+            )</span>
<span class="w"> </span>        elif not data.ndim == 1:
<span class="w"> </span>            raise ValueError(
<span class="gd">-                &quot;&#39;data&#39; should be a 1-dimensional array of geometry objects.&quot;)</span>
<span class="gi">+                &quot;&#39;data&#39; should be a 1-dimensional array of geometry objects.&quot;</span>
<span class="gi">+            )</span>
<span class="w"> </span>        self._data = data
<span class="gi">+</span>
<span class="w"> </span>        self._crs = None
<span class="w"> </span>        self.crs = crs
<span class="w"> </span>        self._sindex = None

<span class="gi">+    @property</span>
<span class="gi">+    def sindex(self):</span>
<span class="gi">+        if self._sindex is None:</span>
<span class="gi">+            self._sindex = SpatialIndex(self._data)</span>
<span class="gi">+        return self._sindex</span>
<span class="gi">+</span>
<span class="w"> </span>    @property
<span class="w"> </span>    def has_sindex(self):
<span class="w"> </span>        &quot;&quot;&quot;Check the existence of the spatial index without generating it.
<span class="gu">@@ -237,7 +362,7 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>            `True` if the spatial index has been generated or
<span class="w"> </span>            `False` if not.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._sindex is not None</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def crs(self):
<span class="gu">@@ -251,16 +376,43 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>        :meth:`pyproj.CRS.from_user_input() &lt;pyproj.crs.CRS.from_user_input&gt;`,
<span class="w"> </span>        such as an authority string (eg &quot;EPSG:4326&quot;) or a WKT string.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._crs</span>

<span class="w"> </span>    @crs.setter
<span class="w"> </span>    def crs(self, value):
<span class="w"> </span>        &quot;&quot;&quot;Sets the value of the crs&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if HAS_PYPROJ:</span>
<span class="gi">+            from pyproj import CRS</span>
<span class="gi">+</span>
<span class="gi">+            self._crs = None if not value else CRS.from_user_input(value)</span>
<span class="gi">+        else:</span>
<span class="gi">+            if value is not None:</span>
<span class="gi">+                warnings.warn(</span>
<span class="gi">+                    &quot;Cannot set the CRS, falling back to None. The CRS support requires&quot;</span>
<span class="gi">+                    &quot; the &#39;pyproj&#39; package, but it is not installed or does not import&quot;</span>
<span class="gi">+                    &quot; correctly. The functions depending on CRS will raise an error or&quot;</span>
<span class="gi">+                    &quot; may produce unexpected results.&quot;,</span>
<span class="gi">+                    UserWarning,</span>
<span class="gi">+                    stacklevel=2,</span>
<span class="gi">+                )</span>
<span class="gi">+            self._crs = None</span>

<span class="w"> </span>    def check_geographic_crs(self, stacklevel):
<span class="w"> </span>        &quot;&quot;&quot;Check CRS and warn if the planar operation is done in a geographic CRS&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self.crs and self.crs.is_geographic:</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                &quot;Geometry is in a geographic CRS. Results from &#39;{}&#39; are likely &quot;</span>
<span class="gi">+                &quot;incorrect. Use &#39;GeoSeries.to_crs()&#39; to re-project geometries to a &quot;</span>
<span class="gi">+                &quot;projected CRS before this operation.\n&quot;.format(</span>
<span class="gi">+                    inspect.stack()[1].function</span>
<span class="gi">+                ),</span>
<span class="gi">+                UserWarning,</span>
<span class="gi">+                stacklevel=stacklevel,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def dtype(self):</span>
<span class="gi">+        return self._dtype</span>

<span class="w"> </span>    def __len__(self):
<span class="w"> </span>        return self.shape[0]
<span class="gu">@@ -268,10 +420,15 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>    def __getitem__(self, idx):
<span class="w"> </span>        if isinstance(idx, numbers.Integral):
<span class="w"> </span>            return self._data[idx]
<span class="gi">+        # array-like, slice</span>
<span class="gi">+        # validate and convert IntegerArray/BooleanArray</span>
<span class="gi">+        # to numpy array, pass-through non-array-like indexers</span>
<span class="w"> </span>        idx = pd.api.indexers.check_array_indexer(self, idx)
<span class="w"> </span>        return GeometryArray(self._data[idx], crs=self.crs)

<span class="w"> </span>    def __setitem__(self, key, value):
<span class="gi">+        # validate and convert IntegerArray/BooleanArray</span>
<span class="gi">+        # keys to numpy array, pass-through non-array-like indexers</span>
<span class="w"> </span>        key = pd.api.indexers.check_array_indexer(self, key)
<span class="w"> </span>        if isinstance(value, pd.Series):
<span class="w"> </span>            value = value.values
<span class="gu">@@ -281,15 +438,17 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>            value = from_shapely(value)
<span class="w"> </span>        if isinstance(value, GeometryArray):
<span class="w"> </span>            if isinstance(key, numbers.Integral):
<span class="gd">-                raise ValueError(&#39;cannot set a single element with an array&#39;)</span>
<span class="gi">+                raise ValueError(&quot;cannot set a single element with an array&quot;)</span>
<span class="w"> </span>            self._data[key] = value._data
<span class="w"> </span>        elif isinstance(value, BaseGeometry) or isna(value):
<span class="w"> </span>            if isna(value):
<span class="gi">+                # internally only use None as missing value indicator</span>
<span class="gi">+                # but accept others</span>
<span class="w"> </span>                value = None
<span class="w"> </span>            elif isinstance(value, BaseGeometry):
<span class="w"> </span>                value = from_shapely([value])._data[0]
<span class="w"> </span>            else:
<span class="gd">-                raise TypeError(&#39;should be valid geometry&#39;)</span>
<span class="gi">+                raise TypeError(&quot;should be valid geometry&quot;)</span>
<span class="w"> </span>            if isinstance(key, (slice, list, np.ndarray)):
<span class="w"> </span>                value_array = np.empty(1, dtype=object)
<span class="w"> </span>                value_array[:] = [value]
<span class="gu">@@ -298,27 +457,475 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>                self._data[key] = value
<span class="w"> </span>        else:
<span class="w"> </span>            raise TypeError(
<span class="gd">-                &#39;Value should be either a BaseGeometry or None, got %s&#39; %</span>
<span class="gd">-                str(value))</span>
<span class="gi">+                &quot;Value should be either a BaseGeometry or None, got %s&quot; % str(value)</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        # invalidate spatial index</span>
<span class="w"> </span>        self._sindex = None

<span class="gi">+        # TODO: use this once pandas-dev/pandas#33457 is fixed</span>
<span class="gi">+        # if hasattr(value, &quot;crs&quot;):</span>
<span class="gi">+        #     if value.crs and (value.crs != self.crs):</span>
<span class="gi">+        #         raise ValueError(</span>
<span class="gi">+        #             &quot;CRS mismatch between CRS of the passed geometries &quot;</span>
<span class="gi">+        #             &quot;and CRS of existing geometries.&quot;</span>
<span class="gi">+        #         )</span>
<span class="gi">+</span>
<span class="w"> </span>    def __getstate__(self):
<span class="gd">-        return shapely.to_wkb(self._data), self._crs</span>
<span class="gi">+        return (shapely.to_wkb(self._data), self._crs)</span>

<span class="w"> </span>    def __setstate__(self, state):
<span class="w"> </span>        if not isinstance(state, dict):
<span class="gi">+            # pickle file saved with pygeos</span>
<span class="w"> </span>            geoms = shapely.from_wkb(state[0])
<span class="w"> </span>            self._crs = state[1]
<span class="gd">-            self._sindex = None</span>
<span class="gi">+            self._sindex = None  # pygeos.STRtree could not be pickled yet</span>
<span class="w"> </span>            self._data = geoms
<span class="w"> </span>            self.base = None
<span class="w"> </span>        else:
<span class="gd">-            if &#39;data&#39; in state:</span>
<span class="gd">-                state[&#39;_data&#39;] = state.pop(&#39;data&#39;)</span>
<span class="gd">-            if &#39;_crs&#39; not in state:</span>
<span class="gd">-                state[&#39;_crs&#39;] = None</span>
<span class="gi">+            if &quot;data&quot; in state:</span>
<span class="gi">+                state[&quot;_data&quot;] = state.pop(&quot;data&quot;)</span>
<span class="gi">+            if &quot;_crs&quot; not in state:</span>
<span class="gi">+                state[&quot;_crs&quot;] = None</span>
<span class="w"> </span>            self.__dict__.update(state)

<span class="gi">+    # -------------------------------------------------------------------------</span>
<span class="gi">+    # Geometry related methods</span>
<span class="gi">+    # -------------------------------------------------------------------------</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def is_valid(self):</span>
<span class="gi">+        return shapely.is_valid(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    def is_valid_reason(self):</span>
<span class="gi">+        return shapely.is_valid_reason(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def is_empty(self):</span>
<span class="gi">+        return shapely.is_empty(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def is_simple(self):</span>
<span class="gi">+        return shapely.is_simple(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def is_ring(self):</span>
<span class="gi">+        return shapely.is_ring(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def is_closed(self):</span>
<span class="gi">+        return shapely.is_closed(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def is_ccw(self):</span>
<span class="gi">+        return shapely.is_ccw(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def has_z(self):</span>
<span class="gi">+        return shapely.has_z(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def geom_type(self):</span>
<span class="gi">+        res = shapely.get_type_id(self._data)</span>
<span class="gi">+        return geometry_type_values[np.searchsorted(geometry_type_ids, res)]</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def area(self):</span>
<span class="gi">+        self.check_geographic_crs(stacklevel=5)</span>
<span class="gi">+        return shapely.area(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def length(self):</span>
<span class="gi">+        self.check_geographic_crs(stacklevel=5)</span>
<span class="gi">+        return shapely.length(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    def count_coordinates(self):</span>
<span class="gi">+        return shapely.get_num_coordinates(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    def count_geometries(self):</span>
<span class="gi">+        return shapely.get_num_geometries(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    def count_interior_rings(self):</span>
<span class="gi">+        return shapely.get_num_interior_rings(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    def get_precision(self):</span>
<span class="gi">+        return shapely.get_precision(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    def get_geometry(self, index):</span>
<span class="gi">+        return shapely.get_geometry(self._data, index=index)</span>
<span class="gi">+</span>
<span class="gi">+    #</span>
<span class="gi">+    # Unary operations that return new geometries</span>
<span class="gi">+    #</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def boundary(self):</span>
<span class="gi">+        return GeometryArray(shapely.boundary(self._data), crs=self.crs)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def centroid(self):</span>
<span class="gi">+        self.check_geographic_crs(stacklevel=5)</span>
<span class="gi">+        return GeometryArray(shapely.centroid(self._data), crs=self.crs)</span>
<span class="gi">+</span>
<span class="gi">+    def concave_hull(self, ratio, allow_holes):</span>
<span class="gi">+        return shapely.concave_hull(self._data, ratio=ratio, allow_holes=allow_holes)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def convex_hull(self):</span>
<span class="gi">+        return GeometryArray(shapely.convex_hull(self._data), crs=self.crs)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def envelope(self):</span>
<span class="gi">+        return GeometryArray(shapely.envelope(self._data), crs=self.crs)</span>
<span class="gi">+</span>
<span class="gi">+    def minimum_rotated_rectangle(self):</span>
<span class="gi">+        return GeometryArray(shapely.oriented_envelope(self._data), crs=self.crs)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def exterior(self):</span>
<span class="gi">+        return GeometryArray(shapely.get_exterior_ring(self._data), crs=self.crs)</span>
<span class="gi">+</span>
<span class="gi">+    def extract_unique_points(self):</span>
<span class="gi">+        return GeometryArray(shapely.extract_unique_points(self._data), crs=self.crs)</span>
<span class="gi">+</span>
<span class="gi">+    def offset_curve(self, distance, quad_segs=8, join_style=&quot;round&quot;, mitre_limit=5.0):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            shapely.offset_curve(</span>
<span class="gi">+                self._data,</span>
<span class="gi">+                distance,</span>
<span class="gi">+                quad_segs=quad_segs,</span>
<span class="gi">+                join_style=join_style,</span>
<span class="gi">+                mitre_limit=mitre_limit,</span>
<span class="gi">+            ),</span>
<span class="gi">+            crs=self.crs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def interiors(self):</span>
<span class="gi">+        # no GeometryArray as result</span>
<span class="gi">+        has_non_poly = False</span>
<span class="gi">+        inner_rings = []</span>
<span class="gi">+        for geom in self._data:</span>
<span class="gi">+            interior_ring_seq = getattr(geom, &quot;interiors&quot;, None)</span>
<span class="gi">+            # polygon case</span>
<span class="gi">+            if interior_ring_seq is not None:</span>
<span class="gi">+                inner_rings.append(list(interior_ring_seq))</span>
<span class="gi">+            # non-polygon case</span>
<span class="gi">+            else:</span>
<span class="gi">+                has_non_poly = True</span>
<span class="gi">+                inner_rings.append(None)</span>
<span class="gi">+        if has_non_poly:</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                &quot;Only Polygon objects have interior rings. For other &quot;</span>
<span class="gi">+                &quot;geometry types, None is returned.&quot;,</span>
<span class="gi">+                stacklevel=2,</span>
<span class="gi">+            )</span>
<span class="gi">+        # need to allocate empty first in case of all empty lists in inner_rings</span>
<span class="gi">+        data = np.empty(len(inner_rings), dtype=object)</span>
<span class="gi">+        data[:] = inner_rings</span>
<span class="gi">+        return data</span>
<span class="gi">+</span>
<span class="gi">+    def remove_repeated_points(self, tolerance=0.0):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            shapely.remove_repeated_points(self._data, tolerance=tolerance),</span>
<span class="gi">+            crs=self.crs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def representative_point(self):</span>
<span class="gi">+        return GeometryArray(shapely.point_on_surface(self._data), crs=self.crs)</span>
<span class="gi">+</span>
<span class="gi">+    def minimum_bounding_circle(self):</span>
<span class="gi">+        return GeometryArray(shapely.minimum_bounding_circle(self._data), crs=self.crs)</span>
<span class="gi">+</span>
<span class="gi">+    def minimum_bounding_radius(self):</span>
<span class="gi">+        return shapely.minimum_bounding_radius(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    def minimum_clearance(self):</span>
<span class="gi">+        return shapely.minimum_clearance(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    def normalize(self):</span>
<span class="gi">+        return GeometryArray(shapely.normalize(self._data), crs=self.crs)</span>
<span class="gi">+</span>
<span class="gi">+    def make_valid(self):</span>
<span class="gi">+        return GeometryArray(shapely.make_valid(self._data), crs=self.crs)</span>
<span class="gi">+</span>
<span class="gi">+    def reverse(self):</span>
<span class="gi">+        return GeometryArray(shapely.reverse(self._data), crs=self.crs)</span>
<span class="gi">+</span>
<span class="gi">+    def segmentize(self, max_segment_length):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            shapely.segmentize(self._data, max_segment_length),</span>
<span class="gi">+            crs=self.crs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def force_2d(self):</span>
<span class="gi">+        return GeometryArray(shapely.force_2d(self._data), crs=self.crs)</span>
<span class="gi">+</span>
<span class="gi">+    def force_3d(self, z=0):</span>
<span class="gi">+        return GeometryArray(shapely.force_3d(self._data, z=z), crs=self.crs)</span>
<span class="gi">+</span>
<span class="gi">+    def transform(self, transformation, include_z=False):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            shapely.transform(self._data, transformation, include_z), crs=self.crs</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def line_merge(self, directed=False):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            shapely.line_merge(self._data, directed=directed), crs=self.crs</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def set_precision(self, grid_size, mode=&quot;valid_output&quot;):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            shapely.set_precision(self._data, grid_size=grid_size, mode=mode),</span>
<span class="gi">+            crs=self.crs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    #</span>
<span class="gi">+    # Binary predicates</span>
<span class="gi">+    #</span>
<span class="gi">+</span>
<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _binary_method(op, left, right, **kwargs):</span>
<span class="gi">+        if isinstance(right, GeometryArray):</span>
<span class="gi">+            if len(left) != len(right):</span>
<span class="gi">+                msg = &quot;Lengths of inputs do not match. Left: {0}, Right: {1}&quot;.format(</span>
<span class="gi">+                    len(left), len(right)</span>
<span class="gi">+                )</span>
<span class="gi">+                raise ValueError(msg)</span>
<span class="gi">+            if not _check_crs(left, right):</span>
<span class="gi">+                _crs_mismatch_warn(left, right, stacklevel=7)</span>
<span class="gi">+            right = right._data</span>
<span class="gi">+</span>
<span class="gi">+        return getattr(shapely, op)(left._data, right, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def covers(self, other):</span>
<span class="gi">+        return self._binary_method(&quot;covers&quot;, self, other)</span>
<span class="gi">+</span>
<span class="gi">+    def covered_by(self, other):</span>
<span class="gi">+        return self._binary_method(&quot;covered_by&quot;, self, other)</span>
<span class="gi">+</span>
<span class="gi">+    def contains(self, other):</span>
<span class="gi">+        return self._binary_method(&quot;contains&quot;, self, other)</span>
<span class="gi">+</span>
<span class="gi">+    def contains_properly(self, other):</span>
<span class="gi">+        return self._binary_method(&quot;contains_properly&quot;, self, other)</span>
<span class="gi">+</span>
<span class="gi">+    def crosses(self, other):</span>
<span class="gi">+        return self._binary_method(&quot;crosses&quot;, self, other)</span>
<span class="gi">+</span>
<span class="gi">+    def disjoint(self, other):</span>
<span class="gi">+        return self._binary_method(&quot;disjoint&quot;, self, other)</span>
<span class="gi">+</span>
<span class="gi">+    def geom_equals(self, other):</span>
<span class="gi">+        return self._binary_method(&quot;equals&quot;, self, other)</span>
<span class="gi">+</span>
<span class="gi">+    def intersects(self, other):</span>
<span class="gi">+        return self._binary_method(&quot;intersects&quot;, self, other)</span>
<span class="gi">+</span>
<span class="gi">+    def overlaps(self, other):</span>
<span class="gi">+        return self._binary_method(&quot;overlaps&quot;, self, other)</span>
<span class="gi">+</span>
<span class="gi">+    def touches(self, other):</span>
<span class="gi">+        return self._binary_method(&quot;touches&quot;, self, other)</span>
<span class="gi">+</span>
<span class="gi">+    def within(self, other):</span>
<span class="gi">+        return self._binary_method(&quot;within&quot;, self, other)</span>
<span class="gi">+</span>
<span class="gi">+    def dwithin(self, other, distance):</span>
<span class="gi">+        self.check_geographic_crs(stacklevel=6)</span>
<span class="gi">+        return self._binary_method(&quot;dwithin&quot;, self, other, distance=distance)</span>
<span class="gi">+</span>
<span class="gi">+    def geom_equals_exact(self, other, tolerance):</span>
<span class="gi">+        return self._binary_method(&quot;equals_exact&quot;, self, other, tolerance=tolerance)</span>
<span class="gi">+</span>
<span class="gi">+    def geom_almost_equals(self, other, decimal):</span>
<span class="gi">+        warnings.warn(</span>
<span class="gi">+            &quot;The &#39;geom_almost_equals()&#39; method is deprecated because the name is &quot;</span>
<span class="gi">+            &quot;confusing. The &#39;geom_equals_exact()&#39; method should be used instead.&quot;,</span>
<span class="gi">+            FutureWarning,</span>
<span class="gi">+            stacklevel=2,</span>
<span class="gi">+        )</span>
<span class="gi">+        return self.geom_equals_exact(other, 0.5 * 10 ** (-decimal))</span>
<span class="gi">+</span>
<span class="gi">+    #</span>
<span class="gi">+    # Binary operations that return new geometries</span>
<span class="gi">+    #</span>
<span class="gi">+</span>
<span class="gi">+    def clip_by_rect(self, xmin, ymin, xmax, ymax):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            shapely.clip_by_rect(self._data, xmin, ymin, xmax, ymax), crs=self.crs</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def difference(self, other):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            self._binary_method(&quot;difference&quot;, self, other), crs=self.crs</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def intersection(self, other):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            self._binary_method(&quot;intersection&quot;, self, other), crs=self.crs</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def symmetric_difference(self, other):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            self._binary_method(&quot;symmetric_difference&quot;, self, other), crs=self.crs</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def union(self, other):</span>
<span class="gi">+        return GeometryArray(self._binary_method(&quot;union&quot;, self, other), crs=self.crs)</span>
<span class="gi">+</span>
<span class="gi">+    def shortest_line(self, other):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            self._binary_method(&quot;shortest_line&quot;, self, other), crs=self.crs</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def snap(self, other, tolerance):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            self._binary_method(&quot;snap&quot;, self, other, tolerance=tolerance), crs=self.crs</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def shared_paths(self, other):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            self._binary_method(&quot;shared_paths&quot;, self, other), crs=self.crs</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    #</span>
<span class="gi">+    # Other operations</span>
<span class="gi">+    #</span>
<span class="gi">+</span>
<span class="gi">+    def distance(self, other):</span>
<span class="gi">+        self.check_geographic_crs(stacklevel=6)</span>
<span class="gi">+        return self._binary_method(&quot;distance&quot;, self, other)</span>
<span class="gi">+</span>
<span class="gi">+    def hausdorff_distance(self, other, **kwargs):</span>
<span class="gi">+        self.check_geographic_crs(stacklevel=6)</span>
<span class="gi">+        return self._binary_method(&quot;hausdorff_distance&quot;, self, other, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def frechet_distance(self, other, **kwargs):</span>
<span class="gi">+        self.check_geographic_crs(stacklevel=6)</span>
<span class="gi">+        return self._binary_method(&quot;frechet_distance&quot;, self, other, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def buffer(self, distance, resolution=16, **kwargs):</span>
<span class="gi">+        if not (isinstance(distance, (int, float)) and distance == 0):</span>
<span class="gi">+            self.check_geographic_crs(stacklevel=5)</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            shapely.buffer(self._data, distance, quad_segs=resolution, **kwargs),</span>
<span class="gi">+            crs=self.crs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def interpolate(self, distance, normalized=False):</span>
<span class="gi">+        self.check_geographic_crs(stacklevel=5)</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            shapely.line_interpolate_point(self._data, distance, normalized=normalized),</span>
<span class="gi">+            crs=self.crs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def simplify(self, tolerance, preserve_topology=True):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            shapely.simplify(</span>
<span class="gi">+                self._data, tolerance, preserve_topology=preserve_topology</span>
<span class="gi">+            ),</span>
<span class="gi">+            crs=self.crs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def project(self, other, normalized=False):</span>
<span class="gi">+        if isinstance(other, GeometryArray):</span>
<span class="gi">+            other = other._data</span>
<span class="gi">+        return shapely.line_locate_point(self._data, other, normalized=normalized)</span>
<span class="gi">+</span>
<span class="gi">+    def relate(self, other):</span>
<span class="gi">+        if isinstance(other, GeometryArray):</span>
<span class="gi">+            other = other._data</span>
<span class="gi">+        return shapely.relate(self._data, other)</span>
<span class="gi">+</span>
<span class="gi">+    def relate_pattern(self, other, pattern):</span>
<span class="gi">+        if isinstance(other, GeometryArray):</span>
<span class="gi">+            other = other._data</span>
<span class="gi">+        return shapely.relate_pattern(self._data, other, pattern)</span>
<span class="gi">+</span>
<span class="gi">+    #</span>
<span class="gi">+    # Reduction operations that return a Shapely geometry</span>
<span class="gi">+    #</span>
<span class="gi">+</span>
<span class="gi">+    def unary_union(self):</span>
<span class="gi">+        warnings.warn(</span>
<span class="gi">+            &quot;The &#39;unary_union&#39; attribute is deprecated, &quot;</span>
<span class="gi">+            &quot;use the &#39;union_all&#39; method instead.&quot;,</span>
<span class="gi">+            DeprecationWarning,</span>
<span class="gi">+            stacklevel=2,</span>
<span class="gi">+        )</span>
<span class="gi">+        return self.union_all()</span>
<span class="gi">+</span>
<span class="gi">+    def union_all(self, method=&quot;unary&quot;):</span>
<span class="gi">+        if method == &quot;coverage&quot;:</span>
<span class="gi">+            return shapely.coverage_union_all(self._data)</span>
<span class="gi">+        elif method == &quot;unary&quot;:</span>
<span class="gi">+            return shapely.union_all(self._data)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                f&quot;Method &#39;{method}&#39; not recognized. Use &#39;coverage&#39; or &#39;unary&#39;.&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    def intersection_all(self):</span>
<span class="gi">+        return shapely.intersection_all(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    #</span>
<span class="gi">+    # Affinity operations</span>
<span class="gi">+    #</span>
<span class="gi">+</span>
<span class="gi">+    @staticmethod</span>
<span class="gi">+    def _affinity_method(op, left, *args, **kwargs):</span>
<span class="gi">+        # not all shapely.affinity methods can handle empty geometries:</span>
<span class="gi">+        # affine_transform itself works (as well as translate), but rotate, scale</span>
<span class="gi">+        # and skew fail (they try to unpack the bounds).</span>
<span class="gi">+        # Here: consistently returning empty geom for input empty geom</span>
<span class="gi">+        out = []</span>
<span class="gi">+        for geom in left:</span>
<span class="gi">+            if geom is None or geom.is_empty:</span>
<span class="gi">+                res = geom</span>
<span class="gi">+            else:</span>
<span class="gi">+                res = getattr(shapely.affinity, op)(geom, *args, **kwargs)</span>
<span class="gi">+            out.append(res)</span>
<span class="gi">+        data = np.empty(len(left), dtype=object)</span>
<span class="gi">+        data[:] = out</span>
<span class="gi">+        return data</span>
<span class="gi">+</span>
<span class="gi">+    def affine_transform(self, matrix):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            self._affinity_method(&quot;affine_transform&quot;, self._data, matrix),</span>
<span class="gi">+            crs=self.crs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def translate(self, xoff=0.0, yoff=0.0, zoff=0.0):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            self._affinity_method(&quot;translate&quot;, self._data, xoff, yoff, zoff),</span>
<span class="gi">+            crs=self.crs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def rotate(self, angle, origin=&quot;center&quot;, use_radians=False):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            self._affinity_method(</span>
<span class="gi">+                &quot;rotate&quot;, self._data, angle, origin=origin, use_radians=use_radians</span>
<span class="gi">+            ),</span>
<span class="gi">+            crs=self.crs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def scale(self, xfact=1.0, yfact=1.0, zfact=1.0, origin=&quot;center&quot;):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            self._affinity_method(</span>
<span class="gi">+                &quot;scale&quot;, self._data, xfact, yfact, zfact, origin=origin</span>
<span class="gi">+            ),</span>
<span class="gi">+            crs=self.crs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def skew(self, xs=0.0, ys=0.0, origin=&quot;center&quot;, use_radians=False):</span>
<span class="gi">+        return GeometryArray(</span>
<span class="gi">+            self._affinity_method(</span>
<span class="gi">+                &quot;skew&quot;, self._data, xs, ys, origin=origin, use_radians=use_radians</span>
<span class="gi">+            ),</span>
<span class="gi">+            crs=self.crs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="w"> </span>    @requires_pyproj
<span class="w"> </span>    def to_crs(self, crs=None, epsg=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeometryArray`` with all geometries transformed to a new
<span class="gu">@@ -389,10 +996,31 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>        - Prime Meridian: Greenwich

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from pyproj import CRS</span>
<span class="gi">+</span>
<span class="gi">+        if self.crs is None:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;Cannot transform naive geometries.  &quot;</span>
<span class="gi">+                &quot;Please set a crs on the object first.&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        if crs is not None:</span>
<span class="gi">+            crs = CRS.from_user_input(crs)</span>
<span class="gi">+        elif epsg is not None:</span>
<span class="gi">+            crs = CRS.from_epsg(epsg)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise ValueError(&quot;Must pass either crs or epsg.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        # skip if the input CRS and output CRS are the exact same</span>
<span class="gi">+        if self.crs.is_exact_same(crs):</span>
<span class="gi">+            return self</span>
<span class="gi">+</span>
<span class="gi">+        transformer = TransformerFromCRS(self.crs, crs, always_xy=True)</span>
<span class="gi">+</span>
<span class="gi">+        new_data = transform(self._data, transformer.transform)</span>
<span class="gi">+        return GeometryArray(new_data, crs=crs)</span>

<span class="w"> </span>    @requires_pyproj
<span class="gd">-    def estimate_utm_crs(self, datum_name=&#39;WGS 84&#39;):</span>
<span class="gi">+    def estimate_utm_crs(self, datum_name=&quot;WGS 84&quot;):</span>
<span class="w"> </span>        &quot;&quot;&quot;Returns the estimated UTM CRS based on the bounds of the dataset.

<span class="w"> </span>        .. versionadded:: 0.9
<span class="gu">@@ -430,22 +1058,168 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>        - Ellipsoid: WGS 84
<span class="w"> </span>        - Prime Meridian: Greenwich
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from pyproj import CRS</span>
<span class="gi">+        from pyproj.aoi import AreaOfInterest</span>
<span class="gi">+        from pyproj.database import query_utm_crs_info</span>
<span class="gi">+</span>
<span class="gi">+        if not self.crs:</span>
<span class="gi">+            raise RuntimeError(&quot;crs must be set to estimate UTM CRS.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        minx, miny, maxx, maxy = self.total_bounds</span>
<span class="gi">+        if self.crs.is_geographic:</span>
<span class="gi">+            x_center = np.mean([minx, maxx])</span>
<span class="gi">+            y_center = np.mean([miny, maxy])</span>
<span class="gi">+        # ensure using geographic coordinates</span>
<span class="gi">+        else:</span>
<span class="gi">+            transformer = TransformerFromCRS(self.crs, &quot;EPSG:4326&quot;, always_xy=True)</span>
<span class="gi">+            minx, miny, maxx, maxy = transformer.transform_bounds(</span>
<span class="gi">+                minx, miny, maxx, maxy</span>
<span class="gi">+            )</span>
<span class="gi">+            y_center = np.mean([miny, maxy])</span>
<span class="gi">+            # crossed the antimeridian</span>
<span class="gi">+            if minx &gt; maxx:</span>
<span class="gi">+                # shift maxx from [-180,180] to [0,360]</span>
<span class="gi">+                # so both numbers are positive for center calculation</span>
<span class="gi">+                # Example: -175 to 185</span>
<span class="gi">+                maxx += 360</span>
<span class="gi">+                x_center = np.mean([minx, maxx])</span>
<span class="gi">+                # shift back to [-180,180]</span>
<span class="gi">+                x_center = ((x_center + 180) % 360) - 180</span>
<span class="gi">+            else:</span>
<span class="gi">+                x_center = np.mean([minx, maxx])</span>
<span class="gi">+</span>
<span class="gi">+        utm_crs_list = query_utm_crs_info(</span>
<span class="gi">+            datum_name=datum_name,</span>
<span class="gi">+            area_of_interest=AreaOfInterest(</span>
<span class="gi">+                west_lon_degree=x_center,</span>
<span class="gi">+                south_lat_degree=y_center,</span>
<span class="gi">+                east_lon_degree=x_center,</span>
<span class="gi">+                north_lat_degree=y_center,</span>
<span class="gi">+            ),</span>
<span class="gi">+        )</span>
<span class="gi">+        try:</span>
<span class="gi">+            return CRS.from_epsg(utm_crs_list[0].code)</span>
<span class="gi">+        except IndexError:</span>
<span class="gi">+            raise RuntimeError(&quot;Unable to determine UTM CRS&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    #</span>
<span class="gi">+    # Coordinate related properties</span>
<span class="gi">+    #</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def x(self):
<span class="w"> </span>        &quot;&quot;&quot;Return the x location of point geometries in a GeoSeries&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if (self.geom_type[~self.isna()] == &quot;Point&quot;).all():</span>
<span class="gi">+            empty = self.is_empty</span>
<span class="gi">+            if empty.any():</span>
<span class="gi">+                nonempty = ~empty</span>
<span class="gi">+                coords = np.full_like(nonempty, dtype=float, fill_value=np.nan)</span>
<span class="gi">+                coords[nonempty] = shapely.get_x(self._data[nonempty])</span>
<span class="gi">+                return coords</span>
<span class="gi">+            else:</span>
<span class="gi">+                return shapely.get_x(self._data)</span>
<span class="gi">+        else:</span>
<span class="gi">+            message = &quot;x attribute access only provided for Point geometries&quot;</span>
<span class="gi">+            raise ValueError(message)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def y(self):
<span class="w"> </span>        &quot;&quot;&quot;Return the y location of point geometries in a GeoSeries&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if (self.geom_type[~self.isna()] == &quot;Point&quot;).all():</span>
<span class="gi">+            empty = self.is_empty</span>
<span class="gi">+            if empty.any():</span>
<span class="gi">+                nonempty = ~empty</span>
<span class="gi">+                coords = np.full_like(nonempty, dtype=float, fill_value=np.nan)</span>
<span class="gi">+                coords[nonempty] = shapely.get_y(self._data[nonempty])</span>
<span class="gi">+                return coords</span>
<span class="gi">+            else:</span>
<span class="gi">+                return shapely.get_y(self._data)</span>
<span class="gi">+        else:</span>
<span class="gi">+            message = &quot;y attribute access only provided for Point geometries&quot;</span>
<span class="gi">+            raise ValueError(message)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def z(self):
<span class="w"> </span>        &quot;&quot;&quot;Return the z location of point geometries in a GeoSeries&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if (self.geom_type[~self.isna()] == &quot;Point&quot;).all():</span>
<span class="gi">+            empty = self.is_empty</span>
<span class="gi">+            if empty.any():</span>
<span class="gi">+                nonempty = ~empty</span>
<span class="gi">+                coords = np.full_like(nonempty, dtype=float, fill_value=np.nan)</span>
<span class="gi">+                coords[nonempty] = shapely.get_z(self._data[nonempty])</span>
<span class="gi">+                return coords</span>
<span class="gi">+            else:</span>
<span class="gi">+                return shapely.get_z(self._data)</span>
<span class="gi">+        else:</span>
<span class="gi">+            message = &quot;z attribute access only provided for Point geometries&quot;</span>
<span class="gi">+            raise ValueError(message)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def bounds(self):</span>
<span class="gi">+        return shapely.bounds(self._data)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def total_bounds(self):</span>
<span class="gi">+        if len(self) == 0:</span>
<span class="gi">+            # numpy &#39;min&#39; cannot handle empty arrays</span>
<span class="gi">+            # TODO with numpy &gt;= 1.15, the &#39;initial&#39; argument can be used</span>
<span class="gi">+            return np.array([np.nan, np.nan, np.nan, np.nan])</span>
<span class="gi">+        b = self.bounds</span>
<span class="gi">+        with warnings.catch_warnings():</span>
<span class="gi">+            # if all rows are empty geometry / none, nan is expected</span>
<span class="gi">+            warnings.filterwarnings(</span>
<span class="gi">+                &quot;ignore&quot;, r&quot;All-NaN slice encountered&quot;, RuntimeWarning</span>
<span class="gi">+            )</span>
<span class="gi">+            return np.array(</span>
<span class="gi">+                (</span>
<span class="gi">+                    np.nanmin(b[:, 0]),  # minx</span>
<span class="gi">+                    np.nanmin(b[:, 1]),  # miny</span>
<span class="gi">+                    np.nanmax(b[:, 2]),  # maxx</span>
<span class="gi">+                    np.nanmax(b[:, 3]),  # maxy</span>
<span class="gi">+                )</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    # -------------------------------------------------------------------------</span>
<span class="gi">+    # general array like compat</span>
<span class="gi">+    # -------------------------------------------------------------------------</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def size(self):</span>
<span class="gi">+        return self._data.size</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def shape(self):</span>
<span class="gi">+        return (self.size,)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def ndim(self):</span>
<span class="gi">+        return len(self.shape)</span>
<span class="gi">+</span>
<span class="gi">+    def copy(self, *args, **kwargs):</span>
<span class="gi">+        # still taking args/kwargs for compat with pandas 0.24</span>
<span class="gi">+        return GeometryArray(self._data.copy(), crs=self._crs)</span>
<span class="gi">+</span>
<span class="gi">+    def take(self, indices, allow_fill=False, fill_value=None):</span>
<span class="gi">+        from pandas.api.extensions import take</span>
<span class="gi">+</span>
<span class="gi">+        if allow_fill:</span>
<span class="gi">+            if fill_value is None or pd.isna(fill_value):</span>
<span class="gi">+                fill_value = None</span>
<span class="gi">+            elif not _is_scalar_geometry(fill_value):</span>
<span class="gi">+                raise TypeError(&quot;provide geometry or None as fill value&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        result = take(self._data, indices, allow_fill=allow_fill, fill_value=fill_value)</span>
<span class="gi">+        if allow_fill and fill_value is None:</span>
<span class="gi">+            result[~shapely.is_valid_input(result)] = None</span>
<span class="gi">+        return GeometryArray(result, crs=self.crs)</span>
<span class="gi">+</span>
<span class="gi">+    # compat for pandas &lt; 3.0</span>
<span class="gi">+    def _pad_or_backfill(</span>
<span class="gi">+        self, method, limit=None, limit_area=None, copy=True, **kwargs</span>
<span class="gi">+    ):</span>
<span class="gi">+        return super()._pad_or_backfill(</span>
<span class="gi">+            method=method, limit=limit, limit_area=limit_area, copy=copy, **kwargs</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def fillna(self, value=None, method=None, limit=None, copy=True):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -474,7 +1248,38 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>        -------
<span class="w"> </span>        GeometryArray
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if method is not None:</span>
<span class="gi">+            raise NotImplementedError(&quot;fillna with a method is not yet supported&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        mask = self.isna()</span>
<span class="gi">+        if copy:</span>
<span class="gi">+            new_values = self.copy()</span>
<span class="gi">+        else:</span>
<span class="gi">+            new_values = self</span>
<span class="gi">+</span>
<span class="gi">+        if not mask.any():</span>
<span class="gi">+            return new_values</span>
<span class="gi">+</span>
<span class="gi">+        if limit is not None and limit &lt; len(self):</span>
<span class="gi">+            modify = mask.cumsum() &gt; limit</span>
<span class="gi">+            if modify.any():</span>
<span class="gi">+                mask[modify] = False</span>
<span class="gi">+</span>
<span class="gi">+        if isna(value):</span>
<span class="gi">+            value = [None]</span>
<span class="gi">+        elif _is_scalar_geometry(value):</span>
<span class="gi">+            value = [value]</span>
<span class="gi">+        elif isinstance(value, GeometryArray):</span>
<span class="gi">+            value = value[mask]</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise TypeError(</span>
<span class="gi">+                &quot;&#39;value&#39; parameter must be None, a scalar geometry, or a GeoSeries, &quot;</span>
<span class="gi">+                f&quot;but you passed a {type(value).__name__!r}&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        value_arr = np.asarray(value, dtype=object)</span>
<span class="gi">+</span>
<span class="gi">+        new_values._data[mask] = value_arr</span>
<span class="gi">+        return new_values</span>

<span class="w"> </span>    def astype(self, dtype, copy=True):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -494,15 +1299,39 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>        array : ndarray
<span class="w"> </span>            NumPy ndarray with &#39;dtype&#39; for its dtype.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(dtype, GeometryDtype):</span>
<span class="gi">+            if copy:</span>
<span class="gi">+                return self.copy()</span>
<span class="gi">+            else:</span>
<span class="gi">+                return self</span>
<span class="gi">+        elif pd.api.types.is_string_dtype(dtype) and not pd.api.types.is_object_dtype(</span>
<span class="gi">+            dtype</span>
<span class="gi">+        ):</span>
<span class="gi">+            string_values = to_wkt(self)</span>
<span class="gi">+            pd_dtype = pd.api.types.pandas_dtype(dtype)</span>
<span class="gi">+            if isinstance(pd_dtype, pd.StringDtype):</span>
<span class="gi">+                # ensure to return a pandas string array instead of numpy array</span>
<span class="gi">+                return pd.array(string_values, dtype=pd_dtype)</span>
<span class="gi">+            return string_values.astype(dtype, copy=False)</span>
<span class="gi">+        else:</span>
<span class="gi">+            # numpy 2.0 makes copy=False case strict (errors if cannot avoid the copy)</span>
<span class="gi">+            # -&gt; in that case use `np.asarray` as backwards compatible alternative</span>
<span class="gi">+            # for `copy=None` (when requiring numpy 2+, this can be cleaned up)</span>
<span class="gi">+            if not copy:</span>
<span class="gi">+                return np.asarray(self, dtype=dtype)</span>
<span class="gi">+            else:</span>
<span class="gi">+                return np.array(self, dtype=dtype, copy=copy)</span>

<span class="w"> </span>    def isna(self):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Boolean NumPy array indicating if each value is missing
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return shapely.is_missing(self._data)</span>

<span class="gd">-    def value_counts(self, dropna: bool=True):</span>
<span class="gi">+    def value_counts(</span>
<span class="gi">+        self,</span>
<span class="gi">+        dropna: bool = True,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Compute a histogram of the counts of non-null values.

<span class="gu">@@ -515,7 +1344,21 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>        -------
<span class="w"> </span>        pd.Series
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+</span>
<span class="gi">+        # note ExtensionArray usage of value_counts only specifies dropna,</span>
<span class="gi">+        # so sort, normalize and bins are not arguments</span>
<span class="gi">+        values = to_wkb(self)</span>
<span class="gi">+        from pandas import Index, Series</span>
<span class="gi">+</span>
<span class="gi">+        result = Series(values).value_counts(dropna=dropna)</span>
<span class="gi">+        # value_counts converts None to nan, need to convert back for from_wkb to work</span>
<span class="gi">+        # note result.index already has object dtype, not geometry</span>
<span class="gi">+        # Can&#39;t use fillna(None) or Index.putmask, as this gets converted back to nan</span>
<span class="gi">+        # for object dtypes</span>
<span class="gi">+        result.index = Index(</span>
<span class="gi">+            from_wkb(np.where(result.index.isna(), None, result.index))</span>
<span class="gi">+        )</span>
<span class="gi">+        return result</span>

<span class="w"> </span>    def unique(self):
<span class="w"> </span>        &quot;&quot;&quot;Compute the ExtensionArray of unique values.
<span class="gu">@@ -524,7 +1367,14 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>        -------
<span class="w"> </span>        uniques : ExtensionArray
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from pandas import factorize</span>
<span class="gi">+</span>
<span class="gi">+        _, uniques = factorize(self)</span>
<span class="gi">+        return uniques</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def nbytes(self):</span>
<span class="gi">+        return self._data.nbytes</span>

<span class="w"> </span>    def shift(self, periods=1, fill_value=None):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -557,7 +1407,13 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>        len(self) is returned, with all values filled with
<span class="w"> </span>        ``self.dtype.na_value``.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        shifted = super().shift(periods, fill_value)</span>
<span class="gi">+        shifted.crs = self.crs</span>
<span class="gi">+        return shifted</span>
<span class="gi">+</span>
<span class="gi">+    # -------------------------------------------------------------------------</span>
<span class="gi">+    # ExtensionArray specific</span>
<span class="gi">+    # -------------------------------------------------------------------------</span>

<span class="w"> </span>    @classmethod
<span class="w"> </span>    def _from_sequence(cls, scalars, dtype=None, copy=False):
<span class="gu">@@ -579,7 +1435,10 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>        -------
<span class="w"> </span>        ExtensionArray
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # GH 1413</span>
<span class="gi">+        if isinstance(scalars, BaseGeometry):</span>
<span class="gi">+            scalars = [scalars]</span>
<span class="gi">+        return from_shapely(scalars)</span>

<span class="w"> </span>    @classmethod
<span class="w"> </span>    def _from_sequence_of_strings(cls, strings, *, dtype=None, copy=False):
<span class="gu">@@ -601,9 +1460,11 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>        -------
<span class="w"> </span>        ExtensionArray
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # GH 3099</span>
<span class="gi">+        return from_wkt(strings)</span>

<span class="w"> </span>    def _values_for_factorize(self):
<span class="gi">+        # type: () -&gt; Tuple[np.ndarray, Any]</span>
<span class="w"> </span>        &quot;&quot;&quot;Return an array and missing value suitable for factorization.

<span class="w"> </span>        Returns
<span class="gu">@@ -618,7 +1479,8 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>            `na_sentinal` and not included in `uniques`. By default,
<span class="w"> </span>            ``np.nan`` is used.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        vals = to_wkb(self)</span>
<span class="gi">+        return vals, None</span>

<span class="w"> </span>    @classmethod
<span class="w"> </span>    def _from_factorized(cls, values, original):
<span class="gu">@@ -637,9 +1499,10 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>        pandas.factorize
<span class="w"> </span>        ExtensionArray.factorize
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return from_wkb(values, crs=original.crs)</span>

<span class="w"> </span>    def _values_for_argsort(self):
<span class="gi">+        # type: () -&gt; np.ndarray</span>
<span class="w"> </span>        &quot;&quot;&quot;Return values for sorting.

<span class="w"> </span>        Returns
<span class="gu">@@ -652,7 +1515,56 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        ExtensionArray.argsort
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # Note: this is used in `ExtensionArray.argsort`.</span>
<span class="gi">+        from geopandas.tools.hilbert_curve import _hilbert_distance</span>
<span class="gi">+</span>
<span class="gi">+        if self.size == 0:</span>
<span class="gi">+            # TODO _hilbert_distance fails for empty array</span>
<span class="gi">+            return np.array([], dtype=&quot;uint32&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        mask_empty = self.is_empty</span>
<span class="gi">+        has_empty = mask_empty.any()</span>
<span class="gi">+        mask = self.isna() | mask_empty</span>
<span class="gi">+        if mask.any():</span>
<span class="gi">+            # if there are missing or empty geometries, we fill those with</span>
<span class="gi">+            # a dummy geometry so that the _hilbert_distance function can</span>
<span class="gi">+            # process those. The missing values are handled separately by</span>
<span class="gi">+            # pandas regardless of the values we return here (to sort</span>
<span class="gi">+            # first/last depending on &#39;na_position&#39;), the distances for the</span>
<span class="gi">+            # empty geometries are substitued below with an appropriate value</span>
<span class="gi">+            geoms = self.copy()</span>
<span class="gi">+            indices = np.nonzero(~mask)[0]</span>
<span class="gi">+            if indices.size:</span>
<span class="gi">+                geom = self[indices[0]]</span>
<span class="gi">+            else:</span>
<span class="gi">+                # for all-empty/NA, just take random geometry</span>
<span class="gi">+                geom = shapely.geometry.Point(0, 0)</span>
<span class="gi">+</span>
<span class="gi">+            geoms[mask] = geom</span>
<span class="gi">+        else:</span>
<span class="gi">+            geoms = self</span>
<span class="gi">+        if has_empty:</span>
<span class="gi">+            # in case we have empty geometries, we need to expand the total</span>
<span class="gi">+            # bounds with a small percentage, so the empties can be</span>
<span class="gi">+            # deterministically sorted first</span>
<span class="gi">+            total_bounds = geoms.total_bounds</span>
<span class="gi">+            xoff = (total_bounds[2] - total_bounds[0]) * 0.01</span>
<span class="gi">+            yoff = (total_bounds[3] - total_bounds[1]) * 0.01</span>
<span class="gi">+            total_bounds += np.array([-xoff, -yoff, xoff, yoff])</span>
<span class="gi">+        else:</span>
<span class="gi">+            total_bounds = None</span>
<span class="gi">+        distances = _hilbert_distance(geoms, total_bounds=total_bounds)</span>
<span class="gi">+        if has_empty:</span>
<span class="gi">+            # empty geometries are sorted first (&quot;smallest&quot;), so fill in</span>
<span class="gi">+            # smallest possible value for uints</span>
<span class="gi">+            distances[mask_empty] = 0</span>
<span class="gi">+        return distances</span>
<span class="gi">+</span>
<span class="gi">+    def argmin(self, skipna: bool = True) -&gt; int:</span>
<span class="gi">+        raise TypeError(&quot;geometries have no minimum or maximum&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def argmax(self, skipna: bool = True) -&gt; int:</span>
<span class="gi">+        raise TypeError(&quot;geometries have no minimum or maximum&quot;)</span>

<span class="w"> </span>    def _formatter(self, boxed=False):
<span class="w"> </span>        &quot;&quot;&quot;Formatting function for scalar values.
<span class="gu">@@ -677,7 +1589,37 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>            when ``boxed=False`` and :func:`str` is used when
<span class="w"> </span>            ``boxed=True``.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if boxed:</span>
<span class="gi">+            import geopandas</span>
<span class="gi">+</span>
<span class="gi">+            precision = geopandas.options.display_precision</span>
<span class="gi">+            if precision is None:</span>
<span class="gi">+                if self.crs:</span>
<span class="gi">+                    if self.crs.is_projected:</span>
<span class="gi">+                        precision = 3</span>
<span class="gi">+                    else:</span>
<span class="gi">+                        precision = 5</span>
<span class="gi">+                else:</span>
<span class="gi">+                    # fallback</span>
<span class="gi">+                    # dummy heuristic based on 10 first geometries that should</span>
<span class="gi">+                    # work in most cases</span>
<span class="gi">+                    with warnings.catch_warnings():</span>
<span class="gi">+                        warnings.simplefilter(&quot;ignore&quot;, category=RuntimeWarning)</span>
<span class="gi">+                        xmin, ymin, xmax, ymax = self[~self.isna()][:10].total_bounds</span>
<span class="gi">+                    if (</span>
<span class="gi">+                        (-180 &lt;= xmin &lt;= 180)</span>
<span class="gi">+                        and (-180 &lt;= xmax &lt;= 180)</span>
<span class="gi">+                        and (-90 &lt;= ymin &lt;= 90)</span>
<span class="gi">+                        and (-90 &lt;= ymax &lt;= 90)</span>
<span class="gi">+                    ):</span>
<span class="gi">+                        # geographic coordinates</span>
<span class="gi">+                        precision = 5</span>
<span class="gi">+                    else:</span>
<span class="gi">+                        # typically projected coordinates</span>
<span class="gi">+                        # (in case of unit meter: mm precision)</span>
<span class="gi">+                        precision = 3</span>
<span class="gi">+            return lambda geom: shapely.to_wkt(geom, rounding_precision=precision)</span>
<span class="gi">+        return repr</span>

<span class="w"> </span>    @classmethod
<span class="w"> </span>    def _concat_same_type(cls, to_concat):
<span class="gu">@@ -692,7 +1634,18 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>        -------
<span class="w"> </span>        ExtensionArray
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        data = np.concatenate([ga._data for ga in to_concat])</span>
<span class="gi">+        return GeometryArray(data, crs=_get_common_crs(to_concat))</span>
<span class="gi">+</span>
<span class="gi">+    def _reduce(self, name, skipna=True, **kwargs):</span>
<span class="gi">+        # including the base class version here (that raises by default)</span>
<span class="gi">+        # because this was not yet defined in pandas 0.23</span>
<span class="gi">+        if name in (&quot;any&quot;, &quot;all&quot;):</span>
<span class="gi">+            return getattr(to_shapely(self), name)()</span>
<span class="gi">+        raise TypeError(</span>
<span class="gi">+            f&quot;&#39;{type(self).__name__}&#39; with dtype {self.dtype} &quot;</span>
<span class="gi">+            f&quot;does not support reduction &#39;{name}&#39;&quot;</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def __array__(self, dtype=None, copy=None):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -702,10 +1655,37 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>        -------
<span class="w"> </span>        values : numpy array
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        if copy and (dtype is None or dtype == np.dtype(&#39;object&#39;)):</span>
<span class="gi">+        if copy and (dtype is None or dtype == np.dtype(&quot;object&quot;)):</span>
<span class="w"> </span>            return self._data.copy()
<span class="w"> </span>        return self._data

<span class="gi">+    def _binop(self, other, op):</span>
<span class="gi">+        def convert_values(param):</span>
<span class="gi">+            if not _is_scalar_geometry(param) and (</span>
<span class="gi">+                isinstance(param, ExtensionArray) or pd.api.types.is_list_like(param)</span>
<span class="gi">+            ):</span>
<span class="gi">+                ovalues = param</span>
<span class="gi">+            else:  # Assume its an object</span>
<span class="gi">+                ovalues = [param] * len(self)</span>
<span class="gi">+            return ovalues</span>
<span class="gi">+</span>
<span class="gi">+        if isinstance(other, (pd.Series, pd.Index, pd.DataFrame)):</span>
<span class="gi">+            # rely on pandas to unbox and dispatch to us</span>
<span class="gi">+            return NotImplemented</span>
<span class="gi">+</span>
<span class="gi">+        lvalues = self</span>
<span class="gi">+        rvalues = convert_values(other)</span>
<span class="gi">+</span>
<span class="gi">+        if len(lvalues) != len(rvalues):</span>
<span class="gi">+            raise ValueError(&quot;Lengths must match to compare&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        # If the operator is not defined for the underlying objects,</span>
<span class="gi">+        # a TypeError should be raised</span>
<span class="gi">+        res = [op(a, b) for (a, b) in zip(lvalues, rvalues)]</span>
<span class="gi">+</span>
<span class="gi">+        res = np.asarray(res, dtype=bool)</span>
<span class="gi">+        return res</span>
<span class="gi">+</span>
<span class="w"> </span>    def __eq__(self, other):
<span class="w"> </span>        return self._binop(other, operator.eq)

<span class="gu">@@ -717,9 +1697,64 @@ class GeometryArray(ExtensionArray):</span>
<span class="w"> </span>        Return for `item in self`.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        if isna(item):
<span class="gd">-            if item is self.dtype.na_value or isinstance(item, self.dtype.type</span>
<span class="gd">-                ) or item is None:</span>
<span class="gi">+            if (</span>
<span class="gi">+                item is self.dtype.na_value</span>
<span class="gi">+                or isinstance(item, self.dtype.type)</span>
<span class="gi">+                or item is None</span>
<span class="gi">+            ):</span>
<span class="w"> </span>                return self.isna().any()
<span class="w"> </span>            else:
<span class="w"> </span>                return False
<span class="w"> </span>        return (self == item).any()
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _get_common_crs(arr_seq):</span>
<span class="gi">+    # mask out all None arrays with no crs (most likely auto generated by pandas</span>
<span class="gi">+    # from concat with missing column)</span>
<span class="gi">+    arr_seq = [ga for ga in arr_seq if not (ga.isna().all() and ga.crs is None)]</span>
<span class="gi">+    # determine unique crs without using a set, because CRS hash can be different</span>
<span class="gi">+    # for objects with the same CRS</span>
<span class="gi">+    unique_crs = []</span>
<span class="gi">+    for arr in arr_seq:</span>
<span class="gi">+        if arr.crs not in unique_crs:</span>
<span class="gi">+            unique_crs.append(arr.crs)</span>
<span class="gi">+</span>
<span class="gi">+    crs_not_none = [crs for crs in unique_crs if crs is not None]</span>
<span class="gi">+    names = [crs.name for crs in crs_not_none]</span>
<span class="gi">+</span>
<span class="gi">+    if len(crs_not_none) == 0:</span>
<span class="gi">+        return None</span>
<span class="gi">+    if len(crs_not_none) == 1:</span>
<span class="gi">+        if len(unique_crs) != 1:</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                &quot;CRS not set for some of the concatenation inputs. &quot;</span>
<span class="gi">+                f&quot;Setting output&#39;s CRS as {names[0]} &quot;</span>
<span class="gi">+                &quot;(the single non-null crs provided).&quot;,</span>
<span class="gi">+                stacklevel=2,</span>
<span class="gi">+            )</span>
<span class="gi">+        return crs_not_none[0]</span>
<span class="gi">+</span>
<span class="gi">+    raise ValueError(</span>
<span class="gi">+        f&quot;Cannot determine common CRS for concatenation inputs, got {names}. &quot;</span>
<span class="gi">+        &quot;Use `to_crs()` to transform geometries to the same CRS before merging.&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def transform(data, func):</span>
<span class="gi">+    has_z = shapely.has_z(data)</span>
<span class="gi">+</span>
<span class="gi">+    result = np.empty_like(data)</span>
<span class="gi">+</span>
<span class="gi">+    coords = shapely.get_coordinates(data[~has_z], include_z=False)</span>
<span class="gi">+    new_coords_z = func(coords[:, 0], coords[:, 1])</span>
<span class="gi">+    result[~has_z] = shapely.set_coordinates(</span>
<span class="gi">+        data[~has_z].copy(), np.array(new_coords_z).T</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    coords_z = shapely.get_coordinates(data[has_z], include_z=True)</span>
<span class="gi">+    new_coords_z = func(coords_z[:, 0], coords_z[:, 1], coords_z[:, 2])</span>
<span class="gi">+    result[has_z] = shapely.set_coordinates(</span>
<span class="gi">+        data[has_z].copy(), np.array(new_coords_z).T</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    return result</span>
<span class="gh">diff --git a/geopandas/base.py b/geopandas/base.py</span>
<span class="gh">index a0f746e2..5e2729e2 100644</span>
<span class="gd">--- a/geopandas/base.py</span>
<span class="gi">+++ b/geopandas/base.py</span>
<span class="gu">@@ -1,11 +1,14 @@</span>
<span class="w"> </span>import warnings
<span class="w"> </span>from warnings import warn
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>import pandas as pd
<span class="w"> </span>from pandas import DataFrame, Series
<span class="gi">+</span>
<span class="w"> </span>import shapely
<span class="w"> </span>from shapely.geometry import MultiPoint, box
<span class="w"> </span>from shapely.geometry.base import BaseGeometry
<span class="gi">+</span>
<span class="w"> </span>from . import _compat as compat
<span class="w"> </span>from .array import GeometryArray, GeometryDtype, points_from_xy

<span class="gu">@@ -16,26 +19,108 @@ def is_geometry_type(data):</span>

<span class="w"> </span>    Does not include object array of shapely scalars.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(getattr(data, &quot;dtype&quot;, None), GeometryDtype):</span>
<span class="gi">+        # GeometryArray, GeoSeries and Series[GeometryArray]</span>
<span class="gi">+        return True</span>
<span class="gi">+    else:</span>
<span class="gi">+        return False</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _delegate_binary_method(op, this, other, align, *args, **kwargs):</span>
<span class="gi">+    # type: (str, GeoSeries, GeoSeries) -&gt; GeoSeries/Series</span>
<span class="gi">+    if align is None:</span>
<span class="gi">+        align = True</span>
<span class="gi">+        maybe_warn = True</span>
<span class="gi">+    else:</span>
<span class="gi">+        maybe_warn = False</span>
<span class="gi">+    this = this.geometry</span>
<span class="gi">+    if isinstance(other, GeoPandasBase):</span>
<span class="gi">+        if align and not this.index.equals(other.index):</span>
<span class="gi">+            if maybe_warn:</span>
<span class="gi">+                warn(</span>
<span class="gi">+                    &quot;The indices of the left and right GeoSeries&#39; are not equal, and &quot;</span>
<span class="gi">+                    &quot;therefore they will be aligned (reordering and/or introducing &quot;</span>
<span class="gi">+                    &quot;missing values) before executing the operation. If this alignment &quot;</span>
<span class="gi">+                    &quot;is the desired behaviour, you can silence this warning by passing &quot;</span>
<span class="gi">+                    &quot;&#39;align=True&#39;. If you don&#39;t want alignment and protect yourself of &quot;</span>
<span class="gi">+                    &quot;accidentally aligning, you can pass &#39;align=False&#39;.&quot;,</span>
<span class="gi">+                    stacklevel=4,</span>
<span class="gi">+                )</span>
<span class="gi">+            this, other = this.align(other.geometry)</span>
<span class="gi">+        else:</span>
<span class="gi">+            other = other.geometry</span>
<span class="gi">+</span>
<span class="gi">+        a_this = GeometryArray(this.values)</span>
<span class="gi">+        other = GeometryArray(other.values)</span>
<span class="gi">+    elif isinstance(other, BaseGeometry):</span>
<span class="gi">+        a_this = GeometryArray(this.values)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise TypeError(type(this), type(other))</span>
<span class="gi">+</span>
<span class="gi">+    data = getattr(a_this, op)(other, *args, **kwargs)</span>
<span class="gi">+    return data, this.index</span>


<span class="w"> </span>def _binary_geo(op, this, other, align, *args, **kwargs):
<span class="gi">+    # type: (str, GeoSeries, GeoSeries) -&gt; GeoSeries</span>
<span class="w"> </span>    &quot;&quot;&quot;Binary operation on GeoSeries objects that returns a GeoSeries&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from .geoseries import GeoSeries</span>
<span class="gi">+</span>
<span class="gi">+    geoms, index = _delegate_binary_method(op, this, other, align, *args, **kwargs)</span>
<span class="gi">+    return GeoSeries(geoms, index=index, crs=this.crs)</span>


<span class="w"> </span>def _binary_op(op, this, other, align, *args, **kwargs):
<span class="gi">+    # type: (str, GeoSeries, GeoSeries, args/kwargs) -&gt; Series[bool/float]</span>
<span class="w"> </span>    &quot;&quot;&quot;Binary operation on GeoSeries objects that returns a Series&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    data, index = _delegate_binary_method(op, this, other, align, *args, **kwargs)</span>
<span class="gi">+    return Series(data, index=index)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _delegate_property(op, this):</span>
<span class="gi">+    # type: (str, GeoSeries) -&gt; GeoSeries/Series</span>
<span class="gi">+    a_this = GeometryArray(this.geometry.values)</span>
<span class="gi">+    data = getattr(a_this, op)</span>
<span class="gi">+    if isinstance(data, GeometryArray):</span>
<span class="gi">+        from .geoseries import GeoSeries</span>
<span class="gi">+</span>
<span class="gi">+        return GeoSeries(data, index=this.index, crs=this.crs)</span>
<span class="gi">+    else:</span>
<span class="gi">+        return Series(data, index=this.index)</span>


<span class="w"> </span>def _delegate_geo_method(op, this, **kwargs):
<span class="gi">+    # type: (str, GeoSeries) -&gt; GeoSeries</span>
<span class="w"> </span>    &quot;&quot;&quot;Unary operation that returns a GeoSeries&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from .geodataframe import GeoDataFrame</span>
<span class="gi">+    from .geoseries import GeoSeries</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(this, GeoSeries):</span>
<span class="gi">+        klass, var_name = &quot;GeoSeries&quot;, &quot;gs&quot;</span>
<span class="gi">+    elif isinstance(this, GeoDataFrame):</span>
<span class="gi">+        klass, var_name = &quot;GeoDataFrame&quot;, &quot;gdf&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        klass, var_name = this.__class__.__name__, &quot;this&quot;</span>
<span class="gi">+</span>
<span class="gi">+    for key, val in kwargs.items():</span>
<span class="gi">+        if isinstance(val, pd.Series):</span>
<span class="gi">+            if not val.index.equals(this.index):</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    f&quot;Index of the Series passed as &#39;{key}&#39; does not match index of &quot;</span>
<span class="gi">+                    f&quot;the {klass}. If you want both Series to be aligned, align them &quot;</span>
<span class="gi">+                    f&quot;before passing them to this method as &quot;</span>
<span class="gi">+                    f&quot;`{var_name}, {key} = {var_name}.align({key})`. If &quot;</span>
<span class="gi">+                    f&quot;you want to ignore the index, pass the underlying array as &quot;</span>
<span class="gi">+                    f&quot;&#39;{key}&#39; using `{key}.values`.&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+            kwargs[key] = np.asarray(val)</span>
<span class="gi">+</span>
<span class="gi">+    a_this = GeometryArray(this.geometry.values)</span>
<span class="gi">+    data = getattr(a_this, op)(**kwargs)</span>
<span class="gi">+    return GeoSeries(data, index=this.index, crs=this.crs)</span>


<span class="w"> </span>class GeoPandasBase(object):
<span class="gd">-</span>
<span class="w"> </span>    @property
<span class="w"> </span>    def area(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` containing the area of each geometry in the
<span class="gu">@@ -83,7 +168,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        Every operation in GeoPandas is planar, i.e. the potential third
<span class="w"> </span>        dimension is not taken into account.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;area&quot;, self)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def crs(self):
<span class="gu">@@ -118,12 +203,12 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.set_crs : assign CRS
<span class="w"> </span>        GeoSeries.to_crs : re-project to another CRS
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.geometry.values.crs</span>

<span class="w"> </span>    @crs.setter
<span class="w"> </span>    def crs(self, value):
<span class="w"> </span>        &quot;&quot;&quot;Sets the value of the crs&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        self.geometry.values.crs = value</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def geom_type(self):
<span class="gu">@@ -143,12 +228,12 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        2    LineString
<span class="w"> </span>        dtype: object
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;geom_type&quot;, self)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def type(self):
<span class="w"> </span>        &quot;&quot;&quot;Return the geometry type of each geometry in the GeoSeries&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.geom_type</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def length(self):
<span class="gu">@@ -161,7 +246,8 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        Examples
<span class="w"> </span>        --------

<span class="gd">-        &gt;&gt;&gt; from shapely.geometry import Polygon, LineString, MultiLineString, Point, GeometryCollection</span>
<span class="gi">+        &gt;&gt;&gt; from shapely.geometry import Polygon, LineString, MultiLineString, Point, \</span>
<span class="gi">+GeometryCollection</span>
<span class="w"> </span>        &gt;&gt;&gt; s = geopandas.GeoSeries(
<span class="w"> </span>        ...     [
<span class="w"> </span>        ...         LineString([(0, 0), (1, 1), (0, 1)]),
<span class="gu">@@ -169,7 +255,8 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        ...         MultiLineString([((0, 0), (1, 0)), ((-1, 0), (1, 0))]),
<span class="w"> </span>        ...         Polygon([(0, 0), (1, 1), (0, 1)]),
<span class="w"> </span>        ...         Point(0, 1),
<span class="gd">-        ...         GeometryCollection([Point(1, 0), LineString([(10, 0), (10, 5), (0, 0)])])</span>
<span class="gi">+        ...         GeometryCollection([Point(1, 0), LineString([(10, 0), (10, 5), (0,\</span>
<span class="gi">+ 0)])])</span>
<span class="w"> </span>        ...     ]
<span class="w"> </span>        ... )
<span class="w"> </span>        &gt;&gt;&gt; s
<span class="gu">@@ -204,7 +291,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        dimension is not taken into account.

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;length&quot;, self)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def is_valid(self):
<span class="gu">@@ -244,7 +331,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.is_valid_reason : reason for invalidity
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;is_valid&quot;, self)</span>

<span class="w"> </span>    def is_valid_reason(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` of strings with the reason for invalidity of
<span class="gu">@@ -284,7 +371,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.is_valid : detect invalid geometries
<span class="w"> </span>        GeoSeries.make_valid : fix invalid geometries
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return Series(self.geometry.values.is_valid_reason(), index=self.index)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def is_empty(self):
<span class="gu">@@ -316,7 +403,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.isna : detect missing values
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;is_empty&quot;, self)</span>

<span class="w"> </span>    def count_coordinates(self):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -359,7 +446,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.get_coordinates : extract coordinates as a :class:`~pandas.DataFrame`
<span class="w"> </span>        GoSeries.count_geometries : count the number of geometries in a collection
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return Series(self.geometry.values.count_coordinates(), index=self.index)</span>

<span class="w"> </span>    def count_geometries(self):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -403,7 +490,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.count_coordinates : count the number of coordinates in a geometry
<span class="w"> </span>        GeoSeries.count_interior_rings : count the number of interior rings
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return Series(self.geometry.values.count_geometries(), index=self.index)</span>

<span class="w"> </span>    def count_interior_rings(self):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -448,7 +535,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.count_coordinates : count the number of coordinates in a geometry
<span class="w"> </span>        GeoSeries.count_geometries : count the number of geometries in a collection
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return Series(self.geometry.values.count_interior_rings(), index=self.index)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def is_simple(self):
<span class="gu">@@ -476,7 +563,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        1     True
<span class="w"> </span>        dtype: bool
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;is_simple&quot;, self)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def is_ring(self):
<span class="gu">@@ -511,7 +598,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        dtype: bool

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;is_ring&quot;, self)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def is_ccw(self):
<span class="gu">@@ -552,7 +639,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        3    False
<span class="w"> </span>        dtype: bool
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;is_ccw&quot;, self)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def is_closed(self):
<span class="gu">@@ -586,7 +673,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        3    False
<span class="w"> </span>        dtype: bool
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;is_closed&quot;, self)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def has_z(self):
<span class="gu">@@ -617,7 +704,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        1     True
<span class="w"> </span>        dtype: bool
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;has_z&quot;, self)</span>

<span class="w"> </span>    def get_precision(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` of the precision of each geometry.
<span class="gu">@@ -667,7 +754,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.set_precision : set precision grid size
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return Series(self.geometry.values.get_precision(), index=self.index)</span>

<span class="w"> </span>    def get_geometry(self, index):
<span class="w"> </span>        &quot;&quot;&quot;Returns the n-th geometry from a collection of geometries.
<span class="gu">@@ -723,7 +810,11 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        dtype: geometry

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(&quot;get_geometry&quot;, self, index=index)</span>
<span class="gi">+</span>
<span class="gi">+    #</span>
<span class="gi">+    # Unary operations that return a GeoSeries</span>
<span class="gi">+    #</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def boundary(self):
<span class="gu">@@ -758,7 +849,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.exterior : outer boundary (without interior rings)

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;boundary&quot;, self)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def centroid(self):
<span class="gu">@@ -794,7 +885,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.representative_point : point guaranteed to be within each geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;centroid&quot;, self)</span>

<span class="w"> </span>    def concave_hull(self, ratio=0.0, allow_holes=False):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` of geometries representing the concave hull
<span class="gu">@@ -856,7 +947,9 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.convex_hull : convex hull geometry

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(</span>
<span class="gi">+            &quot;concave_hull&quot;, self, ratio=ratio, allow_holes=allow_holes</span>
<span class="gi">+        )</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def convex_hull(self):
<span class="gu">@@ -903,7 +996,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.envelope : bounding rectangle geometry

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;convex_hull&quot;, self)</span>

<span class="w"> </span>    def delaunay_triangles(self, tolerance=0.0, only_edges=False):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` consisting of objects representing
<span class="gu">@@ -994,10 +1087,18 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.voronoi_polygons : Voronoi diagram around vertices
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from .geoseries import GeoSeries</span>

<span class="gd">-    def voronoi_polygons(self, tolerance=0.0, extend_to=None, only_edges=False</span>
<span class="gd">-        ):</span>
<span class="gi">+        geometry_input = shapely.geometrycollections(self.geometry.values._data)</span>
<span class="gi">+</span>
<span class="gi">+        delaunay = shapely.delaunay_triangles(</span>
<span class="gi">+            geometry_input,</span>
<span class="gi">+            tolerance=tolerance,</span>
<span class="gi">+            only_edges=only_edges,</span>
<span class="gi">+        )</span>
<span class="gi">+        return GeoSeries(delaunay, crs=self.crs).explode(ignore_index=True)</span>
<span class="gi">+</span>
<span class="gi">+    def voronoi_polygons(self, tolerance=0.0, extend_to=None, only_edges=False):</span>
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` consisting of objects representing
<span class="w"> </span>        the computed Voronoi diagram around the vertices of an input geometry.

<span class="gu">@@ -1110,7 +1211,18 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.delaunay_triangles : Delaunay triangulation around vertices
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from .geoseries import GeoSeries</span>
<span class="gi">+</span>
<span class="gi">+        geometry_input = shapely.geometrycollections(self.geometry.values._data)</span>
<span class="gi">+</span>
<span class="gi">+        voronoi = shapely.voronoi_polygons(</span>
<span class="gi">+            geometry_input,</span>
<span class="gi">+            tolerance=tolerance,</span>
<span class="gi">+            extend_to=extend_to,</span>
<span class="gi">+            only_edges=only_edges,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        return GeoSeries(voronoi, crs=self.crs).explode(ignore_index=True)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def envelope(self):
<span class="gu">@@ -1151,7 +1263,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.convex_hull : convex hull geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;envelope&quot;, self)</span>

<span class="w"> </span>    def minimum_rotated_rectangle(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` of the general minimum bounding rectangle
<span class="gu">@@ -1191,7 +1303,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.envelope : bounding rectangle
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(&quot;minimum_rotated_rectangle&quot;, self)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def exterior(self):
<span class="gu">@@ -1229,7 +1341,8 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.boundary : complete set-theoretic boundary
<span class="w"> </span>        GeoSeries.interiors : list of inner rings of each polygon
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # TODO: return empty geometry for non-polygons</span>
<span class="gi">+        return _delegate_property(&quot;exterior&quot;, self)</span>

<span class="w"> </span>    def extract_unique_points(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` of MultiPoints representing all
<span class="gu">@@ -1260,10 +1373,9 @@ class GeoPandasBase(object):</span>

<span class="w"> </span>        GeoSeries.get_coordinates : extract coordinates as a :class:`~pandas.DataFrame`
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(&quot;extract_unique_points&quot;, self)</span>

<span class="gd">-    def offset_curve(self, distance, quad_segs=8, join_style=&#39;round&#39;,</span>
<span class="gd">-        mitre_limit=5.0):</span>
<span class="gi">+    def offset_curve(self, distance, quad_segs=8, join_style=&quot;round&quot;, mitre_limit=5.0):</span>
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``LineString`` or ``MultiLineString`` geometry at a
<span class="w"> </span>        distance from the object on its right or its left side.

<span class="gu">@@ -1305,7 +1417,14 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        0    LINESTRING (-1 0, -1 1, -0.981 1.195, -0.924 1...
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(</span>
<span class="gi">+            &quot;offset_curve&quot;,</span>
<span class="gi">+            self,</span>
<span class="gi">+            distance=distance,</span>
<span class="gi">+            quad_segs=quad_segs,</span>
<span class="gi">+            join_style=join_style,</span>
<span class="gi">+            mitre_limit=mitre_limit,</span>
<span class="gi">+        )</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def interiors(self):
<span class="gu">@@ -1346,7 +1465,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.exterior : outer boundary
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;interiors&quot;, self)</span>

<span class="w"> </span>    def remove_repeated_points(self, tolerance=0.0):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` containing a copy of the input geometry
<span class="gu">@@ -1384,9 +1503,9 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        1    POLYGON ((0 0, 0 0.5, 0 1, 0.5 1, 0 0))
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(&quot;remove_repeated_points&quot;, self, tolerance=tolerance)</span>

<span class="gd">-    def set_precision(self, grid_size, mode=&#39;valid_output&#39;):</span>
<span class="gi">+    def set_precision(self, grid_size, mode=&quot;valid_output&quot;):</span>
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` with the precision set to a precision grid size.

<span class="w"> </span>        By default, geometries use double precision coordinates (``grid_size=0``).
<span class="gu">@@ -1471,7 +1590,9 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        :meth:`~GeoSeries.make_valid` methods.

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(</span>
<span class="gi">+            &quot;set_precision&quot;, self, grid_size=grid_size, mode=mode</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def representative_point(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` of (cheaply computed) points that are
<span class="gu">@@ -1504,7 +1625,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.centroid : geometric centroid
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(&quot;representative_point&quot;, self)</span>

<span class="w"> </span>    def minimum_bounding_circle(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` of geometries representing the minimum bounding
<span class="gu">@@ -1537,7 +1658,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.convex_hull : convex hull geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(&quot;minimum_bounding_circle&quot;, self)</span>

<span class="w"> </span>    def minimum_bounding_radius(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns a `Series` of the radii of the minimum bounding circles
<span class="gu">@@ -1570,7 +1691,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.minumum_bounding_circle : minimum bounding circle (geometry)

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return Series(self.geometry.values.minimum_bounding_radius(), index=self.index)</span>

<span class="w"> </span>    def minimum_clearance(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` containing the minimum clearance distance,
<span class="gu">@@ -1603,7 +1724,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        2         inf
<span class="w"> </span>        dtype: float64
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return Series(self.geometry.values.minimum_clearance(), index=self.index)</span>

<span class="w"> </span>    def normalize(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` of normalized
<span class="gu">@@ -1636,7 +1757,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        2                       POINT (0 0)
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(&quot;normalize&quot;, self)</span>

<span class="w"> </span>    def make_valid(self):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -1674,7 +1795,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        2                           LINESTRING (0 0, 1 1, 1 0)
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(&quot;make_valid&quot;, self)</span>

<span class="w"> </span>    def reverse(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` with the order of coordinates reversed.
<span class="gu">@@ -1706,7 +1827,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.normalize : normalize order of coordinates
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(&quot;reverse&quot;, self)</span>

<span class="w"> </span>    def segmentize(self, max_segment_length):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` with vertices added to line segments based on
<span class="gu">@@ -1746,7 +1867,9 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        1    POLYGON ((0 0, 5 0, 10 0, 10 5, 10 10, 5 10, 0...
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(</span>
<span class="gi">+            &quot;segmentize&quot;, self, max_segment_length=max_segment_length</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def transform(self, transformation, include_z=False):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` with the transformation function
<span class="gu">@@ -1786,7 +1909,9 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        0    POINT Z (1 1 1)
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(</span>
<span class="gi">+            &quot;transform&quot;, self, transformation=transformation, include_z=include_z</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def force_2d(self):
<span class="w"> </span>        &quot;&quot;&quot;Forces the dimensionality of a geometry to 2D.
<span class="gu">@@ -1819,7 +1944,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        2    POLYGON ((0 0, 0 10, 10 10, 0 0))
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(&quot;force_2d&quot;, self)</span>

<span class="w"> </span>    def force_3d(self, z=0):
<span class="w"> </span>        &quot;&quot;&quot;Forces the dimensionality of a geometry to 3D.
<span class="gu">@@ -1882,7 +2007,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        3    POLYGON Z ((0 0 3, 0 10 3, 10 10 3, 0 0 3))
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(&quot;force_3d&quot;, self, z=z)</span>

<span class="w"> </span>    def line_merge(self, directed=False):
<span class="w"> </span>        &quot;&quot;&quot;Returns (Multi)LineStrings formed by combining the lines in a
<span class="gu">@@ -1949,7 +2074,11 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        4                       GEOMETRYCOLLECTION EMPTY
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(&quot;line_merge&quot;, self, directed=directed)</span>
<span class="gi">+</span>
<span class="gi">+    #</span>
<span class="gi">+    # Reduction operations that return a Shapely geometry</span>
<span class="gi">+    #</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def unary_union(self):
<span class="gu">@@ -1977,9 +2106,17 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.union_all
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>

<span class="gd">-    def union_all(self, method=&#39;unary&#39;):</span>
<span class="gi">+        warn(</span>
<span class="gi">+            &quot;The &#39;unary_union&#39; attribute is deprecated, &quot;</span>
<span class="gi">+            &quot;use the &#39;union_all()&#39; method instead.&quot;,</span>
<span class="gi">+            DeprecationWarning,</span>
<span class="gi">+            stacklevel=2,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        return self.geometry.values.union_all()</span>
<span class="gi">+</span>
<span class="gi">+    def union_all(self, method=&quot;unary&quot;):</span>
<span class="w"> </span>        &quot;&quot;&quot;Returns a geometry containing the union of all geometries in the
<span class="w"> </span>        ``GeoSeries``.

<span class="gu">@@ -2012,7 +2149,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        &gt;&gt;&gt; s.union_all()
<span class="w"> </span>        &lt;POLYGON ((0 1, 0 2, 2 2, 2 0, 1 0, 0 0, 0 1))&gt;
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.geometry.values.union_all(method=method)</span>

<span class="w"> </span>    def intersection_all(self):
<span class="w"> </span>        &quot;&quot;&quot;Returns a geometry containing the intersection of all geometries in
<span class="gu">@@ -2038,7 +2175,11 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        &gt;&gt;&gt; s.intersection_all()
<span class="w"> </span>        &lt;POLYGON ((1 1, 1 1.5, 1.5 1.5, 1.5 1, 1 1))&gt;
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.geometry.values.intersection_all()</span>
<span class="gi">+</span>
<span class="gi">+    #</span>
<span class="gi">+    # Binary operations that return a pandas Series</span>
<span class="gi">+    #</span>

<span class="w"> </span>    def contains(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` of ``dtype(&#39;bool&#39;)`` with value ``True`` for
<span class="gu">@@ -2154,7 +2295,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.contains_properly
<span class="w"> </span>        GeoSeries.within
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;contains&quot;, self, other, align)</span>

<span class="w"> </span>    def contains_properly(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` of ``dtype(&#39;bool&#39;)`` with value ``True`` for
<span class="gu">@@ -2275,7 +2416,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.contains
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;contains_properly&quot;, self, other, align)</span>

<span class="w"> </span>    def dwithin(self, other, distance, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` of ``dtype(&#39;bool&#39;)`` with value ``True`` for
<span class="gu">@@ -2386,7 +2527,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.within
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;dwithin&quot;, self, other, distance=distance, align=align)</span>

<span class="w"> </span>    def geom_equals(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` of ``dtype(&#39;bool&#39;)`` with value ``True`` for
<span class="gu">@@ -2496,7 +2637,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.geom_equals_exact

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;geom_equals&quot;, self, other, align)</span>

<span class="w"> </span>    def geom_almost_equals(self, other, decimal=6, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` of ``dtype(&#39;bool&#39;)`` with value ``True`` if
<span class="gu">@@ -2564,7 +2705,16 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.geom_equals_exact

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        warnings.warn(</span>
<span class="gi">+            &quot;The &#39;geom_almost_equals()&#39; method is deprecated because the name is &quot;</span>
<span class="gi">+            &quot;confusing. The &#39;geom_equals_exact()&#39; method should be used instead.&quot;,</span>
<span class="gi">+            FutureWarning,</span>
<span class="gi">+            stacklevel=2,</span>
<span class="gi">+        )</span>
<span class="gi">+        tolerance = 0.5 * 10 ** (-decimal)</span>
<span class="gi">+        return _binary_op(</span>
<span class="gi">+            &quot;geom_equals_exact&quot;, self, other, tolerance=tolerance, align=align</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def geom_equals_exact(self, other, tolerance, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Return True for all geometries that equal aligned *other* to a given
<span class="gu">@@ -2627,7 +2777,9 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.geom_equals
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(</span>
<span class="gi">+            &quot;geom_equals_exact&quot;, self, other, tolerance=tolerance, align=align</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def crosses(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` of ``dtype(&#39;bool&#39;)`` with value ``True`` for
<span class="gu">@@ -2739,7 +2891,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.intersects

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;crosses&quot;, self, other, align)</span>

<span class="w"> </span>    def disjoint(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` of ``dtype(&#39;bool&#39;)`` with value ``True`` for
<span class="gu">@@ -2840,7 +2992,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.touches

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;disjoint&quot;, self, other, align)</span>

<span class="w"> </span>    def intersects(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` of ``dtype(&#39;bool&#39;)`` with value ``True`` for
<span class="gu">@@ -2951,7 +3103,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.touches
<span class="w"> </span>        GeoSeries.intersection
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;intersects&quot;, self, other, align)</span>

<span class="w"> </span>    def overlaps(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns True for all aligned geometries that overlap *other*, else False.
<span class="gu">@@ -3062,7 +3214,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.intersects

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;overlaps&quot;, self, other, align)</span>

<span class="w"> </span>    def touches(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` of ``dtype(&#39;bool&#39;)`` with value ``True`` for
<span class="gu">@@ -3174,7 +3326,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.intersects

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;touches&quot;, self, other, align)</span>

<span class="w"> </span>    def within(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` of ``dtype(&#39;bool&#39;)`` with value ``True`` for
<span class="gu">@@ -3288,7 +3440,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.contains
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;within&quot;, self, other, align)</span>

<span class="w"> </span>    def covers(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -3402,7 +3554,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.covered_by
<span class="w"> </span>        GeoSeries.overlaps
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;covers&quot;, self, other, align)</span>

<span class="w"> </span>    def covered_by(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -3516,7 +3668,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.covers
<span class="w"> </span>        GeoSeries.overlaps
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;covered_by&quot;, self, other, align)</span>

<span class="w"> </span>    def distance(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` containing the distance to aligned `other`.
<span class="gu">@@ -3612,7 +3764,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        3    1.000000
<span class="w"> </span>        dtype: float64
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;distance&quot;, self, other, align)</span>

<span class="w"> </span>    def hausdorff_distance(self, other, align=None, densify=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` containing the Hausdorff distance to aligned `other`.
<span class="gu">@@ -3727,7 +3879,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        0    70.0
<span class="w"> </span>        dtype: float64
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;hausdorff_distance&quot;, self, other, align, densify=densify)</span>

<span class="w"> </span>    def frechet_distance(self, other, align=None, densify=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``Series`` containing the Frechet distance to aligned `other`.
<span class="gu">@@ -3847,7 +3999,11 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        0    16.77051
<span class="w"> </span>        dtype: float64
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;frechet_distance&quot;, self, other, align, densify=densify)</span>
<span class="gi">+</span>
<span class="gi">+    #</span>
<span class="gi">+    # Binary operations that return a GeoSeries</span>
<span class="gi">+    #</span>

<span class="w"> </span>    def difference(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` of the points in each aligned geometry that
<span class="gu">@@ -3958,7 +4114,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.union
<span class="w"> </span>        GeoSeries.intersection
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_geo(&quot;difference&quot;, self, other, align)</span>

<span class="w"> </span>    def symmetric_difference(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` of the symmetric difference of points in
<span class="gu">@@ -4073,7 +4229,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.union
<span class="w"> </span>        GeoSeries.intersection
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_geo(&quot;symmetric_difference&quot;, self, other, align)</span>

<span class="w"> </span>    def union(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` of the union of points in each aligned geometry with
<span class="gu">@@ -4187,7 +4343,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.difference
<span class="w"> </span>        GeoSeries.intersection
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_geo(&quot;union&quot;, self, other, align)</span>

<span class="w"> </span>    def intersection(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` of the intersection of points in each
<span class="gu">@@ -4300,7 +4456,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        GeoSeries.symmetric_difference
<span class="w"> </span>        GeoSeries.union
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_geo(&quot;intersection&quot;, self, other, align)</span>

<span class="w"> </span>    def clip_by_rect(self, xmin, ymin, xmax, ymax):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` of the portions of geometry within the given
<span class="gu">@@ -4365,7 +4521,11 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.intersection
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from .geoseries import GeoSeries</span>
<span class="gi">+</span>
<span class="gi">+        geometry_array = GeometryArray(self.geometry.values)</span>
<span class="gi">+        clipped_geometry = geometry_array.clip_by_rect(xmin, ymin, xmax, ymax)</span>
<span class="gi">+        return GeoSeries(clipped_geometry, index=self.index, crs=self.crs)</span>

<span class="w"> </span>    def shortest_line(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -4468,7 +4628,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        4            LINESTRING (0 1, 0 1)
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_geo(&quot;shortest_line&quot;, self, other, align)</span>

<span class="w"> </span>    def snap(self, other, tolerance, align=None):
<span class="w"> </span>        &quot;&quot;&quot;Snaps an input geometry to reference geometry&#39;s vertices.
<span class="gu">@@ -4569,7 +4729,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        2    POLYGON ((0 0, 0 10, 8 10, 10 10, 10 0, 0 0))
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_geo(&quot;snap&quot;, self, other, align, tolerance=tolerance)</span>

<span class="w"> </span>    def shared_paths(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -4667,7 +4827,12 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.get_geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+</span>
<span class="gi">+        return _binary_geo(&quot;shared_paths&quot;, self, other, align)</span>
<span class="gi">+</span>
<span class="gi">+    #</span>
<span class="gi">+    # Other operations</span>
<span class="gi">+    #</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def bounds(self):
<span class="gu">@@ -4698,7 +4863,10 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        1  POLYGON ((0 0, 1 1, 1 0, 0 0))   0.0   0.0   1.0   1.0
<span class="w"> </span>        2           LINESTRING (0 1, 1 2)   0.0   1.0   1.0   2.0
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        bounds = GeometryArray(self.geometry.values).bounds</span>
<span class="gi">+        return DataFrame(</span>
<span class="gi">+            bounds, columns=[&quot;minx&quot;, &quot;miny&quot;, &quot;maxx&quot;, &quot;maxy&quot;], index=self.index</span>
<span class="gi">+        )</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def total_bounds(self):
<span class="gu">@@ -4717,7 +4885,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        &gt;&gt;&gt; gdf.total_bounds
<span class="w"> </span>        array([ 0., -1.,  3.,  2.])
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return GeometryArray(self.geometry.values).total_bounds</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def sindex(self):
<span class="gu">@@ -4769,7 +4937,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        array([[0],
<span class="w"> </span>               [2]])
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.geometry.values.sindex</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def has_sindex(self):
<span class="gu">@@ -4801,10 +4969,18 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>            `True` if the spatial index has been generated or
<span class="w"> </span>            `False` if not.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def buffer(self, distance, resolution=16, cap_style=&#39;round&#39;, join_style</span>
<span class="gd">-        =&#39;round&#39;, mitre_limit=5.0, single_sided=False, **kwargs):</span>
<span class="gi">+        return self.geometry.values.has_sindex</span>
<span class="gi">+</span>
<span class="gi">+    def buffer(</span>
<span class="gi">+        self,</span>
<span class="gi">+        distance,</span>
<span class="gi">+        resolution=16,</span>
<span class="gi">+        cap_style=&quot;round&quot;,</span>
<span class="gi">+        join_style=&quot;round&quot;,</span>
<span class="gi">+        mitre_limit=5.0,</span>
<span class="gi">+        single_sided=False,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` of geometries representing all points within
<span class="w"> </span>        a given ``distance`` of each geometric object.

<span class="gu">@@ -4869,7 +5045,17 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        .. plot:: _static/code/buffer.py

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(</span>
<span class="gi">+            &quot;buffer&quot;,</span>
<span class="gi">+            self,</span>
<span class="gi">+            distance=distance,</span>
<span class="gi">+            resolution=resolution,</span>
<span class="gi">+            cap_style=cap_style,</span>
<span class="gi">+            join_style=join_style,</span>
<span class="gi">+            mitre_limit=mitre_limit,</span>
<span class="gi">+            single_sided=single_sided,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def simplify(self, tolerance, preserve_topology=True):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` containing a simplified representation of
<span class="gu">@@ -4919,7 +5105,9 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        1              LINESTRING (0 0, 0 20)
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(</span>
<span class="gi">+            &quot;simplify&quot;, self, tolerance=tolerance, preserve_topology=preserve_topology</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def relate(self, other, align=None):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -5024,7 +5212,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        dtype: object

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;relate&quot;, self, other, align)</span>

<span class="w"> </span>    def relate_pattern(self, other, pattern, align=None):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -5136,7 +5324,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        dtype: bool

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;relate_pattern&quot;, self, other, pattern=pattern, align=align)</span>

<span class="w"> </span>    def project(self, other, normalized=False, align=None):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -5235,7 +5423,7 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.interpolate
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _binary_op(&quot;project&quot;, self, other, normalized=normalized, align=align)</span>

<span class="w"> </span>    def interpolate(self, distance, normalized=False):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -5279,7 +5467,9 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        2                POINT (0 2)
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(</span>
<span class="gi">+            &quot;interpolate&quot;, self, distance=distance, normalized=normalized</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def affine_transform(self, matrix):
<span class="w"> </span>        &quot;&quot;&quot;Return a ``GeoSeries`` with translated geometries.
<span class="gu">@@ -5320,8 +5510,8 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        2    POLYGON ((8 4, 13 10, 14 12, 8 4))
<span class="w"> </span>        dtype: geometry

<span class="gd">-        &quot;&quot;&quot;</span>
<span class="gd">-        pass</span>
<span class="gi">+        &quot;&quot;&quot;  # (E501 link is longer than max line length)</span>
<span class="gi">+        return _delegate_geo_method(&quot;affine_transform&quot;, self, matrix=matrix)</span>

<span class="w"> </span>    def translate(self, xoff=0.0, yoff=0.0, zoff=0.0):
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` with translated geometries.
<span class="gu">@@ -5358,10 +5548,10 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        2    POLYGON ((5 2, 6 3, 5 4, 5 2))
<span class="w"> </span>        dtype: geometry

<span class="gd">-        &quot;&quot;&quot;</span>
<span class="gd">-        pass</span>
<span class="gi">+        &quot;&quot;&quot;  # (E501 link is longer than max line length)</span>
<span class="gi">+        return _delegate_geo_method(&quot;translate&quot;, self, xoff=xoff, yoff=yoff, zoff=zoff)</span>

<span class="gd">-    def rotate(self, angle, origin=&#39;center&#39;, use_radians=False):</span>
<span class="gi">+    def rotate(self, angle, origin=&quot;center&quot;, use_radians=False):</span>
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` with rotated geometries.

<span class="w"> </span>        See http://shapely.readthedocs.io/en/latest/manual.html#shapely.affinity.rotate
<span class="gu">@@ -5409,9 +5599,11 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        dtype: geometry

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(</span>
<span class="gi">+            &quot;rotate&quot;, self, angle=angle, origin=origin, use_radians=use_radians</span>
<span class="gi">+        )</span>

<span class="gd">-    def scale(self, xfact=1.0, yfact=1.0, zfact=1.0, origin=&#39;center&#39;):</span>
<span class="gi">+    def scale(self, xfact=1.0, yfact=1.0, zfact=1.0, origin=&quot;center&quot;):</span>
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` with scaled geometries.

<span class="w"> </span>        The geometries can be scaled by different factors along each
<span class="gu">@@ -5457,9 +5649,11 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        2    POLYGON ((6 -3, 8 0, 6 3, 6 -3))
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(</span>
<span class="gi">+            &quot;scale&quot;, self, xfact=xfact, yfact=yfact, zfact=zfact, origin=origin</span>
<span class="gi">+        )</span>

<span class="gd">-    def skew(self, xs=0.0, ys=0.0, origin=&#39;center&#39;, use_radians=False):</span>
<span class="gi">+    def skew(self, xs=0.0, ys=0.0, origin=&quot;center&quot;, use_radians=False):</span>
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` with skewed geometries.

<span class="w"> </span>        The geometries are sheared by angles along the x and y dimensions.
<span class="gu">@@ -5508,7 +5702,9 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        2    POLYGON ((2 0.73205, 4 2.3094, 4 2.73205, 2 0....
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_geo_method(</span>
<span class="gi">+            &quot;skew&quot;, self, xs=xs, ys=ys, origin=origin, use_radians=use_radians</span>
<span class="gi">+        )</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def cx(self):
<span class="gu">@@ -5545,10 +5741,9 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        dtype: geometry

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _CoordinateIndexer(self)</span>

<span class="gd">-    def get_coordinates(self, include_z=False, ignore_index=False,</span>
<span class="gd">-        index_parts=False):</span>
<span class="gi">+    def get_coordinates(self, include_z=False, ignore_index=False, index_parts=False):</span>
<span class="w"> </span>        &quot;&quot;&quot;Gets coordinates from a :class:`GeoSeries` as a :class:`~pandas.DataFrame` of
<span class="w"> </span>        floats.

<span class="gu">@@ -5619,7 +5814,22 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>          2  3.0  1.0
<span class="w"> </span>          3  3.0 -1.0
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        coords, outer_idx = shapely.get_coordinates(</span>
<span class="gi">+            self.geometry.values._data, include_z=include_z, return_index=True</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        column_names = [&quot;x&quot;, &quot;y&quot;]</span>
<span class="gi">+        if include_z:</span>
<span class="gi">+            column_names.append(&quot;z&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        index = _get_index_for_parts(</span>
<span class="gi">+            self.index,</span>
<span class="gi">+            outer_idx,</span>
<span class="gi">+            ignore_index=ignore_index,</span>
<span class="gi">+            index_parts=index_parts,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        return pd.DataFrame(coords, index=index, columns=column_names)</span>

<span class="w"> </span>    def hilbert_distance(self, total_bounds=None, level=16):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -5647,10 +5857,15 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        Series
<span class="w"> </span>            Series containing distance along the curve for geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from geopandas.tools.hilbert_curve import _hilbert_distance</span>
<span class="gi">+</span>
<span class="gi">+        distances = _hilbert_distance(</span>
<span class="gi">+            self.geometry.values, total_bounds=total_bounds, level=level</span>
<span class="gi">+        )</span>

<span class="gd">-    def sample_points(self, size, method=&#39;uniform&#39;, seed=None, rng=None, **</span>
<span class="gd">-        kwargs):</span>
<span class="gi">+        return pd.Series(distances, index=self.index, name=&quot;hilbert_distance&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def sample_points(self, size, method=&quot;uniform&quot;, seed=None, rng=None, **kwargs):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Sample points from each geometry.

<span class="gu">@@ -5706,8 +5921,50 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        0    MULTIPOINT ((0.1045 -0.10294), (0.35249 -0.264...
<span class="w"> </span>        1    MULTIPOINT ((3.03261 -0.43069), (3.10068 0.114...
<span class="w"> </span>        Name: sampled_points, dtype: geometry
<span class="gd">-        &quot;&quot;&quot;</span>
<span class="gd">-        pass</span>
<span class="gi">+        &quot;&quot;&quot;  # noqa: E501</span>
<span class="gi">+        from .geoseries import GeoSeries</span>
<span class="gi">+        from .tools._random import uniform</span>
<span class="gi">+</span>
<span class="gi">+        if seed is not None:</span>
<span class="gi">+            warn(</span>
<span class="gi">+                &quot;The &#39;seed&#39; keyword is deprecated. Use &#39;rng&#39; instead.&quot;,</span>
<span class="gi">+                FutureWarning,</span>
<span class="gi">+                stacklevel=2,</span>
<span class="gi">+            )</span>
<span class="gi">+            rng = seed</span>
<span class="gi">+</span>
<span class="gi">+        if method == &quot;uniform&quot;:</span>
<span class="gi">+            if pd.api.types.is_list_like(size):</span>
<span class="gi">+                result = [uniform(geom, s, rng) for geom, s in zip(self.geometry, size)]</span>
<span class="gi">+            else:</span>
<span class="gi">+                result = self.geometry.apply(uniform, size=size, rng=rng)</span>
<span class="gi">+</span>
<span class="gi">+        else:</span>
<span class="gi">+            pointpats = compat.import_optional_dependency(</span>
<span class="gi">+                &quot;pointpats&quot;,</span>
<span class="gi">+                f&quot;For complex sampling methods, the pointpats module is required. &quot;</span>
<span class="gi">+                f&quot;Your requested method, &#39;{method}&#39; was not a supported option &quot;</span>
<span class="gi">+                f&quot;and the pointpats package was not able to be imported.&quot;,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            if not hasattr(pointpats.random, method):</span>
<span class="gi">+                raise AttributeError(</span>
<span class="gi">+                    f&quot;pointpats.random module has no sampling method {method}.&quot;</span>
<span class="gi">+                    f&quot;Consult the pointpats.random module documentation for&quot;</span>
<span class="gi">+                    f&quot; available random sampling methods.&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+            sample_function = getattr(pointpats.random, method)</span>
<span class="gi">+            result = self.geometry.apply(</span>
<span class="gi">+                lambda x: (</span>
<span class="gi">+                    points_from_xy(</span>
<span class="gi">+                        *sample_function(x, size=size, **kwargs).T</span>
<span class="gi">+                    ).union_all()</span>
<span class="gi">+                    if not (x.is_empty or x is None or &quot;Polygon&quot; not in x.geom_type)</span>
<span class="gi">+                    else MultiPoint()</span>
<span class="gi">+                ),</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        return GeoSeries(result, name=&quot;sampled_points&quot;, crs=self.crs, index=self.index)</span>

<span class="w"> </span>    def build_area(self, node=True):
<span class="w"> </span>        &quot;&quot;&quot;Creates an areal geometry formed by the constituent linework.
<span class="gu">@@ -5758,7 +6015,17 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        Name: polygons, dtype: geometry

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from .geoseries import GeoSeries</span>
<span class="gi">+</span>
<span class="gi">+        if node:</span>
<span class="gi">+            geometry_input = self.geometry.union_all()</span>
<span class="gi">+        else:</span>
<span class="gi">+            geometry_input = shapely.geometrycollections(self.geometry.values._data)</span>
<span class="gi">+</span>
<span class="gi">+        polygons = shapely.build_area(geometry_input)</span>
<span class="gi">+        return GeoSeries(polygons, crs=self.crs, name=&quot;polygons&quot;).explode(</span>
<span class="gi">+            ignore_index=True</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def polygonize(self, node=True, full=False):
<span class="w"> </span>        &quot;&quot;&quot;Creates polygons formed from the linework of a GeoSeries.
<span class="gu">@@ -5817,7 +6084,35 @@ class GeoPandasBase(object):</span>
<span class="w"> </span>        &gt;&gt;&gt; polygons, cuts, dangles, invalid = s.polygonize(full=True)

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from .geoseries import GeoSeries</span>
<span class="gi">+</span>
<span class="gi">+        if node:</span>
<span class="gi">+            geometry_input = [self.geometry.union_all()]</span>
<span class="gi">+        else:</span>
<span class="gi">+            geometry_input = self.geometry.values</span>
<span class="gi">+</span>
<span class="gi">+        if full:</span>
<span class="gi">+            polygons, cuts, dangles, invalid = shapely.polygonize_full(geometry_input)</span>
<span class="gi">+</span>
<span class="gi">+            cuts = GeoSeries(cuts, crs=self.crs, name=&quot;cut_edges&quot;).explode(</span>
<span class="gi">+                ignore_index=True</span>
<span class="gi">+            )</span>
<span class="gi">+            dangles = GeoSeries(dangles, crs=self.crs, name=&quot;dangles&quot;).explode(</span>
<span class="gi">+                ignore_index=True</span>
<span class="gi">+            )</span>
<span class="gi">+            invalid = GeoSeries(invalid, crs=self.crs, name=&quot;invalid_rings&quot;).explode(</span>
<span class="gi">+                ignore_index=True</span>
<span class="gi">+            )</span>
<span class="gi">+            polygons = GeoSeries(polygons, crs=self.crs, name=&quot;polygons&quot;).explode(</span>
<span class="gi">+                ignore_index=True</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            return (polygons, cuts, dangles, invalid)</span>
<span class="gi">+</span>
<span class="gi">+        polygons = shapely.polygonize(geometry_input)</span>
<span class="gi">+        return GeoSeries(polygons, crs=self.crs, name=&quot;polygons&quot;).explode(</span>
<span class="gi">+            ignore_index=True</span>
<span class="gi">+        )</span>


<span class="w"> </span>def _get_index_for_parts(orig_idx, outer_idx, ignore_index, index_parts):
<span class="gu">@@ -5839,10 +6134,44 @@ def _get_index_for_parts(orig_idx, outer_idx, ignore_index, index_parts):</span>
<span class="w"> </span>    pandas.Index
<span class="w"> </span>        index or multiindex
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    if ignore_index:</span>
<span class="gi">+        return None</span>
<span class="gi">+    else:</span>
<span class="gi">+        if len(outer_idx):</span>
<span class="gi">+            # Generate inner index as a range per value of outer_idx</span>
<span class="gi">+            # 1. identify the start of each run of values in outer_idx</span>
<span class="gi">+            # 2. count number of values per run</span>
<span class="gi">+            # 3. use cumulative sums to create an incremental range</span>
<span class="gi">+            #    starting at 0 in each run</span>
<span class="gi">+            run_start = np.r_[True, outer_idx[:-1] != outer_idx[1:]]</span>
<span class="gi">+            counts = np.diff(np.r_[np.nonzero(run_start)[0], len(outer_idx)])</span>
<span class="gi">+            inner_index = (~run_start).cumsum(dtype=outer_idx.dtype)</span>
<span class="gi">+            inner_index -= np.repeat(inner_index[run_start], counts)</span>
<span class="gi">+</span>
<span class="gi">+        else:</span>
<span class="gi">+            inner_index = []</span>
<span class="gi">+</span>
<span class="gi">+        # extract original index values based on integer index</span>
<span class="gi">+        outer_index = orig_idx.take(outer_idx)</span>
<span class="gi">+</span>
<span class="gi">+        if index_parts:</span>
<span class="gi">+            nlevels = outer_index.nlevels</span>
<span class="gi">+            index_arrays = [outer_index.get_level_values(lvl) for lvl in range(nlevels)]</span>
<span class="gi">+            index_arrays.append(inner_index)</span>
<span class="gi">+</span>
<span class="gi">+            index = pd.MultiIndex.from_arrays(</span>
<span class="gi">+                index_arrays, names=list(orig_idx.names) + [None]</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        else:</span>
<span class="gi">+            index = outer_index</span>
<span class="gi">+</span>
<span class="gi">+    return index</span>


<span class="w"> </span>class _CoordinateIndexer(object):
<span class="gi">+    # see docstring GeoPandasBase.cx property above</span>

<span class="w"> </span>    def __init__(self, obj):
<span class="w"> </span>        self.obj = obj
<span class="gu">@@ -5850,17 +6179,24 @@ class _CoordinateIndexer(object):</span>
<span class="w"> </span>    def __getitem__(self, key):
<span class="w"> </span>        obj = self.obj
<span class="w"> </span>        xs, ys = key
<span class="gi">+        # handle numeric values as x and/or y coordinate index</span>
<span class="w"> </span>        if type(xs) is not slice:
<span class="w"> </span>            xs = slice(xs, xs)
<span class="w"> </span>        if type(ys) is not slice:
<span class="w"> </span>            ys = slice(ys, ys)
<span class="gi">+        # don&#39;t know how to handle step; should this raise?</span>
<span class="w"> </span>        if xs.step is not None or ys.step is not None:
<span class="gd">-            warn(&#39;Ignoring step - full interval is used.&#39;, stacklevel=2)</span>
<span class="gd">-        if (xs.start is None or xs.stop is None or ys.start is None or ys.</span>
<span class="gd">-            stop is None):</span>
<span class="gi">+            warn(</span>
<span class="gi">+                &quot;Ignoring step - full interval is used.&quot;,</span>
<span class="gi">+                stacklevel=2,</span>
<span class="gi">+            )</span>
<span class="gi">+        if xs.start is None or xs.stop is None or ys.start is None or ys.stop is None:</span>
<span class="w"> </span>            xmin, ymin, xmax, ymax = obj.total_bounds
<span class="gd">-        bbox = box(xs.start if xs.start is not None else xmin, ys.start if </span>
<span class="gd">-            ys.start is not None else ymin, xs.stop if xs.stop is not None else</span>
<span class="gd">-            xmax, ys.stop if ys.stop is not None else ymax)</span>
<span class="gi">+        bbox = box(</span>
<span class="gi">+            xs.start if xs.start is not None else xmin,</span>
<span class="gi">+            ys.start if ys.start is not None else ymin,</span>
<span class="gi">+            xs.stop if xs.stop is not None else xmax,</span>
<span class="gi">+            ys.stop if ys.stop is not None else ymax,</span>
<span class="gi">+        )</span>
<span class="w"> </span>        idx = obj.intersects(bbox)
<span class="w"> </span>        return obj[idx]
<span class="gh">diff --git a/geopandas/explore.py b/geopandas/explore.py</span>
<span class="gh">index dbf38bd5..652dd6dd 100644</span>
<span class="gd">--- a/geopandas/explore.py</span>
<span class="gi">+++ b/geopandas/explore.py</span>
<span class="gu">@@ -1,24 +1,70 @@</span>
<span class="w"> </span>import warnings
<span class="w"> </span>from packaging.version import Version
<span class="w"> </span>from statistics import mean
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>import pandas as pd
<span class="w"> </span>from pandas.api.types import is_datetime64_any_dtype
<span class="gi">+</span>
<span class="w"> </span>from shapely.geometry import LineString
<span class="gi">+</span>
<span class="w"> </span>import geopandas
<span class="gd">-_MAP_KWARGS = [&#39;location&#39;, &#39;prefer_canvas&#39;, &#39;no_touch&#39;, &#39;disable_3d&#39;,</span>
<span class="gd">-    &#39;png_enabled&#39;, &#39;zoom_control&#39;, &#39;crs&#39;, &#39;zoom_start&#39;, &#39;left&#39;, &#39;top&#39;,</span>
<span class="gd">-    &#39;position&#39;, &#39;min_zoom&#39;, &#39;max_zoom&#39;, &#39;min_lat&#39;, &#39;max_lat&#39;, &#39;min_lon&#39;,</span>
<span class="gd">-    &#39;max_lon&#39;, &#39;max_bounds&#39;]</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def _explore(df, column=None, cmap=None, color=None, m=None, tiles=</span>
<span class="gd">-    &#39;OpenStreetMap&#39;, attr=None, tooltip=True, popup=False, highlight=True,</span>
<span class="gd">-    categorical=False, legend=True, scheme=None, k=5, vmin=None, vmax=None,</span>
<span class="gd">-    width=&#39;100%&#39;, height=&#39;100%&#39;, categories=None, classification_kwds=None,</span>
<span class="gd">-    control_scale=True, marker_type=None, marker_kwds={}, style_kwds={},</span>
<span class="gd">-    highlight_kwds={}, missing_kwds={}, tooltip_kwds={}, popup_kwds={},</span>
<span class="gd">-    legend_kwds={}, map_kwds={}, **kwargs):</span>
<span class="gi">+</span>
<span class="gi">+_MAP_KWARGS = [</span>
<span class="gi">+    &quot;location&quot;,</span>
<span class="gi">+    &quot;prefer_canvas&quot;,</span>
<span class="gi">+    &quot;no_touch&quot;,</span>
<span class="gi">+    &quot;disable_3d&quot;,</span>
<span class="gi">+    &quot;png_enabled&quot;,</span>
<span class="gi">+    &quot;zoom_control&quot;,</span>
<span class="gi">+    &quot;crs&quot;,</span>
<span class="gi">+    &quot;zoom_start&quot;,</span>
<span class="gi">+    &quot;left&quot;,</span>
<span class="gi">+    &quot;top&quot;,</span>
<span class="gi">+    &quot;position&quot;,</span>
<span class="gi">+    &quot;min_zoom&quot;,</span>
<span class="gi">+    &quot;max_zoom&quot;,</span>
<span class="gi">+    &quot;min_lat&quot;,</span>
<span class="gi">+    &quot;max_lat&quot;,</span>
<span class="gi">+    &quot;min_lon&quot;,</span>
<span class="gi">+    &quot;max_lon&quot;,</span>
<span class="gi">+    &quot;max_bounds&quot;,</span>
<span class="gi">+]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _explore(</span>
<span class="gi">+    df,</span>
<span class="gi">+    column=None,</span>
<span class="gi">+    cmap=None,</span>
<span class="gi">+    color=None,</span>
<span class="gi">+    m=None,</span>
<span class="gi">+    tiles=&quot;OpenStreetMap&quot;,</span>
<span class="gi">+    attr=None,</span>
<span class="gi">+    tooltip=True,</span>
<span class="gi">+    popup=False,</span>
<span class="gi">+    highlight=True,</span>
<span class="gi">+    categorical=False,</span>
<span class="gi">+    legend=True,</span>
<span class="gi">+    scheme=None,</span>
<span class="gi">+    k=5,</span>
<span class="gi">+    vmin=None,</span>
<span class="gi">+    vmax=None,</span>
<span class="gi">+    width=&quot;100%&quot;,</span>
<span class="gi">+    height=&quot;100%&quot;,</span>
<span class="gi">+    categories=None,</span>
<span class="gi">+    classification_kwds=None,</span>
<span class="gi">+    control_scale=True,</span>
<span class="gi">+    marker_type=None,</span>
<span class="gi">+    marker_kwds={},</span>
<span class="gi">+    style_kwds={},</span>
<span class="gi">+    highlight_kwds={},</span>
<span class="gi">+    missing_kwds={},</span>
<span class="gi">+    tooltip_kwds={},</span>
<span class="gi">+    popup_kwds={},</span>
<span class="gi">+    legend_kwds={},</span>
<span class="gi">+    map_kwds={},</span>
<span class="gi">+    **kwargs,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;Interactive map based on GeoPandas and folium/leaflet.js

<span class="w"> </span>    Generate an interactive leaflet map based on :class:`~geopandas.GeoDataFrame`
<span class="gu">@@ -222,12 +268,524 @@ def _explore(df, column=None, cmap=None, color=None, m=None, tiles=</span>

<span class="w"> </span>    &gt;&gt;&gt; df.explore(&quot;Pop2012&quot;, cmap=&quot;Blues&quot;)  # doctest: +SKIP
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    def _colormap_helper(_cmap, n_resample=None, idx=None):</span>
<span class="gi">+        &quot;&quot;&quot;Helper for MPL deprecation - GH#2596&quot;&quot;&quot;</span>
<span class="gi">+        if not n_resample:</span>
<span class="gi">+            return cm.get_cmap(_cmap)</span>
<span class="gi">+        else:</span>
<span class="gi">+            if MPL_361:</span>
<span class="gi">+                return cm.get_cmap(_cmap).resampled(n_resample)(idx)</span>
<span class="gi">+            else:</span>
<span class="gi">+                return cm.get_cmap(_cmap, n_resample)(idx)</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        import re</span>
<span class="gi">+</span>
<span class="gi">+        import branca as bc</span>
<span class="gi">+        import folium</span>
<span class="gi">+        import matplotlib</span>
<span class="gi">+        import matplotlib.pyplot as plt</span>
<span class="gi">+        from mapclassify import classify</span>
<span class="gi">+        from matplotlib import colors</span>
<span class="gi">+</span>
<span class="gi">+        # isolate MPL version - GH#2596</span>
<span class="gi">+        MPL_361 = Version(matplotlib.__version__) &gt;= Version(&quot;3.6.1&quot;)</span>
<span class="gi">+        if MPL_361:</span>
<span class="gi">+            from matplotlib import colormaps as cm</span>
<span class="gi">+        else:</span>
<span class="gi">+            from matplotlib import cm</span>
<span class="gi">+</span>
<span class="gi">+    except (ImportError, ModuleNotFoundError):</span>
<span class="gi">+        raise ImportError(</span>
<span class="gi">+            &quot;The &#39;folium&#39;, &#39;matplotlib&#39; and &#39;mapclassify&#39; packages are required for &quot;</span>
<span class="gi">+            &quot;&#39;explore()&#39;. You can install them using &quot;</span>
<span class="gi">+            &quot;&#39;conda install -c conda-forge folium matplotlib mapclassify&#39; &quot;</span>
<span class="gi">+            &quot;or &#39;pip install folium matplotlib mapclassify&#39;.&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    # xyservices is an optional dependency</span>
<span class="gi">+    try:</span>
<span class="gi">+        import xyzservices</span>
<span class="gi">+</span>
<span class="gi">+        HAS_XYZSERVICES = True</span>
<span class="gi">+    except (ImportError, ModuleNotFoundError):</span>
<span class="gi">+        HAS_XYZSERVICES = False</span>
<span class="gi">+</span>
<span class="gi">+    gdf = df.copy()</span>
<span class="gi">+</span>
<span class="gi">+    # convert LinearRing to LineString</span>
<span class="gi">+    rings_mask = df.geom_type == &quot;LinearRing&quot;</span>
<span class="gi">+    if rings_mask.any():</span>
<span class="gi">+        gdf.geometry[rings_mask] = gdf.geometry[rings_mask].apply(</span>
<span class="gi">+            lambda g: LineString(g)</span>
<span class="gi">+        )</span>
<span class="gi">+    if isinstance(gdf, geopandas.GeoSeries):</span>
<span class="gi">+        gdf = gdf.to_frame()</span>
<span class="gi">+</span>
<span class="gi">+    if gdf.crs is None:</span>
<span class="gi">+        kwargs[&quot;crs&quot;] = &quot;Simple&quot;</span>
<span class="gi">+        tiles = None</span>
<span class="gi">+    elif not gdf.crs.equals(4326):</span>
<span class="gi">+        gdf = gdf.to_crs(4326)</span>
<span class="gi">+</span>
<span class="gi">+    # Fields which are not JSON serializable are coerced to strings</span>
<span class="gi">+    json_not_supported_cols = gdf.columns[</span>
<span class="gi">+        [is_datetime64_any_dtype(gdf[c]) for c in gdf.columns]</span>
<span class="gi">+    ].union(gdf.columns[gdf.dtypes == &quot;object&quot;])</span>
<span class="gi">+</span>
<span class="gi">+    if len(json_not_supported_cols) &gt; 0:</span>
<span class="gi">+        gdf = gdf.astype({c: &quot;string&quot; for c in json_not_supported_cols})</span>
<span class="gi">+</span>
<span class="gi">+    if not isinstance(gdf.index, pd.MultiIndex) and (</span>
<span class="gi">+        is_datetime64_any_dtype(gdf.index) or (gdf.index.dtype == &quot;object&quot;)</span>
<span class="gi">+    ):</span>
<span class="gi">+        gdf.index = gdf.index.astype(&quot;string&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # create folium.Map object</span>
<span class="gi">+    if m is None:</span>
<span class="gi">+        # Get bounds to specify location and map extent</span>
<span class="gi">+        bounds = gdf.total_bounds</span>
<span class="gi">+        location = kwargs.pop(&quot;location&quot;, None)</span>
<span class="gi">+        if location is None and not np.isnan(bounds).all():</span>
<span class="gi">+            x = mean([bounds[0], bounds[2]])</span>
<span class="gi">+            y = mean([bounds[1], bounds[3]])</span>
<span class="gi">+            location = (y, x)</span>
<span class="gi">+            if &quot;zoom_start&quot; in kwargs.keys():</span>
<span class="gi">+                fit = False</span>
<span class="gi">+            else:</span>
<span class="gi">+                fit = True</span>
<span class="gi">+        else:</span>
<span class="gi">+            fit = False</span>
<span class="gi">+</span>
<span class="gi">+        # get a subset of kwargs to be passed to folium.Map</span>
<span class="gi">+        for i in _MAP_KWARGS:</span>
<span class="gi">+            if i in map_kwds:</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    f&quot;&#39;{i}&#39; cannot be specified in &#39;map_kwds&#39;. &quot;</span>
<span class="gi">+                    f&quot;Use the &#39;{i}={map_kwds[i]}&#39; argument instead.&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+        map_kwds = {</span>
<span class="gi">+            **map_kwds,</span>
<span class="gi">+            **{i: kwargs[i] for i in kwargs.keys() if i in _MAP_KWARGS},</span>
<span class="gi">+        }</span>
<span class="gi">+</span>
<span class="gi">+        if HAS_XYZSERVICES:</span>
<span class="gi">+            # match provider name string to xyzservices.TileProvider</span>
<span class="gi">+            if isinstance(tiles, str):</span>
<span class="gi">+                try:</span>
<span class="gi">+                    tiles = xyzservices.providers.query_name(tiles)</span>
<span class="gi">+                except ValueError:</span>
<span class="gi">+                    pass</span>
<span class="gi">+</span>
<span class="gi">+            if isinstance(tiles, xyzservices.TileProvider):</span>
<span class="gi">+                attr = attr if attr else tiles.html_attribution</span>
<span class="gi">+                if &quot;min_zoom&quot; not in map_kwds:</span>
<span class="gi">+                    map_kwds[&quot;min_zoom&quot;] = tiles.get(&quot;min_zoom&quot;, 0)</span>
<span class="gi">+                if &quot;max_zoom&quot; not in map_kwds:</span>
<span class="gi">+                    map_kwds[&quot;max_zoom&quot;] = tiles.get(&quot;max_zoom&quot;, 18)</span>
<span class="gi">+                tiles = tiles.build_url(scale_factor=&quot;{r}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        m = folium.Map(</span>
<span class="gi">+            location=location,</span>
<span class="gi">+            control_scale=control_scale,</span>
<span class="gi">+            tiles=tiles,</span>
<span class="gi">+            attr=attr,</span>
<span class="gi">+            width=width,</span>
<span class="gi">+            height=height,</span>
<span class="gi">+            **map_kwds,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        # fit bounds to get a proper zoom level</span>
<span class="gi">+        if fit:</span>
<span class="gi">+            m.fit_bounds([[bounds[1], bounds[0]], [bounds[3], bounds[2]]])</span>
<span class="gi">+</span>
<span class="gi">+    if gdf.is_empty.all():</span>
<span class="gi">+        warnings.warn(</span>
<span class="gi">+            &quot;The GeoSeries you are attempting to plot is &quot;</span>
<span class="gi">+            &quot;composed of empty geometries. Nothing has been displayed.&quot;,</span>
<span class="gi">+            UserWarning,</span>
<span class="gi">+            stacklevel=3,</span>
<span class="gi">+        )</span>
<span class="gi">+        return m</span>
<span class="gi">+</span>
<span class="gi">+    for map_kwd in _MAP_KWARGS:</span>
<span class="gi">+        kwargs.pop(map_kwd, None)</span>
<span class="gi">+</span>
<span class="gi">+    nan_idx = None</span>
<span class="gi">+</span>
<span class="gi">+    if column is not None:</span>
<span class="gi">+        if pd.api.types.is_list_like(column):</span>
<span class="gi">+            if len(column) != gdf.shape[0]:</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    &quot;The GeoDataFrame and given column have different number of rows.&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+            else:</span>
<span class="gi">+                column_name = &quot;__plottable_column&quot;</span>
<span class="gi">+                gdf[column_name] = column</span>
<span class="gi">+                column = column_name</span>
<span class="gi">+        elif isinstance(gdf[column].dtype, pd.CategoricalDtype):</span>
<span class="gi">+            if categories is not None:</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    &quot;Cannot specify &#39;categories&#39; when column has categorical dtype&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+            categorical = True</span>
<span class="gi">+        elif (</span>
<span class="gi">+            pd.api.types.is_object_dtype(gdf[column])</span>
<span class="gi">+            or pd.api.types.is_bool_dtype(gdf[column])</span>
<span class="gi">+            or pd.api.types.is_string_dtype(gdf[column])</span>
<span class="gi">+            or categories</span>
<span class="gi">+        ):</span>
<span class="gi">+            categorical = True</span>
<span class="gi">+</span>
<span class="gi">+        nan_idx = pd.isna(gdf[column])</span>
<span class="gi">+</span>
<span class="gi">+        if categorical:</span>
<span class="gi">+            cat = pd.Categorical(gdf[column][~nan_idx], categories=categories)</span>
<span class="gi">+            N = len(cat.categories)</span>
<span class="gi">+            cmap = cmap if cmap else &quot;tab20&quot;</span>
<span class="gi">+</span>
<span class="gi">+            # colormap exists in matplotlib</span>
<span class="gi">+            if cmap in plt.colormaps():</span>
<span class="gi">+                color = np.apply_along_axis(</span>
<span class="gi">+                    colors.to_hex,</span>
<span class="gi">+                    1,</span>
<span class="gi">+                    _colormap_helper(cmap, n_resample=N, idx=cat.codes),</span>
<span class="gi">+                )</span>
<span class="gi">+                legend_colors = np.apply_along_axis(</span>
<span class="gi">+                    colors.to_hex, 1, _colormap_helper(cmap, n_resample=N, idx=range(N))</span>
<span class="gi">+                )</span>
<span class="gi">+</span>
<span class="gi">+            # colormap is matplotlib.Colormap</span>
<span class="gi">+            elif isinstance(cmap, colors.Colormap):</span>
<span class="gi">+                color = np.apply_along_axis(colors.to_hex, 1, cmap(cat.codes))</span>
<span class="gi">+                legend_colors = np.apply_along_axis(colors.to_hex, 1, cmap(range(N)))</span>
<span class="gi">+</span>
<span class="gi">+            # custom list of colors</span>
<span class="gi">+            elif pd.api.types.is_list_like(cmap):</span>
<span class="gi">+                if N &gt; len(cmap):</span>
<span class="gi">+                    cmap = cmap * (N // len(cmap) + 1)</span>
<span class="gi">+                color = np.take(cmap, cat.codes)</span>
<span class="gi">+                legend_colors = np.take(cmap, range(N))</span>
<span class="gi">+</span>
<span class="gi">+            else:</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    &quot;&#39;cmap&#39; is invalid. For categorical plots, pass either valid &quot;</span>
<span class="gi">+                    &quot;named matplotlib colormap or a list-like of colors.&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+</span>
<span class="gi">+        elif callable(cmap):</span>
<span class="gi">+            # List of colors based on Branca colormaps or self-defined functions</span>
<span class="gi">+            color = [cmap(x) for x in df[column]]</span>
<span class="gi">+</span>
<span class="gi">+        else:</span>
<span class="gi">+            vmin = gdf[column].min() if vmin is None else vmin</span>
<span class="gi">+            vmax = gdf[column].max() if vmax is None else vmax</span>
<span class="gi">+</span>
<span class="gi">+            # get bins</span>
<span class="gi">+            if scheme is not None:</span>
<span class="gi">+                if classification_kwds is None:</span>
<span class="gi">+                    classification_kwds = {}</span>
<span class="gi">+                if &quot;k&quot; not in classification_kwds:</span>
<span class="gi">+                    classification_kwds[&quot;k&quot;] = k</span>
<span class="gi">+</span>
<span class="gi">+                binning = classify(</span>
<span class="gi">+                    np.asarray(gdf[column][~nan_idx]), scheme, **classification_kwds</span>
<span class="gi">+                )</span>
<span class="gi">+                color = np.apply_along_axis(</span>
<span class="gi">+                    colors.to_hex,</span>
<span class="gi">+                    1,</span>
<span class="gi">+                    _colormap_helper(cmap, n_resample=binning.k, idx=binning.yb),</span>
<span class="gi">+                )</span>
<span class="gi">+</span>
<span class="gi">+            else:</span>
<span class="gi">+                bins = np.linspace(vmin, vmax, 257)[1:]</span>
<span class="gi">+                binning = classify(</span>
<span class="gi">+                    np.asarray(gdf[column][~nan_idx]), &quot;UserDefined&quot;, bins=bins</span>
<span class="gi">+                )</span>
<span class="gi">+</span>
<span class="gi">+                color = np.apply_along_axis(</span>
<span class="gi">+                    colors.to_hex,</span>
<span class="gi">+                    1,</span>
<span class="gi">+                    _colormap_helper(cmap, n_resample=256, idx=binning.yb),</span>
<span class="gi">+                )</span>
<span class="gi">+</span>
<span class="gi">+    # set default style</span>
<span class="gi">+    if &quot;fillOpacity&quot; not in style_kwds:</span>
<span class="gi">+        style_kwds[&quot;fillOpacity&quot;] = 0.5</span>
<span class="gi">+    if &quot;weight&quot; not in style_kwds:</span>
<span class="gi">+        style_kwds[&quot;weight&quot;] = 2</span>
<span class="gi">+    if &quot;style_function&quot; in style_kwds:</span>
<span class="gi">+        style_kwds_function = style_kwds[&quot;style_function&quot;]</span>
<span class="gi">+        if not callable(style_kwds_function):</span>
<span class="gi">+            raise ValueError(&quot;&#39;style_function&#39; has to be a callable&quot;)</span>
<span class="gi">+        style_kwds.pop(&quot;style_function&quot;)</span>
<span class="gi">+    else:</span>
<span class="gi">+</span>
<span class="gi">+        def _no_style(x):</span>
<span class="gi">+            return {}</span>
<span class="gi">+</span>
<span class="gi">+        style_kwds_function = _no_style</span>
<span class="gi">+</span>
<span class="gi">+    # specify color</span>
<span class="gi">+    if color is not None:</span>
<span class="gi">+        if (</span>
<span class="gi">+            isinstance(color, str)</span>
<span class="gi">+            and isinstance(gdf, geopandas.GeoDataFrame)</span>
<span class="gi">+            and color in gdf.columns</span>
<span class="gi">+        ):  # use existing column</span>
<span class="gi">+</span>
<span class="gi">+            def _style_color(x):</span>
<span class="gi">+                base_style = {</span>
<span class="gi">+                    &quot;fillColor&quot;: x[&quot;properties&quot;][color],</span>
<span class="gi">+                    **style_kwds,</span>
<span class="gi">+                }</span>
<span class="gi">+                return {</span>
<span class="gi">+                    **base_style,</span>
<span class="gi">+                    **style_kwds_function(x),</span>
<span class="gi">+                }</span>
<span class="gi">+</span>
<span class="gi">+            style_function = _style_color</span>
<span class="gi">+        else:  # assign new column</span>
<span class="gi">+            if isinstance(gdf, geopandas.GeoSeries):</span>
<span class="gi">+                gdf = geopandas.GeoDataFrame(geometry=gdf)</span>
<span class="gi">+</span>
<span class="gi">+            if nan_idx is not None and nan_idx.any():</span>
<span class="gi">+                nan_color = missing_kwds.pop(&quot;color&quot;, None)</span>
<span class="gi">+</span>
<span class="gi">+                gdf[&quot;__folium_color&quot;] = nan_color</span>
<span class="gi">+                gdf.loc[~nan_idx, &quot;__folium_color&quot;] = color</span>
<span class="gi">+            else:</span>
<span class="gi">+                gdf[&quot;__folium_color&quot;] = color</span>
<span class="gi">+</span>
<span class="gi">+            stroke_color = style_kwds.pop(&quot;color&quot;, None)</span>
<span class="gi">+            if not stroke_color:</span>
<span class="gi">+</span>
<span class="gi">+                def _style_column(x):</span>
<span class="gi">+                    base_style = {</span>
<span class="gi">+                        &quot;fillColor&quot;: x[&quot;properties&quot;][&quot;__folium_color&quot;],</span>
<span class="gi">+                        &quot;color&quot;: x[&quot;properties&quot;][&quot;__folium_color&quot;],</span>
<span class="gi">+                        **style_kwds,</span>
<span class="gi">+                    }</span>
<span class="gi">+                    return {</span>
<span class="gi">+                        **base_style,</span>
<span class="gi">+                        **style_kwds_function(x),</span>
<span class="gi">+                    }</span>
<span class="gi">+</span>
<span class="gi">+                style_function = _style_column</span>
<span class="gi">+            else:</span>
<span class="gi">+</span>
<span class="gi">+                def _style_stroke(x):</span>
<span class="gi">+                    base_style = {</span>
<span class="gi">+                        &quot;fillColor&quot;: x[&quot;properties&quot;][&quot;__folium_color&quot;],</span>
<span class="gi">+                        &quot;color&quot;: stroke_color,</span>
<span class="gi">+                        **style_kwds,</span>
<span class="gi">+                    }</span>
<span class="gi">+                    return {</span>
<span class="gi">+                        **base_style,</span>
<span class="gi">+                        **style_kwds_function(x),</span>
<span class="gi">+                    }</span>
<span class="gi">+</span>
<span class="gi">+                style_function = _style_stroke</span>
<span class="gi">+    else:  # use folium default</span>
<span class="gi">+</span>
<span class="gi">+        def _style_default(x):</span>
<span class="gi">+            return {**style_kwds, **style_kwds_function(x)}</span>
<span class="gi">+</span>
<span class="gi">+        style_function = _style_default</span>
<span class="gi">+</span>
<span class="gi">+    if highlight:</span>
<span class="gi">+        if &quot;fillOpacity&quot; not in highlight_kwds:</span>
<span class="gi">+            highlight_kwds[&quot;fillOpacity&quot;] = 0.75</span>
<span class="gi">+</span>
<span class="gi">+        def _style_highlight(x):</span>
<span class="gi">+            return {**highlight_kwds}</span>
<span class="gi">+</span>
<span class="gi">+        highlight_function = _style_highlight</span>
<span class="gi">+    else:</span>
<span class="gi">+        highlight_function = None</span>
<span class="gi">+</span>
<span class="gi">+    # define default for points</span>
<span class="gi">+    if marker_type is None:</span>
<span class="gi">+        marker_type = &quot;circle_marker&quot;</span>
<span class="gi">+</span>
<span class="gi">+    marker = marker_type</span>
<span class="gi">+    if isinstance(marker_type, str):</span>
<span class="gi">+        if marker_type == &quot;marker&quot;:</span>
<span class="gi">+            marker = folium.Marker(**marker_kwds)</span>
<span class="gi">+        elif marker_type == &quot;circle&quot;:</span>
<span class="gi">+            marker = folium.Circle(**marker_kwds)</span>
<span class="gi">+        elif marker_type == &quot;circle_marker&quot;:</span>
<span class="gi">+            marker_kwds[&quot;radius&quot;] = marker_kwds.get(&quot;radius&quot;, 2)</span>
<span class="gi">+            marker_kwds[&quot;fill&quot;] = marker_kwds.get(&quot;fill&quot;, True)</span>
<span class="gi">+            marker = folium.CircleMarker(**marker_kwds)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;Only &#39;marker&#39;, &#39;circle&#39;, and &#39;circle_marker&#39; are &quot;</span>
<span class="gi">+                &quot;supported as marker values&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    # remove additional geometries</span>
<span class="gi">+    if isinstance(gdf, geopandas.GeoDataFrame):</span>
<span class="gi">+        non_active_geoms = [</span>
<span class="gi">+            name</span>
<span class="gi">+            for name, val in (gdf.dtypes == &quot;geometry&quot;).items()</span>
<span class="gi">+            if val and name != gdf.geometry.name</span>
<span class="gi">+        ]</span>
<span class="gi">+        gdf = gdf.drop(columns=non_active_geoms)</span>
<span class="gi">+</span>
<span class="gi">+    # prepare tooltip and popup</span>
<span class="gi">+    if isinstance(gdf, geopandas.GeoDataFrame):</span>
<span class="gi">+        # add named index to the tooltip</span>
<span class="gi">+        if gdf.index.name is not None:</span>
<span class="gi">+            gdf = gdf.reset_index()</span>
<span class="gi">+        # specify fields to show in the tooltip</span>
<span class="gi">+        tooltip = _tooltip_popup(&quot;tooltip&quot;, tooltip, gdf, **tooltip_kwds)</span>
<span class="gi">+        popup = _tooltip_popup(&quot;popup&quot;, popup, gdf, **popup_kwds)</span>
<span class="gi">+    else:</span>
<span class="gi">+        tooltip = None</span>
<span class="gi">+        popup = None</span>
<span class="gi">+    # escape the curly braces {{}} for jinja2 templates</span>
<span class="gi">+    feature_collection = gdf[</span>
<span class="gi">+        ~(gdf.geometry.isna() | gdf.geometry.is_empty)  # drop missing or empty geoms</span>
<span class="gi">+    ].__geo_interface__</span>
<span class="gi">+    for feature in feature_collection[&quot;features&quot;]:</span>
<span class="gi">+        for k in feature[&quot;properties&quot;]:</span>
<span class="gi">+            # escape the curly braces in values</span>
<span class="gi">+            if isinstance(feature[&quot;properties&quot;][k], str):</span>
<span class="gi">+                feature[&quot;properties&quot;][k] = re.sub(</span>
<span class="gi">+                    r&quot;\{{2,}&quot;,</span>
<span class="gi">+                    lambda x: &quot;{% raw %}&quot; + x.group(0) + &quot;{% endraw %}&quot;,</span>
<span class="gi">+                    feature[&quot;properties&quot;][k],</span>
<span class="gi">+                )</span>
<span class="gi">+</span>
<span class="gi">+    # add dataframe to map</span>
<span class="gi">+    folium.GeoJson(</span>
<span class="gi">+        feature_collection,</span>
<span class="gi">+        tooltip=tooltip,</span>
<span class="gi">+        popup=popup,</span>
<span class="gi">+        marker=marker,</span>
<span class="gi">+        style_function=style_function,</span>
<span class="gi">+        highlight_function=highlight_function,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ).add_to(m)</span>
<span class="gi">+</span>
<span class="gi">+    if legend:</span>
<span class="gi">+        # NOTE: overlaps will be resolved in branca #88</span>
<span class="gi">+        caption = column if not column == &quot;__plottable_column&quot; else &quot;&quot;</span>
<span class="gi">+        caption = legend_kwds.pop(&quot;caption&quot;, caption)</span>
<span class="gi">+        if categorical:</span>
<span class="gi">+            categories = cat.categories.to_list()</span>
<span class="gi">+            legend_colors = legend_colors.tolist()</span>
<span class="gi">+</span>
<span class="gi">+            if nan_idx.any() and nan_color:</span>
<span class="gi">+                categories.append(missing_kwds.pop(&quot;label&quot;, &quot;NaN&quot;))</span>
<span class="gi">+                legend_colors.append(nan_color)</span>
<span class="gi">+</span>
<span class="gi">+            _categorical_legend(m, caption, categories, legend_colors)</span>
<span class="gi">+        elif column is not None:</span>
<span class="gi">+            cbar = legend_kwds.pop(&quot;colorbar&quot;, True)</span>
<span class="gi">+            colormap_kwds = {}</span>
<span class="gi">+            if &quot;max_labels&quot; in legend_kwds:</span>
<span class="gi">+                colormap_kwds[&quot;max_labels&quot;] = legend_kwds.pop(&quot;max_labels&quot;)</span>
<span class="gi">+            if scheme:</span>
<span class="gi">+                cb_colors = np.apply_along_axis(</span>
<span class="gi">+                    colors.to_hex,</span>
<span class="gi">+                    1,</span>
<span class="gi">+                    _colormap_helper(cmap, n_resample=binning.k, idx=range(binning.k)),</span>
<span class="gi">+                )</span>
<span class="gi">+                if cbar:</span>
<span class="gi">+                    if legend_kwds.pop(&quot;scale&quot;, True):</span>
<span class="gi">+                        index = [vmin] + binning.bins.tolist()</span>
<span class="gi">+                    else:</span>
<span class="gi">+                        index = None</span>
<span class="gi">+                    colorbar = bc.colormap.StepColormap(</span>
<span class="gi">+                        cb_colors,</span>
<span class="gi">+                        vmin=vmin,</span>
<span class="gi">+                        vmax=vmax,</span>
<span class="gi">+                        caption=caption,</span>
<span class="gi">+                        index=index,</span>
<span class="gi">+                        **colormap_kwds,</span>
<span class="gi">+                    )</span>
<span class="gi">+                else:</span>
<span class="gi">+                    fmt = legend_kwds.pop(&quot;fmt&quot;, &quot;{:.2f}&quot;)</span>
<span class="gi">+                    if &quot;labels&quot; in legend_kwds:</span>
<span class="gi">+                        categories = legend_kwds[&quot;labels&quot;]</span>
<span class="gi">+                    else:</span>
<span class="gi">+                        categories = binning.get_legend_classes(fmt)</span>
<span class="gi">+                        show_interval = legend_kwds.pop(&quot;interval&quot;, False)</span>
<span class="gi">+                        if not show_interval:</span>
<span class="gi">+                            categories = [c[1:-1] for c in categories]</span>
<span class="gi">+</span>
<span class="gi">+                    if nan_idx.any() and nan_color:</span>
<span class="gi">+                        categories.append(missing_kwds.pop(&quot;label&quot;, &quot;NaN&quot;))</span>
<span class="gi">+                        cb_colors = np.append(cb_colors, nan_color)</span>
<span class="gi">+                    _categorical_legend(m, caption, categories, cb_colors)</span>
<span class="gi">+</span>
<span class="gi">+            else:</span>
<span class="gi">+                if isinstance(cmap, bc.colormap.ColorMap):</span>
<span class="gi">+                    colorbar = cmap</span>
<span class="gi">+                else:</span>
<span class="gi">+                    mp_cmap = _colormap_helper(cmap)</span>
<span class="gi">+                    cb_colors = np.apply_along_axis(</span>
<span class="gi">+                        colors.to_hex, 1, mp_cmap(range(mp_cmap.N))</span>
<span class="gi">+                    )</span>
<span class="gi">+</span>
<span class="gi">+                    # linear legend</span>
<span class="gi">+                    if mp_cmap.N &gt; 20:</span>
<span class="gi">+                        colorbar = bc.colormap.LinearColormap(</span>
<span class="gi">+                            cb_colors,</span>
<span class="gi">+                            vmin=vmin,</span>
<span class="gi">+                            vmax=vmax,</span>
<span class="gi">+                            caption=caption,</span>
<span class="gi">+                            **colormap_kwds,</span>
<span class="gi">+                        )</span>
<span class="gi">+</span>
<span class="gi">+                    # steps</span>
<span class="gi">+                    else:</span>
<span class="gi">+                        colorbar = bc.colormap.StepColormap(</span>
<span class="gi">+                            cb_colors,</span>
<span class="gi">+                            vmin=vmin,</span>
<span class="gi">+                            vmax=vmax,</span>
<span class="gi">+                            caption=caption,</span>
<span class="gi">+                            **colormap_kwds,</span>
<span class="gi">+                        )</span>
<span class="gi">+</span>
<span class="gi">+            if cbar:</span>
<span class="gi">+                if nan_idx.any() and nan_color:</span>
<span class="gi">+                    _categorical_legend(</span>
<span class="gi">+                        m, &quot;&quot;, [missing_kwds.pop(&quot;label&quot;, &quot;NaN&quot;)], [nan_color]</span>
<span class="gi">+                    )</span>
<span class="gi">+                m.add_child(colorbar)</span>
<span class="gi">+</span>
<span class="gi">+    return m</span>


<span class="w"> </span>def _tooltip_popup(type, fields, gdf, **kwds):
<span class="w"> </span>    &quot;&quot;&quot;get tooltip or popup&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import folium</span>
<span class="gi">+</span>
<span class="gi">+    # specify fields to show in the tooltip</span>
<span class="gi">+    if fields is False or fields is None or fields == 0:</span>
<span class="gi">+        return None</span>
<span class="gi">+    else:</span>
<span class="gi">+        if fields is True:</span>
<span class="gi">+            fields = gdf.columns.drop(gdf.geometry.name).to_list()</span>
<span class="gi">+        elif isinstance(fields, int):</span>
<span class="gi">+            fields = gdf.columns.drop(gdf.geometry.name).to_list()[:fields]</span>
<span class="gi">+        elif isinstance(fields, str):</span>
<span class="gi">+            fields = [fields]</span>
<span class="gi">+</span>
<span class="gi">+    for field in [&quot;__plottable_column&quot;, &quot;__folium_color&quot;]:</span>
<span class="gi">+        if field in fields:</span>
<span class="gi">+            fields.remove(field)</span>
<span class="gi">+</span>
<span class="gi">+    # Cast fields to str</span>
<span class="gi">+    fields = list(map(str, fields))</span>
<span class="gi">+    if type == &quot;tooltip&quot;:</span>
<span class="gi">+        return folium.GeoJsonTooltip(fields, **kwds)</span>
<span class="gi">+    elif type == &quot;popup&quot;:</span>
<span class="gi">+        return folium.GeoJsonPopup(fields, **kwds)</span>


<span class="w"> </span>def _categorical_legend(m, title, categories, colors):
<span class="gu">@@ -251,13 +809,118 @@ def _categorical_legend(m, title, categories, colors):</span>
<span class="w"> </span>    colors : list-like
<span class="w"> </span>        list of colors (in the same order as categories)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    # Header to Add</span>
<span class="gi">+    head = &quot;&quot;&quot;</span>
<span class="gi">+    {% macro header(this, kwargs) %}</span>
<span class="gi">+    &lt;script src=&quot;https://code.jquery.com/ui/1.12.1/jquery-ui.js&quot;&gt;&lt;/script&gt;</span>
<span class="gi">+    &lt;script&gt;$( function() {</span>
<span class="gi">+        $( &quot;.maplegend&quot; ).draggable({</span>
<span class="gi">+            start: function (event, ui) {</span>
<span class="gi">+                $(this).css({</span>
<span class="gi">+                    right: &quot;auto&quot;,</span>
<span class="gi">+                    top: &quot;auto&quot;,</span>
<span class="gi">+                    bottom: &quot;auto&quot;</span>
<span class="gi">+                });</span>
<span class="gi">+            }</span>
<span class="gi">+        });</span>
<span class="gi">+    });</span>
<span class="gi">+    &lt;/script&gt;</span>
<span class="gi">+    &lt;style type=&#39;text/css&#39;&gt;</span>
<span class="gi">+      .maplegend {</span>
<span class="gi">+        position: absolute;</span>
<span class="gi">+        z-index:9999;</span>
<span class="gi">+        background-color: rgba(255, 255, 255, .8);</span>
<span class="gi">+        border-radius: 5px;</span>
<span class="gi">+        box-shadow: 0 0 15px rgba(0,0,0,0.2);</span>
<span class="gi">+        padding: 10px;</span>
<span class="gi">+        font: 12px/14px Arial, Helvetica, sans-serif;</span>
<span class="gi">+        right: 10px;</span>
<span class="gi">+        bottom: 20px;</span>
<span class="gi">+      }</span>
<span class="gi">+      .maplegend .legend-title {</span>
<span class="gi">+        text-align: left;</span>
<span class="gi">+        margin-bottom: 5px;</span>
<span class="gi">+        font-weight: bold;</span>
<span class="gi">+        }</span>
<span class="gi">+      .maplegend .legend-scale ul {</span>
<span class="gi">+        margin: 0;</span>
<span class="gi">+        margin-bottom: 0px;</span>
<span class="gi">+        padding: 0;</span>
<span class="gi">+        float: left;</span>
<span class="gi">+        list-style: none;</span>
<span class="gi">+        }</span>
<span class="gi">+      .maplegend .legend-scale ul li {</span>
<span class="gi">+        list-style: none;</span>
<span class="gi">+        margin-left: 0;</span>
<span class="gi">+        line-height: 16px;</span>
<span class="gi">+        margin-bottom: 2px;</span>
<span class="gi">+        }</span>
<span class="gi">+      .maplegend ul.legend-labels li span {</span>
<span class="gi">+        display: block;</span>
<span class="gi">+        float: left;</span>
<span class="gi">+        height: 14px;</span>
<span class="gi">+        width: 14px;</span>
<span class="gi">+        margin-right: 5px;</span>
<span class="gi">+        margin-left: 0;</span>
<span class="gi">+        border: 0px solid #ccc;</span>
<span class="gi">+        }</span>
<span class="gi">+      .maplegend .legend-source {</span>
<span class="gi">+        color: #777;</span>
<span class="gi">+        clear: both;</span>
<span class="gi">+        }</span>
<span class="gi">+      .maplegend a {</span>
<span class="gi">+        color: #777;</span>
<span class="gi">+        }</span>
<span class="gi">+    &lt;/style&gt;</span>
<span class="gi">+    {% endmacro %}</span>
<span class="gi">+    &quot;&quot;&quot;</span>
<span class="gi">+    import branca as bc</span>
<span class="gi">+</span>
<span class="gi">+    # Add CSS (on Header)</span>
<span class="gi">+    macro = bc.element.MacroElement()</span>
<span class="gi">+    macro._template = bc.element.Template(head)</span>
<span class="gi">+    m.get_root().add_child(macro)</span>
<span class="gi">+</span>
<span class="gi">+    body = f&quot;&quot;&quot;</span>
<span class="gi">+    &lt;div id=&#39;maplegend {title}&#39; class=&#39;maplegend&#39;&gt;</span>
<span class="gi">+        &lt;div class=&#39;legend-title&#39;&gt;{title}&lt;/div&gt;</span>
<span class="gi">+        &lt;div class=&#39;legend-scale&#39;&gt;</span>
<span class="gi">+            &lt;ul class=&#39;legend-labels&#39;&gt;&quot;&quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+    # Loop Categories</span>
<span class="gi">+    for label, color in zip(categories, colors):</span>
<span class="gi">+        body += f&quot;&quot;&quot;</span>
<span class="gi">+                &lt;li&gt;&lt;span style=&#39;background:{color}&#39;&gt;&lt;/span&gt;{label}&lt;/li&gt;&quot;&quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+    body += &quot;&quot;&quot;</span>
<span class="gi">+            &lt;/ul&gt;</span>
<span class="gi">+        &lt;/div&gt;</span>
<span class="gi">+    &lt;/div&gt;</span>
<span class="gi">+    &quot;&quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+    # Add Body</span>
<span class="gi">+    body = bc.element.Element(body, &quot;legend&quot;)</span>
<span class="gi">+    m.get_root().html.add_child(body)</span>


<span class="gd">-def _explore_geoseries(s, color=None, m=None, tiles=&#39;OpenStreetMap&#39;, attr=</span>
<span class="gd">-    None, highlight=True, width=&#39;100%&#39;, height=&#39;100%&#39;, control_scale=True,</span>
<span class="gd">-    marker_type=None, marker_kwds={}, style_kwds={}, highlight_kwds={},</span>
<span class="gd">-    map_kwds={}, **kwargs):</span>
<span class="gi">+def _explore_geoseries(</span>
<span class="gi">+    s,</span>
<span class="gi">+    color=None,</span>
<span class="gi">+    m=None,</span>
<span class="gi">+    tiles=&quot;OpenStreetMap&quot;,</span>
<span class="gi">+    attr=None,</span>
<span class="gi">+    highlight=True,</span>
<span class="gi">+    width=&quot;100%&quot;,</span>
<span class="gi">+    height=&quot;100%&quot;,</span>
<span class="gi">+    control_scale=True,</span>
<span class="gi">+    marker_type=None,</span>
<span class="gi">+    marker_kwds={},</span>
<span class="gi">+    style_kwds={},</span>
<span class="gi">+    highlight_kwds={},</span>
<span class="gi">+    map_kwds={},</span>
<span class="gi">+    **kwargs,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;Interactive map based on GeoPandas and folium/leaflet.js

<span class="w"> </span>    Generate an interactive leaflet map based on :class:`~geopandas.GeoSeries`
<span class="gu">@@ -356,4 +1019,20 @@ def _explore_geoseries(s, color=None, m=None, tiles=&#39;OpenStreetMap&#39;, attr=</span>
<span class="w"> </span>        folium :class:`~folium.folium.Map` instance

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return _explore(</span>
<span class="gi">+        s,</span>
<span class="gi">+        color=color,</span>
<span class="gi">+        m=m,</span>
<span class="gi">+        tiles=tiles,</span>
<span class="gi">+        attr=attr,</span>
<span class="gi">+        highlight=highlight,</span>
<span class="gi">+        width=width,</span>
<span class="gi">+        height=height,</span>
<span class="gi">+        control_scale=control_scale,</span>
<span class="gi">+        marker_type=marker_type,</span>
<span class="gi">+        marker_kwds=marker_kwds,</span>
<span class="gi">+        style_kwds=style_kwds,</span>
<span class="gi">+        highlight_kwds=highlight_kwds,</span>
<span class="gi">+        map_kwds=map_kwds,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    )</span>
<span class="gh">diff --git a/geopandas/geodataframe.py b/geopandas/geodataframe.py</span>
<span class="gh">index 9ea3e33f..339315d6 100644</span>
<span class="gd">--- a/geopandas/geodataframe.py</span>
<span class="gi">+++ b/geopandas/geodataframe.py</span>
<span class="gu">@@ -1,18 +1,23 @@</span>
<span class="w"> </span>import json
<span class="w"> </span>import warnings
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>import pandas as pd
<span class="w"> </span>from pandas import DataFrame, Series
<span class="gi">+</span>
<span class="w"> </span>import shapely.errors
<span class="w"> </span>from shapely.geometry import mapping, shape
<span class="w"> </span>from shapely.geometry.base import BaseGeometry
<span class="gi">+</span>
<span class="w"> </span>import geopandas.io
<span class="w"> </span>from geopandas.array import GeometryArray, GeometryDtype, from_shapely, to_wkb, to_wkt
<span class="w"> </span>from geopandas.base import GeoPandasBase, is_geometry_type
<span class="w"> </span>from geopandas.explore import _explore
<span class="w"> </span>from geopandas.geoseries import GeoSeries
<span class="gi">+</span>
<span class="w"> </span>from ._compat import HAS_PYPROJ, PANDAS_GE_30
<span class="w"> </span>from ._decorator import doc
<span class="gi">+</span>
<span class="w"> </span>if PANDAS_GE_30:
<span class="w"> </span>    from pandas.core.accessor import Accessor
<span class="w"> </span>else:
<span class="gu">@@ -25,7 +30,12 @@ def _geodataframe_constructor_with_fallback(*args, **kwargs):</span>
<span class="w"> </span>    to returning a DataFrame (if a certain operation does not preserve the
<span class="w"> </span>    geometry column)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    df = GeoDataFrame(*args, **kwargs)</span>
<span class="gi">+    geometry_cols_mask = df.dtypes == &quot;geometry&quot;</span>
<span class="gi">+    if len(geometry_cols_mask) == 0 or geometry_cols_mask.sum() == 0:</span>
<span class="gi">+        df = pd.DataFrame(df)</span>
<span class="gi">+</span>
<span class="gi">+    return df</span>


<span class="w"> </span>def _ensure_geometry(data, crs=None):
<span class="gu">@@ -37,12 +47,32 @@ def _ensure_geometry(data, crs=None):</span>

<span class="w"> </span>    If the input is a GeometryDtype with a set CRS, `crs` is ignored.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if is_geometry_type(data):</span>
<span class="gi">+        if isinstance(data, Series):</span>
<span class="gi">+            data = GeoSeries(data)</span>
<span class="gi">+        if data.crs is None and crs is not None:</span>
<span class="gi">+            # Avoids caching issues/crs sharing issues</span>
<span class="gi">+            data = data.copy()</span>
<span class="gi">+            if isinstance(data, GeometryArray):</span>
<span class="gi">+                data.crs = crs</span>
<span class="gi">+            else:</span>
<span class="gi">+                data.array.crs = crs</span>
<span class="gi">+        return data</span>
<span class="gi">+    else:</span>
<span class="gi">+        if isinstance(data, Series):</span>
<span class="gi">+            out = from_shapely(np.asarray(data), crs=crs)</span>
<span class="gi">+            return GeoSeries(out, index=data.index, name=data.name)</span>
<span class="gi">+        else:</span>
<span class="gi">+            out = from_shapely(data, crs=crs)</span>
<span class="gi">+            return out</span>


<span class="w"> </span>crs_mismatch_error = (
<span class="gd">-    &quot;CRS mismatch between CRS of the passed geometries and &#39;crs&#39;. Use &#39;GeoDataFrame.set_crs(crs, allow_override=True)&#39; to overwrite CRS or &#39;GeoDataFrame.to_crs(crs)&#39; to reproject geometries. &quot;</span>
<span class="gd">-    )</span>
<span class="gi">+    &quot;CRS mismatch between CRS of the passed geometries &quot;</span>
<span class="gi">+    &quot;and &#39;crs&#39;. Use &#39;GeoDataFrame.set_crs(crs, &quot;</span>
<span class="gi">+    &quot;allow_override=True)&#39; to overwrite CRS or &quot;</span>
<span class="gi">+    &quot;&#39;GeoDataFrame.to_crs(crs)&#39; to reproject geometries. &quot;</span>
<span class="gi">+)</span>


<span class="w"> </span>class GeoDataFrame(GeoPandasBase, DataFrame):
<span class="gu">@@ -103,57 +133,135 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>    --------
<span class="w"> </span>    GeoSeries : Series object designed to store shapely geometry objects
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    _metadata = [&#39;_geometry_column_name&#39;]</span>
<span class="gd">-    _internal_names = DataFrame._internal_names + [&#39;geometry&#39;]</span>
<span class="gi">+</span>
<span class="gi">+    _metadata = [&quot;_geometry_column_name&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    _internal_names = DataFrame._internal_names + [&quot;geometry&quot;]</span>
<span class="w"> </span>    _internal_names_set = set(_internal_names)
<span class="gi">+</span>
<span class="w"> </span>    _geometry_column_name = None

<span class="w"> </span>    def __init__(self, data=None, *args, geometry=None, crs=None, **kwargs):
<span class="gd">-        if kwargs.get(&#39;copy&#39;) is None and isinstance(data, DataFrame</span>
<span class="gd">-            ) and not isinstance(data, GeoDataFrame):</span>
<span class="gi">+        if (</span>
<span class="gi">+            kwargs.get(&quot;copy&quot;) is None</span>
<span class="gi">+            and isinstance(data, DataFrame)</span>
<span class="gi">+            and not isinstance(data, GeoDataFrame)</span>
<span class="gi">+        ):</span>
<span class="w"> </span>            kwargs.update(copy=True)
<span class="w"> </span>        super().__init__(data, *args, **kwargs)
<span class="gi">+</span>
<span class="gi">+        # set_geometry ensures the geometry data have the proper dtype,</span>
<span class="gi">+        # but is not called if `geometry=None` (&#39;geometry&#39; column present</span>
<span class="gi">+        # in the data), so therefore need to ensure it here manually</span>
<span class="gi">+        # but within a try/except because currently non-geometries are</span>
<span class="gi">+        # allowed in that case</span>
<span class="gi">+        # TODO do we want to raise / return normal DataFrame in this case?</span>
<span class="gi">+</span>
<span class="gi">+        # if gdf passed in and geo_col is set, we use that for geometry</span>
<span class="w"> </span>        if geometry is None and isinstance(data, GeoDataFrame):
<span class="w"> </span>            self._geometry_column_name = data._geometry_column_name
<span class="w"> </span>            if crs is not None and data.crs != crs:
<span class="w"> </span>                raise ValueError(crs_mismatch_error)
<span class="gd">-        if (geometry is None and self.columns.nlevels == 1 and &#39;geometry&#39; in</span>
<span class="gd">-            self.columns):</span>
<span class="gd">-            if (self.columns == &#39;geometry&#39;).sum() &gt; 1:</span>
<span class="gi">+</span>
<span class="gi">+        if (</span>
<span class="gi">+            geometry is None</span>
<span class="gi">+            and self.columns.nlevels == 1</span>
<span class="gi">+            and &quot;geometry&quot; in self.columns</span>
<span class="gi">+        ):</span>
<span class="gi">+            # Check for multiple columns with name &quot;geometry&quot;. If there are,</span>
<span class="gi">+            # self[&quot;geometry&quot;] is a gdf and constructor gets recursively recalled</span>
<span class="gi">+            # by pandas internals trying to access this</span>
<span class="gi">+            if (self.columns == &quot;geometry&quot;).sum() &gt; 1:</span>
<span class="w"> </span>                raise ValueError(
<span class="gd">-                    &quot;GeoDataFrame does not support multiple columns using the geometry column name &#39;geometry&#39;.&quot;</span>
<span class="gd">-                    )</span>
<span class="gi">+                    &quot;GeoDataFrame does not support multiple columns &quot;</span>
<span class="gi">+                    &quot;using the geometry column name &#39;geometry&#39;.&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+</span>
<span class="gi">+            # only if we have actual geometry values -&gt; call set_geometry</span>
<span class="w"> </span>            try:
<span class="gd">-                if hasattr(self[&#39;geometry&#39;].values, &#39;crs&#39;) and self[&#39;geometry&#39;</span>
<span class="gd">-                    ].values.crs and crs and not self[&#39;geometry&#39;</span>
<span class="gd">-                    ].values.crs == crs:</span>
<span class="gi">+                if (</span>
<span class="gi">+                    hasattr(self[&quot;geometry&quot;].values, &quot;crs&quot;)</span>
<span class="gi">+                    and self[&quot;geometry&quot;].values.crs</span>
<span class="gi">+                    and crs</span>
<span class="gi">+                    and not self[&quot;geometry&quot;].values.crs == crs</span>
<span class="gi">+                ):</span>
<span class="w"> </span>                    raise ValueError(crs_mismatch_error)
<span class="gd">-                self[&#39;geometry&#39;] = _ensure_geometry(self[&#39;geometry&#39;].values,</span>
<span class="gd">-                    crs)</span>
<span class="gi">+                self[&quot;geometry&quot;] = _ensure_geometry(self[&quot;geometry&quot;].values, crs)</span>
<span class="w"> </span>            except TypeError:
<span class="w"> </span>                pass
<span class="w"> </span>            else:
<span class="gd">-                geometry = &#39;geometry&#39;</span>
<span class="gi">+                geometry = &quot;geometry&quot;</span>
<span class="gi">+</span>
<span class="w"> </span>        if geometry is not None:
<span class="gd">-            if hasattr(geometry, &#39;crs&#39;</span>
<span class="gd">-                ) and geometry.crs and crs and not geometry.crs == crs:</span>
<span class="gi">+            if (</span>
<span class="gi">+                hasattr(geometry, &quot;crs&quot;)</span>
<span class="gi">+                and geometry.crs</span>
<span class="gi">+                and crs</span>
<span class="gi">+                and not geometry.crs == crs</span>
<span class="gi">+            ):</span>
<span class="w"> </span>                raise ValueError(crs_mismatch_error)
<span class="gd">-            if hasattr(geometry, &#39;name&#39;) and geometry.name not in (&#39;geometry&#39;,</span>
<span class="gd">-                None):</span>
<span class="gd">-                geometry = geometry.rename(&#39;geometry&#39;)</span>
<span class="gi">+</span>
<span class="gi">+            if hasattr(geometry, &quot;name&quot;) and geometry.name not in (&quot;geometry&quot;, None):</span>
<span class="gi">+                # __init__ always creates geometry col named &quot;geometry&quot;</span>
<span class="gi">+                # rename as `set_geometry` respects the given series name</span>
<span class="gi">+                geometry = geometry.rename(&quot;geometry&quot;)</span>
<span class="gi">+</span>
<span class="w"> </span>            self.set_geometry(geometry, inplace=True, crs=crs)
<span class="gi">+</span>
<span class="w"> </span>        if geometry is None and crs:
<span class="w"> </span>            raise ValueError(
<span class="gd">-                &quot;Assigning CRS to a GeoDataFrame without a geometry column is not supported. Supply geometry using the &#39;geometry=&#39; keyword argument, or by providing a DataFrame with column name &#39;geometry&#39;&quot;</span>
<span class="gd">-                )</span>
<span class="gi">+                &quot;Assigning CRS to a GeoDataFrame without a geometry column is not &quot;</span>
<span class="gi">+                &quot;supported. Supply geometry using the &#39;geometry=&#39; keyword argument, &quot;</span>
<span class="gi">+                &quot;or by providing a DataFrame with column name &#39;geometry&#39;&quot;,</span>
<span class="gi">+            )</span>

<span class="w"> </span>    def __setattr__(self, attr, val):
<span class="gd">-        if attr == &#39;geometry&#39;:</span>
<span class="gi">+        # have to special case geometry b/c pandas tries to use as column...</span>
<span class="gi">+        if attr == &quot;geometry&quot;:</span>
<span class="w"> </span>            object.__setattr__(self, attr, val)
<span class="w"> </span>        else:
<span class="w"> </span>            super().__setattr__(attr, val)
<span class="gd">-    geometry = property(fget=_get_geometry, fset=_set_geometry, doc=</span>
<span class="gd">-        &#39;Geometry data for GeoDataFrame&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    def _get_geometry(self):</span>
<span class="gi">+        if self._geometry_column_name not in self:</span>
<span class="gi">+            if self._geometry_column_name is None:</span>
<span class="gi">+                msg = (</span>
<span class="gi">+                    &quot;You are calling a geospatial method on the GeoDataFrame, &quot;</span>
<span class="gi">+                    &quot;but the active geometry column to use has not been set. &quot;</span>
<span class="gi">+                )</span>
<span class="gi">+            else:</span>
<span class="gi">+                msg = (</span>
<span class="gi">+                    &quot;You are calling a geospatial method on the GeoDataFrame, &quot;</span>
<span class="gi">+                    f&quot;but the active geometry column (&#39;{self._geometry_column_name}&#39;) &quot;</span>
<span class="gi">+                    &quot;is not present. &quot;</span>
<span class="gi">+                )</span>
<span class="gi">+            geo_cols = list(self.columns[self.dtypes == &quot;geometry&quot;])</span>
<span class="gi">+            if len(geo_cols) &gt; 0:</span>
<span class="gi">+                msg += (</span>
<span class="gi">+                    f&quot;\nThere are columns with geometry data type ({geo_cols}), and &quot;</span>
<span class="gi">+                    &quot;you can either set one as the active geometry with &quot;</span>
<span class="gi">+                    &#39;df.set_geometry(&quot;name&quot;) or access the column as a &#39;</span>
<span class="gi">+                    &#39;GeoSeries (df[&quot;name&quot;]) and call the method directly on it.&#39;</span>
<span class="gi">+                )</span>
<span class="gi">+            else:</span>
<span class="gi">+                msg += (</span>
<span class="gi">+                    &quot;\nThere are no existing columns with geometry data type. You can &quot;</span>
<span class="gi">+                    &quot;add a geometry column as the active geometry column with &quot;</span>
<span class="gi">+                    &quot;df.set_geometry. &quot;</span>
<span class="gi">+                )</span>
<span class="gi">+</span>
<span class="gi">+            raise AttributeError(msg)</span>
<span class="gi">+        return self[self._geometry_column_name]</span>
<span class="gi">+</span>
<span class="gi">+    def _set_geometry(self, col):</span>
<span class="gi">+        if not pd.api.types.is_list_like(col):</span>
<span class="gi">+            raise ValueError(&quot;Must use a list-like to set the geometry property&quot;)</span>
<span class="gi">+        self._persist_old_default_geometry_colname()</span>
<span class="gi">+        self.set_geometry(col, inplace=True)</span>
<span class="gi">+</span>
<span class="gi">+    geometry = property(</span>
<span class="gi">+        fget=_get_geometry, fset=_set_geometry, doc=&quot;Geometry data for GeoDataFrame&quot;</span>
<span class="gi">+    )</span>

<span class="w"> </span>    def set_geometry(self, col, drop=None, inplace=False, crs=None):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -222,7 +330,90 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoDataFrame.rename_geometry : rename an active geometry column
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # Most of the code here is taken from DataFrame.set_index()</span>
<span class="gi">+        if inplace:</span>
<span class="gi">+            frame = self</span>
<span class="gi">+        else:</span>
<span class="gi">+            if PANDAS_GE_30:</span>
<span class="gi">+                frame = self.copy(deep=False)</span>
<span class="gi">+            else:</span>
<span class="gi">+                frame = self.copy()</span>
<span class="gi">+</span>
<span class="gi">+        geo_column_name = self._geometry_column_name</span>
<span class="gi">+</span>
<span class="gi">+        if geo_column_name is None:</span>
<span class="gi">+            geo_column_name = &quot;geometry&quot;</span>
<span class="gi">+        if isinstance(col, (Series, list, np.ndarray, GeometryArray)):</span>
<span class="gi">+            if drop:</span>
<span class="gi">+                msg = (</span>
<span class="gi">+                    &quot;The `drop` keyword argument is deprecated and has no effect when &quot;</span>
<span class="gi">+                    &quot;`col` is an array-like value. You should stop passing `drop` to &quot;</span>
<span class="gi">+                    &quot;`set_geometry` when this is the case.&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+                warnings.warn(msg, category=FutureWarning, stacklevel=2)</span>
<span class="gi">+            if isinstance(col, Series) and col.name is not None:</span>
<span class="gi">+                geo_column_name = col.name</span>
<span class="gi">+</span>
<span class="gi">+            level = col</span>
<span class="gi">+        elif hasattr(col, &quot;ndim&quot;) and col.ndim &gt; 1:</span>
<span class="gi">+            raise ValueError(&quot;Must pass array with one dimension only.&quot;)</span>
<span class="gi">+        else:  # should be a colname</span>
<span class="gi">+            try:</span>
<span class="gi">+                level = frame[col]</span>
<span class="gi">+            except KeyError:</span>
<span class="gi">+                raise ValueError(&quot;Unknown column %s&quot; % col)</span>
<span class="gi">+            if isinstance(level, DataFrame):</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    &quot;GeoDataFrame does not support setting the geometry column where &quot;</span>
<span class="gi">+                    &quot;the column name is shared by multiple columns.&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+</span>
<span class="gi">+            given_colname_drop_msg = (</span>
<span class="gi">+                &quot;The `drop` keyword argument is deprecated and in future the only &quot;</span>
<span class="gi">+                &quot;supported behaviour will match drop=False. To silence this &quot;</span>
<span class="gi">+                &quot;warning and adopt the future behaviour, stop providing &quot;</span>
<span class="gi">+                &quot;`drop` as a keyword to `set_geometry`. To replicate the &quot;</span>
<span class="gi">+                &quot;`drop=True` behaviour you should update &quot;</span>
<span class="gi">+                &quot;your code to\n`geo_col_name = gdf.active_geometry_name;&quot;</span>
<span class="gi">+                &quot; gdf.set_geometry(new_geo_col).drop(&quot;</span>
<span class="gi">+                &quot;columns=geo_col_name).rename_geometry(geo_col_name)`.&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            if drop is False:  # specifically False, not falsy i.e. None</span>
<span class="gi">+                # User supplied False explicitly, but arg is deprecated</span>
<span class="gi">+                warnings.warn(</span>
<span class="gi">+                    given_colname_drop_msg,</span>
<span class="gi">+                    category=FutureWarning,</span>
<span class="gi">+                    stacklevel=2,</span>
<span class="gi">+                )</span>
<span class="gi">+            if drop:</span>
<span class="gi">+                del frame[col]</span>
<span class="gi">+                warnings.warn(</span>
<span class="gi">+                    given_colname_drop_msg,</span>
<span class="gi">+                    category=FutureWarning,</span>
<span class="gi">+                    stacklevel=2,</span>
<span class="gi">+                )</span>
<span class="gi">+            else:</span>
<span class="gi">+                # if not dropping, set the active geometry name to the given col name</span>
<span class="gi">+                geo_column_name = col</span>
<span class="gi">+</span>
<span class="gi">+        if not crs:</span>
<span class="gi">+            crs = getattr(level, &quot;crs&quot;, None)</span>
<span class="gi">+</span>
<span class="gi">+        # Check that we are using a listlike of geometries</span>
<span class="gi">+        level = _ensure_geometry(level, crs=crs)</span>
<span class="gi">+        # ensure_geometry only sets crs on level if it has crs==None</span>
<span class="gi">+        if isinstance(level, GeoSeries):</span>
<span class="gi">+            level.array.crs = crs</span>
<span class="gi">+        else:</span>
<span class="gi">+            level.crs = crs</span>
<span class="gi">+        # update _geometry_column_name prior to assignment</span>
<span class="gi">+        # to avoid default is None warning</span>
<span class="gi">+        frame._geometry_column_name = geo_column_name</span>
<span class="gi">+        frame[geo_column_name] = level</span>
<span class="gi">+</span>
<span class="gi">+        if not inplace:</span>
<span class="gi">+            return frame</span>

<span class="w"> </span>    def rename_geometry(self, col, inplace=False):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -257,7 +448,16 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoDataFrame.set_geometry : set the active geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        geometry_col = self.geometry.name</span>
<span class="gi">+        if col in self.columns:</span>
<span class="gi">+            raise ValueError(f&quot;Column named {col} already exists&quot;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            if not inplace:</span>
<span class="gi">+                return self.rename(columns={geometry_col: col}).set_geometry(</span>
<span class="gi">+                    col, inplace=inplace</span>
<span class="gi">+                )</span>
<span class="gi">+            self.rename(columns={geometry_col: col}, inplace=inplace)</span>
<span class="gi">+            self.set_geometry(col, inplace=inplace)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def active_geometry_name(self):
<span class="gu">@@ -277,7 +477,7 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoDataFrame.set_geometry : set the active geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self._geometry_column_name</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def crs(self):
<span class="gu">@@ -313,28 +513,66 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        GeoDataFrame.to_crs : re-project to another CRS

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        try:</span>
<span class="gi">+            return self.geometry.crs</span>
<span class="gi">+        except AttributeError:</span>
<span class="gi">+            raise AttributeError(</span>
<span class="gi">+                &quot;The CRS attribute of a GeoDataFrame without an active &quot;</span>
<span class="gi">+                &quot;geometry column is not defined. Use GeoDataFrame.set_geometry &quot;</span>
<span class="gi">+                &quot;to set the active geometry column.&quot;</span>
<span class="gi">+            )</span>

<span class="w"> </span>    @crs.setter
<span class="w"> </span>    def crs(self, value):
<span class="w"> </span>        &quot;&quot;&quot;Sets the value of the crs&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if self._geometry_column_name is None:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;Assigning CRS to a GeoDataFrame without a geometry column is not &quot;</span>
<span class="gi">+                &quot;supported. Use GeoDataFrame.set_geometry to set the active &quot;</span>
<span class="gi">+                &quot;geometry column.&quot;,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        if hasattr(self.geometry.values, &quot;crs&quot;):</span>
<span class="gi">+            if self.crs is not None:</span>
<span class="gi">+                warnings.warn(</span>
<span class="gi">+                    &quot;Overriding the CRS of a GeoDataFrame that already has CRS. &quot;</span>
<span class="gi">+                    &quot;This unsafe behavior will be deprecated in future versions. &quot;</span>
<span class="gi">+                    &quot;Use GeoDataFrame.set_crs method instead&quot;,</span>
<span class="gi">+                    stacklevel=2,</span>
<span class="gi">+                    category=DeprecationWarning,</span>
<span class="gi">+                )</span>
<span class="gi">+            self.geometry.values.crs = value</span>
<span class="gi">+        else:</span>
<span class="gi">+            # column called &#39;geometry&#39; without geometry</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;Assigning CRS to a GeoDataFrame without an active geometry &quot;</span>
<span class="gi">+                &quot;column is not supported. Use GeoDataFrame.set_geometry to set &quot;</span>
<span class="gi">+                &quot;the active geometry column.&quot;,</span>
<span class="gi">+            )</span>

<span class="w"> </span>    def __setstate__(self, state):
<span class="gi">+        # overriding DataFrame method for compat with older pickles (CRS handling)</span>
<span class="w"> </span>        crs = None
<span class="w"> </span>        if isinstance(state, dict):
<span class="gd">-            if &#39;crs&#39; in state and &#39;_crs&#39; not in state:</span>
<span class="gd">-                crs = state.pop(&#39;crs&#39;, None)</span>
<span class="gi">+            if &quot;crs&quot; in state and &quot;_crs&quot; not in state:</span>
<span class="gi">+                crs = state.pop(&quot;crs&quot;, None)</span>
<span class="w"> </span>            else:
<span class="gd">-                crs = state.pop(&#39;_crs&#39;, None)</span>
<span class="gi">+                crs = state.pop(&quot;_crs&quot;, None)</span>
<span class="w"> </span>            if crs is not None and not HAS_PYPROJ:
<span class="w"> </span>                raise ImportError(
<span class="gd">-                    &quot;Unpickling a GeoDataFrame with CRS requires the &#39;pyproj&#39; package, but it is not installed or does not import correctly. &quot;</span>
<span class="gd">-                    )</span>
<span class="gi">+                    &quot;Unpickling a GeoDataFrame with CRS requires the &#39;pyproj&#39; package, &quot;</span>
<span class="gi">+                    &quot;but it is not installed or does not import correctly. &quot;</span>
<span class="gi">+                )</span>
<span class="w"> </span>            elif crs is not None:
<span class="w"> </span>                from pyproj import CRS
<span class="gi">+</span>
<span class="w"> </span>                crs = CRS.from_user_input(crs)
<span class="gi">+</span>
<span class="w"> </span>        super().__setstate__(state)
<span class="gi">+</span>
<span class="gi">+        # for some versions that didn&#39;t yet have CRS at array level -&gt; crs is set</span>
<span class="gi">+        # at GeoDataFrame level with &#39;_crs&#39; (and not &#39;crs&#39;), so without propagating</span>
<span class="gi">+        # to the GeoSeries/GeometryArray</span>
<span class="w"> </span>        try:
<span class="w"> </span>            if crs is not None:
<span class="w"> </span>                if self.geometry.values.crs is None:
<span class="gu">@@ -365,7 +603,8 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        GeoDataFrame

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        dataframe = DataFrame.from_dict(data, **kwargs)</span>
<span class="gi">+        return cls(dataframe, geometry=geometry, crs=crs)</span>

<span class="w"> </span>    @classmethod
<span class="w"> </span>    def from_file(cls, filename, **kwargs):
<span class="gu">@@ -393,12 +632,18 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        &gt;&gt;&gt; path = geodatasets.get_path(&#39;nybb&#39;)
<span class="w"> </span>        &gt;&gt;&gt; gdf = geopandas.GeoDataFrame.from_file(path)
<span class="w"> </span>        &gt;&gt;&gt; gdf  # doctest: +SKIP
<span class="gd">-           BoroCode       BoroName     Shape_Leng    Shape_Area                                           geometry</span>
<span class="gd">-        0         5  Staten Island  330470.010332  1.623820e+09  MULTIPOLYGON (((970217.022 145643.332, 970227....</span>
<span class="gd">-        1         4         Queens  896344.047763  3.045213e+09  MULTIPOLYGON (((1029606.077 156073.814, 102957...</span>
<span class="gd">-        2         3       Brooklyn  741080.523166  1.937479e+09  MULTIPOLYGON (((1021176.479 151374.797, 102100...</span>
<span class="gd">-        3         1      Manhattan  359299.096471  6.364715e+08  MULTIPOLYGON (((981219.056 188655.316, 980940....</span>
<span class="gd">-        4         2          Bronx  464392.991824  1.186925e+09  MULTIPOLYGON (((1012821.806 229228.265, 101278...</span>
<span class="gi">+           BoroCode       BoroName     Shape_Leng    Shape_Area                 \</span>
<span class="gi">+                          geometry</span>
<span class="gi">+        0         5  Staten Island  330470.010332  1.623820e+09  MULTIPOLYGON ((\</span>
<span class="gi">+(970217.022 145643.332, 970227....</span>
<span class="gi">+        1         4         Queens  896344.047763  3.045213e+09  MULTIPOLYGON ((\</span>
<span class="gi">+(1029606.077 156073.814, 102957...</span>
<span class="gi">+        2         3       Brooklyn  741080.523166  1.937479e+09  MULTIPOLYGON ((\</span>
<span class="gi">+(1021176.479 151374.797, 102100...</span>
<span class="gi">+        3         1      Manhattan  359299.096471  6.364715e+08  MULTIPOLYGON ((\</span>
<span class="gi">+(981219.056 188655.316, 980940....</span>
<span class="gi">+        4         2          Bronx  464392.991824  1.186925e+09  MULTIPOLYGON ((\</span>
<span class="gi">+(1012821.806 229228.265, 101278...</span>

<span class="w"> </span>        The recommended method of reading files is :func:`geopandas.read_file`:

<span class="gu">@@ -410,7 +655,7 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        GeoDataFrame.to_file : write GeoDataFrame to file

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return geopandas.io.file._read_file(filename, **kwargs)</span>

<span class="w"> </span>    @classmethod
<span class="w"> </span>    def from_features(cls, features, crs=None, columns=None):
<span class="gu">@@ -472,12 +717,46 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        1  POINT (2 1)  name2

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # Handle feature collections</span>
<span class="gi">+        if hasattr(features, &quot;__geo_interface__&quot;):</span>
<span class="gi">+            fs = features.__geo_interface__</span>
<span class="gi">+        else:</span>
<span class="gi">+            fs = features</span>
<span class="gi">+</span>
<span class="gi">+        if isinstance(fs, dict) and fs.get(&quot;type&quot;) == &quot;FeatureCollection&quot;:</span>
<span class="gi">+            features_lst = fs[&quot;features&quot;]</span>
<span class="gi">+        else:</span>
<span class="gi">+            features_lst = features</span>
<span class="gi">+</span>
<span class="gi">+        rows = []</span>
<span class="gi">+        for feature in features_lst:</span>
<span class="gi">+            # load geometry</span>
<span class="gi">+            if hasattr(feature, &quot;__geo_interface__&quot;):</span>
<span class="gi">+                feature = feature.__geo_interface__</span>
<span class="gi">+            row = {</span>
<span class="gi">+                &quot;geometry&quot;: shape(feature[&quot;geometry&quot;]) if feature[&quot;geometry&quot;] else None</span>
<span class="gi">+            }</span>
<span class="gi">+            # load properties</span>
<span class="gi">+            properties = feature[&quot;properties&quot;]</span>
<span class="gi">+            if properties is None:</span>
<span class="gi">+                properties = {}</span>
<span class="gi">+            row.update(properties)</span>
<span class="gi">+            rows.append(row)</span>
<span class="gi">+        return cls(rows, columns=columns, crs=crs)</span>

<span class="w"> </span>    @classmethod
<span class="gd">-    def from_postgis(cls, sql, con, geom_col=&#39;geom&#39;, crs=None, index_col=</span>
<span class="gd">-        None, coerce_float=True, parse_dates=None, params=None, chunksize=None</span>
<span class="gd">-        ):</span>
<span class="gi">+    def from_postgis(</span>
<span class="gi">+        cls,</span>
<span class="gi">+        sql,</span>
<span class="gi">+        con,</span>
<span class="gi">+        geom_col=&quot;geom&quot;,</span>
<span class="gi">+        crs=None,</span>
<span class="gi">+        index_col=None,</span>
<span class="gi">+        coerce_float=True,</span>
<span class="gi">+        parse_dates=None,</span>
<span class="gi">+        params=None,</span>
<span class="gi">+        chunksize=None,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Alternate constructor to create a ``GeoDataFrame`` from a sql query
<span class="w"> </span>        containing a geometry column in WKB representation.
<span class="gu">@@ -534,7 +813,20 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        geopandas.read_postgis : read PostGIS database to GeoDataFrame
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+</span>
<span class="gi">+        df = geopandas.io.sql._read_postgis(</span>
<span class="gi">+            sql,</span>
<span class="gi">+            con,</span>
<span class="gi">+            geom_col=geom_col,</span>
<span class="gi">+            crs=crs,</span>
<span class="gi">+            index_col=index_col,</span>
<span class="gi">+            coerce_float=coerce_float,</span>
<span class="gi">+            parse_dates=parse_dates,</span>
<span class="gi">+            params=params,</span>
<span class="gi">+            chunksize=chunksize,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        return df</span>

<span class="w"> </span>    @classmethod
<span class="w"> </span>    def from_arrow(cls, table, geometry=None):
<span class="gu">@@ -568,10 +860,13 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        GeoDataFrame

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from geopandas.io._geoarrow import arrow_to_geopandas</span>
<span class="gi">+</span>
<span class="gi">+        return arrow_to_geopandas(table, geometry=geometry)</span>

<span class="gd">-    def to_json(self, na=&#39;null&#39;, show_bbox=False, drop_id=False, to_wgs84=</span>
<span class="gd">-        False, **kwargs):</span>
<span class="gi">+    def to_json(</span>
<span class="gi">+        self, na=&quot;null&quot;, show_bbox=False, drop_id=False, to_wgs84=False, **kwargs</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Returns a GeoJSON representation of the ``GeoDataFrame`` as a string.

<span class="gu">@@ -621,7 +916,11 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        1  name2  POINT (2 1)

<span class="w"> </span>        &gt;&gt;&gt; gdf.to_json()
<span class="gd">-        &#39;{&quot;type&quot;: &quot;FeatureCollection&quot;, &quot;features&quot;: [{&quot;id&quot;: &quot;0&quot;, &quot;type&quot;: &quot;Feature&quot;, &quot;properties&quot;: {&quot;col1&quot;: &quot;name1&quot;}, &quot;geometry&quot;: {&quot;type&quot;: &quot;Point&quot;, &quot;coordinates&quot;: [1.0, 2.0]}}, {&quot;id&quot;: &quot;1&quot;, &quot;type&quot;: &quot;Feature&quot;, &quot;properties&quot;: {&quot;col1&quot;: &quot;name2&quot;}, &quot;geometry&quot;: {&quot;type&quot;: &quot;Point&quot;, &quot;coordinates&quot;: [2.0, 1.0]}}], &quot;crs&quot;: {&quot;type&quot;: &quot;name&quot;, &quot;properties&quot;: {&quot;name&quot;: &quot;urn:ogc:def:crs:EPSG::3857&quot;}}}&#39;</span>
<span class="gi">+        &#39;{&quot;type&quot;: &quot;FeatureCollection&quot;, &quot;features&quot;: [{&quot;id&quot;: &quot;0&quot;, &quot;type&quot;: &quot;Feature&quot;, \</span>
<span class="gi">+&quot;properties&quot;: {&quot;col1&quot;: &quot;name1&quot;}, &quot;geometry&quot;: {&quot;type&quot;: &quot;Point&quot;, &quot;coordinates&quot;: [1.0,\</span>
<span class="gi">+ 2.0]}}, {&quot;id&quot;: &quot;1&quot;, &quot;type&quot;: &quot;Feature&quot;, &quot;properties&quot;: {&quot;col1&quot;: &quot;name2&quot;}, &quot;geometry&quot;\</span>
<span class="gi">+: {&quot;type&quot;: &quot;Point&quot;, &quot;coordinates&quot;: [2.0, 1.0]}}], &quot;crs&quot;: {&quot;type&quot;: &quot;name&quot;, &quot;properti\</span>
<span class="gi">+es&quot;: {&quot;name&quot;: &quot;urn:ogc:def:crs:EPSG::3857&quot;}}}&#39;</span>

<span class="w"> </span>        Alternatively, you can write GeoJSON to file:

<span class="gu">@@ -632,7 +931,35 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        GeoDataFrame.to_file : write GeoDataFrame to file

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if to_wgs84:</span>
<span class="gi">+            if self.crs:</span>
<span class="gi">+                df = self.to_crs(epsg=4326)</span>
<span class="gi">+            else:</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    &quot;CRS is not set. Cannot re-project to WGS84 (EPSG:4326).&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+        else:</span>
<span class="gi">+            df = self</span>
<span class="gi">+</span>
<span class="gi">+        geo = df.to_geo_dict(na=na, show_bbox=show_bbox, drop_id=drop_id)</span>
<span class="gi">+</span>
<span class="gi">+        # if the geometry is not in WGS84, include CRS in the JSON</span>
<span class="gi">+        if df.crs is not None and not df.crs.equals(&quot;epsg:4326&quot;):</span>
<span class="gi">+            auth_crsdef = self.crs.to_authority()</span>
<span class="gi">+            allowed_authorities = [&quot;EDCS&quot;, &quot;EPSG&quot;, &quot;OGC&quot;, &quot;SI&quot;, &quot;UCUM&quot;]</span>
<span class="gi">+</span>
<span class="gi">+            if auth_crsdef is None or auth_crsdef[0] not in allowed_authorities:</span>
<span class="gi">+                warnings.warn(</span>
<span class="gi">+                    &quot;GeoDataFrame&#39;s CRS is not representable in URN OGC &quot;</span>
<span class="gi">+                    &quot;format. Resulting JSON will contain no CRS information.&quot;,</span>
<span class="gi">+                    stacklevel=2,</span>
<span class="gi">+                )</span>
<span class="gi">+            else:</span>
<span class="gi">+                authority, code = auth_crsdef</span>
<span class="gi">+                ogc_crs = f&quot;urn:ogc:def:crs:{authority}::{code}&quot;</span>
<span class="gi">+                geo[&quot;crs&quot;] = {&quot;type&quot;: &quot;name&quot;, &quot;properties&quot;: {&quot;name&quot;: ogc_crs}}</span>
<span class="gi">+</span>
<span class="gi">+        return json.dumps(geo, **kwargs)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def __geo_interface__(self):
<span class="gu">@@ -660,11 +987,15 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        1  name2  POINT (2 1)

<span class="w"> </span>        &gt;&gt;&gt; gdf.__geo_interface__
<span class="gd">-        {&#39;type&#39;: &#39;FeatureCollection&#39;, &#39;features&#39;: [{&#39;id&#39;: &#39;0&#39;, &#39;type&#39;: &#39;Feature&#39;, &#39;properties&#39;: {&#39;col1&#39;: &#39;name1&#39;}, &#39;geometry&#39;: {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: (1.0, 2.0)}, &#39;bbox&#39;: (1.0, 2.0, 1.0, 2.0)}, {&#39;id&#39;: &#39;1&#39;, &#39;type&#39;: &#39;Feature&#39;, &#39;properties&#39;: {&#39;col1&#39;: &#39;name2&#39;}, &#39;geometry&#39;: {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: (2.0, 1.0)}, &#39;bbox&#39;: (2.0, 1.0, 2.0, 1.0)}], &#39;bbox&#39;: (1.0, 1.0, 2.0, 2.0)}</span>
<span class="gi">+        {&#39;type&#39;: &#39;FeatureCollection&#39;, &#39;features&#39;: [{&#39;id&#39;: &#39;0&#39;, &#39;type&#39;: &#39;Feature&#39;, \</span>
<span class="gi">+&#39;properties&#39;: {&#39;col1&#39;: &#39;name1&#39;}, &#39;geometry&#39;: {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: (1.0\</span>
<span class="gi">+, 2.0)}, &#39;bbox&#39;: (1.0, 2.0, 1.0, 2.0)}, {&#39;id&#39;: &#39;1&#39;, &#39;type&#39;: &#39;Feature&#39;, &#39;properties\</span>
<span class="gi">+&#39;: {&#39;col1&#39;: &#39;name2&#39;}, &#39;geometry&#39;: {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: (2.0, 1.0)}, &#39;b\</span>
<span class="gi">+box&#39;: (2.0, 1.0, 2.0, 1.0)}], &#39;bbox&#39;: (1.0, 1.0, 2.0, 2.0)}</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        return self.to_geo_dict(na=&#39;null&#39;, show_bbox=True, drop_id=False)</span>
<span class="gi">+        return self.to_geo_dict(na=&quot;null&quot;, show_bbox=True, drop_id=False)</span>

<span class="gd">-    def iterfeatures(self, na=&#39;null&#39;, show_bbox=False, drop_id=False):</span>
<span class="gi">+    def iterfeatures(self, na=&quot;null&quot;, show_bbox=False, drop_id=False):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Returns an iterator that yields feature dictionaries that comply with
<span class="w"> </span>        __geo_interface__
<span class="gu">@@ -676,7 +1007,8 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>            Indicates how to output missing (NaN) values in the GeoDataFrame

<span class="w"> </span>            - null: output the missing entries as JSON null
<span class="gd">-            - drop: remove the property from the feature. This applies to each feature individually so that features may have different properties</span>
<span class="gi">+            - drop: remove the property from the feature. This applies to each feature \</span>
<span class="gi">+individually so that features may have different properties</span>
<span class="w"> </span>            - keep: output the missing entries as NaN

<span class="w"> </span>        show_bbox : bool, optional
<span class="gu">@@ -699,11 +1031,79 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>

<span class="w"> </span>        &gt;&gt;&gt; feature = next(gdf.iterfeatures())
<span class="w"> </span>        &gt;&gt;&gt; feature
<span class="gd">-        {&#39;id&#39;: &#39;0&#39;, &#39;type&#39;: &#39;Feature&#39;, &#39;properties&#39;: {&#39;col1&#39;: &#39;name1&#39;}, &#39;geometry&#39;: {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: (1.0, 2.0)}}</span>
<span class="gi">+        {&#39;id&#39;: &#39;0&#39;, &#39;type&#39;: &#39;Feature&#39;, &#39;properties&#39;: {&#39;col1&#39;: &#39;name1&#39;}, &#39;geometry&#39;: {\</span>
<span class="gi">+&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: (1.0, 2.0)}}</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if na not in [&quot;null&quot;, &quot;drop&quot;, &quot;keep&quot;]:</span>
<span class="gi">+            raise ValueError(&quot;Unknown na method {0}&quot;.format(na))</span>
<span class="gi">+</span>
<span class="gi">+        if self._geometry_column_name not in self:</span>
<span class="gi">+            raise AttributeError(</span>
<span class="gi">+                &quot;No geometry data set (expected in column &#39;%s&#39;).&quot;</span>
<span class="gi">+                % self._geometry_column_name</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        ids = np.array(self.index, copy=False)</span>
<span class="gi">+        geometries = np.array(self[self._geometry_column_name], copy=False)</span>
<span class="gi">+</span>
<span class="gi">+        if not self.columns.is_unique:</span>
<span class="gi">+            raise ValueError(&quot;GeoDataFrame cannot contain duplicated column names.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        properties_cols = self.columns.drop(self._geometry_column_name)</span>
<span class="gi">+</span>
<span class="gi">+        if len(properties_cols) &gt; 0:</span>
<span class="gi">+            # convert to object to get python scalars.</span>
<span class="gi">+            properties_cols = self[properties_cols]</span>
<span class="gi">+            properties = properties_cols.astype(object)</span>
<span class="gi">+            na_mask = pd.isna(properties_cols).values</span>
<span class="gi">+</span>
<span class="gi">+            if na == &quot;null&quot;:</span>
<span class="gi">+                properties[na_mask] = None</span>
<span class="gi">+</span>
<span class="gi">+            for i, row in enumerate(properties.values):</span>
<span class="gi">+                geom = geometries[i]</span>
<span class="gi">+</span>
<span class="gi">+                if na == &quot;drop&quot;:</span>
<span class="gi">+                    na_mask_row = na_mask[i]</span>
<span class="gi">+                    properties_items = {</span>
<span class="gi">+                        k: v</span>
<span class="gi">+                        for k, v, na in zip(properties_cols, row, na_mask_row)</span>
<span class="gi">+                        if not na</span>
<span class="gi">+                    }</span>
<span class="gi">+                else:</span>
<span class="gi">+                    properties_items = dict(zip(properties_cols, row))</span>
<span class="gi">+</span>
<span class="gi">+                if drop_id:</span>
<span class="gi">+                    feature = {}</span>
<span class="gi">+                else:</span>
<span class="gi">+                    feature = {&quot;id&quot;: str(ids[i])}</span>
<span class="gi">+</span>
<span class="gi">+                feature[&quot;type&quot;] = &quot;Feature&quot;</span>
<span class="gi">+                feature[&quot;properties&quot;] = properties_items</span>
<span class="gi">+                feature[&quot;geometry&quot;] = mapping(geom) if geom else None</span>
<span class="gi">+</span>
<span class="gi">+                if show_bbox:</span>
<span class="gi">+                    feature[&quot;bbox&quot;] = geom.bounds if geom else None</span>
<span class="gi">+</span>
<span class="gi">+                yield feature</span>
<span class="gi">+</span>
<span class="gi">+        else:</span>
<span class="gi">+            for fid, geom in zip(ids, geometries):</span>
<span class="gi">+                if drop_id:</span>
<span class="gi">+                    feature = {}</span>
<span class="gi">+                else:</span>
<span class="gi">+                    feature = {&quot;id&quot;: str(fid)}</span>
<span class="gi">+</span>
<span class="gi">+                feature[&quot;type&quot;] = &quot;Feature&quot;</span>
<span class="gi">+                feature[&quot;properties&quot;] = {}</span>
<span class="gi">+                feature[&quot;geometry&quot;] = mapping(geom) if geom else None</span>
<span class="gi">+</span>
<span class="gi">+                if show_bbox:</span>
<span class="gi">+                    feature[&quot;bbox&quot;] = geom.bounds if geom else None</span>
<span class="gi">+</span>
<span class="gi">+                yield feature</span>

<span class="gd">-    def to_geo_dict(self, na=&#39;null&#39;, show_bbox=False, drop_id=False):</span>
<span class="gi">+    def to_geo_dict(self, na=&quot;null&quot;, show_bbox=False, drop_id=False):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Returns a python feature collection representation of the GeoDataFrame
<span class="w"> </span>        as a dictionary with a list of features based on the ``__geo_interface__``
<span class="gu">@@ -716,7 +1116,8 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>            Indicates how to output missing (NaN) values in the GeoDataFrame

<span class="w"> </span>            - null: output the missing entries as JSON null
<span class="gd">-            - drop: remove the property from the feature. This applies to each feature individually so that features may have different properties</span>
<span class="gi">+            - drop: remove the property from the feature. This applies to each feature \</span>
<span class="gi">+individually so that features may have different properties</span>
<span class="w"> </span>            - keep: output the missing entries as NaN

<span class="w"> </span>        show_bbox : bool, optional
<span class="gu">@@ -738,14 +1139,27 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        1  name2  POINT (2 1)

<span class="w"> </span>        &gt;&gt;&gt; gdf.to_geo_dict()
<span class="gd">-        {&#39;type&#39;: &#39;FeatureCollection&#39;, &#39;features&#39;: [{&#39;id&#39;: &#39;0&#39;, &#39;type&#39;: &#39;Feature&#39;, &#39;properties&#39;: {&#39;col1&#39;: &#39;name1&#39;}, &#39;geometry&#39;: {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: (1.0, 2.0)}}, {&#39;id&#39;: &#39;1&#39;, &#39;type&#39;: &#39;Feature&#39;, &#39;properties&#39;: {&#39;col1&#39;: &#39;name2&#39;}, &#39;geometry&#39;: {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: (2.0, 1.0)}}]}</span>
<span class="gi">+        {&#39;type&#39;: &#39;FeatureCollection&#39;, &#39;features&#39;: [{&#39;id&#39;: &#39;0&#39;, &#39;type&#39;: &#39;Feature&#39;, &#39;\</span>
<span class="gi">+properties&#39;: {&#39;col1&#39;: &#39;name1&#39;}, &#39;geometry&#39;: {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: (1.0, \</span>
<span class="gi">+2.0)}}, {&#39;id&#39;: &#39;1&#39;, &#39;type&#39;: &#39;Feature&#39;, &#39;properties&#39;: {&#39;col1&#39;: &#39;name2&#39;}, &#39;geometry&#39;:\</span>
<span class="gi">+ {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: (2.0, 1.0)}}]}</span>

<span class="w"> </span>        See also
<span class="w"> </span>        --------
<span class="w"> </span>        GeoDataFrame.to_json : return a GeoDataFrame as a GeoJSON string

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        geo = {</span>
<span class="gi">+            &quot;type&quot;: &quot;FeatureCollection&quot;,</span>
<span class="gi">+            &quot;features&quot;: list(</span>
<span class="gi">+                self.iterfeatures(na=na, show_bbox=show_bbox, drop_id=drop_id)</span>
<span class="gi">+            ),</span>
<span class="gi">+        }</span>
<span class="gi">+</span>
<span class="gi">+        if show_bbox:</span>
<span class="gi">+            geo[&quot;bbox&quot;] = tuple(self.total_bounds)</span>
<span class="gi">+</span>
<span class="gi">+        return geo</span>

<span class="w"> </span>    def to_wkb(self, hex=False, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -765,7 +1179,14 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        DataFrame
<span class="w"> </span>            geometry columns are encoded to WKB
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+</span>
<span class="gi">+        df = DataFrame(self.copy())</span>
<span class="gi">+</span>
<span class="gi">+        # Encode all geometry columns to WKB</span>
<span class="gi">+        for col in df.columns[df.dtypes == &quot;geometry&quot;]:</span>
<span class="gi">+            df[col] = to_wkb(df[col].values, hex=hex, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+        return df</span>

<span class="w"> </span>    def to_wkt(self, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -781,10 +1202,18 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        DataFrame
<span class="w"> </span>            geometry columns are encoded to WKT
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>

<span class="gd">-    def to_arrow(self, *, index=None, geometry_encoding=&#39;WKB&#39;, interleaved=</span>
<span class="gd">-        True, include_z=None):</span>
<span class="gi">+        df = DataFrame(self.copy())</span>
<span class="gi">+</span>
<span class="gi">+        # Encode all geometry columns to WKT</span>
<span class="gi">+        for col in df.columns[df.dtypes == &quot;geometry&quot;]:</span>
<span class="gi">+            df[col] = to_wkt(df[col].values, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+        return df</span>
<span class="gi">+</span>
<span class="gi">+    def to_arrow(</span>
<span class="gi">+        self, *, index=None, geometry_encoding=&quot;WKB&quot;, interleaved=True, include_z=None</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Encode a GeoDataFrame to GeoArrow format.

<span class="w"> </span>        See https://geoarrow.org/ for details on the GeoArrow specification.
<span class="gu">@@ -855,14 +1284,31 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        geometry: binary
<span class="w"> </span>        ----
<span class="w"> </span>        col1: [[&quot;name1&quot;,&quot;name2&quot;]]
<span class="gd">-        geometry: [[0101000000000000000000F03F0000000000000040,01010000000000000000000040000000000000F03F]]</span>
<span class="gi">+        geometry: [[0101000000000000000000F03F0000000000000040,\</span>
<span class="gi">+01010000000000000000000040000000000000F03F]]</span>

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def to_parquet(self, path, index=None, compression=&#39;snappy&#39;,</span>
<span class="gd">-        geometry_encoding=&#39;WKB&#39;, write_covering_bbox=False, schema_version=</span>
<span class="gd">-        None, **kwargs):</span>
<span class="gi">+        from geopandas.io._geoarrow import ArrowTable, geopandas_to_arrow</span>
<span class="gi">+</span>
<span class="gi">+        table, _ = geopandas_to_arrow(</span>
<span class="gi">+            self,</span>
<span class="gi">+            index=index,</span>
<span class="gi">+            geometry_encoding=geometry_encoding,</span>
<span class="gi">+            interleaved=interleaved,</span>
<span class="gi">+            include_z=include_z,</span>
<span class="gi">+        )</span>
<span class="gi">+        return ArrowTable(table)</span>
<span class="gi">+</span>
<span class="gi">+    def to_parquet(</span>
<span class="gi">+        self,</span>
<span class="gi">+        path,</span>
<span class="gi">+        index=None,</span>
<span class="gi">+        compression=&quot;snappy&quot;,</span>
<span class="gi">+        geometry_encoding=&quot;WKB&quot;,</span>
<span class="gi">+        write_covering_bbox=False,</span>
<span class="gi">+        schema_version=None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Write a GeoDataFrame to the Parquet format.

<span class="w"> </span>        By default, all geometry columns present are serialized to WKB format
<span class="gu">@@ -915,10 +1361,33 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        GeoDataFrame.to_feather : write GeoDataFrame to feather
<span class="w"> </span>        GeoDataFrame.to_file : write GeoDataFrame to file
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>

<span class="gd">-    def to_feather(self, path, index=None, compression=None, schema_version</span>
<span class="gd">-        =None, **kwargs):</span>
<span class="gi">+        # Accept engine keyword for compatibility with pandas.DataFrame.to_parquet</span>
<span class="gi">+        # The only engine currently supported by GeoPandas is pyarrow, so no</span>
<span class="gi">+        # other engine should be specified.</span>
<span class="gi">+        engine = kwargs.pop(&quot;engine&quot;, &quot;auto&quot;)</span>
<span class="gi">+        if engine not in (&quot;auto&quot;, &quot;pyarrow&quot;):</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;GeoPandas only supports using pyarrow as the engine for &quot;</span>
<span class="gi">+                f&quot;to_parquet: {engine!r} passed instead.&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        from geopandas.io.arrow import _to_parquet</span>
<span class="gi">+</span>
<span class="gi">+        _to_parquet(</span>
<span class="gi">+            self,</span>
<span class="gi">+            path,</span>
<span class="gi">+            compression=compression,</span>
<span class="gi">+            geometry_encoding=geometry_encoding,</span>
<span class="gi">+            index=index,</span>
<span class="gi">+            schema_version=schema_version,</span>
<span class="gi">+            write_covering_bbox=write_covering_bbox,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def to_feather(</span>
<span class="gi">+        self, path, index=None, compression=None, schema_version=None, **kwargs</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Write a GeoDataFrame to the Feather format.

<span class="w"> </span>        Any geometry columns present are serialized to WKB format in the file.
<span class="gu">@@ -956,10 +1425,19 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        GeoDataFrame.to_parquet : write GeoDataFrame to parquet
<span class="w"> </span>        GeoDataFrame.to_file : write GeoDataFrame to file
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>

<span class="gd">-    def to_file(self, filename, driver=None, schema=None, index=None, **kwargs</span>
<span class="gd">-        ):</span>
<span class="gi">+        from geopandas.io.arrow import _to_feather</span>
<span class="gi">+</span>
<span class="gi">+        _to_feather(</span>
<span class="gi">+            self,</span>
<span class="gi">+            path,</span>
<span class="gi">+            index=index,</span>
<span class="gi">+            compression=compression,</span>
<span class="gi">+            schema_version=schema_version,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def to_file(self, filename, driver=None, schema=None, index=None, **kwargs):</span>
<span class="w"> </span>        &quot;&quot;&quot;Write the ``GeoDataFrame`` to a file.

<span class="w"> </span>        By default, an ESRI shapefile is written, but any OGR data source
<span class="gu">@@ -1053,10 +1531,11 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        ... )  # doctest: +SKIP

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from geopandas.io.file import _to_file</span>

<span class="gd">-    def set_crs(self, crs=None, epsg=None, inplace=False, allow_override=False</span>
<span class="gd">-        ):</span>
<span class="gi">+        _to_file(self, filename, driver, schema, index, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    def set_crs(self, crs=None, epsg=None, inplace=False, allow_override=False):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Set the Coordinate Reference System (CRS) of the ``GeoDataFrame``.

<span class="gu">@@ -1130,7 +1609,14 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        GeoDataFrame.to_crs : re-project to another CRS

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if not inplace:</span>
<span class="gi">+            df = self.copy()</span>
<span class="gi">+        else:</span>
<span class="gi">+            df = self</span>
<span class="gi">+        df.geometry = df.geometry.set_crs(</span>
<span class="gi">+            crs=crs, epsg=epsg, allow_override=allow_override, inplace=True</span>
<span class="gi">+        )</span>
<span class="gi">+        return df</span>

<span class="w"> </span>    def to_crs(self, crs=None, epsg=None, inplace=False):
<span class="w"> </span>        &quot;&quot;&quot;Transform geometries to a new coordinate reference system.
<span class="gu">@@ -1208,9 +1694,16 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoDataFrame.set_crs : assign CRS without re-projection
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if inplace:</span>
<span class="gi">+            df = self</span>
<span class="gi">+        else:</span>
<span class="gi">+            df = self.copy()</span>
<span class="gi">+        geom = df.geometry.to_crs(crs=crs, epsg=epsg)</span>
<span class="gi">+        df.geometry = geom</span>
<span class="gi">+        if not inplace:</span>
<span class="gi">+            return df</span>

<span class="gd">-    def estimate_utm_crs(self, datum_name=&#39;WGS 84&#39;):</span>
<span class="gi">+    def estimate_utm_crs(self, datum_name=&quot;WGS 84&quot;):</span>
<span class="w"> </span>        &quot;&quot;&quot;Returns the estimated UTM CRS based on the bounds of the dataset.

<span class="w"> </span>        .. versionadded:: 0.9
<span class="gu">@@ -1246,7 +1739,7 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        - Ellipsoid: WGS 84
<span class="w"> </span>        - Prime Meridian: Greenwich
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.geometry.estimate_utm_crs(datum_name=datum_name)</span>

<span class="w"> </span>    def __getitem__(self, key):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -1255,17 +1748,23 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>        return a GeoDataFrame.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        result = super().__getitem__(key)
<span class="gd">-        if pd.api.types.is_scalar(key) and key == &#39;&#39; and isinstance(self.</span>
<span class="gd">-            columns, pd.MultiIndex) and isinstance(result, Series</span>
<span class="gd">-            ) and not is_geometry_type(result):</span>
<span class="gi">+        # Custom logic to avoid waiting for pandas GH51895</span>
<span class="gi">+        # result is not geometry dtype for multi-indexes</span>
<span class="gi">+        if (</span>
<span class="gi">+            pd.api.types.is_scalar(key)</span>
<span class="gi">+            and key == &quot;&quot;</span>
<span class="gi">+            and isinstance(self.columns, pd.MultiIndex)</span>
<span class="gi">+            and isinstance(result, Series)</span>
<span class="gi">+            and not is_geometry_type(result)</span>
<span class="gi">+        ):</span>
<span class="w"> </span>            loc = self.columns.get_loc(key)
<span class="gd">-            result = self.iloc[:, loc].squeeze(axis=&#39;columns&#39;)</span>
<span class="gi">+            # squeeze stops multilevel columns from returning a gdf</span>
<span class="gi">+            result = self.iloc[:, loc].squeeze(axis=&quot;columns&quot;)</span>
<span class="w"> </span>        geo_col = self._geometry_column_name
<span class="gd">-        if isinstance(result, Series) and isinstance(result.dtype,</span>
<span class="gd">-            GeometryDtype):</span>
<span class="gi">+        if isinstance(result, Series) and isinstance(result.dtype, GeometryDtype):</span>
<span class="w"> </span>            result.__class__ = GeoSeries
<span class="w"> </span>        elif isinstance(result, DataFrame):
<span class="gd">-            if (result.dtypes == &#39;geometry&#39;).sum() &gt; 0:</span>
<span class="gi">+            if (result.dtypes == &quot;geometry&quot;).sum() &gt; 0:</span>
<span class="w"> </span>                result.__class__ = GeoDataFrame
<span class="w"> </span>                if geo_col in result:
<span class="w"> </span>                    result._geometry_column_name = geo_col
<span class="gu">@@ -1276,54 +1775,182 @@ class GeoDataFrame(GeoPandasBase, DataFrame):</span>
<span class="w"> </span>    def _persist_old_default_geometry_colname(self):
<span class="w"> </span>        &quot;&quot;&quot;Internal util to temporarily persist the default geometry column
<span class="w"> </span>        name of &#39;geometry&#39; for backwards compatibility.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # self.columns check required to avoid this warning in __init__</span>
<span class="gi">+        if self._geometry_column_name is None and &quot;geometry&quot; not in self.columns:</span>
<span class="gi">+            msg = (</span>
<span class="gi">+                &quot;You are adding a column named &#39;geometry&#39; to a GeoDataFrame &quot;</span>
<span class="gi">+                &quot;constructed without an active geometry column. Currently, &quot;</span>
<span class="gi">+                &quot;this automatically sets the active geometry column to &#39;geometry&#39; &quot;</span>
<span class="gi">+                &quot;but in the future that will no longer happen. Instead, either &quot;</span>
<span class="gi">+                &quot;provide geometry to the GeoDataFrame constructor &quot;</span>
<span class="gi">+                &quot;(GeoDataFrame(... geometry=GeoSeries()) or use &quot;</span>
<span class="gi">+                &quot;`set_geometry(&#39;geometry&#39;)` &quot;</span>
<span class="gi">+                &quot;to explicitly set the active geometry column.&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+            warnings.warn(msg, category=FutureWarning, stacklevel=3)</span>
<span class="gi">+            self._geometry_column_name = &quot;geometry&quot;</span>

<span class="w"> </span>    def __setitem__(self, key, value):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Overwritten to preserve CRS of GeometryArray in cases like
<span class="w"> </span>        df[&#39;geometry&#39;] = [geom... for geom in df.geometry]
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        if not pd.api.types.is_list_like(key) and (key == self.</span>
<span class="gd">-            _geometry_column_name or key == &#39;geometry&#39; and self.</span>
<span class="gd">-            _geometry_column_name is None):</span>
<span class="gd">-            if pd.api.types.is_scalar(value) or isinstance(value, BaseGeometry</span>
<span class="gd">-                ):</span>
<span class="gi">+</span>
<span class="gi">+        if not pd.api.types.is_list_like(key) and (</span>
<span class="gi">+            key == self._geometry_column_name</span>
<span class="gi">+            or key == &quot;geometry&quot;</span>
<span class="gi">+            and self._geometry_column_name is None</span>
<span class="gi">+        ):</span>
<span class="gi">+            if pd.api.types.is_scalar(value) or isinstance(value, BaseGeometry):</span>
<span class="w"> </span>                value = [value] * self.shape[0]
<span class="w"> </span>            try:
<span class="w"> </span>                if self._geometry_column_name is not None:
<span class="gd">-                    crs = getattr(self, &#39;crs&#39;, None)</span>
<span class="gd">-                else:</span>
<span class="gi">+                    crs = getattr(self, &quot;crs&quot;, None)</span>
<span class="gi">+                else:  # don&#39;t use getattr, because a col &quot;crs&quot; might exist</span>
<span class="w"> </span>                    crs = None
<span class="w"> </span>                value = _ensure_geometry(value, crs=crs)
<span class="gd">-                if key == &#39;geometry&#39;:</span>
<span class="gi">+                if key == &quot;geometry&quot;:</span>
<span class="w"> </span>                    self._persist_old_default_geometry_colname()
<span class="w"> </span>            except TypeError:
<span class="gd">-                warnings.warn(&#39;Geometry column does not contain geometry.&#39;,</span>
<span class="gd">-                    stacklevel=2)</span>
<span class="gi">+                warnings.warn(</span>
<span class="gi">+                    &quot;Geometry column does not contain geometry.&quot;,</span>
<span class="gi">+                    stacklevel=2,</span>
<span class="gi">+                )</span>
<span class="w"> </span>        super().__setitem__(key, value)

<span class="gi">+    #</span>
<span class="gi">+    # Implement pandas methods</span>
<span class="gi">+    #</span>
<span class="gi">+    @doc(pd.DataFrame)</span>
<span class="gi">+    def copy(self, deep=True):</span>
<span class="gi">+        copied = super().copy(deep=deep)</span>
<span class="gi">+        if type(copied) is pd.DataFrame:</span>
<span class="gi">+            copied.__class__ = GeoDataFrame</span>
<span class="gi">+            copied._geometry_column_name = self._geometry_column_name</span>
<span class="gi">+        return copied</span>
<span class="gi">+</span>
<span class="gi">+    @doc(pd.DataFrame)</span>
<span class="gi">+    def apply(self, func, axis=0, raw=False, result_type=None, args=(), **kwargs):</span>
<span class="gi">+        result = super().apply(</span>
<span class="gi">+            func, axis=axis, raw=raw, result_type=result_type, args=args, **kwargs</span>
<span class="gi">+        )</span>
<span class="gi">+        # Reconstruct gdf if it was lost by apply</span>
<span class="gi">+        if (</span>
<span class="gi">+            isinstance(result, DataFrame)</span>
<span class="gi">+            and self._geometry_column_name in result.columns</span>
<span class="gi">+        ):</span>
<span class="gi">+            # axis=1 apply will split GeometryDType to object, try and cast back</span>
<span class="gi">+            try:</span>
<span class="gi">+                result = result.set_geometry(self._geometry_column_name)</span>
<span class="gi">+            except TypeError:</span>
<span class="gi">+                pass</span>
<span class="gi">+            else:</span>
<span class="gi">+                if self.crs is not None and result.crs is None:</span>
<span class="gi">+                    result.set_crs(self.crs, inplace=True)</span>
<span class="gi">+        elif isinstance(result, Series) and result.dtype == &quot;object&quot;:</span>
<span class="gi">+            # Try reconstruct series GeometryDtype if lost by apply</span>
<span class="gi">+            # If all none and object dtype assert list of nones is more likely</span>
<span class="gi">+            # intended than list of null geometry.</span>
<span class="gi">+            if not result.isna().all():</span>
<span class="gi">+                try:</span>
<span class="gi">+                    # not enough info about func to preserve CRS</span>
<span class="gi">+                    result = _ensure_geometry(result)</span>
<span class="gi">+</span>
<span class="gi">+                except (TypeError, shapely.errors.GeometryTypeError):</span>
<span class="gi">+                    pass</span>
<span class="gi">+</span>
<span class="gi">+        return result</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def _constructor(self):</span>
<span class="gi">+        return _geodataframe_constructor_with_fallback</span>
<span class="gi">+</span>
<span class="gi">+    def _constructor_from_mgr(self, mgr, axes):</span>
<span class="gi">+        # replicate _geodataframe_constructor_with_fallback behaviour</span>
<span class="gi">+        # unless safe to skip</span>
<span class="gi">+        if not any(isinstance(block.dtype, GeometryDtype) for block in mgr.blocks):</span>
<span class="gi">+            return _geodataframe_constructor_with_fallback(</span>
<span class="gi">+                pd.DataFrame._from_mgr(mgr, axes)</span>
<span class="gi">+            )</span>
<span class="gi">+        gdf = GeoDataFrame._from_mgr(mgr, axes)</span>
<span class="gi">+        # _from_mgr doesn&#39;t preserve metadata (expect __finalize__ to be called)</span>
<span class="gi">+        # still need to mimic __init__ behaviour with geometry=None</span>
<span class="gi">+        if (gdf.columns == &quot;geometry&quot;).sum() == 1:  # only if &quot;geometry&quot; is single col</span>
<span class="gi">+            gdf._geometry_column_name = &quot;geometry&quot;</span>
<span class="gi">+        return gdf</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def _constructor_sliced(self):</span>
<span class="gi">+        def _geodataframe_constructor_sliced(*args, **kwargs):</span>
<span class="gi">+            &quot;&quot;&quot;</span>
<span class="gi">+            A specialized (Geo)Series constructor which can fall back to a</span>
<span class="gi">+            Series if a certain operation does not produce geometries:</span>
<span class="gi">+</span>
<span class="gi">+            - We only return a GeoSeries if the data is actually of geometry</span>
<span class="gi">+              dtype (and so we don&#39;t try to convert geometry objects such as</span>
<span class="gi">+              the normal GeoSeries(..) constructor does with `_ensure_geometry`).</span>
<span class="gi">+            - When we get here from obtaining a row or column from a</span>
<span class="gi">+              GeoDataFrame, the goal is to only return a GeoSeries for a</span>
<span class="gi">+              geometry column, and not return a GeoSeries for a row that happened</span>
<span class="gi">+              to come from a DataFrame with only geometry dtype columns (and</span>
<span class="gi">+              thus could have a geometry dtype). Therefore, we don&#39;t return a</span>
<span class="gi">+              GeoSeries if we are sure we are in a row selection case (by</span>
<span class="gi">+              checking the identity of the index)</span>
<span class="gi">+            &quot;&quot;&quot;</span>
<span class="gi">+            srs = pd.Series(*args, **kwargs)</span>
<span class="gi">+            is_row_proxy = srs.index.is_(self.columns)</span>
<span class="gi">+            if is_geometry_type(srs) and not is_row_proxy:</span>
<span class="gi">+                srs = GeoSeries(srs)</span>
<span class="gi">+            return srs</span>
<span class="gi">+</span>
<span class="gi">+        return _geodataframe_constructor_sliced</span>
<span class="gi">+</span>
<span class="gi">+    def _constructor_sliced_from_mgr(self, mgr, axes):</span>
<span class="gi">+        is_row_proxy = mgr.index.is_(self.columns)</span>
<span class="gi">+</span>
<span class="gi">+        if isinstance(mgr.blocks[0].dtype, GeometryDtype) and not is_row_proxy:</span>
<span class="gi">+            return GeoSeries._from_mgr(mgr, axes)</span>
<span class="gi">+        return Series._from_mgr(mgr, axes)</span>
<span class="gi">+</span>
<span class="w"> </span>    def __finalize__(self, other, method=None, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;propagate metadata from other to self&quot;&quot;&quot;
<span class="w"> </span>        self = super().__finalize__(other, method=method, **kwargs)
<span class="gd">-        if method == &#39;merge&#39;:</span>
<span class="gi">+</span>
<span class="gi">+        # merge operation: using metadata of the left object</span>
<span class="gi">+        if method == &quot;merge&quot;:</span>
<span class="w"> </span>            for name in self._metadata:
<span class="w"> </span>                object.__setattr__(self, name, getattr(other.left, name, None))
<span class="gd">-        elif method == &#39;concat&#39;:</span>
<span class="gi">+        # concat operation: using metadata of the first object</span>
<span class="gi">+        elif method == &quot;concat&quot;:</span>
<span class="w"> </span>            for name in self._metadata:
<span class="gd">-                object.__setattr__(self, name, getattr(other.objs[0], name,</span>
<span class="gd">-                    None))</span>
<span class="gi">+                object.__setattr__(self, name, getattr(other.objs[0], name, None))</span>
<span class="gi">+</span>
<span class="w"> </span>            if (self.columns == self._geometry_column_name).sum() &gt; 1:
<span class="w"> </span>                raise ValueError(
<span class="gd">-                    f&quot;&quot;&quot;Concat operation has resulted in multiple columns using the geometry column name &#39;{self._geometry_column_name}&#39;.</span>
<span class="gd">-Please ensure this column from the first DataFrame is not repeated.&quot;&quot;&quot;</span>
<span class="gd">-                    )</span>
<span class="gd">-        elif method == &#39;unstack&#39;:</span>
<span class="gi">+                    &quot;Concat operation has resulted in multiple columns using &quot;</span>
<span class="gi">+                    f&quot;the geometry column name &#39;{self._geometry_column_name}&#39;.\n&quot;</span>
<span class="gi">+                    &quot;Please ensure this column from the first DataFrame is not &quot;</span>
<span class="gi">+                    &quot;repeated.&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+        elif method == &quot;unstack&quot;:</span>
<span class="gi">+            # unstack adds multiindex columns and reshapes data.</span>
<span class="gi">+            # it never makes sense to retain geometry column</span>
<span class="w"> </span>            self._geometry_column_name = None
<span class="w"> </span>            self._crs = None
<span class="w"> </span>        return self

<span class="gd">-    def dissolve(self, by=None, aggfunc=&#39;first&#39;, as_index=True, level=None,</span>
<span class="gd">-        sort=True, observed=False, dropna=True, method=&#39;unary&#39;, **kwargs):</span>
<span class="gi">+    def dissolve(</span>
<span class="gi">+        self,</span>
<span class="gi">+        by=None,</span>
<span class="gi">+        aggfunc=&quot;first&quot;,</span>
<span class="gi">+        as_index=True,</span>
<span class="gi">+        level=None,</span>
<span class="gi">+        sort=True,</span>
<span class="gi">+        observed=False,</span>
<span class="gi">+        dropna=True,</span>
<span class="gi">+        method=&quot;unary&quot;,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Dissolve geometries within `groupby` into single observation.
<span class="w"> </span>        This is accomplished by applying the `union_all` method
<span class="gu">@@ -1412,10 +2039,64 @@ Please ensure this column from the first DataFrame is not repeated.&quot;&quot;&quot;</span>
<span class="w"> </span>        GeoDataFrame.explode : explode multi-part geometries into single geometries

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>

<span class="gd">-    def explode(self, column=None, ignore_index=False, index_parts=False,</span>
<span class="gd">-        **kwargs):</span>
<span class="gi">+        if by is None and level is None:</span>
<span class="gi">+            by = np.zeros(len(self), dtype=&quot;int64&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        groupby_kwargs = {</span>
<span class="gi">+            &quot;by&quot;: by,</span>
<span class="gi">+            &quot;level&quot;: level,</span>
<span class="gi">+            &quot;sort&quot;: sort,</span>
<span class="gi">+            &quot;observed&quot;: observed,</span>
<span class="gi">+            &quot;dropna&quot;: dropna,</span>
<span class="gi">+        }</span>
<span class="gi">+</span>
<span class="gi">+        # Process non-spatial component</span>
<span class="gi">+        data = self.drop(labels=self.geometry.name, axis=1)</span>
<span class="gi">+        with warnings.catch_warnings(record=True) as record:</span>
<span class="gi">+            aggregated_data = data.groupby(**groupby_kwargs).agg(aggfunc, **kwargs)</span>
<span class="gi">+        for w in record:</span>
<span class="gi">+            if str(w.message).startswith(&quot;The default value of numeric_only&quot;):</span>
<span class="gi">+                msg = (</span>
<span class="gi">+                    f&quot;The default value of numeric_only in aggfunc=&#39;{aggfunc}&#39; &quot;</span>
<span class="gi">+                    &quot;within pandas.DataFrameGroupBy.agg used in dissolve is &quot;</span>
<span class="gi">+                    &quot;deprecated. In pandas 2.0, numeric_only will default to False. &quot;</span>
<span class="gi">+                    &quot;Either specify numeric_only as additional argument in dissolve() &quot;</span>
<span class="gi">+                    &quot;or select only columns which should be valid for the function.&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+                warnings.warn(msg, FutureWarning, stacklevel=2)</span>
<span class="gi">+            else:</span>
<span class="gi">+                # Only want to capture specific warning,</span>
<span class="gi">+                # other warnings from pandas should be passed through</span>
<span class="gi">+                # TODO this is not an ideal approach</span>
<span class="gi">+                warnings.showwarning(</span>
<span class="gi">+                    w.message, w.category, w.filename, w.lineno, w.file, w.line</span>
<span class="gi">+                )</span>
<span class="gi">+</span>
<span class="gi">+        aggregated_data.columns = aggregated_data.columns.to_flat_index()</span>
<span class="gi">+</span>
<span class="gi">+        # Process spatial component</span>
<span class="gi">+        def merge_geometries(block):</span>
<span class="gi">+            merged_geom = block.union_all(method=method)</span>
<span class="gi">+            return merged_geom</span>
<span class="gi">+</span>
<span class="gi">+        g = self.groupby(group_keys=False, **groupby_kwargs)[self.geometry.name].agg(</span>
<span class="gi">+            merge_geometries</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        # Aggregate</span>
<span class="gi">+        aggregated_geometry = GeoDataFrame(g, geometry=self.geometry.name, crs=self.crs)</span>
<span class="gi">+        # Recombine</span>
<span class="gi">+        aggregated = aggregated_geometry.join(aggregated_data)</span>
<span class="gi">+</span>
<span class="gi">+        # Reset if requested</span>
<span class="gi">+        if not as_index:</span>
<span class="gi">+            aggregated = aggregated.reset_index()</span>
<span class="gi">+</span>
<span class="gi">+        return aggregated</span>
<span class="gi">+</span>
<span class="gi">+    # overrides the pandas native explode method to break up features geometrically</span>
<span class="gi">+    def explode(self, column=None, ignore_index=False, index_parts=False, **kwargs):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Explode multi-part geometries into multiple single geometries.

<span class="gu">@@ -1490,9 +2171,39 @@ Please ensure this column from the first DataFrame is not repeated.&quot;&quot;&quot;</span>
<span class="w"> </span>        GeoDataFrame.dissolve : dissolve geometries into a single observation.

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>

<span class="gd">-    def astype(self, dtype, copy=None, errors=&#39;raise&#39;, **kwargs):</span>
<span class="gi">+        # If no column is specified then default to the active geometry column</span>
<span class="gi">+        if column is None:</span>
<span class="gi">+            column = self.geometry.name</span>
<span class="gi">+        # If the specified column is not a geometry dtype use pandas explode</span>
<span class="gi">+        if not isinstance(self[column].dtype, GeometryDtype):</span>
<span class="gi">+            return super().explode(column, ignore_index=ignore_index, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+        exploded_geom = self.geometry.reset_index(drop=True).explode(index_parts=True)</span>
<span class="gi">+</span>
<span class="gi">+        df = self.drop(self._geometry_column_name, axis=1).take(</span>
<span class="gi">+            exploded_geom.index.droplevel(-1)</span>
<span class="gi">+        )</span>
<span class="gi">+        df[exploded_geom.name] = exploded_geom.values</span>
<span class="gi">+        df = df.set_geometry(self._geometry_column_name).__finalize__(self)</span>
<span class="gi">+</span>
<span class="gi">+        if ignore_index:</span>
<span class="gi">+            df.reset_index(inplace=True, drop=True)</span>
<span class="gi">+        elif index_parts:</span>
<span class="gi">+            # reset to MultiIndex, otherwise df index is only first level of</span>
<span class="gi">+            # exploded GeoSeries index.</span>
<span class="gi">+            df = df.set_index(</span>
<span class="gi">+                exploded_geom.index.droplevel(</span>
<span class="gi">+                    list(range(exploded_geom.index.nlevels - 1))</span>
<span class="gi">+                ),</span>
<span class="gi">+                append=True,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        return df</span>
<span class="gi">+</span>
<span class="gi">+    # overrides the pandas astype method to ensure the correct return type</span>
<span class="gi">+    # should be removable when pandas 1.4 is dropped</span>
<span class="gi">+    def astype(self, dtype, copy=None, errors=&quot;raise&quot;, **kwargs):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Cast a pandas object to a specified dtype ``dtype``.
<span class="w"> </span>        Returns a GeoDataFrame when the geometry column is kept as geometries,
<span class="gu">@@ -1502,10 +2213,34 @@ Please ensure this column from the first DataFrame is not repeated.&quot;&quot;&quot;</span>
<span class="w"> </span>        -------
<span class="w"> </span>        GeoDataFrame or DataFrame
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if not PANDAS_GE_30 and copy is None:</span>
<span class="gi">+            copy = True</span>
<span class="gi">+        if copy is not None:</span>
<span class="gi">+            kwargs[&quot;copy&quot;] = copy</span>

<span class="gd">-    def to_postgis(self, name, con, schema=None, if_exists=&#39;fail&#39;, index=</span>
<span class="gd">-        False, index_label=None, chunksize=None, dtype=None):</span>
<span class="gi">+        df = super().astype(dtype, errors=errors, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+        try:</span>
<span class="gi">+            geoms = df[self._geometry_column_name]</span>
<span class="gi">+            if is_geometry_type(geoms):</span>
<span class="gi">+                return geopandas.GeoDataFrame(df, geometry=self._geometry_column_name)</span>
<span class="gi">+        except KeyError:</span>
<span class="gi">+            pass</span>
<span class="gi">+        # if the geometry column is converted to non-geometries or did not exist</span>
<span class="gi">+        # do not return a GeoDataFrame</span>
<span class="gi">+        return pd.DataFrame(df)</span>
<span class="gi">+</span>
<span class="gi">+    def to_postgis(</span>
<span class="gi">+        self,</span>
<span class="gi">+        name,</span>
<span class="gi">+        con,</span>
<span class="gi">+        schema=None,</span>
<span class="gi">+        if_exists=&quot;fail&quot;,</span>
<span class="gi">+        index=False,</span>
<span class="gi">+        index_label=None,</span>
<span class="gi">+        chunksize=None,</span>
<span class="gi">+        dtype=None,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Upload GeoDataFrame into PostGIS database.

<span class="gu">@@ -1549,7 +2284,8 @@ Please ensure this column from the first DataFrame is not repeated.&quot;&quot;&quot;</span>
<span class="w"> </span>        --------

<span class="w"> </span>        &gt;&gt;&gt; from sqlalchemy import create_engine
<span class="gd">-        &gt;&gt;&gt; engine = create_engine(&quot;postgresql://myusername:mypassword@myhost:5432/mydatabase&quot;)  # doctest: +SKIP</span>
<span class="gi">+        &gt;&gt;&gt; engine = create_engine(&quot;postgresql://myusername:mypassword@myhost:5432\</span>
<span class="gi">+/mydatabase&quot;)  # doctest: +SKIP</span>
<span class="w"> </span>        &gt;&gt;&gt; gdf.to_postgis(&quot;my_table&quot;, engine)  # doctest: +SKIP

<span class="w"> </span>        See also
<span class="gu">@@ -1558,8 +2294,15 @@ Please ensure this column from the first DataFrame is not repeated.&quot;&quot;&quot;</span>
<span class="w"> </span>        read_postgis : read PostGIS database to GeoDataFrame

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-    plot = Accessor(&#39;plot&#39;, geopandas.plotting.GeoplotAccessor)</span>
<span class="gi">+        geopandas.io.sql._write_postgis(</span>
<span class="gi">+            self, name, con, schema, if_exists, index, index_label, chunksize, dtype</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    plot = Accessor(&quot;plot&quot;, geopandas.plotting.GeoplotAccessor)</span>
<span class="gi">+</span>
<span class="gi">+    @doc(_explore)</span>
<span class="gi">+    def explore(self, *args, **kwargs):</span>
<span class="gi">+        return _explore(self, *args, **kwargs)</span>

<span class="w"> </span>    def sjoin(self, df, *args, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Spatial join of two GeoDataFrames.
<span class="gu">@@ -1645,10 +2388,18 @@ Please ensure this column from the first DataFrame is not repeated.&quot;&quot;&quot;</span>
<span class="w"> </span>        GeoDataFrame.sjoin_nearest : nearest neighbor join
<span class="w"> </span>        sjoin : equivalent top-level function
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def sjoin_nearest(self, right, how=&#39;inner&#39;, max_distance=None, lsuffix=</span>
<span class="gd">-        &#39;left&#39;, rsuffix=&#39;right&#39;, distance_col=None, exclusive=False):</span>
<span class="gi">+        return geopandas.sjoin(left_df=self, right_df=df, *args, **kwargs)  # noqa: B026</span>
<span class="gi">+</span>
<span class="gi">+    def sjoin_nearest(</span>
<span class="gi">+        self,</span>
<span class="gi">+        right,</span>
<span class="gi">+        how=&quot;inner&quot;,</span>
<span class="gi">+        max_distance=None,</span>
<span class="gi">+        lsuffix=&quot;left&quot;,</span>
<span class="gi">+        rsuffix=&quot;right&quot;,</span>
<span class="gi">+        distance_col=None,</span>
<span class="gi">+        exclusive=False,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Spatial join of two GeoDataFrames based on the distance between their
<span class="w"> </span>        geometries.
<span class="gu">@@ -1727,8 +2478,10 @@ Please ensure this column from the first DataFrame is not repeated.&quot;&quot;&quot;</span>

<span class="w"> </span>        To include the distances:

<span class="gd">-        &gt;&gt;&gt; groceries_w_communities = groceries.sjoin_nearest(chicago, distance_col=&quot;distances&quot;)</span>
<span class="gd">-        &gt;&gt;&gt; groceries_w_communities[[&quot;Chain&quot;, &quot;community&quot;, &quot;distances&quot;]].head(2)</span>
<span class="gi">+        &gt;&gt;&gt; groceries_w_communities = groceries.sjoin_nearest(chicago, \</span>
<span class="gi">+distance_col=&quot;distances&quot;)</span>
<span class="gi">+        &gt;&gt;&gt; groceries_w_communities[[&quot;Chain&quot;, &quot;community&quot;, \</span>
<span class="gi">+&quot;distances&quot;]].head(2)</span>
<span class="w"> </span>                       Chain    community  distances
<span class="w"> </span>        0     VIET HOA PLAZA       UPTOWN        0.0
<span class="w"> </span>        1  COUNTY FAIR FOODS  MORGAN PARK        0.0
<span class="gu">@@ -1737,8 +2490,10 @@ Please ensure this column from the first DataFrame is not repeated.&quot;&quot;&quot;</span>
<span class="w"> </span>        results are equidistant (in this case zero because they intersect).
<span class="w"> </span>        In fact, we get 4 results in total:

<span class="gd">-        &gt;&gt;&gt; chicago_w_groceries = groceries.sjoin_nearest(chicago, distance_col=&quot;distances&quot;, how=&quot;right&quot;)</span>
<span class="gd">-        &gt;&gt;&gt; uptown_results = chicago_w_groceries[chicago_w_groceries[&quot;community&quot;] == &quot;UPTOWN&quot;]</span>
<span class="gi">+        &gt;&gt;&gt; chicago_w_groceries = groceries.sjoin_nearest(chicago, \</span>
<span class="gi">+distance_col=&quot;distances&quot;, how=&quot;right&quot;)</span>
<span class="gi">+        &gt;&gt;&gt; uptown_results = \</span>
<span class="gi">+chicago_w_groceries[chicago_w_groceries[&quot;community&quot;] == &quot;UPTOWN&quot;]</span>
<span class="w"> </span>        &gt;&gt;&gt; uptown_results[[&quot;Chain&quot;, &quot;community&quot;]]
<span class="w"> </span>                    Chain community
<span class="w"> </span>        30  VIET HOA PLAZA    UPTOWN
<span class="gu">@@ -1759,7 +2514,16 @@ Please ensure this column from the first DataFrame is not repeated.&quot;&quot;&quot;</span>
<span class="w"> </span>        Every operation in GeoPandas is planar, i.e. the potential third
<span class="w"> </span>        dimension is not taken into account.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return geopandas.sjoin_nearest(</span>
<span class="gi">+            self,</span>
<span class="gi">+            right,</span>
<span class="gi">+            how=how,</span>
<span class="gi">+            max_distance=max_distance,</span>
<span class="gi">+            lsuffix=lsuffix,</span>
<span class="gi">+            rsuffix=rsuffix,</span>
<span class="gi">+            distance_col=distance_col,</span>
<span class="gi">+            exclusive=exclusive,</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def clip(self, mask, keep_geom_type=False, sort=False):
<span class="w"> </span>        &quot;&quot;&quot;Clip points, lines, or polygon geometries to the mask extent.
<span class="gu">@@ -1818,10 +2582,9 @@ Please ensure this column from the first DataFrame is not repeated.&quot;&quot;&quot;</span>
<span class="w"> </span>        &gt;&gt;&gt; nws_groceries.shape
<span class="w"> </span>        (7, 8)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return geopandas.clip(self, mask=mask, keep_geom_type=keep_geom_type, sort=sort)</span>

<span class="gd">-    def overlay(self, right, how=&#39;intersection&#39;, keep_geom_type=None,</span>
<span class="gd">-        make_valid=True):</span>
<span class="gi">+    def overlay(self, right, how=&quot;intersection&quot;, keep_geom_type=None, make_valid=True):</span>
<span class="w"> </span>        &quot;&quot;&quot;Perform spatial overlay between GeoDataFrames.

<span class="w"> </span>        Currently only supports data GeoDataFrames with uniform geometry types,
<span class="gu">@@ -1909,7 +2672,19 @@ Please ensure this column from the first DataFrame is not repeated.&quot;&quot;&quot;</span>
<span class="w"> </span>        Every operation in GeoPandas is planar, i.e. the potential third
<span class="w"> </span>        dimension is not taken into account.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return geopandas.overlay(</span>
<span class="gi">+            self, right, how=how, keep_geom_type=keep_geom_type, make_valid=make_valid</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _dataframe_set_geometry(self, col, drop=None, inplace=False, crs=None):</span>
<span class="gi">+    if inplace:</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &quot;Can&#39;t do inplace setting when converting from DataFrame to GeoDataFrame&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+    gf = GeoDataFrame(self)</span>
<span class="gi">+    # this will copy so that BlockManager gets copied</span>
<span class="gi">+    return gf.set_geometry(col, drop=drop, inplace=False, crs=crs)</span>


<span class="w"> </span>DataFrame.set_geometry = _dataframe_set_geometry
<span class="gh">diff --git a/geopandas/geoseries.py b/geopandas/geoseries.py</span>
<span class="gh">index 38c4ecf5..ea30f61d 100644</span>
<span class="gd">--- a/geopandas/geoseries.py</span>
<span class="gi">+++ b/geopandas/geoseries.py</span>
<span class="gu">@@ -1,40 +1,79 @@</span>
<span class="w"> </span>from __future__ import annotations
<span class="gi">+</span>
<span class="w"> </span>import typing
<span class="w"> </span>import warnings
<span class="w"> </span>from packaging.version import Version
<span class="w"> </span>from typing import Any, Callable, Dict, Optional
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>import pandas as pd
<span class="w"> </span>from pandas import Series
<span class="w"> </span>from pandas.core.internals import SingleBlockManager
<span class="gi">+</span>
<span class="w"> </span>import shapely
<span class="w"> </span>from shapely.geometry import GeometryCollection
<span class="w"> </span>from shapely.geometry.base import BaseGeometry
<span class="gi">+</span>
<span class="w"> </span>import geopandas
<span class="w"> </span>from geopandas.base import GeoPandasBase, _delegate_property
<span class="w"> </span>from geopandas.explore import _explore_geoseries
<span class="w"> </span>from geopandas.plotting import plot_series
<span class="gi">+</span>
<span class="w"> </span>from . import _compat as compat
<span class="w"> </span>from ._decorator import doc
<span class="gd">-from .array import GeometryDtype, from_shapely, from_wkb, from_wkt, points_from_xy, to_wkb, to_wkt</span>
<span class="gi">+from .array import (</span>
<span class="gi">+    GeometryDtype,</span>
<span class="gi">+    from_shapely,</span>
<span class="gi">+    from_wkb,</span>
<span class="gi">+    from_wkt,</span>
<span class="gi">+    points_from_xy,</span>
<span class="gi">+    to_wkb,</span>
<span class="gi">+    to_wkt,</span>
<span class="gi">+)</span>
<span class="w"> </span>from .base import is_geometry_type
<span class="gi">+</span>
<span class="w"> </span>if typing.TYPE_CHECKING:
<span class="w"> </span>    import os


<span class="gd">-def _geoseries_constructor_with_fallback(data=None, index=None, crs:</span>
<span class="gd">-    Optional[Any]=None, **kwargs):</span>
<span class="gi">+def _geoseries_constructor_with_fallback(</span>
<span class="gi">+    data=None, index=None, crs: Optional[Any] = None, **kwargs</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    A flexible constructor for GeoSeries._constructor, which needs to be able
<span class="w"> </span>    to fall back to a Series (if a certain operation does not produce
<span class="w"> </span>    geometries)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        return GeoSeries(data=data, index=index, crs=crs, **kwargs)</span>
<span class="gi">+    except TypeError:</span>
<span class="gi">+        return Series(data=data, index=index, **kwargs)</span>


<span class="w"> </span>def _expanddim_logic(df):
<span class="w"> </span>    &quot;&quot;&quot;Shared logic for _constructor_expanddim and _constructor_from_mgr_expanddim.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from geopandas import GeoDataFrame</span>
<span class="gi">+</span>
<span class="gi">+    if (df.dtypes == &quot;geometry&quot;).sum() &gt; 0:</span>
<span class="gi">+        if df.shape[1] == 1:</span>
<span class="gi">+            geo_col_name = df.columns[0]</span>
<span class="gi">+        else:</span>
<span class="gi">+            geo_col_name = None</span>
<span class="gi">+</span>
<span class="gi">+        if geo_col_name is None or not is_geometry_type(df[geo_col_name]):</span>
<span class="gi">+            df = GeoDataFrame(df)</span>
<span class="gi">+            df._geometry_column_name = None</span>
<span class="gi">+        else:</span>
<span class="gi">+            df = df.set_geometry(geo_col_name)</span>
<span class="gi">+</span>
<span class="gi">+    return df</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _geoseries_expanddim(data=None, *args, **kwargs):</span>
<span class="gi">+    # pd.Series._constructor_expanddim == pd.DataFrame, we start</span>
<span class="gi">+    # with that then specialize.</span>
<span class="gi">+    df = pd.DataFrame(data, *args, **kwargs)</span>
<span class="gi">+    return _expanddim_logic(df)</span>


<span class="w"> </span>class GeoSeries(GeoPandasBase, Series):
<span class="gu">@@ -115,60 +154,106 @@ class GeoSeries(GeoPandasBase, Series):</span>

<span class="w"> </span>    &quot;&quot;&quot;

<span class="gd">-    def __init__(self, data=None, index=None, crs: Optional[Any]=None, **kwargs</span>
<span class="gd">-        ):</span>
<span class="gd">-        if (hasattr(data, &#39;crs&#39;) or isinstance(data, pd.Series) and hasattr</span>
<span class="gd">-            (data.array, &#39;crs&#39;)) and crs:</span>
<span class="gd">-            data_crs = data.crs if hasattr(data, &#39;crs&#39;) else data.array.crs</span>
<span class="gi">+    def __init__(self, data=None, index=None, crs: Optional[Any] = None, **kwargs):</span>
<span class="gi">+        if (</span>
<span class="gi">+            hasattr(data, &quot;crs&quot;)</span>
<span class="gi">+            or (isinstance(data, pd.Series) and hasattr(data.array, &quot;crs&quot;))</span>
<span class="gi">+        ) and crs:</span>
<span class="gi">+            data_crs = data.crs if hasattr(data, &quot;crs&quot;) else data.array.crs</span>
<span class="w"> </span>            if not data_crs:
<span class="gi">+                # make a copy to avoid setting CRS to passed GeometryArray</span>
<span class="w"> </span>                data = data.copy()
<span class="gd">-            elif not data.crs == crs:</span>
<span class="gd">-                raise ValueError(</span>
<span class="gd">-                    &quot;CRS mismatch between CRS of the passed geometries and &#39;crs&#39;. Use &#39;GeoSeries.set_crs(crs, allow_override=True)&#39; to overwrite CRS or &#39;GeoSeries.to_crs(crs)&#39; to reproject geometries. &quot;</span>
<span class="gi">+            else:</span>
<span class="gi">+                if not data.crs == crs:</span>
<span class="gi">+                    raise ValueError(</span>
<span class="gi">+                        &quot;CRS mismatch between CRS of the passed geometries &quot;</span>
<span class="gi">+                        &quot;and &#39;crs&#39;. Use &#39;GeoSeries.set_crs(crs, &quot;</span>
<span class="gi">+                        &quot;allow_override=True)&#39; to overwrite CRS or &quot;</span>
<span class="gi">+                        &quot;&#39;GeoSeries.to_crs(crs)&#39; to reproject geometries. &quot;</span>
<span class="w"> </span>                    )
<span class="gi">+</span>
<span class="w"> </span>        if isinstance(data, SingleBlockManager):
<span class="w"> </span>            if not isinstance(data.blocks[0].dtype, GeometryDtype):
<span class="w"> </span>                raise TypeError(
<span class="gd">-                    f&quot;Non geometry data passed to GeoSeries constructor, received data of dtype &#39;{data.blocks[0].dtype}&#39;&quot;</span>
<span class="gd">-                    )</span>
<span class="gi">+                    &quot;Non geometry data passed to GeoSeries constructor, &quot;</span>
<span class="gi">+                    f&quot;received data of dtype &#39;{data.blocks[0].dtype}&#39;&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+</span>
<span class="w"> </span>        if isinstance(data, BaseGeometry):
<span class="gi">+            # fix problem for scalar geometries passed, ensure the list of</span>
<span class="gi">+            # scalars is of correct length if index is specified</span>
<span class="w"> </span>            n = len(index) if index is not None else 1
<span class="w"> </span>            data = [data] * n
<span class="gd">-        name = kwargs.pop(&#39;name&#39;, None)</span>
<span class="gi">+</span>
<span class="gi">+        name = kwargs.pop(&quot;name&quot;, None)</span>
<span class="gi">+</span>
<span class="w"> </span>        if not is_geometry_type(data):
<span class="gd">-            kwargs.pop(&#39;dtype&#39;, None)</span>
<span class="gi">+            # if data is None and dtype is specified (eg from empty overlay</span>
<span class="gi">+            # test), specifying dtype raises an error:</span>
<span class="gi">+            # https://github.com/pandas-dev/pandas/issues/26469</span>
<span class="gi">+            kwargs.pop(&quot;dtype&quot;, None)</span>
<span class="gi">+            # Use Series constructor to handle input data</span>
<span class="w"> </span>            with warnings.catch_warnings():
<span class="gd">-                empty_msg = &#39;The default dtype for empty Series&#39;</span>
<span class="gd">-                warnings.filterwarnings(&#39;ignore&#39;, empty_msg, DeprecationWarning</span>
<span class="gd">-                    )</span>
<span class="gd">-                warnings.filterwarnings(&#39;ignore&#39;, empty_msg, FutureWarning)</span>
<span class="gi">+                # suppress additional warning from pandas for empty data</span>
<span class="gi">+                # (will always give object dtype instead of float dtype in the future,</span>
<span class="gi">+                # making the `if s.empty: s = s.astype(object)` below unnecessary)</span>
<span class="gi">+                empty_msg = &quot;The default dtype for empty Series&quot;</span>
<span class="gi">+                warnings.filterwarnings(&quot;ignore&quot;, empty_msg, DeprecationWarning)</span>
<span class="gi">+                warnings.filterwarnings(&quot;ignore&quot;, empty_msg, FutureWarning)</span>
<span class="w"> </span>                s = pd.Series(data, index=index, name=name, **kwargs)
<span class="gi">+            # prevent trying to convert non-geometry objects</span>
<span class="w"> </span>            if s.dtype != object:
<span class="gd">-                if s.empty and s.dtype == &#39;float64&#39; or data is None:</span>
<span class="gi">+                if (s.empty and s.dtype == &quot;float64&quot;) or data is None:</span>
<span class="gi">+                    # pd.Series with empty data gives float64 for older pandas versions</span>
<span class="w"> </span>                    s = s.astype(object)
<span class="w"> </span>                else:
<span class="w"> </span>                    raise TypeError(
<span class="gd">-                        f&quot;Non geometry data passed to GeoSeries constructor, received data of dtype &#39;{s.dtype}&#39;&quot;</span>
<span class="gd">-                        )</span>
<span class="gi">+                        &quot;Non geometry data passed to GeoSeries constructor, &quot;</span>
<span class="gi">+                        f&quot;received data of dtype &#39;{s.dtype}&#39;&quot;</span>
<span class="gi">+                    )</span>
<span class="gi">+            # extract object-dtype numpy array from pandas Series; with CoW this</span>
<span class="gi">+            # gives a read-only array, so we try to set the flag back to writeable</span>
<span class="w"> </span>            data = s.to_numpy()
<span class="w"> </span>            try:
<span class="w"> </span>                data.flags.writeable = True
<span class="w"> </span>            except ValueError:
<span class="w"> </span>                pass
<span class="gi">+            # try to convert to GeometryArray</span>
<span class="w"> </span>            try:
<span class="w"> </span>                data = from_shapely(data, crs)
<span class="w"> </span>            except TypeError:
<span class="w"> </span>                raise TypeError(
<span class="gd">-                    f&quot;Non geometry data passed to GeoSeries constructor, received data of dtype &#39;{s.dtype}&#39;&quot;</span>
<span class="gd">-                    )</span>
<span class="gi">+                    &quot;Non geometry data passed to GeoSeries constructor, &quot;</span>
<span class="gi">+                    f&quot;received data of dtype &#39;{s.dtype}&#39;&quot;</span>
<span class="gi">+                )</span>
<span class="w"> </span>            index = s.index
<span class="w"> </span>            name = s.name
<span class="gi">+</span>
<span class="w"> </span>        super().__init__(data, index=index, name=name, **kwargs)
<span class="w"> </span>        if not self.crs:
<span class="w"> </span>            self.crs = crs

<span class="gi">+    def append(self, *args, **kwargs) -&gt; GeoSeries:</span>
<span class="gi">+        return self._wrapped_pandas_method(&quot;append&quot;, *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    @GeoPandasBase.crs.setter</span>
<span class="gi">+    def crs(self, value):</span>
<span class="gi">+        if self.crs is not None:</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                &quot;Overriding the CRS of a GeoSeries that already has CRS. &quot;</span>
<span class="gi">+                &quot;This unsafe behavior will be deprecated in future versions. &quot;</span>
<span class="gi">+                &quot;Use GeoSeries.set_crs method instead.&quot;,</span>
<span class="gi">+                stacklevel=2,</span>
<span class="gi">+                category=DeprecationWarning,</span>
<span class="gi">+            )</span>
<span class="gi">+        self.geometry.values.crs = value</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def geometry(self) -&gt; GeoSeries:</span>
<span class="gi">+        return self</span>
<span class="gi">+</span>
<span class="w"> </span>    @property
<span class="gd">-    def x(self) -&gt;Series:</span>
<span class="gi">+    def x(self) -&gt; Series:</span>
<span class="w"> </span>        &quot;&quot;&quot;Return the x location of point geometries in a GeoSeries

<span class="w"> </span>        Returns
<span class="gu">@@ -193,10 +278,10 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        GeoSeries.z

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;x&quot;, self)</span>

<span class="w"> </span>    @property
<span class="gd">-    def y(self) -&gt;Series:</span>
<span class="gi">+    def y(self) -&gt; Series:</span>
<span class="w"> </span>        &quot;&quot;&quot;Return the y location of point geometries in a GeoSeries

<span class="w"> </span>        Returns
<span class="gu">@@ -221,10 +306,10 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        GeoSeries.z

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;y&quot;, self)</span>

<span class="w"> </span>    @property
<span class="gd">-    def z(self) -&gt;Series:</span>
<span class="gi">+    def z(self) -&gt; Series:</span>
<span class="w"> </span>        &quot;&quot;&quot;Return the z location of point geometries in a GeoSeries

<span class="w"> </span>        Returns
<span class="gu">@@ -249,11 +334,10 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        GeoSeries.y

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _delegate_property(&quot;z&quot;, self)</span>

<span class="w"> </span>    @classmethod
<span class="gd">-    def from_file(cls, filename: (os.PathLike | typing.IO), **kwargs</span>
<span class="gd">-        ) -&gt;GeoSeries:</span>
<span class="gi">+    def from_file(cls, filename: os.PathLike | typing.IO, **kwargs) -&gt; GeoSeries:</span>
<span class="w"> </span>        &quot;&quot;&quot;Alternate constructor to create a ``GeoSeries`` from a file.

<span class="w"> </span>        Can load a ``GeoSeries`` from a file from any format recognized by
<span class="gu">@@ -289,11 +373,16 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        read_file : read file to GeoDataFrame
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from geopandas import GeoDataFrame</span>
<span class="gi">+</span>
<span class="gi">+        df = GeoDataFrame.from_file(filename, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+        return GeoSeries(df.geometry, crs=df.crs)</span>

<span class="w"> </span>    @classmethod
<span class="gd">-    def from_wkb(cls, data, index=None, crs: Optional[Any]=None, on_invalid</span>
<span class="gd">-        =&#39;raise&#39;, **kwargs) -&gt;GeoSeries:</span>
<span class="gi">+    def from_wkb(</span>
<span class="gi">+        cls, data, index=None, crs: Optional[Any] = None, on_invalid=&quot;raise&quot;, **kwargs</span>
<span class="gi">+    ) -&gt; GeoSeries:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Alternate constructor to create a ``GeoSeries``
<span class="w"> </span>        from a list or array of WKB objects
<span class="gu">@@ -328,11 +417,14 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        GeoSeries.from_wkt

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return cls._from_wkb_or_wkt(</span>
<span class="gi">+            from_wkb, data, index=index, crs=crs, on_invalid=on_invalid, **kwargs</span>
<span class="gi">+        )</span>

<span class="w"> </span>    @classmethod
<span class="gd">-    def from_wkt(cls, data, index=None, crs: Optional[Any]=None, on_invalid</span>
<span class="gd">-        =&#39;raise&#39;, **kwargs) -&gt;GeoSeries:</span>
<span class="gi">+    def from_wkt(</span>
<span class="gi">+        cls, data, index=None, crs: Optional[Any] = None, on_invalid=&quot;raise&quot;, **kwargs</span>
<span class="gi">+    ) -&gt; GeoSeries:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Alternate constructor to create a ``GeoSeries``
<span class="w"> </span>        from a list or array of WKT objects
<span class="gu">@@ -382,10 +474,12 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        2    POINT (3 3)
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return cls._from_wkb_or_wkt(</span>
<span class="gi">+            from_wkt, data, index=index, crs=crs, on_invalid=on_invalid, **kwargs</span>
<span class="gi">+        )</span>

<span class="w"> </span>    @classmethod
<span class="gd">-    def from_xy(cls, x, y, z=None, index=None, crs=None, **kwargs) -&gt;GeoSeries:</span>
<span class="gi">+    def from_xy(cls, x, y, z=None, index=None, crs=None, **kwargs) -&gt; GeoSeries:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Alternate constructor to create a :class:`~geopandas.GeoSeries` of Point
<span class="w"> </span>        geometries from lists or arrays of x, y(, z) coordinates
<span class="gu">@@ -429,17 +523,41 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        2    POINT (-3 1.5)
<span class="w"> </span>        dtype: geometry
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if index is None:</span>
<span class="gi">+            if (</span>
<span class="gi">+                isinstance(x, Series)</span>
<span class="gi">+                and isinstance(y, Series)</span>
<span class="gi">+                and x.index.equals(y.index)</span>
<span class="gi">+                and (z is None or (isinstance(z, Series) and x.index.equals(z.index)))</span>
<span class="gi">+            ):  # check if we can reuse index</span>
<span class="gi">+                index = x.index</span>
<span class="gi">+        return cls(points_from_xy(x, y, z, crs=crs), index=index, crs=crs, **kwargs)</span>

<span class="w"> </span>    @classmethod
<span class="gd">-    def _from_wkb_or_wkt(cls, from_wkb_or_wkt_function: Callable, data,</span>
<span class="gd">-        index=None, crs: Optional[Any]=None, on_invalid: str=&#39;raise&#39;, **kwargs</span>
<span class="gd">-        ) -&gt;GeoSeries:</span>
<span class="gi">+    def _from_wkb_or_wkt(</span>
<span class="gi">+        cls,</span>
<span class="gi">+        from_wkb_or_wkt_function: Callable,</span>
<span class="gi">+        data,</span>
<span class="gi">+        index=None,</span>
<span class="gi">+        crs: Optional[Any] = None,</span>
<span class="gi">+        on_invalid: str = &quot;raise&quot;,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ) -&gt; GeoSeries:</span>
<span class="w"> </span>        &quot;&quot;&quot;Create a GeoSeries from either WKT or WKB values&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if isinstance(data, Series):</span>
<span class="gi">+            if index is not None:</span>
<span class="gi">+                data = data.reindex(index)</span>
<span class="gi">+            else:</span>
<span class="gi">+                index = data.index</span>
<span class="gi">+            data = data.values</span>
<span class="gi">+        return cls(</span>
<span class="gi">+            from_wkb_or_wkt_function(data, crs=crs, on_invalid=on_invalid),</span>
<span class="gi">+            index=index,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>

<span class="w"> </span>    @classmethod
<span class="gd">-    def from_arrow(cls, arr, **kwargs) -&gt;GeoSeries:</span>
<span class="gi">+    def from_arrow(cls, arr, **kwargs) -&gt; GeoSeries:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Construct a GeoSeries from a Arrow array object with a GeoArrow
<span class="w"> </span>        extension type.
<span class="gu">@@ -469,10 +587,12 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        GeoSeries

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from geopandas.io._geoarrow import arrow_to_geometry_array</span>
<span class="gi">+</span>
<span class="gi">+        return cls(arrow_to_geometry_array(arr), **kwargs)</span>

<span class="w"> </span>    @property
<span class="gd">-    def __geo_interface__(self) -&gt;Dict:</span>
<span class="gi">+    def __geo_interface__(self) -&gt; Dict:</span>
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` as a python feature collection.

<span class="w"> </span>        Implements the `geo_interface`. The returned python data structure
<span class="gu">@@ -486,13 +606,25 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        &gt;&gt;&gt; from shapely.geometry import Point
<span class="w"> </span>        &gt;&gt;&gt; s = geopandas.GeoSeries([Point(1, 1), Point(2, 2), Point(3, 3)])
<span class="w"> </span>        &gt;&gt;&gt; s.__geo_interface__
<span class="gd">-        {&#39;type&#39;: &#39;FeatureCollection&#39;, &#39;features&#39;: [{&#39;id&#39;: &#39;0&#39;, &#39;type&#39;: &#39;Feature&#39;, &#39;properties&#39;: {}, &#39;geometry&#39;: {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: (1.0, 1.0)}, &#39;bbox&#39;: (1.0, 1.0, 1.0, 1.0)}, {&#39;id&#39;: &#39;1&#39;, &#39;type&#39;: &#39;Feature&#39;, &#39;properties&#39;: {}, &#39;geometry&#39;: {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: (2.0, 2.0)}, &#39;bbox&#39;: (2.0, 2.0, 2.0, 2.0)}, {&#39;id&#39;: &#39;2&#39;, &#39;type&#39;: &#39;Feature&#39;, &#39;properties&#39;: {}, &#39;geometry&#39;: {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: (3.0, 3.0)}, &#39;bbox&#39;: (3.0, 3.0, 3.0, 3.0)}], &#39;bbox&#39;: (1.0, 1.0, 3.0, 3.0)}</span>
<span class="gi">+        {&#39;type&#39;: &#39;FeatureCollection&#39;, &#39;features&#39;: [{&#39;id&#39;: &#39;0&#39;, &#39;type&#39;: &#39;Feature&#39;, \</span>
<span class="gi">+&#39;properties&#39;: {}, &#39;geometry&#39;: {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: (1.0, 1.0)}, \</span>
<span class="gi">+&#39;bbox&#39;: (1.0, 1.0, 1.0, 1.0)}, {&#39;id&#39;: &#39;1&#39;, &#39;type&#39;: &#39;Feature&#39;, \</span>
<span class="gi">+&#39;properties&#39;: {}, &#39;geometry&#39;: {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: (2.0, 2.0)}, \</span>
<span class="gi">+&#39;bbox&#39;: (2.0, 2.0, 2.0, 2.0)}, {&#39;id&#39;: &#39;2&#39;, &#39;type&#39;: &#39;Feature&#39;, &#39;properties&#39;: \</span>
<span class="gi">+{}, &#39;geometry&#39;: {&#39;type&#39;: &#39;Point&#39;, &#39;coordinates&#39;: (3.0, 3.0)}, &#39;bbox&#39;: (3.0, \</span>
<span class="gi">+3.0, 3.0, 3.0)}], &#39;bbox&#39;: (1.0, 1.0, 3.0, 3.0)}</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        from geopandas import GeoDataFrame
<span class="gd">-        return GeoDataFrame({&#39;geometry&#39;: self}).__geo_interface__</span>

<span class="gd">-    def to_file(self, filename: (os.PathLike | typing.IO), driver: Optional</span>
<span class="gd">-        [str]=None, index: Optional[bool]=None, **kwargs):</span>
<span class="gi">+        return GeoDataFrame({&quot;geometry&quot;: self}).__geo_interface__</span>
<span class="gi">+</span>
<span class="gi">+    def to_file(</span>
<span class="gi">+        self,</span>
<span class="gi">+        filename: os.PathLike | typing.IO,</span>
<span class="gi">+        driver: Optional[str] = None,</span>
<span class="gi">+        index: Optional[bool] = None,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;Write the ``GeoSeries`` to a file.

<span class="w"> </span>        By default, an ESRI shapefile is written, but any OGR data source
<span class="gu">@@ -554,16 +686,76 @@ class GeoSeries(GeoPandasBase, Series):</span>

<span class="w"> </span>        &gt;&gt;&gt; s.to_file(&#39;series.geojson&#39;, driver=&#39;GeoJSON&#39;)  # doctest: +SKIP
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from geopandas import GeoDataFrame</span>
<span class="gi">+</span>
<span class="gi">+        data = GeoDataFrame({&quot;geometry&quot;: self}, index=self.index)</span>
<span class="gi">+        data.to_file(filename, driver, index=index, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    #</span>
<span class="gi">+    # Implement pandas methods</span>
<span class="gi">+    #</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def _constructor(self):</span>
<span class="gi">+        return _geoseries_constructor_with_fallback</span>
<span class="gi">+</span>
<span class="gi">+    def _constructor_from_mgr(self, mgr, axes):</span>
<span class="gi">+        assert isinstance(mgr, SingleBlockManager)</span>
<span class="gi">+</span>
<span class="gi">+        if not isinstance(mgr.blocks[0].dtype, GeometryDtype):</span>
<span class="gi">+            return Series._from_mgr(mgr, axes)</span>
<span class="gi">+</span>
<span class="gi">+        return GeoSeries._from_mgr(mgr, axes)</span>
<span class="gi">+</span>
<span class="gi">+    @property</span>
<span class="gi">+    def _constructor_expanddim(self):</span>
<span class="gi">+        return _geoseries_expanddim</span>
<span class="gi">+</span>
<span class="gi">+    def _constructor_expanddim_from_mgr(self, mgr, axes):</span>
<span class="gi">+        df = pd.DataFrame._from_mgr(mgr, axes)</span>
<span class="gi">+        return _expanddim_logic(df)</span>

<span class="w"> </span>    def _wrapped_pandas_method(self, mtd, *args, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Wrap a generic pandas method to ensure it returns a GeoSeries&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        val = getattr(super(), mtd)(*args, **kwargs)</span>
<span class="gi">+        if type(val) == Series:</span>
<span class="gi">+            val.__class__ = GeoSeries</span>
<span class="gi">+            val.crs = self.crs</span>
<span class="gi">+        return val</span>

<span class="w"> </span>    def __getitem__(self, key):
<span class="gd">-        return self._wrapped_pandas_method(&#39;__getitem__&#39;, key)</span>
<span class="gi">+        return self._wrapped_pandas_method(&quot;__getitem__&quot;, key)</span>

<span class="gd">-    def isna(self) -&gt;Series:</span>
<span class="gi">+    @doc(pd.Series)</span>
<span class="gi">+    def sort_index(self, *args, **kwargs):</span>
<span class="gi">+        return self._wrapped_pandas_method(&quot;sort_index&quot;, *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    @doc(pd.Series)</span>
<span class="gi">+    def take(self, *args, **kwargs):</span>
<span class="gi">+        return self._wrapped_pandas_method(&quot;take&quot;, *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    @doc(pd.Series)</span>
<span class="gi">+    def select(self, *args, **kwargs):</span>
<span class="gi">+        return self._wrapped_pandas_method(&quot;select&quot;, *args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    @doc(pd.Series)</span>
<span class="gi">+    def apply(self, func, convert_dtype: Optional[bool] = None, args=(), **kwargs):</span>
<span class="gi">+        if convert_dtype is not None:</span>
<span class="gi">+            kwargs[&quot;convert_dtype&quot;] = convert_dtype</span>
<span class="gi">+        else:</span>
<span class="gi">+            # if compat.PANDAS_GE_21 don&#39;t pass through, use pandas default</span>
<span class="gi">+            # of true to avoid internally triggering the pandas warning</span>
<span class="gi">+            if not compat.PANDAS_GE_21:</span>
<span class="gi">+                kwargs[&quot;convert_dtype&quot;] = True</span>
<span class="gi">+</span>
<span class="gi">+        # to avoid warning</span>
<span class="gi">+        result = super().apply(func, args=args, **kwargs)</span>
<span class="gi">+        if isinstance(result, GeoSeries):</span>
<span class="gi">+            if self.crs is not None:</span>
<span class="gi">+                result.set_crs(self.crs, inplace=True)</span>
<span class="gi">+        return result</span>
<span class="gi">+</span>
<span class="gi">+    def isna(self) -&gt; Series:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Detect missing values.

<span class="gu">@@ -602,13 +794,13 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        GeoSeries.notna : inverse of isna
<span class="w"> </span>        GeoSeries.is_empty : detect empty geometries
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return super().isna()</span>

<span class="gd">-    def isnull(self) -&gt;Series:</span>
<span class="gi">+    def isnull(self) -&gt; Series:</span>
<span class="w"> </span>        &quot;&quot;&quot;Alias for `isna` method. See `isna` for more detail.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.isna()</span>

<span class="gd">-    def notna(self) -&gt;Series:</span>
<span class="gi">+    def notna(self) -&gt; Series:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Detect non-missing values.

<span class="gu">@@ -647,13 +839,27 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        GeoSeries.isna : inverse of notna
<span class="w"> </span>        GeoSeries.is_empty : detect empty geometries
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def notnull(self) -&gt;Series:</span>
<span class="gi">+        if self.is_empty.any():</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                &quot;GeoSeries.notna() previously returned False for both missing (None) &quot;</span>
<span class="gi">+                &quot;and empty geometries. Now, it only returns False for missing values. &quot;</span>
<span class="gi">+                &quot;Since the calling GeoSeries contains empty geometries, the result &quot;</span>
<span class="gi">+                &quot;has changed compared to previous versions of GeoPandas.\n&quot;</span>
<span class="gi">+                &quot;Given a GeoSeries &#39;s&#39;, you can use &#39;~s.is_empty &amp; s.notna()&#39; to get &quot;</span>
<span class="gi">+                &quot;back the old behaviour.\n\n&quot;</span>
<span class="gi">+                &quot;To further ignore this warning, you can do: \n&quot;</span>
<span class="gi">+                &quot;import warnings; warnings.filterwarnings(&#39;ignore&#39;, &quot;</span>
<span class="gi">+                &quot;&#39;GeoSeries.notna&#39;, UserWarning)&quot;,</span>
<span class="gi">+                UserWarning,</span>
<span class="gi">+                stacklevel=2,</span>
<span class="gi">+            )</span>
<span class="gi">+        return super().notna()</span>
<span class="gi">+</span>
<span class="gi">+    def notnull(self) -&gt; Series:</span>
<span class="w"> </span>        &quot;&quot;&quot;Alias for `notna` method. See `notna` for more detail.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.notna()</span>

<span class="gd">-    def fillna(self, value=None, inplace: bool=False, limit=None, **kwargs):</span>
<span class="gi">+    def fillna(self, value=None, inplace: bool = False, limit=None, **kwargs):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Fill NA values with geometry (or geometries).

<span class="gu">@@ -726,9 +932,11 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.isna : detect missing values
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if value is None:</span>
<span class="gi">+            value = GeometryCollection()</span>
<span class="gi">+        return super().fillna(value=value, limit=limit, inplace=inplace, **kwargs)</span>

<span class="gd">-    def __contains__(self, other) -&gt;bool:</span>
<span class="gi">+    def __contains__(self, other) -&gt; bool:</span>
<span class="w"> </span>        &quot;&quot;&quot;Allow tests of the form &quot;geom in s&quot;

<span class="w"> </span>        Tests whether a GeoSeries contains a geometry.
<span class="gu">@@ -740,12 +948,16 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        else:
<span class="w"> </span>            return False

<span class="gi">+    @doc(plot_series)</span>
<span class="gi">+    def plot(self, *args, **kwargs):</span>
<span class="gi">+        return plot_series(self, *args, **kwargs)</span>
<span class="gi">+</span>
<span class="w"> </span>    @doc(_explore_geoseries)
<span class="w"> </span>    def explore(self, *args, **kwargs):
<span class="w"> </span>        &quot;&quot;&quot;Interactive map based on folium/leaflet.js&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return _explore_geoseries(self, *args, **kwargs)</span>

<span class="gd">-    def explode(self, ignore_index=False, index_parts=False) -&gt;GeoSeries:</span>
<span class="gi">+    def explode(self, ignore_index=False, index_parts=False) -&gt; GeoSeries:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Explode multi-part geometries into multiple single geometries.

<span class="gu">@@ -794,11 +1006,30 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        GeoDataFrame.explode

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from .base import _get_index_for_parts</span>
<span class="gi">+</span>
<span class="gi">+        geometries, outer_idx = shapely.get_parts(self.values._data, return_index=True)</span>

<span class="gi">+        index = _get_index_for_parts(</span>
<span class="gi">+            self.index,</span>
<span class="gi">+            outer_idx,</span>
<span class="gi">+            ignore_index=ignore_index,</span>
<span class="gi">+            index_parts=index_parts,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        return GeoSeries(geometries, index=index, crs=self.crs).__finalize__(self)</span>
<span class="gi">+</span>
<span class="gi">+    #</span>
<span class="gi">+    # Additional methods</span>
<span class="gi">+    #</span>
<span class="w"> </span>    @compat.requires_pyproj
<span class="gd">-    def set_crs(self, crs: Optional[Any]=None, epsg: Optional[int]=None,</span>
<span class="gd">-        inplace: bool=False, allow_override: bool=False):</span>
<span class="gi">+    def set_crs(</span>
<span class="gi">+        self,</span>
<span class="gi">+        crs: Optional[Any] = None,</span>
<span class="gi">+        epsg: Optional[int] = None,</span>
<span class="gi">+        inplace: bool = False,</span>
<span class="gi">+        allow_override: bool = False,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Set the Coordinate Reference System (CRS) of a ``GeoSeries``.

<span class="gu">@@ -873,10 +1104,30 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        GeoSeries.to_crs : re-project to another CRS

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        from pyproj import CRS</span>
<span class="gi">+</span>
<span class="gi">+        if crs is not None:</span>
<span class="gi">+            crs = CRS.from_user_input(crs)</span>
<span class="gi">+        elif epsg is not None:</span>
<span class="gi">+            crs = CRS.from_epsg(epsg)</span>
<span class="gi">+</span>
<span class="gi">+        if not allow_override and self.crs is not None and not self.crs == crs:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;The GeoSeries already has a CRS which is not equal to the passed &quot;</span>
<span class="gi">+                &quot;CRS. Specify &#39;allow_override=True&#39; to allow replacing the existing &quot;</span>
<span class="gi">+                &quot;CRS without doing any transformation. If you actually want to &quot;</span>
<span class="gi">+                &quot;transform the geometries, use &#39;GeoSeries.to_crs&#39; instead.&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        if not inplace:</span>
<span class="gi">+            result = self.copy()</span>
<span class="gi">+        else:</span>
<span class="gi">+            result = self</span>
<span class="gi">+        result.array.crs = crs</span>
<span class="gi">+        return result</span>

<span class="gd">-    def to_crs(self, crs: Optional[Any]=None, epsg: Optional[int]=None</span>
<span class="gd">-        ) -&gt;GeoSeries:</span>
<span class="gi">+    def to_crs(</span>
<span class="gi">+        self, crs: Optional[Any] = None, epsg: Optional[int] = None</span>
<span class="gi">+    ) -&gt; GeoSeries:</span>
<span class="w"> </span>        &quot;&quot;&quot;Returns a ``GeoSeries`` with all geometries transformed to a new
<span class="w"> </span>        coordinate reference system.

<span class="gu">@@ -952,9 +1203,11 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        GeoSeries.set_crs : assign CRS

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return GeoSeries(</span>
<span class="gi">+            self.values.to_crs(crs=crs, epsg=epsg), index=self.index, name=self.name</span>
<span class="gi">+        )</span>

<span class="gd">-    def estimate_utm_crs(self, datum_name: str=&#39;WGS 84&#39;):</span>
<span class="gi">+    def estimate_utm_crs(self, datum_name: str = &quot;WGS 84&quot;):</span>
<span class="w"> </span>        &quot;&quot;&quot;Returns the estimated UTM CRS based on the bounds of the dataset.

<span class="w"> </span>        .. versionadded:: 0.9
<span class="gu">@@ -990,10 +1243,15 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        - Ellipsoid: WGS 84
<span class="w"> </span>        - Prime Meridian: Greenwich
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def to_json(self, show_bbox: bool=True, drop_id: bool=False, to_wgs84:</span>
<span class="gd">-        bool=False, **kwargs) -&gt;str:</span>
<span class="gi">+        return self.values.estimate_utm_crs(datum_name)</span>
<span class="gi">+</span>
<span class="gi">+    def to_json(</span>
<span class="gi">+        self,</span>
<span class="gi">+        show_bbox: bool = True,</span>
<span class="gi">+        drop_id: bool = False,</span>
<span class="gi">+        to_wgs84: bool = False,</span>
<span class="gi">+        **kwargs,</span>
<span class="gi">+    ) -&gt; str:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Returns a GeoJSON string representation of the GeoSeries.

<span class="gu">@@ -1029,15 +1287,22 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        dtype: geometry

<span class="w"> </span>        &gt;&gt;&gt; s.to_json()
<span class="gd">-        &#39;{&quot;type&quot;: &quot;FeatureCollection&quot;, &quot;features&quot;: [{&quot;id&quot;: &quot;0&quot;, &quot;type&quot;: &quot;Feature&quot;, &quot;properties&quot;: {}, &quot;geometry&quot;: {&quot;type&quot;: &quot;Point&quot;, &quot;coordinates&quot;: [1.0, 1.0]}, &quot;bbox&quot;: [1.0, 1.0, 1.0, 1.0]}, {&quot;id&quot;: &quot;1&quot;, &quot;type&quot;: &quot;Feature&quot;, &quot;properties&quot;: {}, &quot;geometry&quot;: {&quot;type&quot;: &quot;Point&quot;, &quot;coordinates&quot;: [2.0, 2.0]}, &quot;bbox&quot;: [2.0, 2.0, 2.0, 2.0]}, {&quot;id&quot;: &quot;2&quot;, &quot;type&quot;: &quot;Feature&quot;, &quot;properties&quot;: {}, &quot;geometry&quot;: {&quot;type&quot;: &quot;Point&quot;, &quot;coordinates&quot;: [3.0, 3.0]}, &quot;bbox&quot;: [3.0, 3.0, 3.0, 3.0]}], &quot;bbox&quot;: [1.0, 1.0, 3.0, 3.0]}&#39;</span>
<span class="gi">+        &#39;{&quot;type&quot;: &quot;FeatureCollection&quot;, &quot;features&quot;: [{&quot;id&quot;: &quot;0&quot;, &quot;type&quot;: &quot;Feature&quot;, &quot;pr\</span>
<span class="gi">+operties&quot;: {}, &quot;geometry&quot;: {&quot;type&quot;: &quot;Point&quot;, &quot;coordinates&quot;: [1.0, 1.0]}, &quot;bbox&quot;: [1.0,\</span>
<span class="gi">+ 1.0, 1.0, 1.0]}, {&quot;id&quot;: &quot;1&quot;, &quot;type&quot;: &quot;Feature&quot;, &quot;properties&quot;: {}, &quot;geometry&quot;: {&quot;type&quot;\</span>
<span class="gi">+: &quot;Point&quot;, &quot;coordinates&quot;: [2.0, 2.0]}, &quot;bbox&quot;: [2.0, 2.0, 2.0, 2.0]}, {&quot;id&quot;: &quot;2&quot;, &quot;typ\</span>
<span class="gi">+e&quot;: &quot;Feature&quot;, &quot;properties&quot;: {}, &quot;geometry&quot;: {&quot;type&quot;: &quot;Point&quot;, &quot;coordinates&quot;: [3.0, 3.\</span>
<span class="gi">+0]}, &quot;bbox&quot;: [3.0, 3.0, 3.0, 3.0]}], &quot;bbox&quot;: [1.0, 1.0, 3.0, 3.0]}&#39;</span>

<span class="w"> </span>        See Also
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.to_file : write GeoSeries to file
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return self.to_frame(&quot;geometry&quot;).to_json(</span>
<span class="gi">+            na=&quot;null&quot;, show_bbox=show_bbox, drop_id=drop_id, to_wgs84=to_wgs84, **kwargs</span>
<span class="gi">+        )</span>

<span class="gd">-    def to_wkb(self, hex: bool=False, **kwargs) -&gt;Series:</span>
<span class="gi">+    def to_wkb(self, hex: bool = False, **kwargs) -&gt; Series:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Convert GeoSeries geometries to WKB

<span class="gu">@@ -1059,9 +1324,9 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.to_wkt
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return Series(to_wkb(self.array, hex=hex, **kwargs), index=self.index)</span>

<span class="gd">-    def to_wkt(self, **kwargs) -&gt;Series:</span>
<span class="gi">+    def to_wkt(self, **kwargs) -&gt; Series:</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Convert GeoSeries geometries to WKT

<span class="gu">@@ -1095,10 +1360,9 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        --------
<span class="w"> </span>        GeoSeries.to_wkb
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return Series(to_wkt(self.array, **kwargs), index=self.index)</span>

<span class="gd">-    def to_arrow(self, geometry_encoding=&#39;WKB&#39;, interleaved=True, include_z</span>
<span class="gd">-        =None):</span>
<span class="gi">+    def to_arrow(self, geometry_encoding=&quot;WKB&quot;, interleaved=True, include_z=None):</span>
<span class="w"> </span>        &quot;&quot;&quot;Encode a GeoSeries to GeoArrow format.

<span class="w"> </span>        See https://geoarrow.org/ for details on the GeoArrow specification.
<span class="gu">@@ -1163,9 +1427,40 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        ]

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        import pyarrow as pa</span>
<span class="gi">+</span>
<span class="gi">+        from geopandas.io._geoarrow import (</span>
<span class="gi">+            GeoArrowArray,</span>
<span class="gi">+            construct_geometry_array,</span>
<span class="gi">+            construct_wkb_array,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        field_name = self.name if self.name is not None else &quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+        if geometry_encoding.lower() == &quot;geoarrow&quot;:</span>
<span class="gi">+            if Version(pa.__version__) &lt; Version(&quot;10.0.0&quot;):</span>
<span class="gi">+                raise ValueError(&quot;Converting to &#39;geoarrow&#39; requires pyarrow &gt;= 10.0.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+            field, geom_arr = construct_geometry_array(</span>
<span class="gi">+                np.array(self.array),</span>
<span class="gi">+                include_z=include_z,</span>
<span class="gi">+                field_name=field_name,</span>
<span class="gi">+                crs=self.crs,</span>
<span class="gi">+                interleaved=interleaved,</span>
<span class="gi">+            )</span>
<span class="gi">+        elif geometry_encoding.lower() == &quot;wkb&quot;:</span>
<span class="gi">+            field, geom_arr = construct_wkb_array(</span>
<span class="gi">+                np.asarray(self.array), field_name=field_name, crs=self.crs</span>
<span class="gi">+            )</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;Expected geometry encoding &#39;WKB&#39; or &#39;geoarrow&#39; &quot;</span>
<span class="gi">+                f&quot;got {geometry_encoding}&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        return GeoArrowArray(field, geom_arr)</span>

<span class="gd">-    def clip(self, mask, keep_geom_type: bool=False, sort=False) -&gt;GeoSeries:</span>
<span class="gi">+    def clip(self, mask, keep_geom_type: bool = False, sort=False) -&gt; GeoSeries:</span>
<span class="w"> </span>        &quot;&quot;&quot;Clip points, lines, or polygon geometries to the mask extent.

<span class="w"> </span>        Both layers must be in the same Coordinate Reference System (CRS).
<span class="gu">@@ -1222,4 +1517,4 @@ class GeoSeries(GeoPandasBase, Series):</span>
<span class="w"> </span>        &gt;&gt;&gt; nws_groceries.shape
<span class="w"> </span>        (7,)
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return geopandas.clip(self, mask=mask, keep_geom_type=keep_geom_type, sort=sort)</span>
<span class="gh">diff --git a/geopandas/io/_geoarrow.py b/geopandas/io/_geoarrow.py</span>
<span class="gh">index cb4401fd..32ccf519 100644</span>
<span class="gd">--- a/geopandas/io/_geoarrow.py</span>
<span class="gi">+++ b/geopandas/io/_geoarrow.py</span>
<span class="gu">@@ -1,17 +1,30 @@</span>
<span class="w"> </span>import json
<span class="w"> </span>from packaging.version import Version
<span class="w"> </span>from typing import Dict, Optional, Tuple
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>import pandas as pd
<span class="w"> </span>import pyarrow as pa
<span class="w"> </span>from numpy.typing import NDArray
<span class="gi">+</span>
<span class="w"> </span>import shapely
<span class="w"> </span>from shapely import GeometryType
<span class="gi">+</span>
<span class="w"> </span>from geopandas import GeoDataFrame
<span class="w"> </span>from geopandas._compat import SHAPELY_GE_204
<span class="w"> </span>from geopandas.array import from_shapely, from_wkb
<span class="gd">-GEOARROW_ENCODINGS = [&#39;point&#39;, &#39;linestring&#39;, &#39;polygon&#39;, &#39;multipoint&#39;,</span>
<span class="gd">-    &#39;multilinestring&#39;, &#39;multipolygon&#39;]</span>
<span class="gi">+</span>
<span class="gi">+GEOARROW_ENCODINGS = [</span>
<span class="gi">+    &quot;point&quot;,</span>
<span class="gi">+    &quot;linestring&quot;,</span>
<span class="gi">+    &quot;polygon&quot;,</span>
<span class="gi">+    &quot;multipoint&quot;,</span>
<span class="gi">+    &quot;multilinestring&quot;,</span>
<span class="gi">+    &quot;multipolygon&quot;,</span>
<span class="gi">+]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+## GeoPandas -&gt; GeoArrow</span>


<span class="w"> </span>class ArrowTable:
<span class="gu">@@ -35,8 +48,7 @@ class ArrowTable:</span>
<span class="w"> </span>        self._pa_table = pa_table

<span class="w"> </span>    def __arrow_c_stream__(self, requested_schema=None):
<span class="gd">-        return self._pa_table.__arrow_c_stream__(requested_schema=</span>
<span class="gd">-            requested_schema)</span>
<span class="gi">+        return self._pa_table.__arrow_c_stream__(requested_schema=requested_schema)</span>


<span class="w"> </span>class GeoArrowArray:
<span class="gu">@@ -63,13 +75,21 @@ class GeoArrowArray:</span>
<span class="w"> </span>    def __arrow_c_array__(self, requested_schema=None):
<span class="w"> </span>        if requested_schema is not None:
<span class="w"> </span>            raise NotImplementedError(
<span class="gd">-                &#39;Requested schema is not supported for geometry arrays&#39;)</span>
<span class="gd">-        return self._pa_field.__arrow_c_schema__(</span>
<span class="gd">-            ), self._pa_array.__arrow_c_array__()[1]</span>
<span class="gi">+                &quot;Requested schema is not supported for geometry arrays&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        return (</span>
<span class="gi">+            self._pa_field.__arrow_c_schema__(),</span>
<span class="gi">+            self._pa_array.__arrow_c_array__()[1],</span>
<span class="gi">+        )</span>


<span class="gd">-def geopandas_to_arrow(df, index=None, geometry_encoding=&#39;WKB&#39;, interleaved</span>
<span class="gd">-    =True, include_z=None):</span>
<span class="gi">+def geopandas_to_arrow(</span>
<span class="gi">+    df,</span>
<span class="gi">+    index=None,</span>
<span class="gi">+    geometry_encoding=&quot;WKB&quot;,</span>
<span class="gi">+    interleaved=True,</span>
<span class="gi">+    include_z=None,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Convert GeoDataFrame to a pyarrow.Table.

<span class="gu">@@ -101,7 +121,330 @@ def geopandas_to_arrow(df, index=None, geometry_encoding=&#39;WKB&#39;, interleaved</span>
<span class="w"> </span>        specify the keyword).

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    mask = df.dtypes == &quot;geometry&quot;</span>
<span class="gi">+    geometry_columns = df.columns[mask]</span>
<span class="gi">+    geometry_indices = np.asarray(mask).nonzero()[0]</span>
<span class="gi">+</span>
<span class="gi">+    df_attr = pd.DataFrame(df.copy(deep=False))</span>
<span class="gi">+</span>
<span class="gi">+    # replace geometry columns with dummy values -&gt; will get converted to</span>
<span class="gi">+    # Arrow null column (not holding any memory), so we can afterwards</span>
<span class="gi">+    # fill the resulting table with the correct geometry fields</span>
<span class="gi">+    for col in geometry_columns:</span>
<span class="gi">+        df_attr[col] = None</span>
<span class="gi">+</span>
<span class="gi">+    table = pa.Table.from_pandas(df_attr, preserve_index=index)</span>
<span class="gi">+</span>
<span class="gi">+    geometry_encoding_dict = {}</span>
<span class="gi">+</span>
<span class="gi">+    if geometry_encoding.lower() == &quot;geoarrow&quot;:</span>
<span class="gi">+        if Version(pa.__version__) &lt; Version(&quot;10.0.0&quot;):</span>
<span class="gi">+            raise ValueError(&quot;Converting to &#39;geoarrow&#39; requires pyarrow &gt;= 10.0.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        # Encode all geometry columns to GeoArrow</span>
<span class="gi">+        for i, col in zip(geometry_indices, geometry_columns):</span>
<span class="gi">+            field, geom_arr = construct_geometry_array(</span>
<span class="gi">+                np.array(df[col].array),</span>
<span class="gi">+                include_z=include_z,</span>
<span class="gi">+                field_name=col,</span>
<span class="gi">+                crs=df[col].crs,</span>
<span class="gi">+                interleaved=interleaved,</span>
<span class="gi">+            )</span>
<span class="gi">+            table = table.set_column(i, field, geom_arr)</span>
<span class="gi">+            geometry_encoding_dict[col] = (</span>
<span class="gi">+                field.metadata[b&quot;ARROW:extension:name&quot;]</span>
<span class="gi">+                .decode()</span>
<span class="gi">+                .removeprefix(&quot;geoarrow.&quot;)</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    elif geometry_encoding.lower() == &quot;wkb&quot;:</span>
<span class="gi">+        # Encode all geometry columns to WKB</span>
<span class="gi">+        for i, col in zip(geometry_indices, geometry_columns):</span>
<span class="gi">+            field, wkb_arr = construct_wkb_array(</span>
<span class="gi">+                np.asarray(df[col].array), field_name=col, crs=df[col].crs</span>
<span class="gi">+            )</span>
<span class="gi">+            table = table.set_column(i, field, wkb_arr)</span>
<span class="gi">+            geometry_encoding_dict[col] = &quot;WKB&quot;</span>
<span class="gi">+</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            f&quot;Expected geometry encoding &#39;WKB&#39; or &#39;geoarrow&#39; got {geometry_encoding}&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+    return table, geometry_encoding_dict</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def construct_wkb_array(</span>
<span class="gi">+    shapely_arr: NDArray[np.object_],</span>
<span class="gi">+    *,</span>
<span class="gi">+    field_name: str = &quot;geometry&quot;,</span>
<span class="gi">+    crs: Optional[str] = None,</span>
<span class="gi">+) -&gt; Tuple[pa.Field, pa.Array]:</span>
<span class="gi">+</span>
<span class="gi">+    if shapely.geos_version &gt; (3, 10, 0):</span>
<span class="gi">+        kwargs = {&quot;flavor&quot;: &quot;iso&quot;}</span>
<span class="gi">+    else:</span>
<span class="gi">+        if shapely.has_z(shapely_arr).any():</span>
<span class="gi">+            raise ValueError(&quot;Cannot write 3D geometries with GEOS&lt;3.10&quot;)</span>
<span class="gi">+        kwargs = {}</span>
<span class="gi">+</span>
<span class="gi">+    wkb_arr = shapely.to_wkb(shapely_arr, **kwargs)</span>
<span class="gi">+    extension_metadata = {&quot;ARROW:extension:name&quot;: &quot;geoarrow.wkb&quot;}</span>
<span class="gi">+    if crs is not None:</span>
<span class="gi">+        extension_metadata[&quot;ARROW:extension:metadata&quot;] = json.dumps(</span>
<span class="gi">+            {&quot;crs&quot;: crs.to_json()}</span>
<span class="gi">+        )</span>
<span class="gi">+    else:</span>
<span class="gi">+        # In theory this should not be needed, but otherwise pyarrow &lt; 17</span>
<span class="gi">+        # crashes on receiving such data through C Data Interface</span>
<span class="gi">+        # https://github.com/apache/arrow/issues/41741</span>
<span class="gi">+        extension_metadata[&quot;ARROW:extension:metadata&quot;] = &quot;{}&quot;</span>
<span class="gi">+</span>
<span class="gi">+    field = pa.field(</span>
<span class="gi">+        field_name, type=pa.binary(), nullable=True, metadata=extension_metadata</span>
<span class="gi">+    )</span>
<span class="gi">+    parr = pa.array(np.asarray(wkb_arr), pa.binary())</span>
<span class="gi">+    return field, parr</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _convert_inner_coords(coords, interleaved, dims, mask=None):</span>
<span class="gi">+    if interleaved:</span>
<span class="gi">+        coords_field = pa.field(dims, pa.float64(), nullable=False)</span>
<span class="gi">+        typ = pa.list_(coords_field, len(dims))</span>
<span class="gi">+        if mask is None:</span>
<span class="gi">+            # mask keyword only added in pyarrow 15.0.0</span>
<span class="gi">+            parr = pa.FixedSizeListArray.from_arrays(coords.ravel(), type=typ)</span>
<span class="gi">+        else:</span>
<span class="gi">+            parr = pa.FixedSizeListArray.from_arrays(</span>
<span class="gi">+                coords.ravel(), type=typ, mask=mask</span>
<span class="gi">+            )</span>
<span class="gi">+    else:</span>
<span class="gi">+        if dims == &quot;xy&quot;:</span>
<span class="gi">+            fields = [</span>
<span class="gi">+                pa.field(&quot;x&quot;, pa.float64(), nullable=False),</span>
<span class="gi">+                pa.field(&quot;y&quot;, pa.float64(), nullable=False),</span>
<span class="gi">+            ]</span>
<span class="gi">+            parr = pa.StructArray.from_arrays(</span>
<span class="gi">+                [coords[:, 0].copy(), coords[:, 1].copy()], fields=fields, mask=mask</span>
<span class="gi">+            )</span>
<span class="gi">+        else:</span>
<span class="gi">+            fields = [</span>
<span class="gi">+                pa.field(&quot;x&quot;, pa.float64(), nullable=False),</span>
<span class="gi">+                pa.field(&quot;y&quot;, pa.float64(), nullable=False),</span>
<span class="gi">+                pa.field(&quot;z&quot;, pa.float64(), nullable=False),</span>
<span class="gi">+            ]</span>
<span class="gi">+            parr = pa.StructArray.from_arrays(</span>
<span class="gi">+                [coords[:, 0].copy(), coords[:, 1].copy(), coords[:, 2].copy()],</span>
<span class="gi">+                fields=fields,</span>
<span class="gi">+                mask=mask,</span>
<span class="gi">+            )</span>
<span class="gi">+    return parr</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _linestring_type(point_type):</span>
<span class="gi">+    return pa.list_(pa.field(&quot;vertices&quot;, point_type, nullable=False))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _polygon_type(point_type):</span>
<span class="gi">+    return pa.list_(</span>
<span class="gi">+        pa.field(</span>
<span class="gi">+            &quot;rings&quot;,</span>
<span class="gi">+            pa.list_(pa.field(&quot;vertices&quot;, point_type, nullable=False)),</span>
<span class="gi">+            nullable=False,</span>
<span class="gi">+        )</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _multipoint_type(point_type):</span>
<span class="gi">+    return pa.list_(pa.field(&quot;points&quot;, point_type, nullable=False))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _multilinestring_type(point_type):</span>
<span class="gi">+    return pa.list_(</span>
<span class="gi">+        pa.field(&quot;linestrings&quot;, _linestring_type(point_type), nullable=False)</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _multipolygon_type(point_type):</span>
<span class="gi">+    return pa.list_(pa.field(&quot;polygons&quot;, _polygon_type(point_type), nullable=False))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def construct_geometry_array(</span>
<span class="gi">+    shapely_arr: NDArray[np.object_],</span>
<span class="gi">+    include_z: Optional[bool] = None,</span>
<span class="gi">+    *,</span>
<span class="gi">+    field_name: str = &quot;geometry&quot;,</span>
<span class="gi">+    crs: Optional[str] = None,</span>
<span class="gi">+    interleaved: bool = True,</span>
<span class="gi">+) -&gt; Tuple[pa.Field, pa.Array]:</span>
<span class="gi">+    # NOTE: this implementation returns a (field, array) pair so that it can set the</span>
<span class="gi">+    # extension metadata on the field without instantiating extension types into the</span>
<span class="gi">+    # global pyarrow registry</span>
<span class="gi">+    geom_type, coords, offsets = shapely.to_ragged_array(</span>
<span class="gi">+        shapely_arr, include_z=include_z</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    mask = shapely.is_missing(shapely_arr)</span>
<span class="gi">+    if mask.any():</span>
<span class="gi">+        if (</span>
<span class="gi">+            geom_type == GeometryType.POINT</span>
<span class="gi">+            and interleaved</span>
<span class="gi">+            and Version(pa.__version__) &lt; Version(&quot;15.0.0&quot;)</span>
<span class="gi">+        ):</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;Converting point geometries with missing values is not supported &quot;</span>
<span class="gi">+                &quot;for interleaved coordinates with pyarrow &lt; 15.0.0. Please &quot;</span>
<span class="gi">+                &quot;upgrade to a newer version of pyarrow.&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        mask = pa.array(mask, type=pa.bool_())</span>
<span class="gi">+</span>
<span class="gi">+        if geom_type == GeometryType.POINT and not SHAPELY_GE_204:</span>
<span class="gi">+            # bug in shapely &lt; 2.0.4, see https://github.com/shapely/shapely/pull/2034</span>
<span class="gi">+            # this workaround only works if there are no empty points</span>
<span class="gi">+            indices = np.nonzero(mask)[0]</span>
<span class="gi">+            indices = indices - np.arange(len(indices))</span>
<span class="gi">+            coords = np.insert(coords, indices, np.nan, axis=0)</span>
<span class="gi">+</span>
<span class="gi">+    else:</span>
<span class="gi">+        mask = None</span>
<span class="gi">+</span>
<span class="gi">+    if coords.shape[-1] == 2:</span>
<span class="gi">+        dims = &quot;xy&quot;</span>
<span class="gi">+    elif coords.shape[-1] == 3:</span>
<span class="gi">+        dims = &quot;xyz&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(f&quot;Unexpected coords dimensions: {coords.shape}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    extension_metadata: Dict[str, str] = {}</span>
<span class="gi">+    if crs is not None:</span>
<span class="gi">+        extension_metadata[&quot;ARROW:extension:metadata&quot;] = json.dumps(</span>
<span class="gi">+            {&quot;crs&quot;: crs.to_json()}</span>
<span class="gi">+        )</span>
<span class="gi">+    else:</span>
<span class="gi">+        # In theory this should not be needed, but otherwise pyarrow &lt; 17</span>
<span class="gi">+        # crashes on receiving such data through C Data Interface</span>
<span class="gi">+        # https://github.com/apache/arrow/issues/41741</span>
<span class="gi">+        extension_metadata[&quot;ARROW:extension:metadata&quot;] = &quot;{}&quot;</span>
<span class="gi">+</span>
<span class="gi">+    if geom_type == GeometryType.POINT:</span>
<span class="gi">+        parr = _convert_inner_coords(coords, interleaved, dims, mask=mask)</span>
<span class="gi">+        extension_metadata[&quot;ARROW:extension:name&quot;] = &quot;geoarrow.point&quot;</span>
<span class="gi">+        field = pa.field(</span>
<span class="gi">+            field_name,</span>
<span class="gi">+            parr.type,</span>
<span class="gi">+            nullable=True,</span>
<span class="gi">+            metadata=extension_metadata,</span>
<span class="gi">+        )</span>
<span class="gi">+        return field, parr</span>
<span class="gi">+</span>
<span class="gi">+    elif geom_type == GeometryType.LINESTRING:</span>
<span class="gi">+        assert len(offsets) == 1, &quot;Expected one offsets array&quot;</span>
<span class="gi">+        (geom_offsets,) = offsets</span>
<span class="gi">+        _parr = _convert_inner_coords(coords, interleaved, dims)</span>
<span class="gi">+        parr = pa.ListArray.from_arrays(</span>
<span class="gi">+            pa.array(geom_offsets), _parr, _linestring_type(_parr.type), mask=mask</span>
<span class="gi">+        )</span>
<span class="gi">+        extension_metadata[&quot;ARROW:extension:name&quot;] = &quot;geoarrow.linestring&quot;</span>
<span class="gi">+        field = pa.field(</span>
<span class="gi">+            field_name,</span>
<span class="gi">+            parr.type,</span>
<span class="gi">+            nullable=True,</span>
<span class="gi">+            metadata=extension_metadata,</span>
<span class="gi">+        )</span>
<span class="gi">+        return field, parr</span>
<span class="gi">+</span>
<span class="gi">+    elif geom_type == GeometryType.POLYGON:</span>
<span class="gi">+        assert len(offsets) == 2, &quot;Expected two offsets arrays&quot;</span>
<span class="gi">+        ring_offsets, geom_offsets = offsets</span>
<span class="gi">+        _parr = _convert_inner_coords(coords, interleaved, dims)</span>
<span class="gi">+        _parr1 = pa.ListArray.from_arrays(pa.array(ring_offsets), _parr)</span>
<span class="gi">+        parr = pa.ListArray.from_arrays(pa.array(geom_offsets), _parr1, mask=mask)</span>
<span class="gi">+        parr = parr.cast(_polygon_type(_parr.type))</span>
<span class="gi">+        extension_metadata[&quot;ARROW:extension:name&quot;] = &quot;geoarrow.polygon&quot;</span>
<span class="gi">+        field = pa.field(</span>
<span class="gi">+            field_name,</span>
<span class="gi">+            parr.type,</span>
<span class="gi">+            nullable=True,</span>
<span class="gi">+            metadata=extension_metadata,</span>
<span class="gi">+        )</span>
<span class="gi">+        return field, parr</span>
<span class="gi">+</span>
<span class="gi">+    elif geom_type == GeometryType.MULTIPOINT:</span>
<span class="gi">+        assert len(offsets) == 1, &quot;Expected one offsets array&quot;</span>
<span class="gi">+        (geom_offsets,) = offsets</span>
<span class="gi">+        _parr = _convert_inner_coords(coords, interleaved, dims)</span>
<span class="gi">+        parr = pa.ListArray.from_arrays(</span>
<span class="gi">+            pa.array(geom_offsets), _parr, type=_multipoint_type(_parr.type), mask=mask</span>
<span class="gi">+        )</span>
<span class="gi">+        extension_metadata[&quot;ARROW:extension:name&quot;] = &quot;geoarrow.multipoint&quot;</span>
<span class="gi">+        field = pa.field(</span>
<span class="gi">+            field_name,</span>
<span class="gi">+            parr.type,</span>
<span class="gi">+            nullable=True,</span>
<span class="gi">+            metadata=extension_metadata,</span>
<span class="gi">+        )</span>
<span class="gi">+        return field, parr</span>
<span class="gi">+</span>
<span class="gi">+    elif geom_type == GeometryType.MULTILINESTRING:</span>
<span class="gi">+        assert len(offsets) == 2, &quot;Expected two offsets arrays&quot;</span>
<span class="gi">+        ring_offsets, geom_offsets = offsets</span>
<span class="gi">+        _parr = _convert_inner_coords(coords, interleaved, dims)</span>
<span class="gi">+        _parr1 = pa.ListArray.from_arrays(pa.array(ring_offsets), _parr)</span>
<span class="gi">+        parr = pa.ListArray.from_arrays(pa.array(geom_offsets), _parr1, mask=mask)</span>
<span class="gi">+        parr = parr.cast(_multilinestring_type(_parr.type))</span>
<span class="gi">+        extension_metadata[&quot;ARROW:extension:name&quot;] = &quot;geoarrow.multilinestring&quot;</span>
<span class="gi">+        field = pa.field(</span>
<span class="gi">+            field_name,</span>
<span class="gi">+            parr.type,</span>
<span class="gi">+            nullable=True,</span>
<span class="gi">+            metadata=extension_metadata,</span>
<span class="gi">+        )</span>
<span class="gi">+        return field, parr</span>
<span class="gi">+</span>
<span class="gi">+    elif geom_type == GeometryType.MULTIPOLYGON:</span>
<span class="gi">+        assert len(offsets) == 3, &quot;Expected three offsets arrays&quot;</span>
<span class="gi">+        ring_offsets, polygon_offsets, geom_offsets = offsets</span>
<span class="gi">+        _parr = _convert_inner_coords(coords, interleaved, dims)</span>
<span class="gi">+        _parr1 = pa.ListArray.from_arrays(pa.array(ring_offsets), _parr)</span>
<span class="gi">+        _parr2 = pa.ListArray.from_arrays(pa.array(polygon_offsets), _parr1)</span>
<span class="gi">+        parr = pa.ListArray.from_arrays(pa.array(geom_offsets), _parr2, mask=mask)</span>
<span class="gi">+        parr = parr.cast(_multipolygon_type(_parr.type))</span>
<span class="gi">+        extension_metadata[&quot;ARROW:extension:name&quot;] = &quot;geoarrow.multipolygon&quot;</span>
<span class="gi">+        field = pa.field(</span>
<span class="gi">+            field_name,</span>
<span class="gi">+            parr.type,</span>
<span class="gi">+            nullable=True,</span>
<span class="gi">+            metadata=extension_metadata,</span>
<span class="gi">+        )</span>
<span class="gi">+        return field, parr</span>
<span class="gi">+</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(f&quot;Unsupported type for geoarrow: {geom_type}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+## GeoArrow -&gt; GeoPandas</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _get_arrow_geometry_field(field):</span>
<span class="gi">+    if (meta := field.metadata) is not None:</span>
<span class="gi">+        if (ext_name := meta.get(b&quot;ARROW:extension:name&quot;, None)) is not None:</span>
<span class="gi">+            if ext_name.startswith(b&quot;geoarrow.&quot;):</span>
<span class="gi">+                if (</span>
<span class="gi">+                    ext_meta := meta.get(b&quot;ARROW:extension:metadata&quot;, None)</span>
<span class="gi">+                ) is not None:</span>
<span class="gi">+                    ext_meta = json.loads(ext_meta.decode())</span>
<span class="gi">+                return ext_name.decode(), ext_meta</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(field.type, pa.ExtensionType):</span>
<span class="gi">+        ext_name = field.type.extension_name</span>
<span class="gi">+        if ext_name.startswith(&quot;geoarrow.&quot;):</span>
<span class="gi">+            ext_meta_ser = field.type.__arrow_ext_serialize__()</span>
<span class="gi">+            if ext_meta_ser:</span>
<span class="gi">+                ext_meta = json.loads(ext_meta_ser.decode())</span>
<span class="gi">+            else:</span>
<span class="gi">+                ext_meta = None</span>
<span class="gi">+            return ext_name, ext_meta</span>
<span class="gi">+</span>
<span class="gi">+    return None</span>


<span class="w"> </span>def arrow_to_geopandas(table, geometry=None):
<span class="gu">@@ -121,7 +464,40 @@ def arrow_to_geopandas(table, geometry=None):</span>
<span class="w"> </span>    GeoDataFrame

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not isinstance(table, pa.Table):</span>
<span class="gi">+        table = pa.table(table)</span>
<span class="gi">+</span>
<span class="gi">+    geom_fields = []</span>
<span class="gi">+</span>
<span class="gi">+    for i, field in enumerate(table.schema):</span>
<span class="gi">+        geom = _get_arrow_geometry_field(field)</span>
<span class="gi">+        if geom is not None:</span>
<span class="gi">+            geom_fields.append((i, field.name, *geom))</span>
<span class="gi">+</span>
<span class="gi">+    if len(geom_fields) == 0:</span>
<span class="gi">+        raise ValueError(&quot;No geometry column found in the Arrow table.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    table_attr = table.drop([f[1] for f in geom_fields])</span>
<span class="gi">+    df = table_attr.to_pandas()</span>
<span class="gi">+</span>
<span class="gi">+    for i, col, ext_name, ext_meta in geom_fields:</span>
<span class="gi">+        crs = None</span>
<span class="gi">+        if ext_meta is not None and &quot;crs&quot; in ext_meta:</span>
<span class="gi">+            crs = ext_meta[&quot;crs&quot;]</span>
<span class="gi">+</span>
<span class="gi">+        if ext_name == &quot;geoarrow.wkb&quot;:</span>
<span class="gi">+            geom_arr = from_wkb(np.array(table[col]), crs=crs)</span>
<span class="gi">+        elif ext_name.split(&quot;.&quot;)[1] in GEOARROW_ENCODINGS:</span>
<span class="gi">+</span>
<span class="gi">+            geom_arr = from_shapely(</span>
<span class="gi">+                construct_shapely_array(table[col].combine_chunks(), ext_name), crs=crs</span>
<span class="gi">+            )</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise TypeError(f&quot;Unknown GeoArrow extension type: {ext_name}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        df.insert(i, col, geom_arr)</span>
<span class="gi">+</span>
<span class="gi">+    return GeoDataFrame(df, geometry=geometry or geom_fields[0][1])</span>


<span class="w"> </span>def arrow_to_geometry_array(arr):
<span class="gu">@@ -131,7 +507,51 @@ def arrow_to_geometry_array(arr):</span>

<span class="w"> </span>    Specifically for GeoSeries.from_arrow.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if Version(pa.__version__) &lt; Version(&quot;14.0.0&quot;):</span>
<span class="gi">+        raise ValueError(&quot;Importing from Arrow requires pyarrow &gt;= 14.0.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    schema_capsule, array_capsule = arr.__arrow_c_array__()</span>
<span class="gi">+    field = pa.Field._import_from_c_capsule(schema_capsule)</span>
<span class="gi">+    pa_arr = pa.Array._import_from_c_capsule(field.__arrow_c_schema__(), array_capsule)</span>
<span class="gi">+</span>
<span class="gi">+    geom_info = _get_arrow_geometry_field(field)</span>
<span class="gi">+    if geom_info is None:</span>
<span class="gi">+        raise ValueError(&quot;No GeoArrow geometry field found.&quot;)</span>
<span class="gi">+    ext_name, ext_meta = geom_info</span>
<span class="gi">+</span>
<span class="gi">+    crs = None</span>
<span class="gi">+    if ext_meta is not None and &quot;crs&quot; in ext_meta:</span>
<span class="gi">+        crs = ext_meta[&quot;crs&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    if ext_name == &quot;geoarrow.wkb&quot;:</span>
<span class="gi">+        geom_arr = from_wkb(np.array(pa_arr), crs=crs)</span>
<span class="gi">+    elif ext_name.split(&quot;.&quot;)[1] in GEOARROW_ENCODINGS:</span>
<span class="gi">+</span>
<span class="gi">+        geom_arr = from_shapely(construct_shapely_array(pa_arr, ext_name), crs=crs)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(f&quot;Unknown GeoArrow extension type: {ext_name}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    return geom_arr</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _get_inner_coords(arr):</span>
<span class="gi">+    if pa.types.is_struct(arr.type):</span>
<span class="gi">+        if arr.type.num_fields == 2:</span>
<span class="gi">+            coords = np.column_stack(</span>
<span class="gi">+                [np.asarray(arr.field(&quot;x&quot;)), np.asarray(arr.field(&quot;y&quot;))]</span>
<span class="gi">+            )</span>
<span class="gi">+        else:</span>
<span class="gi">+            coords = np.column_stack(</span>
<span class="gi">+                [</span>
<span class="gi">+                    np.asarray(arr.field(&quot;x&quot;)),</span>
<span class="gi">+                    np.asarray(arr.field(&quot;y&quot;)),</span>
<span class="gi">+                    np.asarray(arr.field(&quot;z&quot;)),</span>
<span class="gi">+                ]</span>
<span class="gi">+            )</span>
<span class="gi">+        return coords</span>
<span class="gi">+    else:</span>
<span class="gi">+        # fixed size list</span>
<span class="gi">+        return np.asarray(arr.values).reshape(len(arr), -1)</span>


<span class="w"> </span>def construct_shapely_array(arr: pa.Array, extension_name: str):
<span class="gu">@@ -140,4 +560,55 @@ def construct_shapely_array(arr: pa.Array, extension_name: str):</span>
<span class="w"> </span>    with GeoArrow extension type.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(arr, pa.ExtensionArray):</span>
<span class="gi">+        arr = arr.storage</span>
<span class="gi">+</span>
<span class="gi">+    if extension_name == &quot;geoarrow.point&quot;:</span>
<span class="gi">+        coords = _get_inner_coords(arr)</span>
<span class="gi">+        result = shapely.from_ragged_array(GeometryType.POINT, coords, None)</span>
<span class="gi">+</span>
<span class="gi">+    elif extension_name == &quot;geoarrow.linestring&quot;:</span>
<span class="gi">+        coords = _get_inner_coords(arr.values)</span>
<span class="gi">+        offsets1 = np.asarray(arr.offsets)</span>
<span class="gi">+        offsets = (offsets1,)</span>
<span class="gi">+        result = shapely.from_ragged_array(GeometryType.LINESTRING, coords, offsets)</span>
<span class="gi">+</span>
<span class="gi">+    elif extension_name == &quot;geoarrow.polygon&quot;:</span>
<span class="gi">+        coords = _get_inner_coords(arr.values.values)</span>
<span class="gi">+        offsets2 = np.asarray(arr.offsets)</span>
<span class="gi">+        offsets1 = np.asarray(arr.values.offsets)</span>
<span class="gi">+        offsets = (offsets1, offsets2)</span>
<span class="gi">+        result = shapely.from_ragged_array(GeometryType.POLYGON, coords, offsets)</span>
<span class="gi">+</span>
<span class="gi">+    elif extension_name == &quot;geoarrow.multipoint&quot;:</span>
<span class="gi">+        coords = _get_inner_coords(arr.values)</span>
<span class="gi">+        offsets1 = np.asarray(arr.offsets)</span>
<span class="gi">+        offsets = (offsets1,)</span>
<span class="gi">+        result = shapely.from_ragged_array(GeometryType.MULTIPOINT, coords, offsets)</span>
<span class="gi">+</span>
<span class="gi">+    elif extension_name == &quot;geoarrow.multilinestring&quot;:</span>
<span class="gi">+        coords = _get_inner_coords(arr.values.values)</span>
<span class="gi">+        offsets2 = np.asarray(arr.offsets)</span>
<span class="gi">+        offsets1 = np.asarray(arr.values.offsets)</span>
<span class="gi">+        offsets = (offsets1, offsets2)</span>
<span class="gi">+        result = shapely.from_ragged_array(</span>
<span class="gi">+            GeometryType.MULTILINESTRING, coords, offsets</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    elif extension_name == &quot;geoarrow.multipolygon&quot;:</span>
<span class="gi">+        coords = _get_inner_coords(arr.values.values.values)</span>
<span class="gi">+        offsets3 = np.asarray(arr.offsets)</span>
<span class="gi">+        offsets2 = np.asarray(arr.values.offsets)</span>
<span class="gi">+        offsets1 = np.asarray(arr.values.values.offsets)</span>
<span class="gi">+        offsets = (offsets1, offsets2, offsets3)</span>
<span class="gi">+        result = shapely.from_ragged_array(GeometryType.MULTIPOLYGON, coords, offsets)</span>
<span class="gi">+</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(extension_name)</span>
<span class="gi">+</span>
<span class="gi">+    # apply validity mask</span>
<span class="gi">+    if arr.null_count:</span>
<span class="gi">+        mask = np.asarray(arr.is_null())</span>
<span class="gi">+        result = np.where(mask, None, result)</span>
<span class="gi">+</span>
<span class="gi">+    return result</span>
<span class="gh">diff --git a/geopandas/io/_pyarrow_hotfix.py b/geopandas/io/_pyarrow_hotfix.py</span>
<span class="gh">index f8586c5c..731db2d6 100644</span>
<span class="gd">--- a/geopandas/io/_pyarrow_hotfix.py</span>
<span class="gi">+++ b/geopandas/io/_pyarrow_hotfix.py</span>
<span class="gu">@@ -1,10 +1,12 @@</span>
<span class="w"> </span>from packaging.version import Version
<span class="gi">+</span>
<span class="w"> </span>import pyarrow
<span class="gd">-_ERROR_MSG = &quot;&quot;&quot;Disallowed deserialization of &#39;arrow.py_extension_type&#39;:</span>
<span class="gi">+</span>
<span class="gi">+_ERROR_MSG = &quot;&quot;&quot;\</span>
<span class="gi">+Disallowed deserialization of &#39;arrow.py_extension_type&#39;:</span>
<span class="w"> </span>storage_type = {storage_type}
<span class="w"> </span>serialized = {serialized}
<span class="gd">-pickle disassembly:</span>
<span class="gd">-{pickle_disassembly}</span>
<span class="gi">+pickle disassembly:\n{pickle_disassembly}</span>

<span class="w"> </span>Reading of untrusted Parquet or Feather files with a PyExtensionType column
<span class="w"> </span>allows arbitrary code execution.
<span class="gu">@@ -19,4 +21,52 @@ derived from `pyarrow.ExtensionType` instead, and register this type explicitly.</span>
<span class="w"> </span>See https://arrow.apache.org/docs/dev/python/extending_types.html#defining-extension-types-user-defined-types
<span class="w"> </span>for more details.
<span class="w"> </span>&quot;&quot;&quot;
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def patch_pyarrow():</span>
<span class="gi">+    # starting from pyarrow 14.0.1, it has its own mechanism</span>
<span class="gi">+    if Version(pyarrow.__version__) &gt;= Version(&quot;14.0.1&quot;):</span>
<span class="gi">+        return</span>
<span class="gi">+</span>
<span class="gi">+    # if the user has pyarrow_hotfix (https://github.com/pitrou/pyarrow-hotfix)</span>
<span class="gi">+    # installed, use this instead (which also ensures it works if they had</span>
<span class="gi">+    # called `pyarrow_hotfix.uninstall()`)</span>
<span class="gi">+    try:</span>
<span class="gi">+        import pyarrow_hotfix  # noqa: F401</span>
<span class="gi">+    except ImportError:</span>
<span class="gi">+        pass</span>
<span class="gi">+    else:</span>
<span class="gi">+        return</span>
<span class="gi">+</span>
<span class="gi">+    # if the hotfix is already installed and enabled</span>
<span class="gi">+    if getattr(pyarrow, &quot;_hotfix_installed&quot;, False):</span>
<span class="gi">+        return</span>
<span class="gi">+</span>
<span class="gi">+    class ForbiddenExtensionType(pyarrow.ExtensionType):</span>
<span class="gi">+        def __arrow_ext_serialize__(self):</span>
<span class="gi">+            return b&quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+        @classmethod</span>
<span class="gi">+        def __arrow_ext_deserialize__(cls, storage_type, serialized):</span>
<span class="gi">+            import io</span>
<span class="gi">+            import pickletools</span>
<span class="gi">+</span>
<span class="gi">+            out = io.StringIO()</span>
<span class="gi">+            pickletools.dis(serialized, out)</span>
<span class="gi">+            raise RuntimeError(</span>
<span class="gi">+                _ERROR_MSG.format(</span>
<span class="gi">+                    storage_type=storage_type,</span>
<span class="gi">+                    serialized=serialized,</span>
<span class="gi">+                    pickle_disassembly=out.getvalue(),</span>
<span class="gi">+                )</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    pyarrow.unregister_extension_type(&quot;arrow.py_extension_type&quot;)</span>
<span class="gi">+    pyarrow.register_extension_type(</span>
<span class="gi">+        ForbiddenExtensionType(pyarrow.null(), &quot;arrow.py_extension_type&quot;)</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    pyarrow._hotfix_installed = True</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>patch_pyarrow()
<span class="gh">diff --git a/geopandas/io/arrow.py b/geopandas/io/arrow.py</span>
<span class="gh">index defcba99..53cf77ed 100644</span>
<span class="gd">--- a/geopandas/io/arrow.py</span>
<span class="gi">+++ b/geopandas/io/arrow.py</span>
<span class="gu">@@ -1,19 +1,65 @@</span>
<span class="w"> </span>import json
<span class="w"> </span>import warnings
<span class="w"> </span>from packaging.version import Version
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>from pandas import DataFrame, Series
<span class="gi">+</span>
<span class="w"> </span>import shapely
<span class="gi">+</span>
<span class="w"> </span>import geopandas
<span class="w"> </span>from geopandas import GeoDataFrame
<span class="w"> </span>from geopandas._compat import import_optional_dependency
<span class="w"> </span>from geopandas.array import from_shapely, from_wkb
<span class="gi">+</span>
<span class="w"> </span>from .file import _expand_user
<span class="gd">-METADATA_VERSION = &#39;1.0.0&#39;</span>
<span class="gd">-SUPPORTED_VERSIONS = [&#39;0.1.0&#39;, &#39;0.4.0&#39;, &#39;1.0.0-beta.1&#39;, &#39;1.0.0&#39;, &#39;1.1.0&#39;]</span>
<span class="gd">-GEOARROW_ENCODINGS = [&#39;point&#39;, &#39;linestring&#39;, &#39;polygon&#39;, &#39;multipoint&#39;,</span>
<span class="gd">-    &#39;multilinestring&#39;, &#39;multipolygon&#39;]</span>
<span class="gd">-SUPPORTED_ENCODINGS = [&#39;WKB&#39;] + GEOARROW_ENCODINGS</span>
<span class="gi">+</span>
<span class="gi">+METADATA_VERSION = &quot;1.0.0&quot;</span>
<span class="gi">+SUPPORTED_VERSIONS = [&quot;0.1.0&quot;, &quot;0.4.0&quot;, &quot;1.0.0-beta.1&quot;, &quot;1.0.0&quot;, &quot;1.1.0&quot;]</span>
<span class="gi">+GEOARROW_ENCODINGS = [</span>
<span class="gi">+    &quot;point&quot;,</span>
<span class="gi">+    &quot;linestring&quot;,</span>
<span class="gi">+    &quot;polygon&quot;,</span>
<span class="gi">+    &quot;multipoint&quot;,</span>
<span class="gi">+    &quot;multilinestring&quot;,</span>
<span class="gi">+    &quot;multipolygon&quot;,</span>
<span class="gi">+]</span>
<span class="gi">+SUPPORTED_ENCODINGS = [&quot;WKB&quot;] + GEOARROW_ENCODINGS</span>
<span class="gi">+</span>
<span class="gi">+# reference: https://github.com/opengeospatial/geoparquet</span>
<span class="gi">+</span>
<span class="gi">+# Metadata structure:</span>
<span class="gi">+# {</span>
<span class="gi">+#     &quot;geo&quot;: {</span>
<span class="gi">+#         &quot;columns&quot;: {</span>
<span class="gi">+#             &quot;&lt;name&gt;&quot;: {</span>
<span class="gi">+#                 &quot;encoding&quot;: &quot;WKB&quot;</span>
<span class="gi">+#                 &quot;geometry_types&quot;: &lt;list of str: REQUIRED&gt;</span>
<span class="gi">+#                 &quot;crs&quot;: &quot;&lt;PROJJSON or None: OPTIONAL&gt;&quot;,</span>
<span class="gi">+#                 &quot;orientation&quot;: &quot;&lt;&#39;counterclockwise&#39; or None: OPTIONAL&gt;&quot;</span>
<span class="gi">+#                 &quot;edges&quot;: &quot;planar&quot;</span>
<span class="gi">+#                 &quot;bbox&quot;: &lt;list of [xmin, ymin, xmax, ymax]: OPTIONAL&gt;</span>
<span class="gi">+#                 &quot;epoch&quot;: &lt;float: OPTIONAL&gt;</span>
<span class="gi">+#             }</span>
<span class="gi">+#         },</span>
<span class="gi">+#         &quot;primary_column&quot;: &quot;&lt;str: REQUIRED&gt;&quot;,</span>
<span class="gi">+#         &quot;version&quot;: &quot;&lt;METADATA_VERSION&gt;&quot;,</span>
<span class="gi">+#</span>
<span class="gi">+#         # Additional GeoPandas specific metadata (not in metadata spec)</span>
<span class="gi">+#         &quot;creator&quot;: {</span>
<span class="gi">+#             &quot;library&quot;: &quot;geopandas&quot;,</span>
<span class="gi">+#             &quot;version&quot;: &quot;&lt;geopandas.__version__&gt;&quot;</span>
<span class="gi">+#         }</span>
<span class="gi">+#     }</span>
<span class="gi">+# }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _is_fsspec_url(url):</span>
<span class="gi">+    return (</span>
<span class="gi">+        isinstance(url, str)</span>
<span class="gi">+        and &quot;://&quot; in url</span>
<span class="gi">+        and not url.startswith((&quot;http://&quot;, &quot;https://&quot;))</span>
<span class="gi">+    )</span>


<span class="w"> </span>def _remove_id_from_member_of_ensembles(json_dict):
<span class="gu">@@ -26,24 +72,48 @@ def _remove_id_from_member_of_ensembles(json_dict):</span>

<span class="w"> </span>    Mimicking the patch to GDAL from https://github.com/OSGeo/gdal/pull/5872
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-_geometry_type_names = [&#39;Point&#39;, &#39;LineString&#39;, &#39;LineString&#39;, &#39;Polygon&#39;,</span>
<span class="gd">-    &#39;MultiPoint&#39;, &#39;MultiLineString&#39;, &#39;MultiPolygon&#39;, &#39;GeometryCollection&#39;]</span>
<span class="gd">-_geometry_type_names += [(geom_type + &#39; Z&#39;) for geom_type in</span>
<span class="gd">-    _geometry_type_names]</span>
<span class="gi">+    for key, value in json_dict.items():</span>
<span class="gi">+        if isinstance(value, dict):</span>
<span class="gi">+            _remove_id_from_member_of_ensembles(value)</span>
<span class="gi">+        elif key == &quot;members&quot; and isinstance(value, list):</span>
<span class="gi">+            for member in value:</span>
<span class="gi">+                member.pop(&quot;id&quot;, None)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# type ids 0 to 7</span>
<span class="gi">+_geometry_type_names = [</span>
<span class="gi">+    &quot;Point&quot;,</span>
<span class="gi">+    &quot;LineString&quot;,</span>
<span class="gi">+    &quot;LineString&quot;,</span>
<span class="gi">+    &quot;Polygon&quot;,</span>
<span class="gi">+    &quot;MultiPoint&quot;,</span>
<span class="gi">+    &quot;MultiLineString&quot;,</span>
<span class="gi">+    &quot;MultiPolygon&quot;,</span>
<span class="gi">+    &quot;GeometryCollection&quot;,</span>
<span class="gi">+]</span>
<span class="gi">+_geometry_type_names += [geom_type + &quot; Z&quot; for geom_type in _geometry_type_names]</span>


<span class="w"> </span>def _get_geometry_types(series):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Get unique geometry types from a GeoSeries.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    arr_geometry_types = shapely.get_type_id(series.array._data)</span>
<span class="gi">+    # ensure to include &quot;... Z&quot; for 3D geometries</span>
<span class="gi">+    has_z = shapely.has_z(series.array._data)</span>
<span class="gi">+    arr_geometry_types[has_z] += 8</span>
<span class="gi">+</span>
<span class="gi">+    geometry_types = Series(arr_geometry_types).unique().tolist()</span>
<span class="gi">+    # drop missing values (shapely.get_type_id returns -1 for those)</span>
<span class="gi">+    if -1 in geometry_types:</span>
<span class="gi">+        geometry_types.remove(-1)</span>

<span class="gi">+    return sorted([_geometry_type_names[idx] for idx in geometry_types])</span>

<span class="gd">-def _create_metadata(df, schema_version=None, geometry_encoding=None,</span>
<span class="gd">-    write_covering_bbox=False):</span>
<span class="gi">+</span>
<span class="gi">+def _create_metadata(</span>
<span class="gi">+    df, schema_version=None, geometry_encoding=None, write_covering_bbox=False</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;Create and encode geo metadata dict.

<span class="w"> </span>    Parameters
<span class="gu">@@ -61,7 +131,67 @@ def _create_metadata(df, schema_version=None, geometry_encoding=None,</span>
<span class="w"> </span>    -------
<span class="w"> </span>    dict
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if schema_version is None:</span>
<span class="gi">+        if geometry_encoding and any(</span>
<span class="gi">+            encoding != &quot;WKB&quot; for encoding in geometry_encoding.values()</span>
<span class="gi">+        ):</span>
<span class="gi">+            schema_version = &quot;1.1.0&quot;</span>
<span class="gi">+        else:</span>
<span class="gi">+            schema_version = METADATA_VERSION</span>
<span class="gi">+</span>
<span class="gi">+    if schema_version not in SUPPORTED_VERSIONS:</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            f&quot;schema_version must be one of: {&#39;, &#39;.join(SUPPORTED_VERSIONS)}&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    # Construct metadata for each geometry</span>
<span class="gi">+    column_metadata = {}</span>
<span class="gi">+    for col in df.columns[df.dtypes == &quot;geometry&quot;]:</span>
<span class="gi">+        series = df[col]</span>
<span class="gi">+</span>
<span class="gi">+        geometry_types = _get_geometry_types(series)</span>
<span class="gi">+        if schema_version[0] == &quot;0&quot;:</span>
<span class="gi">+            geometry_types_name = &quot;geometry_type&quot;</span>
<span class="gi">+            if len(geometry_types) == 1:</span>
<span class="gi">+                geometry_types = geometry_types[0]</span>
<span class="gi">+        else:</span>
<span class="gi">+            geometry_types_name = &quot;geometry_types&quot;</span>
<span class="gi">+</span>
<span class="gi">+        crs = None</span>
<span class="gi">+        if series.crs:</span>
<span class="gi">+            if schema_version == &quot;0.1.0&quot;:</span>
<span class="gi">+                crs = series.crs.to_wkt()</span>
<span class="gi">+            else:  # version &gt;= 0.4.0</span>
<span class="gi">+                crs = series.crs.to_json_dict()</span>
<span class="gi">+                _remove_id_from_member_of_ensembles(crs)</span>
<span class="gi">+</span>
<span class="gi">+        column_metadata[col] = {</span>
<span class="gi">+            &quot;encoding&quot;: geometry_encoding[col],</span>
<span class="gi">+            &quot;crs&quot;: crs,</span>
<span class="gi">+            geometry_types_name: geometry_types,</span>
<span class="gi">+        }</span>
<span class="gi">+</span>
<span class="gi">+        bbox = series.total_bounds.tolist()</span>
<span class="gi">+        if np.isfinite(bbox).all():</span>
<span class="gi">+            # don&#39;t add bbox with NaNs for empty / all-NA geometry column</span>
<span class="gi">+            column_metadata[col][&quot;bbox&quot;] = bbox</span>
<span class="gi">+</span>
<span class="gi">+        if write_covering_bbox:</span>
<span class="gi">+            column_metadata[col][&quot;covering&quot;] = {</span>
<span class="gi">+                &quot;bbox&quot;: {</span>
<span class="gi">+                    &quot;xmin&quot;: [&quot;bbox&quot;, &quot;xmin&quot;],</span>
<span class="gi">+                    &quot;ymin&quot;: [&quot;bbox&quot;, &quot;ymin&quot;],</span>
<span class="gi">+                    &quot;xmax&quot;: [&quot;bbox&quot;, &quot;xmax&quot;],</span>
<span class="gi">+                    &quot;ymax&quot;: [&quot;bbox&quot;, &quot;ymax&quot;],</span>
<span class="gi">+                },</span>
<span class="gi">+            }</span>
<span class="gi">+</span>
<span class="gi">+    return {</span>
<span class="gi">+        &quot;primary_column&quot;: df._geometry_column_name,</span>
<span class="gi">+        &quot;columns&quot;: column_metadata,</span>
<span class="gi">+        &quot;version&quot;: schema_version,</span>
<span class="gi">+        &quot;creator&quot;: {&quot;library&quot;: &quot;geopandas&quot;, &quot;version&quot;: geopandas.__version__},</span>
<span class="gi">+    }</span>


<span class="w"> </span>def _encode_metadata(metadata):
<span class="gu">@@ -75,7 +205,7 @@ def _encode_metadata(metadata):</span>
<span class="w"> </span>    -------
<span class="w"> </span>    UTF-8 encoded JSON string
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return json.dumps(metadata).encode(&quot;utf-8&quot;)</span>


<span class="w"> </span>def _decode_metadata(metadata_str):
<span class="gu">@@ -89,7 +219,10 @@ def _decode_metadata(metadata_str):</span>
<span class="w"> </span>    -------
<span class="w"> </span>    dict
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if metadata_str is None:</span>
<span class="gi">+        return None</span>
<span class="gi">+</span>
<span class="gi">+    return json.loads(metadata_str.decode(&quot;utf-8&quot;))</span>


<span class="w"> </span>def _validate_dataframe(df):
<span class="gu">@@ -104,7 +237,20 @@ def _validate_dataframe(df):</span>
<span class="w"> </span>    ----------
<span class="w"> </span>    df : GeoDataFrame
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    if not isinstance(df, DataFrame):</span>
<span class="gi">+        raise ValueError(&quot;Writing to Parquet/Feather only supports IO with DataFrames&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # must have value column names (strings only)</span>
<span class="gi">+    if df.columns.inferred_type not in {&quot;string&quot;, &quot;unicode&quot;, &quot;empty&quot;}:</span>
<span class="gi">+        raise ValueError(&quot;Writing to Parquet/Feather requires string column names&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # index level names must be strings</span>
<span class="gi">+    valid_names = all(</span>
<span class="gi">+        isinstance(name, str) for name in df.index.names if name is not None</span>
<span class="gi">+    )</span>
<span class="gi">+    if not valid_names:</span>
<span class="gi">+        raise ValueError(&quot;Index level names must be strings&quot;)</span>


<span class="w"> </span>def _validate_geo_metadata(metadata):
<span class="gu">@@ -117,20 +263,129 @@ def _validate_geo_metadata(metadata):</span>
<span class="w"> </span>    ----------
<span class="w"> </span>    metadata : dict
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>

<span class="gd">-</span>
<span class="gd">-def _geopandas_to_arrow(df, index=None, geometry_encoding=&#39;WKB&#39;,</span>
<span class="gd">-    schema_version=None, write_covering_bbox=None):</span>
<span class="gi">+    if not metadata:</span>
<span class="gi">+        raise ValueError(&quot;Missing or malformed geo metadata in Parquet/Feather file&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # version was schema_version in 0.1.0</span>
<span class="gi">+    version = metadata.get(&quot;version&quot;, metadata.get(&quot;schema_version&quot;))</span>
<span class="gi">+    if not version:</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &quot;&#39;geo&#39; metadata in Parquet/Feather file is missing required key: &quot;</span>
<span class="gi">+            &quot;&#39;version&#39;&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    required_keys = (&quot;primary_column&quot;, &quot;columns&quot;)</span>
<span class="gi">+    for key in required_keys:</span>
<span class="gi">+        if metadata.get(key, None) is None:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;&#39;geo&#39; metadata in Parquet/Feather file is missing required key: &quot;</span>
<span class="gi">+                &quot;&#39;{key}&#39;&quot;.format(key=key)</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    if not isinstance(metadata[&quot;columns&quot;], dict):</span>
<span class="gi">+        raise ValueError(&quot;&#39;columns&#39; in &#39;geo&#39; metadata must be a dict&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # Validate that geometry columns have required metadata and values</span>
<span class="gi">+    # leaving out &quot;geometry_type&quot; for compatibility with 0.1</span>
<span class="gi">+    required_col_keys = (&quot;encoding&quot;,)</span>
<span class="gi">+    for col, column_metadata in metadata[&quot;columns&quot;].items():</span>
<span class="gi">+        for key in required_col_keys:</span>
<span class="gi">+            if key not in column_metadata:</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    &quot;&#39;geo&#39; metadata in Parquet/Feather file is missing required key &quot;</span>
<span class="gi">+                    &quot;&#39;{key}&#39; for column &#39;{col}&#39;&quot;.format(key=key, col=col)</span>
<span class="gi">+                )</span>
<span class="gi">+</span>
<span class="gi">+        if column_metadata[&quot;encoding&quot;] not in SUPPORTED_ENCODINGS:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;Only WKB geometry encoding or one of the native encodings &quot;</span>
<span class="gi">+                f&quot;({GEOARROW_ENCODINGS!r}) are supported, &quot;</span>
<span class="gi">+                f&quot;got: {column_metadata[&#39;encoding&#39;]}&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        if column_metadata.get(&quot;edges&quot;, &quot;planar&quot;) == &quot;spherical&quot;:</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                f&quot;The geo metadata indicate that column &#39;{col}&#39; has spherical edges, &quot;</span>
<span class="gi">+                &quot;but because GeoPandas currently does not support spherical &quot;</span>
<span class="gi">+                &quot;geometry, it ignores this metadata and will interpret the edges of &quot;</span>
<span class="gi">+                &quot;the geometries as planar.&quot;,</span>
<span class="gi">+                UserWarning,</span>
<span class="gi">+                stacklevel=4,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        if &quot;covering&quot; in column_metadata:</span>
<span class="gi">+            covering = column_metadata[&quot;covering&quot;]</span>
<span class="gi">+            if &quot;bbox&quot; in covering:</span>
<span class="gi">+                bbox = covering[&quot;bbox&quot;]</span>
<span class="gi">+                for var in [&quot;xmin&quot;, &quot;ymin&quot;, &quot;xmax&quot;, &quot;ymax&quot;]:</span>
<span class="gi">+                    if var not in bbox.keys():</span>
<span class="gi">+                        raise ValueError(&quot;Metadata for bbox column is malformed.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _geopandas_to_arrow(</span>
<span class="gi">+    df,</span>
<span class="gi">+    index=None,</span>
<span class="gi">+    geometry_encoding=&quot;WKB&quot;,</span>
<span class="gi">+    schema_version=None,</span>
<span class="gi">+    write_covering_bbox=None,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Helper function with main, shared logic for to_parquet/to_feather.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def _to_parquet(df, path, index=None, compression=&#39;snappy&#39;,</span>
<span class="gd">-    geometry_encoding=&#39;WKB&#39;, schema_version=None, write_covering_bbox=False,</span>
<span class="gd">-    **kwargs):</span>
<span class="gi">+    from pyarrow import StructArray</span>
<span class="gi">+</span>
<span class="gi">+    from geopandas.io._geoarrow import geopandas_to_arrow</span>
<span class="gi">+</span>
<span class="gi">+    _validate_dataframe(df)</span>
<span class="gi">+</span>
<span class="gi">+    if schema_version is not None:</span>
<span class="gi">+        if geometry_encoding != &quot;WKB&quot; and schema_version != &quot;1.1.0&quot;:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;&#39;geoarrow&#39; encoding is only supported with schema version &gt;= 1.1.0&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    table, geometry_encoding_dict = geopandas_to_arrow(</span>
<span class="gi">+        df, geometry_encoding=geometry_encoding, index=index, interleaved=False</span>
<span class="gi">+    )</span>
<span class="gi">+    geo_metadata = _create_metadata(</span>
<span class="gi">+        df,</span>
<span class="gi">+        schema_version=schema_version,</span>
<span class="gi">+        geometry_encoding=geometry_encoding_dict,</span>
<span class="gi">+        write_covering_bbox=write_covering_bbox,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    if write_covering_bbox:</span>
<span class="gi">+        if &quot;bbox&quot; in df.columns:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;An existing column &#39;bbox&#39; already exists in the dataframe. &quot;</span>
<span class="gi">+                &quot;Please rename to write covering bbox.&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        bounds = df.bounds</span>
<span class="gi">+        bbox_array = StructArray.from_arrays(</span>
<span class="gi">+            [bounds[&quot;minx&quot;], bounds[&quot;miny&quot;], bounds[&quot;maxx&quot;], bounds[&quot;maxy&quot;]],</span>
<span class="gi">+            names=[&quot;xmin&quot;, &quot;ymin&quot;, &quot;xmax&quot;, &quot;ymax&quot;],</span>
<span class="gi">+        )</span>
<span class="gi">+        table = table.append_column(&quot;bbox&quot;, bbox_array)</span>
<span class="gi">+</span>
<span class="gi">+    # Store geopandas specific file-level metadata</span>
<span class="gi">+    # This must be done AFTER creating the table or it is not persisted</span>
<span class="gi">+    metadata = table.schema.metadata</span>
<span class="gi">+    metadata.update({b&quot;geo&quot;: _encode_metadata(geo_metadata)})</span>
<span class="gi">+</span>
<span class="gi">+    return table.replace_schema_metadata(metadata)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _to_parquet(</span>
<span class="gi">+    df,</span>
<span class="gi">+    path,</span>
<span class="gi">+    index=None,</span>
<span class="gi">+    compression=&quot;snappy&quot;,</span>
<span class="gi">+    geometry_encoding=&quot;WKB&quot;,</span>
<span class="gi">+    schema_version=None,</span>
<span class="gi">+    write_covering_bbox=False,</span>
<span class="gi">+    **kwargs,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Write a GeoDataFrame to the Parquet format.

<span class="gu">@@ -169,11 +424,22 @@ def _to_parquet(df, path, index=None, compression=&#39;snappy&#39;,</span>
<span class="w"> </span>    **kwargs
<span class="w"> </span>        Additional keyword arguments passed to pyarrow.parquet.write_table().
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def _to_feather(df, path, index=None, compression=None, schema_version=None,</span>
<span class="gd">-    **kwargs):</span>
<span class="gi">+    parquet = import_optional_dependency(</span>
<span class="gi">+        &quot;pyarrow.parquet&quot;, extra=&quot;pyarrow is required for Parquet support.&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    path = _expand_user(path)</span>
<span class="gi">+    table = _geopandas_to_arrow(</span>
<span class="gi">+        df,</span>
<span class="gi">+        index=index,</span>
<span class="gi">+        geometry_encoding=geometry_encoding,</span>
<span class="gi">+        schema_version=schema_version,</span>
<span class="gi">+        write_covering_bbox=write_covering_bbox,</span>
<span class="gi">+    )</span>
<span class="gi">+    parquet.write_table(table, path, compression=compression, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _to_feather(df, path, index=None, compression=None, schema_version=None, **kwargs):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Write a GeoDataFrame to the Feather format.

<span class="gu">@@ -205,14 +471,88 @@ def _to_feather(df, path, index=None, compression=None, schema_version=None,</span>
<span class="w"> </span>    kwargs
<span class="w"> </span>        Additional keyword arguments passed to pyarrow.feather.write_feather().
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    feather = import_optional_dependency(</span>
<span class="gi">+        &quot;pyarrow.feather&quot;, extra=&quot;pyarrow is required for Feather support.&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    # TODO move this into `import_optional_dependency`</span>
<span class="gi">+    import pyarrow</span>
<span class="gi">+</span>
<span class="gi">+    if Version(pyarrow.__version__) &lt; Version(&quot;0.17.0&quot;):</span>
<span class="gi">+        raise ImportError(&quot;pyarrow &gt;= 0.17 required for Feather support&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    path = _expand_user(path)</span>
<span class="gi">+    table = _geopandas_to_arrow(df, index=index, schema_version=schema_version)</span>
<span class="gi">+    feather.write_feather(table, path, compression=compression, **kwargs)</span>


<span class="w"> </span>def _arrow_to_geopandas(table, geo_metadata=None):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Helper function with main, shared logic for read_parquet/read_feather.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if geo_metadata is None:</span>
<span class="gi">+        # Note: this path of not passing metadata is also used by dask-geopandas</span>
<span class="gi">+        geo_metadata = _validate_and_decode_metadata(table.schema.metadata)</span>
<span class="gi">+</span>
<span class="gi">+    # Find all geometry columns that were read from the file.  May</span>
<span class="gi">+    # be a subset if &#39;columns&#39; parameter is used.</span>
<span class="gi">+    geometry_columns = [</span>
<span class="gi">+        col for col in geo_metadata[&quot;columns&quot;] if col in table.column_names</span>
<span class="gi">+    ]</span>
<span class="gi">+    result_column_names = list(table.slice(0, 0).to_pandas().columns)</span>
<span class="gi">+    geometry_columns.sort(key=result_column_names.index)</span>
<span class="gi">+</span>
<span class="gi">+    if not len(geometry_columns):</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &quot;&quot;&quot;No geometry columns are included in the columns read from</span>
<span class="gi">+            the Parquet/Feather file.  To read this file without geometry columns,</span>
<span class="gi">+            use pandas.read_parquet/read_feather() instead.&quot;&quot;&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    geometry = geo_metadata[&quot;primary_column&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    # Missing geometry likely indicates a subset of columns was read;</span>
<span class="gi">+    # promote the first available geometry to the primary geometry.</span>
<span class="gi">+    if len(geometry_columns) and geometry not in geometry_columns:</span>
<span class="gi">+        geometry = geometry_columns[0]</span>
<span class="gi">+</span>
<span class="gi">+        # if there are multiple non-primary geometry columns, raise a warning</span>
<span class="gi">+        if len(geometry_columns) &gt; 1:</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                &quot;Multiple non-primary geometry columns read from Parquet/Feather &quot;</span>
<span class="gi">+                &quot;file. The first column read was promoted to the primary geometry.&quot;,</span>
<span class="gi">+                stacklevel=3,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    table_attr = table.drop(geometry_columns)</span>
<span class="gi">+    df = table_attr.to_pandas()</span>
<span class="gi">+</span>
<span class="gi">+    # Convert the WKB columns that are present back to geometry.</span>
<span class="gi">+    for col in geometry_columns:</span>
<span class="gi">+        col_metadata = geo_metadata[&quot;columns&quot;][col]</span>
<span class="gi">+        if &quot;crs&quot; in col_metadata:</span>
<span class="gi">+            crs = col_metadata[&quot;crs&quot;]</span>
<span class="gi">+            if isinstance(crs, dict):</span>
<span class="gi">+                _remove_id_from_member_of_ensembles(crs)</span>
<span class="gi">+        else:</span>
<span class="gi">+            # per the GeoParquet spec, missing CRS is to be interpreted as</span>
<span class="gi">+            # OGC:CRS84</span>
<span class="gi">+            crs = &quot;OGC:CRS84&quot;</span>
<span class="gi">+</span>
<span class="gi">+        if col_metadata[&quot;encoding&quot;] == &quot;WKB&quot;:</span>
<span class="gi">+            geom_arr = from_wkb(np.array(table[col]), crs=crs)</span>
<span class="gi">+        else:</span>
<span class="gi">+            from geopandas.io._geoarrow import construct_shapely_array</span>
<span class="gi">+</span>
<span class="gi">+            geom_arr = from_shapely(</span>
<span class="gi">+                construct_shapely_array(</span>
<span class="gi">+                    table[col].combine_chunks(), &quot;geoarrow.&quot; + col_metadata[&quot;encoding&quot;]</span>
<span class="gi">+                ),</span>
<span class="gi">+                crs=crs,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        df.insert(result_column_names.index(col), col, geom_arr)</span>
<span class="gi">+</span>
<span class="gi">+    return GeoDataFrame(df, geometry=geometry)</span>


<span class="w"> </span>def _get_filesystem_path(path, filesystem=None, storage_options=None):
<span class="gu">@@ -221,7 +561,36 @@ def _get_filesystem_path(path, filesystem=None, storage_options=None):</span>

<span class="w"> </span>    If the filesystem is not None then it&#39;s just returned as is.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import pyarrow</span>
<span class="gi">+</span>
<span class="gi">+    if (</span>
<span class="gi">+        isinstance(path, str)</span>
<span class="gi">+        and storage_options is None</span>
<span class="gi">+        and filesystem is None</span>
<span class="gi">+        and Version(pyarrow.__version__) &gt;= Version(&quot;5.0.0&quot;)</span>
<span class="gi">+    ):</span>
<span class="gi">+        # Use the native pyarrow filesystem if possible.</span>
<span class="gi">+        try:</span>
<span class="gi">+            from pyarrow.fs import FileSystem</span>
<span class="gi">+</span>
<span class="gi">+            filesystem, path = FileSystem.from_uri(path)</span>
<span class="gi">+        except Exception:</span>
<span class="gi">+            # fallback to use get_handle / fsspec for filesystems</span>
<span class="gi">+            # that pyarrow doesn&#39;t support</span>
<span class="gi">+            pass</span>
<span class="gi">+</span>
<span class="gi">+    if _is_fsspec_url(path) and filesystem is None:</span>
<span class="gi">+        fsspec = import_optional_dependency(</span>
<span class="gi">+            &quot;fsspec&quot;, extra=&quot;fsspec is requred for &#39;storage_options&#39;.&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+        filesystem, path = fsspec.core.url_to_fs(path, **(storage_options or {}))</span>
<span class="gi">+</span>
<span class="gi">+    if filesystem is None and storage_options:</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &quot;Cannot provide &#39;storage_options&#39; with non-fsspec path &#39;{}&#39;&quot;.format(path)</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    return filesystem, path</span>


<span class="w"> </span>def _ensure_arrow_fs(filesystem):
<span class="gu">@@ -230,7 +599,38 @@ def _ensure_arrow_fs(filesystem):</span>
<span class="w"> </span>    below because `pyarrow.parquet.read_metadata` does not yet accept a
<span class="w"> </span>    filesystem keyword (https://issues.apache.org/jira/browse/ARROW-16719)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from pyarrow import fs</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(filesystem, fs.FileSystem):</span>
<span class="gi">+        return filesystem</span>
<span class="gi">+</span>
<span class="gi">+    # handle fsspec-compatible filesystems</span>
<span class="gi">+    try:</span>
<span class="gi">+        import fsspec</span>
<span class="gi">+    except ImportError:</span>
<span class="gi">+        pass</span>
<span class="gi">+    else:</span>
<span class="gi">+        if isinstance(filesystem, fsspec.AbstractFileSystem):</span>
<span class="gi">+            return fs.PyFileSystem(fs.FSSpecHandler(filesystem))</span>
<span class="gi">+</span>
<span class="gi">+    return filesystem</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _validate_and_decode_metadata(metadata):</span>
<span class="gi">+    if metadata is None or b&quot;geo&quot; not in metadata:</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &quot;&quot;&quot;Missing geo metadata in Parquet/Feather file.</span>
<span class="gi">+            Use pandas.read_parquet/read_feather() instead.&quot;&quot;&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    # check for malformed metadata</span>
<span class="gi">+    try:</span>
<span class="gi">+        decoded_geo_metadata = _decode_metadata(metadata.get(b&quot;geo&quot;, b&quot;&quot;))</span>
<span class="gi">+    except (TypeError, json.decoder.JSONDecodeError):</span>
<span class="gi">+        raise ValueError(&quot;Missing or malformed geo metadata in Parquet/Feather file&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    _validate_geo_metadata(decoded_geo_metadata)</span>
<span class="gi">+    return decoded_geo_metadata</span>


<span class="w"> </span>def _read_parquet_schema_and_metadata(path, filesystem):
<span class="gu">@@ -242,11 +642,33 @@ def _read_parquet_schema_and_metadata(path, filesystem):</span>
<span class="w"> </span>    that the ParquetDataset interface doesn&#39;t allow passing the filters on read)

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import pyarrow</span>
<span class="gi">+    from pyarrow import parquet</span>

<span class="gi">+    kwargs = {}</span>
<span class="gi">+    if Version(pyarrow.__version__) &lt; Version(&quot;15.0.0&quot;):</span>
<span class="gi">+        kwargs = dict(use_legacy_dataset=False)</span>

<span class="gd">-def _read_parquet(path, columns=None, storage_options=None, bbox=None, **kwargs</span>
<span class="gd">-    ):</span>
<span class="gi">+    try:</span>
<span class="gi">+        schema = parquet.ParquetDataset(path, filesystem=filesystem, **kwargs).schema</span>
<span class="gi">+    except Exception:</span>
<span class="gi">+        schema = parquet.read_schema(path, filesystem=filesystem)</span>
<span class="gi">+</span>
<span class="gi">+    metadata = schema.metadata</span>
<span class="gi">+</span>
<span class="gi">+    # read metadata separately to get the raw Parquet FileMetaData metadata</span>
<span class="gi">+    # (pyarrow doesn&#39;t properly exposes those in schema.metadata for files</span>
<span class="gi">+    # created by GDAL - https://issues.apache.org/jira/browse/ARROW-16688)</span>
<span class="gi">+    if metadata is None or b&quot;geo&quot; not in metadata:</span>
<span class="gi">+        try:</span>
<span class="gi">+            metadata = parquet.read_metadata(path, filesystem=filesystem).metadata</span>
<span class="gi">+        except Exception:</span>
<span class="gi">+            pass</span>
<span class="gi">+</span>
<span class="gi">+    return schema, metadata</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _read_parquet(path, columns=None, storage_options=None, bbox=None, **kwargs):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Load a Parquet object from the file path, returning a GeoDataFrame.

<span class="gu">@@ -313,7 +735,48 @@ def _read_parquet(path, columns=None, storage_options=None, bbox=None, **kwargs</span>
<span class="w"> </span>    ...     columns=[&quot;geometry&quot;, &quot;pop_est&quot;]
<span class="w"> </span>    ... )  # doctest: +SKIP
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    parquet = import_optional_dependency(</span>
<span class="gi">+        &quot;pyarrow.parquet&quot;, extra=&quot;pyarrow is required for Parquet support.&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    import geopandas.io._pyarrow_hotfix  # noqa: F401</span>
<span class="gi">+</span>
<span class="gi">+    # TODO(https://github.com/pandas-dev/pandas/pull/41194): see if pandas</span>
<span class="gi">+    # adds filesystem as a keyword and match that.</span>
<span class="gi">+    filesystem = kwargs.pop(&quot;filesystem&quot;, None)</span>
<span class="gi">+    filesystem, path = _get_filesystem_path(</span>
<span class="gi">+        path, filesystem=filesystem, storage_options=storage_options</span>
<span class="gi">+    )</span>
<span class="gi">+    path = _expand_user(path)</span>
<span class="gi">+    schema, metadata = _read_parquet_schema_and_metadata(path, filesystem)</span>
<span class="gi">+</span>
<span class="gi">+    geo_metadata = _validate_and_decode_metadata(metadata)</span>
<span class="gi">+</span>
<span class="gi">+    bbox_filter = (</span>
<span class="gi">+        _get_parquet_bbox_filter(geo_metadata, bbox) if bbox is not None else None</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    if_bbox_column_exists = _check_if_covering_in_geo_metadata(geo_metadata)</span>
<span class="gi">+</span>
<span class="gi">+    # by default, bbox column is not read in, so must specify which</span>
<span class="gi">+    # columns are read in if it exists.</span>
<span class="gi">+    if not columns and if_bbox_column_exists:</span>
<span class="gi">+        columns = _get_non_bbox_columns(schema, geo_metadata)</span>
<span class="gi">+</span>
<span class="gi">+    # if both bbox and filters kwargs are used, must splice together.</span>
<span class="gi">+    if &quot;filters&quot; in kwargs:</span>
<span class="gi">+        filters_kwarg = kwargs.pop(&quot;filters&quot;)</span>
<span class="gi">+        filters = _splice_bbox_and_filters(filters_kwarg, bbox_filter)</span>
<span class="gi">+    else:</span>
<span class="gi">+        filters = bbox_filter</span>
<span class="gi">+</span>
<span class="gi">+    kwargs[&quot;use_pandas_metadata&quot;] = True</span>
<span class="gi">+</span>
<span class="gi">+    table = parquet.read_table(</span>
<span class="gi">+        path, columns=columns, filesystem=filesystem, filters=filters, **kwargs</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    return _arrow_to_geopandas(table, geo_metadata)</span>


<span class="w"> </span>def _read_feather(path, columns=None, **kwargs):
<span class="gu">@@ -367,4 +830,84 @@ def _read_feather(path, columns=None, **kwargs):</span>
<span class="w"> </span>    ...     columns=[&quot;geometry&quot;, &quot;pop_est&quot;]
<span class="w"> </span>    ... )  # doctest: +SKIP
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    feather = import_optional_dependency(</span>
<span class="gi">+        &quot;pyarrow.feather&quot;, extra=&quot;pyarrow is required for Feather support.&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    # TODO move this into `import_optional_dependency`</span>
<span class="gi">+    import pyarrow</span>
<span class="gi">+</span>
<span class="gi">+    import geopandas.io._pyarrow_hotfix  # noqa: F401</span>
<span class="gi">+</span>
<span class="gi">+    if Version(pyarrow.__version__) &lt; Version(&quot;0.17.0&quot;):</span>
<span class="gi">+        raise ImportError(&quot;pyarrow &gt;= 0.17 required for Feather support&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    path = _expand_user(path)</span>
<span class="gi">+</span>
<span class="gi">+    table = feather.read_table(path, columns=columns, **kwargs)</span>
<span class="gi">+    return _arrow_to_geopandas(table)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _get_parquet_bbox_filter(geo_metadata, bbox):</span>
<span class="gi">+    primary_column = geo_metadata[&quot;primary_column&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    if _check_if_covering_in_geo_metadata(geo_metadata):</span>
<span class="gi">+        bbox_column_name = _get_bbox_encoding_column_name(geo_metadata)</span>
<span class="gi">+        return _convert_bbox_to_parquet_filter(bbox, bbox_column_name)</span>
<span class="gi">+</span>
<span class="gi">+    elif geo_metadata[&quot;columns&quot;][primary_column][&quot;encoding&quot;] == &quot;point&quot;:</span>
<span class="gi">+        import pyarrow.compute as pc</span>
<span class="gi">+</span>
<span class="gi">+        return (</span>
<span class="gi">+            (pc.field((primary_column, &quot;x&quot;)) &gt;= bbox[0])</span>
<span class="gi">+            &amp; (pc.field((primary_column, &quot;x&quot;)) &lt;= bbox[2])</span>
<span class="gi">+            &amp; (pc.field((primary_column, &quot;y&quot;)) &gt;= bbox[1])</span>
<span class="gi">+            &amp; (pc.field((primary_column, &quot;y&quot;)) &lt;= bbox[3])</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &quot;Specifying &#39;bbox&#39; not supported for this Parquet file (it should either &quot;</span>
<span class="gi">+            &quot;have a bbox covering column or use &#39;point&#39; encoding).&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _convert_bbox_to_parquet_filter(bbox, bbox_column_name):</span>
<span class="gi">+    import pyarrow.compute as pc</span>
<span class="gi">+</span>
<span class="gi">+    return ~(</span>
<span class="gi">+        (pc.field((bbox_column_name, &quot;xmin&quot;)) &gt; bbox[2])</span>
<span class="gi">+        | (pc.field((bbox_column_name, &quot;ymin&quot;)) &gt; bbox[3])</span>
<span class="gi">+        | (pc.field((bbox_column_name, &quot;xmax&quot;)) &lt; bbox[0])</span>
<span class="gi">+        | (pc.field((bbox_column_name, &quot;ymax&quot;)) &lt; bbox[1])</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _check_if_covering_in_geo_metadata(geo_metadata):</span>
<span class="gi">+    primary_column = geo_metadata[&quot;primary_column&quot;]</span>
<span class="gi">+    return &quot;covering&quot; in geo_metadata[&quot;columns&quot;][primary_column].keys()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _get_bbox_encoding_column_name(geo_metadata):</span>
<span class="gi">+    primary_column = geo_metadata[&quot;primary_column&quot;]</span>
<span class="gi">+    return geo_metadata[&quot;columns&quot;][primary_column][&quot;covering&quot;][&quot;bbox&quot;][&quot;xmin&quot;][0]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _get_non_bbox_columns(schema, geo_metadata):</span>
<span class="gi">+</span>
<span class="gi">+    bbox_column_name = _get_bbox_encoding_column_name(geo_metadata)</span>
<span class="gi">+    columns = schema.names</span>
<span class="gi">+    if bbox_column_name in columns:</span>
<span class="gi">+        columns.remove(bbox_column_name)</span>
<span class="gi">+    return columns</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _splice_bbox_and_filters(kwarg_filters, bbox_filter):</span>
<span class="gi">+    parquet = import_optional_dependency(</span>
<span class="gi">+        &quot;pyarrow.parquet&quot;, extra=&quot;pyarrow is required for Parquet support.&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    if bbox_filter is None:</span>
<span class="gi">+        return kwarg_filters</span>
<span class="gi">+</span>
<span class="gi">+    filters_expression = parquet.filters_to_expression(kwarg_filters)</span>
<span class="gi">+    return bbox_filter &amp; filters_expression</span>
<span class="gh">diff --git a/geopandas/io/file.py b/geopandas/io/file.py</span>
<span class="gh">index 43101f2e..37aa3038 100644</span>
<span class="gd">--- a/geopandas/io/file.py</span>
<span class="gi">+++ b/geopandas/io/file.py</span>
<span class="gu">@@ -1,51 +1,195 @@</span>
<span class="w"> </span>from __future__ import annotations
<span class="gi">+</span>
<span class="w"> </span>import os
<span class="w"> </span>import urllib.request
<span class="w"> </span>import warnings
<span class="w"> </span>from io import IOBase
<span class="w"> </span>from packaging.version import Version
<span class="w"> </span>from pathlib import Path
<span class="gi">+</span>
<span class="gi">+# Adapted from pandas.io.common</span>
<span class="w"> </span>from urllib.parse import urlparse as parse_url
<span class="w"> </span>from urllib.parse import uses_netloc, uses_params, uses_relative
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>import pandas as pd
<span class="w"> </span>from pandas.api.types import is_integer_dtype
<span class="gi">+</span>
<span class="w"> </span>import shapely
<span class="w"> </span>from shapely.geometry import mapping
<span class="w"> </span>from shapely.geometry.base import BaseGeometry
<span class="gi">+</span>
<span class="w"> </span>from geopandas import GeoDataFrame, GeoSeries
<span class="w"> </span>from geopandas._compat import HAS_PYPROJ, PANDAS_GE_20
<span class="w"> </span>from geopandas.io.util import vsi_path
<span class="gi">+</span>
<span class="w"> </span>_VALID_URLS = set(uses_relative + uses_netloc + uses_params)
<span class="gd">-_VALID_URLS.discard(&#39;&#39;)</span>
<span class="gd">-_VALID_URLS.discard(&#39;file&#39;)</span>
<span class="gi">+_VALID_URLS.discard(&quot;&quot;)</span>
<span class="gi">+# file:// URIs are supported by fiona/pyogrio -&gt; don&#39;t already open + read the file here</span>
<span class="gi">+_VALID_URLS.discard(&quot;file&quot;)</span>
<span class="gi">+</span>
<span class="w"> </span>fiona = None
<span class="w"> </span>fiona_env = None
<span class="w"> </span>fiona_import_error = None
<span class="w"> </span>FIONA_GE_19 = False
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _import_fiona():</span>
<span class="gi">+    global fiona</span>
<span class="gi">+    global fiona_env</span>
<span class="gi">+    global fiona_import_error</span>
<span class="gi">+    global FIONA_GE_19</span>
<span class="gi">+</span>
<span class="gi">+    if fiona is None:</span>
<span class="gi">+        try:</span>
<span class="gi">+            import fiona</span>
<span class="gi">+</span>
<span class="gi">+            # only try to import fiona.Env if the main fiona import succeeded</span>
<span class="gi">+            # (otherwise you can get confusing &quot;AttributeError: module &#39;fiona&#39;</span>
<span class="gi">+            # has no attribute &#39;_loading&#39;&quot; / partially initialized module errors)</span>
<span class="gi">+            try:</span>
<span class="gi">+                from fiona import Env as fiona_env</span>
<span class="gi">+            except ImportError:</span>
<span class="gi">+                try:</span>
<span class="gi">+                    from fiona import drivers as fiona_env</span>
<span class="gi">+                except ImportError:</span>
<span class="gi">+                    fiona_env = None</span>
<span class="gi">+</span>
<span class="gi">+            FIONA_GE_19 = Version(Version(fiona.__version__).base_version) &gt;= Version(</span>
<span class="gi">+                &quot;1.9.0&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        except ImportError as err:</span>
<span class="gi">+            fiona = False</span>
<span class="gi">+            fiona_import_error = str(err)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>pyogrio = None
<span class="w"> </span>pyogrio_import_error = None
<span class="gd">-_EXTENSION_TO_DRIVER = {&#39;.bna&#39;: &#39;BNA&#39;, &#39;.dxf&#39;: &#39;DXF&#39;, &#39;.csv&#39;: &#39;CSV&#39;, &#39;.shp&#39;:</span>
<span class="gd">-    &#39;ESRI Shapefile&#39;, &#39;.dbf&#39;: &#39;ESRI Shapefile&#39;, &#39;.json&#39;: &#39;GeoJSON&#39;,</span>
<span class="gd">-    &#39;.geojson&#39;: &#39;GeoJSON&#39;, &#39;.geojsonl&#39;: &#39;GeoJSONSeq&#39;, &#39;.geojsons&#39;:</span>
<span class="gd">-    &#39;GeoJSONSeq&#39;, &#39;.gpkg&#39;: &#39;GPKG&#39;, &#39;.gml&#39;: &#39;GML&#39;, &#39;.xml&#39;: &#39;GML&#39;, &#39;.gpx&#39;:</span>
<span class="gd">-    &#39;GPX&#39;, &#39;.gtm&#39;: &#39;GPSTrackMaker&#39;, &#39;.gtz&#39;: &#39;GPSTrackMaker&#39;, &#39;.tab&#39;:</span>
<span class="gd">-    &#39;MapInfo File&#39;, &#39;.mif&#39;: &#39;MapInfo File&#39;, &#39;.mid&#39;: &#39;MapInfo File&#39;, &#39;.dgn&#39;:</span>
<span class="gd">-    &#39;DGN&#39;, &#39;.fgb&#39;: &#39;FlatGeobuf&#39;}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _import_pyogrio():</span>
<span class="gi">+    global pyogrio</span>
<span class="gi">+    global pyogrio_import_error</span>
<span class="gi">+</span>
<span class="gi">+    if pyogrio is None:</span>
<span class="gi">+        try:</span>
<span class="gi">+            import pyogrio</span>
<span class="gi">+</span>
<span class="gi">+        except ImportError as err:</span>
<span class="gi">+            pyogrio = False</span>
<span class="gi">+            pyogrio_import_error = str(err)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _check_fiona(func):</span>
<span class="gi">+    if not fiona:</span>
<span class="gi">+        raise ImportError(</span>
<span class="gi">+            f&quot;the {func} requires the &#39;fiona&#39; package, but it is not installed or does &quot;</span>
<span class="gi">+            f&quot;not import correctly.\nImporting fiona resulted in: {fiona_import_error}&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _check_pyogrio(func):</span>
<span class="gi">+    if not pyogrio:</span>
<span class="gi">+        raise ImportError(</span>
<span class="gi">+            f&quot;the {func} requires the &#39;pyogrio&#39; package, but it is not installed &quot;</span>
<span class="gi">+            &quot;or does not import correctly.&quot;</span>
<span class="gi">+            &quot;\nImporting pyogrio resulted in: {pyogrio_import_error}&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _check_metadata_supported(metadata: str | None, engine: str, driver: str) -&gt; None:</span>
<span class="gi">+    if metadata is None:</span>
<span class="gi">+        return</span>
<span class="gi">+    if driver != &quot;GPKG&quot;:</span>
<span class="gi">+        raise NotImplementedError(</span>
<span class="gi">+            &quot;The &#39;metadata&#39; keyword is only supported for the GPKG driver.&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    if engine == &quot;fiona&quot; and not FIONA_GE_19:</span>
<span class="gi">+        raise NotImplementedError(</span>
<span class="gi">+            &quot;The &#39;metadata&#39; keyword is only supported for Fiona &gt;= 1.9.&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _check_engine(engine, func):</span>
<span class="gi">+    # if not specified through keyword or option, then default to &quot;pyogrio&quot; if</span>
<span class="gi">+    # installed, otherwise try fiona</span>
<span class="gi">+    if engine is None:</span>
<span class="gi">+        import geopandas</span>
<span class="gi">+</span>
<span class="gi">+        engine = geopandas.options.io_engine</span>
<span class="gi">+</span>
<span class="gi">+    if engine is None:</span>
<span class="gi">+        _import_pyogrio()</span>
<span class="gi">+        if pyogrio:</span>
<span class="gi">+            engine = &quot;pyogrio&quot;</span>
<span class="gi">+        else:</span>
<span class="gi">+            _import_fiona()</span>
<span class="gi">+            if fiona:</span>
<span class="gi">+                engine = &quot;fiona&quot;</span>
<span class="gi">+</span>
<span class="gi">+    if engine == &quot;pyogrio&quot;:</span>
<span class="gi">+        _import_pyogrio()</span>
<span class="gi">+        _check_pyogrio(func)</span>
<span class="gi">+    elif engine == &quot;fiona&quot;:</span>
<span class="gi">+        _import_fiona()</span>
<span class="gi">+        _check_fiona(func)</span>
<span class="gi">+    elif engine is None:</span>
<span class="gi">+        raise ImportError(</span>
<span class="gi">+            f&quot;The {func} requires the &#39;pyogrio&#39; or &#39;fiona&#39; package, &quot;</span>
<span class="gi">+            &quot;but neither is installed or imports correctly.&quot;</span>
<span class="gi">+            f&quot;\nImporting pyogrio resulted in: {pyogrio_import_error}&quot;</span>
<span class="gi">+            f&quot;\nImporting fiona resulted in: {fiona_import_error}&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    return engine</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+_EXTENSION_TO_DRIVER = {</span>
<span class="gi">+    &quot;.bna&quot;: &quot;BNA&quot;,</span>
<span class="gi">+    &quot;.dxf&quot;: &quot;DXF&quot;,</span>
<span class="gi">+    &quot;.csv&quot;: &quot;CSV&quot;,</span>
<span class="gi">+    &quot;.shp&quot;: &quot;ESRI Shapefile&quot;,</span>
<span class="gi">+    &quot;.dbf&quot;: &quot;ESRI Shapefile&quot;,</span>
<span class="gi">+    &quot;.json&quot;: &quot;GeoJSON&quot;,</span>
<span class="gi">+    &quot;.geojson&quot;: &quot;GeoJSON&quot;,</span>
<span class="gi">+    &quot;.geojsonl&quot;: &quot;GeoJSONSeq&quot;,</span>
<span class="gi">+    &quot;.geojsons&quot;: &quot;GeoJSONSeq&quot;,</span>
<span class="gi">+    &quot;.gpkg&quot;: &quot;GPKG&quot;,</span>
<span class="gi">+    &quot;.gml&quot;: &quot;GML&quot;,</span>
<span class="gi">+    &quot;.xml&quot;: &quot;GML&quot;,</span>
<span class="gi">+    &quot;.gpx&quot;: &quot;GPX&quot;,</span>
<span class="gi">+    &quot;.gtm&quot;: &quot;GPSTrackMaker&quot;,</span>
<span class="gi">+    &quot;.gtz&quot;: &quot;GPSTrackMaker&quot;,</span>
<span class="gi">+    &quot;.tab&quot;: &quot;MapInfo File&quot;,</span>
<span class="gi">+    &quot;.mif&quot;: &quot;MapInfo File&quot;,</span>
<span class="gi">+    &quot;.mid&quot;: &quot;MapInfo File&quot;,</span>
<span class="gi">+    &quot;.dgn&quot;: &quot;DGN&quot;,</span>
<span class="gi">+    &quot;.fgb&quot;: &quot;FlatGeobuf&quot;,</span>
<span class="gi">+}</span>


<span class="w"> </span>def _expand_user(path):
<span class="w"> </span>    &quot;&quot;&quot;Expand paths that use ~.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(path, str):</span>
<span class="gi">+        path = os.path.expanduser(path)</span>
<span class="gi">+    elif isinstance(path, Path):</span>
<span class="gi">+        path = path.expanduser()</span>
<span class="gi">+    return path</span>


<span class="w"> </span>def _is_url(url):
<span class="w"> </span>    &quot;&quot;&quot;Check to see if *url* has a valid protocol.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        return parse_url(url).scheme in _VALID_URLS</span>
<span class="gi">+    except Exception:</span>
<span class="gi">+        return False</span>


<span class="gd">-def _read_file(filename, bbox=None, mask=None, columns=None, rows=None,</span>
<span class="gd">-    engine=None, **kwargs):</span>
<span class="gi">+def _read_file(</span>
<span class="gi">+    filename, bbox=None, mask=None, columns=None, rows=None, engine=None, **kwargs</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Returns a GeoDataFrame from a file or URL.

<span class="gu">@@ -131,18 +275,308 @@ def _read_file(filename, bbox=None, mask=None, columns=None, rows=None,</span>
<span class="w"> </span>    (https://gdal.org/user/virtual_file_systems.html#vsicurl-http-https-ftp-files-random-access).

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    engine = _check_engine(engine, &quot;&#39;read_file&#39; function&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    filename = _expand_user(filename)</span>
<span class="gi">+</span>
<span class="gi">+    from_bytes = False</span>
<span class="gi">+    if _is_url(filename):</span>
<span class="gi">+        # if it is a url that supports random access -&gt; pass through to</span>
<span class="gi">+        # pyogrio/fiona as is (to support downloading only part of the file)</span>
<span class="gi">+        # otherwise still download manually because pyogrio/fiona don&#39;t support</span>
<span class="gi">+        # all types of urls (https://github.com/geopandas/geopandas/issues/2908)</span>
<span class="gi">+        with urllib.request.urlopen(filename) as response:</span>
<span class="gi">+            if not response.headers.get(&quot;Accept-Ranges&quot;) == &quot;bytes&quot;:</span>
<span class="gi">+                filename = response.read()</span>
<span class="gi">+                from_bytes = True</span>
<span class="gi">+</span>
<span class="gi">+    if engine == &quot;pyogrio&quot;:</span>
<span class="gi">+        return _read_file_pyogrio(</span>
<span class="gi">+            filename, bbox=bbox, mask=mask, columns=columns, rows=rows, **kwargs</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    elif engine == &quot;fiona&quot;:</span>
<span class="gi">+        if pd.api.types.is_file_like(filename):</span>
<span class="gi">+            data = filename.read()</span>
<span class="gi">+            path_or_bytes = data.encode(&quot;utf-8&quot;) if isinstance(data, str) else data</span>
<span class="gi">+            from_bytes = True</span>
<span class="gi">+        else:</span>
<span class="gi">+            path_or_bytes = filename</span>
<span class="gi">+</span>
<span class="gi">+        return _read_file_fiona(</span>
<span class="gi">+            path_or_bytes,</span>
<span class="gi">+            from_bytes,</span>
<span class="gi">+            bbox=bbox,</span>
<span class="gi">+            mask=mask,</span>
<span class="gi">+            columns=columns,</span>
<span class="gi">+            rows=rows,</span>
<span class="gi">+            **kwargs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(f&quot;unknown engine &#39;{engine}&#39;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _read_file_fiona(</span>
<span class="gi">+    path_or_bytes,</span>
<span class="gi">+    from_bytes,</span>
<span class="gi">+    bbox=None,</span>
<span class="gi">+    mask=None,</span>
<span class="gi">+    columns=None,</span>
<span class="gi">+    rows=None,</span>
<span class="gi">+    where=None,</span>
<span class="gi">+    **kwargs,</span>
<span class="gi">+):</span>
<span class="gi">+    if where is not None and not FIONA_GE_19:</span>
<span class="gi">+        raise NotImplementedError(&quot;where requires fiona 1.9+&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if columns is not None:</span>
<span class="gi">+        if &quot;include_fields&quot; in kwargs:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;Cannot specify both &#39;include_fields&#39; and &#39;columns&#39; keywords&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        if not FIONA_GE_19:</span>
<span class="gi">+            raise NotImplementedError(&quot;&#39;columns&#39; keyword requires fiona 1.9+&quot;)</span>
<span class="gi">+        kwargs[&quot;include_fields&quot;] = columns</span>
<span class="gi">+    elif &quot;include_fields&quot; in kwargs:</span>
<span class="gi">+        # alias to columns, as this variable is used below to specify column order</span>
<span class="gi">+        # in the dataframe creation</span>
<span class="gi">+        columns = kwargs[&quot;include_fields&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    if not from_bytes:</span>
<span class="gi">+        # Opening a file via URL or file-like-object above automatically detects a</span>
<span class="gi">+        # zipped file. In order to match that behavior, attempt to add a zip scheme</span>
<span class="gi">+        # if missing.</span>
<span class="gi">+        path_or_bytes = vsi_path(str(path_or_bytes))</span>
<span class="gi">+</span>
<span class="gi">+    if from_bytes:</span>
<span class="gi">+        reader = fiona.BytesCollection</span>
<span class="gi">+    else:</span>
<span class="gi">+        reader = fiona.open</span>
<span class="gi">+</span>
<span class="gi">+    with fiona_env():</span>
<span class="gi">+        with reader(path_or_bytes, **kwargs) as features:</span>
<span class="gi">+            crs = features.crs_wkt</span>
<span class="gi">+            # attempt to get EPSG code</span>
<span class="gi">+            try:</span>
<span class="gi">+                # fiona 1.9+</span>
<span class="gi">+                epsg = features.crs.to_epsg(confidence_threshold=100)</span>
<span class="gi">+                if epsg is not None:</span>
<span class="gi">+                    crs = epsg</span>
<span class="gi">+            except AttributeError:</span>
<span class="gi">+                # fiona &lt;= 1.8</span>
<span class="gi">+                try:</span>
<span class="gi">+                    crs = features.crs[&quot;init&quot;]</span>
<span class="gi">+                except (TypeError, KeyError):</span>
<span class="gi">+                    pass</span>
<span class="gi">+</span>
<span class="gi">+            # handle loading the bounding box</span>
<span class="gi">+            if bbox is not None:</span>
<span class="gi">+                if isinstance(bbox, (GeoDataFrame, GeoSeries)):</span>
<span class="gi">+                    bbox = tuple(bbox.to_crs(crs).total_bounds)</span>
<span class="gi">+                elif isinstance(bbox, BaseGeometry):</span>
<span class="gi">+                    bbox = bbox.bounds</span>
<span class="gi">+                assert len(bbox) == 4</span>
<span class="gi">+            # handle loading the mask</span>
<span class="gi">+            elif isinstance(mask, (GeoDataFrame, GeoSeries)):</span>
<span class="gi">+                mask = mapping(mask.to_crs(crs).union_all())</span>
<span class="gi">+            elif isinstance(mask, BaseGeometry):</span>
<span class="gi">+                mask = mapping(mask)</span>
<span class="gi">+</span>
<span class="gi">+            filters = {}</span>
<span class="gi">+            if bbox is not None:</span>
<span class="gi">+                filters[&quot;bbox&quot;] = bbox</span>
<span class="gi">+            if mask is not None:</span>
<span class="gi">+                filters[&quot;mask&quot;] = mask</span>
<span class="gi">+            if where is not None:</span>
<span class="gi">+                filters[&quot;where&quot;] = where</span>
<span class="gi">+</span>
<span class="gi">+            # setup the data loading filter</span>
<span class="gi">+            if rows is not None:</span>
<span class="gi">+                if isinstance(rows, int):</span>
<span class="gi">+                    rows = slice(rows)</span>
<span class="gi">+                elif not isinstance(rows, slice):</span>
<span class="gi">+                    raise TypeError(&quot;&#39;rows&#39; must be an integer or a slice.&quot;)</span>
<span class="gi">+                f_filt = features.filter(rows.start, rows.stop, rows.step, **filters)</span>
<span class="gi">+            elif filters:</span>
<span class="gi">+                f_filt = features.filter(**filters)</span>
<span class="gi">+            else:</span>
<span class="gi">+                f_filt = features</span>
<span class="gi">+            # get list of columns</span>
<span class="gi">+            columns = columns or list(features.schema[&quot;properties&quot;])</span>
<span class="gi">+            datetime_fields = [</span>
<span class="gi">+                k for (k, v) in features.schema[&quot;properties&quot;].items() if v == &quot;datetime&quot;</span>
<span class="gi">+            ]</span>
<span class="gi">+            if (</span>
<span class="gi">+                kwargs.get(&quot;ignore_geometry&quot;, False)</span>
<span class="gi">+                or features.schema[&quot;geometry&quot;] == &quot;None&quot;</span>
<span class="gi">+            ):</span>
<span class="gi">+                df = pd.DataFrame(</span>
<span class="gi">+                    [record[&quot;properties&quot;] for record in f_filt], columns=columns</span>
<span class="gi">+                )</span>
<span class="gi">+            else:</span>
<span class="gi">+                df = GeoDataFrame.from_features(</span>
<span class="gi">+                    f_filt, crs=crs, columns=columns + [&quot;geometry&quot;]</span>
<span class="gi">+                )</span>
<span class="gi">+            for k in datetime_fields:</span>
<span class="gi">+                as_dt = None</span>
<span class="gi">+                # plain try catch for when pandas will raise in the future</span>
<span class="gi">+                # TODO we can tighten the exception type in future when it does</span>
<span class="gi">+                try:</span>
<span class="gi">+                    with warnings.catch_warnings():</span>
<span class="gi">+                        # pandas 2.x does not yet enforce this behaviour but raises a</span>
<span class="gi">+                        # warning  -&gt; we want to to suppress this warning for our users,</span>
<span class="gi">+                        # and do this by turning it into an error so we take the</span>
<span class="gi">+                        # `except` code path to try again with utc=True</span>
<span class="gi">+                        warnings.filterwarnings(</span>
<span class="gi">+                            &quot;error&quot;,</span>
<span class="gi">+                            &quot;In a future version of pandas, parsing datetimes with &quot;</span>
<span class="gi">+                            &quot;mixed time zones will raise an error&quot;,</span>
<span class="gi">+                            FutureWarning,</span>
<span class="gi">+                        )</span>
<span class="gi">+                        as_dt = pd.to_datetime(df[k])</span>
<span class="gi">+                except Exception:</span>
<span class="gi">+                    pass</span>
<span class="gi">+                if as_dt is None or as_dt.dtype == &quot;object&quot;:</span>
<span class="gi">+                    # if to_datetime failed, try again for mixed timezone offsets</span>
<span class="gi">+                    # This can still fail if there are invalid datetimes</span>
<span class="gi">+                    try:</span>
<span class="gi">+                        as_dt = pd.to_datetime(df[k], utc=True)</span>
<span class="gi">+                    except Exception:</span>
<span class="gi">+                        pass</span>
<span class="gi">+                # if to_datetime succeeded, round datetimes as</span>
<span class="gi">+                # fiona only supports up to ms precision (any microseconds are</span>
<span class="gi">+                # floating point rounding error)</span>
<span class="gi">+                if as_dt is not None and not (as_dt.dtype == &quot;object&quot;):</span>
<span class="gi">+                    if PANDAS_GE_20:</span>
<span class="gi">+                        df[k] = as_dt.dt.as_unit(&quot;ms&quot;)</span>
<span class="gi">+                    else:</span>
<span class="gi">+                        df[k] = as_dt.dt.round(freq=&quot;ms&quot;)</span>
<span class="gi">+            return df</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _read_file_pyogrio(path_or_bytes, bbox=None, mask=None, rows=None, **kwargs):</span>
<span class="gi">+    import pyogrio</span>
<span class="gi">+</span>
<span class="gi">+    if rows is not None:</span>
<span class="gi">+        if isinstance(rows, int):</span>
<span class="gi">+            kwargs[&quot;max_features&quot;] = rows</span>
<span class="gi">+        elif isinstance(rows, slice):</span>
<span class="gi">+            if rows.start is not None:</span>
<span class="gi">+                if rows.start &lt; 0:</span>
<span class="gi">+                    raise ValueError(</span>
<span class="gi">+                        &quot;Negative slice start not supported with the &#39;pyogrio&#39; engine.&quot;</span>
<span class="gi">+                    )</span>
<span class="gi">+                kwargs[&quot;skip_features&quot;] = rows.start</span>
<span class="gi">+            if rows.stop is not None:</span>
<span class="gi">+                kwargs[&quot;max_features&quot;] = rows.stop - (rows.start or 0)</span>
<span class="gi">+            if rows.step is not None:</span>
<span class="gi">+                raise ValueError(&quot;slice with step is not supported&quot;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise TypeError(&quot;&#39;rows&#39; must be an integer or a slice.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if bbox is not None and mask is not None:</span>
<span class="gi">+        # match error message from Fiona</span>
<span class="gi">+        raise ValueError(&quot;mask and bbox can not be set together&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if bbox is not None:</span>
<span class="gi">+        if isinstance(bbox, (GeoDataFrame, GeoSeries)):</span>
<span class="gi">+            crs = pyogrio.read_info(path_or_bytes).get(&quot;crs&quot;)</span>
<span class="gi">+            if isinstance(path_or_bytes, IOBase):</span>
<span class="gi">+                path_or_bytes.seek(0)</span>
<span class="gi">+</span>
<span class="gi">+            bbox = tuple(bbox.to_crs(crs).total_bounds)</span>
<span class="gi">+        elif isinstance(bbox, BaseGeometry):</span>
<span class="gi">+            bbox = bbox.bounds</span>
<span class="gi">+        if len(bbox) != 4:</span>
<span class="gi">+            raise ValueError(&quot;&#39;bbox&#39; should be a length-4 tuple.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if mask is not None:</span>
<span class="gi">+        # NOTE: mask cannot be used at same time as bbox keyword</span>
<span class="gi">+        if isinstance(mask, (GeoDataFrame, GeoSeries)):</span>
<span class="gi">+            crs = pyogrio.read_info(path_or_bytes).get(&quot;crs&quot;)</span>
<span class="gi">+            if isinstance(path_or_bytes, IOBase):</span>
<span class="gi">+                path_or_bytes.seek(0)</span>
<span class="gi">+</span>
<span class="gi">+            mask = shapely.unary_union(mask.to_crs(crs).geometry.values)</span>
<span class="gi">+        elif isinstance(mask, BaseGeometry):</span>
<span class="gi">+            mask = shapely.unary_union(mask)</span>
<span class="gi">+        elif isinstance(mask, dict) or hasattr(mask, &quot;__geo_interface__&quot;):</span>
<span class="gi">+            # convert GeoJSON to shapely geometry</span>
<span class="gi">+            mask = shapely.geometry.shape(mask)</span>
<span class="gi">+</span>
<span class="gi">+        kwargs[&quot;mask&quot;] = mask</span>
<span class="gi">+</span>
<span class="gi">+    if kwargs.pop(&quot;ignore_geometry&quot;, False):</span>
<span class="gi">+        kwargs[&quot;read_geometry&quot;] = False</span>
<span class="gi">+</span>
<span class="gi">+    # translate `ignore_fields`/`include_fields` keyword for back compat with fiona</span>
<span class="gi">+    if &quot;ignore_fields&quot; in kwargs and &quot;include_fields&quot; in kwargs:</span>
<span class="gi">+        raise ValueError(&quot;Cannot specify both &#39;ignore_fields&#39; and &#39;include_fields&#39;&quot;)</span>
<span class="gi">+    elif &quot;ignore_fields&quot; in kwargs:</span>
<span class="gi">+        if kwargs.get(&quot;columns&quot;, None) is not None:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;Cannot specify both &#39;columns&#39; and &#39;ignore_fields&#39; keywords&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        warnings.warn(</span>
<span class="gi">+            &quot;The &#39;include_fields&#39; and &#39;ignore_fields&#39; keywords are deprecated, and &quot;</span>
<span class="gi">+            &quot;will be removed in a future release. You can use the &#39;columns&#39; keyword &quot;</span>
<span class="gi">+            &quot;instead to select which columns to read.&quot;,</span>
<span class="gi">+            DeprecationWarning,</span>
<span class="gi">+            stacklevel=3,</span>
<span class="gi">+        )</span>
<span class="gi">+        ignore_fields = kwargs.pop(&quot;ignore_fields&quot;)</span>
<span class="gi">+        fields = pyogrio.read_info(path_or_bytes)[&quot;fields&quot;]</span>
<span class="gi">+        include_fields = [col for col in fields if col not in ignore_fields]</span>
<span class="gi">+        kwargs[&quot;columns&quot;] = include_fields</span>
<span class="gi">+    elif &quot;include_fields&quot; in kwargs:</span>
<span class="gi">+        # translate `include_fields` keyword for back compat with fiona engine</span>
<span class="gi">+        if kwargs.get(&quot;columns&quot;, None) is not None:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;Cannot specify both &#39;columns&#39; and &#39;include_fields&#39; keywords&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        warnings.warn(</span>
<span class="gi">+            &quot;The &#39;include_fields&#39; and &#39;ignore_fields&#39; keywords are deprecated, and &quot;</span>
<span class="gi">+            &quot;will be removed in a future release. You can use the &#39;columns&#39; keyword &quot;</span>
<span class="gi">+            &quot;instead to select which columns to read.&quot;,</span>
<span class="gi">+            DeprecationWarning,</span>
<span class="gi">+            stacklevel=3,</span>
<span class="gi">+        )</span>
<span class="gi">+        kwargs[&quot;columns&quot;] = kwargs.pop(&quot;include_fields&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    return pyogrio.read_dataframe(path_or_bytes, bbox=bbox, **kwargs)</span>


<span class="w"> </span>def _detect_driver(path):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Attempt to auto-detect driver based on the extension
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def _to_file(df, filename, driver=None, schema=None, index=None, mode=&#39;w&#39;,</span>
<span class="gd">-    crs=None, engine=None, metadata=None, **kwargs):</span>
<span class="gi">+    try:</span>
<span class="gi">+        # in case the path is a file handle</span>
<span class="gi">+        path = path.name</span>
<span class="gi">+    except AttributeError:</span>
<span class="gi">+        pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        return _EXTENSION_TO_DRIVER[Path(path).suffix.lower()]</span>
<span class="gi">+    except KeyError:</span>
<span class="gi">+        # Assume it is a shapefile folder for now. In the future,</span>
<span class="gi">+        # will likely raise an exception when the expected</span>
<span class="gi">+        # folder writing behavior is more clearly defined.</span>
<span class="gi">+        return &quot;ESRI Shapefile&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _to_file(</span>
<span class="gi">+    df,</span>
<span class="gi">+    filename,</span>
<span class="gi">+    driver=None,</span>
<span class="gi">+    schema=None,</span>
<span class="gi">+    index=None,</span>
<span class="gi">+    mode=&quot;w&quot;,</span>
<span class="gi">+    crs=None,</span>
<span class="gi">+    engine=None,</span>
<span class="gi">+    metadata=None,</span>
<span class="gi">+    **kwargs,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Write this GeoDataFrame to an OGR data source

<span class="gu">@@ -214,17 +648,179 @@ def _to_file(df, filename, driver=None, schema=None, index=None, mode=&#39;w&#39;,</span>
<span class="w"> </span>    may fail. In this case, the proper encoding can be specified explicitly
<span class="w"> </span>    by using the encoding keyword parameter, e.g. ``encoding=&#39;utf-8&#39;``.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    engine = _check_engine(engine, &quot;&#39;to_file&#39; method&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    filename = _expand_user(filename)</span>
<span class="gi">+</span>
<span class="gi">+    if index is None:</span>
<span class="gi">+        # Determine if index attribute(s) should be saved to file</span>
<span class="gi">+        # (only if they are named or are non-integer)</span>
<span class="gi">+        index = list(df.index.names) != [None] or not is_integer_dtype(df.index.dtype)</span>
<span class="gi">+    if index:</span>
<span class="gi">+        df = df.reset_index(drop=False)</span>
<span class="gi">+</span>
<span class="gi">+    if driver is None:</span>
<span class="gi">+        driver = _detect_driver(filename)</span>
<span class="gi">+</span>
<span class="gi">+    if driver == &quot;ESRI Shapefile&quot; and any(len(c) &gt; 10 for c in df.columns.tolist()):</span>
<span class="gi">+        warnings.warn(</span>
<span class="gi">+            &quot;Column names longer than 10 characters will be truncated when saved to &quot;</span>
<span class="gi">+            &quot;ESRI Shapefile.&quot;,</span>
<span class="gi">+            stacklevel=3,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    if (df.dtypes == &quot;geometry&quot;).sum() &gt; 1:</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &quot;GeoDataFrame contains multiple geometry columns but GeoDataFrame.to_file &quot;</span>
<span class="gi">+            &quot;supports only a single geometry column. Use a GeoDataFrame.to_parquet or &quot;</span>
<span class="gi">+            &quot;GeoDataFrame.to_feather, drop additional geometry columns or convert them &quot;</span>
<span class="gi">+            &quot;to a supported format like a well-known text (WKT) using &quot;</span>
<span class="gi">+            &quot;`GeoSeries.to_wkt()`.&quot;,</span>
<span class="gi">+        )</span>
<span class="gi">+    _check_metadata_supported(metadata, engine, driver)</span>
<span class="gi">+</span>
<span class="gi">+    if mode not in (&quot;w&quot;, &quot;a&quot;):</span>
<span class="gi">+        raise ValueError(f&quot;&#39;mode&#39; should be one of &#39;w&#39; or &#39;a&#39;, got &#39;{mode}&#39; instead&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if engine == &quot;pyogrio&quot;:</span>
<span class="gi">+        _to_file_pyogrio(df, filename, driver, schema, crs, mode, metadata, **kwargs)</span>
<span class="gi">+    elif engine == &quot;fiona&quot;:</span>
<span class="gi">+        _to_file_fiona(df, filename, driver, schema, crs, mode, metadata, **kwargs)</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(f&quot;unknown engine &#39;{engine}&#39;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _to_file_fiona(df, filename, driver, schema, crs, mode, metadata, **kwargs):</span>
<span class="gi">+    if not HAS_PYPROJ and crs:</span>
<span class="gi">+        raise ImportError(</span>
<span class="gi">+            &quot;The &#39;pyproj&#39; package is required to write a file with a CRS, but it is not&quot;</span>
<span class="gi">+            &quot; installed or does not import correctly.&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    if schema is None:</span>
<span class="gi">+        schema = infer_schema(df)</span>
<span class="gi">+</span>
<span class="gi">+    if crs:</span>
<span class="gi">+        from pyproj import CRS</span>
<span class="gi">+</span>
<span class="gi">+        crs = CRS.from_user_input(crs)</span>
<span class="gi">+    else:</span>
<span class="gi">+        crs = df.crs</span>
<span class="gi">+</span>
<span class="gi">+    with fiona_env():</span>
<span class="gi">+        crs_wkt = None</span>
<span class="gi">+        try:</span>
<span class="gi">+            gdal_version = Version(</span>
<span class="gi">+                fiona.env.get_gdal_release_name().strip(&quot;e&quot;)</span>
<span class="gi">+            )  # GH3147</span>
<span class="gi">+        except (AttributeError, ValueError):</span>
<span class="gi">+            gdal_version = Version(&quot;2.0.0&quot;)  # just assume it is not the latest</span>
<span class="gi">+        if gdal_version &gt;= Version(&quot;3.0.0&quot;) and crs:</span>
<span class="gi">+            crs_wkt = crs.to_wkt()</span>
<span class="gi">+        elif crs:</span>
<span class="gi">+            crs_wkt = crs.to_wkt(&quot;WKT1_GDAL&quot;)</span>
<span class="gi">+        with fiona.open(</span>
<span class="gi">+            filename, mode=mode, driver=driver, crs_wkt=crs_wkt, schema=schema, **kwargs</span>
<span class="gi">+        ) as colxn:</span>
<span class="gi">+            if metadata is not None:</span>
<span class="gi">+                colxn.update_tags(metadata)</span>
<span class="gi">+            colxn.writerecords(df.iterfeatures())</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _to_file_pyogrio(df, filename, driver, schema, crs, mode, metadata, **kwargs):</span>
<span class="gi">+    import pyogrio</span>
<span class="gi">+</span>
<span class="gi">+    if schema is not None:</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &quot;The &#39;schema&#39; argument is not supported with the &#39;pyogrio&#39; engine.&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    if mode == &quot;a&quot;:</span>
<span class="gi">+        kwargs[&quot;append&quot;] = True</span>
<span class="gi">+</span>
<span class="gi">+    if crs is not None:</span>
<span class="gi">+        raise ValueError(&quot;Passing &#39;crs&#39; is not supported with the &#39;pyogrio&#39; engine.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # for the fiona engine, this check is done in gdf.iterfeatures()</span>
<span class="gi">+    if not df.columns.is_unique:</span>
<span class="gi">+        raise ValueError(&quot;GeoDataFrame cannot contain duplicated column names.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    pyogrio.write_dataframe(df, filename, driver=driver, metadata=metadata, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def infer_schema(df):</span>
<span class="gi">+    from collections import OrderedDict</span>
<span class="gi">+</span>
<span class="gi">+    # TODO: test pandas string type and boolean type once released</span>
<span class="gi">+    types = {</span>
<span class="gi">+        &quot;Int32&quot;: &quot;int32&quot;,</span>
<span class="gi">+        &quot;int32&quot;: &quot;int32&quot;,</span>
<span class="gi">+        &quot;Int64&quot;: &quot;int&quot;,</span>
<span class="gi">+        &quot;string&quot;: &quot;str&quot;,</span>
<span class="gi">+        &quot;boolean&quot;: &quot;bool&quot;,</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+    def convert_type(column, in_type):</span>
<span class="gi">+        if in_type == object:</span>
<span class="gi">+            return &quot;str&quot;</span>
<span class="gi">+        if in_type.name.startswith(&quot;datetime64&quot;):</span>
<span class="gi">+            # numpy datetime type regardless of frequency</span>
<span class="gi">+            return &quot;datetime&quot;</span>
<span class="gi">+        if str(in_type) in types:</span>
<span class="gi">+            out_type = types[str(in_type)]</span>
<span class="gi">+        else:</span>
<span class="gi">+            out_type = type(np.zeros(1, in_type).item()).__name__</span>
<span class="gi">+        if out_type == &quot;long&quot;:</span>
<span class="gi">+            out_type = &quot;int&quot;</span>
<span class="gi">+        return out_type</span>
<span class="gi">+</span>
<span class="gi">+    properties = OrderedDict(</span>
<span class="gi">+        [</span>
<span class="gi">+            (col, convert_type(col, _type))</span>
<span class="gi">+            for col, _type in zip(df.columns, df.dtypes)</span>
<span class="gi">+            if col != df._geometry_column_name</span>
<span class="gi">+        ]</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    if df.empty:</span>
<span class="gi">+        warnings.warn(</span>
<span class="gi">+            &quot;You are attempting to write an empty DataFrame to file. &quot;</span>
<span class="gi">+            &quot;For some drivers, this operation may fail.&quot;,</span>
<span class="gi">+            UserWarning,</span>
<span class="gi">+            stacklevel=3,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    # Since https://github.com/Toblerity/Fiona/issues/446 resolution,</span>
<span class="gi">+    # Fiona allows a list of geometry types</span>
<span class="gi">+    geom_types = _geometry_types(df)</span>
<span class="gi">+</span>
<span class="gi">+    schema = {&quot;geometry&quot;: geom_types, &quot;properties&quot;: properties}</span>
<span class="gi">+</span>
<span class="gi">+    return schema</span>


<span class="w"> </span>def _geometry_types(df):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Determine the geometry types in the GeoDataFrame for the schema.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    geom_types_2D = df[~df.geometry.has_z].geometry.geom_type.unique()</span>
<span class="gi">+    geom_types_2D = [gtype for gtype in geom_types_2D if gtype is not None]</span>
<span class="gi">+    geom_types_3D = df[df.geometry.has_z].geometry.geom_type.unique()</span>
<span class="gi">+    geom_types_3D = [&quot;3D &quot; + gtype for gtype in geom_types_3D if gtype is not None]</span>
<span class="gi">+    geom_types = geom_types_3D + geom_types_2D</span>
<span class="gi">+</span>
<span class="gi">+    if len(geom_types) == 0:</span>
<span class="gi">+        # Default geometry type supported by Fiona</span>
<span class="gi">+        # (Since https://github.com/Toblerity/Fiona/issues/446 resolution)</span>
<span class="gi">+        return &quot;Unknown&quot;</span>
<span class="gi">+</span>
<span class="gi">+    if len(geom_types) == 1:</span>
<span class="gi">+        geom_types = geom_types[0]</span>

<span class="gi">+    return geom_types</span>

<span class="gd">-def _list_layers(filename) -&gt;pd.DataFrame:</span>
<span class="gi">+</span>
<span class="gi">+def _list_layers(filename) -&gt; pd.DataFrame:</span>
<span class="w"> </span>    &quot;&quot;&quot;List layers available in a file.

<span class="w"> </span>    Provides an overview of layers available in a file or URL together with their
<span class="gu">@@ -245,4 +841,11 @@ def _list_layers(filename) -&gt;pd.DataFrame:</span>
<span class="w"> </span>    pandas.DataFrame
<span class="w"> </span>        A DataFrame with columns &quot;name&quot; and &quot;geometry_type&quot; and one row per layer.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    _import_pyogrio()</span>
<span class="gi">+    _check_pyogrio(&quot;list_layers&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    import pyogrio</span>
<span class="gi">+</span>
<span class="gi">+    return pd.DataFrame(</span>
<span class="gi">+        pyogrio.list_layers(filename), columns=[&quot;name&quot;, &quot;geometry_type&quot;]</span>
<span class="gi">+    )</span>
<span class="gh">diff --git a/geopandas/io/sql.py b/geopandas/io/sql.py</span>
<span class="gh">index 12554611..0f99b09e 100644</span>
<span class="gd">--- a/geopandas/io/sql.py</span>
<span class="gi">+++ b/geopandas/io/sql.py</span>
<span class="gu">@@ -1,9 +1,12 @@</span>
<span class="w"> </span>import warnings
<span class="w"> </span>from contextlib import contextmanager
<span class="w"> </span>from functools import lru_cache
<span class="gi">+</span>
<span class="w"> </span>import pandas as pd
<span class="gi">+</span>
<span class="w"> </span>import shapely
<span class="w"> </span>import shapely.wkb
<span class="gi">+</span>
<span class="w"> </span>from geopandas import GeoDataFrame


<span class="gu">@@ -24,10 +27,22 @@ def _get_conn(conn_or_engine):</span>
<span class="w"> </span>    -------
<span class="w"> </span>    Connection
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from sqlalchemy.engine.base import Connection, Engine</span>

<span class="gi">+    if isinstance(conn_or_engine, Connection):</span>
<span class="gi">+        if not conn_or_engine.in_transaction():</span>
<span class="gi">+            with conn_or_engine.begin():</span>
<span class="gi">+                yield conn_or_engine</span>
<span class="gi">+        else:</span>
<span class="gi">+            yield conn_or_engine</span>
<span class="gi">+    elif isinstance(conn_or_engine, Engine):</span>
<span class="gi">+        with conn_or_engine.begin() as conn:</span>
<span class="gi">+            yield conn</span>
<span class="gi">+    else:</span>
<span class="gi">+        raise ValueError(f&quot;Unknown Connectable: {conn_or_engine}&quot;)</span>

<span class="gd">-def _df_to_geodf(df, geom_col=&#39;geom&#39;, crs=None, con=None):</span>
<span class="gi">+</span>
<span class="gi">+def _df_to_geodf(df, geom_col=&quot;geom&quot;, crs=None, con=None):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Transforms a pandas DataFrame into a GeoDataFrame.
<span class="w"> </span>    The column &#39;geom_col&#39; must be a geometry column in WKB representation.
<span class="gu">@@ -50,11 +65,73 @@ def _df_to_geodf(df, geom_col=&#39;geom&#39;, crs=None, con=None):</span>
<span class="w"> </span>    -------
<span class="w"> </span>    GeoDataFrame
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>

<span class="gi">+    if geom_col not in df:</span>
<span class="gi">+        raise ValueError(&quot;Query missing geometry column &#39;{}&#39;&quot;.format(geom_col))</span>
<span class="gi">+</span>
<span class="gi">+    if df.columns.to_list().count(geom_col) &gt; 1:</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            f&quot;Duplicate geometry column &#39;{geom_col}&#39; detected in SQL query output. Only&quot;</span>
<span class="gi">+            &quot;one geometry column is allowed.&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    geoms = df[geom_col].dropna()</span>
<span class="gi">+</span>
<span class="gi">+    if not geoms.empty:</span>
<span class="gi">+        load_geom_bytes = shapely.wkb.loads</span>
<span class="gi">+        &quot;&quot;&quot;Load from Python 3 binary.&quot;&quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+        def load_geom_text(x):</span>
<span class="gi">+            &quot;&quot;&quot;Load from binary encoded as text.&quot;&quot;&quot;</span>
<span class="gi">+            return shapely.wkb.loads(str(x), hex=True)</span>
<span class="gi">+</span>
<span class="gi">+        if isinstance(geoms.iat[0], bytes):</span>
<span class="gi">+            load_geom = load_geom_bytes</span>
<span class="gi">+        else:</span>
<span class="gi">+            load_geom = load_geom_text</span>
<span class="gi">+</span>
<span class="gi">+        df[geom_col] = geoms = geoms.apply(load_geom)</span>
<span class="gi">+        if crs is None:</span>
<span class="gi">+            srid = shapely.get_srid(geoms.iat[0])</span>
<span class="gi">+            # if no defined SRID in geodatabase, returns SRID of 0</span>
<span class="gi">+            if srid != 0:</span>
<span class="gi">+                try:</span>
<span class="gi">+                    spatial_ref_sys_df = _get_spatial_ref_sys_df(con, srid)</span>
<span class="gi">+                except pd.errors.DatabaseError:</span>
<span class="gi">+                    warning_msg = (</span>
<span class="gi">+                        f&quot;Could not find the spatial reference system table &quot;</span>
<span class="gi">+                        f&quot;(spatial_ref_sys) in PostGIS.&quot;</span>
<span class="gi">+                        f&quot;Trying epsg:{srid} as a fallback.&quot;</span>
<span class="gi">+                    )</span>
<span class="gi">+                    warnings.warn(warning_msg, UserWarning, stacklevel=3)</span>
<span class="gi">+                    crs = &quot;epsg:{}&quot;.format(srid)</span>
<span class="gi">+                else:</span>
<span class="gi">+                    if not spatial_ref_sys_df.empty:</span>
<span class="gi">+                        auth_name = spatial_ref_sys_df[&quot;auth_name&quot;].item()</span>
<span class="gi">+                        crs = f&quot;{auth_name}:{srid}&quot;</span>
<span class="gi">+                    else:</span>
<span class="gi">+                        warning_msg = (</span>
<span class="gi">+                            f&quot;Could not find srid {srid} in the &quot;</span>
<span class="gi">+                            f&quot;spatial_ref_sys table. &quot;</span>
<span class="gi">+                            f&quot;Trying epsg:{srid} as a fallback.&quot;</span>
<span class="gi">+                        )</span>
<span class="gi">+                        warnings.warn(warning_msg, UserWarning, stacklevel=3)</span>
<span class="gi">+                        crs = &quot;epsg:{}&quot;.format(srid)</span>
<span class="gi">+</span>
<span class="gi">+    return GeoDataFrame(df, crs=crs, geometry=geom_col)</span>

<span class="gd">-def _read_postgis(sql, con, geom_col=&#39;geom&#39;, crs=None, index_col=None,</span>
<span class="gd">-    coerce_float=True, parse_dates=None, params=None, chunksize=None):</span>
<span class="gi">+</span>
<span class="gi">+def _read_postgis(</span>
<span class="gi">+    sql,</span>
<span class="gi">+    con,</span>
<span class="gi">+    geom_col=&quot;geom&quot;,</span>
<span class="gi">+    crs=None,</span>
<span class="gi">+    index_col=None,</span>
<span class="gi">+    coerce_float=True,</span>
<span class="gi">+    parse_dates=None,</span>
<span class="gi">+    params=None,</span>
<span class="gi">+    chunksize=None,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Returns a GeoDataFrame corresponding to the result of the query
<span class="w"> </span>    string, which must contain a geometry column in WKB representation.
<span class="gu">@@ -102,7 +179,34 @@ def _read_postgis(sql, con, geom_col=&#39;geom&#39;, crs=None, index_col=None,</span>
<span class="w"> </span>    &gt;&gt;&gt; sql = &quot;SELECT ST_AsBinary(geom) AS geom, highway FROM roads&quot;
<span class="w"> </span>    &gt;&gt;&gt; df = geopandas.read_postgis(sql, con)  # doctest: +SKIP
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    if chunksize is None:</span>
<span class="gi">+        # read all in one chunk and return a single GeoDataFrame</span>
<span class="gi">+        df = pd.read_sql(</span>
<span class="gi">+            sql,</span>
<span class="gi">+            con,</span>
<span class="gi">+            index_col=index_col,</span>
<span class="gi">+            coerce_float=coerce_float,</span>
<span class="gi">+            parse_dates=parse_dates,</span>
<span class="gi">+            params=params,</span>
<span class="gi">+            chunksize=chunksize,</span>
<span class="gi">+        )</span>
<span class="gi">+        return _df_to_geodf(df, geom_col=geom_col, crs=crs, con=con)</span>
<span class="gi">+</span>
<span class="gi">+    else:</span>
<span class="gi">+        # read data in chunks and return a generator</span>
<span class="gi">+        df_generator = pd.read_sql(</span>
<span class="gi">+            sql,</span>
<span class="gi">+            con,</span>
<span class="gi">+            index_col=index_col,</span>
<span class="gi">+            coerce_float=coerce_float,</span>
<span class="gi">+            parse_dates=parse_dates,</span>
<span class="gi">+            params=params,</span>
<span class="gi">+            chunksize=chunksize,</span>
<span class="gi">+        )</span>
<span class="gi">+        return (</span>
<span class="gi">+            _df_to_geodf(df, geom_col=geom_col, crs=crs, con=con) for df in df_generator</span>
<span class="gi">+        )</span>


<span class="w"> </span>def _get_geometry_type(gdf):
<span class="gu">@@ -124,23 +228,131 @@ def _get_geometry_type(gdf):</span>
<span class="w"> </span>     - if any of the geometries has Z-coordinate, all records will
<span class="w"> </span>       be written with 3D.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    geom_types = list(gdf.geometry.geom_type.unique())</span>
<span class="gi">+    has_curve = False</span>
<span class="gi">+</span>
<span class="gi">+    for gt in geom_types:</span>
<span class="gi">+        if gt is None:</span>
<span class="gi">+            continue</span>
<span class="gi">+        elif &quot;LinearRing&quot; in gt:</span>
<span class="gi">+            has_curve = True</span>
<span class="gi">+</span>
<span class="gi">+    if len(geom_types) == 1:</span>
<span class="gi">+        if has_curve:</span>
<span class="gi">+            target_geom_type = &quot;LINESTRING&quot;</span>
<span class="gi">+        else:</span>
<span class="gi">+            if geom_types[0] is None:</span>
<span class="gi">+                raise ValueError(&quot;No valid geometries in the data.&quot;)</span>
<span class="gi">+            else:</span>
<span class="gi">+                target_geom_type = geom_types[0].upper()</span>
<span class="gi">+    else:</span>
<span class="gi">+        target_geom_type = &quot;GEOMETRY&quot;</span>
<span class="gi">+</span>
<span class="gi">+    # Check for 3D-coordinates</span>
<span class="gi">+    if any(gdf.geometry.has_z):</span>
<span class="gi">+        target_geom_type += &quot;Z&quot;</span>
<span class="gi">+</span>
<span class="gi">+    return target_geom_type, has_curve</span>


<span class="w"> </span>def _get_srid_from_crs(gdf):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Get EPSG code from CRS if available. If not, return 0.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    # Use geoalchemy2 default for srid</span>
<span class="gi">+    # Note: undefined srid in PostGIS is 0</span>
<span class="gi">+    srid = None</span>
<span class="gi">+    warning_msg = (</span>
<span class="gi">+        &quot;Could not parse CRS from the GeoDataFrame. &quot;</span>
<span class="gi">+        &quot;Inserting data without defined CRS.&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    if gdf.crs is not None:</span>
<span class="gi">+        try:</span>
<span class="gi">+            for confidence in (100, 70, 25):</span>
<span class="gi">+                srid = gdf.crs.to_epsg(min_confidence=confidence)</span>
<span class="gi">+                if srid is not None:</span>
<span class="gi">+                    break</span>
<span class="gi">+                auth_srid = gdf.crs.to_authority(</span>
<span class="gi">+                    auth_name=&quot;ESRI&quot;, min_confidence=confidence</span>
<span class="gi">+                )</span>
<span class="gi">+                if auth_srid is not None:</span>
<span class="gi">+                    srid = int(auth_srid[1])</span>
<span class="gi">+                    break</span>
<span class="gi">+        except Exception:</span>
<span class="gi">+            warnings.warn(warning_msg, UserWarning, stacklevel=2)</span>
<span class="gi">+</span>
<span class="gi">+    if srid is None:</span>
<span class="gi">+        srid = 0</span>
<span class="gi">+        warnings.warn(warning_msg, UserWarning, stacklevel=2)</span>
<span class="gi">+</span>
<span class="gi">+    return srid</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _convert_linearring_to_linestring(gdf, geom_name):</span>
<span class="gi">+    from shapely.geometry import LineString</span>
<span class="gi">+</span>
<span class="gi">+    # Todo: Use shapely function once it&#39;s implemented:</span>
<span class="gi">+    # https://github.com/shapely/shapely/issues/1617</span>
<span class="gi">+</span>
<span class="gi">+    mask = gdf.geom_type == &quot;LinearRing&quot;</span>
<span class="gi">+    gdf.loc[mask, geom_name] = gdf.loc[mask, geom_name].apply(</span>
<span class="gi">+        lambda geom: LineString(geom)</span>
<span class="gi">+    )</span>
<span class="gi">+    return gdf</span>


<span class="w"> </span>def _convert_to_ewkb(gdf, geom_name, srid):
<span class="w"> </span>    &quot;&quot;&quot;Convert geometries to ewkb.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    geoms = shapely.to_wkb(</span>
<span class="gi">+        shapely.set_srid(gdf[geom_name].values._data, srid=srid),</span>
<span class="gi">+        hex=True,</span>
<span class="gi">+        include_srid=True,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    # The gdf will warn that the geometry column doesn&#39;t hold in-memory geometries</span>
<span class="gi">+    # now that they are EWKB, so convert back to a regular dataframe to avoid warning</span>
<span class="gi">+    # the user that the dtypes are unexpected.</span>
<span class="gi">+    df = pd.DataFrame(gdf, copy=False)</span>
<span class="gi">+    df[geom_name] = geoms</span>
<span class="gi">+    return df</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _psql_insert_copy(tbl, conn, keys, data_iter):</span>
<span class="gi">+    import csv</span>
<span class="gi">+    import io</span>

<span class="gi">+    s_buf = io.StringIO()</span>
<span class="gi">+    writer = csv.writer(s_buf)</span>
<span class="gi">+    writer.writerows(data_iter)</span>
<span class="gi">+    s_buf.seek(0)</span>

<span class="gd">-def _write_postgis(gdf, name, con, schema=None, if_exists=&#39;fail&#39;, index=</span>
<span class="gd">-    False, index_label=None, chunksize=None, dtype=None):</span>
<span class="gi">+    columns = &quot;, &quot;.join(&#39;&quot;{}&quot;&#39;.format(k) for k in keys)</span>
<span class="gi">+</span>
<span class="gi">+    dbapi_conn = conn.connection</span>
<span class="gi">+    sql = &#39;COPY &quot;{}&quot;.&quot;{}&quot; ({}) FROM STDIN WITH CSV&#39;.format(</span>
<span class="gi">+        tbl.table.schema, tbl.table.name, columns</span>
<span class="gi">+    )</span>
<span class="gi">+    with dbapi_conn.cursor() as cur:</span>
<span class="gi">+        # Use psycopg method if it&#39;s available</span>
<span class="gi">+        if hasattr(cur, &quot;copy&quot;) and callable(cur.copy):</span>
<span class="gi">+            with cur.copy(sql) as copy:</span>
<span class="gi">+                copy.write(s_buf.read())</span>
<span class="gi">+        else:  # otherwise use psycopg2 method</span>
<span class="gi">+            cur.copy_expert(sql, s_buf)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _write_postgis(</span>
<span class="gi">+    gdf,</span>
<span class="gi">+    name,</span>
<span class="gi">+    con,</span>
<span class="gi">+    schema=None,</span>
<span class="gi">+    if_exists=&quot;fail&quot;,</span>
<span class="gi">+    index=False,</span>
<span class="gi">+    index_label=None,</span>
<span class="gi">+    chunksize=None,</span>
<span class="gi">+    dtype=None,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Upload GeoDataFrame into PostGIS database.

<span class="gu">@@ -180,7 +392,82 @@ def _write_postgis(gdf, name, con, schema=None, if_exists=&#39;fail&#39;, index=</span>
<span class="w"> </span>    --------

<span class="w"> </span>    &gt;&gt;&gt; from sqlalchemy import create_engine  # doctest: +SKIP
<span class="gd">-    &gt;&gt;&gt; engine = create_engine(&quot;postgresql://myusername:mypassword@myhost:5432/mydatabase&quot;;)  # doctest: +SKIP</span>
<span class="gi">+    &gt;&gt;&gt; engine = create_engine(&quot;postgresql://myusername:mypassword@myhost:5432\</span>
<span class="gi">+/mydatabase&quot;;)  # doctest: +SKIP</span>
<span class="w"> </span>    &gt;&gt;&gt; gdf.to_postgis(&quot;my_table&quot;, engine)  # doctest: +SKIP
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        from geoalchemy2 import Geometry</span>
<span class="gi">+        from sqlalchemy import text</span>
<span class="gi">+    except ImportError:</span>
<span class="gi">+        raise ImportError(&quot;&#39;to_postgis()&#39; requires geoalchemy2 package.&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    gdf = gdf.copy()</span>
<span class="gi">+    geom_name = gdf.geometry.name</span>
<span class="gi">+</span>
<span class="gi">+    # Get srid</span>
<span class="gi">+    srid = _get_srid_from_crs(gdf)</span>
<span class="gi">+</span>
<span class="gi">+    # Get geometry type and info whether data contains LinearRing.</span>
<span class="gi">+    geometry_type, has_curve = _get_geometry_type(gdf)</span>
<span class="gi">+</span>
<span class="gi">+    # Build dtype with Geometry</span>
<span class="gi">+    if dtype is not None:</span>
<span class="gi">+        dtype[geom_name] = Geometry(geometry_type=geometry_type, srid=srid)</span>
<span class="gi">+    else:</span>
<span class="gi">+        dtype = {geom_name: Geometry(geometry_type=geometry_type, srid=srid)}</span>
<span class="gi">+</span>
<span class="gi">+    # Convert LinearRing geometries to LineString</span>
<span class="gi">+    if has_curve:</span>
<span class="gi">+        gdf = _convert_linearring_to_linestring(gdf, geom_name)</span>
<span class="gi">+</span>
<span class="gi">+    # Convert geometries to EWKB</span>
<span class="gi">+    gdf = _convert_to_ewkb(gdf, geom_name, srid)</span>
<span class="gi">+</span>
<span class="gi">+    if schema is not None:</span>
<span class="gi">+        schema_name = schema</span>
<span class="gi">+    else:</span>
<span class="gi">+        schema_name = &quot;public&quot;</span>
<span class="gi">+</span>
<span class="gi">+    if if_exists == &quot;append&quot;:</span>
<span class="gi">+        # Check that the geometry srid matches with the current GeoDataFrame</span>
<span class="gi">+        with _get_conn(con) as connection:</span>
<span class="gi">+            # Only check SRID if table exists</span>
<span class="gi">+            if connection.dialect.has_table(connection, name, schema):</span>
<span class="gi">+                target_srid = connection.execute(</span>
<span class="gi">+                    text(</span>
<span class="gi">+                        &quot;SELECT Find_SRID(&#39;{schema}&#39;, &#39;{table}&#39;, &#39;{geom_col}&#39;);&quot;.format(</span>
<span class="gi">+                            schema=schema_name, table=name, geom_col=geom_name</span>
<span class="gi">+                        )</span>
<span class="gi">+                    )</span>
<span class="gi">+                ).fetchone()[0]</span>
<span class="gi">+</span>
<span class="gi">+                if target_srid != srid:</span>
<span class="gi">+                    msg = (</span>
<span class="gi">+                        &quot;The CRS of the target table (EPSG:{epsg_t}) differs from the &quot;</span>
<span class="gi">+                        &quot;CRS of current GeoDataFrame (EPSG:{epsg_src}).&quot;.format(</span>
<span class="gi">+                            epsg_t=target_srid, epsg_src=srid</span>
<span class="gi">+                        )</span>
<span class="gi">+                    )</span>
<span class="gi">+                    raise ValueError(msg)</span>
<span class="gi">+</span>
<span class="gi">+    with _get_conn(con) as connection:</span>
<span class="gi">+        gdf.to_sql(</span>
<span class="gi">+            name,</span>
<span class="gi">+            connection,</span>
<span class="gi">+            schema=schema_name,</span>
<span class="gi">+            if_exists=if_exists,</span>
<span class="gi">+            index=index,</span>
<span class="gi">+            index_label=index_label,</span>
<span class="gi">+            chunksize=chunksize,</span>
<span class="gi">+            dtype=dtype,</span>
<span class="gi">+            method=_psql_insert_copy,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@lru_cache</span>
<span class="gi">+def _get_spatial_ref_sys_df(con, srid):</span>
<span class="gi">+    spatial_ref_sys_sql = (</span>
<span class="gi">+        f&quot;SELECT srid, auth_name FROM spatial_ref_sys WHERE srid = {srid}&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    return pd.read_sql(spatial_ref_sys_sql, con)</span>
<span class="gh">diff --git a/geopandas/io/tests/generate_legacy_storage_files.py b/geopandas/io/tests/generate_legacy_storage_files.py</span>
<span class="gh">index 9b4e0426..fb6e136f 100644</span>
<span class="gd">--- a/geopandas/io/tests/generate_legacy_storage_files.py</span>
<span class="gi">+++ b/geopandas/io/tests/generate_legacy_storage_files.py</span>
<span class="gu">@@ -6,7 +6,8 @@ Based on pandas&#39; generate_legacy_storage_files.py script.</span>
<span class="w"> </span>To use this script, create an environment for which you want to
<span class="w"> </span>generate pickles, activate the environment, and run this script as:

<span class="gd">-$ python geopandas/geopandas/io/tests/generate_legacy_storage_files.py     geopandas/geopandas/io/tests/data/pickle/ pickle</span>
<span class="gi">+$ python geopandas/geopandas/io/tests/generate_legacy_storage_files.py \</span>
<span class="gi">+    geopandas/geopandas/io/tests/data/pickle/ pickle</span>

<span class="w"> </span>This script generates a storage file for the current arch, system,

<span class="gu">@@ -18,19 +19,82 @@ pickles and test versus the current data that is generated</span>
<span class="w"> </span>(with master). These are then compared.

<span class="w"> </span>&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>import os
<span class="w"> </span>import pickle
<span class="w"> </span>import platform
<span class="w"> </span>import sys
<span class="gi">+</span>
<span class="w"> </span>import pandas as pd
<span class="gi">+</span>
<span class="w"> </span>from shapely.geometry import Point
<span class="gi">+</span>
<span class="w"> </span>import geopandas


<span class="w"> </span>def create_pickle_data():
<span class="w"> </span>    &quot;&quot;&quot;create the pickle data&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    # custom geometry column name</span>
<span class="gi">+    gdf_the_geom = geopandas.GeoDataFrame(</span>
<span class="gi">+        {&quot;a&quot;: [1, 2, 3], &quot;the_geom&quot;: [Point(1, 1), Point(2, 2), Point(3, 3)]},</span>
<span class="gi">+        geometry=&quot;the_geom&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    # with crs</span>
<span class="gi">+    gdf_crs = geopandas.GeoDataFrame(</span>
<span class="gi">+        {&quot;a&quot;: [0.1, 0.2, 0.3], &quot;geometry&quot;: [Point(1, 1), Point(2, 2), Point(3, 3)]},</span>
<span class="gi">+        crs=&quot;EPSG:4326&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    return {&quot;gdf_the_geom&quot;: gdf_the_geom, &quot;gdf_crs&quot;: gdf_crs}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def platform_name():</span>
<span class="gi">+    return &quot;_&quot;.join(</span>
<span class="gi">+        [</span>
<span class="gi">+            str(geopandas.__version__),</span>
<span class="gi">+            &quot;pd-&quot; + str(pd.__version__),</span>
<span class="gi">+            &quot;py-&quot; + str(platform.python_version()),</span>
<span class="gi">+            str(platform.machine()),</span>
<span class="gi">+            str(platform.system().lower()),</span>
<span class="gi">+        ]</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def write_legacy_pickles(output_dir):</span>
<span class="gi">+    print(</span>
<span class="gi">+        &quot;This script generates a storage file for the current arch, system, &quot;</span>
<span class="gi">+        &quot;and python version&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    print(&quot;geopandas version: {}&quot;).format(geopandas.__version__)</span>
<span class="gi">+    print(&quot;   output dir    : {}&quot;.format(output_dir))</span>
<span class="gi">+    print(&quot;   storage format: pickle&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    pth = &quot;{}.pickle&quot;.format(platform_name())</span>
<span class="gi">+</span>
<span class="gi">+    fh = open(os.path.join(output_dir, pth), &quot;wb&quot;)</span>
<span class="gi">+    pickle.dump(create_pickle_data(), fh, pickle.DEFAULT_PROTOCOL)</span>
<span class="gi">+    fh.close()</span>
<span class="gi">+</span>
<span class="gi">+    print(&quot;created pickle file: {}&quot;.format(pth))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def main():</span>
<span class="gi">+    if len(sys.argv) != 3:</span>
<span class="gi">+        sys.exit(</span>
<span class="gi">+            &quot;Specify output directory and storage type: generate_legacy_&quot;</span>
<span class="gi">+            &quot;storage_files.py &lt;output_dir&gt; &lt;storage_type&gt; &quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    output_dir = str(sys.argv[1])</span>
<span class="gi">+    storage_type = str(sys.argv[2])</span>
<span class="gi">+</span>
<span class="gi">+    if storage_type == &quot;pickle&quot;:</span>
<span class="gi">+        write_legacy_pickles(output_dir=output_dir)</span>
<span class="gi">+    else:</span>
<span class="gi">+        sys.exit(&quot;storage_type must be one of {&#39;pickle&#39;}&quot;)</span>


<span class="gd">-if __name__ == &#39;__main__&#39;:</span>
<span class="gi">+if __name__ == &quot;__main__&quot;:</span>
<span class="w"> </span>    main()
<span class="gh">diff --git a/geopandas/io/tests/test_arrow.py b/geopandas/io/tests/test_arrow.py</span>
<span class="gh">index a5dbeb1b..9078191d 100644</span>
<span class="gd">--- a/geopandas/io/tests/test_arrow.py</span>
<span class="gi">+++ b/geopandas/io/tests/test_arrow.py</span>
<span class="gu">@@ -1,81 +1,552 @@</span>
<span class="w"> </span>from __future__ import absolute_import
<span class="gi">+</span>
<span class="w"> </span>import json
<span class="w"> </span>import os
<span class="w"> </span>import pathlib
<span class="w"> </span>from itertools import product
<span class="w"> </span>from packaging.version import Version
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>from pandas import DataFrame
<span class="w"> </span>from pandas import read_parquet as pd_read_parquet
<span class="gi">+</span>
<span class="w"> </span>import shapely
<span class="w"> </span>from shapely.geometry import LineString, MultiPolygon, Point, Polygon, box
<span class="gi">+</span>
<span class="w"> </span>import geopandas
<span class="w"> </span>from geopandas import GeoDataFrame, read_feather, read_file, read_parquet
<span class="w"> </span>from geopandas._compat import HAS_PYPROJ
<span class="w"> </span>from geopandas.array import to_wkb
<span class="gd">-from geopandas.io.arrow import METADATA_VERSION, SUPPORTED_VERSIONS, _convert_bbox_to_parquet_filter, _create_metadata, _decode_metadata, _encode_metadata, _geopandas_to_arrow, _get_filesystem_path, _remove_id_from_member_of_ensembles, _validate_dataframe, _validate_geo_metadata</span>
<span class="gi">+from geopandas.io.arrow import (</span>
<span class="gi">+    METADATA_VERSION,</span>
<span class="gi">+    SUPPORTED_VERSIONS,</span>
<span class="gi">+    _convert_bbox_to_parquet_filter,</span>
<span class="gi">+    _create_metadata,</span>
<span class="gi">+    _decode_metadata,</span>
<span class="gi">+    _encode_metadata,</span>
<span class="gi">+    _geopandas_to_arrow,</span>
<span class="gi">+    _get_filesystem_path,</span>
<span class="gi">+    _remove_id_from_member_of_ensembles,</span>
<span class="gi">+    _validate_dataframe,</span>
<span class="gi">+    _validate_geo_metadata,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="w"> </span>from geopandas.testing import assert_geodataframe_equal, assert_geoseries_equal
<span class="w"> </span>from geopandas.tests.util import mock
<span class="w"> </span>from pandas.testing import assert_frame_equal
<span class="gd">-DATA_PATH = pathlib.Path(os.path.dirname(__file__)) / &#39;data&#39;</span>
<span class="gd">-pyarrow = pytest.importorskip(&#39;pyarrow&#39;)</span>
<span class="gi">+</span>
<span class="gi">+DATA_PATH = pathlib.Path(os.path.dirname(__file__)) / &quot;data&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# Skip all tests in this module if pyarrow is not available</span>
<span class="gi">+pyarrow = pytest.importorskip(&quot;pyarrow&quot;)</span>
<span class="gi">+</span>
<span class="w"> </span>import pyarrow.compute as pc
<span class="w"> </span>import pyarrow.parquet as pq
<span class="w"> </span>from pyarrow import feather


<span class="gd">-@pytest.mark.parametrize(&#39;test_dataset&#39;, [&#39;naturalearth_lowres&#39;,</span>
<span class="gd">-    &#39;naturalearth_cities&#39;, &#39;nybb_filename&#39;])</span>
<span class="gi">+@pytest.fixture(</span>
<span class="gi">+    params=[</span>
<span class="gi">+        &quot;parquet&quot;,</span>
<span class="gi">+        pytest.param(</span>
<span class="gi">+            &quot;feather&quot;,</span>
<span class="gi">+            marks=pytest.mark.skipif(</span>
<span class="gi">+                Version(pyarrow.__version__) &lt; Version(&quot;0.17.0&quot;),</span>
<span class="gi">+                reason=&quot;needs pyarrow &gt;= 0.17&quot;,</span>
<span class="gi">+            ),</span>
<span class="gi">+        ),</span>
<span class="gi">+    ]</span>
<span class="gi">+)</span>
<span class="gi">+def file_format(request):</span>
<span class="gi">+    if request.param == &quot;parquet&quot;:</span>
<span class="gi">+        return read_parquet, GeoDataFrame.to_parquet</span>
<span class="gi">+    elif request.param == &quot;feather&quot;:</span>
<span class="gi">+        return read_feather, GeoDataFrame.to_feather</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_create_metadata(naturalearth_lowres):</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+    metadata = _create_metadata(df, geometry_encoding={&quot;geometry&quot;: &quot;WKB&quot;})</span>
<span class="gi">+</span>
<span class="gi">+    assert isinstance(metadata, dict)</span>
<span class="gi">+    assert metadata[&quot;version&quot;] == METADATA_VERSION</span>
<span class="gi">+    assert metadata[&quot;primary_column&quot;] == &quot;geometry&quot;</span>
<span class="gi">+    assert &quot;geometry&quot; in metadata[&quot;columns&quot;]</span>
<span class="gi">+    if HAS_PYPROJ:</span>
<span class="gi">+        crs_expected = df.crs.to_json_dict()</span>
<span class="gi">+        _remove_id_from_member_of_ensembles(crs_expected)</span>
<span class="gi">+        assert metadata[&quot;columns&quot;][&quot;geometry&quot;][&quot;crs&quot;] == crs_expected</span>
<span class="gi">+    assert metadata[&quot;columns&quot;][&quot;geometry&quot;][&quot;encoding&quot;] == &quot;WKB&quot;</span>
<span class="gi">+    assert metadata[&quot;columns&quot;][&quot;geometry&quot;][&quot;geometry_types&quot;] == [</span>
<span class="gi">+        &quot;MultiPolygon&quot;,</span>
<span class="gi">+        &quot;Polygon&quot;,</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+    assert np.array_equal(</span>
<span class="gi">+        metadata[&quot;columns&quot;][&quot;geometry&quot;][&quot;bbox&quot;], df.geometry.total_bounds</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    assert metadata[&quot;creator&quot;][&quot;library&quot;] == &quot;geopandas&quot;</span>
<span class="gi">+    assert metadata[&quot;creator&quot;][&quot;version&quot;] == geopandas.__version__</span>
<span class="gi">+</span>
<span class="gi">+    # specifying non-WKB encoding sets default schema to 1.1.0</span>
<span class="gi">+    metadata = _create_metadata(df, geometry_encoding={&quot;geometry&quot;: &quot;point&quot;})</span>
<span class="gi">+    assert metadata[&quot;version&quot;] == &quot;1.1.0&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_create_metadata_with_z_geometries():</span>
<span class="gi">+    geometry_types = [</span>
<span class="gi">+        &quot;Point&quot;,</span>
<span class="gi">+        &quot;Point Z&quot;,</span>
<span class="gi">+        &quot;LineString&quot;,</span>
<span class="gi">+        &quot;LineString Z&quot;,</span>
<span class="gi">+        &quot;Polygon&quot;,</span>
<span class="gi">+        &quot;Polygon Z&quot;,</span>
<span class="gi">+        &quot;MultiPolygon&quot;,</span>
<span class="gi">+        &quot;MultiPolygon Z&quot;,</span>
<span class="gi">+    ]</span>
<span class="gi">+    df = geopandas.GeoDataFrame(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;geo_type&quot;: geometry_types,</span>
<span class="gi">+            &quot;geometry&quot;: [</span>
<span class="gi">+                Point(1, 2),</span>
<span class="gi">+                Point(1, 2, 3),</span>
<span class="gi">+                LineString([(0, 0), (1, 1), (2, 2)]),</span>
<span class="gi">+                LineString([(0, 0, 1), (1, 1, 2), (2, 2, 3)]),</span>
<span class="gi">+                Polygon([(0, 0), (0, 1), (1, 1), (1, 0)]),</span>
<span class="gi">+                Polygon([(0, 0, 0), (0, 1, 0.5), (1, 1, 1), (1, 0, 0.5)]),</span>
<span class="gi">+                MultiPolygon(</span>
<span class="gi">+                    [</span>
<span class="gi">+                        Polygon([(0, 0), (0, 1), (1, 1), (1, 0)]),</span>
<span class="gi">+                        Polygon([(0.5, 0.5), (0.5, 1.5), (1.5, 1.5), (1.5, 0.5)]),</span>
<span class="gi">+                    ]</span>
<span class="gi">+                ),</span>
<span class="gi">+                MultiPolygon(</span>
<span class="gi">+                    [</span>
<span class="gi">+                        Polygon([(0, 0, 0), (0, 1, 0.5), (1, 1, 1), (1, 0, 0.5)]),</span>
<span class="gi">+                        Polygon(</span>
<span class="gi">+                            [</span>
<span class="gi">+                                (0.5, 0.5, 1),</span>
<span class="gi">+                                (0.5, 1.5, 1.5),</span>
<span class="gi">+                                (1.5, 1.5, 2),</span>
<span class="gi">+                                (1.5, 0.5, 1.5),</span>
<span class="gi">+                            ]</span>
<span class="gi">+                        ),</span>
<span class="gi">+                    ]</span>
<span class="gi">+                ),</span>
<span class="gi">+            ],</span>
<span class="gi">+        },</span>
<span class="gi">+    )</span>
<span class="gi">+    metadata = _create_metadata(df, geometry_encoding={&quot;geometry&quot;: &quot;WKB&quot;})</span>
<span class="gi">+    assert sorted(metadata[&quot;columns&quot;][&quot;geometry&quot;][&quot;geometry_types&quot;]) == sorted(</span>
<span class="gi">+        geometry_types</span>
<span class="gi">+    )</span>
<span class="gi">+    # only 3D geometries</span>
<span class="gi">+    metadata = _create_metadata(df.iloc[1::2], geometry_encoding={&quot;geometry&quot;: &quot;WKB&quot;})</span>
<span class="gi">+    assert all(</span>
<span class="gi">+        geom_type.endswith(&quot; Z&quot;)</span>
<span class="gi">+        for geom_type in metadata[&quot;columns&quot;][&quot;geometry&quot;][&quot;geometry_types&quot;]</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    metadata = _create_metadata(df.iloc[5:7], geometry_encoding={&quot;geometry&quot;: &quot;WKB&quot;})</span>
<span class="gi">+    assert metadata[&quot;columns&quot;][&quot;geometry&quot;][&quot;geometry_types&quot;] == [</span>
<span class="gi">+        &quot;MultiPolygon&quot;,</span>
<span class="gi">+        &quot;Polygon Z&quot;,</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_crs_metadata_datum_ensemble():</span>
<span class="gi">+    pyproj = pytest.importorskip(&quot;pyproj&quot;)</span>
<span class="gi">+    # compatibility for older PROJ versions using PROJJSON with datum ensembles</span>
<span class="gi">+    # https://github.com/geopandas/geopandas/pull/2453</span>
<span class="gi">+    crs = pyproj.CRS(&quot;EPSG:4326&quot;)</span>
<span class="gi">+    crs_json = crs.to_json_dict()</span>
<span class="gi">+    check_ensemble = False</span>
<span class="gi">+    if &quot;datum_ensemble&quot; in crs_json:</span>
<span class="gi">+        # older version of PROJ don&#39;t yet have datum ensembles</span>
<span class="gi">+        check_ensemble = True</span>
<span class="gi">+        assert &quot;id&quot; in crs_json[&quot;datum_ensemble&quot;][&quot;members&quot;][0]</span>
<span class="gi">+    _remove_id_from_member_of_ensembles(crs_json)</span>
<span class="gi">+    if check_ensemble:</span>
<span class="gi">+        assert &quot;id&quot; not in crs_json[&quot;datum_ensemble&quot;][&quot;members&quot;][0]</span>
<span class="gi">+    # ensure roundtrip still results in an equivalent CRS</span>
<span class="gi">+    assert pyproj.CRS(crs_json) == crs</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_write_metadata_invalid_spec_version(tmp_path):</span>
<span class="gi">+    gdf = geopandas.GeoDataFrame(geometry=[box(0, 0, 10, 10)], crs=&quot;EPSG:4326&quot;)</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;schema_version must be one of&quot;):</span>
<span class="gi">+        _create_metadata(gdf, schema_version=&quot;invalid&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(</span>
<span class="gi">+        ValueError,</span>
<span class="gi">+        match=&quot;&#39;geoarrow&#39; encoding is only supported with schema version &gt;= 1.1.0&quot;,</span>
<span class="gi">+    ):</span>
<span class="gi">+        gdf.to_parquet(tmp_path, schema_version=&quot;1.0.0&quot;, geometry_encoding=&quot;geoarrow&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_encode_metadata():</span>
<span class="gi">+    metadata = {&quot;a&quot;: &quot;b&quot;}</span>
<span class="gi">+</span>
<span class="gi">+    expected = b&#39;{&quot;a&quot;: &quot;b&quot;}&#39;</span>
<span class="gi">+    assert _encode_metadata(metadata) == expected</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_decode_metadata():</span>
<span class="gi">+    metadata_str = b&#39;{&quot;a&quot;: &quot;b&quot;}&#39;</span>
<span class="gi">+</span>
<span class="gi">+    expected = {&quot;a&quot;: &quot;b&quot;}</span>
<span class="gi">+    assert _decode_metadata(metadata_str) == expected</span>
<span class="gi">+</span>
<span class="gi">+    assert _decode_metadata(None) is None</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_validate_dataframe(naturalearth_lowres):</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+</span>
<span class="gi">+    # valid: should not raise ValueError</span>
<span class="gi">+    _validate_dataframe(df)</span>
<span class="gi">+    _validate_dataframe(df.set_index(&quot;iso_a3&quot;))</span>
<span class="gi">+</span>
<span class="gi">+    # add column with non-string type</span>
<span class="gi">+    df[0] = 1</span>
<span class="gi">+</span>
<span class="gi">+    # invalid: should raise ValueError</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        _validate_dataframe(df)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        _validate_dataframe(df.set_index(0))</span>
<span class="gi">+</span>
<span class="gi">+    # not a DataFrame: should raise ValueError</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        _validate_dataframe(&quot;not a dataframe&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_validate_geo_metadata_valid():</span>
<span class="gi">+    _validate_geo_metadata(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;primary_column&quot;: &quot;geometry&quot;,</span>
<span class="gi">+            &quot;columns&quot;: {&quot;geometry&quot;: {&quot;crs&quot;: None, &quot;encoding&quot;: &quot;WKB&quot;}},</span>
<span class="gi">+            &quot;schema_version&quot;: &quot;0.1.0&quot;,</span>
<span class="gi">+        }</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    _validate_geo_metadata(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;primary_column&quot;: &quot;geometry&quot;,</span>
<span class="gi">+            &quot;columns&quot;: {&quot;geometry&quot;: {&quot;crs&quot;: None, &quot;encoding&quot;: &quot;WKB&quot;}},</span>
<span class="gi">+            &quot;version&quot;: &quot;&lt;version&gt;&quot;,</span>
<span class="gi">+        }</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    _validate_geo_metadata(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;primary_column&quot;: &quot;geometry&quot;,</span>
<span class="gi">+            &quot;columns&quot;: {</span>
<span class="gi">+                &quot;geometry&quot;: {</span>
<span class="gi">+                    &quot;crs&quot;: {</span>
<span class="gi">+                        # truncated PROJJSON for testing, as PROJJSON contents</span>
<span class="gi">+                        # not validated here</span>
<span class="gi">+                        &quot;id&quot;: {&quot;authority&quot;: &quot;EPSG&quot;, &quot;code&quot;: 4326},</span>
<span class="gi">+                    },</span>
<span class="gi">+                    &quot;encoding&quot;: &quot;point&quot;,</span>
<span class="gi">+                }</span>
<span class="gi">+            },</span>
<span class="gi">+            &quot;version&quot;: &quot;0.4.0&quot;,</span>
<span class="gi">+        }</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;metadata,error&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        (None, &quot;Missing or malformed geo metadata in Parquet/Feather file&quot;),</span>
<span class="gi">+        ({}, &quot;Missing or malformed geo metadata in Parquet/Feather file&quot;),</span>
<span class="gi">+        # missing &quot;version&quot; key:</span>
<span class="gi">+        (</span>
<span class="gi">+            {&quot;primary_column&quot;: &quot;foo&quot;, &quot;columns&quot;: None},</span>
<span class="gi">+            &quot;&#39;geo&#39; metadata in Parquet/Feather file is missing required key&quot;,</span>
<span class="gi">+        ),</span>
<span class="gi">+        # missing &quot;columns&quot; key:</span>
<span class="gi">+        (</span>
<span class="gi">+            {&quot;primary_column&quot;: &quot;foo&quot;, &quot;version&quot;: &quot;&lt;version&gt;&quot;},</span>
<span class="gi">+            &quot;&#39;geo&#39; metadata in Parquet/Feather file is missing required key:&quot;,</span>
<span class="gi">+        ),</span>
<span class="gi">+        # missing &quot;primary_column&quot;</span>
<span class="gi">+        (</span>
<span class="gi">+            {&quot;columns&quot;: [], &quot;version&quot;: &quot;&lt;version&gt;&quot;},</span>
<span class="gi">+            &quot;&#39;geo&#39; metadata in Parquet/Feather file is missing required key:&quot;,</span>
<span class="gi">+        ),</span>
<span class="gi">+        (</span>
<span class="gi">+            {&quot;primary_column&quot;: &quot;foo&quot;, &quot;columns&quot;: [], &quot;version&quot;: &quot;&lt;version&gt;&quot;},</span>
<span class="gi">+            &quot;&#39;columns&#39; in &#39;geo&#39; metadata must be a dict&quot;,</span>
<span class="gi">+        ),</span>
<span class="gi">+        # missing &quot;encoding&quot; for column</span>
<span class="gi">+        (</span>
<span class="gi">+            {&quot;primary_column&quot;: &quot;foo&quot;, &quot;columns&quot;: {&quot;foo&quot;: {}}, &quot;version&quot;: &quot;&lt;version&gt;&quot;},</span>
<span class="gi">+            (</span>
<span class="gi">+                &quot;&#39;geo&#39; metadata in Parquet/Feather file is missing required key &quot;</span>
<span class="gi">+                &quot;&#39;encoding&#39; for column &#39;foo&#39;&quot;</span>
<span class="gi">+            ),</span>
<span class="gi">+        ),</span>
<span class="gi">+        # invalid column encoding</span>
<span class="gi">+        (</span>
<span class="gi">+            {</span>
<span class="gi">+                &quot;primary_column&quot;: &quot;foo&quot;,</span>
<span class="gi">+                &quot;columns&quot;: {&quot;foo&quot;: {&quot;crs&quot;: None, &quot;encoding&quot;: None}},</span>
<span class="gi">+                &quot;version&quot;: &quot;&lt;version&gt;&quot;,</span>
<span class="gi">+            },</span>
<span class="gi">+            &quot;Only WKB geometry encoding&quot;,</span>
<span class="gi">+        ),</span>
<span class="gi">+        (</span>
<span class="gi">+            {</span>
<span class="gi">+                &quot;primary_column&quot;: &quot;foo&quot;,</span>
<span class="gi">+                &quot;columns&quot;: {&quot;foo&quot;: {&quot;crs&quot;: None, &quot;encoding&quot;: &quot;BKW&quot;}},</span>
<span class="gi">+                &quot;version&quot;: &quot;&lt;version&gt;&quot;,</span>
<span class="gi">+            },</span>
<span class="gi">+            &quot;Only WKB geometry encoding&quot;,</span>
<span class="gi">+        ),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_validate_geo_metadata_invalid(metadata, error):</span>
<span class="gi">+    with pytest.raises(ValueError, match=error):</span>
<span class="gi">+        _validate_geo_metadata(metadata)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_validate_geo_metadata_edges():</span>
<span class="gi">+    metadata = {</span>
<span class="gi">+        &quot;primary_column&quot;: &quot;geometry&quot;,</span>
<span class="gi">+        &quot;columns&quot;: {&quot;geometry&quot;: {&quot;crs&quot;: None, &quot;encoding&quot;: &quot;WKB&quot;, &quot;edges&quot;: &quot;spherical&quot;}},</span>
<span class="gi">+        &quot;version&quot;: &quot;1.0.0-beta.1&quot;,</span>
<span class="gi">+    }</span>
<span class="gi">+    with pytest.warns(</span>
<span class="gi">+        UserWarning,</span>
<span class="gi">+        match=&quot;The geo metadata indicate that column &#39;geometry&#39; has spherical edges&quot;,</span>
<span class="gi">+    ):</span>
<span class="gi">+        _validate_geo_metadata(metadata)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_to_parquet_fails_on_invalid_engine(tmpdir):</span>
<span class="gi">+    df = GeoDataFrame(data=[[1, 2, 3]], columns=[&quot;a&quot;, &quot;b&quot;, &quot;a&quot;], geometry=[Point(1, 1)])</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(</span>
<span class="gi">+        ValueError,</span>
<span class="gi">+        match=(</span>
<span class="gi">+            &quot;GeoPandas only supports using pyarrow as the engine for &quot;</span>
<span class="gi">+            &quot;to_parquet: &#39;fastparquet&#39; passed instead.&quot;</span>
<span class="gi">+        ),</span>
<span class="gi">+    ):</span>
<span class="gi">+        df.to_parquet(tmpdir / &quot;test.parquet&quot;, engine=&quot;fastparquet&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@mock.patch(&quot;geopandas.io.arrow._to_parquet&quot;)</span>
<span class="gi">+def test_to_parquet_does_not_pass_engine_along(mock_to_parquet):</span>
<span class="gi">+    df = GeoDataFrame(data=[[1, 2, 3]], columns=[&quot;a&quot;, &quot;b&quot;, &quot;a&quot;], geometry=[Point(1, 1)])</span>
<span class="gi">+    df.to_parquet(&quot;&quot;, engine=&quot;pyarrow&quot;)</span>
<span class="gi">+    # assert that engine keyword is not passed through to _to_parquet (and thus</span>
<span class="gi">+    # parquet.write_table)</span>
<span class="gi">+    mock_to_parquet.assert_called_with(</span>
<span class="gi">+        df,</span>
<span class="gi">+        &quot;&quot;,</span>
<span class="gi">+        compression=&quot;snappy&quot;,</span>
<span class="gi">+        geometry_encoding=&quot;WKB&quot;,</span>
<span class="gi">+        index=None,</span>
<span class="gi">+        schema_version=None,</span>
<span class="gi">+        write_covering_bbox=False,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# TEMPORARY: used to determine if pyarrow fails for roundtripping pandas data</span>
<span class="gi">+# without geometries</span>
<span class="gi">+def test_pandas_parquet_roundtrip1(tmpdir):</span>
<span class="gi">+    df = DataFrame({&quot;a&quot;: [1, 2, 3], &quot;b&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]})</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    df.to_parquet(filename)</span>
<span class="gi">+</span>
<span class="gi">+    pq_df = pd_read_parquet(filename)</span>
<span class="gi">+</span>
<span class="gi">+    assert_frame_equal(df, pq_df)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;test_dataset&quot;, [&quot;naturalearth_lowres&quot;, &quot;naturalearth_cities&quot;, &quot;nybb_filename&quot;]</span>
<span class="gi">+)</span>
<span class="gi">+def test_pandas_parquet_roundtrip2(test_dataset, tmpdir, request):</span>
<span class="gi">+    path = request.getfixturevalue(test_dataset)</span>
<span class="gi">+    df = DataFrame(read_file(path).drop(columns=[&quot;geometry&quot;]))</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    df.to_parquet(filename)</span>
<span class="gi">+</span>
<span class="gi">+    pq_df = pd_read_parquet(filename)</span>
<span class="gi">+</span>
<span class="gi">+    assert_frame_equal(df, pq_df)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;test_dataset&quot;, [&quot;naturalearth_lowres&quot;, &quot;naturalearth_cities&quot;, &quot;nybb_filename&quot;]</span>
<span class="gi">+)</span>
<span class="w"> </span>def test_roundtrip(tmpdir, file_format, test_dataset, request):
<span class="w"> </span>    &quot;&quot;&quot;Writing to parquet should not raise errors, and should not alter original
<span class="w"> </span>    GeoDataFrame
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    path = request.getfixturevalue(test_dataset)</span>
<span class="gi">+    reader, writer = file_format</span>
<span class="gi">+</span>
<span class="gi">+    df = read_file(path)</span>
<span class="gi">+    orig = df.copy()</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    writer(df, filename)</span>
<span class="gi">+</span>
<span class="gi">+    assert os.path.exists(filename)</span>
<span class="gi">+</span>
<span class="gi">+    # make sure that the original data frame is unaltered</span>
<span class="gi">+    assert_geodataframe_equal(df, orig)</span>
<span class="gi">+</span>
<span class="gi">+    # make sure that we can roundtrip the data frame</span>
<span class="gi">+    pq_df = reader(filename)</span>
<span class="gi">+</span>
<span class="gi">+    assert isinstance(pq_df, GeoDataFrame)</span>
<span class="gi">+    assert_geodataframe_equal(df, pq_df)</span>


<span class="w"> </span>def test_index(tmpdir, file_format, naturalearth_lowres):
<span class="w"> </span>    &quot;&quot;&quot;Setting index=`True` should preserve index in output, and
<span class="w"> </span>    setting index=`False` should drop index from output.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    reader, writer = file_format</span>
<span class="gi">+</span>
<span class="gi">+    df = read_file(naturalearth_lowres).set_index(&quot;iso_a3&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test_with_index.pq&quot;)</span>
<span class="gi">+    writer(df, filename, index=True)</span>
<span class="gi">+    pq_df = reader(filename)</span>
<span class="gi">+    assert_geodataframe_equal(df, pq_df)</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;drop_index.pq&quot;)</span>
<span class="gi">+    writer(df, filename, index=False)</span>
<span class="gi">+    pq_df = reader(filename)</span>
<span class="gi">+    assert_geodataframe_equal(df.reset_index(drop=True), pq_df)</span>


<span class="w"> </span>def test_column_order(tmpdir, file_format, naturalearth_lowres):
<span class="w"> </span>    &quot;&quot;&quot;The order of columns should be preserved in the output.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    reader, writer = file_format</span>
<span class="gi">+</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+    df = df.set_index(&quot;iso_a3&quot;)</span>
<span class="gi">+    df[&quot;geom2&quot;] = df.geometry.representative_point()</span>
<span class="gi">+    table = _geopandas_to_arrow(df)</span>
<span class="gi">+    custom_column_order = [</span>
<span class="gi">+        &quot;iso_a3&quot;,</span>
<span class="gi">+        &quot;geom2&quot;,</span>
<span class="gi">+        &quot;pop_est&quot;,</span>
<span class="gi">+        &quot;continent&quot;,</span>
<span class="gi">+        &quot;name&quot;,</span>
<span class="gi">+        &quot;geometry&quot;,</span>
<span class="gi">+        &quot;gdp_md_est&quot;,</span>
<span class="gi">+    ]</span>
<span class="gi">+    table = table.select(custom_column_order)</span>

<span class="gi">+    if reader is read_parquet:</span>
<span class="gi">+        filename = os.path.join(str(tmpdir), &quot;test_column_order.pq&quot;)</span>
<span class="gi">+        pq.write_table(table, filename)</span>
<span class="gi">+    else:</span>
<span class="gi">+        filename = os.path.join(str(tmpdir), &quot;test_column_order.feather&quot;)</span>
<span class="gi">+        feather.write_feather(table, filename)</span>

<span class="gd">-@pytest.mark.parametrize(&#39;compression&#39;, [&#39;snappy&#39;, &#39;gzip&#39;, &#39;brotli&#39;, None])</span>
<span class="gi">+    result = reader(filename)</span>
<span class="gi">+    assert list(result.columns) == custom_column_order[1:]</span>
<span class="gi">+    assert_geodataframe_equal(result, df[custom_column_order[1:]])</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;compression&quot;, [&quot;snappy&quot;, &quot;gzip&quot;, &quot;brotli&quot;, None])</span>
<span class="w"> </span>def test_parquet_compression(compression, tmpdir, naturalearth_lowres):
<span class="w"> </span>    &quot;&quot;&quot;Using compression options should not raise errors, and should
<span class="w"> </span>    return identical GeoDataFrame.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>

<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    df.to_parquet(filename, compression=compression)</span>
<span class="gi">+    pq_df = read_parquet(filename)</span>
<span class="gi">+</span>
<span class="gi">+    assert isinstance(pq_df, GeoDataFrame)</span>
<span class="gi">+    assert_geodataframe_equal(df, pq_df)</span>

<span class="gd">-@pytest.mark.skipif(Version(pyarrow.__version__) &lt; Version(&#39;0.17.0&#39;),</span>
<span class="gd">-    reason=&#39;Feather only supported for pyarrow &gt;= 0.17&#39;)</span>
<span class="gd">-@pytest.mark.parametrize(&#39;compression&#39;, [&#39;uncompressed&#39;, &#39;lz4&#39;, &#39;zstd&#39;])</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(</span>
<span class="gi">+    Version(pyarrow.__version__) &lt; Version(&quot;0.17.0&quot;),</span>
<span class="gi">+    reason=&quot;Feather only supported for pyarrow &gt;= 0.17&quot;,</span>
<span class="gi">+)</span>
<span class="gi">+@pytest.mark.parametrize(&quot;compression&quot;, [&quot;uncompressed&quot;, &quot;lz4&quot;, &quot;zstd&quot;])</span>
<span class="w"> </span>def test_feather_compression(compression, tmpdir, naturalearth_lowres):
<span class="w"> </span>    &quot;&quot;&quot;Using compression options should not raise errors, and should
<span class="w"> </span>    return identical GeoDataFrame.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.feather&quot;)</span>
<span class="gi">+    df.to_feather(filename, compression=compression)</span>
<span class="gi">+    pq_df = read_feather(filename)</span>
<span class="gi">+</span>
<span class="gi">+    assert isinstance(pq_df, GeoDataFrame)</span>
<span class="gi">+    assert_geodataframe_equal(df, pq_df)</span>


<span class="w"> </span>def test_parquet_multiple_geom_cols(tmpdir, file_format, naturalearth_lowres):
<span class="w"> </span>    &quot;&quot;&quot;If multiple geometry columns are present when written to parquet,
<span class="w"> </span>    they should all be returned as such when read from parquet.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    reader, writer = file_format</span>
<span class="gi">+</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+    df[&quot;geom2&quot;] = df.geometry.copy()</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    writer(df, filename)</span>
<span class="gi">+</span>
<span class="gi">+    assert os.path.exists(filename)</span>
<span class="gi">+</span>
<span class="gi">+    pq_df = reader(filename)</span>
<span class="gi">+</span>
<span class="gi">+    assert isinstance(pq_df, GeoDataFrame)</span>
<span class="gi">+    assert_geodataframe_equal(df, pq_df)</span>
<span class="gi">+</span>
<span class="gi">+    assert_geoseries_equal(df.geom2, pq_df.geom2, check_geom_type=True)</span>


<span class="w"> </span>def test_parquet_missing_metadata(tmpdir, naturalearth_lowres):
<span class="w"> </span>    &quot;&quot;&quot;Missing geo metadata, such as from a parquet file created
<span class="w"> </span>    from a pandas DataFrame, will raise a ValueError.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+</span>
<span class="gi">+    # convert to DataFrame</span>
<span class="gi">+    df = DataFrame(df)</span>
<span class="gi">+</span>
<span class="gi">+    # convert the geometry column so we can extract later</span>
<span class="gi">+    df[&quot;geometry&quot;] = to_wkb(df[&quot;geometry&quot;].values)</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # use pandas to_parquet (no geo metadata)</span>
<span class="gi">+    df.to_parquet(filename)</span>
<span class="gi">+</span>
<span class="gi">+    # missing metadata will raise ValueError</span>
<span class="gi">+    with pytest.raises(</span>
<span class="gi">+        ValueError, match=&quot;Missing geo metadata in Parquet/Feather file.&quot;</span>
<span class="gi">+    ):</span>
<span class="gi">+        read_parquet(filename)</span>


<span class="w"> </span>def test_parquet_missing_metadata2(tmpdir):
<span class="gu">@@ -83,53 +554,340 @@ def test_parquet_missing_metadata2(tmpdir):</span>
<span class="w"> </span>    from a pyarrow Table (which will also not contain pandas metadata),
<span class="w"> </span>    will raise a ValueError.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import pyarrow.parquet as pq</span>

<span class="gi">+    table = pyarrow.table({&quot;a&quot;: [1, 2, 3]})</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>

<span class="gd">-@pytest.mark.parametrize(&#39;geo_meta,error&#39;, [({&#39;geo&#39;: b&#39;&#39;},</span>
<span class="gd">-    &#39;Missing or malformed geo metadata in Parquet/Feather file&#39;), ({&#39;geo&#39;:</span>
<span class="gd">-    _encode_metadata({})},</span>
<span class="gd">-    &#39;Missing or malformed geo metadata in Parquet/Feather file&#39;), ({&#39;geo&#39;:</span>
<span class="gd">-    _encode_metadata({&#39;foo&#39;: &#39;bar&#39;})},</span>
<span class="gd">-    &quot;&#39;geo&#39; metadata in Parquet/Feather file is missing required key&quot;)])</span>
<span class="gd">-def test_parquet_invalid_metadata(tmpdir, geo_meta, error, naturalearth_lowres</span>
<span class="gi">+    # use pyarrow.parquet write_table (no geo metadata, but also no pandas metadata)</span>
<span class="gi">+    pq.write_table(table, filename)</span>
<span class="gi">+</span>
<span class="gi">+    # missing metadata will raise ValueError</span>
<span class="gi">+    with pytest.raises(</span>
<span class="gi">+        ValueError, match=&quot;Missing geo metadata in Parquet/Feather file.&quot;</span>
<span class="w"> </span>    ):
<span class="gi">+        read_parquet(filename)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;geo_meta,error&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        ({&quot;geo&quot;: b&quot;&quot;}, &quot;Missing or malformed geo metadata in Parquet/Feather file&quot;),</span>
<span class="gi">+        (</span>
<span class="gi">+            {&quot;geo&quot;: _encode_metadata({})},</span>
<span class="gi">+            &quot;Missing or malformed geo metadata in Parquet/Feather file&quot;,</span>
<span class="gi">+        ),</span>
<span class="gi">+        (</span>
<span class="gi">+            {&quot;geo&quot;: _encode_metadata({&quot;foo&quot;: &quot;bar&quot;})},</span>
<span class="gi">+            &quot;&#39;geo&#39; metadata in Parquet/Feather file is missing required key&quot;,</span>
<span class="gi">+        ),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_parquet_invalid_metadata(tmpdir, geo_meta, error, naturalearth_lowres):</span>
<span class="w"> </span>    &quot;&quot;&quot;Has geo metadata with missing required fields will raise a ValueError.

<span class="w"> </span>    This requires writing the parquet file directly below, so that we can
<span class="w"> </span>    control the metadata that is written for this test.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    from pyarrow import Table, parquet</span>
<span class="gi">+</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+</span>
<span class="gi">+    # convert to DataFrame and encode geometry to WKB</span>
<span class="gi">+    df = DataFrame(df)</span>
<span class="gi">+    df[&quot;geometry&quot;] = to_wkb(df[&quot;geometry&quot;].values)</span>
<span class="gi">+</span>
<span class="gi">+    table = Table.from_pandas(df)</span>
<span class="gi">+    metadata = table.schema.metadata</span>
<span class="gi">+    metadata.update(geo_meta)</span>
<span class="gi">+    table = table.replace_schema_metadata(metadata)</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    parquet.write_table(table, filename)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ValueError, match=error):</span>
<span class="gi">+        read_parquet(filename)</span>


<span class="w"> </span>def test_subset_columns(tmpdir, file_format, naturalearth_lowres):
<span class="w"> </span>    &quot;&quot;&quot;Reading a subset of columns should correctly decode selected geometry
<span class="w"> </span>    columns.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    reader, writer = file_format</span>
<span class="gi">+</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    writer(df, filename)</span>
<span class="gi">+    pq_df = reader(filename, columns=[&quot;name&quot;, &quot;geometry&quot;])</span>
<span class="gi">+</span>
<span class="gi">+    assert_geodataframe_equal(df[[&quot;name&quot;, &quot;geometry&quot;]], pq_df)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(</span>
<span class="gi">+        ValueError, match=&quot;No geometry columns are included in the columns read&quot;</span>
<span class="gi">+    ):</span>
<span class="gi">+        reader(filename, columns=[&quot;name&quot;])</span>


<span class="w"> </span>def test_promote_secondary_geometry(tmpdir, file_format, naturalearth_lowres):
<span class="w"> </span>    &quot;&quot;&quot;Reading a subset of columns that does not include the primary geometry
<span class="w"> </span>    column should promote the first geometry column present.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    reader, writer = file_format</span>
<span class="gi">+</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+    df[&quot;geom2&quot;] = df.geometry.copy()</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    writer(df, filename)</span>
<span class="gi">+    pq_df = reader(filename, columns=[&quot;name&quot;, &quot;geom2&quot;])</span>
<span class="gi">+</span>
<span class="gi">+    assert_geodataframe_equal(df.set_geometry(&quot;geom2&quot;)[[&quot;name&quot;, &quot;geom2&quot;]], pq_df)</span>
<span class="gi">+</span>
<span class="gi">+    df[&quot;geom3&quot;] = df.geometry.copy()</span>
<span class="gi">+</span>
<span class="gi">+    writer(df, filename)</span>
<span class="gi">+    with pytest.warns(</span>
<span class="gi">+        UserWarning,</span>
<span class="gi">+        match=&quot;Multiple non-primary geometry columns read from Parquet/Feather file.&quot;,</span>
<span class="gi">+    ):</span>
<span class="gi">+        pq_df = reader(filename, columns=[&quot;name&quot;, &quot;geom2&quot;, &quot;geom3&quot;])</span>
<span class="gi">+</span>
<span class="gi">+    assert_geodataframe_equal(</span>
<span class="gi">+        df.set_geometry(&quot;geom2&quot;)[[&quot;name&quot;, &quot;geom2&quot;, &quot;geom3&quot;]], pq_df</span>
<span class="gi">+    )</span>


<span class="w"> </span>def test_columns_no_geometry(tmpdir, file_format, naturalearth_lowres):
<span class="w"> </span>    &quot;&quot;&quot;Reading a parquet file that is missing all of the geometry columns
<span class="w"> </span>    should raise a ValueError&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    reader, writer = file_format</span>
<span class="gi">+</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    writer(df, filename)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        reader(filename, columns=[&quot;name&quot;])</span>


<span class="w"> </span>def test_missing_crs(tmpdir, file_format, naturalearth_lowres):
<span class="w"> </span>    &quot;&quot;&quot;If CRS is `None`, it should be properly handled
<span class="w"> </span>    and remain `None` when read from parquet`.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    reader, writer = file_format</span>
<span class="gi">+</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+    df.geometry.array.crs = None</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    writer(df, filename)</span>
<span class="gi">+    pq_df = reader(filename)</span>
<span class="gi">+</span>
<span class="gi">+    assert pq_df.crs is None</span>
<span class="gi">+</span>
<span class="gi">+    assert_geodataframe_equal(df, pq_df, check_crs=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_default_geo_col_writes(tmp_path):</span>
<span class="gi">+    # edge case geo col name None writes successfully</span>
<span class="gi">+    df = GeoDataFrame({&quot;a&quot;: [1, 2]})</span>
<span class="gi">+    df.to_parquet(tmp_path / &quot;test.pq&quot;)</span>
<span class="gi">+    # cannot be round tripped as gdf due to invalid geom col</span>
<span class="gi">+    pq_df = pd_read_parquet(tmp_path / &quot;test.pq&quot;)</span>
<span class="gi">+    assert_frame_equal(df, pq_df)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(</span>
<span class="gi">+    Version(pyarrow.__version__) &gt;= Version(&quot;0.17.0&quot;),</span>
<span class="gi">+    reason=&quot;Feather only supported for pyarrow &gt;= 0.17&quot;,</span>
<span class="gi">+)</span>
<span class="gi">+def test_feather_arrow_version(tmpdir, naturalearth_lowres):</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.feather&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(</span>
<span class="gi">+        ImportError, match=&quot;pyarrow &gt;= 0.17 required for Feather support&quot;</span>
<span class="gi">+    ):</span>
<span class="gi">+        df.to_feather(filename)</span>


<span class="gd">-@pytest.mark.parametrize(&#39;version&#39;, [&#39;0.1.0&#39;, &#39;0.4.0&#39;, &#39;1.0.0-beta.1&#39;])</span>
<span class="gi">+def test_fsspec_url(naturalearth_lowres):</span>
<span class="gi">+    fsspec = pytest.importorskip(&quot;fsspec&quot;)</span>
<span class="gi">+    import fsspec.implementations.memory</span>
<span class="gi">+</span>
<span class="gi">+    class MyMemoryFileSystem(fsspec.implementations.memory.MemoryFileSystem):</span>
<span class="gi">+        # Simple fsspec filesystem that adds a required keyword.</span>
<span class="gi">+        # Attempting to use this filesystem without the keyword will raise an exception.</span>
<span class="gi">+        def __init__(self, is_set, *args, **kwargs):</span>
<span class="gi">+            self.is_set = is_set</span>
<span class="gi">+            super().__init__(*args, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    fsspec.register_implementation(&quot;memory&quot;, MyMemoryFileSystem, clobber=True)</span>
<span class="gi">+    memfs = MyMemoryFileSystem(is_set=True)</span>
<span class="gi">+</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+</span>
<span class="gi">+    with memfs.open(&quot;data.parquet&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        df.to_parquet(f)</span>
<span class="gi">+</span>
<span class="gi">+    result = read_parquet(&quot;memory://data.parquet&quot;, storage_options={&quot;is_set&quot;: True})</span>
<span class="gi">+    assert_geodataframe_equal(result, df)</span>
<span class="gi">+</span>
<span class="gi">+    result = read_parquet(&quot;memory://data.parquet&quot;, filesystem=memfs)</span>
<span class="gi">+    assert_geodataframe_equal(result, df)</span>
<span class="gi">+</span>
<span class="gi">+    # reset fsspec registry</span>
<span class="gi">+    fsspec.register_implementation(</span>
<span class="gi">+        &quot;memory&quot;, fsspec.implementations.memory.MemoryFileSystem, clobber=True</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_non_fsspec_url_with_storage_options_raises(naturalearth_lowres):</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;storage_options&quot;):</span>
<span class="gi">+        read_parquet(naturalearth_lowres, storage_options={&quot;foo&quot;: &quot;bar&quot;})</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(</span>
<span class="gi">+    Version(pyarrow.__version__) &lt; Version(&quot;5.0.0&quot;),</span>
<span class="gi">+    reason=&quot;pyarrow.fs requires pyarrow&gt;=5.0.0&quot;,</span>
<span class="gi">+)</span>
<span class="gi">+def test_prefers_pyarrow_fs():</span>
<span class="gi">+    filesystem, _ = _get_filesystem_path(&quot;file:///data.parquet&quot;)</span>
<span class="gi">+    assert isinstance(filesystem, pyarrow.fs.LocalFileSystem)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_write_read_parquet_expand_user():</span>
<span class="gi">+    gdf = geopandas.GeoDataFrame(geometry=[box(0, 0, 10, 10)], crs=&quot;epsg:4326&quot;)</span>
<span class="gi">+    test_file = &quot;~/test_file.parquet&quot;</span>
<span class="gi">+    gdf.to_parquet(test_file)</span>
<span class="gi">+    pq_df = geopandas.read_parquet(test_file)</span>
<span class="gi">+    assert_geodataframe_equal(gdf, pq_df, check_crs=True)</span>
<span class="gi">+    os.remove(os.path.expanduser(test_file))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_write_read_feather_expand_user():</span>
<span class="gi">+    gdf = geopandas.GeoDataFrame(geometry=[box(0, 0, 10, 10)], crs=&quot;epsg:4326&quot;)</span>
<span class="gi">+    test_file = &quot;~/test_file.feather&quot;</span>
<span class="gi">+    gdf.to_feather(test_file)</span>
<span class="gi">+    f_df = geopandas.read_feather(test_file)</span>
<span class="gi">+    assert_geodataframe_equal(gdf, f_df, check_crs=True)</span>
<span class="gi">+    os.remove(os.path.expanduser(test_file))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;geometry&quot;, [[], [None]])</span>
<span class="gi">+def test_write_empty_bbox(tmpdir, geometry):</span>
<span class="gi">+    # empty dataframe or all missing geometries -&gt; avoid bbox with NaNs</span>
<span class="gi">+    gdf = geopandas.GeoDataFrame({&quot;col&quot;: [1] * len(geometry)}, geometry=geometry)</span>
<span class="gi">+    gdf.to_parquet(tmpdir / &quot;test.parquet&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    from pyarrow.parquet import read_table</span>
<span class="gi">+</span>
<span class="gi">+    table = read_table(tmpdir / &quot;test.parquet&quot;)</span>
<span class="gi">+    metadata = json.loads(table.schema.metadata[b&quot;geo&quot;])</span>
<span class="gi">+    assert &quot;encoding&quot; in metadata[&quot;columns&quot;][&quot;geometry&quot;]</span>
<span class="gi">+    assert &quot;bbox&quot; not in metadata[&quot;columns&quot;][&quot;geometry&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;format&quot;, [&quot;feather&quot;, &quot;parquet&quot;])</span>
<span class="gi">+def test_write_read_default_crs(tmpdir, format):</span>
<span class="gi">+    pyproj = pytest.importorskip(&quot;pyproj&quot;)</span>
<span class="gi">+    if format == &quot;feather&quot;:</span>
<span class="gi">+        from pyarrow.feather import write_feather as write</span>
<span class="gi">+    else:</span>
<span class="gi">+        from pyarrow.parquet import write_table as write</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), f&quot;test.{format}&quot;)</span>
<span class="gi">+    gdf = geopandas.GeoDataFrame(geometry=[box(0, 0, 10, 10)])</span>
<span class="gi">+    table = _geopandas_to_arrow(gdf)</span>
<span class="gi">+</span>
<span class="gi">+    # update the geo metadata to strip &#39;crs&#39; entry</span>
<span class="gi">+    metadata = table.schema.metadata</span>
<span class="gi">+    geo_metadata = _decode_metadata(metadata[b&quot;geo&quot;])</span>
<span class="gi">+    del geo_metadata[&quot;columns&quot;][&quot;geometry&quot;][&quot;crs&quot;]</span>
<span class="gi">+    metadata.update({b&quot;geo&quot;: _encode_metadata(geo_metadata)})</span>
<span class="gi">+    table = table.replace_schema_metadata(metadata)</span>
<span class="gi">+</span>
<span class="gi">+    write(table, filename)</span>
<span class="gi">+</span>
<span class="gi">+    read = getattr(geopandas, f&quot;read_{format}&quot;)</span>
<span class="gi">+    df = read(filename)</span>
<span class="gi">+    assert df.crs.equals(pyproj.CRS(&quot;OGC:CRS84&quot;))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(shapely.geos_version &lt; (3, 10, 0), reason=&quot;requires GEOS&gt;=3.10&quot;)</span>
<span class="gi">+def test_write_iso_wkb(tmpdir):</span>
<span class="gi">+    gdf = geopandas.GeoDataFrame(</span>
<span class="gi">+        geometry=geopandas.GeoSeries.from_wkt([&quot;POINT Z (1 2 3)&quot;])</span>
<span class="gi">+    )</span>
<span class="gi">+    gdf.to_parquet(tmpdir / &quot;test.parquet&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    from pyarrow.parquet import read_table</span>
<span class="gi">+</span>
<span class="gi">+    table = read_table(tmpdir / &quot;test.parquet&quot;)</span>
<span class="gi">+    wkb = table[&quot;geometry&quot;][0].as_py().hex()</span>
<span class="gi">+</span>
<span class="gi">+    # correct ISO flavor</span>
<span class="gi">+    assert wkb == &quot;01e9030000000000000000f03f00000000000000400000000000000840&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(shapely.geos_version &gt;= (3, 10, 0), reason=&quot;tests GEOS&lt;3.10&quot;)</span>
<span class="gi">+def test_write_iso_wkb_old_geos(tmpdir):</span>
<span class="gi">+    gdf = geopandas.GeoDataFrame(</span>
<span class="gi">+        geometry=geopandas.GeoSeries.from_wkt([&quot;POINT Z (1 2 3)&quot;])</span>
<span class="gi">+    )</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;Cannot write 3D&quot;):</span>
<span class="gi">+        gdf.to_parquet(tmpdir / &quot;test.parquet&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;format,schema_version&quot;,</span>
<span class="gi">+    product([&quot;feather&quot;, &quot;parquet&quot;], [None] + SUPPORTED_VERSIONS),</span>
<span class="gi">+)</span>
<span class="gi">+def test_write_spec_version(tmpdir, format, schema_version):</span>
<span class="gi">+    if format == &quot;feather&quot;:</span>
<span class="gi">+        from pyarrow.feather import read_table</span>
<span class="gi">+    else:</span>
<span class="gi">+        from pyarrow.parquet import read_table</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), f&quot;test.{format}&quot;)</span>
<span class="gi">+    gdf = geopandas.GeoDataFrame(geometry=[box(0, 0, 10, 10)], crs=&quot;EPSG:4326&quot;)</span>
<span class="gi">+    write = getattr(gdf, f&quot;to_{format}&quot;)</span>
<span class="gi">+    write(filename, schema_version=schema_version)</span>
<span class="gi">+</span>
<span class="gi">+    # ensure that we can roundtrip data regardless of version</span>
<span class="gi">+    read = getattr(geopandas, f&quot;read_{format}&quot;)</span>
<span class="gi">+    df = read(filename)</span>
<span class="gi">+    assert_geodataframe_equal(df, gdf)</span>
<span class="gi">+</span>
<span class="gi">+    # verify the correct version is written in the metadata</span>
<span class="gi">+    schema_version = schema_version or METADATA_VERSION</span>
<span class="gi">+    table = read_table(filename)</span>
<span class="gi">+    metadata = json.loads(table.schema.metadata[b&quot;geo&quot;])</span>
<span class="gi">+    assert metadata[&quot;version&quot;] == schema_version</span>
<span class="gi">+</span>
<span class="gi">+    # verify that CRS is correctly handled between versions</span>
<span class="gi">+    if HAS_PYPROJ:</span>
<span class="gi">+        if schema_version == &quot;0.1.0&quot;:</span>
<span class="gi">+            assert metadata[&quot;columns&quot;][&quot;geometry&quot;][&quot;crs&quot;] == gdf.crs.to_wkt()</span>
<span class="gi">+</span>
<span class="gi">+        else:</span>
<span class="gi">+            crs_expected = gdf.crs.to_json_dict()</span>
<span class="gi">+            _remove_id_from_member_of_ensembles(crs_expected)</span>
<span class="gi">+            assert metadata[&quot;columns&quot;][&quot;geometry&quot;][&quot;crs&quot;] == crs_expected</span>
<span class="gi">+</span>
<span class="gi">+    # verify that geometry_type(s) is correctly handled between versions</span>
<span class="gi">+    if Version(schema_version) &lt;= Version(&quot;0.4.0&quot;):</span>
<span class="gi">+        assert &quot;geometry_type&quot; in metadata[&quot;columns&quot;][&quot;geometry&quot;]</span>
<span class="gi">+        assert metadata[&quot;columns&quot;][&quot;geometry&quot;][&quot;geometry_type&quot;] == &quot;Polygon&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        assert &quot;geometry_types&quot; in metadata[&quot;columns&quot;][&quot;geometry&quot;]</span>
<span class="gi">+        assert metadata[&quot;columns&quot;][&quot;geometry&quot;][&quot;geometry_types&quot;] == [&quot;Polygon&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;version&quot;, [&quot;0.1.0&quot;, &quot;0.4.0&quot;, &quot;1.0.0-beta.1&quot;])</span>
<span class="w"> </span>def test_read_versioned_file(version):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Verify that files for different metadata spec versions can be read
<span class="gu">@@ -145,7 +903,17 @@ def test_read_versioned_file(version):</span>
<span class="w"> </span>    df.to_feather(DATA_PATH / &#39;arrow&#39; / f&#39;test_data_v{METADATA_VERSION}.feather&#39;)
<span class="w"> </span>    df.to_parquet(DATA_PATH / &#39;arrow&#39; / f&#39;test_data_v{METADATA_VERSION}.parquet&#39;)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    expected = geopandas.GeoDataFrame(</span>
<span class="gi">+        {&quot;col_str&quot;: [&quot;a&quot;, &quot;b&quot;], &quot;col_int&quot;: [1, 2], &quot;col_float&quot;: [0.1, 0.2]},</span>
<span class="gi">+        geometry=[MultiPolygon([box(0, 0, 1, 1), box(2, 2, 3, 3)]), box(4, 4, 5, 5)],</span>
<span class="gi">+        crs=&quot;EPSG:4326&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    df = geopandas.read_feather(DATA_PATH / &quot;arrow&quot; / f&quot;test_data_v{version}.feather&quot;)</span>
<span class="gi">+    assert_geodataframe_equal(df, expected, check_crs=True)</span>
<span class="gi">+</span>
<span class="gi">+    df = geopandas.read_parquet(DATA_PATH / &quot;arrow&quot; / f&quot;test_data_v{version}.parquet&quot;)</span>
<span class="gi">+    assert_geodataframe_equal(df, expected, check_crs=True)</span>


<span class="w"> </span>def test_read_gdal_files():
<span class="gu">@@ -169,5 +937,396 @@ def test_read_gdal_files():</span>

<span class="w"> </span>    Repeated for GDAL 3.9 which adds a bbox covering column:
<span class="w"> </span>    $ ogr2ogr -f Parquet -lco FID= test_data_gdal390.parquet test_data.gpkg
<span class="gd">-    &quot;&quot;&quot;</span>
<span class="gd">-    pass</span>
<span class="gi">+    &quot;&quot;&quot;  # noqa: E501</span>
<span class="gi">+    pytest.importorskip(&quot;pyproj&quot;)</span>
<span class="gi">+    expected = geopandas.GeoDataFrame(</span>
<span class="gi">+        {&quot;col_str&quot;: [&quot;a&quot;, &quot;b&quot;], &quot;col_int&quot;: [1, 2], &quot;col_float&quot;: [0.1, 0.2]},</span>
<span class="gi">+        geometry=[MultiPolygon([box(0, 0, 1, 1), box(2, 2, 3, 3)]), box(4, 4, 5, 5)],</span>
<span class="gi">+        crs=&quot;EPSG:4326&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    df = geopandas.read_parquet(DATA_PATH / &quot;arrow&quot; / &quot;test_data_gdal350.parquet&quot;)</span>
<span class="gi">+    assert_geodataframe_equal(df, expected, check_crs=True)</span>
<span class="gi">+</span>
<span class="gi">+    df = geopandas.read_feather(DATA_PATH / &quot;arrow&quot; / &quot;test_data_gdal350.arrow&quot;)</span>
<span class="gi">+    assert_geodataframe_equal(df, expected, check_crs=True)</span>
<span class="gi">+</span>
<span class="gi">+    df = geopandas.read_parquet(DATA_PATH / &quot;arrow&quot; / &quot;test_data_gdal390.parquet&quot;)</span>
<span class="gi">+    # recent GDAL no longer writes CRS in metadata in case of EPSG:4326, so comes back</span>
<span class="gi">+    # as default OGC:CRS84</span>
<span class="gi">+    expected = expected.to_crs(&quot;OGC:CRS84&quot;)</span>
<span class="gi">+    assert_geodataframe_equal(df, expected, check_crs=True)</span>
<span class="gi">+</span>
<span class="gi">+    df = geopandas.read_parquet(</span>
<span class="gi">+        DATA_PATH / &quot;arrow&quot; / &quot;test_data_gdal390.parquet&quot;, bbox=(0, 0, 2, 2)</span>
<span class="gi">+    )</span>
<span class="gi">+    assert len(df) == 1</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_parquet_read_partitioned_dataset(tmpdir, naturalearth_lowres):</span>
<span class="gi">+    # we don&#39;t yet explicitly support this (in writing), but for Parquet it</span>
<span class="gi">+    # works for reading (by relying on pyarrow.read_table)</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+</span>
<span class="gi">+    # manually create partitioned dataset</span>
<span class="gi">+    basedir = tmpdir / &quot;partitioned_dataset&quot;</span>
<span class="gi">+    basedir.mkdir()</span>
<span class="gi">+    df[:100].to_parquet(basedir / &quot;data1.parquet&quot;)</span>
<span class="gi">+    df[100:].to_parquet(basedir / &quot;data2.parquet&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    result = read_parquet(basedir)</span>
<span class="gi">+    assert_geodataframe_equal(result, df)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_parquet_read_partitioned_dataset_fsspec(tmpdir, naturalearth_lowres):</span>
<span class="gi">+    fsspec = pytest.importorskip(&quot;fsspec&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+</span>
<span class="gi">+    # manually create partitioned dataset</span>
<span class="gi">+    memfs = fsspec.filesystem(&quot;memory&quot;)</span>
<span class="gi">+    memfs.mkdir(&quot;partitioned_dataset&quot;)</span>
<span class="gi">+    with memfs.open(&quot;partitioned_dataset/data1.parquet&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        df[:100].to_parquet(f)</span>
<span class="gi">+    with memfs.open(&quot;partitioned_dataset/data2.parquet&quot;, &quot;wb&quot;) as f:</span>
<span class="gi">+        df[100:].to_parquet(f)</span>
<span class="gi">+</span>
<span class="gi">+    result = read_parquet(&quot;memory://partitioned_dataset&quot;)</span>
<span class="gi">+    assert_geodataframe_equal(result, df)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;geometry_type&quot;,</span>
<span class="gi">+    [&quot;point&quot;, &quot;linestring&quot;, &quot;polygon&quot;, &quot;multipoint&quot;, &quot;multilinestring&quot;, &quot;multipolygon&quot;],</span>
<span class="gi">+)</span>
<span class="gi">+def test_read_parquet_geoarrow(geometry_type):</span>
<span class="gi">+    result = geopandas.read_parquet(</span>
<span class="gi">+        DATA_PATH</span>
<span class="gi">+        / &quot;arrow&quot;</span>
<span class="gi">+        / &quot;geoparquet&quot;</span>
<span class="gi">+        / f&quot;data-{geometry_type}-encoding_native.parquet&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    expected = geopandas.read_parquet(</span>
<span class="gi">+        DATA_PATH</span>
<span class="gi">+        / &quot;arrow&quot;</span>
<span class="gi">+        / &quot;geoparquet&quot;</span>
<span class="gi">+        / f&quot;data-{geometry_type}-encoding_wkb.parquet&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    assert_geodataframe_equal(result, expected, check_crs=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;geometry_type&quot;,</span>
<span class="gi">+    [&quot;point&quot;, &quot;linestring&quot;, &quot;polygon&quot;, &quot;multipoint&quot;, &quot;multilinestring&quot;, &quot;multipolygon&quot;],</span>
<span class="gi">+)</span>
<span class="gi">+def test_geoarrow_roundtrip(tmp_path, geometry_type):</span>
<span class="gi">+</span>
<span class="gi">+    df = geopandas.read_parquet(</span>
<span class="gi">+        DATA_PATH</span>
<span class="gi">+        / &quot;arrow&quot;</span>
<span class="gi">+        / &quot;geoparquet&quot;</span>
<span class="gi">+        / f&quot;data-{geometry_type}-encoding_wkb.parquet&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    df.to_parquet(tmp_path / &quot;test.parquet&quot;, geometry_encoding=&quot;geoarrow&quot;)</span>
<span class="gi">+    result = geopandas.read_parquet(tmp_path / &quot;test.parquet&quot;)</span>
<span class="gi">+    assert_geodataframe_equal(result, df, check_crs=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_to_parquet_bbox_structure_and_metadata(tmpdir, naturalearth_lowres):</span>
<span class="gi">+    # check metadata being written for covering.</span>
<span class="gi">+    from pyarrow import parquet</span>
<span class="gi">+</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    df.to_parquet(filename, write_covering_bbox=True)</span>
<span class="gi">+</span>
<span class="gi">+    table = parquet.read_table(filename)</span>
<span class="gi">+    metadata = json.loads(table.schema.metadata[b&quot;geo&quot;].decode(&quot;utf-8&quot;))</span>
<span class="gi">+    assert metadata[&quot;columns&quot;][&quot;geometry&quot;][&quot;covering&quot;] == {</span>
<span class="gi">+        &quot;bbox&quot;: {</span>
<span class="gi">+            &quot;xmin&quot;: [&quot;bbox&quot;, &quot;xmin&quot;],</span>
<span class="gi">+            &quot;ymin&quot;: [&quot;bbox&quot;, &quot;ymin&quot;],</span>
<span class="gi">+            &quot;xmax&quot;: [&quot;bbox&quot;, &quot;xmax&quot;],</span>
<span class="gi">+            &quot;ymax&quot;: [&quot;bbox&quot;, &quot;ymax&quot;],</span>
<span class="gi">+        }</span>
<span class="gi">+    }</span>
<span class="gi">+    assert &quot;bbox&quot; in table.schema.names</span>
<span class="gi">+    assert [field.name for field in table.schema.field(&quot;bbox&quot;).type] == [</span>
<span class="gi">+        &quot;xmin&quot;,</span>
<span class="gi">+        &quot;ymin&quot;,</span>
<span class="gi">+        &quot;xmax&quot;,</span>
<span class="gi">+        &quot;ymax&quot;,</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;geometry, expected_bbox&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        (Point(1, 3), {&quot;xmin&quot;: 1.0, &quot;ymin&quot;: 3.0, &quot;xmax&quot;: 1.0, &quot;ymax&quot;: 3.0}),</span>
<span class="gi">+        (</span>
<span class="gi">+            LineString([(1, 1), (3, 3)]),</span>
<span class="gi">+            {&quot;xmin&quot;: 1.0, &quot;ymin&quot;: 1.0, &quot;xmax&quot;: 3.0, &quot;ymax&quot;: 3.0},</span>
<span class="gi">+        ),</span>
<span class="gi">+        (</span>
<span class="gi">+            Polygon([(2, 1), (1, 2), (2, 3), (3, 2)]),</span>
<span class="gi">+            {&quot;xmin&quot;: 1.0, &quot;ymin&quot;: 1.0, &quot;xmax&quot;: 3.0, &quot;ymax&quot;: 3.0},</span>
<span class="gi">+        ),</span>
<span class="gi">+        (</span>
<span class="gi">+            MultiPolygon([box(0, 0, 1, 1), box(2, 2, 3, 3), box(4, 4, 5, 5)]),</span>
<span class="gi">+            {&quot;xmin&quot;: 0.0, &quot;ymin&quot;: 0.0, &quot;xmax&quot;: 5.0, &quot;ymax&quot;: 5.0},</span>
<span class="gi">+        ),</span>
<span class="gi">+    ],</span>
<span class="gi">+    ids=[&quot;Point&quot;, &quot;LineString&quot;, &quot;Polygon&quot;, &quot;Multipolygon&quot;],</span>
<span class="gi">+)</span>
<span class="gi">+def test_to_parquet_bbox_values(tmpdir, geometry, expected_bbox):</span>
<span class="gi">+    # check bbox bounds being written for different geometry types.</span>
<span class="gi">+    import pyarrow.parquet as pq</span>
<span class="gi">+</span>
<span class="gi">+    df = GeoDataFrame(data=[[1, 2]], columns=[&quot;a&quot;, &quot;b&quot;], geometry=[geometry])</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    df.to_parquet(filename, write_covering_bbox=True)</span>
<span class="gi">+</span>
<span class="gi">+    result = pq.read_table(filename).to_pandas()</span>
<span class="gi">+    assert result[&quot;bbox&quot;][0] == expected_bbox</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_parquet_bbox_single_point(tmpdir):</span>
<span class="gi">+    # confirm that on a single point, bbox will pick it up.</span>
<span class="gi">+    df = GeoDataFrame(data=[[1, 2]], columns=[&quot;a&quot;, &quot;b&quot;], geometry=[Point(1, 1)])</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    df.to_parquet(filename, write_covering_bbox=True)</span>
<span class="gi">+    pq_df = read_parquet(filename, bbox=(1, 1, 1, 1))</span>
<span class="gi">+    assert len(pq_df) == 1</span>
<span class="gi">+    assert pq_df.geometry[0] == Point(1, 1)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;geometry_name&quot;, [&quot;geometry&quot;, &quot;custum_geom_col&quot;])</span>
<span class="gi">+def test_read_parquet_bbox(tmpdir, naturalearth_lowres, geometry_name):</span>
<span class="gi">+    # check bbox is being used to filter results.</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+    if geometry_name != &quot;geometry&quot;:</span>
<span class="gi">+        df = df.rename_geometry(geometry_name)</span>
<span class="gi">+</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    df.to_parquet(filename, write_covering_bbox=True)</span>
<span class="gi">+</span>
<span class="gi">+    pq_df = read_parquet(filename, bbox=(0, 0, 10, 10))</span>
<span class="gi">+</span>
<span class="gi">+    assert pq_df[&quot;name&quot;].values.tolist() == [</span>
<span class="gi">+        &quot;France&quot;,</span>
<span class="gi">+        &quot;Benin&quot;,</span>
<span class="gi">+        &quot;Nigeria&quot;,</span>
<span class="gi">+        &quot;Cameroon&quot;,</span>
<span class="gi">+        &quot;Togo&quot;,</span>
<span class="gi">+        &quot;Ghana&quot;,</span>
<span class="gi">+        &quot;Burkina Faso&quot;,</span>
<span class="gi">+        &quot;Gabon&quot;,</span>
<span class="gi">+        &quot;Eq. Guinea&quot;,</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;geometry_name&quot;, [&quot;geometry&quot;, &quot;custum_geom_col&quot;])</span>
<span class="gi">+def test_read_parquet_bbox_partitioned(tmpdir, naturalearth_lowres, geometry_name):</span>
<span class="gi">+    # check bbox is being used to filter results on partioned data.</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+    if geometry_name != &quot;geometry&quot;:</span>
<span class="gi">+        df = df.rename_geometry(geometry_name)</span>
<span class="gi">+</span>
<span class="gi">+    # manually create partitioned dataset</span>
<span class="gi">+    basedir = tmpdir / &quot;partitioned_dataset&quot;</span>
<span class="gi">+    basedir.mkdir()</span>
<span class="gi">+    df[:100].to_parquet(basedir / &quot;data1.parquet&quot;, write_covering_bbox=True)</span>
<span class="gi">+    df[100:].to_parquet(basedir / &quot;data2.parquet&quot;, write_covering_bbox=True)</span>
<span class="gi">+</span>
<span class="gi">+    pq_df = read_parquet(basedir, bbox=(0, 0, 10, 10))</span>
<span class="gi">+</span>
<span class="gi">+    assert pq_df[&quot;name&quot;].values.tolist() == [</span>
<span class="gi">+        &quot;France&quot;,</span>
<span class="gi">+        &quot;Benin&quot;,</span>
<span class="gi">+        &quot;Nigeria&quot;,</span>
<span class="gi">+        &quot;Cameroon&quot;,</span>
<span class="gi">+        &quot;Togo&quot;,</span>
<span class="gi">+        &quot;Ghana&quot;,</span>
<span class="gi">+        &quot;Burkina Faso&quot;,</span>
<span class="gi">+        &quot;Gabon&quot;,</span>
<span class="gi">+        &quot;Eq. Guinea&quot;,</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;geometry, bbox&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        (LineString([(1, 1), (3, 3)]), (1.5, 1.5, 3.5, 3.5)),</span>
<span class="gi">+        (LineString([(1, 1), (3, 3)]), (3, 3, 3, 3)),</span>
<span class="gi">+        (LineString([(1, 1), (3, 3)]), (1.5, 1.5, 2.5, 2.5)),</span>
<span class="gi">+        (Polygon([(0, 0), (4, 0), (4, 4), (0, 4)]), (1, 1, 3, 3)),</span>
<span class="gi">+        (Polygon([(0, 0), (4, 0), (4, 4), (0, 4)]), (1, 1, 5, 5)),</span>
<span class="gi">+        (Polygon([(0, 0), (4, 0), (4, 4), (0, 4)]), (2, 2, 4, 4)),</span>
<span class="gi">+        (Polygon([(0, 0), (4, 0), (4, 4), (0, 4)]), (4, 4, 4, 4)),</span>
<span class="gi">+        (Polygon([(0, 0), (4, 0), (4, 4), (0, 4)]), (1, 1, 5, 3)),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_read_parquet_bbox_partial_overlap_of_geometry(tmpdir, geometry, bbox):</span>
<span class="gi">+    df = GeoDataFrame(data=[[1, 2]], columns=[&quot;a&quot;, &quot;b&quot;], geometry=[geometry])</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    df.to_parquet(filename, write_covering_bbox=True)</span>
<span class="gi">+</span>
<span class="gi">+    pq_df = read_parquet(filename, bbox=bbox)</span>
<span class="gi">+    assert len(pq_df) == 1</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_parquet_no_bbox(tmpdir, naturalearth_lowres):</span>
<span class="gi">+    # check error message when parquet lacks a bbox column but</span>
<span class="gi">+    # want to use bbox kwarg in read_parquet.</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    df.to_parquet(filename)</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;Specifying &#39;bbox&#39; not supported&quot;):</span>
<span class="gi">+        read_parquet(filename, bbox=(0, 0, 20, 20))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_parquet_no_bbox_partitioned(tmpdir, naturalearth_lowres):</span>
<span class="gi">+    # check error message when partitioned parquet data does not have</span>
<span class="gi">+    # a bbox column but want to use kwarg to read_parquet.</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+</span>
<span class="gi">+    # manually create partitioned dataset</span>
<span class="gi">+    basedir = tmpdir / &quot;partitioned_dataset&quot;</span>
<span class="gi">+    basedir.mkdir()</span>
<span class="gi">+    df[:100].to_parquet(basedir / &quot;data1.parquet&quot;)</span>
<span class="gi">+    df[100:].to_parquet(basedir / &quot;data2.parquet&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;Specifying &#39;bbox&#39; not supported&quot;):</span>
<span class="gi">+        read_parquet(basedir, bbox=(0, 0, 20, 20))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_convert_bbox_to_parquet_filter():</span>
<span class="gi">+    # check conversion of bbox to parquet filter expression</span>
<span class="gi">+    import pyarrow.compute as pc</span>
<span class="gi">+</span>
<span class="gi">+    bbox = (0, 0, 25, 35)</span>
<span class="gi">+    expected = ~(</span>
<span class="gi">+        (pc.field((&quot;bbox&quot;, &quot;xmin&quot;)) &gt; 25)</span>
<span class="gi">+        | (pc.field((&quot;bbox&quot;, &quot;ymin&quot;)) &gt; 35)</span>
<span class="gi">+        | (pc.field((&quot;bbox&quot;, &quot;xmax&quot;)) &lt; 0)</span>
<span class="gi">+        | (pc.field((&quot;bbox&quot;, &quot;ymax&quot;)) &lt; 0)</span>
<span class="gi">+    )</span>
<span class="gi">+    assert expected.equals(_convert_bbox_to_parquet_filter(bbox, &quot;bbox&quot;))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_parquet_bbox_column_default_behaviour(tmpdir, naturalearth_lowres):</span>
<span class="gi">+    # check that bbox column is not read in by default</span>
<span class="gi">+</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    df.to_parquet(filename, write_covering_bbox=True)</span>
<span class="gi">+    result1 = read_parquet(filename)</span>
<span class="gi">+    assert &quot;bbox&quot; not in result1</span>
<span class="gi">+</span>
<span class="gi">+    result2 = read_parquet(filename, columns=[&quot;name&quot;, &quot;geometry&quot;])</span>
<span class="gi">+    assert &quot;bbox&quot; not in result2</span>
<span class="gi">+    assert list(result2.columns) == [&quot;name&quot;, &quot;geometry&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;filters&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        [(&quot;gdp_md_est&quot;, &quot;&gt;&quot;, 20000)],</span>
<span class="gi">+        pc.field(&quot;gdp_md_est&quot;) &gt; 20000,</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_read_parquet_filters_and_bbox(tmpdir, naturalearth_lowres, filters):</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    df.to_parquet(filename, write_covering_bbox=True)</span>
<span class="gi">+</span>
<span class="gi">+    result = read_parquet(filename, filters=filters, bbox=(0, 0, 20, 20))</span>
<span class="gi">+    assert result[&quot;name&quot;].values.tolist() == [</span>
<span class="gi">+        &quot;Dem. Rep. Congo&quot;,</span>
<span class="gi">+        &quot;France&quot;,</span>
<span class="gi">+        &quot;Nigeria&quot;,</span>
<span class="gi">+        &quot;Cameroon&quot;,</span>
<span class="gi">+        &quot;Ghana&quot;,</span>
<span class="gi">+        &quot;Algeria&quot;,</span>
<span class="gi">+        &quot;Libya&quot;,</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;filters&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        ([(&quot;gdp_md_est&quot;, &quot;&gt;&quot;, 15000), (&quot;gdp_md_est&quot;, &quot;&lt;&quot;, 16000)]),</span>
<span class="gi">+        ((pc.field(&quot;gdp_md_est&quot;) &gt; 15000) &amp; (pc.field(&quot;gdp_md_est&quot;) &lt; 16000)),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_read_parquet_filters_without_bbox(tmpdir, naturalearth_lowres, filters):</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+    df.to_parquet(filename, write_covering_bbox=True)</span>
<span class="gi">+</span>
<span class="gi">+    result = read_parquet(filename, filters=filters)</span>
<span class="gi">+    assert result[&quot;name&quot;].values.tolist() == [&quot;Burkina Faso&quot;, &quot;Mozambique&quot;, &quot;Albania&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_parquet_file_with_custom_bbox_encoding_fieldname(tmpdir):</span>
<span class="gi">+    import pyarrow.parquet as pq</span>
<span class="gi">+</span>
<span class="gi">+    data = {</span>
<span class="gi">+        &quot;name&quot;: [&quot;point1&quot;, &quot;point2&quot;, &quot;point3&quot;],</span>
<span class="gi">+        &quot;geometry&quot;: [Point(1, 1), Point(2, 2), Point(3, 3)],</span>
<span class="gi">+    }</span>
<span class="gi">+    df = GeoDataFrame(data)</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    table = _geopandas_to_arrow(</span>
<span class="gi">+        df,</span>
<span class="gi">+        schema_version=&quot;1.1.0&quot;,</span>
<span class="gi">+        write_covering_bbox=True,</span>
<span class="gi">+    )</span>
<span class="gi">+    metadata = table.schema.metadata  # rename_columns results in wiping of metadata</span>
<span class="gi">+</span>
<span class="gi">+    table = table.rename_columns([&quot;name&quot;, &quot;geometry&quot;, &quot;custom_bbox_name&quot;])</span>
<span class="gi">+</span>
<span class="gi">+    geo_metadata = json.loads(metadata[b&quot;geo&quot;])</span>
<span class="gi">+    geo_metadata[&quot;columns&quot;][&quot;geometry&quot;][&quot;covering&quot;][&quot;bbox&quot;] = {</span>
<span class="gi">+        &quot;xmin&quot;: [&quot;custom_bbox_name&quot;, &quot;xmin&quot;],</span>
<span class="gi">+        &quot;ymin&quot;: [&quot;custom_bbox_name&quot;, &quot;ymin&quot;],</span>
<span class="gi">+        &quot;xmax&quot;: [&quot;custom_bbox_name&quot;, &quot;xmax&quot;],</span>
<span class="gi">+        &quot;ymax&quot;: [&quot;custom_bbox_name&quot;, &quot;ymax&quot;],</span>
<span class="gi">+    }</span>
<span class="gi">+    metadata.update({b&quot;geo&quot;: _encode_metadata(geo_metadata)})</span>
<span class="gi">+</span>
<span class="gi">+    table = table.replace_schema_metadata(metadata)</span>
<span class="gi">+    pq.write_table(table, filename)</span>
<span class="gi">+</span>
<span class="gi">+    pq_table = pq.read_table(filename)</span>
<span class="gi">+    assert &quot;custom_bbox_name&quot; in pq_table.schema.names</span>
<span class="gi">+</span>
<span class="gi">+    pq_df = read_parquet(filename, bbox=(1.5, 1.5, 2.5, 2.5))</span>
<span class="gi">+    assert pq_df[&quot;name&quot;].values.tolist() == [&quot;point2&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_to_parquet_with_existing_bbox_column(tmpdir, naturalearth_lowres):</span>
<span class="gi">+    df = read_file(naturalearth_lowres)</span>
<span class="gi">+    df = df.assign(bbox=[0] * len(df))</span>
<span class="gi">+    filename = os.path.join(str(tmpdir), &quot;test.pq&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(</span>
<span class="gi">+        ValueError, match=&quot;An existing column &#39;bbox&#39; already exists in the dataframe&quot;</span>
<span class="gi">+    ):</span>
<span class="gi">+        df.to_parquet(filename, write_covering_bbox=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_parquet_bbox_points(tmp_path):</span>
<span class="gi">+    # check bbox filtering on point geometries</span>
<span class="gi">+    df = geopandas.GeoDataFrame(</span>
<span class="gi">+        {&quot;col&quot;: range(10)}, geometry=[Point(i, i) for i in range(10)]</span>
<span class="gi">+    )</span>
<span class="gi">+    df.to_parquet(tmp_path / &quot;test.parquet&quot;, geometry_encoding=&quot;geoarrow&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    result = geopandas.read_parquet(tmp_path / &quot;test.parquet&quot;, bbox=(0, 0, 10, 10))</span>
<span class="gi">+    assert len(result) == 10</span>
<span class="gi">+    result = geopandas.read_parquet(tmp_path / &quot;test.parquet&quot;, bbox=(3, 3, 5, 5))</span>
<span class="gi">+    assert len(result) == 3</span>
<span class="gh">diff --git a/geopandas/io/tests/test_file.py b/geopandas/io/tests/test_file.py</span>
<span class="gh">index c64ca09a..014b1f3c 100644</span>
<span class="gd">--- a/geopandas/io/tests/test_file.py</span>
<span class="gi">+++ b/geopandas/io/tests/test_file.py</span>
<span class="gu">@@ -7,93 +7,412 @@ import shutil</span>
<span class="w"> </span>import tempfile
<span class="w"> </span>from collections import OrderedDict
<span class="w"> </span>from packaging.version import Version
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>import pandas as pd
<span class="w"> </span>import pytz
<span class="w"> </span>from pandas.api.types import is_datetime64_any_dtype
<span class="gi">+</span>
<span class="w"> </span>from shapely.geometry import Point, Polygon, box, mapping
<span class="gi">+</span>
<span class="w"> </span>import geopandas
<span class="w"> </span>from geopandas import GeoDataFrame, read_file
<span class="w"> </span>from geopandas._compat import HAS_PYPROJ, PANDAS_GE_20, PANDAS_GE_30
<span class="w"> </span>from geopandas.io.file import _EXTENSION_TO_DRIVER, _detect_driver
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="w"> </span>from geopandas.testing import assert_geodataframe_equal, assert_geoseries_equal
<span class="w"> </span>from geopandas.tests.util import PACKAGE_DIR, validate_boro_df
<span class="w"> </span>from pandas.testing import assert_frame_equal, assert_series_equal
<span class="gi">+</span>
<span class="w"> </span>try:
<span class="w"> </span>    import pyogrio
<span class="gd">-    PYOGRIO_GE_090 = Version(Version(pyogrio.__version__).base_version</span>
<span class="gd">-        ) &gt;= Version(&#39;0.9.0&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    # those version checks have to be defined here instead of imported from</span>
<span class="gi">+    # geopandas.io.file (those are only initialized lazily on first usage)</span>
<span class="gi">+    PYOGRIO_GE_090 = Version(Version(pyogrio.__version__).base_version) &gt;= Version(</span>
<span class="gi">+        &quot;0.9.0&quot;</span>
<span class="gi">+    )</span>
<span class="w"> </span>except ImportError:
<span class="w"> </span>    pyogrio = False
<span class="w"> </span>    PYOGRIO_GE_090 = False
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>try:
<span class="w"> </span>    import fiona
<span class="gd">-    FIONA_GE_19 = Version(Version(fiona.__version__).base_version) &gt;= Version(</span>
<span class="gd">-        &#39;1.9.0&#39;)</span>
<span class="gi">+</span>
<span class="gi">+    FIONA_GE_19 = Version(Version(fiona.__version__).base_version) &gt;= Version(&quot;1.9.0&quot;)</span>
<span class="w"> </span>except ImportError:
<span class="w"> </span>    fiona = False
<span class="w"> </span>    FIONA_GE_19 = False
<span class="gd">-PYOGRIO_MARK = pytest.mark.skipif(not pyogrio, reason=&#39;pyogrio not installed&#39;)</span>
<span class="gd">-FIONA_MARK = pytest.mark.skipif(not fiona, reason=&#39;fiona not installed&#39;)</span>
<span class="gd">-_CRS = &#39;epsg:4326&#39;</span>
<span class="gd">-pytestmark = pytest.mark.filterwarnings(&#39;ignore:Value:RuntimeWarning:pyogrio&#39;)</span>
<span class="gd">-driver_ext_pairs = [(&#39;ESRI Shapefile&#39;, &#39;.shp&#39;), (&#39;GeoJSON&#39;, &#39;.geojson&#39;), (</span>
<span class="gd">-    &#39;GPKG&#39;, &#39;.gpkg&#39;), (None, &#39;.shp&#39;), (None, &#39;&#39;), (None, &#39;.geojson&#39;), (None,</span>
<span class="gd">-    &#39;.gpkg&#39;)]</span>


<span class="gd">-@pytest.mark.parametrize(&#39;driver,ext&#39;, driver_ext_pairs)</span>
<span class="gi">+PYOGRIO_MARK = pytest.mark.skipif(not pyogrio, reason=&quot;pyogrio not installed&quot;)</span>
<span class="gi">+FIONA_MARK = pytest.mark.skipif(not fiona, reason=&quot;fiona not installed&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+_CRS = &quot;epsg:4326&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+pytestmark = pytest.mark.filterwarnings(&quot;ignore:Value:RuntimeWarning:pyogrio&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture(</span>
<span class="gi">+    params=[</span>
<span class="gi">+        pytest.param(&quot;fiona&quot;, marks=FIONA_MARK),</span>
<span class="gi">+        pytest.param(&quot;pyogrio&quot;, marks=PYOGRIO_MARK),</span>
<span class="gi">+    ]</span>
<span class="gi">+)</span>
<span class="gi">+def engine(request):</span>
<span class="gi">+    return request.param</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def skip_pyogrio_not_supported(engine):</span>
<span class="gi">+    if engine == &quot;pyogrio&quot;:</span>
<span class="gi">+        pytest.skip(&quot;not supported for the pyogrio engine&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def df_nybb(engine, nybb_filename):</span>
<span class="gi">+    df = read_file(nybb_filename, engine=engine)</span>
<span class="gi">+    return df</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def df_null():</span>
<span class="gi">+    return read_file(</span>
<span class="gi">+        os.path.join(PACKAGE_DIR, &quot;geopandas&quot;, &quot;tests&quot;, &quot;data&quot;, &quot;null_geom.geojson&quot;)</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def file_path():</span>
<span class="gi">+    return os.path.join(PACKAGE_DIR, &quot;geopandas&quot;, &quot;tests&quot;, &quot;data&quot;, &quot;null_geom.geojson&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def df_points():</span>
<span class="gi">+    N = 10</span>
<span class="gi">+    crs = _CRS</span>
<span class="gi">+    df = GeoDataFrame(</span>
<span class="gi">+        [</span>
<span class="gi">+            {&quot;geometry&quot;: Point(x, y), &quot;value1&quot;: x + y, &quot;value2&quot;: x * y}</span>
<span class="gi">+            for x, y in zip(range(N), range(N))</span>
<span class="gi">+        ],</span>
<span class="gi">+        crs=crs,</span>
<span class="gi">+    )</span>
<span class="gi">+    return df</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# -----------------------------------------------------------------------------</span>
<span class="gi">+# to_file tests</span>
<span class="gi">+# -----------------------------------------------------------------------------</span>
<span class="gi">+</span>
<span class="gi">+driver_ext_pairs = [</span>
<span class="gi">+    (&quot;ESRI Shapefile&quot;, &quot;.shp&quot;),</span>
<span class="gi">+    (&quot;GeoJSON&quot;, &quot;.geojson&quot;),</span>
<span class="gi">+    (&quot;GPKG&quot;, &quot;.gpkg&quot;),</span>
<span class="gi">+    (None, &quot;.shp&quot;),</span>
<span class="gi">+    (None, &quot;&quot;),</span>
<span class="gi">+    (None, &quot;.geojson&quot;),</span>
<span class="gi">+    (None, &quot;.gpkg&quot;),</span>
<span class="gi">+]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def assert_correct_driver(file_path, ext, engine):</span>
<span class="gi">+    # check the expected driver</span>
<span class="gi">+    expected_driver = &quot;ESRI Shapefile&quot; if ext == &quot;&quot; else _EXTENSION_TO_DRIVER[ext]</span>
<span class="gi">+</span>
<span class="gi">+    if engine == &quot;fiona&quot;:</span>
<span class="gi">+        with fiona.open(str(file_path)) as fds:</span>
<span class="gi">+            assert fds.driver == expected_driver</span>
<span class="gi">+    else:</span>
<span class="gi">+        # TODO pyogrio doesn&#39;t yet provide a way to check the driver of a file</span>
<span class="gi">+        return</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;driver,ext&quot;, driver_ext_pairs)</span>
<span class="w"> </span>def test_to_file(tmpdir, df_nybb, df_null, driver, ext, engine):
<span class="w"> </span>    &quot;&quot;&quot;Test to_file and from_file&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;boros.&quot; + ext)</span>
<span class="gi">+    df_nybb.to_file(tempfilename, driver=driver, engine=engine)</span>
<span class="gi">+    # Read layer back in</span>
<span class="gi">+    df = GeoDataFrame.from_file(tempfilename, engine=engine)</span>
<span class="gi">+    assert &quot;geometry&quot; in df</span>
<span class="gi">+    assert len(df) == 5</span>
<span class="gi">+    assert np.all(df[&quot;BoroName&quot;].values == df_nybb[&quot;BoroName&quot;])</span>

<span class="gi">+    # Write layer with null geometry out to file</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;null_geom&quot; + ext)</span>
<span class="gi">+    df_null.to_file(tempfilename, driver=driver, engine=engine)</span>
<span class="gi">+    # Read layer back in</span>
<span class="gi">+    df = GeoDataFrame.from_file(tempfilename, engine=engine)</span>
<span class="gi">+    assert &quot;geometry&quot; in df</span>
<span class="gi">+    assert len(df) == 2</span>
<span class="gi">+    assert np.all(df[&quot;Name&quot;].values == df_null[&quot;Name&quot;])</span>
<span class="gi">+    # check the expected driver</span>
<span class="gi">+    assert_correct_driver(tempfilename, ext, engine)</span>

<span class="gd">-@pytest.mark.parametrize(&#39;driver,ext&#39;, driver_ext_pairs)</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;driver,ext&quot;, driver_ext_pairs)</span>
<span class="w"> </span>def test_to_file_pathlib(tmpdir, df_nybb, driver, ext, engine):
<span class="w"> </span>    &quot;&quot;&quot;Test to_file and from_file&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    temppath = pathlib.Path(os.path.join(str(tmpdir), &quot;boros.&quot; + ext))</span>
<span class="gi">+    df_nybb.to_file(temppath, driver=driver, engine=engine)</span>
<span class="gi">+    # Read layer back in</span>
<span class="gi">+    df = GeoDataFrame.from_file(temppath, engine=engine)</span>
<span class="gi">+    assert &quot;geometry&quot; in df</span>
<span class="gi">+    assert len(df) == 5</span>
<span class="gi">+    assert np.all(df[&quot;BoroName&quot;].values == df_nybb[&quot;BoroName&quot;])</span>
<span class="gi">+    # check the expected driver</span>
<span class="gi">+    assert_correct_driver(temppath, ext, engine)</span>


<span class="gd">-@pytest.mark.parametrize(&#39;driver,ext&#39;, driver_ext_pairs)</span>
<span class="gi">+@pytest.mark.parametrize(&quot;driver,ext&quot;, driver_ext_pairs)</span>
<span class="w"> </span>def test_to_file_bool(tmpdir, driver, ext, engine):
<span class="w"> </span>    &quot;&quot;&quot;Test error raise when writing with a boolean column (GH #437).&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;temp.{0}&quot;.format(ext))</span>
<span class="gi">+    df = GeoDataFrame(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;col&quot;: [True, False, True],</span>
<span class="gi">+            &quot;geometry&quot;: [Point(0, 0), Point(1, 1), Point(2, 2)],</span>
<span class="gi">+        },</span>
<span class="gi">+        crs=4326,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    df.to_file(tempfilename, driver=driver, engine=engine)</span>
<span class="gi">+    result = read_file(tempfilename, engine=engine)</span>
<span class="gi">+    if ext in (&quot;.shp&quot;, &quot;&quot;):</span>
<span class="gi">+        # Shapefile does not support boolean, so is read back as int</span>
<span class="gi">+        # but since GDAL 3.9 supports boolean fields in SHP</span>
<span class="gi">+        if engine == &quot;fiona&quot; and fiona.gdal_version.minor &lt; 9:</span>
<span class="gi">+            df[&quot;col&quot;] = df[&quot;col&quot;].astype(&quot;int64&quot;)</span>
<span class="gi">+        elif engine == &quot;pyogrio&quot; and pyogrio.__gdal_version__ &lt; (3, 9):</span>
<span class="gi">+            df[&quot;col&quot;] = df[&quot;col&quot;].astype(&quot;int32&quot;)</span>
<span class="gi">+    assert_geodataframe_equal(result, df)</span>
<span class="gi">+    # check the expected driver</span>
<span class="gi">+    assert_correct_driver(tempfilename, ext, engine)</span>


<span class="w"> </span>TEST_DATE = datetime.datetime(2021, 11, 21, 1, 7, 43, 17500)
<span class="gd">-eastern = pytz.timezone(&#39;America/New_York&#39;)</span>
<span class="gd">-datetime_type_tests = TEST_DATE, eastern.localize(TEST_DATE)</span>
<span class="gi">+eastern = pytz.timezone(&quot;America/New_York&quot;)</span>
<span class="gi">+</span>
<span class="gi">+datetime_type_tests = (TEST_DATE, eastern.localize(TEST_DATE))</span>


<span class="w"> </span>@pytest.mark.filterwarnings(
<span class="gd">-    &#39;ignore:Non-conformant content for record 1 in column b:RuntimeWarning&#39;)</span>
<span class="gd">-@pytest.mark.parametrize(&#39;time&#39;, datetime_type_tests, ids=(&#39;naive_datetime&#39;,</span>
<span class="gd">-    &#39;datetime_with_timezone&#39;))</span>
<span class="gd">-@pytest.mark.parametrize(&#39;driver,ext&#39;, driver_ext_pairs)</span>
<span class="gi">+    &quot;ignore:Non-conformant content for record 1 in column b:RuntimeWarning&quot;</span>
<span class="gi">+)  # for GPKG, GDAL writes the tz data but warns on reading (see DATETIME_FORMAT option)</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;time&quot;, datetime_type_tests, ids=(&quot;naive_datetime&quot;, &quot;datetime_with_timezone&quot;)</span>
<span class="gi">+)</span>
<span class="gi">+@pytest.mark.parametrize(&quot;driver,ext&quot;, driver_ext_pairs)</span>
<span class="w"> </span>def test_to_file_datetime(tmpdir, driver, ext, time, engine):
<span class="w"> </span>    &quot;&quot;&quot;Test writing a data file with the datetime column type&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if ext in (&quot;.shp&quot;, &quot;&quot;):</span>
<span class="gi">+        pytest.skip(f&quot;Driver corresponding to ext {ext} doesn&#39;t support dt fields&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), f&quot;test_datetime{ext}&quot;)</span>
<span class="gi">+    point = Point(0, 0)</span>
<span class="gi">+</span>
<span class="gi">+    df = GeoDataFrame(</span>
<span class="gi">+        {&quot;a&quot;: [1.0, 2.0], &quot;b&quot;: [time, time]}, geometry=[point, point], crs=4326</span>
<span class="gi">+    )</span>
<span class="gi">+    df[&quot;b&quot;] = df[&quot;b&quot;].dt.round(freq=&quot;ms&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    df.to_file(tempfilename, driver=driver, engine=engine)</span>
<span class="gi">+    df_read = read_file(tempfilename, engine=engine)</span>
<span class="gi">+</span>
<span class="gi">+    assert_geodataframe_equal(df.drop(columns=[&quot;b&quot;]), df_read.drop(columns=[&quot;b&quot;]))</span>
<span class="gi">+    # Check datetime column</span>
<span class="gi">+    expected = df[&quot;b&quot;]</span>
<span class="gi">+    if PANDAS_GE_20:</span>
<span class="gi">+        expected = df[&quot;b&quot;].dt.as_unit(&quot;ms&quot;)</span>
<span class="gi">+    actual = df_read[&quot;b&quot;]</span>
<span class="gi">+    if df[&quot;b&quot;].dt.tz is not None:</span>
<span class="gi">+        # US/Eastern becomes pytz.FixedOffset(-300) when read from file</span>
<span class="gi">+        # as GDAL only models offsets, not timezones.</span>
<span class="gi">+        # Compare fair result in terms of UTC instead</span>
<span class="gi">+        expected = expected.dt.tz_convert(pytz.utc)</span>
<span class="gi">+        actual = actual.dt.tz_convert(pytz.utc)</span>
<span class="gi">+</span>
<span class="gi">+    assert_series_equal(expected, actual)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+dt_exts = [&quot;gpkg&quot;, &quot;geojson&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def write_invalid_date_file(date_str, tmpdir, ext, engine):</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), f&quot;test_invalid_datetime.{ext}&quot;)</span>
<span class="gi">+    df = GeoDataFrame(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;date&quot;: [&quot;2014-08-26T10:01:23&quot;, &quot;2014-08-26T10:01:23&quot;, date_str],</span>
<span class="gi">+            &quot;geometry&quot;: [Point(1, 1), Point(1, 1), Point(1, 1)],</span>
<span class="gi">+        }</span>
<span class="gi">+    )</span>
<span class="gi">+    # Schema not required for GeoJSON since not typed, but needed for GPKG</span>
<span class="gi">+    if ext == &quot;geojson&quot;:</span>
<span class="gi">+        df.to_file(tempfilename, engine=engine)</span>
<span class="gi">+    else:</span>
<span class="gi">+        schema = {&quot;geometry&quot;: &quot;Point&quot;, &quot;properties&quot;: {&quot;date&quot;: &quot;datetime&quot;}}</span>
<span class="gi">+        if engine == &quot;pyogrio&quot; and not fiona:</span>
<span class="gi">+            # (use schema to write the invalid date without pandas datetimes</span>
<span class="gi">+            pytest.skip(&quot;test requires fiona kwarg schema&quot;)</span>
<span class="gi">+        df.to_file(tempfilename, schema=schema, engine=&quot;fiona&quot;)</span>
<span class="gi">+    return tempfilename</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;ext&quot;, dt_exts)</span>
<span class="gi">+def test_read_file_datetime_invalid(tmpdir, ext, engine):</span>
<span class="gi">+    # https://github.com/geopandas/geopandas/issues/2502</span>
<span class="gi">+    date_str = &quot;9999-99-99T00:00:00&quot;  # invalid date handled by GDAL</span>
<span class="gi">+    tempfilename = write_invalid_date_file(date_str, tmpdir, ext, engine)</span>
<span class="gi">+    res = read_file(tempfilename, engine=engine)</span>
<span class="gi">+    if ext == &quot;gpkg&quot;:</span>
<span class="gi">+        assert is_datetime64_any_dtype(res[&quot;date&quot;])</span>
<span class="gi">+        assert pd.isna(res[&quot;date&quot;].iloc[-1])</span>
<span class="gi">+    else:</span>
<span class="gi">+        assert res[&quot;date&quot;].dtype == &quot;object&quot;</span>
<span class="gi">+        assert isinstance(res[&quot;date&quot;].iloc[-1], str)</span>
<span class="gi">+</span>

<span class="gi">+@pytest.mark.parametrize(&quot;ext&quot;, dt_exts)</span>
<span class="gi">+def test_read_file_datetime_out_of_bounds_ns(tmpdir, ext, engine):</span>
<span class="gi">+    if engine == &quot;pyogrio&quot; and not PANDAS_GE_20:</span>
<span class="gi">+        pytest.skip(&quot;with pyogrio requires pandas &gt;= 2.0 to pass&quot;)</span>
<span class="gi">+    # https://github.com/geopandas/geopandas/issues/2502</span>
<span class="gi">+    date_str = &quot;9999-12-31T00:00:00&quot;  # valid to GDAL, not to [ns] format</span>
<span class="gi">+    tempfilename = write_invalid_date_file(date_str, tmpdir, ext, engine)</span>
<span class="gi">+    res = read_file(tempfilename, engine=engine)</span>
<span class="gi">+    if PANDAS_GE_30:</span>
<span class="gi">+        assert res[&quot;date&quot;].dtype == &quot;datetime64[ms]&quot;</span>
<span class="gi">+        assert res[&quot;date&quot;].iloc[-1] == pd.Timestamp(&quot;9999-12-31 00:00:00&quot;)</span>
<span class="gi">+    else:</span>
<span class="gi">+        # Pandas invalid datetimes are read in as object dtype (strings)</span>
<span class="gi">+        assert res[&quot;date&quot;].dtype == &quot;object&quot;</span>
<span class="gi">+        assert isinstance(res[&quot;date&quot;].iloc[0], str)</span>

<span class="gd">-dt_exts = [&#39;gpkg&#39;, &#39;geojson&#39;]</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_datetime_mixed_offsets(tmpdir):</span>
<span class="gi">+    # https://github.com/geopandas/geopandas/issues/2478</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;test_mixed_datetime.geojson&quot;)</span>
<span class="gi">+    df = GeoDataFrame(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;date&quot;: [</span>
<span class="gi">+                &quot;2014-08-26 10:01:23.040001+02:00&quot;,</span>
<span class="gi">+                &quot;2019-03-07 17:31:43.118999+01:00&quot;,</span>
<span class="gi">+            ],</span>
<span class="gi">+            &quot;geometry&quot;: [Point(1, 1), Point(1, 1)],</span>
<span class="gi">+        }</span>
<span class="gi">+    )</span>
<span class="gi">+    df.to_file(tempfilename)</span>
<span class="gi">+    # check mixed tz don&#39;t crash GH2478</span>
<span class="gi">+    res = read_file(tempfilename)</span>
<span class="gi">+    # Convert mixed timezones to UTC equivalent</span>
<span class="gi">+    assert is_datetime64_any_dtype(res[&quot;date&quot;])</span>
<span class="gi">+    if not PANDAS_GE_20:</span>
<span class="gi">+        utc = pytz.utc</span>
<span class="gi">+    else:</span>
<span class="gi">+        utc = datetime.timezone.utc</span>
<span class="gi">+    assert res[&quot;date&quot;].dt.tz == utc</span>


<span class="gd">-@pytest.mark.parametrize(&#39;driver,ext&#39;, driver_ext_pairs)</span>
<span class="gi">+@pytest.mark.parametrize(&quot;driver,ext&quot;, driver_ext_pairs)</span>
<span class="w"> </span>def test_to_file_with_point_z(tmpdir, ext, driver, engine):
<span class="w"> </span>    &quot;&quot;&quot;Test that 3D geometries are retained in writes (GH #612).&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;test_3Dpoint&quot; + ext)</span>
<span class="gi">+    point3d = Point(0, 0, 500)</span>
<span class="gi">+    point2d = Point(1, 1)</span>
<span class="gi">+    df = GeoDataFrame({&quot;a&quot;: [1, 2]}, geometry=[point3d, point2d], crs=_CRS)</span>
<span class="gi">+    df.to_file(tempfilename, driver=driver, engine=engine)</span>
<span class="gi">+    df_read = GeoDataFrame.from_file(tempfilename, engine=engine)</span>
<span class="gi">+    assert_geoseries_equal(df.geometry, df_read.geometry)</span>
<span class="gi">+    # check the expected driver</span>
<span class="gi">+    assert_correct_driver(tempfilename, ext, engine)</span>


<span class="gd">-@pytest.mark.parametrize(&#39;driver,ext&#39;, driver_ext_pairs)</span>
<span class="gi">+@pytest.mark.parametrize(&quot;driver,ext&quot;, driver_ext_pairs)</span>
<span class="w"> </span>def test_to_file_with_poly_z(tmpdir, ext, driver, engine):
<span class="w"> </span>    &quot;&quot;&quot;Test that 3D geometries are retained in writes (GH #612).&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;test_3Dpoly&quot; + ext)</span>
<span class="gi">+    poly3d = Polygon([[0, 0, 5], [0, 1, 5], [1, 1, 5], [1, 0, 5]])</span>
<span class="gi">+    poly2d = Polygon([[0, 0], [0, 1], [1, 1], [1, 0]])</span>
<span class="gi">+    df = GeoDataFrame({&quot;a&quot;: [1, 2]}, geometry=[poly3d, poly2d], crs=_CRS)</span>
<span class="gi">+    df.to_file(tempfilename, driver=driver, engine=engine)</span>
<span class="gi">+    df_read = GeoDataFrame.from_file(tempfilename, engine=engine)</span>
<span class="gi">+    assert_geoseries_equal(df.geometry, df_read.geometry)</span>
<span class="gi">+    # check the expected driver</span>
<span class="gi">+    assert_correct_driver(tempfilename, ext, engine)</span>


<span class="w"> </span>def test_to_file_types(tmpdir, df_points, engine):
<span class="w"> </span>    &quot;&quot;&quot;Test various integer type columns (GH#93)&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;int.shp&quot;)</span>
<span class="gi">+    int_types = [</span>
<span class="gi">+        np.int8,</span>
<span class="gi">+        np.int16,</span>
<span class="gi">+        np.int32,</span>
<span class="gi">+        np.int64,</span>
<span class="gi">+        np.intp,</span>
<span class="gi">+        np.uint8,</span>
<span class="gi">+        np.uint16,</span>
<span class="gi">+        np.uint32,</span>
<span class="gi">+        np.uint64,</span>
<span class="gi">+    ]</span>
<span class="gi">+    geometry = df_points.geometry</span>
<span class="gi">+    data = {</span>
<span class="gi">+        str(i): np.arange(len(geometry), dtype=dtype)</span>
<span class="gi">+        for i, dtype in enumerate(int_types)</span>
<span class="gi">+    }</span>
<span class="gi">+    df = GeoDataFrame(data, geometry=geometry)</span>
<span class="gi">+    df.to_file(tempfilename, engine=engine)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;driver,ext&quot;, driver_ext_pairs + [(&quot;OGR_GMT&quot;, &quot;.gmt&quot;)])</span>
<span class="gi">+def test_to_file_int32(tmpdir, df_points, engine, driver, ext):</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), f&quot;int32.{ext}&quot;)</span>
<span class="gi">+    geometry = df_points.geometry</span>
<span class="gi">+    df = GeoDataFrame(geometry=geometry)</span>
<span class="gi">+    df[&quot;data&quot;] = pd.array([1, np.nan] * 5, dtype=pd.Int32Dtype())</span>
<span class="gi">+    df.to_file(tempfilename, driver=driver, engine=engine)</span>
<span class="gi">+    df_read = GeoDataFrame.from_file(tempfilename, engine=engine)</span>
<span class="gi">+    # the int column with missing values comes back as float</span>
<span class="gi">+    expected = df.copy()</span>
<span class="gi">+    expected[&quot;data&quot;] = expected[&quot;data&quot;].astype(&quot;float64&quot;)</span>
<span class="gi">+    assert_geodataframe_equal(df_read, expected, check_like=True)</span>
<span class="gi">+</span>
<span class="gi">+    tempfilename2 = os.path.join(str(tmpdir), f&quot;int32_2.{ext}&quot;)</span>
<span class="gi">+    df2 = df.dropna()</span>
<span class="gi">+    df2.to_file(tempfilename2, driver=driver, engine=engine)</span>
<span class="gi">+    df2_read = GeoDataFrame.from_file(tempfilename2, engine=engine)</span>
<span class="gi">+    if engine == &quot;pyogrio&quot;:</span>
<span class="gi">+        assert df2_read[&quot;data&quot;].dtype == &quot;int32&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        # with the fiona engine the 32 bitwidth is not preserved</span>
<span class="gi">+        assert df2_read[&quot;data&quot;].dtype == &quot;int64&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;driver,ext&quot;, driver_ext_pairs)</span>
<span class="gi">+def test_to_file_int64(tmpdir, df_points, engine, driver, ext):</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), f&quot;int64.{ext}&quot;)</span>
<span class="gi">+    geometry = df_points.geometry</span>
<span class="gi">+    df = GeoDataFrame(geometry=geometry)</span>
<span class="gi">+    df[&quot;data&quot;] = pd.array([1, np.nan] * 5, dtype=pd.Int64Dtype())</span>
<span class="gi">+    df.to_file(tempfilename, driver=driver, engine=engine)</span>
<span class="gi">+    df_read = GeoDataFrame.from_file(tempfilename, engine=engine)</span>
<span class="gi">+    # the int column with missing values comes back as float</span>
<span class="gi">+    expected = df.copy()</span>
<span class="gi">+    expected[&quot;data&quot;] = expected[&quot;data&quot;].astype(&quot;float64&quot;)</span>
<span class="gi">+    assert_geodataframe_equal(df_read, expected, check_like=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_to_file_empty(tmpdir, engine):</span>
<span class="gi">+    input_empty_df = GeoDataFrame(columns=[&quot;geometry&quot;])</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;test.shp&quot;)</span>
<span class="gi">+    with pytest.warns(UserWarning):</span>
<span class="gi">+        input_empty_df.to_file(tempfilename, engine=engine)</span>


<span class="w"> </span>def test_to_file_schema(tmpdir, df_nybb, engine):
<span class="gu">@@ -102,16 +421,61 @@ def test_to_file_schema(tmpdir, df_nybb, engine):</span>
<span class="w"> </span>    if it is specified

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;test.shp&quot;)</span>
<span class="gi">+    properties = OrderedDict(</span>
<span class="gi">+        [</span>
<span class="gi">+            (&quot;Shape_Leng&quot;, &quot;float:19.11&quot;),</span>
<span class="gi">+            (&quot;BoroName&quot;, &quot;str:40&quot;),</span>
<span class="gi">+            (&quot;BoroCode&quot;, &quot;int:10&quot;),</span>
<span class="gi">+            (&quot;Shape_Area&quot;, &quot;float:19.11&quot;),</span>
<span class="gi">+        ]</span>
<span class="gi">+    )</span>
<span class="gi">+    schema = {&quot;geometry&quot;: &quot;Polygon&quot;, &quot;properties&quot;: properties}</span>
<span class="gi">+</span>
<span class="gi">+    if engine == &quot;pyogrio&quot;:</span>
<span class="gi">+        with pytest.raises(ValueError):</span>
<span class="gi">+            df_nybb.iloc[:2].to_file(tempfilename, schema=schema, engine=engine)</span>
<span class="gi">+    else:</span>
<span class="gi">+        # Take the first 2 features to speed things up a bit</span>
<span class="gi">+        df_nybb.iloc[:2].to_file(tempfilename, schema=schema, engine=engine)</span>
<span class="gi">+</span>
<span class="gi">+        import fiona</span>

<span class="gi">+        with fiona.open(tempfilename) as f:</span>
<span class="gi">+            result_schema = f.schema</span>

<span class="gd">-@pytest.mark.skipif(not HAS_PYPROJ, reason=&#39;pyproj not installed&#39;)</span>
<span class="gi">+        assert result_schema == schema</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(not HAS_PYPROJ, reason=&quot;pyproj not installed&quot;)</span>
<span class="w"> </span>def test_to_file_crs(tmpdir, engine, nybb_filename):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Ensure that the file is written according to the crs
<span class="w"> </span>    if it is specified
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    df = read_file(nybb_filename, engine=engine)</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;crs.shp&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # save correct CRS</span>
<span class="gi">+    df.to_file(tempfilename, engine=engine)</span>
<span class="gi">+    result = GeoDataFrame.from_file(tempfilename, engine=engine)</span>
<span class="gi">+    assert result.crs == df.crs</span>
<span class="gi">+</span>
<span class="gi">+    if engine == &quot;pyogrio&quot;:</span>
<span class="gi">+        with pytest.raises(ValueError, match=&quot;Passing &#39;crs&#39; is not supported&quot;):</span>
<span class="gi">+            df.to_file(tempfilename, crs=3857, engine=engine)</span>
<span class="gi">+        return</span>
<span class="gi">+</span>
<span class="gi">+    # overwrite CRS</span>
<span class="gi">+    df.to_file(tempfilename, crs=3857, engine=engine)</span>
<span class="gi">+    result = GeoDataFrame.from_file(tempfilename, engine=engine)</span>
<span class="gi">+    assert result.crs == &quot;epsg:3857&quot;</span>
<span class="gi">+</span>
<span class="gi">+    # specify CRS for gdf without one</span>
<span class="gi">+    df2 = df.set_crs(None, allow_override=True)</span>
<span class="gi">+    df2.to_file(tempfilename, crs=2263, engine=engine)</span>
<span class="gi">+    df = GeoDataFrame.from_file(tempfilename, engine=engine)</span>
<span class="gi">+    assert df.crs == &quot;epsg:2263&quot;</span>


<span class="w"> </span>def test_to_file_column_len(tmpdir, df_points, engine):
<span class="gu">@@ -119,28 +483,643 @@ def test_to_file_column_len(tmpdir, df_points, engine):</span>
<span class="w"> </span>    Ensure that a warning about truncation is given when a geodataframe with
<span class="w"> </span>    column names longer than 10 characters is saved to shapefile
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;test.shp&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    df = df_points.iloc[:1].copy()</span>
<span class="gi">+    df[&quot;0123456789A&quot;] = [&quot;the column name is 11 characters&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.warns(</span>
<span class="gi">+        UserWarning, match=&quot;Column names longer than 10 characters will be truncated&quot;</span>
<span class="gi">+    ):</span>
<span class="gi">+        df.to_file(tempfilename, driver=&quot;ESRI Shapefile&quot;, engine=engine)</span>
<span class="gi">+</span>

<span class="gi">+def test_to_file_with_duplicate_columns(tmpdir, engine):</span>
<span class="gi">+    df = GeoDataFrame(data=[[1, 2, 3]], columns=[&quot;a&quot;, &quot;b&quot;, &quot;a&quot;], geometry=[Point(1, 1)])</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;duplicate.shp&quot;)</span>
<span class="gi">+    with pytest.raises(</span>
<span class="gi">+        ValueError, match=&quot;GeoDataFrame cannot contain duplicated column names.&quot;</span>
<span class="gi">+    ):</span>
<span class="gi">+        df.to_file(tempfilename, engine=engine)</span>

<span class="gd">-@pytest.mark.parametrize(&#39;driver,ext&#39;, driver_ext_pairs)</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;driver,ext&quot;, driver_ext_pairs)</span>
<span class="w"> </span>def test_append_file(tmpdir, df_nybb, df_null, driver, ext, engine):
<span class="w"> </span>    &quot;&quot;&quot;Test to_file with append mode and from_file&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;boros&quot; + ext)</span>
<span class="gi">+    driver = driver if driver else _detect_driver(tempfilename)</span>

<span class="gi">+    df_nybb.to_file(tempfilename, driver=driver, engine=engine)</span>
<span class="gi">+    df_nybb.to_file(tempfilename, mode=&quot;a&quot;, driver=driver, engine=engine)</span>
<span class="gi">+    # Read layer back in</span>
<span class="gi">+    df = GeoDataFrame.from_file(tempfilename, engine=engine)</span>
<span class="gi">+    assert &quot;geometry&quot; in df</span>
<span class="gi">+    assert len(df) == (5 * 2)</span>
<span class="gi">+    expected = pd.concat([df_nybb] * 2, ignore_index=True)</span>
<span class="gi">+    assert_geodataframe_equal(df, expected, check_less_precise=True)</span>

<span class="gd">-@pytest.mark.filterwarnings(&quot;ignore:&#39;crs&#39; was not provided:UserWarning:pyogrio&quot;</span>
<span class="gd">-    )</span>
<span class="gd">-@pytest.mark.parametrize(&#39;driver,ext&#39;, driver_ext_pairs)</span>
<span class="gi">+    if engine == &quot;pyogrio&quot;:</span>
<span class="gi">+        # for pyogrio also ensure append=True works</span>
<span class="gi">+        tempfilename = os.path.join(str(tmpdir), &quot;boros2&quot; + ext)</span>
<span class="gi">+        df_nybb.to_file(tempfilename, driver=driver, engine=engine)</span>
<span class="gi">+        df_nybb.to_file(tempfilename, append=True, driver=driver, engine=engine)</span>
<span class="gi">+        # Read layer back in</span>
<span class="gi">+        df = GeoDataFrame.from_file(tempfilename, engine=engine)</span>
<span class="gi">+        assert len(df) == (len(df_nybb) * 2)</span>
<span class="gi">+</span>
<span class="gi">+    # Write layer with null geometry out to file</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;null_geom&quot; + ext)</span>
<span class="gi">+    df_null.to_file(tempfilename, driver=driver, engine=engine)</span>
<span class="gi">+    df_null.to_file(tempfilename, mode=&quot;a&quot;, driver=driver, engine=engine)</span>
<span class="gi">+    # Read layer back in</span>
<span class="gi">+    df = GeoDataFrame.from_file(tempfilename, engine=engine)</span>
<span class="gi">+    assert &quot;geometry&quot; in df</span>
<span class="gi">+    assert len(df) == (2 * 2)</span>
<span class="gi">+    expected = pd.concat([df_null] * 2, ignore_index=True)</span>
<span class="gi">+    assert_geodataframe_equal(df, expected, check_less_precise=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_mode_unsupported(tmpdir, df_nybb, engine):</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;data.shp&quot;)</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;&#39;mode&#39; should be one of &#39;w&#39; or &#39;a&#39;&quot;):</span>
<span class="gi">+        df_nybb.to_file(tempfilename, mode=&quot;r&quot;, engine=engine)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.filterwarnings(&quot;ignore:&#39;crs&#39; was not provided:UserWarning:pyogrio&quot;)</span>
<span class="gi">+@pytest.mark.parametrize(&quot;driver,ext&quot;, driver_ext_pairs)</span>
<span class="w"> </span>def test_empty_crs(tmpdir, driver, ext, engine):
<span class="w"> </span>    &quot;&quot;&quot;Test handling of undefined CRS with GPKG driver (GH #1975).&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if ext == &quot;.gpkg&quot;:</span>
<span class="gi">+        pytest.xfail(&quot;GPKG is read with Undefined geographic SRS.&quot;)</span>

<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;boros&quot; + ext)</span>
<span class="gi">+    df = GeoDataFrame(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;a&quot;: [1.0, 2.0, 3.0],</span>
<span class="gi">+            &quot;geometry&quot;: [Point(0, 0), Point(1, 1), Point(2, 2)],</span>
<span class="gi">+        },</span>
<span class="gi">+    )</span>

<span class="gd">-NYBB_CRS = &#39;epsg:2263&#39;</span>
<span class="gi">+    df.to_file(tempfilename, driver=driver, engine=engine)</span>
<span class="gi">+    result = read_file(tempfilename, engine=engine)</span>

<span class="gi">+    if ext == &quot;.geojson&quot;:</span>
<span class="gi">+        # geojson by default assumes epsg:4326</span>
<span class="gi">+        df.geometry.array.crs = &quot;EPSG:4326&quot;</span>
<span class="gi">+</span>
<span class="gi">+    assert_geodataframe_equal(result, df)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# -----------------------------------------------------------------------------</span>
<span class="gi">+# read_file tests</span>
<span class="gi">+# -----------------------------------------------------------------------------</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+NYBB_CRS = &quot;epsg:2263&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file(engine, nybb_filename):</span>
<span class="gi">+    df = read_file(nybb_filename, engine=engine)</span>
<span class="gi">+    validate_boro_df(df)</span>
<span class="gi">+    if HAS_PYPROJ:</span>
<span class="gi">+        assert df.crs == NYBB_CRS</span>
<span class="gi">+    expected_columns = [&quot;BoroCode&quot;, &quot;BoroName&quot;, &quot;Shape_Leng&quot;, &quot;Shape_Area&quot;]</span>
<span class="gi">+    assert (df.columns[:-1] == expected_columns).all()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.web</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;url&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        # geojson url</span>
<span class="gi">+        &quot;https://raw.githubusercontent.com/geopandas/geopandas/&quot;</span>
<span class="gi">+        &quot;main/geopandas/tests/data/null_geom.geojson&quot;,</span>
<span class="gi">+        # url to zip file</span>
<span class="gi">+        &quot;https://raw.githubusercontent.com/geopandas/geopandas/&quot;</span>
<span class="gi">+        &quot;main/geopandas/tests/data/nybb_16a.zip&quot;,</span>
<span class="gi">+        # url to zipfile without extension</span>
<span class="gi">+        &quot;https://geonode.goosocean.org/download/480&quot;,</span>
<span class="gi">+        # url to web service</span>
<span class="gi">+        &quot;https://demo.pygeoapi.io/stable/collections/obs/items&quot;,</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_read_file_url(engine, url):</span>
<span class="gi">+    gdf = read_file(url, engine=engine)</span>
<span class="gi">+    assert isinstance(gdf, geopandas.GeoDataFrame)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_local_uri(file_path, engine):</span>
<span class="gi">+    local_uri = &quot;file://&quot; + file_path</span>
<span class="gi">+    gdf = read_file(local_uri, engine=engine)</span>
<span class="gi">+    assert isinstance(gdf, geopandas.GeoDataFrame)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(not HAS_PYPROJ, reason=&quot;pyproj not installed&quot;)</span>
<span class="gi">+def test_read_file_geojson_string_path(engine):</span>
<span class="gi">+    if engine == &quot;pyogrio&quot; and not PYOGRIO_GE_090:</span>
<span class="gi">+        pytest.skip(&quot;fixed in pyogrio 0.9.0&quot;)</span>
<span class="gi">+    expected = GeoDataFrame({&quot;val_with_hash&quot;: [&quot;row # 0&quot;], &quot;geometry&quot;: [Point(0, 1)]})</span>
<span class="gi">+    features = {</span>
<span class="gi">+        &quot;type&quot;: &quot;FeatureCollection&quot;,</span>
<span class="gi">+        &quot;features&quot;: [</span>
<span class="gi">+            {</span>
<span class="gi">+                &quot;type&quot;: &quot;Feature&quot;,</span>
<span class="gi">+                &quot;properties&quot;: {&quot;val_with_hash&quot;: &quot;row # 0&quot;},</span>
<span class="gi">+                &quot;geometry&quot;: {&quot;type&quot;: &quot;Point&quot;, &quot;coordinates&quot;: [0.0, 1.0]},</span>
<span class="gi">+            }</span>
<span class="gi">+        ],</span>
<span class="gi">+    }</span>
<span class="gi">+    df_read = read_file(json.dumps(features))</span>
<span class="gi">+    assert_geodataframe_equal(expected.set_crs(&quot;EPSG:4326&quot;), df_read)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_textio(file_path, engine):</span>
<span class="gi">+    file_text_stream = open(file_path)</span>
<span class="gi">+    file_stringio = io.StringIO(open(file_path).read())</span>
<span class="gi">+    gdf_text_stream = read_file(file_text_stream, engine=engine)</span>
<span class="gi">+    gdf_stringio = read_file(file_stringio, engine=engine)</span>
<span class="gi">+    assert isinstance(gdf_text_stream, geopandas.GeoDataFrame)</span>
<span class="gi">+    assert isinstance(gdf_stringio, geopandas.GeoDataFrame)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_bytesio(file_path, engine):</span>
<span class="gi">+    file_binary_stream = open(file_path, &quot;rb&quot;)</span>
<span class="gi">+    file_bytesio = io.BytesIO(open(file_path, &quot;rb&quot;).read())</span>
<span class="gi">+    gdf_binary_stream = read_file(file_binary_stream, engine=engine)</span>
<span class="gi">+    gdf_bytesio = read_file(file_bytesio, engine=engine)</span>
<span class="gi">+    assert isinstance(gdf_binary_stream, geopandas.GeoDataFrame)</span>
<span class="gi">+    assert isinstance(gdf_bytesio, geopandas.GeoDataFrame)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_raw_stream(file_path, engine):</span>
<span class="gi">+    file_raw_stream = open(file_path, &quot;rb&quot;, buffering=0)</span>
<span class="gi">+    gdf_raw_stream = read_file(file_raw_stream, engine=engine)</span>
<span class="gi">+    assert isinstance(gdf_raw_stream, geopandas.GeoDataFrame)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_pathlib(file_path, engine):</span>
<span class="gi">+    path_object = pathlib.Path(file_path)</span>
<span class="gi">+    gdf_path_object = read_file(path_object, engine=engine)</span>
<span class="gi">+    assert isinstance(gdf_path_object, geopandas.GeoDataFrame)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_tempfile(engine):</span>
<span class="gi">+    temp = tempfile.TemporaryFile()</span>
<span class="gi">+    temp.write(</span>
<span class="gi">+        b&quot;&quot;&quot;</span>
<span class="gi">+    {</span>
<span class="gi">+      &quot;type&quot;: &quot;Feature&quot;,</span>
<span class="gi">+      &quot;geometry&quot;: {</span>
<span class="gi">+        &quot;type&quot;: &quot;Point&quot;,</span>
<span class="gi">+        &quot;coordinates&quot;: [0, 0]</span>
<span class="gi">+      },</span>
<span class="gi">+      &quot;properties&quot;: {</span>
<span class="gi">+        &quot;name&quot;: &quot;Null Island&quot;</span>
<span class="gi">+      }</span>
<span class="gi">+    }</span>
<span class="gi">+    &quot;&quot;&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    temp.seek(0)</span>
<span class="gi">+    gdf_tempfile = geopandas.read_file(temp, engine=engine)</span>
<span class="gi">+    assert isinstance(gdf_tempfile, geopandas.GeoDataFrame)</span>
<span class="gi">+    temp.close()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_binary_file_fsspec(engine, nybb_filename):</span>
<span class="gi">+    fsspec = pytest.importorskip(&quot;fsspec&quot;)</span>
<span class="gi">+    # Remove the zip scheme so fsspec doesn&#39;t open as a zipped file,</span>
<span class="gi">+    # instead we want to read as bytes and let fiona decode it.</span>
<span class="gi">+    path = nybb_filename[6:]</span>
<span class="gi">+    with fsspec.open(path, &quot;rb&quot;) as f:</span>
<span class="gi">+        gdf = read_file(f, engine=engine)</span>
<span class="gi">+        assert isinstance(gdf, geopandas.GeoDataFrame)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_text_file_fsspec(file_path, engine):</span>
<span class="gi">+    fsspec = pytest.importorskip(&quot;fsspec&quot;)</span>
<span class="gi">+    with fsspec.open(file_path, &quot;r&quot;) as f:</span>
<span class="gi">+        gdf = read_file(f, engine=engine)</span>
<span class="gi">+        assert isinstance(gdf, geopandas.GeoDataFrame)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_zipped_file(engine, nybb_filename):</span>
<span class="gi">+    # Remove the zip scheme so that the test for a zipped file can</span>
<span class="gi">+    # check it and add it back.</span>
<span class="gi">+    path = nybb_filename[6:]</span>
<span class="gi">+    gdf = read_file(path, engine=engine)</span>
<span class="gi">+    assert isinstance(gdf, geopandas.GeoDataFrame)</span>
<span class="gi">+</span>
<span class="gi">+    # Check that it can successfully add a zip scheme to a path that already has a</span>
<span class="gi">+    # scheme</span>
<span class="gi">+    gdf = read_file(&quot;file+file://&quot; + path, engine=engine)</span>
<span class="gi">+    assert isinstance(gdf, geopandas.GeoDataFrame)</span>
<span class="gi">+</span>
<span class="gi">+    # Check that it can add a zip scheme for a path that includes a subpath</span>
<span class="gi">+    # within the archive.</span>
<span class="gi">+    gdf = read_file(path + &quot;!nybb.shp&quot;, engine=engine)</span>
<span class="gi">+    assert isinstance(gdf, geopandas.GeoDataFrame)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_allow_legacy_gdal_path(engine, nybb_filename):</span>
<span class="gi">+    # Construct a GDAL-style zip path.</span>
<span class="gi">+    path = &quot;/vsizip/&quot; + nybb_filename[6:]</span>
<span class="gi">+    gdf = read_file(path, engine=engine)</span>
<span class="gi">+    assert isinstance(gdf, geopandas.GeoDataFrame)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(not PYOGRIO_GE_090, reason=&quot;bug fixed in pyogrio 0.9.0&quot;)</span>
<span class="gi">+def test_read_file_with_hash_in_path(engine, nybb_filename, tmp_path):</span>
<span class="gi">+    folder_with_hash = tmp_path / &quot;path with # present&quot;</span>
<span class="gi">+    folder_with_hash.mkdir(exist_ok=True, parents=True)</span>
<span class="gi">+    read_path = folder_with_hash / &quot;nybb.zip&quot;</span>
<span class="gi">+    shutil.copy(nybb_filename[6:], read_path)</span>
<span class="gi">+    gdf = read_file(read_path, engine=engine)</span>
<span class="gi">+    assert isinstance(gdf, geopandas.GeoDataFrame)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_bbox_tuple(df_nybb, engine, nybb_filename):</span>
<span class="gi">+    bbox = (</span>
<span class="gi">+        1031051.7879884212,</span>
<span class="gi">+        224272.49231459625,</span>
<span class="gi">+        1047224.3104931959,</span>
<span class="gi">+        244317.30894023244,</span>
<span class="gi">+    )</span>
<span class="gi">+    filtered_df = read_file(nybb_filename, bbox=bbox, engine=engine)</span>
<span class="gi">+    expected = df_nybb[df_nybb[&quot;BoroName&quot;].isin([&quot;Bronx&quot;, &quot;Queens&quot;])]</span>
<span class="gi">+    assert_geodataframe_equal(filtered_df, expected.reset_index(drop=True))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_bbox_polygon(df_nybb, engine, nybb_filename):</span>
<span class="gi">+    bbox = box(</span>
<span class="gi">+        1031051.7879884212, 224272.49231459625, 1047224.3104931959, 244317.30894023244</span>
<span class="gi">+    )</span>
<span class="gi">+    filtered_df = read_file(nybb_filename, bbox=bbox, engine=engine)</span>
<span class="gi">+    expected = df_nybb[df_nybb[&quot;BoroName&quot;].isin([&quot;Bronx&quot;, &quot;Queens&quot;])]</span>
<span class="gi">+    assert_geodataframe_equal(filtered_df, expected.reset_index(drop=True))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_filtered__rows(df_nybb, engine, nybb_filename):</span>
<span class="gi">+    filtered_df = read_file(nybb_filename, rows=1, engine=engine)</span>
<span class="gi">+    assert_geodataframe_equal(filtered_df, df_nybb.iloc[[0], :])</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_filtered__rows_slice(df_nybb, engine, nybb_filename):</span>
<span class="gi">+    filtered_df = read_file(nybb_filename, rows=slice(1, 3), engine=engine)</span>
<span class="gi">+    assert_geodataframe_equal(filtered_df, df_nybb.iloc[1:3, :].reset_index(drop=True))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.filterwarnings(</span>
<span class="gi">+    &quot;ignore:Layer does not support OLC_FASTFEATURECOUNT:RuntimeWarning&quot;</span>
<span class="gi">+)  # for the slice with -1</span>
<span class="gi">+def test_read_file_filtered__rows_bbox(df_nybb, engine, nybb_filename):</span>
<span class="gi">+    bbox = (</span>
<span class="gi">+        1031051.7879884212,</span>
<span class="gi">+        224272.49231459625,</span>
<span class="gi">+        1047224.3104931959,</span>
<span class="gi">+        244317.30894023244,</span>
<span class="gi">+    )</span>
<span class="gi">+    if engine == &quot;fiona&quot;:</span>
<span class="gi">+        # combination bbox and rows (rows slice applied after bbox filtering!)</span>
<span class="gi">+        filtered_df = read_file(</span>
<span class="gi">+            nybb_filename, bbox=bbox, rows=slice(4, None), engine=engine</span>
<span class="gi">+        )</span>
<span class="gi">+        assert filtered_df.empty</span>
<span class="gi">+</span>
<span class="gi">+    if engine == &quot;pyogrio&quot;:</span>
<span class="gi">+        # TODO: support negative rows in pyogrio</span>
<span class="gi">+        with pytest.raises(</span>
<span class="gi">+            ValueError,</span>
<span class="gi">+            match=&quot;&#39;skip_features&#39; must be between 0 and 1|Negative slice start&quot;,</span>
<span class="gi">+        ):</span>
<span class="gi">+            filtered_df = read_file(</span>
<span class="gi">+                nybb_filename, bbox=bbox, rows=slice(-1, None), engine=engine</span>
<span class="gi">+            )</span>
<span class="gi">+    else:</span>
<span class="gi">+        filtered_df = read_file(</span>
<span class="gi">+            nybb_filename, bbox=bbox, rows=slice(-1, None), engine=engine</span>
<span class="gi">+        )</span>
<span class="gi">+        filtered_df[&quot;BoroCode&quot;] = filtered_df[&quot;BoroCode&quot;].astype(&quot;int64&quot;)</span>
<span class="gi">+        assert_geodataframe_equal(</span>
<span class="gi">+            filtered_df, df_nybb.iloc[4:, :].reset_index(drop=True)</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_filtered_rows_invalid(engine, nybb_filename):</span>
<span class="gi">+    with pytest.raises(TypeError):</span>
<span class="gi">+        read_file(nybb_filename, rows=&quot;not_a_slice&quot;, engine=engine)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file__ignore_geometry(engine, naturalearth_lowres):</span>
<span class="gi">+    pdf = geopandas.read_file(</span>
<span class="gi">+        naturalearth_lowres,</span>
<span class="gi">+        ignore_geometry=True,</span>
<span class="gi">+        engine=engine,</span>
<span class="gi">+    )</span>
<span class="gi">+    assert &quot;geometry&quot; not in pdf.columns</span>
<span class="gi">+    assert isinstance(pdf, pd.DataFrame) and not isinstance(pdf, geopandas.GeoDataFrame)</span>

<span class="gd">-class FileNumber(object):</span>

<span class="gi">+@pytest.mark.filterwarnings(</span>
<span class="gi">+    &quot;ignore:The &#39;include_fields&#39; and &#39;ignore_fields&#39; keywords:DeprecationWarning&quot;</span>
<span class="gi">+)</span>
<span class="gi">+def test_read_file__ignore_fields(engine, naturalearth_lowres):</span>
<span class="gi">+    gdf = geopandas.read_file(</span>
<span class="gi">+        naturalearth_lowres,</span>
<span class="gi">+        ignore_fields=[&quot;pop_est&quot;, &quot;continent&quot;, &quot;iso_a3&quot;, &quot;gdp_md_est&quot;],</span>
<span class="gi">+        engine=engine,</span>
<span class="gi">+    )</span>
<span class="gi">+    assert gdf.columns.tolist() == [&quot;name&quot;, &quot;geometry&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.filterwarnings(</span>
<span class="gi">+    &quot;ignore:The &#39;include_fields&#39; and &#39;ignore_fields&#39; keywords:DeprecationWarning&quot;</span>
<span class="gi">+)</span>
<span class="gi">+def test_read_file__ignore_all_fields(engine, naturalearth_lowres):</span>
<span class="gi">+    gdf = geopandas.read_file(</span>
<span class="gi">+        naturalearth_lowres,</span>
<span class="gi">+        ignore_fields=[&quot;pop_est&quot;, &quot;continent&quot;, &quot;name&quot;, &quot;iso_a3&quot;, &quot;gdp_md_est&quot;],</span>
<span class="gi">+        engine=engine,</span>
<span class="gi">+    )</span>
<span class="gi">+    assert gdf.columns.tolist() == [&quot;geometry&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_missing_geometry(tmpdir, engine):</span>
<span class="gi">+    filename = str(tmpdir / &quot;test.csv&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    expected = pd.DataFrame(</span>
<span class="gi">+        {&quot;col1&quot;: np.array([1, 2, 3], dtype=&quot;int64&quot;), &quot;col2&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]}</span>
<span class="gi">+    )</span>
<span class="gi">+    expected.to_csv(filename, index=False)</span>
<span class="gi">+</span>
<span class="gi">+    df = geopandas.read_file(filename, engine=engine)</span>
<span class="gi">+    # both engines read integers as strings; force back to original type</span>
<span class="gi">+    df[&quot;col1&quot;] = df[&quot;col1&quot;].astype(&quot;int64&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    assert isinstance(df, pd.DataFrame)</span>
<span class="gi">+    assert not isinstance(df, geopandas.GeoDataFrame)</span>
<span class="gi">+</span>
<span class="gi">+    assert_frame_equal(df, expected)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_None_attribute(tmp_path, engine):</span>
<span class="gi">+    # Test added in context of https://github.com/geopandas/geopandas/issues/2901</span>
<span class="gi">+    test_path = tmp_path / &quot;test.gpkg&quot;</span>
<span class="gi">+    gdf = GeoDataFrame(</span>
<span class="gi">+        {&quot;a&quot;: [None, None]}, geometry=[Point(1, 2), Point(3, 4)], crs=4326</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    gdf.to_file(test_path, engine=engine)</span>
<span class="gi">+    read_gdf = read_file(test_path, engine=engine)</span>
<span class="gi">+    assert_geodataframe_equal(gdf, read_gdf)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_csv_dtype(tmpdir, df_nybb):</span>
<span class="gi">+    filename = str(tmpdir / &quot;test.csv&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    df_nybb.to_csv(filename, index=False)</span>
<span class="gi">+    pdf = pd.read_csv(filename, dtype={&quot;geometry&quot;: &quot;geometry&quot;})</span>
<span class="gi">+</span>
<span class="gi">+    assert pdf.geometry.dtype == &quot;geometry&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file__where_filter(engine, naturalearth_lowres):</span>
<span class="gi">+    if FIONA_GE_19 or engine == &quot;pyogrio&quot;:</span>
<span class="gi">+        gdf = geopandas.read_file(</span>
<span class="gi">+            naturalearth_lowres,</span>
<span class="gi">+            where=&quot;continent=&#39;Africa&#39;&quot;,</span>
<span class="gi">+            engine=engine,</span>
<span class="gi">+        )</span>
<span class="gi">+        assert gdf.continent.unique().tolist() == [&quot;Africa&quot;]</span>
<span class="gi">+    else:</span>
<span class="gi">+        with pytest.raises(NotImplementedError):</span>
<span class="gi">+            geopandas.read_file(</span>
<span class="gi">+                naturalearth_lowres,</span>
<span class="gi">+                where=&quot;continent=&#39;Africa&#39;&quot;,</span>
<span class="gi">+                engine=&quot;fiona&quot;,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file__columns(engine, naturalearth_lowres):</span>
<span class="gi">+    if engine == &quot;fiona&quot; and not FIONA_GE_19:</span>
<span class="gi">+        pytest.skip(&quot;columns requires fiona 1.9+&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    gdf = geopandas.read_file(</span>
<span class="gi">+        naturalearth_lowres, columns=[&quot;name&quot;, &quot;pop_est&quot;], engine=engine</span>
<span class="gi">+    )</span>
<span class="gi">+    assert gdf.columns.tolist() == [&quot;name&quot;, &quot;pop_est&quot;, &quot;geometry&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file__columns_empty(engine, naturalearth_lowres):</span>
<span class="gi">+    if engine == &quot;fiona&quot; and not FIONA_GE_19:</span>
<span class="gi">+        pytest.skip(&quot;columns requires fiona 1.9+&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    gdf = geopandas.read_file(naturalearth_lowres, columns=[], engine=engine)</span>
<span class="gi">+    assert gdf.columns.tolist() == [&quot;geometry&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(FIONA_GE_19 or not fiona, reason=&quot;test for fiona &lt; 1.9&quot;)</span>
<span class="gi">+def test_read_file__columns_old_fiona(naturalearth_lowres):</span>
<span class="gi">+    with pytest.raises(NotImplementedError):</span>
<span class="gi">+        geopandas.read_file(</span>
<span class="gi">+            naturalearth_lowres, columns=[&quot;name&quot;, &quot;pop_est&quot;], engine=&quot;fiona&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.filterwarnings(</span>
<span class="gi">+    &quot;ignore:The &#39;include_fields&#39; and &#39;ignore_fields&#39; keywords:DeprecationWarning&quot;</span>
<span class="gi">+)</span>
<span class="gi">+def test_read_file__include_fields(engine, naturalearth_lowres):</span>
<span class="gi">+    if engine == &quot;fiona&quot; and not FIONA_GE_19:</span>
<span class="gi">+        pytest.skip(&quot;columns requires fiona 1.9+&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    gdf = geopandas.read_file(</span>
<span class="gi">+        naturalearth_lowres, include_fields=[&quot;name&quot;, &quot;pop_est&quot;], engine=engine</span>
<span class="gi">+    )</span>
<span class="gi">+    assert gdf.columns.tolist() == [&quot;name&quot;, &quot;pop_est&quot;, &quot;geometry&quot;]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(not FIONA_GE_19, reason=&quot;columns requires fiona 1.9+&quot;)</span>
<span class="gi">+def test_read_file__columns_conflicting_keywords(engine, naturalearth_lowres):</span>
<span class="gi">+    path = naturalearth_lowres</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;Cannot specify both&quot;):</span>
<span class="gi">+        geopandas.read_file(</span>
<span class="gi">+            path, include_fields=[&quot;name&quot;], ignore_fields=[&quot;pop_est&quot;], engine=engine</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;Cannot specify both&quot;):</span>
<span class="gi">+        geopandas.read_file(</span>
<span class="gi">+            path, columns=[&quot;name&quot;], include_fields=[&quot;pop_est&quot;], engine=engine</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;Cannot specify both&quot;):</span>
<span class="gi">+        geopandas.read_file(</span>
<span class="gi">+            path, columns=[&quot;name&quot;], ignore_fields=[&quot;pop_est&quot;], engine=engine</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(not HAS_PYPROJ, reason=&quot;pyproj not installed&quot;)</span>
<span class="gi">+@pytest.mark.parametrize(&quot;file_like&quot;, [False, True])</span>
<span class="gi">+def test_read_file_bbox_gdf(df_nybb, engine, nybb_filename, file_like):</span>
<span class="gi">+    full_df_shape = df_nybb.shape</span>
<span class="gi">+    bbox = geopandas.GeoDataFrame(</span>
<span class="gi">+        geometry=[</span>
<span class="gi">+            box(</span>
<span class="gi">+                1031051.7879884212,</span>
<span class="gi">+                224272.49231459625,</span>
<span class="gi">+                1047224.3104931959,</span>
<span class="gi">+                244317.30894023244,</span>
<span class="gi">+            )</span>
<span class="gi">+        ],</span>
<span class="gi">+        crs=NYBB_CRS,</span>
<span class="gi">+    )</span>
<span class="gi">+    infile = (</span>
<span class="gi">+        open(nybb_filename.replace(&quot;zip://&quot;, &quot;&quot;), &quot;rb&quot;) if file_like else nybb_filename</span>
<span class="gi">+    )</span>
<span class="gi">+    filtered_df = read_file(infile, bbox=bbox, engine=engine)</span>
<span class="gi">+    filtered_df_shape = filtered_df.shape</span>
<span class="gi">+    assert full_df_shape != filtered_df_shape</span>
<span class="gi">+    assert filtered_df_shape == (2, 5)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(not HAS_PYPROJ, reason=&quot;pyproj not installed&quot;)</span>
<span class="gi">+@pytest.mark.parametrize(&quot;file_like&quot;, [False, True])</span>
<span class="gi">+def test_read_file_mask_gdf(df_nybb, engine, nybb_filename, file_like):</span>
<span class="gi">+    full_df_shape = df_nybb.shape</span>
<span class="gi">+    mask = geopandas.GeoDataFrame(</span>
<span class="gi">+        geometry=[</span>
<span class="gi">+            box(</span>
<span class="gi">+                1031051.7879884212,</span>
<span class="gi">+                224272.49231459625,</span>
<span class="gi">+                1047224.3104931959,</span>
<span class="gi">+                244317.30894023244,</span>
<span class="gi">+            )</span>
<span class="gi">+        ],</span>
<span class="gi">+        crs=NYBB_CRS,</span>
<span class="gi">+    )</span>
<span class="gi">+    infile = (</span>
<span class="gi">+        open(nybb_filename.replace(&quot;zip://&quot;, &quot;&quot;), &quot;rb&quot;) if file_like else nybb_filename</span>
<span class="gi">+    )</span>
<span class="gi">+    filtered_df = read_file(infile, mask=mask, engine=engine)</span>
<span class="gi">+    filtered_df_shape = filtered_df.shape</span>
<span class="gi">+    assert full_df_shape != filtered_df_shape</span>
<span class="gi">+    assert filtered_df_shape == (2, 5)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_mask_polygon(df_nybb, engine, nybb_filename):</span>
<span class="gi">+    full_df_shape = df_nybb.shape</span>
<span class="gi">+    mask = box(</span>
<span class="gi">+        1031051.7879884212, 224272.49231459625, 1047224.3104931959, 244317.30894023244</span>
<span class="gi">+    )</span>
<span class="gi">+    filtered_df = read_file(nybb_filename, mask=mask, engine=engine)</span>
<span class="gi">+    filtered_df_shape = filtered_df.shape</span>
<span class="gi">+    assert full_df_shape != filtered_df_shape</span>
<span class="gi">+    assert filtered_df_shape == (2, 5)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_mask_geojson(df_nybb, nybb_filename, engine):</span>
<span class="gi">+    full_df_shape = df_nybb.shape</span>
<span class="gi">+    mask = mapping(</span>
<span class="gi">+        box(</span>
<span class="gi">+            1031051.7879884212,</span>
<span class="gi">+            224272.49231459625,</span>
<span class="gi">+            1047224.3104931959,</span>
<span class="gi">+            244317.30894023244,</span>
<span class="gi">+        )</span>
<span class="gi">+    )</span>
<span class="gi">+    filtered_df = read_file(nybb_filename, mask=mask, engine=engine)</span>
<span class="gi">+    filtered_df_shape = filtered_df.shape</span>
<span class="gi">+    assert full_df_shape != filtered_df_shape</span>
<span class="gi">+    assert filtered_df_shape == (2, 5)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(not HAS_PYPROJ, reason=&quot;pyproj not installed&quot;)</span>
<span class="gi">+def test_read_file_bbox_gdf_mismatched_crs(df_nybb, engine, nybb_filename):</span>
<span class="gi">+    full_df_shape = df_nybb.shape</span>
<span class="gi">+    bbox = geopandas.GeoDataFrame(</span>
<span class="gi">+        geometry=[</span>
<span class="gi">+            box(</span>
<span class="gi">+                1031051.7879884212,</span>
<span class="gi">+                224272.49231459625,</span>
<span class="gi">+                1047224.3104931959,</span>
<span class="gi">+                244317.30894023244,</span>
<span class="gi">+            )</span>
<span class="gi">+        ],</span>
<span class="gi">+        crs=NYBB_CRS,</span>
<span class="gi">+    )</span>
<span class="gi">+    bbox.to_crs(epsg=4326, inplace=True)</span>
<span class="gi">+    filtered_df = read_file(nybb_filename, bbox=bbox, engine=engine)</span>
<span class="gi">+    filtered_df_shape = filtered_df.shape</span>
<span class="gi">+    assert full_df_shape != filtered_df_shape</span>
<span class="gi">+    assert filtered_df_shape == (2, 5)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(not HAS_PYPROJ, reason=&quot;pyproj not installed&quot;)</span>
<span class="gi">+def test_read_file_mask_gdf_mismatched_crs(df_nybb, engine, nybb_filename):</span>
<span class="gi">+    full_df_shape = df_nybb.shape</span>
<span class="gi">+    mask = geopandas.GeoDataFrame(</span>
<span class="gi">+        geometry=[</span>
<span class="gi">+            box(</span>
<span class="gi">+                1031051.7879884212,</span>
<span class="gi">+                224272.49231459625,</span>
<span class="gi">+                1047224.3104931959,</span>
<span class="gi">+                244317.30894023244,</span>
<span class="gi">+            )</span>
<span class="gi">+        ],</span>
<span class="gi">+        crs=NYBB_CRS,</span>
<span class="gi">+    )</span>
<span class="gi">+    mask.to_crs(epsg=4326, inplace=True)</span>
<span class="gi">+    filtered_df = read_file(nybb_filename, mask=mask.geometry, engine=engine)</span>
<span class="gi">+    filtered_df_shape = filtered_df.shape</span>
<span class="gi">+    assert full_df_shape != filtered_df_shape</span>
<span class="gi">+    assert filtered_df_shape == (2, 5)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_read_file_bbox_mask_not_allowed(engine, nybb_filename):</span>
<span class="gi">+    bbox = (</span>
<span class="gi">+        1031051.7879884212,</span>
<span class="gi">+        224272.49231459625,</span>
<span class="gi">+        1047224.3104931959,</span>
<span class="gi">+        244317.30894023244,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    mask = box(*bbox)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;mask and bbox can not be set together&quot;):</span>
<span class="gi">+        read_file(nybb_filename, bbox=bbox, mask=mask)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.filterwarnings(</span>
<span class="gi">+    &quot;ignore:Layer &#39;b&#39;test_empty&#39;&#39; does not have any features:UserWarning&quot;</span>
<span class="gi">+)</span>
<span class="gi">+def test_read_file_empty_shapefile(tmpdir, engine):</span>
<span class="gi">+    if engine == &quot;pyogrio&quot; and not fiona:</span>
<span class="gi">+        pytest.skip(&quot;test requires fiona to work&quot;)</span>
<span class="gi">+    from geopandas.io.file import fiona_env</span>
<span class="gi">+</span>
<span class="gi">+    # create empty shapefile</span>
<span class="gi">+    meta = {</span>
<span class="gi">+        &quot;crs&quot;: {},</span>
<span class="gi">+        &quot;crs_wkt&quot;: &quot;&quot;,</span>
<span class="gi">+        &quot;driver&quot;: &quot;ESRI Shapefile&quot;,</span>
<span class="gi">+        &quot;schema&quot;: {</span>
<span class="gi">+            &quot;geometry&quot;: &quot;Point&quot;,</span>
<span class="gi">+            &quot;properties&quot;: OrderedDict([(&quot;A&quot;, &quot;int:9&quot;), (&quot;Z&quot;, &quot;float:24.15&quot;)]),</span>
<span class="gi">+        },</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+    fname = str(tmpdir.join(&quot;test_empty.shp&quot;))</span>
<span class="gi">+</span>
<span class="gi">+    with fiona_env():</span>
<span class="gi">+        with fiona.open(fname, &quot;w&quot;, **meta) as _:</span>
<span class="gi">+            pass</span>
<span class="gi">+</span>
<span class="gi">+    empty = read_file(fname, engine=engine)</span>
<span class="gi">+    assert isinstance(empty, geopandas.GeoDataFrame)</span>
<span class="gi">+    assert all(empty.columns == [&quot;A&quot;, &quot;Z&quot;, &quot;geometry&quot;])</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+class FileNumber(object):</span>
<span class="w"> </span>    def __init__(self, tmpdir, base, ext):
<span class="w"> </span>        self.tmpdir = str(tmpdir)
<span class="w"> </span>        self.base = base
<span class="gu">@@ -148,9 +1127,312 @@ class FileNumber(object):</span>
<span class="w"> </span>        self.fileno = 0

<span class="w"> </span>    def __repr__(self):
<span class="gd">-        filename = &#39;{0}{1:02d}.{2}&#39;.format(self.base, self.fileno, self.ext)</span>
<span class="gi">+        filename = &quot;{0}{1:02d}.{2}&quot;.format(self.base, self.fileno, self.ext)</span>
<span class="w"> </span>        return os.path.join(self.tmpdir, filename)

<span class="w"> </span>    def __next__(self):
<span class="w"> </span>        self.fileno += 1
<span class="w"> </span>        return repr(self)
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;driver,ext&quot;, [(&quot;ESRI Shapefile&quot;, &quot;shp&quot;), (&quot;GeoJSON&quot;, &quot;geojson&quot;)]</span>
<span class="gi">+)</span>
<span class="gi">+def test_write_index_to_file(tmpdir, df_points, driver, ext, engine):</span>
<span class="gi">+    fngen = FileNumber(tmpdir, &quot;check&quot;, ext)</span>
<span class="gi">+</span>
<span class="gi">+    def do_checks(df, index_is_used):</span>
<span class="gi">+        # check combinations of index=None|True|False on GeoDataFrame/GeoSeries</span>
<span class="gi">+        other_cols = list(df.columns)</span>
<span class="gi">+        other_cols.remove(&quot;geometry&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        if driver == &quot;ESRI Shapefile&quot;:</span>
<span class="gi">+            # ESRI Shapefile will add FID if no other columns exist</span>
<span class="gi">+            driver_col = [&quot;FID&quot;]</span>
<span class="gi">+        else:</span>
<span class="gi">+            driver_col = []</span>
<span class="gi">+</span>
<span class="gi">+        if index_is_used:</span>
<span class="gi">+            index_cols = list(df.index.names)</span>
<span class="gi">+        else:</span>
<span class="gi">+            index_cols = [None] * len(df.index.names)</span>
<span class="gi">+</span>
<span class="gi">+        # replicate pandas&#39; default index names for regular and MultiIndex</span>
<span class="gi">+        if index_cols == [None]:</span>
<span class="gi">+            index_cols = [&quot;index&quot;]</span>
<span class="gi">+        elif len(index_cols) &gt; 1 and not all(index_cols):</span>
<span class="gi">+            for level, index_col in enumerate(index_cols):</span>
<span class="gi">+                if index_col is None:</span>
<span class="gi">+                    index_cols[level] = &quot;level_&quot; + str(level)</span>
<span class="gi">+</span>
<span class="gi">+        # check GeoDataFrame with default index=None to autodetect</span>
<span class="gi">+        tempfilename = next(fngen)</span>
<span class="gi">+        df.to_file(tempfilename, driver=driver, index=None, engine=engine)</span>
<span class="gi">+        df_check = read_file(tempfilename, engine=engine)</span>
<span class="gi">+        if len(other_cols) == 0:</span>
<span class="gi">+            expected_cols = driver_col[:]</span>
<span class="gi">+        else:</span>
<span class="gi">+            expected_cols = []</span>
<span class="gi">+        if index_is_used:</span>
<span class="gi">+            expected_cols += index_cols</span>
<span class="gi">+        expected_cols += other_cols + [&quot;geometry&quot;]</span>
<span class="gi">+        assert list(df_check.columns) == expected_cols</span>
<span class="gi">+</span>
<span class="gi">+        # similar check on GeoSeries with index=None</span>
<span class="gi">+        tempfilename = next(fngen)</span>
<span class="gi">+        df.geometry.to_file(tempfilename, driver=driver, index=None, engine=engine)</span>
<span class="gi">+        df_check = read_file(tempfilename, engine=engine)</span>
<span class="gi">+        if index_is_used:</span>
<span class="gi">+            expected_cols = index_cols + [&quot;geometry&quot;]</span>
<span class="gi">+        else:</span>
<span class="gi">+            expected_cols = driver_col + [&quot;geometry&quot;]</span>
<span class="gi">+        assert list(df_check.columns) == expected_cols</span>
<span class="gi">+</span>
<span class="gi">+        # check GeoDataFrame with index=True</span>
<span class="gi">+        tempfilename = next(fngen)</span>
<span class="gi">+        df.to_file(tempfilename, driver=driver, index=True, engine=engine)</span>
<span class="gi">+        df_check = read_file(tempfilename, engine=engine)</span>
<span class="gi">+        assert list(df_check.columns) == index_cols + other_cols + [&quot;geometry&quot;]</span>
<span class="gi">+</span>
<span class="gi">+        # similar check on GeoSeries with index=True</span>
<span class="gi">+        tempfilename = next(fngen)</span>
<span class="gi">+        df.geometry.to_file(tempfilename, driver=driver, index=True, engine=engine)</span>
<span class="gi">+        df_check = read_file(tempfilename, engine=engine)</span>
<span class="gi">+        assert list(df_check.columns) == index_cols + [&quot;geometry&quot;]</span>
<span class="gi">+</span>
<span class="gi">+        # check GeoDataFrame with index=False</span>
<span class="gi">+        tempfilename = next(fngen)</span>
<span class="gi">+        df.to_file(tempfilename, driver=driver, index=False, engine=engine)</span>
<span class="gi">+        df_check = read_file(tempfilename, engine=engine)</span>
<span class="gi">+        if len(other_cols) == 0:</span>
<span class="gi">+            expected_cols = driver_col + [&quot;geometry&quot;]</span>
<span class="gi">+        else:</span>
<span class="gi">+            expected_cols = other_cols + [&quot;geometry&quot;]</span>
<span class="gi">+        assert list(df_check.columns) == expected_cols</span>
<span class="gi">+</span>
<span class="gi">+        # similar check on GeoSeries with index=False</span>
<span class="gi">+        tempfilename = next(fngen)</span>
<span class="gi">+        df.geometry.to_file(tempfilename, driver=driver, index=False, engine=engine)</span>
<span class="gi">+        df_check = read_file(tempfilename, engine=engine)</span>
<span class="gi">+        assert list(df_check.columns) == driver_col + [&quot;geometry&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    #</span>
<span class="gi">+    # Checks where index is not used/saved</span>
<span class="gi">+    #</span>
<span class="gi">+</span>
<span class="gi">+    # index is a default RangeIndex</span>
<span class="gi">+    df_p = df_points.copy()</span>
<span class="gi">+    df = GeoDataFrame(df_p[&quot;value1&quot;], geometry=df_p.geometry)</span>
<span class="gi">+    do_checks(df, index_is_used=False)</span>
<span class="gi">+</span>
<span class="gi">+    # index is a RangeIndex, starting from 1</span>
<span class="gi">+    df.index += 1</span>
<span class="gi">+    do_checks(df, index_is_used=False)</span>
<span class="gi">+</span>
<span class="gi">+    # index is a Int64Index regular sequence from 1</span>
<span class="gi">+    df_p.index = list(range(1, len(df) + 1))</span>
<span class="gi">+    df = GeoDataFrame(df_p[&quot;value1&quot;], geometry=df_p.geometry)</span>
<span class="gi">+    do_checks(df, index_is_used=False)</span>
<span class="gi">+</span>
<span class="gi">+    # index was a default RangeIndex, but delete one row to make an Int64Index</span>
<span class="gi">+    df_p = df_points.copy()</span>
<span class="gi">+    df = GeoDataFrame(df_p[&quot;value1&quot;], geometry=df_p.geometry).drop(5, axis=0)</span>
<span class="gi">+    do_checks(df, index_is_used=False)</span>
<span class="gi">+</span>
<span class="gi">+    # no other columns (except geometry)</span>
<span class="gi">+    df = GeoDataFrame(geometry=df_p.geometry)</span>
<span class="gi">+    do_checks(df, index_is_used=False)</span>
<span class="gi">+</span>
<span class="gi">+    #</span>
<span class="gi">+    # Checks where index is used/saved</span>
<span class="gi">+    #</span>
<span class="gi">+</span>
<span class="gi">+    # named index</span>
<span class="gi">+    df_p = df_points.copy()</span>
<span class="gi">+    df = GeoDataFrame(df_p[&quot;value1&quot;], geometry=df_p.geometry)</span>
<span class="gi">+    df.index.name = &quot;foo_index&quot;</span>
<span class="gi">+    do_checks(df, index_is_used=True)</span>
<span class="gi">+</span>
<span class="gi">+    # named index, same as pandas&#39; default name after .reset_index(drop=False)</span>
<span class="gi">+    df.index.name = &quot;index&quot;</span>
<span class="gi">+    do_checks(df, index_is_used=True)</span>
<span class="gi">+</span>
<span class="gi">+    # named MultiIndex</span>
<span class="gi">+    df_p = df_points.copy()</span>
<span class="gi">+    df_p[&quot;value3&quot;] = df_p[&quot;value2&quot;] - df_p[&quot;value1&quot;]</span>
<span class="gi">+    df_p.set_index([&quot;value1&quot;, &quot;value2&quot;], inplace=True)</span>
<span class="gi">+    df = GeoDataFrame(df_p, geometry=df_p.geometry)</span>
<span class="gi">+    do_checks(df, index_is_used=True)</span>
<span class="gi">+</span>
<span class="gi">+    # partially unnamed MultiIndex</span>
<span class="gi">+    df.index.names = [&quot;first&quot;, None]</span>
<span class="gi">+    do_checks(df, index_is_used=True)</span>
<span class="gi">+</span>
<span class="gi">+    # unnamed MultiIndex</span>
<span class="gi">+    df.index.names = [None, None]</span>
<span class="gi">+    do_checks(df, index_is_used=True)</span>
<span class="gi">+</span>
<span class="gi">+    # unnamed Float64Index</span>
<span class="gi">+    df_p = df_points.copy()</span>
<span class="gi">+    df = GeoDataFrame(df_p[&quot;value1&quot;], geometry=df_p.geometry)</span>
<span class="gi">+    df.index = df_p.index.astype(float) / 10</span>
<span class="gi">+    do_checks(df, index_is_used=True)</span>
<span class="gi">+</span>
<span class="gi">+    # named Float64Index</span>
<span class="gi">+    df.index.name = &quot;centile&quot;</span>
<span class="gi">+    do_checks(df, index_is_used=True)</span>
<span class="gi">+</span>
<span class="gi">+    # index as string</span>
<span class="gi">+    df_p = df_points.copy()</span>
<span class="gi">+    df = GeoDataFrame(df_p[&quot;value1&quot;], geometry=df_p.geometry)</span>
<span class="gi">+    df.index = pd.to_timedelta(range(len(df)), unit=&quot;days&quot;)</span>
<span class="gi">+    # TODO: TimedeltaIndex is an invalid field type</span>
<span class="gi">+    df.index = df.index.astype(str)</span>
<span class="gi">+    do_checks(df, index_is_used=True)</span>
<span class="gi">+</span>
<span class="gi">+    # unnamed DatetimeIndex</span>
<span class="gi">+    df_p = df_points.copy()</span>
<span class="gi">+    df = GeoDataFrame(df_p[&quot;value1&quot;], geometry=df_p.geometry)</span>
<span class="gi">+    df.index = pd.to_timedelta(range(len(df)), unit=&quot;days&quot;) + pd.to_datetime(</span>
<span class="gi">+        [&quot;1999-12-27&quot;] * len(df)</span>
<span class="gi">+    )</span>
<span class="gi">+    if driver == &quot;ESRI Shapefile&quot;:</span>
<span class="gi">+        # Shapefile driver does not support datetime fields</span>
<span class="gi">+        df.index = df.index.astype(str)</span>
<span class="gi">+    do_checks(df, index_is_used=True)</span>
<span class="gi">+</span>
<span class="gi">+    # named DatetimeIndex</span>
<span class="gi">+    df.index.name = &quot;datetime&quot;</span>
<span class="gi">+    do_checks(df, index_is_used=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_to_file__undetermined_driver(tmp_path, df_nybb):</span>
<span class="gi">+    shpdir = tmp_path / &quot;boros.invalid&quot;</span>
<span class="gi">+    df_nybb.to_file(shpdir)</span>
<span class="gi">+    assert shpdir.is_dir()</span>
<span class="gi">+    assert list(shpdir.glob(&quot;*.shp&quot;))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;test_file&quot;, [(pathlib.Path(&quot;~/test_file.geojson&quot;)), &quot;~/test_file.geojson&quot;]</span>
<span class="gi">+)</span>
<span class="gi">+def test_write_read_file(test_file, engine):</span>
<span class="gi">+    gdf = geopandas.GeoDataFrame(geometry=[box(0, 0, 10, 10)], crs=_CRS)</span>
<span class="gi">+    gdf.to_file(test_file, driver=&quot;GeoJSON&quot;)</span>
<span class="gi">+    df_json = geopandas.read_file(test_file, engine=engine)</span>
<span class="gi">+    assert_geodataframe_equal(gdf, df_json, check_crs=True)</span>
<span class="gi">+    os.remove(os.path.expanduser(test_file))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(fiona is False, reason=&quot;Fiona not available&quot;)</span>
<span class="gi">+@pytest.mark.skipif(FIONA_GE_19, reason=&quot;Fiona &gt;= 1.9 supports metadata&quot;)</span>
<span class="gi">+def test_to_file_metadata_unsupported_fiona_version(tmp_path, df_points):</span>
<span class="gi">+    metadata = {&quot;title&quot;: &quot;test&quot;}</span>
<span class="gi">+    tmp_file = tmp_path / &quot;test.gpkg&quot;</span>
<span class="gi">+    match = &quot;&#39;metadata&#39; keyword is only supported for Fiona &gt;= 1.9&quot;</span>
<span class="gi">+    with pytest.raises(NotImplementedError, match=match):</span>
<span class="gi">+        df_points.to_file(tmp_file, driver=&quot;GPKG&quot;, engine=&quot;fiona&quot;, metadata=metadata)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(not FIONA_GE_19, reason=&quot;only Fiona &gt;= 1.9 supports metadata&quot;)</span>
<span class="gi">+def test_to_file_metadata_supported_fiona_version(tmp_path, df_points):</span>
<span class="gi">+    metadata = {&quot;title&quot;: &quot;test&quot;}</span>
<span class="gi">+    tmp_file = tmp_path / &quot;test.gpkg&quot;</span>
<span class="gi">+</span>
<span class="gi">+    df_points.to_file(tmp_file, driver=&quot;GPKG&quot;, engine=&quot;fiona&quot;, metadata=metadata)</span>
<span class="gi">+</span>
<span class="gi">+    # Check that metadata is written to the file</span>
<span class="gi">+    with fiona.open(tmp_file) as src:</span>
<span class="gi">+        tags = src.tags()</span>
<span class="gi">+        assert tags == metadata</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(pyogrio is False, reason=&quot;Pyogrio not available&quot;)</span>
<span class="gi">+def test_to_file_metadata_pyogrio(tmp_path, df_points):</span>
<span class="gi">+    metadata = {&quot;title&quot;: &quot;test&quot;}</span>
<span class="gi">+    tmp_file = tmp_path / &quot;test.gpkg&quot;</span>
<span class="gi">+</span>
<span class="gi">+    df_points.to_file(tmp_file, driver=&quot;GPKG&quot;, engine=&quot;pyogrio&quot;, metadata=metadata)</span>
<span class="gi">+</span>
<span class="gi">+    # Check that metadata is written to the file</span>
<span class="gi">+    info = pyogrio.read_info(tmp_file)</span>
<span class="gi">+    layer_metadata = info[&quot;layer_metadata&quot;]</span>
<span class="gi">+    assert layer_metadata == metadata</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;driver, ext&quot;, [(&quot;ESRI Shapefile&quot;, &quot;.shp&quot;), (&quot;GeoJSON&quot;, &quot;.geojson&quot;)]</span>
<span class="gi">+)</span>
<span class="gi">+def test_to_file_metadata_unsupported_driver(driver, ext, tmpdir, df_points, engine):</span>
<span class="gi">+    metadata = {&quot;title&quot;: &quot;Test&quot;}</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;test&quot; + ext)</span>
<span class="gi">+    with pytest.raises(</span>
<span class="gi">+        NotImplementedError, match=&quot;&#39;metadata&#39; keyword is only supported for&quot;</span>
<span class="gi">+    ):</span>
<span class="gi">+        df_points.to_file(tempfilename, driver=driver, metadata=metadata)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_multiple_geom_cols_error(tmpdir, df_nybb):</span>
<span class="gi">+    df_nybb[&quot;geom2&quot;] = df_nybb.geometry</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;GeoDataFrame contains multiple geometry&quot;):</span>
<span class="gi">+        df_nybb.to_file(os.path.join(str(tmpdir), &quot;boros.gpkg&quot;))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@PYOGRIO_MARK</span>
<span class="gi">+@FIONA_MARK</span>
<span class="gi">+def test_option_io_engine(nybb_filename):</span>
<span class="gi">+    try:</span>
<span class="gi">+        geopandas.options.io_engine = &quot;pyogrio&quot;</span>
<span class="gi">+</span>
<span class="gi">+        # disallowing to read a Shapefile with fiona should ensure we are</span>
<span class="gi">+        # actually reading with pyogrio</span>
<span class="gi">+        import fiona</span>
<span class="gi">+</span>
<span class="gi">+        orig = fiona.supported_drivers[&quot;ESRI Shapefile&quot;]</span>
<span class="gi">+        fiona.supported_drivers[&quot;ESRI Shapefile&quot;] = &quot;w&quot;</span>
<span class="gi">+</span>
<span class="gi">+        _ = geopandas.read_file(nybb_filename)</span>
<span class="gi">+    finally:</span>
<span class="gi">+        fiona.supported_drivers[&quot;ESRI Shapefile&quot;] = orig</span>
<span class="gi">+        geopandas.options.io_engine = None</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(pyogrio, reason=&quot;test for pyogrio not installed&quot;)</span>
<span class="gi">+def test_error_engine_unavailable_pyogrio(tmp_path, df_points, file_path):</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ImportError, match=&quot;the &#39;read_file&#39; function requires&quot;):</span>
<span class="gi">+        geopandas.read_file(file_path, engine=&quot;pyogrio&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ImportError, match=&quot;the &#39;to_file&#39; method requires&quot;):</span>
<span class="gi">+        df_points.to_file(tmp_path / &quot;test.gpkg&quot;, engine=&quot;pyogrio&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(fiona, reason=&quot;test for fiona not installed&quot;)</span>
<span class="gi">+def test_error_engine_unavailable_fiona(tmp_path, df_points, file_path):</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ImportError, match=&quot;the &#39;read_file&#39; function requires&quot;):</span>
<span class="gi">+        geopandas.read_file(file_path, engine=&quot;fiona&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ImportError, match=&quot;the &#39;to_file&#39; method requires&quot;):</span>
<span class="gi">+        df_points.to_file(tmp_path / &quot;test.gpkg&quot;, engine=&quot;fiona&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@PYOGRIO_MARK</span>
<span class="gi">+def test_list_layers(df_points, tmpdir):</span>
<span class="gi">+    tempfilename = os.path.join(str(tmpdir), &quot;dataset.gpkg&quot;)</span>
<span class="gi">+    df_points.to_file(tempfilename, layer=&quot;original&quot;)</span>
<span class="gi">+    df_points.set_geometry(df_points.buffer(1)).to_file(tempfilename, layer=&quot;buffered&quot;)</span>
<span class="gi">+    df_points.set_geometry(df_points.buffer(2).boundary).to_file(</span>
<span class="gi">+        tempfilename, layer=&quot;boundary&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    pyogrio.write_dataframe(</span>
<span class="gi">+        df_points[[&quot;value1&quot;, &quot;value2&quot;]], tempfilename, layer=&quot;non-spatial&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    layers = geopandas.list_layers(tempfilename)</span>
<span class="gi">+    expected = pd.DataFrame(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;name&quot;: [&quot;original&quot;, &quot;buffered&quot;, &quot;boundary&quot;, &quot;non-spatial&quot;],</span>
<span class="gi">+            &quot;geometry_type&quot;: [&quot;Point&quot;, &quot;Polygon&quot;, &quot;LineString&quot;, None],</span>
<span class="gi">+        }</span>
<span class="gi">+    )</span>
<span class="gi">+    assert_frame_equal(layers, expected)</span>
<span class="gh">diff --git a/geopandas/io/tests/test_file_geom_types_drivers.py b/geopandas/io/tests/test_file_geom_types_drivers.py</span>
<span class="gh">index b81ff5f8..b28260fb 100644</span>
<span class="gd">--- a/geopandas/io/tests/test_file_geom_types_drivers.py</span>
<span class="gi">+++ b/geopandas/io/tests/test_file_geom_types_drivers.py</span>
<span class="gu">@@ -1,94 +1,328 @@</span>
<span class="w"> </span>import os
<span class="gd">-from shapely.geometry import LineString, MultiLineString, MultiPoint, MultiPolygon, Point, Polygon</span>
<span class="gi">+</span>
<span class="gi">+from shapely.geometry import (</span>
<span class="gi">+    LineString,</span>
<span class="gi">+    MultiLineString,</span>
<span class="gi">+    MultiPoint,</span>
<span class="gi">+    MultiPolygon,</span>
<span class="gi">+    Point,</span>
<span class="gi">+    Polygon,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="w"> </span>import geopandas
<span class="w"> </span>from geopandas import GeoDataFrame
<span class="gi">+</span>
<span class="w"> </span>from .test_file import FIONA_MARK, PYOGRIO_MARK
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="w"> </span>from geopandas.testing import assert_geodataframe_equal
<span class="gd">-city_hall_boundaries = Polygon(((-73.5541107525234, 45.5091983609661), (-</span>
<span class="gd">-    73.5546126200639, 45.5086813829106), (-73.5540185061397, </span>
<span class="gd">-    45.5084409343852), (-73.5539986525799, 45.5084323044531), (-</span>
<span class="gd">-    73.5535801792994, 45.5089539203786), (-73.5541107525234, 45.5091983609661))</span>
<span class="gi">+</span>
<span class="gi">+# Credit: Polygons below come from Montreal city Open Data portal</span>
<span class="gi">+# http://donnees.ville.montreal.qc.ca/dataset/unites-evaluation-fonciere</span>
<span class="gi">+city_hall_boundaries = Polygon(</span>
<span class="gi">+    (</span>
<span class="gi">+        (-73.5541107525234, 45.5091983609661),</span>
<span class="gi">+        (-73.5546126200639, 45.5086813829106),</span>
<span class="gi">+        (-73.5540185061397, 45.5084409343852),</span>
<span class="gi">+        (-73.5539986525799, 45.5084323044531),</span>
<span class="gi">+        (-73.5535801792994, 45.5089539203786),</span>
<span class="gi">+        (-73.5541107525234, 45.5091983609661),</span>
<span class="gi">+    )</span>
<span class="gi">+)</span>
<span class="gi">+vauquelin_place = Polygon(</span>
<span class="gi">+    (</span>
<span class="gi">+        (-73.5542465586147, 45.5081555487952),</span>
<span class="gi">+        (-73.5540185061397, 45.5084409343852),</span>
<span class="gi">+        (-73.5546126200639, 45.5086813829106),</span>
<span class="gi">+        (-73.5548825850032, 45.5084033554357),</span>
<span class="gi">+        (-73.5542465586147, 45.5081555487952),</span>
<span class="w"> </span>    )
<span class="gd">-vauquelin_place = Polygon(((-73.5542465586147, 45.5081555487952), (-</span>
<span class="gd">-    73.5540185061397, 45.5084409343852), (-73.5546126200639, </span>
<span class="gd">-    45.5086813829106), (-73.5548825850032, 45.5084033554357), (-</span>
<span class="gd">-    73.5542465586147, 45.5081555487952)))</span>
<span class="gd">-city_hall_walls = [LineString(((-73.5541107525234, 45.5091983609661), (-</span>
<span class="gd">-    73.5546126200639, 45.5086813829106), (-73.5540185061397, </span>
<span class="gd">-    45.5084409343852))), LineString(((-73.5539986525799, 45.5084323044531),</span>
<span class="gd">-    (-73.5535801792994, 45.5089539203786), (-73.5541107525234, </span>
<span class="gd">-    45.5091983609661)))]</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="gi">+city_hall_walls = [</span>
<span class="gi">+    LineString(</span>
<span class="gi">+        (</span>
<span class="gi">+            (-73.5541107525234, 45.5091983609661),</span>
<span class="gi">+            (-73.5546126200639, 45.5086813829106),</span>
<span class="gi">+            (-73.5540185061397, 45.5084409343852),</span>
<span class="gi">+        )</span>
<span class="gi">+    ),</span>
<span class="gi">+    LineString(</span>
<span class="gi">+        (</span>
<span class="gi">+            (-73.5539986525799, 45.5084323044531),</span>
<span class="gi">+            (-73.5535801792994, 45.5089539203786),</span>
<span class="gi">+            (-73.5541107525234, 45.5091983609661),</span>
<span class="gi">+        )</span>
<span class="gi">+    ),</span>
<span class="gi">+]</span>
<span class="gi">+</span>
<span class="w"> </span>city_hall_entrance = Point(-73.553785, 45.508722)
<span class="gd">-city_hall_balcony = Point(-73.554138, 45.50908)</span>
<span class="gi">+city_hall_balcony = Point(-73.554138, 45.509080)</span>
<span class="w"> </span>city_hall_council_chamber = Point(-73.554246, 45.508931)
<span class="gi">+</span>
<span class="w"> </span>point_3D = Point(-73.553785, 45.508722, 300)


<span class="gd">-class _ExpectedError:</span>
<span class="gi">+# *****************************************</span>
<span class="gi">+# TEST TOOLING</span>

<span class="gi">+</span>
<span class="gi">+class _ExpectedError:</span>
<span class="w"> </span>    def __init__(self, error_type, error_message_match):
<span class="w"> </span>        self.type = error_type
<span class="w"> </span>        self.match = error_message_match


<span class="w"> </span>class _ExpectedErrorBuilder:
<span class="gd">-</span>
<span class="w"> </span>    def __init__(self, composite_key):
<span class="w"> </span>        self.composite_key = composite_key

<span class="gi">+    def to_raise(self, error_type, error_match):</span>
<span class="gi">+        _expected_exceptions[self.composite_key] = _ExpectedError(</span>
<span class="gi">+            error_type, error_match</span>
<span class="gi">+        )</span>

<span class="gi">+</span>
<span class="gi">+def _expect_writing(gdf, ogr_driver):</span>
<span class="gi">+    return _ExpectedErrorBuilder(_composite_key(gdf, ogr_driver))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _composite_key(gdf, ogr_driver):</span>
<span class="gi">+    return frozenset([id(gdf), ogr_driver])</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _expected_error_on(gdf, ogr_driver):</span>
<span class="gi">+    composite_key = _composite_key(gdf, ogr_driver)</span>
<span class="gi">+    return _expected_exceptions.get(composite_key, None)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# *****************************************</span>
<span class="gi">+# TEST CASES</span>
<span class="w"> </span>_geodataframes_to_write = []
<span class="w"> </span>_expected_exceptions = {}
<span class="gd">-_CRS = &#39;epsg:4326&#39;</span>
<span class="gd">-gdf = GeoDataFrame({&#39;a&#39;: [1, 2]}, crs=_CRS, geometry=[city_hall_entrance,</span>
<span class="gd">-    city_hall_balcony])</span>
<span class="gi">+_CRS = &quot;epsg:4326&quot;</span>
<span class="gi">+</span>
<span class="gi">+# ------------------</span>
<span class="gi">+# gdf with Points</span>
<span class="gi">+gdf = GeoDataFrame(</span>
<span class="gi">+    {&quot;a&quot;: [1, 2]}, crs=_CRS, geometry=[city_hall_entrance, city_hall_balcony]</span>
<span class="gi">+)</span>
<span class="w"> </span>_geodataframes_to_write.append(gdf)
<span class="gd">-gdf = GeoDataFrame({&#39;a&#39;: [1, 2]}, crs=_CRS, geometry=[MultiPoint([</span>
<span class="gd">-    city_hall_balcony, city_hall_council_chamber]), MultiPoint([</span>
<span class="gd">-    city_hall_entrance, city_hall_balcony, city_hall_council_chamber])])</span>
<span class="gi">+</span>
<span class="gi">+# ------------------</span>
<span class="gi">+# gdf with MultiPoints</span>
<span class="gi">+gdf = GeoDataFrame(</span>
<span class="gi">+    {&quot;a&quot;: [1, 2]},</span>
<span class="gi">+    crs=_CRS,</span>
<span class="gi">+    geometry=[</span>
<span class="gi">+        MultiPoint([city_hall_balcony, city_hall_council_chamber]),</span>
<span class="gi">+        MultiPoint([city_hall_entrance, city_hall_balcony, city_hall_council_chamber]),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="w"> </span>_geodataframes_to_write.append(gdf)
<span class="gd">-gdf = GeoDataFrame({&#39;a&#39;: [1, 2]}, crs=_CRS, geometry=[MultiPoint([</span>
<span class="gd">-    city_hall_entrance, city_hall_balcony]), city_hall_balcony])</span>
<span class="gi">+</span>
<span class="gi">+# ------------------</span>
<span class="gi">+# gdf with Points and MultiPoints</span>
<span class="gi">+gdf = GeoDataFrame(</span>
<span class="gi">+    {&quot;a&quot;: [1, 2]},</span>
<span class="gi">+    crs=_CRS,</span>
<span class="gi">+    geometry=[MultiPoint([city_hall_entrance, city_hall_balcony]), city_hall_balcony],</span>
<span class="gi">+)</span>
<span class="w"> </span>_geodataframes_to_write.append(gdf)
<span class="gd">-_expect_writing(gdf, &#39;ESRI Shapefile&#39;).to_raise(RuntimeError,</span>
<span class="gd">-    &#39;Failed to write record&#39;)</span>
<span class="gd">-gdf = GeoDataFrame({&#39;a&#39;: [1, 2]}, crs=_CRS, geometry=city_hall_walls)</span>
<span class="gi">+# &#39;ESRI Shapefile&#39; driver supports writing LineString/MultiLinestring and</span>
<span class="gi">+# Polygon/MultiPolygon but does not mention Point/MultiPoint</span>
<span class="gi">+# see https://www.gdal.org/drv_shapefile.html</span>
<span class="gi">+_expect_writing(gdf, &quot;ESRI Shapefile&quot;).to_raise(RuntimeError, &quot;Failed to write record&quot;)</span>
<span class="gi">+</span>
<span class="gi">+# ------------------</span>
<span class="gi">+# gdf with LineStrings</span>
<span class="gi">+gdf = GeoDataFrame({&quot;a&quot;: [1, 2]}, crs=_CRS, geometry=city_hall_walls)</span>
<span class="w"> </span>_geodataframes_to_write.append(gdf)
<span class="gd">-gdf = GeoDataFrame({&#39;a&#39;: [1, 2]}, crs=_CRS, geometry=[MultiLineString(</span>
<span class="gd">-    city_hall_walls), MultiLineString(city_hall_walls)])</span>
<span class="gi">+</span>
<span class="gi">+# ------------------</span>
<span class="gi">+# gdf with MultiLineStrings</span>
<span class="gi">+gdf = GeoDataFrame(</span>
<span class="gi">+    {&quot;a&quot;: [1, 2]},</span>
<span class="gi">+    crs=_CRS,</span>
<span class="gi">+    geometry=[MultiLineString(city_hall_walls), MultiLineString(city_hall_walls)],</span>
<span class="gi">+)</span>
<span class="w"> </span>_geodataframes_to_write.append(gdf)
<span class="gd">-gdf = GeoDataFrame({&#39;a&#39;: [1, 2]}, crs=_CRS, geometry=[MultiLineString(</span>
<span class="gd">-    city_hall_walls), city_hall_walls[0]])</span>
<span class="gi">+</span>
<span class="gi">+# ------------------</span>
<span class="gi">+# gdf with LineStrings and MultiLineStrings</span>
<span class="gi">+gdf = GeoDataFrame(</span>
<span class="gi">+    {&quot;a&quot;: [1, 2]},</span>
<span class="gi">+    crs=_CRS,</span>
<span class="gi">+    geometry=[MultiLineString(city_hall_walls), city_hall_walls[0]],</span>
<span class="gi">+)</span>
<span class="w"> </span>_geodataframes_to_write.append(gdf)
<span class="gd">-gdf = GeoDataFrame({&#39;a&#39;: [1, 2]}, crs=_CRS, geometry=[city_hall_boundaries,</span>
<span class="gd">-    vauquelin_place])</span>
<span class="gi">+</span>
<span class="gi">+# ------------------</span>
<span class="gi">+# gdf with Polygons</span>
<span class="gi">+gdf = GeoDataFrame(</span>
<span class="gi">+    {&quot;a&quot;: [1, 2]}, crs=_CRS, geometry=[city_hall_boundaries, vauquelin_place]</span>
<span class="gi">+)</span>
<span class="w"> </span>_geodataframes_to_write.append(gdf)
<span class="gd">-gdf = GeoDataFrame({&#39;a&#39;: [1]}, crs=_CRS, geometry=[MultiPolygon((</span>
<span class="gd">-    city_hall_boundaries, vauquelin_place))])</span>
<span class="gi">+</span>
<span class="gi">+# ------------------</span>
<span class="gi">+# gdf with MultiPolygon</span>
<span class="gi">+gdf = GeoDataFrame(</span>
<span class="gi">+    {&quot;a&quot;: [1]},</span>
<span class="gi">+    crs=_CRS,</span>
<span class="gi">+    geometry=[MultiPolygon((city_hall_boundaries, vauquelin_place))],</span>
<span class="gi">+)</span>
<span class="w"> </span>_geodataframes_to_write.append(gdf)
<span class="gd">-gdf = GeoDataFrame({&#39;a&#39;: [1, 2]}, crs=_CRS, geometry=[MultiPolygon((</span>
<span class="gd">-    city_hall_boundaries, vauquelin_place)), city_hall_boundaries])</span>
<span class="gi">+</span>
<span class="gi">+# ------------------</span>
<span class="gi">+# gdf with Polygon and MultiPolygon</span>
<span class="gi">+gdf = GeoDataFrame(</span>
<span class="gi">+    {&quot;a&quot;: [1, 2]},</span>
<span class="gi">+    crs=_CRS,</span>
<span class="gi">+    geometry=[</span>
<span class="gi">+        MultiPolygon((city_hall_boundaries, vauquelin_place)),</span>
<span class="gi">+        city_hall_boundaries,</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="w"> </span>_geodataframes_to_write.append(gdf)
<span class="gd">-gdf = GeoDataFrame({&#39;a&#39;: [1, 2]}, crs=_CRS, geometry=[None, city_hall_entrance]</span>
<span class="gd">-    )</span>
<span class="gi">+</span>
<span class="gi">+# ------------------</span>
<span class="gi">+# gdf with null geometry and Point</span>
<span class="gi">+gdf = GeoDataFrame({&quot;a&quot;: [1, 2]}, crs=_CRS, geometry=[None, city_hall_entrance])</span>
<span class="w"> </span>_geodataframes_to_write.append(gdf)
<span class="gd">-gdf = GeoDataFrame({&#39;a&#39;: [1, 2]}, crs=_CRS, geometry=[None, point_3D])</span>
<span class="gi">+</span>
<span class="gi">+# ------------------</span>
<span class="gi">+# gdf with null geometry and 3D Point</span>
<span class="gi">+gdf = GeoDataFrame({&quot;a&quot;: [1, 2]}, crs=_CRS, geometry=[None, point_3D])</span>
<span class="w"> </span>_geodataframes_to_write.append(gdf)
<span class="gd">-gdf = GeoDataFrame({&#39;a&#39;: [1, 2]}, crs=_CRS, geometry=[None, None])</span>
<span class="gi">+</span>
<span class="gi">+# ------------------</span>
<span class="gi">+# gdf with null geometries only</span>
<span class="gi">+gdf = GeoDataFrame({&quot;a&quot;: [1, 2]}, crs=_CRS, geometry=[None, None])</span>
<span class="w"> </span>_geodataframes_to_write.append(gdf)
<span class="gd">-gdf = GeoDataFrame({&#39;a&#39;: [1, 2, 3, 4, 5, 6]}, crs=_CRS, geometry=[</span>
<span class="gd">-    MultiPolygon((city_hall_boundaries, vauquelin_place)),</span>
<span class="gd">-    city_hall_entrance, MultiLineString(city_hall_walls), city_hall_walls[0</span>
<span class="gd">-    ], MultiPoint([city_hall_entrance, city_hall_balcony]), city_hall_balcony])</span>
<span class="gi">+</span>
<span class="gi">+# ------------------</span>
<span class="gi">+# gdf with all shape types mixed together</span>
<span class="gi">+gdf = GeoDataFrame(</span>
<span class="gi">+    {&quot;a&quot;: [1, 2, 3, 4, 5, 6]},</span>
<span class="gi">+    crs=_CRS,</span>
<span class="gi">+    geometry=[</span>
<span class="gi">+        MultiPolygon((city_hall_boundaries, vauquelin_place)),</span>
<span class="gi">+        city_hall_entrance,</span>
<span class="gi">+        MultiLineString(city_hall_walls),</span>
<span class="gi">+        city_hall_walls[0],</span>
<span class="gi">+        MultiPoint([city_hall_entrance, city_hall_balcony]),</span>
<span class="gi">+        city_hall_balcony,</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="w"> </span>_geodataframes_to_write.append(gdf)
<span class="gd">-_expect_writing(gdf, &#39;ESRI Shapefile&#39;).to_raise(RuntimeError,</span>
<span class="gd">-    &#39;Failed to write record&#39;)</span>
<span class="gd">-gdf = GeoDataFrame({&#39;a&#39;: [1, 2, 3, 4, 5, 6, 7]}, crs=_CRS, geometry=[</span>
<span class="gd">-    MultiPolygon((city_hall_boundaries, vauquelin_place)),</span>
<span class="gd">-    city_hall_entrance, MultiLineString(city_hall_walls), city_hall_walls[0</span>
<span class="gd">-    ], MultiPoint([city_hall_entrance, city_hall_balcony]),</span>
<span class="gd">-    city_hall_balcony, point_3D])</span>
<span class="gi">+# Not supported by &#39;ESRI Shapefile&#39; driver</span>
<span class="gi">+_expect_writing(gdf, &quot;ESRI Shapefile&quot;).to_raise(RuntimeError, &quot;Failed to write record&quot;)</span>
<span class="gi">+</span>
<span class="gi">+# ------------------</span>
<span class="gi">+# gdf with all 2D shape types and 3D Point mixed together</span>
<span class="gi">+gdf = GeoDataFrame(</span>
<span class="gi">+    {&quot;a&quot;: [1, 2, 3, 4, 5, 6, 7]},</span>
<span class="gi">+    crs=_CRS,</span>
<span class="gi">+    geometry=[</span>
<span class="gi">+        MultiPolygon((city_hall_boundaries, vauquelin_place)),</span>
<span class="gi">+        city_hall_entrance,</span>
<span class="gi">+        MultiLineString(city_hall_walls),</span>
<span class="gi">+        city_hall_walls[0],</span>
<span class="gi">+        MultiPoint([city_hall_entrance, city_hall_balcony]),</span>
<span class="gi">+        city_hall_balcony,</span>
<span class="gi">+        point_3D,</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="w"> </span>_geodataframes_to_write.append(gdf)
<span class="gd">-_expect_writing(gdf, &#39;ESRI Shapefile&#39;).to_raise(RuntimeError,</span>
<span class="gd">-    &#39;Failed to write record&#39;)</span>
<span class="gi">+# Not supported by &#39;ESRI Shapefile&#39; driver</span>
<span class="gi">+_expect_writing(gdf, &quot;ESRI Shapefile&quot;).to_raise(RuntimeError, &quot;Failed to write record&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture(params=_geodataframes_to_write)</span>
<span class="gi">+def geodataframe(request):</span>
<span class="gi">+    return request.param</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture(</span>
<span class="gi">+    params=[</span>
<span class="gi">+        (&quot;GeoJSON&quot;, &quot;.geojson&quot;),</span>
<span class="gi">+        (&quot;ESRI Shapefile&quot;, &quot;.shp&quot;),</span>
<span class="gi">+        (&quot;GPKG&quot;, &quot;.gpkg&quot;),</span>
<span class="gi">+        (&quot;SQLite&quot;, &quot;.sqlite&quot;),</span>
<span class="gi">+    ]</span>
<span class="gi">+)</span>
<span class="gi">+def ogr_driver(request):</span>
<span class="gi">+    return request.param</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture(</span>
<span class="gi">+    params=[</span>
<span class="gi">+        pytest.param(&quot;fiona&quot;, marks=FIONA_MARK),</span>
<span class="gi">+        pytest.param(&quot;pyogrio&quot;, marks=PYOGRIO_MARK),</span>
<span class="gi">+    ]</span>
<span class="gi">+)</span>
<span class="gi">+def engine(request):</span>
<span class="gi">+    return request.param</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_to_file_roundtrip(tmpdir, geodataframe, ogr_driver, engine):</span>
<span class="gi">+    driver, ext = ogr_driver</span>
<span class="gi">+    output_file = os.path.join(str(tmpdir), &quot;output_file&quot; + ext)</span>
<span class="gi">+    write_kwargs = {}</span>
<span class="gi">+    if driver == &quot;SQLite&quot;:</span>
<span class="gi">+        write_kwargs[&quot;spatialite&quot;] = True</span>
<span class="gi">+</span>
<span class="gi">+        # This if statement can be removed once minimal fiona version &gt;= 1.8.20</span>
<span class="gi">+        if engine == &quot;fiona&quot;:</span>
<span class="gi">+            from packaging.version import Version</span>
<span class="gi">+</span>
<span class="gi">+            import fiona</span>
<span class="gi">+</span>
<span class="gi">+            if Version(fiona.__version__) &lt; Version(&quot;1.8.20&quot;):</span>
<span class="gi">+                pytest.skip(&quot;SQLite driver only available from version 1.8.20&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        # If only 3D Points, geometry_type needs to be specified for spatialite at the</span>
<span class="gi">+        # moment. This if can be removed once the following PR is released:</span>
<span class="gi">+        # https://github.com/geopandas/pyogrio/pull/223</span>
<span class="gi">+        if (</span>
<span class="gi">+            engine == &quot;pyogrio&quot;</span>
<span class="gi">+            and len(geodataframe == 2)</span>
<span class="gi">+            and geodataframe.geometry[0] is None</span>
<span class="gi">+            and geodataframe.geometry[1] is not None</span>
<span class="gi">+            and geodataframe.geometry[1].has_z</span>
<span class="gi">+        ):</span>
<span class="gi">+            write_kwargs[&quot;geometry_type&quot;] = &quot;Point Z&quot;</span>
<span class="gi">+</span>
<span class="gi">+    expected_error = _expected_error_on(geodataframe, driver)</span>
<span class="gi">+    if expected_error:</span>
<span class="gi">+        with pytest.raises(</span>
<span class="gi">+            RuntimeError, match=&quot;Failed to write record|Could not add feature to layer&quot;</span>
<span class="gi">+        ):</span>
<span class="gi">+            geodataframe.to_file(</span>
<span class="gi">+                output_file, driver=driver, engine=engine, **write_kwargs</span>
<span class="gi">+            )</span>
<span class="gi">+    else:</span>
<span class="gi">+        if driver == &quot;SQLite&quot; and engine == &quot;pyogrio&quot;:</span>
<span class="gi">+            try:</span>
<span class="gi">+                geodataframe.to_file(</span>
<span class="gi">+                    output_file, driver=driver, engine=engine, **write_kwargs</span>
<span class="gi">+                )</span>
<span class="gi">+            except ValueError as e:</span>
<span class="gi">+                if &quot;unrecognized option &#39;SPATIALITE&#39;&quot; in str(e):</span>
<span class="gi">+                    pytest.xfail(</span>
<span class="gi">+                        &quot;pyogrio wheels from PyPI do not come with SpatiaLite support. &quot;</span>
<span class="gi">+                        f&quot;Error: {e}&quot;</span>
<span class="gi">+                    )</span>
<span class="gi">+                raise</span>
<span class="gi">+        else:</span>
<span class="gi">+            geodataframe.to_file(</span>
<span class="gi">+                output_file, driver=driver, engine=engine, **write_kwargs</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        reloaded = geopandas.read_file(output_file, engine=engine)</span>
<span class="gi">+</span>
<span class="gi">+        if driver == &quot;GeoJSON&quot; and engine == &quot;pyogrio&quot;:</span>
<span class="gi">+            # For GeoJSON files, the int64 column comes back as int32</span>
<span class="gi">+            reloaded[&quot;a&quot;] = reloaded[&quot;a&quot;].astype(&quot;int64&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        assert_geodataframe_equal(geodataframe, reloaded, check_column_type=&quot;equiv&quot;)</span>
<span class="gh">diff --git a/geopandas/io/tests/test_geoarrow.py b/geopandas/io/tests/test_geoarrow.py</span>
<span class="gh">index 1336e5bd..0087e6b0 100644</span>
<span class="gd">--- a/geopandas/io/tests/test_geoarrow.py</span>
<span class="gi">+++ b/geopandas/io/tests/test_geoarrow.py</span>
<span class="gu">@@ -3,14 +3,535 @@ import json</span>
<span class="w"> </span>import os
<span class="w"> </span>import pathlib
<span class="w"> </span>from packaging.version import Version
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="gi">+</span>
<span class="w"> </span>import shapely
<span class="w"> </span>from shapely import MultiPoint, Point, box
<span class="gi">+</span>
<span class="w"> </span>from geopandas import GeoDataFrame, GeoSeries
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="w"> </span>from geopandas.testing import assert_geodataframe_equal, assert_geoseries_equal
<span class="gd">-pytest.importorskip(&#39;pyarrow&#39;)</span>
<span class="gi">+</span>
<span class="gi">+pytest.importorskip(&quot;pyarrow&quot;)</span>
<span class="w"> </span>import pyarrow as pa
<span class="w"> </span>import pyarrow.compute as pc
<span class="w"> </span>from pyarrow import feather
<span class="gd">-DATA_PATH = pathlib.Path(os.path.dirname(__file__)) / &#39;data&#39;</span>
<span class="gi">+</span>
<span class="gi">+DATA_PATH = pathlib.Path(os.path.dirname(__file__)) / &quot;data&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def pa_table(table):</span>
<span class="gi">+    if Version(pa.__version__) &lt; Version(&quot;14.0.0&quot;):</span>
<span class="gi">+        return table._pa_table</span>
<span class="gi">+    else:</span>
<span class="gi">+        return pa.table(table)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def pa_array(array):</span>
<span class="gi">+    if Version(pa.__version__) &lt; Version(&quot;14.0.0&quot;):</span>
<span class="gi">+        return array._pa_array</span>
<span class="gi">+    else:</span>
<span class="gi">+        return pa.array(array)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def assert_table_equal(left, right, check_metadata=True):</span>
<span class="gi">+    geom_type = left[&quot;geometry&quot;].type</span>
<span class="gi">+    # in case of Points (directly the inner fixed_size_list or struct type)</span>
<span class="gi">+    # -&gt; there are NaNs for empties -&gt; we need to compare them separately</span>
<span class="gi">+    # and then fill, because pyarrow.Table.equals considers NaNs as not equal</span>
<span class="gi">+    if pa.types.is_fixed_size_list(geom_type):</span>
<span class="gi">+        left_values = left[&quot;geometry&quot;].chunk(0).values</span>
<span class="gi">+        right_values = right[&quot;geometry&quot;].chunk(0).values</span>
<span class="gi">+        assert pc.is_nan(left_values).equals(pc.is_nan(right_values))</span>
<span class="gi">+        left_geoms = pa.FixedSizeListArray.from_arrays(</span>
<span class="gi">+            pc.replace_with_mask(left_values, pc.is_nan(left_values), 0.0),</span>
<span class="gi">+            type=left[&quot;geometry&quot;].type,</span>
<span class="gi">+        )</span>
<span class="gi">+        right_geoms = pa.FixedSizeListArray.from_arrays(</span>
<span class="gi">+            pc.replace_with_mask(right_values, pc.is_nan(right_values), 0.0),</span>
<span class="gi">+            type=right[&quot;geometry&quot;].type,</span>
<span class="gi">+        )</span>
<span class="gi">+        left = left.set_column(1, left.schema.field(&quot;geometry&quot;), left_geoms)</span>
<span class="gi">+        right = right.set_column(1, right.schema.field(&quot;geometry&quot;), right_geoms)</span>
<span class="gi">+</span>
<span class="gi">+    elif pa.types.is_struct(geom_type):</span>
<span class="gi">+        left_arr = left[&quot;geometry&quot;].chunk(0)</span>
<span class="gi">+        right_arr = right[&quot;geometry&quot;].chunk(0)</span>
<span class="gi">+</span>
<span class="gi">+        for i in range(left_arr.type.num_fields):</span>
<span class="gi">+            assert pc.is_nan(left_arr.field(i)).equals(pc.is_nan(right_arr.field(i)))</span>
<span class="gi">+</span>
<span class="gi">+        left_geoms = pa.StructArray.from_arrays(</span>
<span class="gi">+            [</span>
<span class="gi">+                pc.replace_with_mask(</span>
<span class="gi">+                    left_arr.field(i), pc.is_nan(left_arr.field(i)), 0.0</span>
<span class="gi">+                )</span>
<span class="gi">+                for i in range(left_arr.type.num_fields)</span>
<span class="gi">+            ],</span>
<span class="gi">+            fields=list(left[&quot;geometry&quot;].type),</span>
<span class="gi">+        )</span>
<span class="gi">+        right_geoms = pa.StructArray.from_arrays(</span>
<span class="gi">+            [</span>
<span class="gi">+                pc.replace_with_mask(</span>
<span class="gi">+                    right_arr.field(i), pc.is_nan(right_arr.field(i)), 0.0</span>
<span class="gi">+                )</span>
<span class="gi">+                for i in range(right_arr.type.num_fields)</span>
<span class="gi">+            ],</span>
<span class="gi">+            fields=list(right[&quot;geometry&quot;].type),</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        left = left.set_column(1, left.schema.field(&quot;geometry&quot;), left_geoms)</span>
<span class="gi">+        right = right.set_column(1, right.schema.field(&quot;geometry&quot;), right_geoms)</span>
<span class="gi">+</span>
<span class="gi">+    if left.equals(right, check_metadata=check_metadata):</span>
<span class="gi">+        return</span>
<span class="gi">+</span>
<span class="gi">+    if not left.schema.equals(right.schema):</span>
<span class="gi">+        raise AssertionError(</span>
<span class="gi">+            &quot;Schema not equal\nLeft:\n{0}\nRight:\n{1}&quot;.format(</span>
<span class="gi">+                left.schema, right.schema</span>
<span class="gi">+            )</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    if check_metadata:</span>
<span class="gi">+        if not left.schema.equals(right.schema, check_metadata=True):</span>
<span class="gi">+            if not left.schema.metadata == right.schema.metadata:</span>
<span class="gi">+                raise AssertionError(</span>
<span class="gi">+                    &quot;Metadata not equal\nLeft:\n{0}\nRight:\n{1}&quot;.format(</span>
<span class="gi">+                        left.schema.metadata, right.schema.metadata</span>
<span class="gi">+                    )</span>
<span class="gi">+                )</span>
<span class="gi">+        for col in left.schema.names:</span>
<span class="gi">+            assert left.schema.field(col).equals(</span>
<span class="gi">+                right.schema.field(col), check_metadata=True</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    for col in left.column_names:</span>
<span class="gi">+        a_left = pa.concat_arrays(left.column(col).chunks)</span>
<span class="gi">+        a_right = pa.concat_arrays(right.column(col).chunks)</span>
<span class="gi">+        if not a_left.equals(a_right):</span>
<span class="gi">+            raise AssertionError(</span>
<span class="gi">+                &quot;Column &#39;{0}&#39; not equal:\n{1}&quot;.format(col, a_left.diff(a_right))</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    raise AssertionError(&quot;Tables not equal for unknown reason&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(</span>
<span class="gi">+    shapely.geos_version &lt; (3, 9, 0),</span>
<span class="gi">+    reason=&quot;Checking for empty is buggy with GEOS&lt;3.9&quot;,</span>
<span class="gi">+)  # an old GEOS is installed in the CI builds with the defaults channel</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;dim&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        &quot;xy&quot;,</span>
<span class="gi">+        pytest.param(</span>
<span class="gi">+            &quot;xyz&quot;,</span>
<span class="gi">+            marks=pytest.mark.skipif(</span>
<span class="gi">+                shapely.geos_version &lt; (3, 10, 0),</span>
<span class="gi">+                reason=&quot;Cannot write 3D geometries with GEOS&lt;3.10&quot;,</span>
<span class="gi">+            ),</span>
<span class="gi">+        ),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;geometry_type&quot;,</span>
<span class="gi">+    [&quot;point&quot;, &quot;linestring&quot;, &quot;polygon&quot;, &quot;multipoint&quot;, &quot;multilinestring&quot;, &quot;multipolygon&quot;],</span>
<span class="gi">+)</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;geometry_encoding, interleaved&quot;,</span>
<span class="gi">+    [(&quot;WKB&quot;, None), (&quot;geoarrow&quot;, True), (&quot;geoarrow&quot;, False)],</span>
<span class="gi">+    ids=[&quot;WKB&quot;, &quot;geoarrow-interleaved&quot;, &quot;geoarrow-separated&quot;],</span>
<span class="gi">+)</span>
<span class="gi">+def test_geoarrow_export(geometry_type, dim, geometry_encoding, interleaved):</span>
<span class="gi">+    base_path = DATA_PATH / &quot;geoarrow&quot;</span>
<span class="gi">+    suffix = geometry_type + (&quot;_z&quot; if dim == &quot;xyz&quot; else &quot;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # Read the example data</span>
<span class="gi">+    df = feather.read_feather(base_path / f&quot;example-{suffix}-wkb.arrow&quot;)</span>
<span class="gi">+    df[&quot;geometry&quot;] = GeoSeries.from_wkb(df[&quot;geometry&quot;])</span>
<span class="gi">+    df[&quot;row_number&quot;] = df[&quot;row_number&quot;].astype(&quot;int32&quot;)</span>
<span class="gi">+    df = GeoDataFrame(df)</span>
<span class="gi">+    df.geometry.array.crs = None</span>
<span class="gi">+</span>
<span class="gi">+    # Read the expected data</span>
<span class="gi">+    if geometry_encoding == &quot;WKB&quot;:</span>
<span class="gi">+        filename = f&quot;example-{suffix}-wkb.arrow&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        filename = f&quot;example-{suffix}{&#39;-interleaved&#39; if interleaved else &#39;&#39;}.arrow&quot;</span>
<span class="gi">+    expected = feather.read_table(base_path / filename)</span>
<span class="gi">+</span>
<span class="gi">+    # GeoDataFrame -&gt; Arrow Table</span>
<span class="gi">+    result = pa_table(</span>
<span class="gi">+        df.to_arrow(geometry_encoding=geometry_encoding, interleaved=interleaved)</span>
<span class="gi">+    )</span>
<span class="gi">+    # remove the &quot;pandas&quot; metadata</span>
<span class="gi">+    result = result.replace_schema_metadata(None)</span>
<span class="gi">+</span>
<span class="gi">+    mask_nonempty = None</span>
<span class="gi">+    if (</span>
<span class="gi">+        geometry_encoding == &quot;WKB&quot;</span>
<span class="gi">+        and dim == &quot;xyz&quot;</span>
<span class="gi">+        and geometry_type.startswith(&quot;multi&quot;)</span>
<span class="gi">+    ):</span>
<span class="gi">+        # for collections with z dimension, drop the empties because those don&#39;t</span>
<span class="gi">+        # roundtrip correctly to WKB</span>
<span class="gi">+        # (https://github.com/libgeos/geos/issues/888)</span>
<span class="gi">+        mask_nonempty = pa.array(np.asarray(~df.geometry.is_empty))</span>
<span class="gi">+        result = result.filter(mask_nonempty)</span>
<span class="gi">+        expected = expected.filter(mask_nonempty)</span>
<span class="gi">+</span>
<span class="gi">+    assert_table_equal(result, expected)</span>
<span class="gi">+</span>
<span class="gi">+    # GeoSeries -&gt; Arrow array</span>
<span class="gi">+    if geometry_encoding != &quot;WKB&quot; and geometry_type == &quot;point&quot;:</span>
<span class="gi">+        # for points, we again have to handle NaNs separately, we already did that</span>
<span class="gi">+        # for table so let&#39;s just skip this part</span>
<span class="gi">+        return</span>
<span class="gi">+    result_arr = pa_array(</span>
<span class="gi">+        df.geometry.to_arrow(</span>
<span class="gi">+            geometry_encoding=geometry_encoding, interleaved=interleaved</span>
<span class="gi">+        )</span>
<span class="gi">+    )</span>
<span class="gi">+    if mask_nonempty is not None:</span>
<span class="gi">+        result_arr = result_arr.filter(mask_nonempty)</span>
<span class="gi">+    assert result_arr.equals(expected[&quot;geometry&quot;].chunk(0))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(</span>
<span class="gi">+    Version(shapely.__version__) &lt; Version(&quot;2.0.2&quot;),</span>
<span class="gi">+    reason=&quot;from_ragged_array failing with read-only array input&quot;,</span>
<span class="gi">+)</span>
<span class="gi">+@pytest.mark.parametrize(&quot;encoding&quot;, [&quot;WKB&quot;, &quot;geoarrow&quot;])</span>
<span class="gi">+def test_geoarrow_multiple_geometry_crs(encoding):</span>
<span class="gi">+    pytest.importorskip(&quot;pyproj&quot;)</span>
<span class="gi">+    # ensure each geometry column has its own crs</span>
<span class="gi">+    gdf = GeoDataFrame(geometry=[box(0, 0, 10, 10)], crs=&quot;epsg:4326&quot;)</span>
<span class="gi">+    gdf[&quot;geom2&quot;] = gdf.geometry.to_crs(&quot;epsg:3857&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    result = pa_table(gdf.to_arrow(geometry_encoding=encoding))</span>
<span class="gi">+    meta1 = json.loads(</span>
<span class="gi">+        result.schema.field(&quot;geometry&quot;).metadata[b&quot;ARROW:extension:metadata&quot;]</span>
<span class="gi">+    )</span>
<span class="gi">+    assert json.loads(meta1[&quot;crs&quot;])[&quot;id&quot;][&quot;code&quot;] == 4326</span>
<span class="gi">+    meta2 = json.loads(</span>
<span class="gi">+        result.schema.field(&quot;geom2&quot;).metadata[b&quot;ARROW:extension:metadata&quot;]</span>
<span class="gi">+    )</span>
<span class="gi">+    assert json.loads(meta2[&quot;crs&quot;])[&quot;id&quot;][&quot;code&quot;] == 3857</span>
<span class="gi">+</span>
<span class="gi">+    roundtripped = GeoDataFrame.from_arrow(result)</span>
<span class="gi">+    assert_geodataframe_equal(gdf, roundtripped)</span>
<span class="gi">+    assert gdf.geometry.crs == &quot;epsg:4326&quot;</span>
<span class="gi">+    assert gdf.geom2.crs == &quot;epsg:3857&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;encoding&quot;, [&quot;WKB&quot;, &quot;geoarrow&quot;])</span>
<span class="gi">+def test_geoarrow_series_name_crs(encoding):</span>
<span class="gi">+    pytest.importorskip(&quot;pyproj&quot;)</span>
<span class="gi">+    pytest.importorskip(&quot;pyarrow&quot;, minversion=&quot;14.0.0&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    gser = GeoSeries([box(0, 0, 10, 10)], crs=&quot;epsg:4326&quot;, name=&quot;geom&quot;)</span>
<span class="gi">+    schema_capsule, _ = gser.to_arrow(geometry_encoding=encoding).__arrow_c_array__()</span>
<span class="gi">+    field = pa.Field._import_from_c_capsule(schema_capsule)</span>
<span class="gi">+    assert field.name == &quot;geom&quot;</span>
<span class="gi">+    assert (</span>
<span class="gi">+        field.metadata[b&quot;ARROW:extension:name&quot;] == b&quot;geoarrow.wkb&quot;</span>
<span class="gi">+        if encoding == &quot;WKB&quot;</span>
<span class="gi">+        else b&quot;geoarrow.polygon&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    meta = json.loads(field.metadata[b&quot;ARROW:extension:metadata&quot;])</span>
<span class="gi">+    assert json.loads(meta[&quot;crs&quot;])[&quot;id&quot;][&quot;code&quot;] == 4326</span>
<span class="gi">+</span>
<span class="gi">+    # ensure it also works without a name</span>
<span class="gi">+    gser = GeoSeries([box(0, 0, 10, 10)])</span>
<span class="gi">+    schema_capsule, _ = gser.to_arrow(geometry_encoding=encoding).__arrow_c_array__()</span>
<span class="gi">+    field = pa.Field._import_from_c_capsule(schema_capsule)</span>
<span class="gi">+    assert field.name == &quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_geoarrow_unsupported_encoding():</span>
<span class="gi">+    gdf = GeoDataFrame(geometry=[box(0, 0, 10, 10)], crs=&quot;epsg:4326&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;Expected geometry encoding&quot;):</span>
<span class="gi">+        gdf.to_arrow(geometry_encoding=&quot;invalid&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;Expected geometry encoding&quot;):</span>
<span class="gi">+        gdf.geometry.to_arrow(geometry_encoding=&quot;invalid&quot;)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_geoarrow_mixed_geometry_types():</span>
<span class="gi">+    gdf = GeoDataFrame(</span>
<span class="gi">+        {&quot;geometry&quot;: [Point(0, 0), box(0, 0, 10, 10)]},</span>
<span class="gi">+        crs=&quot;epsg:4326&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;Geometry type combination is not supported&quot;):</span>
<span class="gi">+        gdf.to_arrow(geometry_encoding=&quot;geoarrow&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    gdf = GeoDataFrame(</span>
<span class="gi">+        {&quot;geometry&quot;: [Point(0, 0), MultiPoint([(0, 0), (1, 1)])]},</span>
<span class="gi">+        crs=&quot;epsg:4326&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+    result = pa_table(gdf.to_arrow(geometry_encoding=&quot;geoarrow&quot;))</span>
<span class="gi">+    assert (</span>
<span class="gi">+        result.schema.field(&quot;geometry&quot;).metadata[b&quot;ARROW:extension:name&quot;]</span>
<span class="gi">+        == b&quot;geoarrow.multipoint&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;geom_type&quot;, [&quot;point&quot;, &quot;polygon&quot;])</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;encoding, interleaved&quot;, [(&quot;WKB&quot;, True), (&quot;geoarrow&quot;, True), (&quot;geoarrow&quot;, False)]</span>
<span class="gi">+)</span>
<span class="gi">+def test_geoarrow_missing(encoding, interleaved, geom_type):</span>
<span class="gi">+    # dummy test for single geometry type until missing values are included</span>
<span class="gi">+    # in the test data for test_geoarrow_export</span>
<span class="gi">+    gdf = GeoDataFrame(</span>
<span class="gi">+        geometry=[Point(0, 0) if geom_type == &quot;point&quot; else box(0, 0, 10, 10), None],</span>
<span class="gi">+        crs=&quot;epsg:4326&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+    if (</span>
<span class="gi">+        encoding == &quot;geoarrow&quot;</span>
<span class="gi">+        and geom_type == &quot;point&quot;</span>
<span class="gi">+        and interleaved</span>
<span class="gi">+        and Version(pa.__version__) &lt; Version(&quot;15.0.0&quot;)</span>
<span class="gi">+    ):</span>
<span class="gi">+        with pytest.raises(</span>
<span class="gi">+            ValueError,</span>
<span class="gi">+            match=&quot;Converting point geometries with missing values is not supported&quot;,</span>
<span class="gi">+        ):</span>
<span class="gi">+            gdf.to_arrow(geometry_encoding=encoding, interleaved=interleaved)</span>
<span class="gi">+        return</span>
<span class="gi">+    result = pa_table(gdf.to_arrow(geometry_encoding=encoding, interleaved=interleaved))</span>
<span class="gi">+    assert result[&quot;geometry&quot;].null_count == 1</span>
<span class="gi">+    assert result[&quot;geometry&quot;].is_null().to_pylist() == [False, True]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_geoarrow_include_z():</span>
<span class="gi">+    gdf = GeoDataFrame({&quot;geometry&quot;: [Point(0, 0), Point(1, 1), Point()]})</span>
<span class="gi">+</span>
<span class="gi">+    table = pa_table(gdf.to_arrow(geometry_encoding=&quot;geoarrow&quot;))</span>
<span class="gi">+    assert table[&quot;geometry&quot;].type.value_field.name == &quot;xy&quot;</span>
<span class="gi">+    assert table[&quot;geometry&quot;].type.list_size == 2</span>
<span class="gi">+</span>
<span class="gi">+    table = pa_table(gdf.to_arrow(geometry_encoding=&quot;geoarrow&quot;, include_z=True))</span>
<span class="gi">+    assert table[&quot;geometry&quot;].type.value_field.name == &quot;xyz&quot;</span>
<span class="gi">+    assert table[&quot;geometry&quot;].type.list_size == 3</span>
<span class="gi">+    assert np.isnan(table[&quot;geometry&quot;].chunk(0).values.to_numpy()[2::3]).all()</span>
<span class="gi">+</span>
<span class="gi">+    gdf = GeoDataFrame({&quot;geometry&quot;: [Point(0, 0, 0), Point(1, 1, 1), Point()]})</span>
<span class="gi">+</span>
<span class="gi">+    table = pa_table(gdf.to_arrow(geometry_encoding=&quot;geoarrow&quot;))</span>
<span class="gi">+    assert table[&quot;geometry&quot;].type.value_field.name == &quot;xyz&quot;</span>
<span class="gi">+    assert table[&quot;geometry&quot;].type.list_size == 3</span>
<span class="gi">+</span>
<span class="gi">+    table = pa_table(gdf.to_arrow(geometry_encoding=&quot;geoarrow&quot;, include_z=False))</span>
<span class="gi">+    assert table[&quot;geometry&quot;].type.value_field.name == &quot;xy&quot;</span>
<span class="gi">+    assert table[&quot;geometry&quot;].type.list_size == 2</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@contextlib.contextmanager</span>
<span class="gi">+def with_geoarrow_extension_types():</span>
<span class="gi">+    gp = pytest.importorskip(&quot;geoarrow.pyarrow&quot;)</span>
<span class="gi">+    gp.register_extension_types()</span>
<span class="gi">+    try:</span>
<span class="gi">+        yield</span>
<span class="gi">+    finally:</span>
<span class="gi">+        gp.unregister_extension_types()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;dim&quot;, [&quot;xy&quot;, &quot;xyz&quot;])</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;geometry_type&quot;,</span>
<span class="gi">+    [&quot;point&quot;, &quot;linestring&quot;, &quot;polygon&quot;, &quot;multipoint&quot;, &quot;multilinestring&quot;, &quot;multipolygon&quot;],</span>
<span class="gi">+)</span>
<span class="gi">+def test_geoarrow_export_with_extension_types(geometry_type, dim):</span>
<span class="gi">+    # ensure the exported data can be imported by geoarrow-pyarrow and are</span>
<span class="gi">+    # recognized as extension types</span>
<span class="gi">+    base_path = DATA_PATH / &quot;geoarrow&quot;</span>
<span class="gi">+    suffix = geometry_type + (&quot;_z&quot; if dim == &quot;xyz&quot; else &quot;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # Read the example data</span>
<span class="gi">+    df = feather.read_feather(base_path / f&quot;example-{suffix}-wkb.arrow&quot;)</span>
<span class="gi">+    df[&quot;geometry&quot;] = GeoSeries.from_wkb(df[&quot;geometry&quot;])</span>
<span class="gi">+    df[&quot;row_number&quot;] = df[&quot;row_number&quot;].astype(&quot;int32&quot;)</span>
<span class="gi">+    df = GeoDataFrame(df)</span>
<span class="gi">+    df.geometry.array.crs = None</span>
<span class="gi">+</span>
<span class="gi">+    pytest.importorskip(&quot;geoarrow.pyarrow&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with with_geoarrow_extension_types():</span>
<span class="gi">+        result1 = pa_table(df.to_arrow(geometry_encoding=&quot;WKB&quot;))</span>
<span class="gi">+        assert isinstance(result1[&quot;geometry&quot;].type, pa.ExtensionType)</span>
<span class="gi">+</span>
<span class="gi">+        result2 = pa_table(df.to_arrow(geometry_encoding=&quot;geoarrow&quot;))</span>
<span class="gi">+        assert isinstance(result2[&quot;geometry&quot;].type, pa.ExtensionType)</span>
<span class="gi">+</span>
<span class="gi">+        result3 = pa_table(df.to_arrow(geometry_encoding=&quot;geoarrow&quot;, interleaved=False))</span>
<span class="gi">+        assert isinstance(result3[&quot;geometry&quot;].type, pa.ExtensionType)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(</span>
<span class="gi">+    Version(shapely.__version__) &lt; Version(&quot;2.0.2&quot;),</span>
<span class="gi">+    reason=&quot;from_ragged_array failing with read-only array input&quot;,</span>
<span class="gi">+)</span>
<span class="gi">+@pytest.mark.parametrize(&quot;dim&quot;, [&quot;xy&quot;, &quot;xyz&quot;])</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;geometry_type&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        &quot;point&quot;,</span>
<span class="gi">+        &quot;linestring&quot;,</span>
<span class="gi">+        &quot;polygon&quot;,</span>
<span class="gi">+        &quot;multipoint&quot;,</span>
<span class="gi">+        &quot;multilinestring&quot;,</span>
<span class="gi">+        &quot;multipolygon&quot;,</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_geoarrow_import(geometry_type, dim):</span>
<span class="gi">+    base_path = DATA_PATH / &quot;geoarrow&quot;</span>
<span class="gi">+    suffix = geometry_type + (&quot;_z&quot; if dim == &quot;xyz&quot; else &quot;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # Read the example data</span>
<span class="gi">+    df = feather.read_feather(base_path / f&quot;example-{suffix}-wkb.arrow&quot;)</span>
<span class="gi">+    df[&quot;geometry&quot;] = GeoSeries.from_wkb(df[&quot;geometry&quot;])</span>
<span class="gi">+    df = GeoDataFrame(df)</span>
<span class="gi">+    df.geometry.crs = None</span>
<span class="gi">+</span>
<span class="gi">+    table1 = feather.read_table(base_path / f&quot;example-{suffix}-wkb.arrow&quot;)</span>
<span class="gi">+    result1 = GeoDataFrame.from_arrow(table1)</span>
<span class="gi">+    assert_geodataframe_equal(result1, df)</span>
<span class="gi">+</span>
<span class="gi">+    table2 = feather.read_table(base_path / f&quot;example-{suffix}-interleaved.arrow&quot;)</span>
<span class="gi">+    result2 = GeoDataFrame.from_arrow(table2)</span>
<span class="gi">+    assert_geodataframe_equal(result2, df)</span>
<span class="gi">+</span>
<span class="gi">+    table3 = feather.read_table(base_path / f&quot;example-{suffix}.arrow&quot;)</span>
<span class="gi">+    result3 = GeoDataFrame.from_arrow(table3)</span>
<span class="gi">+    assert_geodataframe_equal(result3, df)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(</span>
<span class="gi">+    Version(shapely.__version__) &lt; Version(&quot;2.0.2&quot;),</span>
<span class="gi">+    reason=&quot;from_ragged_array failing with read-only array input&quot;,</span>
<span class="gi">+)</span>
<span class="gi">+@pytest.mark.parametrize(&quot;encoding&quot;, [&quot;WKB&quot;, &quot;geoarrow&quot;])</span>
<span class="gi">+def test_geoarrow_import_geometry_column(encoding):</span>
<span class="gi">+    pytest.importorskip(&quot;pyproj&quot;)</span>
<span class="gi">+    # ensure each geometry column has its own crs</span>
<span class="gi">+    gdf = GeoDataFrame(geometry=[box(0, 0, 10, 10)])</span>
<span class="gi">+    gdf[&quot;centroid&quot;] = gdf.geometry.centroid</span>
<span class="gi">+</span>
<span class="gi">+    result = GeoDataFrame.from_arrow(pa_table(gdf.to_arrow(geometry_encoding=encoding)))</span>
<span class="gi">+    assert_geodataframe_equal(result, gdf)</span>
<span class="gi">+    assert result.active_geometry_name == &quot;geometry&quot;</span>
<span class="gi">+</span>
<span class="gi">+    result = GeoDataFrame.from_arrow(</span>
<span class="gi">+        pa_table(gdf[[&quot;centroid&quot;]].to_arrow(geometry_encoding=encoding))</span>
<span class="gi">+    )</span>
<span class="gi">+    assert result.active_geometry_name == &quot;centroid&quot;</span>
<span class="gi">+</span>
<span class="gi">+    result = GeoDataFrame.from_arrow(</span>
<span class="gi">+        pa_table(gdf.to_arrow(geometry_encoding=encoding)), geometry=&quot;centroid&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    assert result.active_geometry_name == &quot;centroid&quot;</span>
<span class="gi">+    assert_geodataframe_equal(result, gdf.set_geometry(&quot;centroid&quot;))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_geoarrow_import_missing_geometry():</span>
<span class="gi">+    pytest.importorskip(&quot;pyarrow&quot;, minversion=&quot;14.0.0&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    table = pa.table({&quot;a&quot;: [0, 1, 2], &quot;b&quot;: [0.1, 0.2, 0.3]})</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;No geometry column found&quot;):</span>
<span class="gi">+        GeoDataFrame.from_arrow(table)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(ValueError, match=&quot;No GeoArrow geometry field found&quot;):</span>
<span class="gi">+        GeoSeries.from_arrow(table[&quot;a&quot;].chunk(0))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_geoarrow_import_capsule_interface():</span>
<span class="gi">+    # ensure we can import non-pyarrow object</span>
<span class="gi">+    pytest.importorskip(&quot;pyarrow&quot;, minversion=&quot;14.0.0&quot;)</span>
<span class="gi">+    gdf = GeoDataFrame({&quot;col&quot;: [1]}, geometry=[box(0, 0, 10, 10)])</span>
<span class="gi">+</span>
<span class="gi">+    result = GeoDataFrame.from_arrow(gdf.to_arrow())</span>
<span class="gi">+    assert_geodataframe_equal(result, gdf)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;dim&quot;, [&quot;xy&quot;, &quot;xyz&quot;])</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;geometry_type&quot;,</span>
<span class="gi">+    [&quot;point&quot;, &quot;linestring&quot;, &quot;polygon&quot;, &quot;multipoint&quot;, &quot;multilinestring&quot;, &quot;multipolygon&quot;],</span>
<span class="gi">+)</span>
<span class="gi">+def test_geoarrow_import_from_extension_types(geometry_type, dim):</span>
<span class="gi">+    # ensure the exported data can be imported by geoarrow-pyarrow and are</span>
<span class="gi">+    # recognized as extension types</span>
<span class="gi">+    pytest.importorskip(&quot;pyproj&quot;)</span>
<span class="gi">+    base_path = DATA_PATH / &quot;geoarrow&quot;</span>
<span class="gi">+    suffix = geometry_type + (&quot;_z&quot; if dim == &quot;xyz&quot; else &quot;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    # Read the example data</span>
<span class="gi">+    df = feather.read_feather(base_path / f&quot;example-{suffix}-wkb.arrow&quot;)</span>
<span class="gi">+    df[&quot;geometry&quot;] = GeoSeries.from_wkb(df[&quot;geometry&quot;])</span>
<span class="gi">+    df = GeoDataFrame(df, crs=&quot;EPSG:3857&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    pytest.importorskip(&quot;geoarrow.pyarrow&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with with_geoarrow_extension_types():</span>
<span class="gi">+        result1 = GeoDataFrame.from_arrow(</span>
<span class="gi">+            pa_table(df.to_arrow(geometry_encoding=&quot;WKB&quot;))</span>
<span class="gi">+        )</span>
<span class="gi">+        assert_geodataframe_equal(result1, df)</span>
<span class="gi">+</span>
<span class="gi">+        result2 = GeoDataFrame.from_arrow(</span>
<span class="gi">+            pa_table(df.to_arrow(geometry_encoding=&quot;geoarrow&quot;))</span>
<span class="gi">+        )</span>
<span class="gi">+        assert_geodataframe_equal(result2, df)</span>
<span class="gi">+</span>
<span class="gi">+        result3 = GeoDataFrame.from_arrow(</span>
<span class="gi">+            pa_table(df.to_arrow(geometry_encoding=&quot;geoarrow&quot;, interleaved=False))</span>
<span class="gi">+        )</span>
<span class="gi">+        assert_geodataframe_equal(result3, df)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_geoarrow_import_geoseries():</span>
<span class="gi">+    pytest.importorskip(&quot;pyproj&quot;)</span>
<span class="gi">+    gp = pytest.importorskip(&quot;geoarrow.pyarrow&quot;)</span>
<span class="gi">+    ser = GeoSeries.from_wkt([&quot;POINT (1 1)&quot;, &quot;POINT (2 2)&quot;], crs=&quot;EPSG:3857&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    with with_geoarrow_extension_types():</span>
<span class="gi">+        arr = gp.array(ser.to_arrow(geometry_encoding=&quot;WKB&quot;))</span>
<span class="gi">+        result = GeoSeries.from_arrow(arr)</span>
<span class="gi">+        assert_geoseries_equal(result, ser)</span>
<span class="gi">+</span>
<span class="gi">+        arr = gp.array(ser.to_arrow(geometry_encoding=&quot;geoarrow&quot;))</span>
<span class="gi">+        result = GeoSeries.from_arrow(arr)</span>
<span class="gi">+        assert_geoseries_equal(result, ser)</span>
<span class="gi">+</span>
<span class="gi">+        # the name is lost when going through a pyarrow.Array</span>
<span class="gi">+        ser.name = &quot;name&quot;</span>
<span class="gi">+        arr = gp.array(ser.to_arrow())</span>
<span class="gi">+        result = GeoSeries.from_arrow(arr)</span>
<span class="gi">+        assert result.name is None</span>
<span class="gi">+        # we can specify the name as one of the kwargs</span>
<span class="gi">+        result = GeoSeries.from_arrow(arr, name=&quot;test&quot;)</span>
<span class="gi">+        assert_geoseries_equal(result, ser)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_geoarrow_import_unknown_geoarrow_type():</span>
<span class="gi">+    gdf = GeoDataFrame({&quot;col&quot;: [1]}, geometry=[box(0, 0, 10, 10)])</span>
<span class="gi">+    table = pa_table(gdf.to_arrow())</span>
<span class="gi">+    schema = table.schema</span>
<span class="gi">+    new_field = schema.field(&quot;geometry&quot;).with_metadata(</span>
<span class="gi">+        {</span>
<span class="gi">+            b&quot;ARROW:extension:name&quot;: b&quot;geoarrow.unknown&quot;,</span>
<span class="gi">+            b&quot;ARROW:extension:metadata&quot;: b&quot;{}&quot;,</span>
<span class="gi">+        }</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    new_schema = pa.schema([schema.field(0), new_field])</span>
<span class="gi">+    new_table = table.cast(new_schema)</span>
<span class="gi">+</span>
<span class="gi">+    with pytest.raises(TypeError, match=&quot;Unknown GeoArrow extension type&quot;):</span>
<span class="gi">+        GeoDataFrame.from_arrow(new_table)</span>
<span class="gh">diff --git a/geopandas/io/tests/test_infer_schema.py b/geopandas/io/tests/test_infer_schema.py</span>
<span class="gh">index 014ddf7d..61a72171 100644</span>
<span class="gd">--- a/geopandas/io/tests/test_infer_schema.py</span>
<span class="gi">+++ b/geopandas/io/tests/test_infer_schema.py</span>
<span class="gu">@@ -1,31 +1,306 @@</span>
<span class="w"> </span>from collections import OrderedDict
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>import pandas as pd
<span class="gd">-from shapely.geometry import LineString, MultiLineString, MultiPoint, MultiPolygon, Point, Polygon</span>
<span class="gi">+</span>
<span class="gi">+from shapely.geometry import (</span>
<span class="gi">+    LineString,</span>
<span class="gi">+    MultiLineString,</span>
<span class="gi">+    MultiPoint,</span>
<span class="gi">+    MultiPolygon,</span>
<span class="gi">+    Point,</span>
<span class="gi">+    Polygon,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="w"> </span>from geopandas import GeoDataFrame
<span class="w"> </span>from geopandas.io.file import infer_schema
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gd">-city_hall_boundaries = Polygon(((-73.5541107525234, 45.5091983609661), (-</span>
<span class="gd">-    73.5546126200639, 45.5086813829106), (-73.5540185061397, </span>
<span class="gd">-    45.5084409343852), (-73.5539986525799, 45.5084323044531), (-</span>
<span class="gd">-    73.5535801792994, 45.5089539203786), (-73.5541107525234, 45.5091983609661))</span>
<span class="gd">-    )</span>
<span class="gd">-vauquelin_place = Polygon(((-73.5542465586147, 45.5081555487952), (-</span>
<span class="gd">-    73.5540185061397, 45.5084409343852), (-73.5546126200639, </span>
<span class="gd">-    45.5086813829106), (-73.5548825850032, 45.5084033554357), (-</span>
<span class="gd">-    73.5542465586147, 45.5081555487952)))</span>
<span class="gd">-city_hall_walls = [LineString(((-73.5541107525234, 45.5091983609661), (-</span>
<span class="gd">-    73.5546126200639, 45.5086813829106), (-73.5540185061397, </span>
<span class="gd">-    45.5084409343852))), LineString(((-73.5539986525799, 45.5084323044531),</span>
<span class="gd">-    (-73.5535801792994, 45.5089539203786), (-73.5541107525234, </span>
<span class="gd">-    45.5091983609661)))]</span>
<span class="gi">+</span>
<span class="gi">+# Credit: Polygons below come from Montreal city Open Data portal</span>
<span class="gi">+# http://donnees.ville.montreal.qc.ca/dataset/unites-evaluation-fonciere</span>
<span class="gi">+city_hall_boundaries = Polygon(</span>
<span class="gi">+    (</span>
<span class="gi">+        (-73.5541107525234, 45.5091983609661),</span>
<span class="gi">+        (-73.5546126200639, 45.5086813829106),</span>
<span class="gi">+        (-73.5540185061397, 45.5084409343852),</span>
<span class="gi">+        (-73.5539986525799, 45.5084323044531),</span>
<span class="gi">+        (-73.5535801792994, 45.5089539203786),</span>
<span class="gi">+        (-73.5541107525234, 45.5091983609661),</span>
<span class="gi">+    )</span>
<span class="gi">+)</span>
<span class="gi">+vauquelin_place = Polygon(</span>
<span class="gi">+    (</span>
<span class="gi">+        (-73.5542465586147, 45.5081555487952),</span>
<span class="gi">+        (-73.5540185061397, 45.5084409343852),</span>
<span class="gi">+        (-73.5546126200639, 45.5086813829106),</span>
<span class="gi">+        (-73.5548825850032, 45.5084033554357),</span>
<span class="gi">+        (-73.5542465586147, 45.5081555487952),</span>
<span class="gi">+    )</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="gi">+city_hall_walls = [</span>
<span class="gi">+    LineString(</span>
<span class="gi">+        (</span>
<span class="gi">+            (-73.5541107525234, 45.5091983609661),</span>
<span class="gi">+            (-73.5546126200639, 45.5086813829106),</span>
<span class="gi">+            (-73.5540185061397, 45.5084409343852),</span>
<span class="gi">+        )</span>
<span class="gi">+    ),</span>
<span class="gi">+    LineString(</span>
<span class="gi">+        (</span>
<span class="gi">+            (-73.5539986525799, 45.5084323044531),</span>
<span class="gi">+            (-73.5535801792994, 45.5089539203786),</span>
<span class="gi">+            (-73.5541107525234, 45.5091983609661),</span>
<span class="gi">+        )</span>
<span class="gi">+    ),</span>
<span class="gi">+]</span>
<span class="gi">+</span>
<span class="w"> </span>city_hall_entrance = Point(-73.553785, 45.508722)
<span class="gd">-city_hall_balcony = Point(-73.554138, 45.50908)</span>
<span class="gi">+city_hall_balcony = Point(-73.554138, 45.509080)</span>
<span class="w"> </span>city_hall_council_chamber = Point(-73.554246, 45.508931)
<span class="gi">+</span>
<span class="w"> </span>point_3D = Point(-73.553785, 45.508722, 300)
<span class="gd">-linestring_3D = LineString(((-73.5541107525234, 45.5091983609661, 300), (-</span>
<span class="gd">-    73.5546126200639, 45.5086813829106, 300), (-73.5540185061397, </span>
<span class="gd">-    45.5084409343852, 300)))</span>
<span class="gd">-polygon_3D = Polygon(((-73.5541107525234, 45.5091983609661, 300), (-</span>
<span class="gd">-    73.5535801792994, 45.5089539203786, 300), (-73.5541107525234, </span>
<span class="gd">-    45.5091983609661, 300)))</span>
<span class="gi">+linestring_3D = LineString(</span>
<span class="gi">+    (</span>
<span class="gi">+        (-73.5541107525234, 45.5091983609661, 300),</span>
<span class="gi">+        (-73.5546126200639, 45.5086813829106, 300),</span>
<span class="gi">+        (-73.5540185061397, 45.5084409343852, 300),</span>
<span class="gi">+    )</span>
<span class="gi">+)</span>
<span class="gi">+polygon_3D = Polygon(</span>
<span class="gi">+    (</span>
<span class="gi">+        (-73.5541107525234, 45.5091983609661, 300),</span>
<span class="gi">+        (-73.5535801792994, 45.5089539203786, 300),</span>
<span class="gi">+        (-73.5541107525234, 45.5091983609661, 300),</span>
<span class="gi">+    )</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_only_points():</span>
<span class="gi">+    df = GeoDataFrame(geometry=[city_hall_entrance, city_hall_balcony])</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {&quot;geometry&quot;: &quot;Point&quot;, &quot;properties&quot;: OrderedDict()}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_points_and_multipoints():</span>
<span class="gi">+    df = GeoDataFrame(</span>
<span class="gi">+        geometry=[</span>
<span class="gi">+            MultiPoint([city_hall_entrance, city_hall_balcony]),</span>
<span class="gi">+            city_hall_balcony,</span>
<span class="gi">+        ]</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {</span>
<span class="gi">+        &quot;geometry&quot;: [&quot;MultiPoint&quot;, &quot;Point&quot;],</span>
<span class="gi">+        &quot;properties&quot;: OrderedDict(),</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_only_multipoints():</span>
<span class="gi">+    df = GeoDataFrame(</span>
<span class="gi">+        geometry=[</span>
<span class="gi">+            MultiPoint(</span>
<span class="gi">+                [city_hall_entrance, city_hall_balcony, city_hall_council_chamber]</span>
<span class="gi">+            )</span>
<span class="gi">+        ]</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {&quot;geometry&quot;: &quot;MultiPoint&quot;, &quot;properties&quot;: OrderedDict()}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_only_linestrings():</span>
<span class="gi">+    df = GeoDataFrame(geometry=city_hall_walls)</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {&quot;geometry&quot;: &quot;LineString&quot;, &quot;properties&quot;: OrderedDict()}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_linestrings_and_multilinestrings():</span>
<span class="gi">+    df = GeoDataFrame(geometry=[MultiLineString(city_hall_walls), city_hall_walls[0]])</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {</span>
<span class="gi">+        &quot;geometry&quot;: [&quot;MultiLineString&quot;, &quot;LineString&quot;],</span>
<span class="gi">+        &quot;properties&quot;: OrderedDict(),</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_only_multilinestrings():</span>
<span class="gi">+    df = GeoDataFrame(geometry=[MultiLineString(city_hall_walls)])</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {</span>
<span class="gi">+        &quot;geometry&quot;: &quot;MultiLineString&quot;,</span>
<span class="gi">+        &quot;properties&quot;: OrderedDict(),</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_only_polygons():</span>
<span class="gi">+    df = GeoDataFrame(geometry=[city_hall_boundaries, vauquelin_place])</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {&quot;geometry&quot;: &quot;Polygon&quot;, &quot;properties&quot;: OrderedDict()}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_polygons_and_multipolygons():</span>
<span class="gi">+    df = GeoDataFrame(</span>
<span class="gi">+        geometry=[</span>
<span class="gi">+            MultiPolygon((city_hall_boundaries, vauquelin_place)),</span>
<span class="gi">+            city_hall_boundaries,</span>
<span class="gi">+        ]</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {</span>
<span class="gi">+        &quot;geometry&quot;: [&quot;MultiPolygon&quot;, &quot;Polygon&quot;],</span>
<span class="gi">+        &quot;properties&quot;: OrderedDict(),</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_only_multipolygons():</span>
<span class="gi">+    df = GeoDataFrame(geometry=[MultiPolygon((city_hall_boundaries, vauquelin_place))])</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {&quot;geometry&quot;: &quot;MultiPolygon&quot;, &quot;properties&quot;: OrderedDict()}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_multiple_shape_types():</span>
<span class="gi">+    df = GeoDataFrame(</span>
<span class="gi">+        geometry=[</span>
<span class="gi">+            MultiPolygon((city_hall_boundaries, vauquelin_place)),</span>
<span class="gi">+            city_hall_boundaries,</span>
<span class="gi">+            MultiLineString(city_hall_walls),</span>
<span class="gi">+            city_hall_walls[0],</span>
<span class="gi">+            MultiPoint([city_hall_entrance, city_hall_balcony]),</span>
<span class="gi">+            city_hall_balcony,</span>
<span class="gi">+        ]</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {</span>
<span class="gi">+        &quot;geometry&quot;: [</span>
<span class="gi">+            &quot;MultiPolygon&quot;,</span>
<span class="gi">+            &quot;Polygon&quot;,</span>
<span class="gi">+            &quot;MultiLineString&quot;,</span>
<span class="gi">+            &quot;LineString&quot;,</span>
<span class="gi">+            &quot;MultiPoint&quot;,</span>
<span class="gi">+            &quot;Point&quot;,</span>
<span class="gi">+        ],</span>
<span class="gi">+        &quot;properties&quot;: OrderedDict(),</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_mixed_3D_shape_type():</span>
<span class="gi">+    df = GeoDataFrame(</span>
<span class="gi">+        geometry=[</span>
<span class="gi">+            MultiPolygon((city_hall_boundaries, vauquelin_place)),</span>
<span class="gi">+            city_hall_boundaries,</span>
<span class="gi">+            MultiLineString(city_hall_walls),</span>
<span class="gi">+            city_hall_walls[0],</span>
<span class="gi">+            MultiPoint([city_hall_entrance, city_hall_balcony]),</span>
<span class="gi">+            city_hall_balcony,</span>
<span class="gi">+            point_3D,</span>
<span class="gi">+        ]</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {</span>
<span class="gi">+        &quot;geometry&quot;: [</span>
<span class="gi">+            &quot;3D Point&quot;,</span>
<span class="gi">+            &quot;MultiPolygon&quot;,</span>
<span class="gi">+            &quot;Polygon&quot;,</span>
<span class="gi">+            &quot;MultiLineString&quot;,</span>
<span class="gi">+            &quot;LineString&quot;,</span>
<span class="gi">+            &quot;MultiPoint&quot;,</span>
<span class="gi">+            &quot;Point&quot;,</span>
<span class="gi">+        ],</span>
<span class="gi">+        &quot;properties&quot;: OrderedDict(),</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_mixed_3D_Point():</span>
<span class="gi">+    df = GeoDataFrame(geometry=[city_hall_balcony, point_3D])</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {</span>
<span class="gi">+        &quot;geometry&quot;: [&quot;3D Point&quot;, &quot;Point&quot;],</span>
<span class="gi">+        &quot;properties&quot;: OrderedDict(),</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_only_3D_Points():</span>
<span class="gi">+    df = GeoDataFrame(geometry=[point_3D, point_3D])</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {&quot;geometry&quot;: &quot;3D Point&quot;, &quot;properties&quot;: OrderedDict()}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_mixed_3D_linestring():</span>
<span class="gi">+    df = GeoDataFrame(geometry=[city_hall_walls[0], linestring_3D])</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {</span>
<span class="gi">+        &quot;geometry&quot;: [&quot;3D LineString&quot;, &quot;LineString&quot;],</span>
<span class="gi">+        &quot;properties&quot;: OrderedDict(),</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_only_3D_linestrings():</span>
<span class="gi">+    df = GeoDataFrame(geometry=[linestring_3D, linestring_3D])</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {</span>
<span class="gi">+        &quot;geometry&quot;: &quot;3D LineString&quot;,</span>
<span class="gi">+        &quot;properties&quot;: OrderedDict(),</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_mixed_3D_Polygon():</span>
<span class="gi">+    df = GeoDataFrame(geometry=[city_hall_boundaries, polygon_3D])</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {</span>
<span class="gi">+        &quot;geometry&quot;: [&quot;3D Polygon&quot;, &quot;Polygon&quot;],</span>
<span class="gi">+        &quot;properties&quot;: OrderedDict(),</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_only_3D_Polygons():</span>
<span class="gi">+    df = GeoDataFrame(geometry=[polygon_3D, polygon_3D])</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {&quot;geometry&quot;: &quot;3D Polygon&quot;, &quot;properties&quot;: OrderedDict()}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_null_geometry_and_2D_point():</span>
<span class="gi">+    df = GeoDataFrame(geometry=[None, city_hall_entrance])</span>
<span class="gi">+</span>
<span class="gi">+    # None geometry type is then omitted</span>
<span class="gi">+    assert infer_schema(df) == {&quot;geometry&quot;: &quot;Point&quot;, &quot;properties&quot;: OrderedDict()}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_null_geometry_and_3D_point():</span>
<span class="gi">+    df = GeoDataFrame(geometry=[None, point_3D])</span>
<span class="gi">+</span>
<span class="gi">+    # None geometry type is then omitted</span>
<span class="gi">+    assert infer_schema(df) == {&quot;geometry&quot;: &quot;3D Point&quot;, &quot;properties&quot;: OrderedDict()}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_null_geometry_all():</span>
<span class="gi">+    df = GeoDataFrame(geometry=[None, None])</span>
<span class="gi">+</span>
<span class="gi">+    # None geometry type in then replaced by &#39;Unknown&#39;</span>
<span class="gi">+    # (default geometry type supported by Fiona)</span>
<span class="gi">+    assert infer_schema(df) == {&quot;geometry&quot;: &quot;Unknown&quot;, &quot;properties&quot;: OrderedDict()}</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;array_data,dtype&quot;, [([1, 2**31 - 1], np.int32), ([1, np.nan], pd.Int32Dtype())]</span>
<span class="gi">+)</span>
<span class="gi">+def test_infer_schema_int32(array_data, dtype):</span>
<span class="gi">+    int32col = pd.array(data=array_data, dtype=dtype)</span>
<span class="gi">+    df = GeoDataFrame(geometry=[city_hall_entrance, city_hall_balcony])</span>
<span class="gi">+    df[&quot;int32_column&quot;] = int32col</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {</span>
<span class="gi">+        &quot;geometry&quot;: &quot;Point&quot;,</span>
<span class="gi">+        &quot;properties&quot;: OrderedDict([(&quot;int32_column&quot;, &quot;int32&quot;)]),</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_infer_schema_int64():</span>
<span class="gi">+    int64col = pd.array([1, np.nan], dtype=pd.Int64Dtype())</span>
<span class="gi">+    df = GeoDataFrame(geometry=[city_hall_entrance, city_hall_balcony])</span>
<span class="gi">+    df[&quot;int64_column&quot;] = int64col</span>
<span class="gi">+</span>
<span class="gi">+    assert infer_schema(df) == {</span>
<span class="gi">+        &quot;geometry&quot;: &quot;Point&quot;,</span>
<span class="gi">+        &quot;properties&quot;: OrderedDict([(&quot;int64_column&quot;, &quot;int&quot;)]),</span>
<span class="gi">+    }</span>
<span class="gh">diff --git a/geopandas/io/tests/test_pickle.py b/geopandas/io/tests/test_pickle.py</span>
<span class="gh">index 03867e3a..6d962807 100644</span>
<span class="gd">--- a/geopandas/io/tests/test_pickle.py</span>
<span class="gi">+++ b/geopandas/io/tests/test_pickle.py</span>
<span class="gu">@@ -2,11 +2,55 @@</span>
<span class="w"> </span>See generate_legacy_storage_files.py for the creation of the legacy files.

<span class="w"> </span>&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>import glob
<span class="w"> </span>import os
<span class="w"> </span>import pathlib
<span class="gi">+</span>
<span class="w"> </span>import pandas as pd
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="w"> </span>from geopandas.testing import assert_geodataframe_equal
<span class="gd">-DATA_PATH = pathlib.Path(os.path.dirname(__file__)) / &#39;data&#39;</span>
<span class="gd">-files = glob.glob(str(DATA_PATH / &#39;pickle&#39; / &#39;*.pickle&#39;))</span>
<span class="gi">+</span>
<span class="gi">+DATA_PATH = pathlib.Path(os.path.dirname(__file__)) / &quot;data&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture(scope=&quot;module&quot;)</span>
<span class="gi">+def current_pickle_data():</span>
<span class="gi">+    # our current version pickle data</span>
<span class="gi">+    from .generate_legacy_storage_files import create_pickle_data</span>
<span class="gi">+</span>
<span class="gi">+    return create_pickle_data()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+files = glob.glob(str(DATA_PATH / &quot;pickle&quot; / &quot;*.pickle&quot;))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture(params=files, ids=[p.split(&quot;/&quot;)[-1] for p in files])</span>
<span class="gi">+def legacy_pickle(request):</span>
<span class="gi">+    return request.param</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skip(</span>
<span class="gi">+    reason=(</span>
<span class="gi">+        &quot;shapely 2.0/pygeos-based unpickling currently only works for &quot;</span>
<span class="gi">+        &quot;shapely-2.0/pygeos-written files&quot;</span>
<span class="gi">+    ),</span>
<span class="gi">+)</span>
<span class="gi">+def test_legacy_pickles(current_pickle_data, legacy_pickle):</span>
<span class="gi">+    result = pd.read_pickle(legacy_pickle)</span>
<span class="gi">+</span>
<span class="gi">+    for name, value in result.items():</span>
<span class="gi">+        expected = current_pickle_data[name]</span>
<span class="gi">+        assert_geodataframe_equal(value, expected)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_round_trip_current(tmpdir, current_pickle_data):</span>
<span class="gi">+    data = current_pickle_data</span>
<span class="gi">+</span>
<span class="gi">+    for name, value in data.items():</span>
<span class="gi">+        path = str(tmpdir / &quot;{}.pickle&quot;.format(name))</span>
<span class="gi">+        value.to_pickle(path)</span>
<span class="gi">+        result = pd.read_pickle(path)</span>
<span class="gi">+        assert_geodataframe_equal(result, value)</span>
<span class="gi">+        assert isinstance(result.has_sindex, bool)</span>
<span class="gh">diff --git a/geopandas/io/tests/test_sql.py b/geopandas/io/tests/test_sql.py</span>
<span class="gh">index 00f0209c..d394098f 100644</span>
<span class="gd">--- a/geopandas/io/tests/test_sql.py</span>
<span class="gi">+++ b/geopandas/io/tests/test_sql.py</span>
<span class="gu">@@ -4,38 +4,67 @@ The spatial database tests may not work without additional system</span>
<span class="w"> </span>configuration. postGIS tests require a test database to have been setup;
<span class="w"> </span>see geopandas.tests.util for more information.
<span class="w"> </span>&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>import os
<span class="w"> </span>import warnings
<span class="w"> </span>from importlib.util import find_spec
<span class="gi">+</span>
<span class="w"> </span>import pandas as pd
<span class="gi">+</span>
<span class="w"> </span>import geopandas
<span class="w"> </span>import geopandas._compat as compat
<span class="w"> </span>from geopandas import GeoDataFrame, read_file, read_postgis
<span class="w"> </span>from geopandas._compat import HAS_PYPROJ
<span class="w"> </span>from geopandas.io.sql import _get_conn as get_conn
<span class="w"> </span>from geopandas.io.sql import _write_postgis as write_postgis
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gd">-from geopandas.tests.util import create_postgis, create_spatialite, mock, validate_boro_df</span>
<span class="gi">+from geopandas.tests.util import (</span>
<span class="gi">+    create_postgis,</span>
<span class="gi">+    create_spatialite,</span>
<span class="gi">+    mock,</span>
<span class="gi">+    validate_boro_df,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="w"> </span>try:
<span class="w"> </span>    from sqlalchemy import text
<span class="w"> </span>except ImportError:
<span class="gi">+    # Avoid local imports for text in all sqlalchemy tests</span>
<span class="gi">+    # all tests using text use engine_postgis, which ensures sqlalchemy is available</span>
<span class="w"> </span>    text = str


<span class="gd">-def check_available_postgis_drivers() -&gt;list[str]:</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def df_nybb(nybb_filename):</span>
<span class="gi">+    df = read_file(nybb_filename)</span>
<span class="gi">+    return df</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def check_available_postgis_drivers() -&gt; list[str]:</span>
<span class="w"> </span>    &quot;&quot;&quot;Work out which of psycopg2 and psycopg are available.
<span class="w"> </span>    This prevents tests running if the relevant package isn&#39;t installed
<span class="w"> </span>    (rather than being skipped, as skips are treated as failures during postgis CI)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    drivers = []</span>
<span class="gi">+    if find_spec(&quot;psycopg&quot;):</span>
<span class="gi">+        drivers.append(&quot;psycopg&quot;)</span>
<span class="gi">+    if find_spec(&quot;psycopg2&quot;):</span>
<span class="gi">+        drivers.append(&quot;psycopg2&quot;)</span>
<span class="gi">+    return drivers</span>


<span class="w"> </span>POSTGIS_DRIVERS = check_available_postgis_drivers()


<span class="gd">-def prepare_database_credentials() -&gt;dict:</span>
<span class="gi">+def prepare_database_credentials() -&gt; dict:</span>
<span class="w"> </span>    &quot;&quot;&quot;Gather postgres connection credentials from environment variables.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return {</span>
<span class="gi">+        &quot;dbname&quot;: &quot;test_geopandas&quot;,</span>
<span class="gi">+        &quot;user&quot;: os.environ.get(&quot;PGUSER&quot;),</span>
<span class="gi">+        &quot;password&quot;: os.environ.get(&quot;PGPASSWORD&quot;),</span>
<span class="gi">+        &quot;host&quot;: os.environ.get(&quot;PGHOST&quot;),</span>
<span class="gi">+        &quot;port&quot;: os.environ.get(&quot;PGPORT&quot;),</span>
<span class="gi">+    }</span>


<span class="w"> </span>@pytest.fixture()
<span class="gu">@@ -43,7 +72,18 @@ def connection_postgis(request):</span>
<span class="w"> </span>    &quot;&quot;&quot;Create a postgres connection using either psycopg2 or psycopg.

<span class="w"> </span>    Use this as an indirect fixture, where the request parameter is POSTGIS_DRIVERS.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    psycopg = pytest.importorskip(request.param)</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        con = psycopg.connect(**prepare_database_credentials())</span>
<span class="gi">+    except psycopg.OperationalError:</span>
<span class="gi">+        pytest.skip(&quot;Cannot connect with postgresql database&quot;)</span>
<span class="gi">+    with warnings.catch_warnings():</span>
<span class="gi">+        warnings.filterwarnings(</span>
<span class="gi">+            &quot;ignore&quot;, message=&quot;pandas only supports SQLAlchemy connectable.*&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+        yield con</span>
<span class="gi">+    con.close()</span>


<span class="w"> </span>@pytest.fixture()
<span class="gu">@@ -53,7 +93,27 @@ def engine_postgis(request):</span>

<span class="w"> </span>    Use this as an indirect fixture, where the request parameter is POSTGIS_DRIVERS.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    sqlalchemy = pytest.importorskip(&quot;sqlalchemy&quot;)</span>
<span class="gi">+    from sqlalchemy.engine.url import URL</span>
<span class="gi">+</span>
<span class="gi">+    credentials = prepare_database_credentials()</span>
<span class="gi">+    try:</span>
<span class="gi">+        con = sqlalchemy.create_engine(</span>
<span class="gi">+            URL.create(</span>
<span class="gi">+                drivername=f&quot;postgresql+{request.param}&quot;,</span>
<span class="gi">+                username=credentials[&quot;user&quot;],</span>
<span class="gi">+                database=credentials[&quot;dbname&quot;],</span>
<span class="gi">+                password=credentials[&quot;password&quot;],</span>
<span class="gi">+                host=credentials[&quot;host&quot;],</span>
<span class="gi">+                port=credentials[&quot;port&quot;],</span>
<span class="gi">+            )</span>
<span class="gi">+        )</span>
<span class="gi">+        con.connect()</span>
<span class="gi">+    except Exception:</span>
<span class="gi">+        pytest.skip(&quot;Cannot connect with postgresql database&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    yield con</span>
<span class="gi">+    con.dispose()</span>


<span class="w"> </span>@pytest.fixture()
<span class="gu">@@ -72,186 +132,747 @@ def connection_spatialite():</span>
<span class="w"> </span>    ``AttributeError`` on missing support for loadable SQLite extensions
<span class="w"> </span>    ``sqlite3.OperationalError`` on missing SpatiaLite
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    sqlite3 = pytest.importorskip(&quot;sqlite3&quot;)</span>
<span class="gi">+    try:</span>
<span class="gi">+        with sqlite3.connect(&quot;:memory:&quot;) as con:</span>
<span class="gi">+            con.enable_load_extension(True)</span>
<span class="gi">+            con.load_extension(&quot;mod_spatialite&quot;)</span>
<span class="gi">+            con.execute(&quot;SELECT InitSpatialMetaData(TRUE)&quot;)</span>
<span class="gi">+    except Exception:</span>
<span class="gi">+        con.close()</span>
<span class="gi">+        pytest.skip(&quot;Cannot setup spatialite database&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    yield con</span>
<span class="gi">+    con.close()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def drop_table_if_exists(conn_or_engine, table):</span>
<span class="gi">+    sqlalchemy = pytest.importorskip(&quot;sqlalchemy&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if sqlalchemy.inspect(conn_or_engine).has_table(table):</span>
<span class="gi">+        metadata = sqlalchemy.MetaData()</span>
<span class="gi">+        with warnings.catch_warnings():</span>
<span class="gi">+            warnings.filterwarnings(</span>
<span class="gi">+                &quot;ignore&quot;, message=&quot;Did not recognize type &#39;geometry&#39; of column.*&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+            metadata.reflect(conn_or_engine)</span>
<span class="gi">+        table = metadata.tables.get(table)</span>
<span class="gi">+        if table is not None:</span>
<span class="gi">+            table.drop(conn_or_engine, checkfirst=True)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def df_mixed_single_and_multi():</span>
<span class="gi">+    from shapely.geometry import LineString, MultiLineString, Point</span>
<span class="gi">+</span>
<span class="gi">+    df = geopandas.GeoDataFrame(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;geometry&quot;: [</span>
<span class="gi">+                LineString([(0, 0), (1, 1)]),</span>
<span class="gi">+                MultiLineString([[(0, 0), (1, 1)], [(2, 2), (3, 3)]]),</span>
<span class="gi">+                Point(0, 1),</span>
<span class="gi">+            ]</span>
<span class="gi">+        },</span>
<span class="gi">+        crs=&quot;epsg:4326&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+    return df</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def df_geom_collection():</span>
<span class="gi">+    from shapely.geometry import GeometryCollection, LineString, Point, Polygon</span>
<span class="gi">+</span>
<span class="gi">+    df = geopandas.GeoDataFrame(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;geometry&quot;: [</span>
<span class="gi">+                GeometryCollection(</span>
<span class="gi">+                    [</span>
<span class="gi">+                        Polygon([(0, 0), (1, 1), (0, 1)]),</span>
<span class="gi">+                        LineString([(0, 0), (1, 1)]),</span>
<span class="gi">+                        Point(0, 0),</span>
<span class="gi">+                    ]</span>
<span class="gi">+                )</span>
<span class="gi">+            ]</span>
<span class="gi">+        },</span>
<span class="gi">+        crs=&quot;epsg:4326&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+    return df</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def df_linear_ring():</span>
<span class="gi">+    from shapely.geometry import LinearRing</span>
<span class="gi">+</span>
<span class="gi">+    df = geopandas.GeoDataFrame(</span>
<span class="gi">+        {&quot;geometry&quot;: [LinearRing(((0, 0), (0, 1), (1, 1), (1, 0)))]}, crs=&quot;epsg:4326&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    return df</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def df_3D_geoms():</span>
<span class="gi">+    from shapely.geometry import LineString, Point, Polygon</span>
<span class="gi">+</span>
<span class="gi">+    df = geopandas.GeoDataFrame(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;geometry&quot;: [</span>
<span class="gi">+                LineString([(0, 0, 0), (1, 1, 1)]),</span>
<span class="gi">+                Polygon([(0, 0, 0), (1, 1, 1), (0, 1, 1)]),</span>
<span class="gi">+                Point(0, 1, 2),</span>
<span class="gi">+            ]</span>
<span class="gi">+        },</span>
<span class="gi">+        crs=&quot;epsg:4326&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+    return df</span>


<span class="w"> </span>class TestIO:
<span class="gd">-</span>
<span class="gd">-    @pytest.mark.parametrize(&#39;connection_postgis&#39;, POSTGIS_DRIVERS,</span>
<span class="gd">-        indirect=True)</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_get_conn(self, engine_postgis):</span>
<span class="gi">+        Connection = pytest.importorskip(&quot;sqlalchemy.engine.base&quot;).Connection</span>
<span class="gi">+</span>
<span class="gi">+        engine = engine_postgis</span>
<span class="gi">+        with get_conn(engine) as output:</span>
<span class="gi">+            assert isinstance(output, Connection)</span>
<span class="gi">+        with engine.connect() as conn:</span>
<span class="gi">+            with get_conn(conn) as output:</span>
<span class="gi">+                assert isinstance(output, Connection)</span>
<span class="gi">+        with pytest.raises(ValueError):</span>
<span class="gi">+            with get_conn(object()):</span>
<span class="gi">+                pass</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;connection_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_read_postgis_default(self, connection_postgis, df_nybb):</span>
<span class="gi">+        con = connection_postgis</span>
<span class="gi">+        create_postgis(con, df_nybb)</span>
<span class="gi">+</span>
<span class="gi">+        sql = &quot;SELECT * FROM nybb;&quot;</span>
<span class="gi">+        df = read_postgis(sql, con)</span>
<span class="gi">+</span>
<span class="gi">+        validate_boro_df(df)</span>
<span class="gi">+        # no crs defined on the created geodatabase, and none specified</span>
<span class="gi">+        # by user; should not be set to 0, as from get_srid failure</span>
<span class="gi">+        assert df.crs is None</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;connection_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_read_postgis_custom_geom_col(self, connection_postgis, df_nybb):</span>
<span class="gi">+        con = connection_postgis</span>
<span class="gi">+        geom_col = &quot;the_geom&quot;</span>
<span class="gi">+        create_postgis(con, df_nybb, geom_col=geom_col)</span>
<span class="gi">+</span>
<span class="gi">+        sql = &quot;SELECT * FROM nybb;&quot;</span>
<span class="gi">+        df = read_postgis(sql, con, geom_col=geom_col)</span>
<span class="gi">+</span>
<span class="gi">+        validate_boro_df(df)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;connection_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="w"> </span>    def test_read_postgis_select_geom_as(self, connection_postgis, df_nybb):
<span class="w"> </span>        &quot;&quot;&quot;Tests that a SELECT {geom} AS {some_other_geom} works.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        con = connection_postgis</span>
<span class="gi">+        orig_geom = &quot;geom&quot;</span>
<span class="gi">+        out_geom = &quot;the_geom&quot;</span>
<span class="gi">+        create_postgis(con, df_nybb, geom_col=orig_geom)</span>
<span class="gi">+</span>
<span class="gi">+        sql = &quot;&quot;&quot;SELECT borocode, boroname, shape_leng, shape_area,</span>
<span class="gi">+                    {} as {} FROM nybb;&quot;&quot;&quot;.format(</span>
<span class="gi">+            orig_geom, out_geom</span>
<span class="gi">+        )</span>
<span class="gi">+        df = read_postgis(sql, con, geom_col=out_geom)</span>
<span class="gi">+</span>
<span class="gi">+        validate_boro_df(df)</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;connection_postgis&#39;, POSTGIS_DRIVERS,</span>
<span class="gd">-        indirect=True)</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;connection_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="w"> </span>    def test_read_postgis_get_srid(self, connection_postgis, df_nybb):
<span class="w"> </span>        &quot;&quot;&quot;Tests that an SRID can be read from a geodatabase (GH #451).&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        con = connection_postgis</span>
<span class="gi">+        crs = &quot;epsg:4269&quot;</span>
<span class="gi">+        df_reproj = df_nybb.to_crs(crs)</span>
<span class="gi">+        create_postgis(con, df_reproj, srid=4269)</span>
<span class="gi">+</span>
<span class="gi">+        sql = &quot;SELECT * FROM nybb;&quot;</span>
<span class="gi">+        df = read_postgis(sql, con)</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;connection_postgis&#39;, POSTGIS_DRIVERS,</span>
<span class="gd">-        indirect=True)</span>
<span class="gi">+        validate_boro_df(df)</span>
<span class="gi">+        assert df.crs == crs</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;connection_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="w"> </span>    def test_read_postgis_override_srid(self, connection_postgis, df_nybb):
<span class="w"> </span>        &quot;&quot;&quot;Tests that a user specified CRS overrides the geodatabase SRID.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        con = connection_postgis</span>
<span class="gi">+        orig_crs = df_nybb.crs</span>
<span class="gi">+        create_postgis(con, df_nybb, srid=4269)</span>
<span class="gi">+</span>
<span class="gi">+        sql = &quot;SELECT * FROM nybb;&quot;</span>
<span class="gi">+        df = read_postgis(sql, con, crs=orig_crs)</span>
<span class="gi">+</span>
<span class="gi">+        validate_boro_df(df)</span>
<span class="gi">+        assert df.crs == orig_crs</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;connection_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_from_postgis_default(self, connection_postgis, df_nybb):</span>
<span class="gi">+        con = connection_postgis</span>
<span class="gi">+        create_postgis(con, df_nybb)</span>
<span class="gi">+</span>
<span class="gi">+        sql = &quot;SELECT * FROM nybb;&quot;</span>
<span class="gi">+        df = GeoDataFrame.from_postgis(sql, con)</span>
<span class="gi">+</span>
<span class="gi">+        validate_boro_df(df, case_sensitive=False)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;connection_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_from_postgis_custom_geom_col(self, connection_postgis, df_nybb):</span>
<span class="gi">+        con = connection_postgis</span>
<span class="gi">+        geom_col = &quot;the_geom&quot;</span>
<span class="gi">+        create_postgis(con, df_nybb, geom_col=geom_col)</span>
<span class="gi">+</span>
<span class="gi">+        sql = &quot;SELECT * FROM nybb;&quot;</span>
<span class="gi">+        df = GeoDataFrame.from_postgis(sql, con, geom_col=geom_col)</span>
<span class="gi">+</span>
<span class="gi">+        validate_boro_df(df, case_sensitive=False)</span>

<span class="w"> </span>    def test_read_postgis_null_geom(self, connection_spatialite, df_nybb):
<span class="w"> </span>        &quot;&quot;&quot;Tests that geometry with NULL is accepted.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        con = connection_spatialite</span>
<span class="gi">+        geom_col = df_nybb.geometry.name</span>
<span class="gi">+        df_nybb.geometry.iat[0] = None</span>
<span class="gi">+        create_spatialite(con, df_nybb)</span>
<span class="gi">+        sql = (</span>
<span class="gi">+            &quot;SELECT ogc_fid, borocode, boroname, shape_leng, shape_area, &quot;</span>
<span class="gi">+            &#39;AsEWKB(&quot;{0}&quot;) AS &quot;{0}&quot; FROM nybb&#39;.format(geom_col)</span>
<span class="gi">+        )</span>
<span class="gi">+        df = read_postgis(sql, con, geom_col=geom_col)</span>
<span class="gi">+        validate_boro_df(df)</span>

<span class="w"> </span>    def test_read_postgis_binary(self, connection_spatialite, df_nybb):
<span class="w"> </span>        &quot;&quot;&quot;Tests that geometry read as binary is accepted.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        con = connection_spatialite</span>
<span class="gi">+        geom_col = df_nybb.geometry.name</span>
<span class="gi">+        create_spatialite(con, df_nybb)</span>
<span class="gi">+        sql = (</span>
<span class="gi">+            &quot;SELECT ogc_fid, borocode, boroname, shape_leng, shape_area, &quot;</span>
<span class="gi">+            &#39;ST_AsBinary(&quot;{0}&quot;) AS &quot;{0}&quot; FROM nybb&#39;.format(geom_col)</span>
<span class="gi">+        )</span>
<span class="gi">+        df = read_postgis(sql, con, geom_col=geom_col)</span>
<span class="gi">+        validate_boro_df(df)</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;connection_postgis&#39;, POSTGIS_DRIVERS,</span>
<span class="gd">-        indirect=True)</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;connection_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="w"> </span>    def test_read_postgis_chunksize(self, connection_postgis, df_nybb):
<span class="w"> </span>        &quot;&quot;&quot;Test chunksize argument&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        chunksize = 2</span>
<span class="gi">+        con = connection_postgis</span>
<span class="gi">+        create_postgis(con, df_nybb)</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+        sql = &quot;SELECT * FROM nybb;&quot;</span>
<span class="gi">+        df = pd.concat(read_postgis(sql, con, chunksize=chunksize))</span>
<span class="gi">+</span>
<span class="gi">+        validate_boro_df(df)</span>
<span class="gi">+        # no crs defined on the created geodatabase, and none specified</span>
<span class="gi">+        # by user; should not be set to 0, as from get_srid failure</span>
<span class="gi">+        assert df.crs is None</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="w"> </span>    def test_write_postgis_default(self, engine_postgis, df_nybb):
<span class="w"> </span>        &quot;&quot;&quot;Tests that GeoDataFrame can be written to PostGIS with defaults.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>
<span class="gi">+        table = &quot;nybb&quot;</span>
<span class="gi">+</span>
<span class="gi">+        # If table exists, delete it before trying to write with defaults</span>
<span class="gi">+        drop_table_if_exists(engine, table)</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+        # Write to db</span>
<span class="gi">+        write_postgis(df_nybb, con=engine, name=table, if_exists=&quot;fail&quot;)</span>
<span class="gi">+        # Validate</span>
<span class="gi">+        sql = text(&quot;SELECT * FROM {table};&quot;.format(table=table))</span>
<span class="gi">+        df = read_postgis(sql, engine, geom_col=&quot;geometry&quot;)</span>
<span class="gi">+        validate_boro_df(df)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="w"> </span>    def test_write_postgis_uppercase_tablename(self, engine_postgis, df_nybb):
<span class="w"> </span>        &quot;&quot;&quot;Tests writing GeoDataFrame to PostGIS with uppercase tablename.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>
<span class="gi">+        table = &quot;aTestTable&quot;</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gd">-    def test_write_postgis_sqlalchemy_connection(self, engine_postgis, df_nybb</span>
<span class="gd">-        ):</span>
<span class="gi">+        # If table exists, delete it before trying to write with defaults</span>
<span class="gi">+        drop_table_if_exists(engine, table)</span>
<span class="gi">+</span>
<span class="gi">+        # Write to db</span>
<span class="gi">+        write_postgis(df_nybb, con=engine, name=table, if_exists=&quot;fail&quot;)</span>
<span class="gi">+        # Validate</span>
<span class="gi">+        sql = text(&#39;SELECT * FROM &quot;{table}&quot;;&#39;.format(table=table))</span>
<span class="gi">+        df = read_postgis(sql, engine, geom_col=&quot;geometry&quot;)</span>
<span class="gi">+        validate_boro_df(df)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_write_postgis_sqlalchemy_connection(self, engine_postgis, df_nybb):</span>
<span class="w"> </span>        &quot;&quot;&quot;Tests that GeoDataFrame can be written to PostGIS with defaults.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with engine_postgis.begin() as con:</span>
<span class="gi">+            table = &quot;nybb_con&quot;</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gd">-    def test_write_postgis_fail_when_table_exists(self, engine_postgis, df_nybb</span>
<span class="gd">-        ):</span>
<span class="gi">+            # If table exists, delete it before trying to write with defaults</span>
<span class="gi">+            drop_table_if_exists(con, table)</span>
<span class="gi">+</span>
<span class="gi">+            # Write to db</span>
<span class="gi">+            write_postgis(df_nybb, con=con, name=table, if_exists=&quot;fail&quot;)</span>
<span class="gi">+            # Validate</span>
<span class="gi">+            sql = text(&quot;SELECT * FROM {table};&quot;.format(table=table))</span>
<span class="gi">+            df = read_postgis(sql, con, geom_col=&quot;geometry&quot;)</span>
<span class="gi">+            validate_boro_df(df)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_write_postgis_fail_when_table_exists(self, engine_postgis, df_nybb):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Tests that uploading the same table raises error when: if_replace=&#39;fail&#39;.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gd">-    def test_write_postgis_replace_when_table_exists(self, engine_postgis,</span>
<span class="gd">-        df_nybb):</span>
<span class="gi">+        table = &quot;nybb&quot;</span>
<span class="gi">+</span>
<span class="gi">+        # Ensure table exists</span>
<span class="gi">+        write_postgis(df_nybb, con=engine, name=table, if_exists=&quot;replace&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        try:</span>
<span class="gi">+            write_postgis(df_nybb, con=engine, name=table, if_exists=&quot;fail&quot;)</span>
<span class="gi">+        except ValueError as e:</span>
<span class="gi">+            if &quot;already exists&quot; in str(e):</span>
<span class="gi">+                pass</span>
<span class="gi">+            else:</span>
<span class="gi">+                raise e</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_write_postgis_replace_when_table_exists(self, engine_postgis, df_nybb):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Tests that replacing a table is possible when: if_replace=&#39;replace&#39;.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>
<span class="gi">+</span>
<span class="gi">+        table = &quot;nybb&quot;</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gd">-    def test_write_postgis_append_when_table_exists(self, engine_postgis,</span>
<span class="gd">-        df_nybb):</span>
<span class="gi">+        # Ensure table exists</span>
<span class="gi">+        write_postgis(df_nybb, con=engine, name=table, if_exists=&quot;replace&quot;)</span>
<span class="gi">+        # Overwrite</span>
<span class="gi">+        write_postgis(df_nybb, con=engine, name=table, if_exists=&quot;replace&quot;)</span>
<span class="gi">+        # Validate</span>
<span class="gi">+        sql = text(&quot;SELECT * FROM {table};&quot;.format(table=table))</span>
<span class="gi">+        df = read_postgis(sql, engine, geom_col=&quot;geometry&quot;)</span>
<span class="gi">+        validate_boro_df(df)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_write_postgis_append_when_table_exists(self, engine_postgis, df_nybb):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Tests that appending to existing table produces correct results when:
<span class="w"> </span>        if_replace=&#39;append&#39;.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>
<span class="gi">+</span>
<span class="gi">+        table = &quot;nybb&quot;</span>
<span class="gi">+</span>
<span class="gi">+        orig_rows, orig_cols = df_nybb.shape</span>
<span class="gi">+        write_postgis(df_nybb, con=engine, name=table, if_exists=&quot;replace&quot;)</span>
<span class="gi">+        write_postgis(df_nybb, con=engine, name=table, if_exists=&quot;append&quot;)</span>
<span class="gi">+        # Validate</span>
<span class="gi">+        sql = text(&quot;SELECT * FROM {table};&quot;.format(table=table))</span>
<span class="gi">+        df = read_postgis(sql, engine, geom_col=&quot;geometry&quot;)</span>
<span class="gi">+        new_rows, new_cols = df.shape</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+        # There should be twice as many rows in the new table</span>
<span class="gi">+        assert new_rows == orig_rows * 2, (</span>
<span class="gi">+            &quot;There should be {target} rows,found: {current}&quot;.format(</span>
<span class="gi">+                target=orig_rows * 2, current=new_rows</span>
<span class="gi">+            ),</span>
<span class="gi">+        )</span>
<span class="gi">+        # Number of columns should stay the same</span>
<span class="gi">+        assert new_cols == orig_cols, (</span>
<span class="gi">+            &quot;There should be {target} columns,found: {current}&quot;.format(</span>
<span class="gi">+                target=orig_cols, current=new_cols</span>
<span class="gi">+            ),</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="w"> </span>    def test_write_postgis_without_crs(self, engine_postgis, df_nybb):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Tests that GeoDataFrame can be written to PostGIS without CRS information.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>
<span class="gi">+</span>
<span class="gi">+        table = &quot;nybb&quot;</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+        # Write to db</span>
<span class="gi">+        df_nybb.geometry.array.crs = None</span>
<span class="gi">+        with pytest.warns(UserWarning, match=&quot;Could not parse CRS from the GeoDataF&quot;):</span>
<span class="gi">+            write_postgis(df_nybb, con=engine, name=table, if_exists=&quot;replace&quot;)</span>
<span class="gi">+        # Validate that srid is -1</span>
<span class="gi">+        sql = text(</span>
<span class="gi">+            &quot;SELECT Find_SRID(&#39;{schema}&#39;, &#39;{table}&#39;, &#39;{geom_col}&#39;);&quot;.format(</span>
<span class="gi">+                schema=&quot;public&quot;, table=table, geom_col=&quot;geometry&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        )</span>
<span class="gi">+        with engine.connect() as conn:</span>
<span class="gi">+            target_srid = conn.execute(sql).fetchone()[0]</span>
<span class="gi">+        assert target_srid == 0, &quot;SRID should be 0, found %s&quot; % target_srid</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="w"> </span>    def test_write_postgis_with_esri_authority(self, engine_postgis, df_nybb):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Tests that GeoDataFrame can be written to PostGIS with ESRI Authority
<span class="w"> </span>        CRS information (GH #2414).
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>
<span class="gi">+</span>
<span class="gi">+        table = &quot;nybb&quot;</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gd">-    def test_write_postgis_geometry_collection(self, engine_postgis,</span>
<span class="gd">-        df_geom_collection):</span>
<span class="gi">+        # Write to db</span>
<span class="gi">+        df_nybb_esri = df_nybb.to_crs(&quot;ESRI:102003&quot;)</span>
<span class="gi">+        write_postgis(df_nybb_esri, con=engine, name=table, if_exists=&quot;replace&quot;)</span>
<span class="gi">+        # Validate that srid is 102003</span>
<span class="gi">+        sql = text(</span>
<span class="gi">+            &quot;SELECT Find_SRID(&#39;{schema}&#39;, &#39;{table}&#39;, &#39;{geom_col}&#39;);&quot;.format(</span>
<span class="gi">+                schema=&quot;public&quot;, table=table, geom_col=&quot;geometry&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        )</span>
<span class="gi">+        with engine.connect() as conn:</span>
<span class="gi">+            target_srid = conn.execute(sql).fetchone()[0]</span>
<span class="gi">+        assert target_srid == 102003, &quot;SRID should be 102003, found %s&quot; % target_srid</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_write_postgis_geometry_collection(</span>
<span class="gi">+        self, engine_postgis, df_geom_collection</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Tests that writing a mix of different geometry types is possible.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>
<span class="gi">+</span>
<span class="gi">+        table = &quot;geomtype_tests&quot;</span>
<span class="gi">+</span>
<span class="gi">+        write_postgis(df_geom_collection, con=engine, name=table, if_exists=&quot;replace&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        # Validate geometry type</span>
<span class="gi">+        sql = text(</span>
<span class="gi">+            &quot;SELECT DISTINCT(GeometryType(geometry)) FROM {table} ORDER BY 1;&quot;.format(</span>
<span class="gi">+                table=table</span>
<span class="gi">+            )</span>
<span class="gi">+        )</span>
<span class="gi">+        with engine.connect() as conn:</span>
<span class="gi">+            geom_type = conn.execute(sql).fetchone()[0]</span>
<span class="gi">+        sql = text(&quot;SELECT * FROM {table};&quot;.format(table=table))</span>
<span class="gi">+        df = read_postgis(sql, engine, geom_col=&quot;geometry&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        assert geom_type.upper() == &quot;GEOMETRYCOLLECTION&quot;</span>
<span class="gi">+        assert df.geom_type.unique()[0] == &quot;GeometryCollection&quot;</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gd">-    def test_write_postgis_mixed_geometry_types(self, engine_postgis,</span>
<span class="gd">-        df_mixed_single_and_multi):</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_write_postgis_mixed_geometry_types(</span>
<span class="gi">+        self, engine_postgis, df_mixed_single_and_multi</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Tests that writing a mix of single and MultiGeometries is possible.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+        table = &quot;geomtype_tests&quot;</span>
<span class="gi">+</span>
<span class="gi">+        write_postgis(</span>
<span class="gi">+            df_mixed_single_and_multi, con=engine, name=table, if_exists=&quot;replace&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        # Validate geometry type</span>
<span class="gi">+        sql = text(</span>
<span class="gi">+            &quot;SELECT DISTINCT GeometryType(geometry) FROM {table} ORDER BY 1;&quot;.format(</span>
<span class="gi">+                table=table</span>
<span class="gi">+            )</span>
<span class="gi">+        )</span>
<span class="gi">+        with engine.connect() as conn:</span>
<span class="gi">+            res = conn.execute(sql).fetchall()</span>
<span class="gi">+        assert res[0][0].upper() == &quot;LINESTRING&quot;</span>
<span class="gi">+        assert res[1][0].upper() == &quot;MULTILINESTRING&quot;</span>
<span class="gi">+        assert res[2][0].upper() == &quot;POINT&quot;</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="w"> </span>    def test_write_postgis_linear_ring(self, engine_postgis, df_linear_ring):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Tests that writing a LinearRing.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>
<span class="gi">+</span>
<span class="gi">+        table = &quot;geomtype_tests&quot;</span>
<span class="gi">+</span>
<span class="gi">+        write_postgis(df_linear_ring, con=engine, name=table, if_exists=&quot;replace&quot;)</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gd">-    def test_write_postgis_in_chunks(self, engine_postgis,</span>
<span class="gd">-        df_mixed_single_and_multi):</span>
<span class="gi">+        # Validate geometry type</span>
<span class="gi">+        sql = text(</span>
<span class="gi">+            &quot;SELECT DISTINCT(GeometryType(geometry)) FROM {table} ORDER BY 1;&quot;.format(</span>
<span class="gi">+                table=table</span>
<span class="gi">+            )</span>
<span class="gi">+        )</span>
<span class="gi">+        with engine.connect() as conn:</span>
<span class="gi">+            geom_type = conn.execute(sql).fetchone()[0]</span>
<span class="gi">+</span>
<span class="gi">+        assert geom_type.upper() == &quot;LINESTRING&quot;</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_write_postgis_in_chunks(self, engine_postgis, df_mixed_single_and_multi):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Tests writing a LinearRing works.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>
<span class="gi">+</span>
<span class="gi">+        table = &quot;geomtype_tests&quot;</span>
<span class="gi">+</span>
<span class="gi">+        write_postgis(</span>
<span class="gi">+            df_mixed_single_and_multi,</span>
<span class="gi">+            con=engine,</span>
<span class="gi">+            name=table,</span>
<span class="gi">+            if_exists=&quot;replace&quot;,</span>
<span class="gi">+            chunksize=1,</span>
<span class="gi">+        )</span>
<span class="gi">+        # Validate row count</span>
<span class="gi">+        sql = text(&quot;SELECT COUNT(geometry) FROM {table};&quot;.format(table=table))</span>
<span class="gi">+        with engine.connect() as conn:</span>
<span class="gi">+            row_cnt = conn.execute(sql).fetchone()[0]</span>
<span class="gi">+        assert row_cnt == 3</span>
<span class="gi">+</span>
<span class="gi">+        # Validate geometry type</span>
<span class="gi">+        sql = text(</span>
<span class="gi">+            &quot;SELECT DISTINCT GeometryType(geometry) FROM {table} ORDER BY 1;&quot;.format(</span>
<span class="gi">+                table=table</span>
<span class="gi">+            )</span>
<span class="gi">+        )</span>
<span class="gi">+        with engine.connect() as conn:</span>
<span class="gi">+            res = conn.execute(sql).fetchall()</span>
<span class="gi">+        assert res[0][0].upper() == &quot;LINESTRING&quot;</span>
<span class="gi">+        assert res[1][0].upper() == &quot;MULTILINESTRING&quot;</span>
<span class="gi">+        assert res[2][0].upper() == &quot;POINT&quot;</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="w"> </span>    def test_write_postgis_to_different_schema(self, engine_postgis, df_nybb):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Tests writing data to alternative schema.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gd">-    def test_write_postgis_to_different_schema_when_table_exists(self,</span>
<span class="gd">-        engine_postgis, df_nybb):</span>
<span class="gi">+        table = &quot;nybb&quot;</span>
<span class="gi">+        schema_to_use = &quot;test&quot;</span>
<span class="gi">+        sql = text(&quot;CREATE SCHEMA IF NOT EXISTS {schema};&quot;.format(schema=schema_to_use))</span>
<span class="gi">+        with engine.begin() as conn:</span>
<span class="gi">+            conn.execute(sql)</span>
<span class="gi">+</span>
<span class="gi">+        write_postgis(</span>
<span class="gi">+            df_nybb, con=engine, name=table, if_exists=&quot;replace&quot;, schema=schema_to_use</span>
<span class="gi">+        )</span>
<span class="gi">+        # Validate</span>
<span class="gi">+        sql = text(</span>
<span class="gi">+            &quot;SELECT * FROM {schema}.{table};&quot;.format(schema=schema_to_use, table=table)</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        df = read_postgis(sql, engine, geom_col=&quot;geometry&quot;)</span>
<span class="gi">+        validate_boro_df(df)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_write_postgis_to_different_schema_when_table_exists(</span>
<span class="gi">+        self, engine_postgis, df_nybb</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Tests writing data to alternative schema.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>
<span class="gi">+</span>
<span class="gi">+        table = &quot;nybb&quot;</span>
<span class="gi">+        schema_to_use = &quot;test&quot;</span>
<span class="gi">+        sql = text(&quot;CREATE SCHEMA IF NOT EXISTS {schema};&quot;.format(schema=schema_to_use))</span>
<span class="gi">+        with engine.begin() as conn:</span>
<span class="gi">+            conn.execute(sql)</span>
<span class="gi">+</span>
<span class="gi">+        try:</span>
<span class="gi">+            write_postgis(</span>
<span class="gi">+                df_nybb, con=engine, name=table, if_exists=&quot;fail&quot;, schema=schema_to_use</span>
<span class="gi">+            )</span>
<span class="gi">+            # Validate</span>
<span class="gi">+            sql = text(</span>
<span class="gi">+                &quot;SELECT * FROM {schema}.{table};&quot;.format(</span>
<span class="gi">+                    schema=schema_to_use, table=table</span>
<span class="gi">+                )</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            df = read_postgis(sql, engine, geom_col=&quot;geometry&quot;)</span>
<span class="gi">+            validate_boro_df(df)</span>
<span class="gi">+</span>
<span class="gi">+        # Should raise a ValueError when table exists</span>
<span class="gi">+        except ValueError:</span>
<span class="gi">+            pass</span>
<span class="gi">+</span>
<span class="gi">+        # Try with replace flag on</span>
<span class="gi">+        write_postgis(</span>
<span class="gi">+            df_nybb, con=engine, name=table, if_exists=&quot;replace&quot;, schema=schema_to_use</span>
<span class="gi">+        )</span>
<span class="gi">+        # Validate</span>
<span class="gi">+        sql = text(</span>
<span class="gi">+            &quot;SELECT * FROM {schema}.{table};&quot;.format(schema=schema_to_use, table=table)</span>
<span class="gi">+        )</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+        df = read_postgis(sql, engine, geom_col=&quot;geometry&quot;)</span>
<span class="gi">+        validate_boro_df(df)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="w"> </span>    def test_write_postgis_3D_geometries(self, engine_postgis, df_3D_geoms):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Tests writing a geometries with 3 dimensions works.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>
<span class="gi">+</span>
<span class="gi">+        table = &quot;geomtype_tests&quot;</span>
<span class="gi">+</span>
<span class="gi">+        write_postgis(df_3D_geoms, con=engine, name=table, if_exists=&quot;replace&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        # Check that all geometries have 3 dimensions</span>
<span class="gi">+        sql = text(&quot;SELECT * FROM {table};&quot;.format(table=table))</span>
<span class="gi">+        df = read_postgis(sql, engine, geom_col=&quot;geometry&quot;)</span>
<span class="gi">+        assert list(df.geometry.has_z) == [True, True, True]</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="w"> </span>    def test_row_order(self, engine_postgis, df_nybb):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Tests that the row order in db table follows the order of the original frame.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>
<span class="gi">+</span>
<span class="gi">+        table = &quot;row_order_test&quot;</span>
<span class="gi">+        correct_order = df_nybb[&quot;BoroCode&quot;].tolist()</span>
<span class="gi">+</span>
<span class="gi">+        write_postgis(df_nybb, con=engine, name=table, if_exists=&quot;replace&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        # Check that the row order matches</span>
<span class="gi">+        sql = text(&quot;SELECT * FROM {table};&quot;.format(table=table))</span>
<span class="gi">+        df = read_postgis(sql, engine, geom_col=&quot;geometry&quot;)</span>
<span class="gi">+        assert df[&quot;BoroCode&quot;].tolist() == correct_order</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="w"> </span>    def test_append_before_table_exists(self, engine_postgis, df_nybb):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Tests that insert works with if_exists=&#39;append&#39; when table does not exist yet.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+        table = &quot;nybb&quot;</span>
<span class="gi">+        # If table exists, delete it before trying to write with defaults</span>
<span class="gi">+        drop_table_if_exists(engine, table)</span>
<span class="gi">+</span>
<span class="gi">+        write_postgis(df_nybb, con=engine, name=table, if_exists=&quot;append&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        # Check that the row order matches</span>
<span class="gi">+        sql = text(&quot;SELECT * FROM {table};&quot;.format(table=table))</span>
<span class="gi">+        df = read_postgis(sql, engine, geom_col=&quot;geometry&quot;)</span>
<span class="gi">+        validate_boro_df(df)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="w"> </span>    def test_append_with_different_crs(self, engine_postgis, df_nybb):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Tests that the warning is raised if table CRS differs from frame.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;engine_postgis&#39;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gd">-    @pytest.mark.xfail(compat.PANDAS_GE_20 and not compat.PANDAS_GE_202,</span>
<span class="gd">-        reason=</span>
<span class="gd">-        &#39;Duplicate columns are dropped in read_sql with pandas 2.0.0 and 2.0.1&#39;</span>
<span class="gd">-        )</span>
<span class="gi">+        table = &quot;nybb&quot;</span>
<span class="gi">+        write_postgis(df_nybb, con=engine, name=table, if_exists=&quot;replace&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        # Reproject</span>
<span class="gi">+        df_nybb2 = df_nybb.to_crs(epsg=4326)</span>
<span class="gi">+</span>
<span class="gi">+        # Should raise error when appending</span>
<span class="gi">+        with pytest.raises(ValueError, match=&quot;CRS of the target table&quot;):</span>
<span class="gi">+            write_postgis(df_nybb2, con=engine, name=table, if_exists=&quot;append&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_append_without_crs(self, engine_postgis, df_nybb):</span>
<span class="gi">+        # This test was included in #3328 when the default value for no</span>
<span class="gi">+        # CRS was changed from an SRID of -1 to 0. This resolves issues</span>
<span class="gi">+        # of appending dataframes to postgis that have no CRS as postgis</span>
<span class="gi">+        # no CRS value is 0.</span>
<span class="gi">+        engine = engine_postgis</span>
<span class="gi">+        df_nybb = df_nybb.set_crs(None, allow_override=True)</span>
<span class="gi">+        table = &quot;nybb&quot;</span>
<span class="gi">+</span>
<span class="gi">+        write_postgis(df_nybb, con=engine, name=table, if_exists=&quot;replace&quot;)</span>
<span class="gi">+        # append another dataframe with no crs</span>
<span class="gi">+</span>
<span class="gi">+        df_nybb2 = df_nybb</span>
<span class="gi">+        write_postgis(df_nybb2, con=engine, name=table, if_exists=&quot;append&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;engine_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    @pytest.mark.xfail(</span>
<span class="gi">+        compat.PANDAS_GE_20 and not compat.PANDAS_GE_202,</span>
<span class="gi">+        reason=&quot;Duplicate columns are dropped in read_sql with pandas 2.0.0 and 2.0.1&quot;,</span>
<span class="gi">+    )</span>
<span class="w"> </span>    def test_duplicate_geometry_column_fails(self, engine_postgis):
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Tests that a ValueError is raised if an SQL query returns two geometry columns.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        engine = engine_postgis</span>
<span class="gi">+</span>
<span class="gi">+        sql = &quot;select ST_MakePoint(0, 0) as geom, ST_MakePoint(0, 0) as geom;&quot;</span>
<span class="gi">+</span>
<span class="gi">+        with pytest.raises(ValueError):</span>
<span class="gi">+            read_postgis(sql, engine, geom_col=&quot;geom&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;connection_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_read_non_epsg_crs(self, connection_postgis, df_nybb):</span>
<span class="gi">+        con = connection_postgis</span>
<span class="gi">+        df_nybb = df_nybb.to_crs(crs=&quot;esri:54052&quot;)</span>
<span class="gi">+        create_postgis(con, df_nybb, srid=54052)</span>
<span class="gi">+</span>
<span class="gi">+        sql = &quot;SELECT * FROM nybb;&quot;</span>
<span class="gi">+        df = read_postgis(sql, con)</span>
<span class="gi">+        validate_boro_df(df)</span>
<span class="gi">+        assert df.crs == &quot;ESRI:54052&quot;</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;connection_postgis&#39;, POSTGIS_DRIVERS,</span>
<span class="gd">-        indirect=True)</span>
<span class="gi">+    @pytest.mark.skipif(not HAS_PYPROJ, reason=&quot;pyproj not installed&quot;)</span>
<span class="gi">+    @mock.patch(&quot;shapely.get_srid&quot;)</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;connection_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_read_srid_not_in_table(self, mock_get_srid, connection_postgis, df_nybb):</span>
<span class="gi">+        # mock a non-existent srid for edge case if shapely has an srid</span>
<span class="gi">+        # not present in postgis table.</span>
<span class="gi">+        pyproj = pytest.importorskip(&quot;pyproj&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        mock_get_srid.return_value = 99999</span>
<span class="gi">+</span>
<span class="gi">+        con = connection_postgis</span>
<span class="gi">+        df_nybb = df_nybb.to_crs(crs=&quot;epsg:4326&quot;)</span>
<span class="gi">+        create_postgis(con, df_nybb)</span>
<span class="gi">+</span>
<span class="gi">+        sql = &quot;SELECT * FROM nybb;&quot;</span>
<span class="gi">+        with pytest.raises(pyproj.exceptions.CRSError, match=&quot;crs not found&quot;):</span>
<span class="gi">+            with pytest.warns(UserWarning, match=&quot;Could not find srid 99999&quot;):</span>
<span class="gi">+                read_postgis(sql, con)</span>
<span class="gi">+</span>
<span class="gi">+    @mock.patch(&quot;geopandas.io.sql._get_spatial_ref_sys_df&quot;)</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;connection_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="gi">+    def test_read_no_spatial_ref_sys_table_in_postgis(</span>
<span class="gi">+        self, mock_get_spatial_ref_sys_df, connection_postgis, df_nybb</span>
<span class="gi">+    ):</span>
<span class="gi">+        # mock for a non-existent spatial_ref_sys database</span>
<span class="gi">+</span>
<span class="gi">+        mock_get_spatial_ref_sys_df.side_effect = pd.errors.DatabaseError</span>
<span class="gi">+</span>
<span class="gi">+        con = connection_postgis</span>
<span class="gi">+        df_nybb = df_nybb.to_crs(crs=&quot;epsg:4326&quot;)</span>
<span class="gi">+        create_postgis(con, df_nybb, srid=4326)</span>
<span class="gi">+</span>
<span class="gi">+        sql = &quot;SELECT * FROM nybb;&quot;</span>
<span class="gi">+        with pytest.warns(</span>
<span class="gi">+            UserWarning, match=&quot;Could not find the spatial reference system table&quot;</span>
<span class="gi">+        ):</span>
<span class="gi">+            df = read_postgis(sql, con)</span>
<span class="gi">+</span>
<span class="gi">+        assert df.crs == &quot;EPSG:4326&quot;</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;connection_postgis&quot;, POSTGIS_DRIVERS, indirect=True)</span>
<span class="w"> </span>    def test_read_non_epsg_crs_chunksize(self, connection_postgis, df_nybb):
<span class="w"> </span>        &quot;&quot;&quot;Test chunksize argument with non epsg crs&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        chunksize = 2</span>
<span class="gi">+        con = connection_postgis</span>
<span class="gi">+        df_nybb = df_nybb.to_crs(crs=&quot;esri:54052&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        create_postgis(con, df_nybb, srid=54052)</span>
<span class="gi">+</span>
<span class="gi">+        sql = &quot;SELECT * FROM nybb;&quot;</span>
<span class="gi">+        df = pd.concat(read_postgis(sql, con, chunksize=chunksize))</span>
<span class="gi">+</span>
<span class="gi">+        validate_boro_df(df)</span>
<span class="gi">+        assert df.crs == &quot;ESRI:54052&quot;</span>
<span class="gh">diff --git a/geopandas/io/util.py b/geopandas/io/util.py</span>
<span class="gh">index a13ec40c..86ecf69c 100644</span>
<span class="gd">--- a/geopandas/io/util.py</span>
<span class="gi">+++ b/geopandas/io/util.py</span>
<span class="gu">@@ -1,22 +1,58 @@</span>
<span class="w"> </span>&quot;&quot;&quot;Vendored, cut down version of pyogrio/util.py for use with fiona&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>import re
<span class="w"> </span>import sys
<span class="w"> </span>from urllib.parse import urlparse


<span class="gd">-def vsi_path(path: str) -&gt;str:</span>
<span class="gi">+def vsi_path(path: str) -&gt; str:</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Ensure path is a local path or a GDAL-compatible vsi path.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>

<span class="gi">+    # path is already in GDAL format</span>
<span class="gi">+    if path.startswith(&quot;/vsi&quot;):</span>
<span class="gi">+        return path</span>
<span class="gi">+</span>
<span class="gi">+    # Windows drive letters (e.g. &quot;C:\&quot;) confuse `urlparse` as they look like</span>
<span class="gi">+    # URL schemes</span>
<span class="gi">+    if sys.platform == &quot;win32&quot; and re.match(&quot;^[a-zA-Z]\\:&quot;, path):</span>
<span class="gi">+        if not path.split(&quot;!&quot;)[0].endswith(&quot;.zip&quot;):</span>
<span class="gi">+            return path</span>
<span class="gi">+</span>
<span class="gi">+        # prefix then allow to proceed with remaining parsing</span>
<span class="gi">+        path = f&quot;zip://{path}&quot;</span>
<span class="gi">+</span>
<span class="gi">+    path, archive, scheme = _parse_uri(path)</span>
<span class="gi">+</span>
<span class="gi">+    if scheme or archive or path.endswith(&quot;.zip&quot;):</span>
<span class="gi">+        return _construct_vsi_path(path, archive, scheme)</span>

<span class="gd">-SCHEMES = {&#39;file&#39;: &#39;file&#39;, &#39;zip&#39;: &#39;zip&#39;, &#39;tar&#39;: &#39;tar&#39;, &#39;gzip&#39;: &#39;gzip&#39;,</span>
<span class="gd">-    &#39;http&#39;: &#39;curl&#39;, &#39;https&#39;: &#39;curl&#39;, &#39;ftp&#39;: &#39;curl&#39;, &#39;s3&#39;: &#39;s3&#39;, &#39;gs&#39;: &#39;gs&#39;,</span>
<span class="gd">-    &#39;az&#39;: &#39;az&#39;, &#39;adls&#39;: &#39;adls&#39;, &#39;adl&#39;: &#39;adls&#39;, &#39;hdfs&#39;: &#39;hdfs&#39;, &#39;webhdfs&#39;:</span>
<span class="gd">-    &#39;webhdfs&#39;}</span>
<span class="gd">-CURLSCHEMES = {k for k, v in SCHEMES.items() if v == &#39;curl&#39;}</span>
<span class="gi">+    return path</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# Supported URI schemes and their mapping to GDAL&#39;s VSI suffix.</span>
<span class="gi">+SCHEMES = {</span>
<span class="gi">+    &quot;file&quot;: &quot;file&quot;,</span>
<span class="gi">+    &quot;zip&quot;: &quot;zip&quot;,</span>
<span class="gi">+    &quot;tar&quot;: &quot;tar&quot;,</span>
<span class="gi">+    &quot;gzip&quot;: &quot;gzip&quot;,</span>
<span class="gi">+    &quot;http&quot;: &quot;curl&quot;,</span>
<span class="gi">+    &quot;https&quot;: &quot;curl&quot;,</span>
<span class="gi">+    &quot;ftp&quot;: &quot;curl&quot;,</span>
<span class="gi">+    &quot;s3&quot;: &quot;s3&quot;,</span>
<span class="gi">+    &quot;gs&quot;: &quot;gs&quot;,</span>
<span class="gi">+    &quot;az&quot;: &quot;az&quot;,</span>
<span class="gi">+    &quot;adls&quot;: &quot;adls&quot;,</span>
<span class="gi">+    &quot;adl&quot;: &quot;adls&quot;,  # fsspec uses this</span>
<span class="gi">+    &quot;hdfs&quot;: &quot;hdfs&quot;,</span>
<span class="gi">+    &quot;webhdfs&quot;: &quot;webhdfs&quot;,</span>
<span class="gi">+    # GDAL additionally supports oss and swift for remote filesystems, but</span>
<span class="gi">+    # those are for now not added as supported URI</span>
<span class="gi">+}</span>
<span class="gi">+</span>
<span class="gi">+CURLSCHEMES = {k for k, v in SCHEMES.items() if v == &quot;curl&quot;}</span>


<span class="w"> </span>def _parse_uri(path: str):
<span class="gu">@@ -33,9 +69,50 @@ def _parse_uri(path: str):</span>
<span class="w"> </span>    scheme : str
<span class="w"> </span>        URI scheme such as &quot;https&quot; or &quot;zip+s3&quot;.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    parts = urlparse(path, allow_fragments=False)</span>
<span class="gi">+</span>
<span class="gi">+    # if the scheme is not one of GDAL&#39;s supported schemes, return raw path</span>
<span class="gi">+    if parts.scheme and not all(p in SCHEMES for p in parts.scheme.split(&quot;+&quot;)):</span>
<span class="gi">+        return path, &quot;&quot;, &quot;&quot;</span>
<span class="gi">+</span>
<span class="gi">+    # we have a URI</span>
<span class="gi">+    path = parts.path</span>
<span class="gi">+    scheme = parts.scheme or &quot;&quot;</span>

<span class="gi">+    if parts.query:</span>
<span class="gi">+        path += &quot;?&quot; + parts.query</span>

<span class="gd">-def _construct_vsi_path(path, archive, scheme) -&gt;str:</span>
<span class="gi">+    if parts.scheme and parts.netloc:</span>
<span class="gi">+        path = parts.netloc + path</span>
<span class="gi">+</span>
<span class="gi">+    parts = path.split(&quot;!&quot;)</span>
<span class="gi">+    path = parts.pop() if parts else &quot;&quot;</span>
<span class="gi">+    archive = parts.pop() if parts else &quot;&quot;</span>
<span class="gi">+    return (path, archive, scheme)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _construct_vsi_path(path, archive, scheme) -&gt; str:</span>
<span class="w"> </span>    &quot;&quot;&quot;Convert a parsed path to a GDAL VSI path&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    prefix = &quot;&quot;</span>
<span class="gi">+    suffix = &quot;&quot;</span>
<span class="gi">+    schemes = scheme.split(&quot;+&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if &quot;zip&quot; not in schemes and (archive.endswith(&quot;.zip&quot;) or path.endswith(&quot;.zip&quot;)):</span>
<span class="gi">+        schemes.insert(0, &quot;zip&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if schemes:</span>
<span class="gi">+        prefix = &quot;/&quot;.join(</span>
<span class="gi">+            &quot;vsi{0}&quot;.format(SCHEMES[p]) for p in schemes if p and p != &quot;file&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        if schemes[-1] in CURLSCHEMES:</span>
<span class="gi">+            suffix = f&quot;{schemes[-1]}://&quot;</span>
<span class="gi">+</span>
<span class="gi">+    if prefix:</span>
<span class="gi">+        if archive:</span>
<span class="gi">+            return &quot;/{}/{}{}/{}&quot;.format(prefix, suffix, archive, path.lstrip(&quot;/&quot;))</span>
<span class="gi">+        else:</span>
<span class="gi">+            return &quot;/{}/{}{}&quot;.format(prefix, suffix, path)</span>
<span class="gi">+</span>
<span class="gi">+    return path</span>
<span class="gh">diff --git a/geopandas/plotting.py b/geopandas/plotting.py</span>
<span class="gh">index 974bdc10..5c2f416e 100644</span>
<span class="gd">--- a/geopandas/plotting.py</span>
<span class="gi">+++ b/geopandas/plotting.py</span>
<span class="gu">@@ -1,14 +1,17 @@</span>
<span class="w"> </span>import warnings
<span class="w"> </span>from packaging.version import Version
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>import pandas as pd
<span class="w"> </span>from pandas import CategoricalDtype
<span class="w"> </span>from pandas.plotting import PlotAccessor
<span class="gi">+</span>
<span class="w"> </span>import geopandas
<span class="gi">+</span>
<span class="w"> </span>from ._decorator import doc


<span class="gd">-def _sanitize_geoms(geoms, prefix=&#39;Multi&#39;):</span>
<span class="gi">+def _sanitize_geoms(geoms, prefix=&quot;Multi&quot;):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Returns Series like geoms and index, except that any Multi geometries
<span class="w"> </span>    are split into their components and indices are repeated for all component
<span class="gu">@@ -25,7 +28,29 @@ def _sanitize_geoms(geoms, prefix=&#39;Multi&#39;):</span>
<span class="w"> </span>    component_index : index array
<span class="w"> </span>        indices are repeated for all components in the same Multi geometry
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # TODO(shapely) look into simplifying this with</span>
<span class="gi">+    # shapely.get_parts(geoms, return_index=True) from shapely 2.0</span>
<span class="gi">+    components, component_index = [], []</span>
<span class="gi">+</span>
<span class="gi">+    if (</span>
<span class="gi">+        not geoms.geom_type.str.startswith(prefix).any()</span>
<span class="gi">+        and not geoms.is_empty.any()</span>
<span class="gi">+        and not geoms.isna().any()</span>
<span class="gi">+    ):</span>
<span class="gi">+        return geoms, np.arange(len(geoms))</span>
<span class="gi">+</span>
<span class="gi">+    for ix, geom in enumerate(geoms):</span>
<span class="gi">+        if geom is not None and geom.geom_type.startswith(prefix) and not geom.is_empty:</span>
<span class="gi">+            for poly in geom.geoms:</span>
<span class="gi">+                components.append(poly)</span>
<span class="gi">+                component_index.append(ix)</span>
<span class="gi">+        elif geom is None or geom.is_empty:</span>
<span class="gi">+            continue</span>
<span class="gi">+        else:</span>
<span class="gi">+            components.append(geom)</span>
<span class="gi">+            component_index.append(ix)</span>
<span class="gi">+</span>
<span class="gi">+    return components, np.array(component_index)</span>


<span class="w"> </span>def _expand_kwargs(kwargs, multiindex):
<span class="gu">@@ -35,7 +60,29 @@ def _expand_kwargs(kwargs, multiindex):</span>
<span class="w"> </span>    it (in place) to the correct length/formats with help of &#39;multiindex&#39;, unless
<span class="w"> </span>    the value appears to already be a valid (single) value for the key.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    from typing import Iterable</span>
<span class="gi">+</span>
<span class="gi">+    from matplotlib.colors import is_color_like</span>
<span class="gi">+</span>
<span class="gi">+    scalar_kwargs = [&quot;marker&quot;, &quot;path_effects&quot;]</span>
<span class="gi">+    for att, value in kwargs.items():</span>
<span class="gi">+        if &quot;color&quot; in att:  # color(s), edgecolor(s), facecolor(s)</span>
<span class="gi">+            if is_color_like(value):</span>
<span class="gi">+                continue</span>
<span class="gi">+        elif &quot;linestyle&quot; in att:  # linestyle(s)</span>
<span class="gi">+            # A single linestyle can be 2-tuple of a number and an iterable.</span>
<span class="gi">+            if (</span>
<span class="gi">+                isinstance(value, tuple)</span>
<span class="gi">+                and len(value) == 2</span>
<span class="gi">+                and isinstance(value[1], Iterable)</span>
<span class="gi">+            ):</span>
<span class="gi">+                continue</span>
<span class="gi">+        elif att in scalar_kwargs:</span>
<span class="gi">+            # For these attributes, only a single value is allowed, so never expand.</span>
<span class="gi">+            continue</span>
<span class="gi">+</span>
<span class="gi">+        if pd.api.types.is_list_like(value):</span>
<span class="gi">+            kwargs[att] = np.take(value, multiindex, axis=0)</span>


<span class="w"> </span>def _PolygonPatch(polygon, **kwargs):
<span class="gu">@@ -54,11 +101,27 @@ def _PolygonPatch(polygon, **kwargs):</span>
<span class="w"> </span>    (BSD license, https://pypi.org/project/descartes) for PolygonPatch, but
<span class="w"> </span>    this dependency was removed in favor of the below matplotlib code.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def _plot_polygon_collection(ax, geoms, values=None, color=None, cmap=None,</span>
<span class="gd">-    vmin=None, vmax=None, autolim=True, **kwargs):</span>
<span class="gi">+    from matplotlib.patches import PathPatch</span>
<span class="gi">+    from matplotlib.path import Path</span>
<span class="gi">+</span>
<span class="gi">+    path = Path.make_compound_path(</span>
<span class="gi">+        Path(np.asarray(polygon.exterior.coords)[:, :2]),</span>
<span class="gi">+        *[Path(np.asarray(ring.coords)[:, :2]) for ring in polygon.interiors],</span>
<span class="gi">+    )</span>
<span class="gi">+    return PathPatch(path, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _plot_polygon_collection(</span>
<span class="gi">+    ax,</span>
<span class="gi">+    geoms,</span>
<span class="gi">+    values=None,</span>
<span class="gi">+    color=None,</span>
<span class="gi">+    cmap=None,</span>
<span class="gi">+    vmin=None,</span>
<span class="gi">+    vmax=None,</span>
<span class="gi">+    autolim=True,</span>
<span class="gi">+    **kwargs,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Plots a collection of Polygon and MultiPolygon geometries to `ax`

<span class="gu">@@ -87,11 +150,49 @@ def _plot_polygon_collection(ax, geoms, values=None, color=None, cmap=None,</span>
<span class="w"> </span>    -------
<span class="w"> </span>    collection : matplotlib.collections.Collection that was plotted
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def _plot_linestring_collection(ax, geoms, values=None, color=None, cmap=</span>
<span class="gd">-    None, vmin=None, vmax=None, autolim=True, **kwargs):</span>
<span class="gi">+    from matplotlib.collections import PatchCollection</span>
<span class="gi">+</span>
<span class="gi">+    geoms, multiindex = _sanitize_geoms(geoms)</span>
<span class="gi">+    if values is not None:</span>
<span class="gi">+        values = np.take(values, multiindex, axis=0)</span>
<span class="gi">+</span>
<span class="gi">+    # PatchCollection does not accept some kwargs.</span>
<span class="gi">+    kwargs = {</span>
<span class="gi">+        att: value</span>
<span class="gi">+        for att, value in kwargs.items()</span>
<span class="gi">+        if att not in [&quot;markersize&quot;, &quot;marker&quot;]</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+    # Add to kwargs for easier checking below.</span>
<span class="gi">+    if color is not None:</span>
<span class="gi">+        kwargs[&quot;color&quot;] = color</span>
<span class="gi">+</span>
<span class="gi">+    _expand_kwargs(kwargs, multiindex)</span>
<span class="gi">+</span>
<span class="gi">+    collection = PatchCollection([_PolygonPatch(poly) for poly in geoms], **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    if values is not None:</span>
<span class="gi">+        collection.set_array(np.asarray(values))</span>
<span class="gi">+        collection.set_cmap(cmap)</span>
<span class="gi">+        if &quot;norm&quot; not in kwargs:</span>
<span class="gi">+            collection.set_clim(vmin, vmax)</span>
<span class="gi">+</span>
<span class="gi">+    ax.add_collection(collection, autolim=autolim)</span>
<span class="gi">+    ax.autoscale_view()</span>
<span class="gi">+    return collection</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _plot_linestring_collection(</span>
<span class="gi">+    ax,</span>
<span class="gi">+    geoms,</span>
<span class="gi">+    values=None,</span>
<span class="gi">+    color=None,</span>
<span class="gi">+    cmap=None,</span>
<span class="gi">+    vmin=None,</span>
<span class="gi">+    vmax=None,</span>
<span class="gi">+    autolim=True,</span>
<span class="gi">+    **kwargs,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Plots a collection of LineString and MultiLineString geometries to `ax`

<span class="gu">@@ -113,11 +214,51 @@ def _plot_linestring_collection(ax, geoms, values=None, color=None, cmap=</span>
<span class="w"> </span>    -------
<span class="w"> </span>    collection : matplotlib.collections.Collection that was plotted
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def _plot_point_collection(ax, geoms, values=None, color=None, cmap=None,</span>
<span class="gd">-    vmin=None, vmax=None, marker=&#39;o&#39;, markersize=None, **kwargs):</span>
<span class="gi">+    from matplotlib.collections import LineCollection</span>
<span class="gi">+</span>
<span class="gi">+    geoms, multiindex = _sanitize_geoms(geoms)</span>
<span class="gi">+    if values is not None:</span>
<span class="gi">+        values = np.take(values, multiindex, axis=0)</span>
<span class="gi">+</span>
<span class="gi">+    # LineCollection does not accept some kwargs.</span>
<span class="gi">+    kwargs = {</span>
<span class="gi">+        att: value</span>
<span class="gi">+        for att, value in kwargs.items()</span>
<span class="gi">+        if att not in [&quot;markersize&quot;, &quot;marker&quot;]</span>
<span class="gi">+    }</span>
<span class="gi">+</span>
<span class="gi">+    # Add to kwargs for easier checking below.</span>
<span class="gi">+    if color is not None:</span>
<span class="gi">+        kwargs[&quot;color&quot;] = color</span>
<span class="gi">+</span>
<span class="gi">+    _expand_kwargs(kwargs, multiindex)</span>
<span class="gi">+</span>
<span class="gi">+    segments = [np.array(linestring.coords)[:, :2] for linestring in geoms]</span>
<span class="gi">+    collection = LineCollection(segments, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    if values is not None:</span>
<span class="gi">+        collection.set_array(np.asarray(values))</span>
<span class="gi">+        collection.set_cmap(cmap)</span>
<span class="gi">+        if &quot;norm&quot; not in kwargs:</span>
<span class="gi">+            collection.set_clim(vmin, vmax)</span>
<span class="gi">+</span>
<span class="gi">+    ax.add_collection(collection, autolim=autolim)</span>
<span class="gi">+    ax.autoscale_view()</span>
<span class="gi">+    return collection</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _plot_point_collection(</span>
<span class="gi">+    ax,</span>
<span class="gi">+    geoms,</span>
<span class="gi">+    values=None,</span>
<span class="gi">+    color=None,</span>
<span class="gi">+    cmap=None,</span>
<span class="gi">+    vmin=None,</span>
<span class="gi">+    vmax=None,</span>
<span class="gi">+    marker=&quot;o&quot;,</span>
<span class="gi">+    markersize=None,</span>
<span class="gi">+    **kwargs,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Plots a collection of Point and MultiPoint geometries to `ax`

<span class="gu">@@ -139,11 +280,46 @@ def _plot_point_collection(ax, geoms, values=None, color=None, cmap=None,</span>
<span class="w"> </span>    -------
<span class="w"> </span>    collection : matplotlib.collections.Collection that was plotted
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def plot_series(s, cmap=None, color=None, ax=None, figsize=None, aspect=</span>
<span class="gd">-    &#39;auto&#39;, autolim=True, **style_kwds):</span>
<span class="gi">+    if values is not None and color is not None:</span>
<span class="gi">+        raise ValueError(&quot;Can only specify one of &#39;values&#39; and &#39;color&#39; kwargs&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    geoms, multiindex = _sanitize_geoms(geoms)</span>
<span class="gi">+    # values are expanded below as kwargs[&quot;c&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    x = [p.x if not p.is_empty else None for p in geoms]</span>
<span class="gi">+    y = [p.y if not p.is_empty else None for p in geoms]</span>
<span class="gi">+</span>
<span class="gi">+    # matplotlib 1.4 does not support c=None, and &lt; 2.0 does not support s=None</span>
<span class="gi">+    if values is not None:</span>
<span class="gi">+        kwargs[&quot;c&quot;] = values</span>
<span class="gi">+    if markersize is not None:</span>
<span class="gi">+        kwargs[&quot;s&quot;] = markersize</span>
<span class="gi">+</span>
<span class="gi">+    # Add to kwargs for easier checking below.</span>
<span class="gi">+    if color is not None:</span>
<span class="gi">+        kwargs[&quot;color&quot;] = color</span>
<span class="gi">+    if marker is not None:</span>
<span class="gi">+        kwargs[&quot;marker&quot;] = marker</span>
<span class="gi">+    _expand_kwargs(kwargs, multiindex)</span>
<span class="gi">+</span>
<span class="gi">+    if &quot;norm&quot; not in kwargs:</span>
<span class="gi">+        collection = ax.scatter(x, y, vmin=vmin, vmax=vmax, cmap=cmap, **kwargs)</span>
<span class="gi">+    else:</span>
<span class="gi">+        collection = ax.scatter(x, y, cmap=cmap, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    return collection</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def plot_series(</span>
<span class="gi">+    s,</span>
<span class="gi">+    cmap=None,</span>
<span class="gi">+    color=None,</span>
<span class="gi">+    ax=None,</span>
<span class="gi">+    figsize=None,</span>
<span class="gi">+    aspect=&quot;auto&quot;,</span>
<span class="gi">+    autolim=True,</span>
<span class="gi">+    **style_kwds,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Plot a GeoSeries.

<span class="gu">@@ -189,14 +365,147 @@ def plot_series(s, cmap=None, color=None, ax=None, figsize=None, aspect=</span>
<span class="w"> </span>    -------
<span class="w"> </span>    ax : matplotlib axes instance
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>

<span class="gd">-def plot_dataframe(df, column=None, cmap=None, color=None, ax=None, cax=</span>
<span class="gd">-    None, categorical=False, legend=False, scheme=None, k=5, vmin=None,</span>
<span class="gd">-    vmax=None, markersize=None, figsize=None, legend_kwds=None, categories=</span>
<span class="gd">-    None, classification_kwds=None, missing_kwds=None, aspect=&#39;auto&#39;,</span>
<span class="gd">-    autolim=True, **style_kwds):</span>
<span class="gi">+    try:</span>
<span class="gi">+        import matplotlib.pyplot as plt</span>
<span class="gi">+    except ImportError:</span>
<span class="gi">+        raise ImportError(</span>
<span class="gi">+            &quot;The matplotlib package is required for plotting in geopandas. &quot;</span>
<span class="gi">+            &quot;You can install it using &#39;conda install -c conda-forge matplotlib&#39; or &quot;</span>
<span class="gi">+            &quot;&#39;pip install matplotlib&#39;.&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    if ax is None:</span>
<span class="gi">+        fig, ax = plt.subplots(figsize=figsize)</span>
<span class="gi">+</span>
<span class="gi">+    if aspect == &quot;auto&quot;:</span>
<span class="gi">+        if s.crs and s.crs.is_geographic:</span>
<span class="gi">+            bounds = s.total_bounds</span>
<span class="gi">+            y_coord = np.mean([bounds[1], bounds[3]])</span>
<span class="gi">+            ax.set_aspect(1 / np.cos(y_coord * np.pi / 180))</span>
<span class="gi">+            # formula ported from R package sp</span>
<span class="gi">+            # https://github.com/edzer/sp/blob/master/R/mapasp.R</span>
<span class="gi">+        else:</span>
<span class="gi">+            ax.set_aspect(&quot;equal&quot;)</span>
<span class="gi">+    elif aspect is not None:</span>
<span class="gi">+        ax.set_aspect(aspect)</span>
<span class="gi">+</span>
<span class="gi">+    if s.empty:</span>
<span class="gi">+        warnings.warn(</span>
<span class="gi">+            &quot;The GeoSeries you are attempting to plot is &quot;</span>
<span class="gi">+            &quot;empty. Nothing has been displayed.&quot;,</span>
<span class="gi">+            UserWarning,</span>
<span class="gi">+            stacklevel=3,</span>
<span class="gi">+        )</span>
<span class="gi">+        return ax</span>
<span class="gi">+</span>
<span class="gi">+    if s.is_empty.all():</span>
<span class="gi">+        warnings.warn(</span>
<span class="gi">+            &quot;The GeoSeries you are attempting to plot is &quot;</span>
<span class="gi">+            &quot;composed of empty geometries. Nothing has been displayed.&quot;,</span>
<span class="gi">+            UserWarning,</span>
<span class="gi">+            stacklevel=3,</span>
<span class="gi">+        )</span>
<span class="gi">+        return ax</span>
<span class="gi">+</span>
<span class="gi">+    # have colors been given for all geometries?</span>
<span class="gi">+    color_given = pd.api.types.is_list_like(color) and len(color) == len(s)</span>
<span class="gi">+</span>
<span class="gi">+    # if cmap is specified, create range of colors based on cmap</span>
<span class="gi">+    values = None</span>
<span class="gi">+    if cmap is not None:</span>
<span class="gi">+        values = np.arange(len(s))</span>
<span class="gi">+        if hasattr(cmap, &quot;N&quot;):</span>
<span class="gi">+            values = values % cmap.N</span>
<span class="gi">+        style_kwds[&quot;vmin&quot;] = style_kwds.get(&quot;vmin&quot;, values.min())</span>
<span class="gi">+        style_kwds[&quot;vmax&quot;] = style_kwds.get(&quot;vmax&quot;, values.max())</span>
<span class="gi">+</span>
<span class="gi">+    # decompose GeometryCollections</span>
<span class="gi">+    geoms, multiindex = _sanitize_geoms(s.geometry, prefix=&quot;Geom&quot;)</span>
<span class="gi">+    values = np.take(values, multiindex, axis=0) if cmap else None</span>
<span class="gi">+    # ensure indexes are consistent</span>
<span class="gi">+    if color_given and isinstance(color, pd.Series):</span>
<span class="gi">+        color = color.reindex(s.index)</span>
<span class="gi">+    expl_color = np.take(color, multiindex, axis=0) if color_given else color</span>
<span class="gi">+    expl_series = geopandas.GeoSeries(geoms)</span>
<span class="gi">+</span>
<span class="gi">+    geom_types = expl_series.geom_type</span>
<span class="gi">+    poly_idx = np.asarray((geom_types == &quot;Polygon&quot;) | (geom_types == &quot;MultiPolygon&quot;))</span>
<span class="gi">+    line_idx = np.asarray(</span>
<span class="gi">+        (geom_types == &quot;LineString&quot;)</span>
<span class="gi">+        | (geom_types == &quot;MultiLineString&quot;)</span>
<span class="gi">+        | (geom_types == &quot;LinearRing&quot;)</span>
<span class="gi">+    )</span>
<span class="gi">+    point_idx = np.asarray((geom_types == &quot;Point&quot;) | (geom_types == &quot;MultiPoint&quot;))</span>
<span class="gi">+</span>
<span class="gi">+    # plot all Polygons and all MultiPolygon components in the same collection</span>
<span class="gi">+    polys = expl_series[poly_idx]</span>
<span class="gi">+    if not polys.empty:</span>
<span class="gi">+        # color overrides both face and edgecolor. As we want people to be</span>
<span class="gi">+        # able to use edgecolor as well, pass color to facecolor</span>
<span class="gi">+        facecolor = style_kwds.pop(&quot;facecolor&quot;, None)</span>
<span class="gi">+        color_ = expl_color[poly_idx] if color_given else color</span>
<span class="gi">+        if color is not None:</span>
<span class="gi">+            facecolor = color_</span>
<span class="gi">+</span>
<span class="gi">+        values_ = values[poly_idx] if cmap else None</span>
<span class="gi">+        _plot_polygon_collection(</span>
<span class="gi">+            ax,</span>
<span class="gi">+            polys,</span>
<span class="gi">+            values_,</span>
<span class="gi">+            facecolor=facecolor,</span>
<span class="gi">+            cmap=cmap,</span>
<span class="gi">+            autolim=autolim,</span>
<span class="gi">+            **style_kwds,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    # plot all LineStrings and MultiLineString components in same collection</span>
<span class="gi">+    lines = expl_series[line_idx]</span>
<span class="gi">+    if not lines.empty:</span>
<span class="gi">+        values_ = values[line_idx] if cmap else None</span>
<span class="gi">+        color_ = expl_color[line_idx] if color_given else color</span>
<span class="gi">+</span>
<span class="gi">+        _plot_linestring_collection(</span>
<span class="gi">+            ax, lines, values_, color=color_, cmap=cmap, autolim=autolim, **style_kwds</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    # plot all Points in the same collection</span>
<span class="gi">+    points = expl_series[point_idx]</span>
<span class="gi">+    if not points.empty:</span>
<span class="gi">+        values_ = values[point_idx] if cmap else None</span>
<span class="gi">+        color_ = expl_color[point_idx] if color_given else color</span>
<span class="gi">+</span>
<span class="gi">+        _plot_point_collection(</span>
<span class="gi">+            ax, points, values_, color=color_, cmap=cmap, **style_kwds</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    ax.figure.canvas.draw_idle()</span>
<span class="gi">+    return ax</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def plot_dataframe(</span>
<span class="gi">+    df,</span>
<span class="gi">+    column=None,</span>
<span class="gi">+    cmap=None,</span>
<span class="gi">+    color=None,</span>
<span class="gi">+    ax=None,</span>
<span class="gi">+    cax=None,</span>
<span class="gi">+    categorical=False,</span>
<span class="gi">+    legend=False,</span>
<span class="gi">+    scheme=None,</span>
<span class="gi">+    k=5,</span>
<span class="gi">+    vmin=None,</span>
<span class="gi">+    vmax=None,</span>
<span class="gi">+    markersize=None,</span>
<span class="gi">+    figsize=None,</span>
<span class="gi">+    legend_kwds=None,</span>
<span class="gi">+    categories=None,</span>
<span class="gi">+    classification_kwds=None,</span>
<span class="gi">+    missing_kwds=None,</span>
<span class="gi">+    aspect=&quot;auto&quot;,</span>
<span class="gi">+    autolim=True,</span>
<span class="gi">+    **style_kwds,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Plot a GeoDataFrame.

<span class="gu">@@ -326,7 +635,326 @@ def plot_dataframe(df, column=None, cmap=None, color=None, ax=None, cax=</span>
<span class="w"> </span>    See the User Guide page :doc:`../../user_guide/mapping` for details.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if column is not None and color is not None:</span>
<span class="gi">+        warnings.warn(</span>
<span class="gi">+            &quot;Only specify one of &#39;column&#39; or &#39;color&#39;. Using &#39;color&#39;.&quot;,</span>
<span class="gi">+            UserWarning,</span>
<span class="gi">+            stacklevel=3,</span>
<span class="gi">+        )</span>
<span class="gi">+        column = None</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        import matplotlib.pyplot as plt</span>
<span class="gi">+    except ImportError:</span>
<span class="gi">+        raise ImportError(</span>
<span class="gi">+            &quot;The matplotlib package is required for plotting in geopandas. &quot;</span>
<span class="gi">+            &quot;You can install it using &#39;conda install -c conda-forge matplotlib&#39; or &quot;</span>
<span class="gi">+            &quot;&#39;pip install matplotlib&#39;.&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    if ax is None:</span>
<span class="gi">+        if cax is not None:</span>
<span class="gi">+            raise ValueError(&quot;&#39;ax&#39; can not be None if &#39;cax&#39; is not.&quot;)</span>
<span class="gi">+        fig, ax = plt.subplots(figsize=figsize)</span>
<span class="gi">+</span>
<span class="gi">+    if aspect == &quot;auto&quot;:</span>
<span class="gi">+        if df.crs and df.crs.is_geographic:</span>
<span class="gi">+            bounds = df.total_bounds</span>
<span class="gi">+            y_coord = np.mean([bounds[1], bounds[3]])</span>
<span class="gi">+            ax.set_aspect(1 / np.cos(y_coord * np.pi / 180))</span>
<span class="gi">+            # formula ported from R package sp</span>
<span class="gi">+            # https://github.com/edzer/sp/blob/master/R/mapasp.R</span>
<span class="gi">+        else:</span>
<span class="gi">+            ax.set_aspect(&quot;equal&quot;)</span>
<span class="gi">+    elif aspect is not None:</span>
<span class="gi">+        ax.set_aspect(aspect)</span>
<span class="gi">+</span>
<span class="gi">+    # GH 1555</span>
<span class="gi">+    # if legend_kwds set, copy so we don&#39;t update it in place</span>
<span class="gi">+    if legend_kwds is not None:</span>
<span class="gi">+        legend_kwds = legend_kwds.copy()</span>
<span class="gi">+</span>
<span class="gi">+    if df.empty:</span>
<span class="gi">+        warnings.warn(</span>
<span class="gi">+            &quot;The GeoDataFrame you are attempting to plot is &quot;</span>
<span class="gi">+            &quot;empty. Nothing has been displayed.&quot;,</span>
<span class="gi">+            UserWarning,</span>
<span class="gi">+            stacklevel=3,</span>
<span class="gi">+        )</span>
<span class="gi">+        return ax</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(markersize, str):</span>
<span class="gi">+        markersize = df[markersize].values</span>
<span class="gi">+</span>
<span class="gi">+    if column is None:</span>
<span class="gi">+        return plot_series(</span>
<span class="gi">+            df.geometry,</span>
<span class="gi">+            cmap=cmap,</span>
<span class="gi">+            color=color,</span>
<span class="gi">+            ax=ax,</span>
<span class="gi">+            figsize=figsize,</span>
<span class="gi">+            markersize=markersize,</span>
<span class="gi">+            aspect=aspect,</span>
<span class="gi">+            autolim=autolim,</span>
<span class="gi">+            **style_kwds,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    # To accept pd.Series and np.arrays as column</span>
<span class="gi">+    if isinstance(column, (np.ndarray, pd.Series)):</span>
<span class="gi">+        if column.shape[0] != df.shape[0]:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;The dataframe and given column have different number of rows.&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        else:</span>
<span class="gi">+            values = column</span>
<span class="gi">+</span>
<span class="gi">+            # Make sure index of a Series matches index of df</span>
<span class="gi">+            if isinstance(values, pd.Series):</span>
<span class="gi">+                values = values.reindex(df.index)</span>
<span class="gi">+    else:</span>
<span class="gi">+        values = df[column]</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(values.dtype, CategoricalDtype):</span>
<span class="gi">+        if categories is not None:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;Cannot specify &#39;categories&#39; when column has categorical dtype&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+        categorical = True</span>
<span class="gi">+    elif (</span>
<span class="gi">+        pd.api.types.is_object_dtype(values.dtype)</span>
<span class="gi">+        or pd.api.types.is_bool_dtype(values.dtype)</span>
<span class="gi">+        or pd.api.types.is_string_dtype(values.dtype)</span>
<span class="gi">+        or categories</span>
<span class="gi">+    ):</span>
<span class="gi">+        categorical = True</span>
<span class="gi">+</span>
<span class="gi">+    nan_idx = np.asarray(pd.isna(values), dtype=&quot;bool&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if scheme is not None:</span>
<span class="gi">+        mc_err = (</span>
<span class="gi">+            &quot;The &#39;mapclassify&#39; package (&gt;= 2.4.0) is &quot;</span>
<span class="gi">+            &quot;required to use the &#39;scheme&#39; keyword.&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+        try:</span>
<span class="gi">+            import mapclassify</span>
<span class="gi">+</span>
<span class="gi">+        except ImportError:</span>
<span class="gi">+            raise ImportError(mc_err)</span>
<span class="gi">+</span>
<span class="gi">+        if Version(mapclassify.__version__) &lt; Version(&quot;2.4.0&quot;):</span>
<span class="gi">+            raise ImportError(mc_err)</span>
<span class="gi">+</span>
<span class="gi">+        if classification_kwds is None:</span>
<span class="gi">+            classification_kwds = {}</span>
<span class="gi">+        if &quot;k&quot; not in classification_kwds:</span>
<span class="gi">+            classification_kwds[&quot;k&quot;] = k</span>
<span class="gi">+</span>
<span class="gi">+        binning = mapclassify.classify(</span>
<span class="gi">+            np.asarray(values[~nan_idx]), scheme, **classification_kwds</span>
<span class="gi">+        )</span>
<span class="gi">+        # set categorical to True for creating the legend</span>
<span class="gi">+        categorical = True</span>
<span class="gi">+        if legend_kwds is not None and &quot;labels&quot; in legend_kwds:</span>
<span class="gi">+            if len(legend_kwds[&quot;labels&quot;]) != binning.k:</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    &quot;Number of labels must match number of bins, &quot;</span>
<span class="gi">+                    &quot;received {} labels for {} bins&quot;.format(</span>
<span class="gi">+                        len(legend_kwds[&quot;labels&quot;]), binning.k</span>
<span class="gi">+                    )</span>
<span class="gi">+                )</span>
<span class="gi">+            else:</span>
<span class="gi">+                labels = list(legend_kwds.pop(&quot;labels&quot;))</span>
<span class="gi">+        else:</span>
<span class="gi">+            fmt = &quot;{:.2f}&quot;</span>
<span class="gi">+            if legend_kwds is not None and &quot;fmt&quot; in legend_kwds:</span>
<span class="gi">+                fmt = legend_kwds.pop(&quot;fmt&quot;)</span>
<span class="gi">+</span>
<span class="gi">+            labels = binning.get_legend_classes(fmt)</span>
<span class="gi">+            if legend_kwds is not None:</span>
<span class="gi">+                show_interval = legend_kwds.pop(&quot;interval&quot;, False)</span>
<span class="gi">+            else:</span>
<span class="gi">+                show_interval = False</span>
<span class="gi">+            if not show_interval:</span>
<span class="gi">+                labels = [c[1:-1] for c in labels]</span>
<span class="gi">+</span>
<span class="gi">+        values = pd.Categorical(</span>
<span class="gi">+            [np.nan] * len(values), categories=binning.bins, ordered=True</span>
<span class="gi">+        )</span>
<span class="gi">+        values[~nan_idx] = pd.Categorical.from_codes(</span>
<span class="gi">+            binning.yb, categories=binning.bins, ordered=True</span>
<span class="gi">+        )</span>
<span class="gi">+        if cmap is None:</span>
<span class="gi">+            cmap = &quot;viridis&quot;</span>
<span class="gi">+</span>
<span class="gi">+    # Define `values` as a Series</span>
<span class="gi">+    if categorical:</span>
<span class="gi">+        if cmap is None:</span>
<span class="gi">+            cmap = &quot;tab10&quot;</span>
<span class="gi">+</span>
<span class="gi">+        cat = pd.Categorical(values, categories=categories)</span>
<span class="gi">+        categories = list(cat.categories)</span>
<span class="gi">+</span>
<span class="gi">+        # values missing in the Categorical but not in original values</span>
<span class="gi">+        missing = list(np.unique(values[~nan_idx &amp; cat.isna()]))</span>
<span class="gi">+        if missing:</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;Column contains values not listed in categories. &quot;</span>
<span class="gi">+                &quot;Missing categories: {}.&quot;.format(missing)</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        values = cat.codes[~nan_idx]</span>
<span class="gi">+        vmin = 0 if vmin is None else vmin</span>
<span class="gi">+        vmax = len(categories) - 1 if vmax is None else vmax</span>
<span class="gi">+</span>
<span class="gi">+    # fill values with placeholder where were NaNs originally to map them properly</span>
<span class="gi">+    # (after removing them in categorical or scheme)</span>
<span class="gi">+    if categorical:</span>
<span class="gi">+        for n in np.where(nan_idx)[0]:</span>
<span class="gi">+            values = np.insert(values, n, values[0])</span>
<span class="gi">+</span>
<span class="gi">+    mn = values[~np.isnan(values)].min() if vmin is None else vmin</span>
<span class="gi">+    mx = values[~np.isnan(values)].max() if vmax is None else vmax</span>
<span class="gi">+</span>
<span class="gi">+    # decompose GeometryCollections</span>
<span class="gi">+    geoms, multiindex = _sanitize_geoms(df.geometry, prefix=&quot;Geom&quot;)</span>
<span class="gi">+    values = np.take(values, multiindex, axis=0)</span>
<span class="gi">+    nan_idx = np.take(nan_idx, multiindex, axis=0)</span>
<span class="gi">+    expl_series = geopandas.GeoSeries(geoms)</span>
<span class="gi">+</span>
<span class="gi">+    geom_types = expl_series.geom_type</span>
<span class="gi">+    poly_idx = np.asarray((geom_types == &quot;Polygon&quot;) | (geom_types == &quot;MultiPolygon&quot;))</span>
<span class="gi">+    line_idx = np.asarray(</span>
<span class="gi">+        (geom_types == &quot;LineString&quot;)</span>
<span class="gi">+        | (geom_types == &quot;MultiLineString&quot;)</span>
<span class="gi">+        | (geom_types == &quot;LinearRing&quot;)</span>
<span class="gi">+    )</span>
<span class="gi">+    point_idx = np.asarray((geom_types == &quot;Point&quot;) | (geom_types == &quot;MultiPoint&quot;))</span>
<span class="gi">+</span>
<span class="gi">+    # plot all Polygons and all MultiPolygon components in the same collection</span>
<span class="gi">+    polys = expl_series[poly_idx &amp; np.invert(nan_idx)]</span>
<span class="gi">+    subset = values[poly_idx &amp; np.invert(nan_idx)]</span>
<span class="gi">+    if not polys.empty:</span>
<span class="gi">+        _plot_polygon_collection(</span>
<span class="gi">+            ax,</span>
<span class="gi">+            polys,</span>
<span class="gi">+            subset,</span>
<span class="gi">+            vmin=mn,</span>
<span class="gi">+            vmax=mx,</span>
<span class="gi">+            cmap=cmap,</span>
<span class="gi">+            autolim=autolim,</span>
<span class="gi">+            **style_kwds,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    # plot all LineStrings and MultiLineString components in same collection</span>
<span class="gi">+    lines = expl_series[line_idx &amp; np.invert(nan_idx)]</span>
<span class="gi">+    subset = values[line_idx &amp; np.invert(nan_idx)]</span>
<span class="gi">+    if not lines.empty:</span>
<span class="gi">+        _plot_linestring_collection(</span>
<span class="gi">+            ax,</span>
<span class="gi">+            lines,</span>
<span class="gi">+            subset,</span>
<span class="gi">+            vmin=mn,</span>
<span class="gi">+            vmax=mx,</span>
<span class="gi">+            cmap=cmap,</span>
<span class="gi">+            autolim=autolim,</span>
<span class="gi">+            **style_kwds,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    # plot all Points in the same collection</span>
<span class="gi">+    points = expl_series[point_idx &amp; np.invert(nan_idx)]</span>
<span class="gi">+    subset = values[point_idx &amp; np.invert(nan_idx)]</span>
<span class="gi">+    if not points.empty:</span>
<span class="gi">+        if isinstance(markersize, np.ndarray):</span>
<span class="gi">+            markersize = np.take(markersize, multiindex, axis=0)</span>
<span class="gi">+            markersize = markersize[point_idx &amp; np.invert(nan_idx)]</span>
<span class="gi">+        _plot_point_collection(</span>
<span class="gi">+            ax,</span>
<span class="gi">+            points,</span>
<span class="gi">+            subset,</span>
<span class="gi">+            vmin=mn,</span>
<span class="gi">+            vmax=mx,</span>
<span class="gi">+            markersize=markersize,</span>
<span class="gi">+            cmap=cmap,</span>
<span class="gi">+            **style_kwds,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    missing_data = not expl_series[nan_idx].empty</span>
<span class="gi">+    if missing_kwds is not None and missing_data:</span>
<span class="gi">+        if color:</span>
<span class="gi">+            if &quot;color&quot; not in missing_kwds:</span>
<span class="gi">+                missing_kwds[&quot;color&quot;] = color</span>
<span class="gi">+</span>
<span class="gi">+        merged_kwds = style_kwds.copy()</span>
<span class="gi">+        merged_kwds.update(missing_kwds)</span>
<span class="gi">+</span>
<span class="gi">+        plot_series(expl_series[nan_idx], ax=ax, **merged_kwds)</span>
<span class="gi">+</span>
<span class="gi">+    if legend and not color:</span>
<span class="gi">+        if legend_kwds is None:</span>
<span class="gi">+            legend_kwds = {}</span>
<span class="gi">+        if &quot;fmt&quot; in legend_kwds:</span>
<span class="gi">+            legend_kwds.pop(&quot;fmt&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        from matplotlib import cm</span>
<span class="gi">+        from matplotlib.colors import Normalize</span>
<span class="gi">+        from matplotlib.lines import Line2D</span>
<span class="gi">+</span>
<span class="gi">+        norm = style_kwds.get(&quot;norm&quot;, None)</span>
<span class="gi">+        if not norm:</span>
<span class="gi">+            norm = Normalize(vmin=mn, vmax=mx)</span>
<span class="gi">+        n_cmap = cm.ScalarMappable(norm=norm, cmap=cmap)</span>
<span class="gi">+        if categorical:</span>
<span class="gi">+            if scheme is not None:</span>
<span class="gi">+                categories = labels</span>
<span class="gi">+            patches = []</span>
<span class="gi">+            for i in range(len(categories)):</span>
<span class="gi">+                patches.append(</span>
<span class="gi">+                    Line2D(</span>
<span class="gi">+                        [0],</span>
<span class="gi">+                        [0],</span>
<span class="gi">+                        linestyle=&quot;none&quot;,</span>
<span class="gi">+                        marker=&quot;o&quot;,</span>
<span class="gi">+                        alpha=style_kwds.get(&quot;alpha&quot;, 1),</span>
<span class="gi">+                        markersize=10,</span>
<span class="gi">+                        markerfacecolor=n_cmap.to_rgba(i),</span>
<span class="gi">+                        markeredgewidth=0,</span>
<span class="gi">+                    )</span>
<span class="gi">+                )</span>
<span class="gi">+            if missing_kwds is not None and missing_data:</span>
<span class="gi">+                if &quot;color&quot; in merged_kwds:</span>
<span class="gi">+                    merged_kwds[&quot;facecolor&quot;] = merged_kwds[&quot;color&quot;]</span>
<span class="gi">+                patches.append(</span>
<span class="gi">+                    Line2D(</span>
<span class="gi">+                        [0],</span>
<span class="gi">+                        [0],</span>
<span class="gi">+                        linestyle=&quot;none&quot;,</span>
<span class="gi">+                        marker=&quot;o&quot;,</span>
<span class="gi">+                        alpha=merged_kwds.get(&quot;alpha&quot;, 1),</span>
<span class="gi">+                        markersize=10,</span>
<span class="gi">+                        markerfacecolor=merged_kwds.get(&quot;facecolor&quot;, None),</span>
<span class="gi">+                        markeredgecolor=merged_kwds.get(&quot;edgecolor&quot;, None),</span>
<span class="gi">+                        markeredgewidth=merged_kwds.get(</span>
<span class="gi">+                            &quot;linewidth&quot;, 1 if merged_kwds.get(&quot;edgecolor&quot;, False) else 0</span>
<span class="gi">+                        ),</span>
<span class="gi">+                    )</span>
<span class="gi">+                )</span>
<span class="gi">+                categories.append(merged_kwds.get(&quot;label&quot;, &quot;NaN&quot;))</span>
<span class="gi">+            legend_kwds.setdefault(&quot;numpoints&quot;, 1)</span>
<span class="gi">+            legend_kwds.setdefault(&quot;loc&quot;, &quot;best&quot;)</span>
<span class="gi">+            legend_kwds.setdefault(&quot;handles&quot;, patches)</span>
<span class="gi">+            legend_kwds.setdefault(&quot;labels&quot;, categories)</span>
<span class="gi">+            ax.legend(**legend_kwds)</span>
<span class="gi">+        else:</span>
<span class="gi">+            if cax is not None:</span>
<span class="gi">+                legend_kwds.setdefault(&quot;cax&quot;, cax)</span>
<span class="gi">+            else:</span>
<span class="gi">+                legend_kwds.setdefault(&quot;ax&quot;, ax)</span>
<span class="gi">+</span>
<span class="gi">+            n_cmap.set_array(np.array([]))</span>
<span class="gi">+            ax.get_figure().colorbar(n_cmap, **legend_kwds)</span>
<span class="gi">+</span>
<span class="gi">+    ax.figure.canvas.draw_idle()</span>
<span class="gi">+    return ax</span>


<span class="w"> </span>@doc(plot_dataframe)
<span class="gu">@@ -335,10 +963,15 @@ class GeoplotAccessor(PlotAccessor):</span>

<span class="w"> </span>    def __call__(self, *args, **kwargs):
<span class="w"> </span>        data = self._parent.copy()
<span class="gd">-        kind = kwargs.pop(&#39;kind&#39;, &#39;geo&#39;)</span>
<span class="gd">-        if kind == &#39;geo&#39;:</span>
<span class="gi">+        kind = kwargs.pop(&quot;kind&quot;, &quot;geo&quot;)</span>
<span class="gi">+        if kind == &quot;geo&quot;:</span>
<span class="w"> </span>            return plot_dataframe(data, *args, **kwargs)
<span class="w"> </span>        if kind in self._pandas_kinds:
<span class="gi">+            # Access pandas plots</span>
<span class="w"> </span>            return PlotAccessor(data)(kind=kind, **kwargs)
<span class="w"> </span>        else:
<span class="gd">-            raise ValueError(f&#39;{kind} is not a valid plot kind&#39;)</span>
<span class="gi">+            # raise error</span>
<span class="gi">+            raise ValueError(f&quot;{kind} is not a valid plot kind&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def geo(self, *args, **kwargs):</span>
<span class="gi">+        return self(kind=&quot;geo&quot;, *args, **kwargs)  # noqa: B026</span>
<span class="gh">diff --git a/geopandas/sindex.py b/geopandas/sindex.py</span>
<span class="gh">index f72d4f2a..6966cc46 100644</span>
<span class="gd">--- a/geopandas/sindex.py</span>
<span class="gi">+++ b/geopandas/sindex.py</span>
<span class="gu">@@ -1,11 +1,15 @@</span>
<span class="w"> </span>import numpy as np
<span class="gi">+</span>
<span class="w"> </span>import shapely
<span class="w"> </span>from shapely.geometry.base import BaseGeometry
<span class="gi">+</span>
<span class="w"> </span>from . import _compat as compat
<span class="w"> </span>from . import array, geoseries
<span class="gi">+</span>
<span class="w"> </span>PREDICATES = {p.name for p in shapely.strtree.BinaryPredicate} | {None}
<span class="gi">+</span>
<span class="w"> </span>if compat.GEOS_GE_310:
<span class="gd">-    PREDICATES.update([&#39;dwithin&#39;])</span>
<span class="gi">+    PREDICATES.update([&quot;dwithin&quot;])</span>


<span class="w"> </span>class SpatialIndex:
<span class="gu">@@ -19,9 +23,15 @@ class SpatialIndex:</span>
<span class="w"> </span>    &quot;&quot;&quot;

<span class="w"> </span>    def __init__(self, geometry):
<span class="gi">+        # set empty geometries to None to avoid segfault on GEOS &lt;= 3.6</span>
<span class="gi">+        # see:</span>
<span class="gi">+        # https://github.com/pygeos/pygeos/issues/146</span>
<span class="gi">+        # https://github.com/pygeos/pygeos/issues/147</span>
<span class="w"> </span>        non_empty = geometry.copy()
<span class="w"> </span>        non_empty[shapely.is_empty(non_empty)] = None
<span class="gi">+        # set empty geometries to None to maintain indexing</span>
<span class="w"> </span>        self._tree = shapely.STRtree(non_empty)
<span class="gi">+        # store geometries, including empty geometries for user access</span>
<span class="w"> </span>        self.geometries = geometry.copy()

<span class="w"> </span>    @property
<span class="gu">@@ -38,12 +48,14 @@ class SpatialIndex:</span>
<span class="w"> </span>        &gt;&gt;&gt; from shapely.geometry import Point
<span class="w"> </span>        &gt;&gt;&gt; s = geopandas.GeoSeries([Point(0, 0), Point(1, 1)])
<span class="w"> </span>        &gt;&gt;&gt; s.sindex.valid_query_predicates  # doctest: +SKIP
<span class="gd">-        {None, &quot;contains&quot;, &quot;contains_properly&quot;, &quot;covered_by&quot;, &quot;covers&quot;, &quot;crosses&quot;, &quot;dwithin&quot;, &quot;intersects&quot;, &quot;overlaps&quot;, &quot;touches&quot;, &quot;within&quot;}</span>
<span class="gi">+        {None, &quot;contains&quot;, &quot;contains_properly&quot;, &quot;covered_by&quot;, &quot;covers&quot;, \</span>
<span class="gi">+&quot;crosses&quot;, &quot;dwithin&quot;, &quot;intersects&quot;, &quot;overlaps&quot;, &quot;touches&quot;, &quot;within&quot;}</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return PREDICATES</span>

<span class="gd">-    def query(self, geometry, predicate=None, sort=False, distance=None,</span>
<span class="gd">-        output_format=&#39;tuple&#39;):</span>
<span class="gi">+    def query(</span>
<span class="gi">+        self, geometry, predicate=None, sort=False, distance=None, output_format=&quot;tuple&quot;</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Return the integer indices of all combinations of each input geometry
<span class="w"> </span>        and tree geometries where the bounding box of each input geometry
<span class="gu">@@ -73,12 +85,14 @@ class SpatialIndex:</span>

<span class="w"> </span>        Parameters
<span class="w"> </span>        ----------
<span class="gd">-        geometry : shapely.Geometry or array-like of geometries (numpy.ndarray, GeoSeries, GeometryArray)</span>
<span class="gi">+        geometry : shapely.Geometry or array-like of geometries \</span>
<span class="gi">+(numpy.ndarray, GeoSeries, GeometryArray)</span>
<span class="w"> </span>            A single shapely geometry or array of geometries to query against
<span class="w"> </span>            the spatial index. For array-like, accepts both GeoPandas geometry
<span class="w"> </span>            iterables (GeoSeries, GeometryArray) or a numpy array of Shapely
<span class="w"> </span>            geometries.
<span class="gd">-        predicate : {None, &quot;contains&quot;, &quot;contains_properly&quot;, &quot;covered_by&quot;, &quot;covers&quot;, &quot;crosses&quot;, &quot;intersects&quot;, &quot;overlaps&quot;, &quot;touches&quot;, &quot;within&quot;, &quot;dwithin&quot;}, optional</span>
<span class="gi">+        predicate : {None, &quot;contains&quot;, &quot;contains_properly&quot;, &quot;covered_by&quot;, &quot;covers&quot;, \</span>
<span class="gi">+&quot;crosses&quot;, &quot;intersects&quot;, &quot;overlaps&quot;, &quot;touches&quot;, &quot;within&quot;, &quot;dwithin&quot;}, optional</span>
<span class="w"> </span>            If predicate is provided, the input geometries are tested
<span class="w"> </span>            using the predicate function against each item in the tree
<span class="w"> </span>            whose extent intersects the envelope of the input geometry:
<span class="gu">@@ -165,7 +179,68 @@ class SpatialIndex:</span>
<span class="w"> </span>        geometries that can be joined based on overlapping bounding boxes or
<span class="w"> </span>        optional predicate are returned.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        if predicate not in self.valid_query_predicates:</span>
<span class="gi">+            if predicate == &quot;dwithin&quot;:</span>
<span class="gi">+                raise ValueError(&quot;predicate = &#39;dwithin&#39; requires GEOS &gt;= 3.10.0&quot;)</span>
<span class="gi">+</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;Got predicate=&#39;{}&#39;; &quot;.format(predicate)</span>
<span class="gi">+                + &quot;`predicate` must be one of {}&quot;.format(self.valid_query_predicates)</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        # distance argument requirement of predicate `dwithin`</span>
<span class="gi">+        # and only valid for predicate `dwithin`</span>
<span class="gi">+        kwargs = {}</span>
<span class="gi">+        if predicate == &quot;dwithin&quot;:</span>
<span class="gi">+            if distance is None:</span>
<span class="gi">+                # the distance parameter is needed</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    &quot;&#39;distance&#39; parameter is required for &#39;dwithin&#39; predicate&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+            # add distance to kwargs</span>
<span class="gi">+            kwargs[&quot;distance&quot;] = distance</span>
<span class="gi">+</span>
<span class="gi">+        elif distance is not None:</span>
<span class="gi">+            # distance parameter is invalid</span>
<span class="gi">+            raise ValueError(</span>
<span class="gi">+                &quot;&#39;distance&#39; parameter is only supported in combination with &quot;</span>
<span class="gi">+                &quot;&#39;dwithin&#39; predicate&quot;</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        geometry = self._as_geometry_array(geometry)</span>
<span class="gi">+</span>
<span class="gi">+        indices = self._tree.query(geometry, predicate=predicate, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+        if output_format != &quot;tuple&quot;:</span>
<span class="gi">+            sort = True</span>
<span class="gi">+</span>
<span class="gi">+        if sort:</span>
<span class="gi">+            if indices.ndim == 1:</span>
<span class="gi">+                indices = np.sort(indices)</span>
<span class="gi">+            else:</span>
<span class="gi">+                # sort by first array (geometry) and then second (tree)</span>
<span class="gi">+                geo_idx, tree_idx = indices</span>
<span class="gi">+                sort_indexer = np.lexsort((tree_idx, geo_idx))</span>
<span class="gi">+                indices = np.vstack((geo_idx[sort_indexer], tree_idx[sort_indexer]))</span>
<span class="gi">+</span>
<span class="gi">+        if output_format == &quot;sparse&quot;:</span>
<span class="gi">+            from scipy.sparse import coo_array</span>
<span class="gi">+</span>
<span class="gi">+            return coo_array(</span>
<span class="gi">+                (np.ones(len(indices[0]), dtype=np.bool_), indices),</span>
<span class="gi">+                shape=(len(self.geometries), len(geometry)),</span>
<span class="gi">+                dtype=np.bool_,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        if output_format == &quot;dense&quot;:</span>
<span class="gi">+            dense = np.zeros((len(self.geometries), len(geometry)), dtype=bool)</span>
<span class="gi">+            dense[indices] = True</span>
<span class="gi">+            return dense</span>
<span class="gi">+</span>
<span class="gi">+        if output_format == &quot;tuple&quot;:</span>
<span class="gi">+            return indices</span>
<span class="gi">+</span>
<span class="gi">+        raise ValueError(&quot;Invalid output_format: {}&quot;.format(output_format))</span>

<span class="w"> </span>    @staticmethod
<span class="w"> </span>    def _as_geometry_array(geometry):
<span class="gu">@@ -182,10 +257,27 @@ class SpatialIndex:</span>
<span class="w"> </span>        np.ndarray
<span class="w"> </span>            A numpy array of Shapely geometries.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gd">-</span>
<span class="gd">-    def nearest(self, geometry, return_all=True, max_distance=None,</span>
<span class="gd">-        return_distance=False, exclusive=False):</span>
<span class="gi">+        if isinstance(geometry, np.ndarray):</span>
<span class="gi">+            return array.from_shapely(geometry)._data</span>
<span class="gi">+        elif isinstance(geometry, geoseries.GeoSeries):</span>
<span class="gi">+            return geometry.values._data</span>
<span class="gi">+        elif isinstance(geometry, array.GeometryArray):</span>
<span class="gi">+            return geometry._data</span>
<span class="gi">+        elif isinstance(geometry, BaseGeometry):</span>
<span class="gi">+            return geometry</span>
<span class="gi">+        elif geometry is None:</span>
<span class="gi">+            return None</span>
<span class="gi">+        else:</span>
<span class="gi">+            return np.asarray(geometry)</span>
<span class="gi">+</span>
<span class="gi">+    def nearest(</span>
<span class="gi">+        self,</span>
<span class="gi">+        geometry,</span>
<span class="gi">+        return_all=True,</span>
<span class="gi">+        max_distance=None,</span>
<span class="gi">+        return_distance=False,</span>
<span class="gi">+        exclusive=False,</span>
<span class="gi">+    ):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        Return the nearest geometry in the tree for each input geometry in
<span class="w"> </span>        ``geometry``.
<span class="gu">@@ -209,7 +301,8 @@ class SpatialIndex:</span>

<span class="w"> </span>        Parameters
<span class="w"> </span>        ----------
<span class="gd">-        geometry : {shapely.geometry, GeoSeries, GeometryArray, numpy.array of Shapely geometries}</span>
<span class="gi">+        geometry : {shapely.geometry, GeoSeries, GeometryArray, numpy.array of Shapely \</span>
<span class="gi">+geometries}</span>
<span class="w"> </span>            A single shapely geometry, one of the GeoPandas geometry iterables
<span class="w"> </span>            (GeoSeries, GeometryArray), or a numpy array of Shapely geometries to query
<span class="w"> </span>            against the spatial index.
<span class="gu">@@ -264,7 +357,26 @@ class SpatialIndex:</span>
<span class="w"> </span>        array([[0, 1],
<span class="w"> </span>               [8, 9]])
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        geometry = self._as_geometry_array(geometry)</span>
<span class="gi">+        if isinstance(geometry, BaseGeometry) or geometry is None:</span>
<span class="gi">+            geometry = [geometry]</span>
<span class="gi">+</span>
<span class="gi">+        result = self._tree.query_nearest(</span>
<span class="gi">+            geometry,</span>
<span class="gi">+            max_distance=max_distance,</span>
<span class="gi">+            return_distance=return_distance,</span>
<span class="gi">+            all_matches=return_all,</span>
<span class="gi">+            exclusive=exclusive,</span>
<span class="gi">+        )</span>
<span class="gi">+        if return_distance:</span>
<span class="gi">+            indices, distances = result</span>
<span class="gi">+        else:</span>
<span class="gi">+            indices = result</span>
<span class="gi">+</span>
<span class="gi">+        if return_distance:</span>
<span class="gi">+            return indices, distances</span>
<span class="gi">+        else:</span>
<span class="gi">+            return indices</span>

<span class="w"> </span>    def intersection(self, coordinates):
<span class="w"> </span>        &quot;&quot;&quot;Compatibility wrapper for rtree.index.Index.intersection,
<span class="gu">@@ -302,7 +414,34 @@ class SpatialIndex:</span>
<span class="w"> </span>        array([1, 2, 3])

<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        # TODO: we should deprecate this</span>
<span class="gi">+        # convert bounds to geometry</span>
<span class="gi">+        # the old API uses tuples of bound, but Shapely uses geometries</span>
<span class="gi">+        try:</span>
<span class="gi">+            iter(coordinates)</span>
<span class="gi">+        except TypeError:</span>
<span class="gi">+            # likely not an iterable</span>
<span class="gi">+            # this is a check that rtree does, we mimic it</span>
<span class="gi">+            # to ensure a useful failure message</span>
<span class="gi">+            raise TypeError(</span>
<span class="gi">+                &quot;Invalid coordinates, must be iterable in format &quot;</span>
<span class="gi">+                &quot;(minx, miny, maxx, maxy) (for bounds) or (x, y) (for points). &quot;</span>
<span class="gi">+                &quot;Got `coordinates` = {}.&quot;.format(coordinates)</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        # need to convert tuple of bounds to a geometry object</span>
<span class="gi">+        if len(coordinates) == 4:</span>
<span class="gi">+            indexes = self._tree.query(shapely.box(*coordinates))</span>
<span class="gi">+        elif len(coordinates) == 2:</span>
<span class="gi">+            indexes = self._tree.query(shapely.points(*coordinates))</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise TypeError(</span>
<span class="gi">+                &quot;Invalid coordinates, must be iterable in format &quot;</span>
<span class="gi">+                &quot;(minx, miny, maxx, maxy) (for bounds) or (x, y) (for points). &quot;</span>
<span class="gi">+                &quot;Got `coordinates` = {}.&quot;.format(coordinates)</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+        return indexes</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def size(self):
<span class="gu">@@ -330,7 +469,7 @@ class SpatialIndex:</span>
<span class="w"> </span>        &gt;&gt;&gt; s.sindex.size
<span class="w"> </span>        10
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return len(self._tree)</span>

<span class="w"> </span>    @property
<span class="w"> </span>    def is_empty(self):
<span class="gu">@@ -360,7 +499,7 @@ class SpatialIndex:</span>
<span class="w"> </span>        &gt;&gt;&gt; s2.sindex.is_empty
<span class="w"> </span>        True
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        return len(self._tree) == 0</span>

<span class="w"> </span>    def __len__(self):
<span class="w"> </span>        return len(self._tree)
<span class="gh">diff --git a/geopandas/testing.py b/geopandas/testing.py</span>
<span class="gh">index 582d8a23..62328e45 100644</span>
<span class="gd">--- a/geopandas/testing.py</span>
<span class="gi">+++ b/geopandas/testing.py</span>
<span class="gu">@@ -1,15 +1,31 @@</span>
<span class="w"> </span>&quot;&quot;&quot;
<span class="w"> </span>Testing functionality for geopandas objects.
<span class="w"> </span>&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>import warnings
<span class="gi">+</span>
<span class="w"> </span>import pandas as pd
<span class="gi">+</span>
<span class="w"> </span>from geopandas import GeoDataFrame, GeoSeries
<span class="w"> </span>from geopandas.array import GeometryDtype


<span class="w"> </span>def _isna(this):
<span class="w"> </span>    &quot;&quot;&quot;isna version that works for both scalars and (Geo)Series&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    with warnings.catch_warnings():</span>
<span class="gi">+        # GeoSeries.isna will raise a warning about no longer returning True</span>
<span class="gi">+        # for empty geometries. This helper is used below always in combination</span>
<span class="gi">+        # with an is_empty check to preserve behaviour, and thus we ignore the</span>
<span class="gi">+        # warning here to avoid it bubbling up to the user</span>
<span class="gi">+        warnings.filterwarnings(</span>
<span class="gi">+            &quot;ignore&quot;, r&quot;GeoSeries.isna\(\) previously returned&quot;, UserWarning</span>
<span class="gi">+        )</span>
<span class="gi">+        if hasattr(this, &quot;isna&quot;):</span>
<span class="gi">+            return this.isna()</span>
<span class="gi">+        elif hasattr(this, &quot;isnull&quot;):</span>
<span class="gi">+            return this.isnull()</span>
<span class="gi">+        else:</span>
<span class="gi">+            return pd.isnull(this)</span>


<span class="w"> </span>def _geom_equals_mask(this, that):
<span class="gu">@@ -27,7 +43,12 @@ def _geom_equals_mask(this, that):</span>
<span class="w"> </span>    Series
<span class="w"> </span>        boolean Series, True if geometries in left equal geometries in right
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    return (</span>
<span class="gi">+        this.geom_equals(that)</span>
<span class="gi">+        | (this.is_empty &amp; that.is_empty)</span>
<span class="gi">+        | (_isna(this) &amp; _isna(that))</span>
<span class="gi">+    )</span>


<span class="w"> </span>def geom_equals(this, that):
<span class="gu">@@ -45,7 +66,8 @@ def geom_equals(this, that):</span>
<span class="w"> </span>    bool
<span class="w"> </span>        True if all geometries in left equal geometries in right
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    return _geom_equals_mask(this, that).all()</span>


<span class="w"> </span>def _geom_almost_equals_mask(this, that):
<span class="gu">@@ -65,7 +87,12 @@ def _geom_almost_equals_mask(this, that):</span>
<span class="w"> </span>    Series
<span class="w"> </span>        boolean Series, True if geometries in left almost equal geometries in right
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    return (</span>
<span class="gi">+        this.geom_equals_exact(that, tolerance=0.5 * 10 ** (-6))</span>
<span class="gi">+        | (this.is_empty &amp; that.is_empty)</span>
<span class="gi">+        | (_isna(this) &amp; _isna(that))</span>
<span class="gi">+    )</span>


<span class="w"> </span>def geom_almost_equals(this, that):
<span class="gu">@@ -86,12 +113,24 @@ def geom_almost_equals(this, that):</span>
<span class="w"> </span>    bool
<span class="w"> </span>        True if all geometries in left almost equal geometries in right
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(this, GeoDataFrame) and isinstance(that, GeoDataFrame):</span>
<span class="gi">+        this = this.geometry</span>
<span class="gi">+        that = that.geometry</span>
<span class="gi">+</span>
<span class="gi">+    return _geom_almost_equals_mask(this, that).all()</span>


<span class="gd">-def assert_geoseries_equal(left, right, check_dtype=True, check_index_type=</span>
<span class="gd">-    False, check_series_type=True, check_less_precise=False,</span>
<span class="gd">-    check_geom_type=False, check_crs=True, normalize=False):</span>
<span class="gi">+def assert_geoseries_equal(</span>
<span class="gi">+    left,</span>
<span class="gi">+    right,</span>
<span class="gi">+    check_dtype=True,</span>
<span class="gi">+    check_index_type=False,</span>
<span class="gi">+    check_series_type=True,</span>
<span class="gi">+    check_less_precise=False,</span>
<span class="gi">+    check_geom_type=False,</span>
<span class="gi">+    check_crs=True,</span>
<span class="gi">+    normalize=False,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Test util for checking that two GeoSeries are equal.

<span class="gu">@@ -119,18 +158,100 @@ def assert_geoseries_equal(left, right, check_dtype=True, check_index_type=</span>
<span class="w"> </span>        Typically useful with ``check_less_precise=True``, which uses
<span class="w"> </span>        ``geom_equals_exact`` and requires exact coordinate order.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    assert len(left) == len(right), &quot;%d != %d&quot; % (len(left), len(right))</span>
<span class="gi">+</span>
<span class="gi">+    if check_dtype:</span>
<span class="gi">+        msg = &quot;dtype should be a GeometryDtype, got {0}&quot;</span>
<span class="gi">+        assert isinstance(left.dtype, GeometryDtype), msg.format(left.dtype)</span>
<span class="gi">+        assert isinstance(right.dtype, GeometryDtype), msg.format(left.dtype)</span>
<span class="gi">+</span>
<span class="gi">+    if check_index_type:</span>
<span class="gi">+        assert isinstance(left.index, type(right.index))</span>
<span class="gi">+</span>
<span class="gi">+    if check_series_type:</span>
<span class="gi">+        assert isinstance(left, GeoSeries)</span>
<span class="gi">+        assert isinstance(left, type(right))</span>
<span class="gi">+</span>
<span class="gi">+        if check_crs:</span>
<span class="gi">+            assert left.crs == right.crs</span>
<span class="gi">+    else:</span>
<span class="gi">+        if not isinstance(left, GeoSeries):</span>
<span class="gi">+            left = GeoSeries(left)</span>
<span class="gi">+        if not isinstance(right, GeoSeries):</span>
<span class="gi">+            right = GeoSeries(right, index=left.index)</span>
<span class="gi">+</span>
<span class="gi">+    assert left.index.equals(right.index), &quot;index: %s != %s&quot; % (left.index, right.index)</span>
<span class="gi">+</span>
<span class="gi">+    if check_geom_type:</span>
<span class="gi">+        assert (left.geom_type == right.geom_type).all(), &quot;type: %s != %s&quot; % (</span>
<span class="gi">+            left.geom_type,</span>
<span class="gi">+            right.geom_type,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    if normalize:</span>
<span class="gi">+        left = GeoSeries(left.array.normalize())</span>
<span class="gi">+        right = GeoSeries(right.array.normalize())</span>
<span class="gi">+</span>
<span class="gi">+    if not check_crs:</span>
<span class="gi">+        with warnings.catch_warnings():</span>
<span class="gi">+            warnings.filterwarnings(&quot;ignore&quot;, &quot;CRS mismatch&quot;, UserWarning)</span>
<span class="gi">+            _check_equality(left, right, check_less_precise)</span>
<span class="gi">+    else:</span>
<span class="gi">+        _check_equality(left, right, check_less_precise)</span>


<span class="w"> </span>def _truncated_string(geom):
<span class="w"> </span>    &quot;&quot;&quot;Truncated WKT repr of geom&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    s = str(geom)</span>
<span class="gi">+    if len(s) &gt; 100:</span>
<span class="gi">+        return s[:100] + &quot;...&quot;</span>
<span class="gi">+    else:</span>
<span class="gi">+        return s</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _check_equality(left, right, check_less_precise):</span>
<span class="gi">+    assert_error_message = (</span>
<span class="gi">+        &quot;{0} out of {1} geometries are not {3}equal.\n&quot;</span>
<span class="gi">+        &quot;Indices where geometries are not {3}equal: {2} \n&quot;</span>
<span class="gi">+        &quot;The first not {3}equal geometry:\n&quot;</span>
<span class="gi">+        &quot;Left: {4}\n&quot;</span>
<span class="gi">+        &quot;Right: {5}\n&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    if check_less_precise:</span>
<span class="gi">+        precise = &quot;almost &quot;</span>
<span class="gi">+        equal = _geom_almost_equals_mask(left, right)</span>
<span class="gi">+    else:</span>
<span class="gi">+        precise = &quot;&quot;</span>
<span class="gi">+        equal = _geom_equals_mask(left, right)</span>

<span class="gi">+    if not equal.all():</span>
<span class="gi">+        unequal_left_geoms = left[~equal]</span>
<span class="gi">+        unequal_right_geoms = right[~equal]</span>
<span class="gi">+        raise AssertionError(</span>
<span class="gi">+            assert_error_message.format(</span>
<span class="gi">+                len(unequal_left_geoms),</span>
<span class="gi">+                len(left),</span>
<span class="gi">+                unequal_left_geoms.index.to_list(),</span>
<span class="gi">+                precise,</span>
<span class="gi">+                _truncated_string(unequal_left_geoms.iloc[0]),</span>
<span class="gi">+                _truncated_string(unequal_right_geoms.iloc[0]),</span>
<span class="gi">+            )</span>
<span class="gi">+        )</span>

<span class="gd">-def assert_geodataframe_equal(left, right, check_dtype=True,</span>
<span class="gd">-    check_index_type=&#39;equiv&#39;, check_column_type=&#39;equiv&#39;, check_frame_type=</span>
<span class="gd">-    True, check_like=False, check_less_precise=False, check_geom_type=False,</span>
<span class="gd">-    check_crs=True, normalize=False):</span>
<span class="gi">+</span>
<span class="gi">+def assert_geodataframe_equal(</span>
<span class="gi">+    left,</span>
<span class="gi">+    right,</span>
<span class="gi">+    check_dtype=True,</span>
<span class="gi">+    check_index_type=&quot;equiv&quot;,</span>
<span class="gi">+    check_column_type=&quot;equiv&quot;,</span>
<span class="gi">+    check_frame_type=True,</span>
<span class="gi">+    check_like=False,</span>
<span class="gi">+    check_less_precise=False,</span>
<span class="gi">+    check_geom_type=False,</span>
<span class="gi">+    check_crs=True,</span>
<span class="gi">+    normalize=False,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Check that two GeoDataFrames are equal/

<span class="gu">@@ -158,4 +279,80 @@ def assert_geodataframe_equal(left, right, check_dtype=True,</span>
<span class="w"> </span>        Typically useful with ``check_less_precise=True``, which uses
<span class="w"> </span>        ``geom_equals_exact`` and requires exact coordinate order.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        # added from pandas 0.20</span>
<span class="gi">+        from pandas.testing import assert_frame_equal, assert_index_equal</span>
<span class="gi">+    except ImportError:</span>
<span class="gi">+        from pandas.util.testing import assert_frame_equal, assert_index_equal</span>
<span class="gi">+</span>
<span class="gi">+    # instance validation</span>
<span class="gi">+    if check_frame_type:</span>
<span class="gi">+        assert isinstance(left, GeoDataFrame)</span>
<span class="gi">+        assert isinstance(left, type(right))</span>
<span class="gi">+</span>
<span class="gi">+        if check_crs:</span>
<span class="gi">+            # allow if neither left and right has an active geometry column</span>
<span class="gi">+            if (</span>
<span class="gi">+                left._geometry_column_name is None</span>
<span class="gi">+                and right._geometry_column_name is None</span>
<span class="gi">+            ):</span>
<span class="gi">+                pass</span>
<span class="gi">+            elif (</span>
<span class="gi">+                left._geometry_column_name not in left.columns</span>
<span class="gi">+                and right._geometry_column_name not in right.columns</span>
<span class="gi">+            ):</span>
<span class="gi">+                pass</span>
<span class="gi">+            # no crs can be either None or {}</span>
<span class="gi">+            elif not left.crs and not right.crs:</span>
<span class="gi">+                pass</span>
<span class="gi">+            else:</span>
<span class="gi">+                assert left.crs == right.crs</span>
<span class="gi">+    else:</span>
<span class="gi">+        if not isinstance(left, GeoDataFrame):</span>
<span class="gi">+            left = GeoDataFrame(left)</span>
<span class="gi">+        if not isinstance(right, GeoDataFrame):</span>
<span class="gi">+            right = GeoDataFrame(right)</span>
<span class="gi">+</span>
<span class="gi">+    # shape comparison</span>
<span class="gi">+    assert left.shape == right.shape, (</span>
<span class="gi">+        &quot;GeoDataFrame shape mismatch, left: {lshape!r}, right: {rshape!r}.\n&quot;</span>
<span class="gi">+        &quot;Left columns: {lcols!r}, right columns: {rcols!r}&quot;</span>
<span class="gi">+    ).format(</span>
<span class="gi">+        lshape=left.shape, rshape=right.shape, lcols=left.columns, rcols=right.columns</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    if check_like:</span>
<span class="gi">+        left = left.reindex_like(right)</span>
<span class="gi">+</span>
<span class="gi">+    # column comparison</span>
<span class="gi">+    assert_index_equal(</span>
<span class="gi">+        left.columns, right.columns, exact=check_column_type, obj=&quot;GeoDataFrame.columns&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    # geometry comparison</span>
<span class="gi">+    for col, dtype in left.dtypes.items():</span>
<span class="gi">+        if isinstance(dtype, GeometryDtype):</span>
<span class="gi">+            assert_geoseries_equal(</span>
<span class="gi">+                left[col],</span>
<span class="gi">+                right[col],</span>
<span class="gi">+                normalize=normalize,</span>
<span class="gi">+                check_dtype=check_dtype,</span>
<span class="gi">+                check_less_precise=check_less_precise,</span>
<span class="gi">+                check_geom_type=check_geom_type,</span>
<span class="gi">+                check_crs=check_crs,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    # ensure the active geometry column is the same</span>
<span class="gi">+    assert left._geometry_column_name == right._geometry_column_name</span>
<span class="gi">+</span>
<span class="gi">+    # drop geometries and check remaining columns</span>
<span class="gi">+    left2 = left.select_dtypes(exclude=&quot;geometry&quot;)</span>
<span class="gi">+    right2 = right.select_dtypes(exclude=&quot;geometry&quot;)</span>
<span class="gi">+    assert_frame_equal(</span>
<span class="gi">+        left2,</span>
<span class="gi">+        right2,</span>
<span class="gi">+        check_dtype=check_dtype,</span>
<span class="gi">+        check_index_type=check_index_type,</span>
<span class="gi">+        check_column_type=check_column_type,</span>
<span class="gi">+        obj=&quot;GeoDataFrame&quot;,</span>
<span class="gi">+    )</span>
<span class="gh">diff --git a/geopandas/tools/_random.py b/geopandas/tools/_random.py</span>
<span class="gh">index b79a37a9..007d02fa 100644</span>
<span class="gd">--- a/geopandas/tools/_random.py</span>
<span class="gi">+++ b/geopandas/tools/_random.py</span>
<span class="gu">@@ -1,6 +1,9 @@</span>
<span class="w"> </span>from warnings import warn
<span class="gi">+</span>
<span class="w"> </span>import numpy
<span class="gi">+</span>
<span class="w"> </span>from shapely.geometry import MultiPoint
<span class="gi">+</span>
<span class="w"> </span>from geopandas.array import from_shapely, points_from_xy
<span class="w"> </span>from geopandas.geoseries import GeoSeries

<span class="gu">@@ -37,18 +40,45 @@ def uniform(geom, size, rng=None):</span>
<span class="w"> </span>    &gt;&gt;&gt; square = box(0,0,1,1)
<span class="w"> </span>    &gt;&gt;&gt; uniform(square, size=102) # doctest: +SKIP
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    generator = numpy.random.default_rng(seed=rng)</span>
<span class="gi">+</span>
<span class="gi">+    if geom is None or geom.is_empty:</span>
<span class="gi">+        return MultiPoint()</span>
<span class="gi">+</span>
<span class="gi">+    if geom.geom_type in (&quot;Polygon&quot;, &quot;MultiPolygon&quot;):</span>
<span class="gi">+        return _uniform_polygon(geom, size=size, generator=generator)</span>
<span class="gi">+</span>
<span class="gi">+    if geom.geom_type in (&quot;LineString&quot;, &quot;MultiLineString&quot;):</span>
<span class="gi">+        return _uniform_line(geom, size=size, generator=generator)</span>
<span class="gi">+</span>
<span class="gi">+    warn(</span>
<span class="gi">+        f&quot;Sampling is not supported for {geom.geom_type} geometry type.&quot;,</span>
<span class="gi">+        UserWarning,</span>
<span class="gi">+        stacklevel=8,</span>
<span class="gi">+    )</span>
<span class="gi">+    return MultiPoint()</span>


<span class="w"> </span>def _uniform_line(geom, size, generator):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Sample points from an input shapely linestring
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    fracs = generator.uniform(size=size)</span>
<span class="gi">+    return from_shapely(geom.interpolate(fracs, normalized=True)).union_all()</span>


<span class="w"> </span>def _uniform_polygon(geom, size, generator):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Sample uniformly from within a polygon using batched sampling.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    xmin, ymin, xmax, ymax = geom.bounds</span>
<span class="gi">+    candidates = []</span>
<span class="gi">+    while len(candidates) &lt; size:</span>
<span class="gi">+        batch = points_from_xy(</span>
<span class="gi">+            x=generator.uniform(xmin, xmax, size=size),</span>
<span class="gi">+            y=generator.uniform(ymin, ymax, size=size),</span>
<span class="gi">+        )</span>
<span class="gi">+        valid_samples = batch[batch.sindex.query(geom, predicate=&quot;contains&quot;)]</span>
<span class="gi">+        candidates.extend(valid_samples)</span>
<span class="gi">+    return GeoSeries(candidates[:size]).union_all()</span>
<span class="gh">diff --git a/geopandas/tools/_show_versions.py b/geopandas/tools/_show_versions.py</span>
<span class="gh">index 661c2c22..26d02f3a 100644</span>
<span class="gd">--- a/geopandas/tools/_show_versions.py</span>
<span class="gi">+++ b/geopandas/tools/_show_versions.py</span>
<span class="gu">@@ -11,7 +11,15 @@ def _get_sys_info():</span>
<span class="w"> </span>    sys_info : dict
<span class="w"> </span>        system and Python version information
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    python = sys.version.replace(&quot;\n&quot;, &quot; &quot;)</span>
<span class="gi">+</span>
<span class="gi">+    blob = [</span>
<span class="gi">+        (&quot;python&quot;, python),</span>
<span class="gi">+        (&quot;executable&quot;, sys.executable),</span>
<span class="gi">+        (&quot;machine&quot;, platform.platform()),</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+    return dict(blob)</span>


<span class="w"> </span>def _get_C_info():
<span class="gu">@@ -21,7 +29,67 @@ def _get_C_info():</span>
<span class="w"> </span>    c_info: dict
<span class="w"> </span>        system PROJ information
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    try:</span>
<span class="gi">+        import pyproj</span>
<span class="gi">+</span>
<span class="gi">+        proj_version = pyproj.proj_version_str</span>
<span class="gi">+    except Exception:</span>
<span class="gi">+        proj_version = None</span>
<span class="gi">+    try:</span>
<span class="gi">+        import pyproj</span>
<span class="gi">+</span>
<span class="gi">+        proj_dir = pyproj.datadir.get_data_dir()</span>
<span class="gi">+    except Exception:</span>
<span class="gi">+        proj_dir = None</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        import shapely._buildcfg</span>
<span class="gi">+</span>
<span class="gi">+        geos_version = &quot;{}.{}.{}&quot;.format(*shapely._buildcfg.geos_version)</span>
<span class="gi">+        geos_dir = shapely._buildcfg.geos_library_path</span>
<span class="gi">+    except Exception:</span>
<span class="gi">+        try:</span>
<span class="gi">+            from shapely import geos_version_string</span>
<span class="gi">+</span>
<span class="gi">+            geos_version = geos_version_string</span>
<span class="gi">+            geos_dir = None</span>
<span class="gi">+        except Exception:</span>
<span class="gi">+            geos_version = None</span>
<span class="gi">+            geos_dir = None</span>
<span class="gi">+</span>
<span class="gi">+    try:</span>
<span class="gi">+        import pyogrio</span>
<span class="gi">+</span>
<span class="gi">+        gdal_version = pyogrio.__gdal_version_string__</span>
<span class="gi">+        gdal_dir = pyogrio.get_gdal_data_path()</span>
<span class="gi">+    except Exception:</span>
<span class="gi">+        gdal_version = None</span>
<span class="gi">+        gdal_dir = None</span>
<span class="gi">+</span>
<span class="gi">+    if gdal_version is None:</span>
<span class="gi">+        try:</span>
<span class="gi">+            import fiona</span>
<span class="gi">+</span>
<span class="gi">+            gdal_version = fiona.env.get_gdal_release_name()</span>
<span class="gi">+        except Exception:</span>
<span class="gi">+            gdal_version = None</span>
<span class="gi">+        try:</span>
<span class="gi">+            import fiona</span>
<span class="gi">+</span>
<span class="gi">+            gdal_dir = fiona.env.GDALDataFinder().search()</span>
<span class="gi">+        except Exception:</span>
<span class="gi">+            gdal_dir = None</span>
<span class="gi">+</span>
<span class="gi">+    blob = [</span>
<span class="gi">+        (&quot;GEOS&quot;, geos_version),</span>
<span class="gi">+        (&quot;GEOS lib&quot;, geos_dir),</span>
<span class="gi">+        (&quot;GDAL&quot;, gdal_version),</span>
<span class="gi">+        (&quot;GDAL data dir&quot;, gdal_dir),</span>
<span class="gi">+        (&quot;PROJ&quot;, proj_version),</span>
<span class="gi">+        (&quot;PROJ data dir&quot;, proj_dir),</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+    return dict(blob)</span>


<span class="w"> </span>def _get_deps_info():
<span class="gu">@@ -32,7 +100,42 @@ def _get_deps_info():</span>
<span class="w"> </span>    deps_info: dict
<span class="w"> </span>        version information on relevant Python libraries
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    deps = [</span>
<span class="gi">+        &quot;geopandas&quot;,</span>
<span class="gi">+        # required deps</span>
<span class="gi">+        &quot;numpy&quot;,</span>
<span class="gi">+        &quot;pandas&quot;,</span>
<span class="gi">+        &quot;pyproj&quot;,</span>
<span class="gi">+        &quot;shapely&quot;,</span>
<span class="gi">+        # optional deps</span>
<span class="gi">+        &quot;pyogrio&quot;,</span>
<span class="gi">+        &quot;geoalchemy2&quot;,</span>
<span class="gi">+        &quot;geopy&quot;,</span>
<span class="gi">+        &quot;matplotlib&quot;,</span>
<span class="gi">+        &quot;mapclassify&quot;,</span>
<span class="gi">+        &quot;fiona&quot;,</span>
<span class="gi">+        &quot;psycopg&quot;,</span>
<span class="gi">+        &quot;psycopg2&quot;,</span>
<span class="gi">+        &quot;pyarrow&quot;,</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+    def get_version(module):</span>
<span class="gi">+        return module.__version__</span>
<span class="gi">+</span>
<span class="gi">+    deps_info = {}</span>
<span class="gi">+</span>
<span class="gi">+    for modname in deps:</span>
<span class="gi">+        try:</span>
<span class="gi">+            if modname in sys.modules:</span>
<span class="gi">+                mod = sys.modules[modname]</span>
<span class="gi">+            else:</span>
<span class="gi">+                mod = importlib.import_module(modname)</span>
<span class="gi">+            ver = get_version(mod)</span>
<span class="gi">+            deps_info[modname] = ver</span>
<span class="gi">+        except Exception:</span>
<span class="gi">+            deps_info[modname] = None</span>
<span class="gi">+</span>
<span class="gi">+    return deps_info</span>


<span class="w"> </span>def show_versions():
<span class="gu">@@ -46,4 +149,21 @@ def show_versions():</span>

<span class="w"> </span>        $ python -c &quot;import geopandas; geopandas.show_versions()&quot;
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    sys_info = _get_sys_info()</span>
<span class="gi">+    deps_info = _get_deps_info()</span>
<span class="gi">+    proj_info = _get_C_info()</span>
<span class="gi">+</span>
<span class="gi">+    maxlen = max(len(x) for x in deps_info)</span>
<span class="gi">+    tpl = &quot;{{k:&lt;{maxlen}}}: {{stat}}&quot;.format(maxlen=maxlen)</span>
<span class="gi">+    print(&quot;\nSYSTEM INFO&quot;)</span>
<span class="gi">+    print(&quot;-----------&quot;)</span>
<span class="gi">+    for k, stat in sys_info.items():</span>
<span class="gi">+        print(tpl.format(k=k, stat=stat))</span>
<span class="gi">+    print(&quot;\nGEOS, GDAL, PROJ INFO&quot;)</span>
<span class="gi">+    print(&quot;---------------------&quot;)</span>
<span class="gi">+    for k, stat in proj_info.items():</span>
<span class="gi">+        print(tpl.format(k=k, stat=stat))</span>
<span class="gi">+    print(&quot;\nPYTHON DEPENDENCIES&quot;)</span>
<span class="gi">+    print(&quot;-------------------&quot;)</span>
<span class="gi">+    for k, stat in deps_info.items():</span>
<span class="gi">+        print(tpl.format(k=k, stat=stat))</span>
<span class="gh">diff --git a/geopandas/tools/clip.py b/geopandas/tools/clip.py</span>
<span class="gh">index 2ec2edaf..0382ff2d 100644</span>
<span class="gd">--- a/geopandas/tools/clip.py</span>
<span class="gi">+++ b/geopandas/tools/clip.py</span>
<span class="gu">@@ -5,14 +5,24 @@ geopandas.clip</span>
<span class="w"> </span>A module to clip vector data using GeoPandas.

<span class="w"> </span>&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>import warnings
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>import pandas.api.types
<span class="gi">+</span>
<span class="w"> </span>from shapely.geometry import MultiPolygon, Polygon, box
<span class="gi">+</span>
<span class="w"> </span>from geopandas import GeoDataFrame, GeoSeries
<span class="w"> </span>from geopandas.array import _check_crs, _crs_mismatch_warn


<span class="gi">+def _mask_is_list_like_rectangle(mask):</span>
<span class="gi">+    return pandas.api.types.is_list_like(mask) and not isinstance(</span>
<span class="gi">+        mask, (GeoDataFrame, GeoSeries, Polygon, MultiPolygon)</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>def _clip_gdf_with_mask(gdf, mask, sort=False):
<span class="w"> </span>    &quot;&quot;&quot;Clip geometry to the polygon/rectangle extent.

<span class="gu">@@ -37,7 +47,46 @@ def _clip_gdf_with_mask(gdf, mask, sort=False):</span>
<span class="w"> </span>        The returned GeoDataFrame is a clipped subset of gdf
<span class="w"> </span>        that intersects with polygon/rectangle.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    clipping_by_rectangle = _mask_is_list_like_rectangle(mask)</span>
<span class="gi">+    if clipping_by_rectangle:</span>
<span class="gi">+        intersection_polygon = box(*mask)</span>
<span class="gi">+    else:</span>
<span class="gi">+        intersection_polygon = mask</span>
<span class="gi">+</span>
<span class="gi">+    gdf_sub = gdf.iloc[</span>
<span class="gi">+        gdf.sindex.query(intersection_polygon, predicate=&quot;intersects&quot;, sort=sort)</span>
<span class="gi">+    ]</span>
<span class="gi">+</span>
<span class="gi">+    # For performance reasons points don&#39;t need to be intersected with poly</span>
<span class="gi">+    non_point_mask = gdf_sub.geom_type != &quot;Point&quot;</span>
<span class="gi">+</span>
<span class="gi">+    if not non_point_mask.any():</span>
<span class="gi">+        # only points, directly return</span>
<span class="gi">+        return gdf_sub</span>
<span class="gi">+</span>
<span class="gi">+    # Clip the data with the polygon</span>
<span class="gi">+    if isinstance(gdf_sub, GeoDataFrame):</span>
<span class="gi">+        clipped = gdf_sub.copy()</span>
<span class="gi">+        if clipping_by_rectangle:</span>
<span class="gi">+            clipped.loc[non_point_mask, clipped._geometry_column_name] = (</span>
<span class="gi">+                gdf_sub.geometry.values[non_point_mask].clip_by_rect(*mask)</span>
<span class="gi">+            )</span>
<span class="gi">+        else:</span>
<span class="gi">+            clipped.loc[non_point_mask, clipped._geometry_column_name] = (</span>
<span class="gi">+                gdf_sub.geometry.values[non_point_mask].intersection(mask)</span>
<span class="gi">+            )</span>
<span class="gi">+    else:</span>
<span class="gi">+        # GeoSeries</span>
<span class="gi">+        clipped = gdf_sub.copy()</span>
<span class="gi">+        if clipping_by_rectangle:</span>
<span class="gi">+            clipped[non_point_mask] = gdf_sub.values[non_point_mask].clip_by_rect(*mask)</span>
<span class="gi">+        else:</span>
<span class="gi">+            clipped[non_point_mask] = gdf_sub.values[non_point_mask].intersection(mask)</span>
<span class="gi">+</span>
<span class="gi">+    if clipping_by_rectangle:</span>
<span class="gi">+        # clip_by_rect might return empty geometry collections in edge cases</span>
<span class="gi">+        clipped = clipped[~clipped.is_empty]</span>
<span class="gi">+    return clipped</span>


<span class="w"> </span>def clip(gdf, mask, keep_geom_type=False, sort=False):
<span class="gu">@@ -105,4 +154,104 @@ def clip(gdf, mask, keep_geom_type=False, sort=False):</span>
<span class="w"> </span>    &gt;&gt;&gt; nws_groceries.shape
<span class="w"> </span>    (7, 8)
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not isinstance(gdf, (GeoDataFrame, GeoSeries)):</span>
<span class="gi">+        raise TypeError(</span>
<span class="gi">+            &quot;&#39;gdf&#39; should be GeoDataFrame or GeoSeries, got {}&quot;.format(type(gdf))</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    mask_is_list_like = _mask_is_list_like_rectangle(mask)</span>
<span class="gi">+    if (</span>
<span class="gi">+        not isinstance(mask, (GeoDataFrame, GeoSeries, Polygon, MultiPolygon))</span>
<span class="gi">+        and not mask_is_list_like</span>
<span class="gi">+    ):</span>
<span class="gi">+        raise TypeError(</span>
<span class="gi">+            &quot;&#39;mask&#39; should be GeoDataFrame, GeoSeries,&quot;</span>
<span class="gi">+            f&quot;(Multi)Polygon or list-like, got {type(mask)}&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    if mask_is_list_like and len(mask) != 4:</span>
<span class="gi">+        raise TypeError(</span>
<span class="gi">+            &quot;If &#39;mask&#39; is list-like, it must have four values (minx, miny, maxx, maxy)&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(mask, (GeoDataFrame, GeoSeries)):</span>
<span class="gi">+        if not _check_crs(gdf, mask):</span>
<span class="gi">+            _crs_mismatch_warn(gdf, mask, stacklevel=3)</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(mask, (GeoDataFrame, GeoSeries)):</span>
<span class="gi">+        box_mask = mask.total_bounds</span>
<span class="gi">+    elif mask_is_list_like:</span>
<span class="gi">+        box_mask = mask</span>
<span class="gi">+    else:</span>
<span class="gi">+        # Avoid empty tuple returned by .bounds when geometry is empty. A tuple of</span>
<span class="gi">+        # all nan values is consistent with the behavior of</span>
<span class="gi">+        # {GeoSeries, GeoDataFrame}.total_bounds for empty geometries.</span>
<span class="gi">+        # TODO(shapely) can simpely use mask.bounds once relying on Shapely 2.0</span>
<span class="gi">+        box_mask = mask.bounds if not mask.is_empty else (np.nan,) * 4</span>
<span class="gi">+    box_gdf = gdf.total_bounds</span>
<span class="gi">+    if not (</span>
<span class="gi">+        ((box_mask[0] &lt;= box_gdf[2]) and (box_gdf[0] &lt;= box_mask[2]))</span>
<span class="gi">+        and ((box_mask[1] &lt;= box_gdf[3]) and (box_gdf[1] &lt;= box_mask[3]))</span>
<span class="gi">+    ):</span>
<span class="gi">+        return gdf.iloc[:0]</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(mask, (GeoDataFrame, GeoSeries)):</span>
<span class="gi">+        combined_mask = mask.geometry.union_all()</span>
<span class="gi">+    else:</span>
<span class="gi">+        combined_mask = mask</span>
<span class="gi">+</span>
<span class="gi">+    clipped = _clip_gdf_with_mask(gdf, combined_mask, sort=sort)</span>
<span class="gi">+</span>
<span class="gi">+    if keep_geom_type:</span>
<span class="gi">+        geomcoll_concat = (clipped.geom_type == &quot;GeometryCollection&quot;).any()</span>
<span class="gi">+        geomcoll_orig = (gdf.geom_type == &quot;GeometryCollection&quot;).any()</span>
<span class="gi">+</span>
<span class="gi">+        new_collection = geomcoll_concat and not geomcoll_orig</span>
<span class="gi">+</span>
<span class="gi">+        if geomcoll_orig:</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                &quot;keep_geom_type can not be called on a &quot;</span>
<span class="gi">+                &quot;GeoDataFrame with GeometryCollection.&quot;,</span>
<span class="gi">+                stacklevel=2,</span>
<span class="gi">+            )</span>
<span class="gi">+        else:</span>
<span class="gi">+            polys = [&quot;Polygon&quot;, &quot;MultiPolygon&quot;]</span>
<span class="gi">+            lines = [&quot;LineString&quot;, &quot;MultiLineString&quot;, &quot;LinearRing&quot;]</span>
<span class="gi">+            points = [&quot;Point&quot;, &quot;MultiPoint&quot;]</span>
<span class="gi">+</span>
<span class="gi">+            # Check that the gdf for multiple geom types (points, lines and/or polys)</span>
<span class="gi">+            orig_types_total = sum(</span>
<span class="gi">+                [</span>
<span class="gi">+                    gdf.geom_type.isin(polys).any(),</span>
<span class="gi">+                    gdf.geom_type.isin(lines).any(),</span>
<span class="gi">+                    gdf.geom_type.isin(points).any(),</span>
<span class="gi">+                ]</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            # Check how many geometry types are in the clipped GeoDataFrame</span>
<span class="gi">+            clip_types_total = sum(</span>
<span class="gi">+                [</span>
<span class="gi">+                    clipped.geom_type.isin(polys).any(),</span>
<span class="gi">+                    clipped.geom_type.isin(lines).any(),</span>
<span class="gi">+                    clipped.geom_type.isin(points).any(),</span>
<span class="gi">+                ]</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            # Check there aren&#39;t any new geom types in the clipped GeoDataFrame</span>
<span class="gi">+            more_types = orig_types_total &lt; clip_types_total</span>
<span class="gi">+</span>
<span class="gi">+            if orig_types_total &gt; 1:</span>
<span class="gi">+                warnings.warn(</span>
<span class="gi">+                    &quot;keep_geom_type can not be called on a mixed type GeoDataFrame.&quot;,</span>
<span class="gi">+                    stacklevel=2,</span>
<span class="gi">+                )</span>
<span class="gi">+            elif new_collection or more_types:</span>
<span class="gi">+                orig_type = gdf.geom_type.iloc[0]</span>
<span class="gi">+                if new_collection:</span>
<span class="gi">+                    clipped = clipped.explode(index_parts=False)</span>
<span class="gi">+                if orig_type in polys:</span>
<span class="gi">+                    clipped = clipped.loc[clipped.geom_type.isin(polys)]</span>
<span class="gi">+                elif orig_type in lines:</span>
<span class="gi">+                    clipped = clipped.loc[clipped.geom_type.isin(lines)]</span>
<span class="gi">+</span>
<span class="gi">+    return clipped</span>
<span class="gh">diff --git a/geopandas/tools/geocoding.py b/geopandas/tools/geocoding.py</span>
<span class="gh">index 995d1d88..d1b9aaa6 100644</span>
<span class="gd">--- a/geopandas/tools/geocoding.py</span>
<span class="gi">+++ b/geopandas/tools/geocoding.py</span>
<span class="gu">@@ -1,7 +1,10 @@</span>
<span class="w"> </span>import time
<span class="w"> </span>from collections import defaultdict
<span class="gi">+</span>
<span class="w"> </span>import pandas as pd
<span class="gi">+</span>
<span class="w"> </span>from shapely.geometry import Point
<span class="gi">+</span>
<span class="w"> </span>import geopandas


<span class="gu">@@ -10,7 +13,13 @@ def _get_throttle_time(provider):</span>
<span class="w"> </span>    Amount of time to wait between requests to a geocoding API, for providers
<span class="w"> </span>    that specify rate limits in their terms of service.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    import geopy.geocoders</span>
<span class="gi">+</span>
<span class="gi">+    # https://operations.osmfoundation.org/policies/nominatim/</span>
<span class="gi">+    if provider == geopy.geocoders.Nominatim:</span>
<span class="gi">+        return 1</span>
<span class="gi">+    else:</span>
<span class="gi">+        return 0</span>


<span class="w"> </span>def geocode(strings, provider=None, **kwargs):
<span class="gu">@@ -50,7 +59,12 @@ def geocode(strings, provider=None, **kwargs):</span>
<span class="w"> </span>    0  POINT (-71.05863 42.35899)                          Boston, MA, United States
<span class="w"> </span>    1  POINT (-77.03651 38.89766)  1600 Pennsylvania Ave NW, Washington, DC 20006...
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    if provider is None:</span>
<span class="gi">+        provider = &quot;photon&quot;</span>
<span class="gi">+    throttle_time = _get_throttle_time(provider)</span>
<span class="gi">+</span>
<span class="gi">+    return _query(strings, True, provider, throttle_time, **kwargs)</span>


<span class="w"> </span>def reverse_geocode(points, provider=None, **kwargs):
<span class="gu">@@ -96,7 +110,43 @@ def reverse_geocode(points, provider=None, **kwargs):</span>
<span class="w"> </span>    0  POINT (-71.05941 42.35837)       29 Court Sq, Boston, MA 02108, United States
<span class="w"> </span>    1  POINT (-77.03641 38.89766)  1600 Pennsylvania Ave NW, Washington, DC 20006...
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    if provider is None:</span>
<span class="gi">+        provider = &quot;photon&quot;</span>
<span class="gi">+    throttle_time = _get_throttle_time(provider)</span>
<span class="gi">+</span>
<span class="gi">+    return _query(points, False, provider, throttle_time, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _query(data, forward, provider, throttle_time, **kwargs):</span>
<span class="gi">+    # generic wrapper for calls over lists to geopy Geocoders</span>
<span class="gi">+    from geopy.geocoders import get_geocoder_for_service</span>
<span class="gi">+    from geopy.geocoders.base import GeocoderQueryError</span>
<span class="gi">+</span>
<span class="gi">+    if forward:</span>
<span class="gi">+        if not isinstance(data, pd.Series):</span>
<span class="gi">+            data = pd.Series(data)</span>
<span class="gi">+    else:</span>
<span class="gi">+        if not isinstance(data, geopandas.GeoSeries):</span>
<span class="gi">+            data = geopandas.GeoSeries(data)</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(provider, str):</span>
<span class="gi">+        provider = get_geocoder_for_service(provider)</span>
<span class="gi">+</span>
<span class="gi">+    coder = provider(**kwargs)</span>
<span class="gi">+    results = {}</span>
<span class="gi">+    for i, s in data.items():</span>
<span class="gi">+        try:</span>
<span class="gi">+            if forward:</span>
<span class="gi">+                results[i] = coder.geocode(s)</span>
<span class="gi">+            else:</span>
<span class="gi">+                results[i] = coder.reverse((s.y, s.x), exactly_one=True)</span>
<span class="gi">+        except (GeocoderQueryError, ValueError):</span>
<span class="gi">+            results[i] = (None, None)</span>
<span class="gi">+        time.sleep(throttle_time)</span>
<span class="gi">+</span>
<span class="gi">+    df = _prepare_geocode_result(results)</span>
<span class="gi">+    return df</span>


<span class="w"> </span>def _prepare_geocode_result(results):
<span class="gu">@@ -107,4 +157,28 @@ def _prepare_geocode_result(results):</span>
<span class="w"> </span>    (address, (lat, lon))

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # Prepare the data for the DataFrame as a dict of lists</span>
<span class="gi">+    d = defaultdict(list)</span>
<span class="gi">+    index = []</span>
<span class="gi">+</span>
<span class="gi">+    for i, s in results.items():</span>
<span class="gi">+        if s is None:</span>
<span class="gi">+            p = Point()</span>
<span class="gi">+            address = None</span>
<span class="gi">+</span>
<span class="gi">+        else:</span>
<span class="gi">+            address, loc = s</span>
<span class="gi">+</span>
<span class="gi">+            # loc is lat, lon and we want lon, lat</span>
<span class="gi">+            if loc is None:</span>
<span class="gi">+                p = Point()</span>
<span class="gi">+            else:</span>
<span class="gi">+                p = Point(loc[1], loc[0])</span>
<span class="gi">+</span>
<span class="gi">+        d[&quot;geometry&quot;].append(p)</span>
<span class="gi">+        d[&quot;address&quot;].append(address)</span>
<span class="gi">+        index.append(i)</span>
<span class="gi">+</span>
<span class="gi">+    df = geopandas.GeoDataFrame(d, index=index, crs=&quot;EPSG:4326&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    return df</span>
<span class="gh">diff --git a/geopandas/tools/hilbert_curve.py b/geopandas/tools/hilbert_curve.py</span>
<span class="gh">index 7315816a..4d42abac 100644</span>
<span class="gd">--- a/geopandas/tools/hilbert_curve.py</span>
<span class="gi">+++ b/geopandas/tools/hilbert_curve.py</span>
<span class="gu">@@ -23,7 +23,20 @@ def _hilbert_distance(geoms, total_bounds=None, level=16):</span>
<span class="w"> </span>        Array containing distances along the Hilbert curve

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if geoms.is_empty.any() | geoms.isna().any():</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &quot;Hilbert distance cannot be computed on a GeoSeries with empty or &quot;</span>
<span class="gi">+            &quot;missing geometries.&quot;,</span>
<span class="gi">+        )</span>
<span class="gi">+    # Calculate bounds as numpy array</span>
<span class="gi">+    bounds = geoms.bounds</span>
<span class="gi">+</span>
<span class="gi">+    # Calculate discrete coords based on total bounds and bounds</span>
<span class="gi">+    x, y = _continuous_to_discrete_coords(bounds, level, total_bounds)</span>
<span class="gi">+    # Compute distance along hilbert curve</span>
<span class="gi">+    distances = _encode(level, x, y)</span>
<span class="gi">+</span>
<span class="gi">+    return distances</span>


<span class="w"> </span>def _continuous_to_discrete_coords(bounds, level, total_bounds):
<span class="gu">@@ -46,7 +59,29 @@ def _continuous_to_discrete_coords(bounds, level, total_bounds):</span>
<span class="w"> </span>    Two-dimensional array Array of hilbert distances for each geom

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # Hilbert Side length</span>
<span class="gi">+    side_length = (2**level) - 1</span>
<span class="gi">+</span>
<span class="gi">+    # Calculate mid points for x and y bound coords - returns array</span>
<span class="gi">+    x_mids = (bounds[:, 0] + bounds[:, 2]) / 2.0</span>
<span class="gi">+    y_mids = (bounds[:, 1] + bounds[:, 3]) / 2.0</span>
<span class="gi">+</span>
<span class="gi">+    # Calculate x and y range of total bound coords - returns array</span>
<span class="gi">+    if total_bounds is None:</span>
<span class="gi">+        total_bounds = (</span>
<span class="gi">+            np.nanmin(x_mids),</span>
<span class="gi">+            np.nanmin(y_mids),</span>
<span class="gi">+            np.nanmax(x_mids),</span>
<span class="gi">+            np.nanmax(y_mids),</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    xmin, ymin, xmax, ymax = total_bounds</span>
<span class="gi">+</span>
<span class="gi">+    # Transform continuous value to discrete integer for each dimension</span>
<span class="gi">+    x_int = _continuous_to_discrete(x_mids, (xmin, xmax), side_length)</span>
<span class="gi">+    y_int = _continuous_to_discrete(y_mids, (ymin, ymax), side_length)</span>
<span class="gi">+</span>
<span class="gi">+    return x_int, y_int</span>


<span class="w"> </span>def _continuous_to_discrete(vals, val_range, n):
<span class="gu">@@ -67,7 +102,87 @@ def _continuous_to_discrete(vals, val_range, n):</span>
<span class="w"> </span>    One-dimensional array of discrete ints

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    width = val_range[1] - val_range[0]</span>
<span class="gi">+    if width == 0:</span>
<span class="gi">+        return np.zeros_like(vals, dtype=np.uint32)</span>
<span class="gi">+    res = (vals - val_range[0]) * (n / width)</span>
<span class="gi">+</span>
<span class="gi">+    np.clip(res, 0, n, out=res)</span>
<span class="gi">+    return res.astype(np.uint32)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+# Fast Hilbert curve algorithm by http://threadlocalmutex.com/</span>
<span class="gi">+# From C++ https://github.com/rawrunprotected/hilbert_curves</span>
<span class="gi">+# (public domain)</span>


<span class="w"> </span>MAX_LEVEL = 16
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _interleave(x):</span>
<span class="gi">+    x = (x | (x &lt;&lt; 8)) &amp; 0x00FF00FF</span>
<span class="gi">+    x = (x | (x &lt;&lt; 4)) &amp; 0x0F0F0F0F</span>
<span class="gi">+    x = (x | (x &lt;&lt; 2)) &amp; 0x33333333</span>
<span class="gi">+    x = (x | (x &lt;&lt; 1)) &amp; 0x55555555</span>
<span class="gi">+    return x</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _encode(level, x, y):</span>
<span class="gi">+    x = np.asarray(x, dtype=&quot;uint32&quot;)</span>
<span class="gi">+    y = np.asarray(y, dtype=&quot;uint32&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    if level &gt; MAX_LEVEL:</span>
<span class="gi">+        raise ValueError(&quot;Level out of range&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    x = x &lt;&lt; (16 - level)</span>
<span class="gi">+    y = y &lt;&lt; (16 - level)</span>
<span class="gi">+</span>
<span class="gi">+    # Initial prefix scan round, prime with x and y</span>
<span class="gi">+    a = x ^ y</span>
<span class="gi">+    b = 0xFFFF ^ a</span>
<span class="gi">+    c = 0xFFFF ^ (x | y)</span>
<span class="gi">+    d = x &amp; (y ^ 0xFFFF)</span>
<span class="gi">+</span>
<span class="gi">+    A = a | (b &gt;&gt; 1)</span>
<span class="gi">+    B = (a &gt;&gt; 1) ^ a</span>
<span class="gi">+    C = ((c &gt;&gt; 1) ^ (b &amp; (d &gt;&gt; 1))) ^ c</span>
<span class="gi">+    D = ((a &amp; (c &gt;&gt; 1)) ^ (d &gt;&gt; 1)) ^ d</span>
<span class="gi">+</span>
<span class="gi">+    a = A.copy()</span>
<span class="gi">+    b = B.copy()</span>
<span class="gi">+    c = C.copy()</span>
<span class="gi">+    d = D.copy()</span>
<span class="gi">+</span>
<span class="gi">+    A = (a &amp; (a &gt;&gt; 2)) ^ (b &amp; (b &gt;&gt; 2))</span>
<span class="gi">+    B = (a &amp; (b &gt;&gt; 2)) ^ (b &amp; ((a ^ b) &gt;&gt; 2))</span>
<span class="gi">+    C ^= (a &amp; (c &gt;&gt; 2)) ^ (b &amp; (d &gt;&gt; 2))</span>
<span class="gi">+    D ^= (b &amp; (c &gt;&gt; 2)) ^ ((a ^ b) &amp; (d &gt;&gt; 2))</span>
<span class="gi">+</span>
<span class="gi">+    a = A.copy()</span>
<span class="gi">+    b = B.copy()</span>
<span class="gi">+    c = C.copy()</span>
<span class="gi">+    d = D.copy()</span>
<span class="gi">+</span>
<span class="gi">+    A = (a &amp; (a &gt;&gt; 4)) ^ (b &amp; (b &gt;&gt; 4))</span>
<span class="gi">+    B = (a &amp; (b &gt;&gt; 4)) ^ (b &amp; ((a ^ b) &gt;&gt; 4))</span>
<span class="gi">+    C ^= (a &amp; (c &gt;&gt; 4)) ^ (b &amp; (d &gt;&gt; 4))</span>
<span class="gi">+    D ^= (b &amp; (c &gt;&gt; 4)) ^ ((a ^ b) &amp; (d &gt;&gt; 4))</span>
<span class="gi">+</span>
<span class="gi">+    # Final round and projection</span>
<span class="gi">+    a = A.copy()</span>
<span class="gi">+    b = B.copy()</span>
<span class="gi">+    c = C.copy()</span>
<span class="gi">+    d = D.copy()</span>
<span class="gi">+</span>
<span class="gi">+    C ^= (a &amp; (c &gt;&gt; 8)) ^ (b &amp; (d &gt;&gt; 8))</span>
<span class="gi">+    D ^= (b &amp; (c &gt;&gt; 8)) ^ ((a ^ b) &amp; (d &gt;&gt; 8))</span>
<span class="gi">+</span>
<span class="gi">+    # Undo transformation prefix scan</span>
<span class="gi">+    a = C ^ (C &gt;&gt; 1)</span>
<span class="gi">+    b = D ^ (D &gt;&gt; 1)</span>
<span class="gi">+</span>
<span class="gi">+    # Recover index bits</span>
<span class="gi">+    i0 = x ^ y</span>
<span class="gi">+    i1 = b | (0xFFFF ^ (i0 | a))</span>
<span class="gi">+</span>
<span class="gi">+    return ((_interleave(i1) &lt;&lt; 1) | _interleave(i0)) &gt;&gt; (32 - 2 * level)</span>
<span class="gh">diff --git a/geopandas/tools/overlay.py b/geopandas/tools/overlay.py</span>
<span class="gh">index efb6afbd..06e60f7c 100644</span>
<span class="gd">--- a/geopandas/tools/overlay.py</span>
<span class="gi">+++ b/geopandas/tools/overlay.py</span>
<span class="gu">@@ -1,7 +1,9 @@</span>
<span class="w"> </span>import warnings
<span class="w"> </span>from functools import reduce
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>import pandas as pd
<span class="gi">+</span>
<span class="w"> </span>from geopandas import GeoDataFrame, GeoSeries
<span class="w"> </span>from geopandas._compat import PANDAS_GE_30
<span class="w"> </span>from geopandas.array import _check_crs, _crs_mismatch_warn
<span class="gu">@@ -12,39 +14,140 @@ def _ensure_geometry_column(df):</span>
<span class="w"> </span>    Helper function to ensure the geometry column is called &#39;geometry&#39;.
<span class="w"> </span>    If another column with that name exists, it will be dropped.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if not df._geometry_column_name == &quot;geometry&quot;:</span>
<span class="gi">+        if PANDAS_GE_30:</span>
<span class="gi">+            if &quot;geometry&quot; in df.columns:</span>
<span class="gi">+                df = df.drop(&quot;geometry&quot;, axis=1)</span>
<span class="gi">+            df = df.rename_geometry(&quot;geometry&quot;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            if &quot;geometry&quot; in df.columns:</span>
<span class="gi">+                df.drop(&quot;geometry&quot;, axis=1, inplace=True)</span>
<span class="gi">+            df.rename_geometry(&quot;geometry&quot;, inplace=True)</span>
<span class="gi">+    return df</span>


<span class="w"> </span>def _overlay_intersection(df1, df2):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Overlay Intersection operation used in overlay function
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # Spatial Index to create intersections</span>
<span class="gi">+    idx1, idx2 = df2.sindex.query(df1.geometry, predicate=&quot;intersects&quot;, sort=True)</span>
<span class="gi">+    # Create pairs of geometries in both dataframes to be intersected</span>
<span class="gi">+    if idx1.size &gt; 0 and idx2.size &gt; 0:</span>
<span class="gi">+        left = df1.geometry.take(idx1)</span>
<span class="gi">+        left.reset_index(drop=True, inplace=True)</span>
<span class="gi">+        right = df2.geometry.take(idx2)</span>
<span class="gi">+        right.reset_index(drop=True, inplace=True)</span>
<span class="gi">+        intersections = left.intersection(right)</span>
<span class="gi">+        poly_ix = intersections.geom_type.isin([&quot;Polygon&quot;, &quot;MultiPolygon&quot;])</span>
<span class="gi">+        intersections.loc[poly_ix] = intersections[poly_ix].make_valid()</span>
<span class="gi">+</span>
<span class="gi">+        # only keep actual intersecting geometries</span>
<span class="gi">+        pairs_intersect = pd.DataFrame({&quot;__idx1&quot;: idx1, &quot;__idx2&quot;: idx2})</span>
<span class="gi">+        geom_intersect = intersections</span>
<span class="gi">+</span>
<span class="gi">+        # merge data for intersecting geometries</span>
<span class="gi">+        df1 = df1.reset_index(drop=True)</span>
<span class="gi">+        df2 = df2.reset_index(drop=True)</span>
<span class="gi">+        dfinter = pairs_intersect.merge(</span>
<span class="gi">+            df1.drop(df1._geometry_column_name, axis=1),</span>
<span class="gi">+            left_on=&quot;__idx1&quot;,</span>
<span class="gi">+            right_index=True,</span>
<span class="gi">+        )</span>
<span class="gi">+        dfinter = dfinter.merge(</span>
<span class="gi">+            df2.drop(df2._geometry_column_name, axis=1),</span>
<span class="gi">+            left_on=&quot;__idx2&quot;,</span>
<span class="gi">+            right_index=True,</span>
<span class="gi">+            suffixes=(&quot;_1&quot;, &quot;_2&quot;),</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        return GeoDataFrame(dfinter, geometry=geom_intersect, crs=df1.crs)</span>
<span class="gi">+    else:</span>
<span class="gi">+        result = df1.iloc[:0].merge(</span>
<span class="gi">+            df2.iloc[:0].drop(df2.geometry.name, axis=1),</span>
<span class="gi">+            left_index=True,</span>
<span class="gi">+            right_index=True,</span>
<span class="gi">+            suffixes=(&quot;_1&quot;, &quot;_2&quot;),</span>
<span class="gi">+        )</span>
<span class="gi">+        result[&quot;__idx1&quot;] = np.nan</span>
<span class="gi">+        result[&quot;__idx2&quot;] = np.nan</span>
<span class="gi">+        return result[</span>
<span class="gi">+            result.columns.drop(df1.geometry.name).tolist() + [df1.geometry.name]</span>
<span class="gi">+        ]</span>


<span class="w"> </span>def _overlay_difference(df1, df2):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Overlay Difference operation used in overlay function
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # spatial index query to find intersections</span>
<span class="gi">+    idx1, idx2 = df2.sindex.query(df1.geometry, predicate=&quot;intersects&quot;, sort=True)</span>
<span class="gi">+    idx1_unique, idx1_unique_indices = np.unique(idx1, return_index=True)</span>
<span class="gi">+    idx2_split = np.split(idx2, idx1_unique_indices[1:])</span>
<span class="gi">+    sidx = [</span>
<span class="gi">+        idx2_split.pop(0) if idx in idx1_unique else []</span>
<span class="gi">+        for idx in range(df1.geometry.size)</span>
<span class="gi">+    ]</span>
<span class="gi">+    # Create differences</span>
<span class="gi">+    new_g = []</span>
<span class="gi">+    for geom, neighbours in zip(df1.geometry, sidx):</span>
<span class="gi">+        new = reduce(</span>
<span class="gi">+            lambda x, y: x.difference(y), [geom] + list(df2.geometry.iloc[neighbours])</span>
<span class="gi">+        )</span>
<span class="gi">+        new_g.append(new)</span>
<span class="gi">+    differences = GeoSeries(new_g, index=df1.index, crs=df1.crs)</span>
<span class="gi">+    poly_ix = differences.geom_type.isin([&quot;Polygon&quot;, &quot;MultiPolygon&quot;])</span>
<span class="gi">+    differences.loc[poly_ix] = differences[poly_ix].make_valid()</span>
<span class="gi">+    geom_diff = differences[~differences.is_empty].copy()</span>
<span class="gi">+    dfdiff = df1[~differences.is_empty].copy()</span>
<span class="gi">+    dfdiff[dfdiff._geometry_column_name] = geom_diff</span>
<span class="gi">+    return dfdiff</span>


<span class="w"> </span>def _overlay_symmetric_diff(df1, df2):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Overlay Symmetric Difference operation used in overlay function
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    dfdiff1 = _overlay_difference(df1, df2)</span>
<span class="gi">+    dfdiff2 = _overlay_difference(df2, df1)</span>
<span class="gi">+    dfdiff1[&quot;__idx1&quot;] = range(len(dfdiff1))</span>
<span class="gi">+    dfdiff2[&quot;__idx2&quot;] = range(len(dfdiff2))</span>
<span class="gi">+    dfdiff1[&quot;__idx2&quot;] = np.nan</span>
<span class="gi">+    dfdiff2[&quot;__idx1&quot;] = np.nan</span>
<span class="gi">+    # ensure geometry name (otherwise merge goes wrong)</span>
<span class="gi">+    dfdiff1 = _ensure_geometry_column(dfdiff1)</span>
<span class="gi">+    dfdiff2 = _ensure_geometry_column(dfdiff2)</span>
<span class="gi">+    # combine both &#39;difference&#39; dataframes</span>
<span class="gi">+    dfsym = dfdiff1.merge(</span>
<span class="gi">+        dfdiff2, on=[&quot;__idx1&quot;, &quot;__idx2&quot;], how=&quot;outer&quot;, suffixes=(&quot;_1&quot;, &quot;_2&quot;)</span>
<span class="gi">+    )</span>
<span class="gi">+    geometry = dfsym.geometry_1.copy()</span>
<span class="gi">+    geometry.name = &quot;geometry&quot;</span>
<span class="gi">+    # https://github.com/pandas-dev/pandas/issues/26468 use loc for now</span>
<span class="gi">+    geometry.loc[dfsym.geometry_1.isnull()] = dfsym.loc[</span>
<span class="gi">+        dfsym.geometry_1.isnull(), &quot;geometry_2&quot;</span>
<span class="gi">+    ]</span>
<span class="gi">+    dfsym.drop([&quot;geometry_1&quot;, &quot;geometry_2&quot;], axis=1, inplace=True)</span>
<span class="gi">+    dfsym.reset_index(drop=True, inplace=True)</span>
<span class="gi">+    dfsym = GeoDataFrame(dfsym, geometry=geometry, crs=df1.crs)</span>
<span class="gi">+    return dfsym</span>


<span class="w"> </span>def _overlay_union(df1, df2):
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Overlay Union operation used in overlay function
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    dfinter = _overlay_intersection(df1, df2)</span>
<span class="gi">+    dfsym = _overlay_symmetric_diff(df1, df2)</span>
<span class="gi">+    dfunion = pd.concat([dfinter, dfsym], ignore_index=True, sort=False)</span>
<span class="gi">+    # keep geometry column last</span>
<span class="gi">+    columns = list(dfunion.columns)</span>
<span class="gi">+    columns.remove(&quot;geometry&quot;)</span>
<span class="gi">+    columns.append(&quot;geometry&quot;)</span>
<span class="gi">+    return dfunion.reindex(columns=columns)</span>


<span class="gd">-def overlay(df1, df2, how=&#39;intersection&#39;, keep_geom_type=None, make_valid=True</span>
<span class="gd">-    ):</span>
<span class="gi">+def overlay(df1, df2, how=&quot;intersection&quot;, keep_geom_type=None, make_valid=True):</span>
<span class="w"> </span>    &quot;&quot;&quot;Perform spatial overlay between two GeoDataFrames.

<span class="w"> </span>    Currently only supports data GeoDataFrames with uniform geometry types,
<span class="gu">@@ -132,4 +235,165 @@ def overlay(df1, df2, how=&#39;intersection&#39;, keep_geom_type=None, make_valid=True</span>
<span class="w"> </span>    Every operation in GeoPandas is planar, i.e. the potential third
<span class="w"> </span>    dimension is not taken into account.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # Allowed operations</span>
<span class="gi">+    allowed_hows = [</span>
<span class="gi">+        &quot;intersection&quot;,</span>
<span class="gi">+        &quot;union&quot;,</span>
<span class="gi">+        &quot;identity&quot;,</span>
<span class="gi">+        &quot;symmetric_difference&quot;,</span>
<span class="gi">+        &quot;difference&quot;,  # aka erase</span>
<span class="gi">+    ]</span>
<span class="gi">+    # Error Messages</span>
<span class="gi">+    if how not in allowed_hows:</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &quot;`how` was &#39;{0}&#39; but is expected to be in {1}&quot;.format(how, allowed_hows)</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    if isinstance(df1, GeoSeries) or isinstance(df2, GeoSeries):</span>
<span class="gi">+        raise NotImplementedError(</span>
<span class="gi">+            &quot;overlay currently only implemented for GeoDataFrames&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    if not _check_crs(df1, df2):</span>
<span class="gi">+        _crs_mismatch_warn(df1, df2, stacklevel=3)</span>
<span class="gi">+</span>
<span class="gi">+    if keep_geom_type is None:</span>
<span class="gi">+        keep_geom_type = True</span>
<span class="gi">+        keep_geom_type_warning = True</span>
<span class="gi">+    else:</span>
<span class="gi">+        keep_geom_type_warning = False</span>
<span class="gi">+</span>
<span class="gi">+    polys = [&quot;Polygon&quot;, &quot;MultiPolygon&quot;]</span>
<span class="gi">+    lines = [&quot;LineString&quot;, &quot;MultiLineString&quot;, &quot;LinearRing&quot;]</span>
<span class="gi">+    points = [&quot;Point&quot;, &quot;MultiPoint&quot;]</span>
<span class="gi">+    for i, df in enumerate([df1, df2]):</span>
<span class="gi">+        poly_check = df.geom_type.isin(polys).any()</span>
<span class="gi">+        lines_check = df.geom_type.isin(lines).any()</span>
<span class="gi">+        points_check = df.geom_type.isin(points).any()</span>
<span class="gi">+        if sum([poly_check, lines_check, points_check]) &gt; 1:</span>
<span class="gi">+            raise NotImplementedError(</span>
<span class="gi">+                &quot;df{} contains mixed geometry types.&quot;.format(i + 1)</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    if how == &quot;intersection&quot;:</span>
<span class="gi">+        box_gdf1 = df1.total_bounds</span>
<span class="gi">+        box_gdf2 = df2.total_bounds</span>
<span class="gi">+</span>
<span class="gi">+        if not (</span>
<span class="gi">+            ((box_gdf1[0] &lt;= box_gdf2[2]) and (box_gdf2[0] &lt;= box_gdf1[2]))</span>
<span class="gi">+            and ((box_gdf1[1] &lt;= box_gdf2[3]) and (box_gdf2[1] &lt;= box_gdf1[3]))</span>
<span class="gi">+        ):</span>
<span class="gi">+            result = df1.iloc[:0].merge(</span>
<span class="gi">+                df2.iloc[:0].drop(df2.geometry.name, axis=1),</span>
<span class="gi">+                left_index=True,</span>
<span class="gi">+                right_index=True,</span>
<span class="gi">+                suffixes=(&quot;_1&quot;, &quot;_2&quot;),</span>
<span class="gi">+            )</span>
<span class="gi">+            return result[</span>
<span class="gi">+                result.columns.drop(df1.geometry.name).tolist() + [df1.geometry.name]</span>
<span class="gi">+            ]</span>
<span class="gi">+</span>
<span class="gi">+    # Computations</span>
<span class="gi">+    def _make_valid(df):</span>
<span class="gi">+        df = df.copy()</span>
<span class="gi">+        if df.geom_type.isin(polys).all():</span>
<span class="gi">+            mask = ~df.geometry.is_valid</span>
<span class="gi">+            col = df._geometry_column_name</span>
<span class="gi">+            if make_valid:</span>
<span class="gi">+                df.loc[mask, col] = df.loc[mask, col].make_valid()</span>
<span class="gi">+            elif mask.any():</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    &quot;You have passed make_valid=False along with &quot;</span>
<span class="gi">+                    f&quot;{mask.sum()} invalid input geometries. &quot;</span>
<span class="gi">+                    &quot;Use make_valid=True or make sure that all geometries &quot;</span>
<span class="gi">+                    &quot;are valid before using overlay.&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+        return df</span>
<span class="gi">+</span>
<span class="gi">+    df1 = _make_valid(df1)</span>
<span class="gi">+    df2 = _make_valid(df2)</span>
<span class="gi">+</span>
<span class="gi">+    with warnings.catch_warnings():  # CRS checked above, suppress array-level warning</span>
<span class="gi">+        warnings.filterwarnings(&quot;ignore&quot;, message=&quot;CRS mismatch between the CRS&quot;)</span>
<span class="gi">+        if how == &quot;difference&quot;:</span>
<span class="gi">+            result = _overlay_difference(df1, df2)</span>
<span class="gi">+        elif how == &quot;intersection&quot;:</span>
<span class="gi">+            result = _overlay_intersection(df1, df2)</span>
<span class="gi">+        elif how == &quot;symmetric_difference&quot;:</span>
<span class="gi">+            result = _overlay_symmetric_diff(df1, df2)</span>
<span class="gi">+        elif how == &quot;union&quot;:</span>
<span class="gi">+            result = _overlay_union(df1, df2)</span>
<span class="gi">+        elif how == &quot;identity&quot;:</span>
<span class="gi">+            dfunion = _overlay_union(df1, df2)</span>
<span class="gi">+            result = dfunion[dfunion[&quot;__idx1&quot;].notnull()].copy()</span>
<span class="gi">+</span>
<span class="gi">+        if how in [&quot;intersection&quot;, &quot;symmetric_difference&quot;, &quot;union&quot;, &quot;identity&quot;]:</span>
<span class="gi">+            result.drop([&quot;__idx1&quot;, &quot;__idx2&quot;], axis=1, inplace=True)</span>
<span class="gi">+</span>
<span class="gi">+    if keep_geom_type:</span>
<span class="gi">+        geom_type = df1.geom_type.iloc[0]</span>
<span class="gi">+</span>
<span class="gi">+        # First we filter the geometry types inside GeometryCollections objects</span>
<span class="gi">+        # (e.g. GeometryCollection([polygon, point]) -&gt; polygon)</span>
<span class="gi">+        # we do this separately on only the relevant rows, as this is an expensive</span>
<span class="gi">+        # operation (an expensive no-op for geometry types other than collections)</span>
<span class="gi">+        is_collection = result.geom_type == &quot;GeometryCollection&quot;</span>
<span class="gi">+        if is_collection.any():</span>
<span class="gi">+            geom_col = result._geometry_column_name</span>
<span class="gi">+            collections = result[[geom_col]][is_collection]</span>
<span class="gi">+</span>
<span class="gi">+            exploded = collections.reset_index(drop=True).explode(index_parts=True)</span>
<span class="gi">+            exploded = exploded.reset_index(level=0)</span>
<span class="gi">+</span>
<span class="gi">+            orig_num_geoms_exploded = exploded.shape[0]</span>
<span class="gi">+            if geom_type in polys:</span>
<span class="gi">+                exploded.loc[~exploded.geom_type.isin(polys), geom_col] = None</span>
<span class="gi">+            elif geom_type in lines:</span>
<span class="gi">+                exploded.loc[~exploded.geom_type.isin(lines), geom_col] = None</span>
<span class="gi">+            elif geom_type in points:</span>
<span class="gi">+                exploded.loc[~exploded.geom_type.isin(points), geom_col] = None</span>
<span class="gi">+            else:</span>
<span class="gi">+                raise TypeError(</span>
<span class="gi">+                    &quot;`keep_geom_type` does not support {}.&quot;.format(geom_type)</span>
<span class="gi">+                )</span>
<span class="gi">+            num_dropped_collection = (</span>
<span class="gi">+                orig_num_geoms_exploded - exploded.geometry.isna().sum()</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+            # level_0 created with above reset_index operation</span>
<span class="gi">+            # and represents the original geometry collections</span>
<span class="gi">+            # TODO avoiding dissolve to call union_all in this case could further</span>
<span class="gi">+            # improve performance (we only need to collect geometries in their</span>
<span class="gi">+            # respective Multi version)</span>
<span class="gi">+            dissolved = exploded.dissolve(by=&quot;level_0&quot;)</span>
<span class="gi">+            result.loc[is_collection, geom_col] = dissolved[geom_col].values</span>
<span class="gi">+        else:</span>
<span class="gi">+            num_dropped_collection = 0</span>
<span class="gi">+</span>
<span class="gi">+        # Now we filter all geometries (in theory we don&#39;t need to do this</span>
<span class="gi">+        # again for the rows handled above for GeometryCollections, but filtering</span>
<span class="gi">+        # them out is probably more expensive as simply including them when this</span>
<span class="gi">+        # is typically about only a few rows)</span>
<span class="gi">+        orig_num_geoms = result.shape[0]</span>
<span class="gi">+        if geom_type in polys:</span>
<span class="gi">+            result = result.loc[result.geom_type.isin(polys)]</span>
<span class="gi">+        elif geom_type in lines:</span>
<span class="gi">+            result = result.loc[result.geom_type.isin(lines)]</span>
<span class="gi">+        elif geom_type in points:</span>
<span class="gi">+            result = result.loc[result.geom_type.isin(points)]</span>
<span class="gi">+        else:</span>
<span class="gi">+            raise TypeError(&quot;`keep_geom_type` does not support {}.&quot;.format(geom_type))</span>
<span class="gi">+        num_dropped = orig_num_geoms - result.shape[0]</span>
<span class="gi">+</span>
<span class="gi">+        if (num_dropped &gt; 0 or num_dropped_collection &gt; 0) and keep_geom_type_warning:</span>
<span class="gi">+            warnings.warn(</span>
<span class="gi">+                &quot;`keep_geom_type=True` in overlay resulted in {} dropped &quot;</span>
<span class="gi">+                &quot;geometries of different geometry types than df1 has. &quot;</span>
<span class="gi">+                &quot;Set `keep_geom_type=False` to retain all &quot;</span>
<span class="gi">+                &quot;geometries&quot;.format(num_dropped + num_dropped_collection),</span>
<span class="gi">+                UserWarning,</span>
<span class="gi">+                stacklevel=2,</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    result.reset_index(drop=True, inplace=True)</span>
<span class="gi">+    return result</span>
<span class="gh">diff --git a/geopandas/tools/sjoin.py b/geopandas/tools/sjoin.py</span>
<span class="gh">index 04fc98c9..06d7ef74 100644</span>
<span class="gd">--- a/geopandas/tools/sjoin.py</span>
<span class="gi">+++ b/geopandas/tools/sjoin.py</span>
<span class="gu">@@ -1,15 +1,26 @@</span>
<span class="w"> </span>import warnings
<span class="w"> </span>from functools import partial
<span class="w"> </span>from typing import Optional
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>import pandas as pd
<span class="gi">+</span>
<span class="w"> </span>from geopandas import GeoDataFrame
<span class="w"> </span>from geopandas._compat import PANDAS_GE_30
<span class="w"> </span>from geopandas.array import _check_crs, _crs_mismatch_warn


<span class="gd">-def sjoin(left_df, right_df, how=&#39;inner&#39;, predicate=&#39;intersects&#39;, lsuffix=</span>
<span class="gd">-    &#39;left&#39;, rsuffix=&#39;right&#39;, distance=None, on_attribute=None, **kwargs):</span>
<span class="gi">+def sjoin(</span>
<span class="gi">+    left_df,</span>
<span class="gi">+    right_df,</span>
<span class="gi">+    how=&quot;inner&quot;,</span>
<span class="gi">+    predicate=&quot;intersects&quot;,</span>
<span class="gi">+    lsuffix=&quot;left&quot;,</span>
<span class="gi">+    rsuffix=&quot;right&quot;,</span>
<span class="gi">+    distance=None,</span>
<span class="gi">+    on_attribute=None,</span>
<span class="gi">+    **kwargs,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;Spatial join of two GeoDataFrames.

<span class="w"> </span>    See the User Guide page :doc:`../../user_guide/mergingdata` for details.
<span class="gu">@@ -94,7 +105,39 @@ def sjoin(left_df, right_df, how=&#39;inner&#39;, predicate=&#39;intersects&#39;, lsuffix=</span>
<span class="w"> </span>    Every operation in GeoPandas is planar, i.e. the potential third
<span class="w"> </span>    dimension is not taken into account.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if kwargs:</span>
<span class="gi">+        first = next(iter(kwargs.keys()))</span>
<span class="gi">+        raise TypeError(f&quot;sjoin() got an unexpected keyword argument &#39;{first}&#39;&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    on_attribute = _maybe_make_list(on_attribute)</span>
<span class="gi">+</span>
<span class="gi">+    _basic_checks(left_df, right_df, how, lsuffix, rsuffix, on_attribute=on_attribute),</span>
<span class="gi">+</span>
<span class="gi">+    indices = _geom_predicate_query(</span>
<span class="gi">+        left_df, right_df, predicate, distance, on_attribute=on_attribute</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    joined, _ = _frame_join(</span>
<span class="gi">+        left_df,</span>
<span class="gi">+        right_df,</span>
<span class="gi">+        indices,</span>
<span class="gi">+        None,</span>
<span class="gi">+        how,</span>
<span class="gi">+        lsuffix,</span>
<span class="gi">+        rsuffix,</span>
<span class="gi">+        predicate,</span>
<span class="gi">+        on_attribute=on_attribute,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    return joined</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _maybe_make_list(obj):</span>
<span class="gi">+    if isinstance(obj, tuple):</span>
<span class="gi">+        return list(obj)</span>
<span class="gi">+    if obj is not None and not isinstance(obj, list):</span>
<span class="gi">+        return [obj]</span>
<span class="gi">+    return obj</span>


<span class="w"> </span>def _basic_checks(left_df, right_df, how, lsuffix, rsuffix, on_attribute=None):
<span class="gu">@@ -117,11 +160,47 @@ def _basic_checks(left_df, right_df, how, lsuffix, rsuffix, on_attribute=None):</span>
<span class="w"> </span>    on_attribute : list, default None
<span class="w"> </span>        list of column names to merge on along with geometry
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def _geom_predicate_query(left_df, right_df, predicate, distance,</span>
<span class="gd">-    on_attribute=None):</span>
<span class="gi">+    if not isinstance(left_df, GeoDataFrame):</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &quot;&#39;left_df&#39; should be GeoDataFrame, got {}&quot;.format(type(left_df))</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    if not isinstance(right_df, GeoDataFrame):</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &quot;&#39;right_df&#39; should be GeoDataFrame, got {}&quot;.format(type(right_df))</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    allowed_hows = [&quot;left&quot;, &quot;right&quot;, &quot;inner&quot;]</span>
<span class="gi">+    if how not in allowed_hows:</span>
<span class="gi">+        raise ValueError(</span>
<span class="gi">+            &#39;`how` was &quot;{}&quot; but is expected to be in {}&#39;.format(how, allowed_hows)</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    if not _check_crs(left_df, right_df):</span>
<span class="gi">+        _crs_mismatch_warn(left_df, right_df, stacklevel=4)</span>
<span class="gi">+</span>
<span class="gi">+    if on_attribute:</span>
<span class="gi">+        for attr in on_attribute:</span>
<span class="gi">+            if (attr not in left_df) and (attr not in right_df):</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    f&quot;Expected column {attr} is missing from both of the dataframes.&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+            if attr not in left_df:</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    f&quot;Expected column {attr} is missing from the left dataframe.&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+            if attr not in right_df:</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    f&quot;Expected column {attr} is missing from the right dataframe.&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+            if attr in (left_df.geometry.name, right_df.geometry.name):</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    &quot;Active geometry column cannot be used as an input &quot;</span>
<span class="gi">+                    &quot;for on_attribute parameter.&quot;</span>
<span class="gi">+                )</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _geom_predicate_query(left_df, right_df, predicate, distance, on_attribute=None):</span>
<span class="w"> </span>    &quot;&quot;&quot;Compute geometric comparisons and get matching indices.

<span class="w"> </span>    Parameters
<span class="gu">@@ -140,7 +219,45 @@ def _geom_predicate_query(left_df, right_df, predicate, distance,</span>
<span class="w"> </span>        DataFrame with matching indices in
<span class="w"> </span>        columns named `_key_left` and `_key_right`.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    original_predicate = predicate</span>
<span class="gi">+</span>
<span class="gi">+    if predicate == &quot;within&quot;:</span>
<span class="gi">+        # within is implemented as the inverse of contains</span>
<span class="gi">+        # contains is a faster predicate</span>
<span class="gi">+        # see discussion at https://github.com/geopandas/geopandas/pull/1421</span>
<span class="gi">+        predicate = &quot;contains&quot;</span>
<span class="gi">+        sindex = left_df.sindex</span>
<span class="gi">+        input_geoms = right_df.geometry</span>
<span class="gi">+    else:</span>
<span class="gi">+        # all other predicates are symmetric</span>
<span class="gi">+        # keep them the same</span>
<span class="gi">+        sindex = right_df.sindex</span>
<span class="gi">+        input_geoms = left_df.geometry</span>
<span class="gi">+</span>
<span class="gi">+    if sindex:</span>
<span class="gi">+        l_idx, r_idx = sindex.query(</span>
<span class="gi">+            input_geoms, predicate=predicate, sort=False, distance=distance</span>
<span class="gi">+        )</span>
<span class="gi">+    else:</span>
<span class="gi">+        # when sindex is empty / has no valid geometries</span>
<span class="gi">+        l_idx, r_idx = np.array([], dtype=np.intp), np.array([], dtype=np.intp)</span>
<span class="gi">+</span>
<span class="gi">+    if original_predicate == &quot;within&quot;:</span>
<span class="gi">+        # within is implemented as the inverse of contains</span>
<span class="gi">+        # flip back the results</span>
<span class="gi">+        r_idx, l_idx = l_idx, r_idx</span>
<span class="gi">+        indexer = np.lexsort((r_idx, l_idx))</span>
<span class="gi">+        l_idx = l_idx[indexer]</span>
<span class="gi">+        r_idx = r_idx[indexer]</span>
<span class="gi">+</span>
<span class="gi">+    if on_attribute:</span>
<span class="gi">+        for attr in on_attribute:</span>
<span class="gi">+            (l_idx, r_idx), _ = _filter_shared_attribute(</span>
<span class="gi">+                left_df, right_df, l_idx, r_idx, attr</span>
<span class="gi">+            )</span>
<span class="gi">+</span>
<span class="gi">+    return l_idx, r_idx</span>


<span class="w"> </span>def _reset_index_with_suffix(df, suffix, other):
<span class="gu">@@ -148,18 +265,91 @@ def _reset_index_with_suffix(df, suffix, other):</span>
<span class="w"> </span>    Equivalent of df.reset_index(), but with adding &#39;suffix&#39; to auto-generated
<span class="w"> </span>    column names.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def _process_column_names_with_suffix(left: pd.Index, right: pd.Index,</span>
<span class="gd">-    suffixes, left_df, right_df):</span>
<span class="gi">+    index_original = df.index.names</span>
<span class="gi">+    if PANDAS_GE_30:</span>
<span class="gi">+        df_reset = df.reset_index()</span>
<span class="gi">+    else:</span>
<span class="gi">+        # we already made a copy of the dataframe in _frame_join before getting here</span>
<span class="gi">+        df_reset = df</span>
<span class="gi">+        df_reset.reset_index(inplace=True)</span>
<span class="gi">+    column_names = df_reset.columns.to_numpy(copy=True)</span>
<span class="gi">+    for i, label in enumerate(index_original):</span>
<span class="gi">+        # if the original label was None, add suffix to auto-generated name</span>
<span class="gi">+        if label is None:</span>
<span class="gi">+            new_label = column_names[i]</span>
<span class="gi">+            if &quot;level&quot; in new_label:</span>
<span class="gi">+                # reset_index of MultiIndex gives &quot;level_i&quot; names, preserve the &quot;i&quot;</span>
<span class="gi">+                lev = new_label.split(&quot;_&quot;)[1]</span>
<span class="gi">+                new_label = f&quot;index_{suffix}{lev}&quot;</span>
<span class="gi">+            else:</span>
<span class="gi">+                new_label = f&quot;index_{suffix}&quot;</span>
<span class="gi">+            # check new label will not be in other dataframe</span>
<span class="gi">+            if new_label in df.columns or new_label in other.columns:</span>
<span class="gi">+                raise ValueError(</span>
<span class="gi">+                    &quot;&#39;{0}&#39; cannot be a column name in the frames being&quot;</span>
<span class="gi">+                    &quot; joined&quot;.format(new_label)</span>
<span class="gi">+                )</span>
<span class="gi">+            column_names[i] = new_label</span>
<span class="gi">+    return df_reset, pd.Index(column_names)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _process_column_names_with_suffix(</span>
<span class="gi">+    left: pd.Index, right: pd.Index, suffixes, left_df, right_df</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;
<span class="w"> </span>    Add suffixes to overlapping labels (ignoring the geometry column).

<span class="w"> </span>    This is based on pandas&#39; merge logic at https://github.com/pandas-dev/pandas/blob/
<span class="w"> </span>    a0779adb183345a8eb4be58b3ad00c223da58768/pandas/core/reshape/merge.py#L2300-L2370
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    to_rename = left.intersection(right)</span>
<span class="gi">+    if len(to_rename) == 0:</span>
<span class="gi">+        return left, right</span>
<span class="gi">+</span>
<span class="gi">+    lsuffix, rsuffix = suffixes</span>
<span class="gi">+</span>
<span class="gi">+    if not lsuffix and not rsuffix:</span>
<span class="gi">+        raise ValueError(f&quot;columns overlap but no suffix specified: {to_rename}&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def renamer(x, suffix, geometry):</span>
<span class="gi">+        if x in to_rename and x != geometry and suffix is not None:</span>
<span class="gi">+            return f&quot;{x}_{suffix}&quot;</span>
<span class="gi">+        return x</span>
<span class="gi">+</span>
<span class="gi">+    lrenamer = partial(</span>
<span class="gi">+        renamer,</span>
<span class="gi">+        suffix=lsuffix,</span>
<span class="gi">+        geometry=getattr(left_df, &quot;_geometry_column_name&quot;, None),</span>
<span class="gi">+    )</span>
<span class="gi">+    rrenamer = partial(</span>
<span class="gi">+        renamer,</span>
<span class="gi">+        suffix=rsuffix,</span>
<span class="gi">+        geometry=getattr(right_df, &quot;_geometry_column_name&quot;, None),</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    # TODO retain index name?</span>
<span class="gi">+    left_renamed = pd.Index([lrenamer(lab) for lab in left])</span>
<span class="gi">+    right_renamed = pd.Index([rrenamer(lab) for lab in right])</span>
<span class="gi">+</span>
<span class="gi">+    dups = []</span>
<span class="gi">+    if not left_renamed.is_unique:</span>
<span class="gi">+        # Only warn when duplicates are caused because of suffixes, already duplicated</span>
<span class="gi">+        # columns in origin should not warn</span>
<span class="gi">+        dups = left_renamed[(left_renamed.duplicated()) &amp; (~left.duplicated())].tolist()</span>
<span class="gi">+    if not right_renamed.is_unique:</span>
<span class="gi">+        dups.extend(</span>
<span class="gi">+            right_renamed[(right_renamed.duplicated()) &amp; (~right.duplicated())].tolist()</span>
<span class="gi">+        )</span>
<span class="gi">+    # TODO turn this into an error (pandas has done so as well)</span>
<span class="gi">+    if dups:</span>
<span class="gi">+        warnings.warn(</span>
<span class="gi">+            f&quot;Passing &#39;suffixes&#39; which cause duplicate columns {set(dups)} in the &quot;</span>
<span class="gi">+            f&quot;result is deprecated and will raise a MergeError in a future version.&quot;,</span>
<span class="gi">+            FutureWarning,</span>
<span class="gi">+            stacklevel=4,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    return left_renamed, right_renamed</span>


<span class="w"> </span>def _restore_index(joined, index_names, index_names_original):
<span class="gu">@@ -167,7 +357,18 @@ def _restore_index(joined, index_names, index_names_original):</span>
<span class="w"> </span>    Set back the the original index columns, and restoring their name as `None`
<span class="w"> </span>    if they didn&#39;t have a name originally.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if PANDAS_GE_30:</span>
<span class="gi">+        joined = joined.set_index(list(index_names))</span>
<span class="gi">+    else:</span>
<span class="gi">+        joined.set_index(list(index_names), inplace=True)</span>
<span class="gi">+</span>
<span class="gi">+    # restore the fact that the index didn&#39;t have a name</span>
<span class="gi">+    joined_index_names = list(joined.index.names)</span>
<span class="gi">+    for i, label in enumerate(index_names_original):</span>
<span class="gi">+        if label is None:</span>
<span class="gi">+            joined_index_names[i] = None</span>
<span class="gi">+    joined.index.names = joined_index_names</span>
<span class="gi">+    return joined</span>


<span class="w"> </span>def _adjust_indexers(indices, distances, original_length, how, predicate):
<span class="gu">@@ -176,11 +377,52 @@ def _adjust_indexers(indices, distances, original_length, how, predicate):</span>
<span class="w"> </span>    For a left or right join, we need to adjust them to include the rows
<span class="w"> </span>    that would not be present in an inner join.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def _frame_join(left_df, right_df, indices, distances, how, lsuffix,</span>
<span class="gd">-    rsuffix, predicate, on_attribute=None):</span>
<span class="gi">+    # the indices represent an inner join, no adjustment needed</span>
<span class="gi">+    if how == &quot;inner&quot;:</span>
<span class="gi">+        return indices, distances</span>
<span class="gi">+</span>
<span class="gi">+    l_idx, r_idx = indices</span>
<span class="gi">+</span>
<span class="gi">+    if how == &quot;right&quot;:</span>
<span class="gi">+        # re-sort so it is sorted by the right indexer</span>
<span class="gi">+        indexer = np.lexsort((l_idx, r_idx))</span>
<span class="gi">+        l_idx, r_idx = l_idx[indexer], r_idx[indexer]</span>
<span class="gi">+        if distances is not None:</span>
<span class="gi">+            distances = distances[indexer]</span>
<span class="gi">+</span>
<span class="gi">+        # switch order</span>
<span class="gi">+        r_idx, l_idx = l_idx, r_idx</span>
<span class="gi">+</span>
<span class="gi">+    # determine which indices are missing and where they would need to be inserted</span>
<span class="gi">+    idx = np.arange(original_length)</span>
<span class="gi">+    l_idx_missing = idx[~np.isin(idx, l_idx)]</span>
<span class="gi">+    insert_idx = np.searchsorted(l_idx, l_idx_missing)</span>
<span class="gi">+    # for the left indexer, insert those missing indices</span>
<span class="gi">+    l_idx = np.insert(l_idx, insert_idx, l_idx_missing)</span>
<span class="gi">+    # for the right indexer, insert -1 -&gt; to get missing values in pandas&#39; reindexing</span>
<span class="gi">+    r_idx = np.insert(r_idx, insert_idx, -1)</span>
<span class="gi">+    # for the indices, already insert those missing values manually</span>
<span class="gi">+    if distances is not None:</span>
<span class="gi">+        distances = np.insert(distances, insert_idx, np.nan)</span>
<span class="gi">+</span>
<span class="gi">+    if how == &quot;right&quot;:</span>
<span class="gi">+        # switch back</span>
<span class="gi">+        l_idx, r_idx = r_idx, l_idx</span>
<span class="gi">+</span>
<span class="gi">+    return (l_idx, r_idx), distances</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _frame_join(</span>
<span class="gi">+    left_df,</span>
<span class="gi">+    right_df,</span>
<span class="gi">+    indices,</span>
<span class="gi">+    distances,</span>
<span class="gi">+    how,</span>
<span class="gi">+    lsuffix,</span>
<span class="gi">+    rsuffix,</span>
<span class="gi">+    predicate,</span>
<span class="gi">+    on_attribute=None,</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;Join the GeoDataFrames at the DataFrame level.

<span class="w"> </span>    Parameters
<span class="gu">@@ -208,7 +450,117 @@ def _frame_join(left_df, right_df, indices, distances, how, lsuffix,</span>
<span class="w"> </span>    GeoDataFrame
<span class="w"> </span>        Joined GeoDataFrame.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if on_attribute:  # avoid renaming or duplicating shared column</span>
<span class="gi">+        right_df = right_df.drop(on_attribute, axis=1)</span>
<span class="gi">+</span>
<span class="gi">+    if how in (&quot;inner&quot;, &quot;left&quot;):</span>
<span class="gi">+        right_df = right_df.drop(right_df.geometry.name, axis=1)</span>
<span class="gi">+    else:  # how == &#39;right&#39;:</span>
<span class="gi">+        left_df = left_df.drop(left_df.geometry.name, axis=1)</span>
<span class="gi">+</span>
<span class="gi">+    left_df = left_df.copy(deep=False)</span>
<span class="gi">+    left_nlevels = left_df.index.nlevels</span>
<span class="gi">+    left_index_original = left_df.index.names</span>
<span class="gi">+    left_df, left_column_names = _reset_index_with_suffix(left_df, lsuffix, right_df)</span>
<span class="gi">+</span>
<span class="gi">+    right_df = right_df.copy(deep=False)</span>
<span class="gi">+    right_nlevels = right_df.index.nlevels</span>
<span class="gi">+    right_index_original = right_df.index.names</span>
<span class="gi">+    right_df, right_column_names = _reset_index_with_suffix(right_df, rsuffix, left_df)</span>
<span class="gi">+</span>
<span class="gi">+    # if conflicting names in left and right, add suffix</span>
<span class="gi">+    left_column_names, right_column_names = _process_column_names_with_suffix(</span>
<span class="gi">+        left_column_names,</span>
<span class="gi">+        right_column_names,</span>
<span class="gi">+        (lsuffix, rsuffix),</span>
<span class="gi">+        left_df,</span>
<span class="gi">+        right_df,</span>
<span class="gi">+    )</span>
<span class="gi">+    left_df.columns = left_column_names</span>
<span class="gi">+    right_df.columns = right_column_names</span>
<span class="gi">+    left_index = left_df.columns[:left_nlevels]</span>
<span class="gi">+    right_index = right_df.columns[:right_nlevels]</span>
<span class="gi">+</span>
<span class="gi">+    # perform join on the dataframes</span>
<span class="gi">+    original_length = len(right_df) if how == &quot;right&quot; else len(left_df)</span>
<span class="gi">+    (l_idx, r_idx), distances = _adjust_indexers(</span>
<span class="gi">+        indices, distances, original_length, how, predicate</span>
<span class="gi">+    )</span>
<span class="gi">+    # the `take` method doesn&#39;t allow introducing NaNs with -1 indices</span>
<span class="gi">+    # left = left_df.take(l_idx)</span>
<span class="gi">+    # therefore we are using the private _reindex_with_indexers as workaround</span>
<span class="gi">+    new_index = pd.RangeIndex(len(l_idx))</span>
<span class="gi">+    left = left_df._reindex_with_indexers({0: (new_index, l_idx)})</span>
<span class="gi">+    right = right_df._reindex_with_indexers({0: (new_index, r_idx)})</span>
<span class="gi">+    if PANDAS_GE_30:</span>
<span class="gi">+        kwargs = {}</span>
<span class="gi">+    else:</span>
<span class="gi">+        kwargs = dict(copy=False)</span>
<span class="gi">+    joined = pd.concat([left, right], axis=1, **kwargs)</span>
<span class="gi">+</span>
<span class="gi">+    if how in (&quot;inner&quot;, &quot;left&quot;):</span>
<span class="gi">+        joined = _restore_index(joined, left_index, left_index_original)</span>
<span class="gi">+    else:  # how == &#39;right&#39;:</span>
<span class="gi">+        joined = joined.set_geometry(right_df.geometry.name)</span>
<span class="gi">+        joined = _restore_index(joined, right_index, right_index_original)</span>
<span class="gi">+</span>
<span class="gi">+    return joined, distances</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def _nearest_query(</span>
<span class="gi">+    left_df: GeoDataFrame,</span>
<span class="gi">+    right_df: GeoDataFrame,</span>
<span class="gi">+    max_distance: float,</span>
<span class="gi">+    how: str,</span>
<span class="gi">+    return_distance: bool,</span>
<span class="gi">+    exclusive: bool,</span>
<span class="gi">+    on_attribute: Optional[list] = None,</span>
<span class="gi">+):</span>
<span class="gi">+    # use the opposite of the join direction for the index</span>
<span class="gi">+    use_left_as_sindex = how == &quot;right&quot;</span>
<span class="gi">+    if use_left_as_sindex:</span>
<span class="gi">+        sindex = left_df.sindex</span>
<span class="gi">+        query = right_df.geometry</span>
<span class="gi">+    else:</span>
<span class="gi">+        sindex = right_df.sindex</span>
<span class="gi">+        query = left_df.geometry</span>
<span class="gi">+    if sindex:</span>
<span class="gi">+        res = sindex.nearest(</span>
<span class="gi">+            query,</span>
<span class="gi">+            return_all=True,</span>
<span class="gi">+            max_distance=max_distance,</span>
<span class="gi">+            return_distance=return_distance,</span>
<span class="gi">+            exclusive=exclusive,</span>
<span class="gi">+        )</span>
<span class="gi">+        if return_distance:</span>
<span class="gi">+            (input_idx, tree_idx), distances = res</span>
<span class="gi">+        else:</span>
<span class="gi">+            (input_idx, tree_idx) = res</span>
<span class="gi">+            distances = None</span>
<span class="gi">+        if use_left_as_sindex:</span>
<span class="gi">+            l_idx, r_idx = tree_idx, input_idx</span>
<span class="gi">+            sort_order = np.argsort(l_idx, kind=&quot;stable&quot;)</span>
<span class="gi">+            l_idx, r_idx = l_idx[sort_order], r_idx[sort_order]</span>
<span class="gi">+            if distances is not None:</span>
<span class="gi">+                distances = distances[sort_order]</span>
<span class="gi">+        else:</span>
<span class="gi">+            l_idx, r_idx = input_idx, tree_idx</span>
<span class="gi">+    else:</span>
<span class="gi">+        # when sindex is empty / has no valid geometries</span>
<span class="gi">+        l_idx, r_idx = np.array([], dtype=np.intp), np.array([], dtype=np.intp)</span>
<span class="gi">+        if return_distance:</span>
<span class="gi">+            distances = np.array([], dtype=np.float64)</span>
<span class="gi">+        else:</span>
<span class="gi">+            distances = None</span>
<span class="gi">+</span>
<span class="gi">+    if on_attribute:</span>
<span class="gi">+        for attr in on_attribute:</span>
<span class="gi">+            (l_idx, r_idx), shared_attribute_rows = _filter_shared_attribute(</span>
<span class="gi">+                left_df, right_df, l_idx, r_idx, attr</span>
<span class="gi">+            )</span>
<span class="gi">+            distances = distances[shared_attribute_rows]</span>
<span class="gi">+</span>
<span class="gi">+    return (l_idx, r_idx), distances</span>


<span class="w"> </span>def _filter_shared_attribute(left_df, right_df, l_idx, r_idx, attribute):
<span class="gu">@@ -217,13 +569,25 @@ def _filter_shared_attribute(left_df, right_df, l_idx, r_idx, attribute):</span>
<span class="w"> </span>    in the attribute column. Also returns a Boolean `shared_attribute_rows` for rows
<span class="w"> </span>    with the same entry.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-def sjoin_nearest(left_df: GeoDataFrame, right_df: GeoDataFrame, how: str=</span>
<span class="gd">-    &#39;inner&#39;, max_distance: Optional[float]=None, lsuffix: str=&#39;left&#39;,</span>
<span class="gd">-    rsuffix: str=&#39;right&#39;, distance_col: Optional[str]=None, exclusive: bool</span>
<span class="gd">-    =False) -&gt;GeoDataFrame:</span>
<span class="gi">+    shared_attribute_rows = (</span>
<span class="gi">+        left_df[attribute].iloc[l_idx].values == right_df[attribute].iloc[r_idx].values</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    l_idx = l_idx[shared_attribute_rows]</span>
<span class="gi">+    r_idx = r_idx[shared_attribute_rows]</span>
<span class="gi">+    return (l_idx, r_idx), shared_attribute_rows</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def sjoin_nearest(</span>
<span class="gi">+    left_df: GeoDataFrame,</span>
<span class="gi">+    right_df: GeoDataFrame,</span>
<span class="gi">+    how: str = &quot;inner&quot;,</span>
<span class="gi">+    max_distance: Optional[float] = None,</span>
<span class="gi">+    lsuffix: str = &quot;left&quot;,</span>
<span class="gi">+    rsuffix: str = &quot;right&quot;,</span>
<span class="gi">+    distance_col: Optional[str] = None,</span>
<span class="gi">+    exclusive: bool = False,</span>
<span class="gi">+) -&gt; GeoDataFrame:</span>
<span class="w"> </span>    &quot;&quot;&quot;Spatial join of two GeoDataFrames based on the distance between their geometries.

<span class="w"> </span>    Results will include multiple output records for a single input record
<span class="gu">@@ -301,8 +665,10 @@ def sjoin_nearest(left_df: GeoDataFrame, right_df: GeoDataFrame, how: str=</span>

<span class="w"> </span>    To include the distances:

<span class="gd">-    &gt;&gt;&gt; groceries_w_communities = geopandas.sjoin_nearest(groceries, chicago, distance_col=&quot;distances&quot;)</span>
<span class="gd">-    &gt;&gt;&gt; groceries_w_communities[[&quot;Chain&quot;, &quot;community&quot;, &quot;distances&quot;]].head(2)</span>
<span class="gi">+    &gt;&gt;&gt; groceries_w_communities = geopandas.sjoin_nearest(groceries, chicago, \</span>
<span class="gi">+distance_col=&quot;distances&quot;)</span>
<span class="gi">+    &gt;&gt;&gt; groceries_w_communities[[&quot;Chain&quot;, &quot;community&quot;, \</span>
<span class="gi">+&quot;distances&quot;]].head(2)</span>
<span class="w"> </span>                   Chain    community  distances
<span class="w"> </span>    0     VIET HOA PLAZA       UPTOWN        0.0
<span class="w"> </span>    1  COUNTY FAIR FOODS  MORGAN PARK        0.0
<span class="gu">@@ -311,8 +677,10 @@ def sjoin_nearest(left_df: GeoDataFrame, right_df: GeoDataFrame, how: str=</span>
<span class="w"> </span>    results are equidistant (in this case zero because they intersect).
<span class="w"> </span>    In fact, we get 4 results in total:

<span class="gd">-    &gt;&gt;&gt; chicago_w_groceries = geopandas.sjoin_nearest(groceries, chicago, distance_col=&quot;distances&quot;, how=&quot;right&quot;)</span>
<span class="gd">-    &gt;&gt;&gt; uptown_results = chicago_w_groceries[chicago_w_groceries[&quot;community&quot;] == &quot;UPTOWN&quot;]</span>
<span class="gi">+    &gt;&gt;&gt; chicago_w_groceries = geopandas.sjoin_nearest(groceries, chicago, \</span>
<span class="gi">+distance_col=&quot;distances&quot;, how=&quot;right&quot;)</span>
<span class="gi">+    &gt;&gt;&gt; uptown_results = \</span>
<span class="gi">+chicago_w_groceries[chicago_w_groceries[&quot;community&quot;] == &quot;UPTOWN&quot;]</span>
<span class="w"> </span>    &gt;&gt;&gt; uptown_results[[&quot;Chain&quot;, &quot;community&quot;]]
<span class="w"> </span>                Chain community
<span class="w"> </span>    30  VIET HOA PLAZA    UPTOWN
<span class="gu">@@ -333,4 +701,34 @@ def sjoin_nearest(left_df: GeoDataFrame, right_df: GeoDataFrame, how: str=</span>
<span class="w"> </span>    Every operation in GeoPandas is planar, i.e. the potential third
<span class="w"> </span>    dimension is not taken into account.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+</span>
<span class="gi">+    _basic_checks(left_df, right_df, how, lsuffix, rsuffix)</span>
<span class="gi">+</span>
<span class="gi">+    left_df.geometry.values.check_geographic_crs(stacklevel=1)</span>
<span class="gi">+    right_df.geometry.values.check_geographic_crs(stacklevel=1)</span>
<span class="gi">+</span>
<span class="gi">+    return_distance = distance_col is not None</span>
<span class="gi">+</span>
<span class="gi">+    indices, distances = _nearest_query(</span>
<span class="gi">+        left_df,</span>
<span class="gi">+        right_df,</span>
<span class="gi">+        max_distance,</span>
<span class="gi">+        how,</span>
<span class="gi">+        return_distance,</span>
<span class="gi">+        exclusive,</span>
<span class="gi">+    )</span>
<span class="gi">+    joined, distances = _frame_join(</span>
<span class="gi">+        left_df,</span>
<span class="gi">+        right_df,</span>
<span class="gi">+        indices,</span>
<span class="gi">+        distances,</span>
<span class="gi">+        how,</span>
<span class="gi">+        lsuffix,</span>
<span class="gi">+        rsuffix,</span>
<span class="gi">+        None,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    if return_distance:</span>
<span class="gi">+        joined[distance_col] = distances</span>
<span class="gi">+</span>
<span class="gi">+    return joined</span>
<span class="gh">diff --git a/geopandas/tools/tests/test_clip.py b/geopandas/tools/tests/test_clip.py</span>
<span class="gh">index 6ccf6e29..dbdbfe6e 100644</span>
<span class="gd">--- a/geopandas/tools/tests/test_clip.py</span>
<span class="gi">+++ b/geopandas/tools/tests/test_clip.py</span>
<span class="gu">@@ -1,70 +1,99 @@</span>
<span class="w"> </span>&quot;&quot;&quot;Tests for the clip module.&quot;&quot;&quot;
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>import pandas as pd
<span class="gi">+</span>
<span class="w"> </span>import shapely
<span class="gd">-from shapely.geometry import GeometryCollection, LinearRing, LineString, MultiPoint, Point, Polygon, box</span>
<span class="gi">+from shapely.geometry import (</span>
<span class="gi">+    GeometryCollection,</span>
<span class="gi">+    LinearRing,</span>
<span class="gi">+    LineString,</span>
<span class="gi">+    MultiPoint,</span>
<span class="gi">+    Point,</span>
<span class="gi">+    Polygon,</span>
<span class="gi">+    box,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="w"> </span>import geopandas
<span class="w"> </span>from geopandas import GeoDataFrame, GeoSeries, clip
<span class="w"> </span>from geopandas._compat import HAS_PYPROJ
<span class="w"> </span>from geopandas.tools.clip import _mask_is_list_like_rectangle
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="w"> </span>from geopandas.testing import assert_geodataframe_equal, assert_geoseries_equal
<span class="w"> </span>from pandas.testing import assert_index_equal
<span class="gd">-mask_variants_single_rectangle = [&#39;single_rectangle_gdf&#39;,</span>
<span class="gd">-    &#39;single_rectangle_gdf_list_bounds&#39;, &#39;single_rectangle_gdf_tuple_bounds&#39;,</span>
<span class="gd">-    &#39;single_rectangle_gdf_array_bounds&#39;]</span>
<span class="gd">-mask_variants_large_rectangle = [&#39;larger_single_rectangle_gdf&#39;,</span>
<span class="gd">-    &#39;larger_single_rectangle_gdf_bounds&#39;]</span>
<span class="gi">+</span>
<span class="gi">+mask_variants_single_rectangle = [</span>
<span class="gi">+    &quot;single_rectangle_gdf&quot;,</span>
<span class="gi">+    &quot;single_rectangle_gdf_list_bounds&quot;,</span>
<span class="gi">+    &quot;single_rectangle_gdf_tuple_bounds&quot;,</span>
<span class="gi">+    &quot;single_rectangle_gdf_array_bounds&quot;,</span>
<span class="gi">+]</span>
<span class="gi">+mask_variants_large_rectangle = [</span>
<span class="gi">+    &quot;larger_single_rectangle_gdf&quot;,</span>
<span class="gi">+    &quot;larger_single_rectangle_gdf_bounds&quot;,</span>
<span class="gi">+]</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def point_gdf():
<span class="w"> </span>    &quot;&quot;&quot;Create a point GeoDataFrame.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    pts = np.array([[2, 2], [3, 4], [9, 8], [-12, -15]])</span>
<span class="gi">+    gdf = GeoDataFrame([Point(xy) for xy in pts], columns=[&quot;geometry&quot;], crs=&quot;EPSG:3857&quot;)</span>
<span class="gi">+    return gdf</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def point_gdf2():
<span class="w"> </span>    &quot;&quot;&quot;Create a point GeoDataFrame.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    pts = np.array([[5, 5], [2, 2], [4, 4], [0, 0], [3, 3], [1, 1]])</span>
<span class="gi">+    gdf = GeoDataFrame([Point(xy) for xy in pts], columns=[&quot;geometry&quot;], crs=&quot;EPSG:3857&quot;)</span>
<span class="gi">+    return gdf</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def pointsoutside_nooverlap_gdf():
<span class="w"> </span>    &quot;&quot;&quot;Create a point GeoDataFrame. Its points are all outside the single
<span class="w"> </span>    rectangle, and its bounds are outside the single rectangle&#39;s.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    pts = np.array([[5, 15], [15, 15], [15, 20]])</span>
<span class="gi">+    gdf = GeoDataFrame([Point(xy) for xy in pts], columns=[&quot;geometry&quot;], crs=&quot;EPSG:3857&quot;)</span>
<span class="gi">+    return gdf</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def pointsoutside_overlap_gdf():
<span class="w"> </span>    &quot;&quot;&quot;Create a point GeoDataFrame. Its points are all outside the single
<span class="w"> </span>    rectangle, and its bounds are overlapping the single rectangle&#39;s.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    pts = np.array([[5, 15], [15, 15], [15, 5]])</span>
<span class="gi">+    gdf = GeoDataFrame([Point(xy) for xy in pts], columns=[&quot;geometry&quot;], crs=&quot;EPSG:3857&quot;)</span>
<span class="gi">+    return gdf</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def single_rectangle_gdf():
<span class="w"> </span>    &quot;&quot;&quot;Create a single rectangle for clipping.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    poly_inters = Polygon([(0, 0), (0, 10), (10, 10), (10, 0), (0, 0)])</span>
<span class="gi">+    gdf = GeoDataFrame([1], geometry=[poly_inters], crs=&quot;EPSG:3857&quot;)</span>
<span class="gi">+    gdf[&quot;attr2&quot;] = &quot;site-boundary&quot;</span>
<span class="gi">+    return gdf</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def single_rectangle_gdf_tuple_bounds(single_rectangle_gdf):
<span class="w"> </span>    &quot;&quot;&quot;Bounds of the created single rectangle&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return tuple(single_rectangle_gdf.total_bounds)</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def single_rectangle_gdf_list_bounds(single_rectangle_gdf):
<span class="w"> </span>    &quot;&quot;&quot;Bounds of the created single rectangle&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return list(single_rectangle_gdf.total_bounds)</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def single_rectangle_gdf_array_bounds(single_rectangle_gdf):
<span class="w"> </span>    &quot;&quot;&quot;Bounds of the created single rectangle&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return single_rectangle_gdf.total_bounds</span>


<span class="w"> </span>@pytest.fixture
<span class="gu">@@ -74,204 +103,382 @@ def larger_single_rectangle_gdf():</span>
<span class="w"> </span>    are returned when you clip polygons. This fixture is larger which
<span class="w"> </span>    eliminates the slivers in the clip return.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    poly_inters = Polygon([(-5, -5), (-5, 15), (15, 15), (15, -5), (-5, -5)])</span>
<span class="gi">+    gdf = GeoDataFrame([1], geometry=[poly_inters], crs=&quot;EPSG:3857&quot;)</span>
<span class="gi">+    gdf[&quot;attr2&quot;] = [&quot;study area&quot;]</span>
<span class="gi">+    return gdf</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def larger_single_rectangle_gdf_bounds(larger_single_rectangle_gdf):
<span class="w"> </span>    &quot;&quot;&quot;Bounds of the created single rectangle&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    return tuple(larger_single_rectangle_gdf.total_bounds)</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def buffered_locations(point_gdf):
<span class="w"> </span>    &quot;&quot;&quot;Buffer points to create a multi-polygon.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    buffered_locs = point_gdf</span>
<span class="gi">+    buffered_locs[&quot;geometry&quot;] = buffered_locs.buffer(4)</span>
<span class="gi">+    buffered_locs[&quot;type&quot;] = &quot;plot&quot;</span>
<span class="gi">+    return buffered_locs</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def donut_geometry(buffered_locations, single_rectangle_gdf):
<span class="w"> </span>    &quot;&quot;&quot;Make a geometry with a hole in the middle (a donut).&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    donut = geopandas.overlay(</span>
<span class="gi">+        buffered_locations, single_rectangle_gdf, how=&quot;symmetric_difference&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    return donut</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def two_line_gdf():
<span class="w"> </span>    &quot;&quot;&quot;Create Line Objects For Testing&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    linea = LineString([(1, 1), (2, 2), (3, 2), (5, 3)])</span>
<span class="gi">+    lineb = LineString([(3, 4), (5, 7), (12, 2), (10, 5), (9, 7.5)])</span>
<span class="gi">+    gdf = GeoDataFrame([1, 2], geometry=[linea, lineb], crs=&quot;EPSG:3857&quot;)</span>
<span class="gi">+    return gdf</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def multi_poly_gdf(donut_geometry):
<span class="w"> </span>    &quot;&quot;&quot;Create a multi-polygon GeoDataFrame.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    multi_poly = donut_geometry.union_all()</span>
<span class="gi">+    out_df = GeoDataFrame(geometry=GeoSeries(multi_poly), crs=&quot;EPSG:3857&quot;)</span>
<span class="gi">+    out_df[&quot;attr&quot;] = [&quot;pool&quot;]</span>
<span class="gi">+    return out_df</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def multi_line(two_line_gdf):
<span class="w"> </span>    &quot;&quot;&quot;Create a multi-line GeoDataFrame.
<span class="w"> </span>    This GDF has one multiline and one regular line.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    # Create a single and multi line object</span>
<span class="gi">+    multiline_feat = two_line_gdf.union_all()</span>
<span class="gi">+    linec = LineString([(2, 1), (3, 1), (4, 1), (5, 2)])</span>
<span class="gi">+    out_df = GeoDataFrame(geometry=GeoSeries([multiline_feat, linec]), crs=&quot;EPSG:3857&quot;)</span>
<span class="gi">+    out_df[&quot;attr&quot;] = [&quot;road&quot;, &quot;stream&quot;]</span>
<span class="gi">+    return out_df</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def multi_point(point_gdf):
<span class="w"> </span>    &quot;&quot;&quot;Create a multi-point GeoDataFrame.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    multi_point = point_gdf.union_all()</span>
<span class="gi">+    out_df = GeoDataFrame(</span>
<span class="gi">+        geometry=GeoSeries(</span>
<span class="gi">+            [multi_point, Point(2, 5), Point(-11, -14), Point(-10, -12)]</span>
<span class="gi">+        ),</span>
<span class="gi">+        crs=&quot;EPSG:3857&quot;,</span>
<span class="gi">+    )</span>
<span class="gi">+    out_df[&quot;attr&quot;] = [&quot;tree&quot;, &quot;another tree&quot;, &quot;shrub&quot;, &quot;berries&quot;]</span>
<span class="gi">+    return out_df</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def mixed_gdf():
<span class="w"> </span>    &quot;&quot;&quot;Create a Mixed Polygon and LineString For Testing&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    point = Point(2, 3)</span>
<span class="gi">+    line = LineString([(1, 1), (2, 2), (3, 2), (5, 3), (12, 1)])</span>
<span class="gi">+    poly = Polygon([(3, 4), (5, 2), (12, 2), (10, 5), (9, 7.5)])</span>
<span class="gi">+    ring = LinearRing([(1, 1), (2, 2), (3, 2), (5, 3), (12, 1)])</span>
<span class="gi">+    gdf = GeoDataFrame(</span>
<span class="gi">+        [1, 2, 3, 4], geometry=[point, poly, line, ring], crs=&quot;EPSG:3857&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    return gdf</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def geomcol_gdf():
<span class="w"> </span>    &quot;&quot;&quot;Create a Mixed Polygon and LineString For Testing&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    point = Point(2, 3)</span>
<span class="gi">+    poly = Polygon([(3, 4), (5, 2), (12, 2), (10, 5), (9, 7.5)])</span>
<span class="gi">+    coll = GeometryCollection([point, poly])</span>
<span class="gi">+    gdf = GeoDataFrame([1], geometry=[coll], crs=&quot;EPSG:3857&quot;)</span>
<span class="gi">+    return gdf</span>


<span class="w"> </span>@pytest.fixture
<span class="w"> </span>def sliver_line():
<span class="w"> </span>    &quot;&quot;&quot;Create a line that will create a point when clipped.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    linea = LineString([(10, 5), (13, 5), (15, 5)])</span>
<span class="gi">+    lineb = LineString([(1, 1), (2, 2), (3, 2), (5, 3), (12, 1)])</span>
<span class="gi">+    gdf = GeoDataFrame([1, 2], geometry=[linea, lineb], crs=&quot;EPSG:3857&quot;)</span>
<span class="gi">+    return gdf</span>


<span class="w"> </span>def test_not_gdf(single_rectangle_gdf):
<span class="w"> </span>    &quot;&quot;&quot;Non-GeoDataFrame inputs raise attribute errors.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    with pytest.raises(TypeError):</span>
<span class="gi">+        clip((2, 3), single_rectangle_gdf)</span>
<span class="gi">+    with pytest.raises(TypeError):</span>
<span class="gi">+        clip(single_rectangle_gdf, &quot;foobar&quot;)</span>
<span class="gi">+    with pytest.raises(TypeError):</span>
<span class="gi">+        clip(single_rectangle_gdf, (1, 2, 3))</span>
<span class="gi">+    with pytest.raises(TypeError):</span>
<span class="gi">+        clip(single_rectangle_gdf, (1, 2, 3, 4, 5))</span>


<span class="w"> </span>def test_non_overlapping_geoms():
<span class="w"> </span>    &quot;&quot;&quot;Test that a bounding box returns empty if the extents don&#39;t overlap&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-@pytest.mark.parametrize(&#39;mask_fixture_name&#39;, mask_variants_single_rectangle)</span>
<span class="gi">+    unit_box = Polygon([(0, 0), (0, 1), (1, 1), (1, 0), (0, 0)])</span>
<span class="gi">+    unit_gdf = GeoDataFrame([1], geometry=[unit_box], crs=&quot;EPSG:3857&quot;)</span>
<span class="gi">+    non_overlapping_gdf = unit_gdf.copy()</span>
<span class="gi">+    non_overlapping_gdf = non_overlapping_gdf.geometry.apply(</span>
<span class="gi">+        lambda x: shapely.affinity.translate(x, xoff=20)</span>
<span class="gi">+    )</span>
<span class="gi">+    out = clip(unit_gdf, non_overlapping_gdf)</span>
<span class="gi">+    assert_geodataframe_equal(out, unit_gdf.iloc[:0])</span>
<span class="gi">+    out2 = clip(unit_gdf.geometry, non_overlapping_gdf)</span>
<span class="gi">+    assert_geoseries_equal(out2, GeoSeries(crs=unit_gdf.crs))</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;mask_fixture_name&quot;, mask_variants_single_rectangle)</span>
<span class="w"> </span>class TestClipWithSingleRectangleGdf:
<span class="gi">+    @pytest.fixture</span>
<span class="gi">+    def mask(self, mask_fixture_name, request):</span>
<span class="gi">+        return request.getfixturevalue(mask_fixture_name)</span>

<span class="w"> </span>    def test_returns_gdf(self, point_gdf, mask):
<span class="w"> </span>        &quot;&quot;&quot;Test that function returns a GeoDataFrame (or GDF-like) object.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        out = clip(point_gdf, mask)</span>
<span class="gi">+        assert isinstance(out, GeoDataFrame)</span>

<span class="w"> </span>    def test_returns_series(self, point_gdf, mask):
<span class="w"> </span>        &quot;&quot;&quot;Test that function returns a GeoSeries if GeoSeries is passed.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        out = clip(point_gdf.geometry, mask)</span>
<span class="gi">+        assert isinstance(out, GeoSeries)</span>

<span class="w"> </span>    def test_clip_points(self, point_gdf, mask):
<span class="w"> </span>        &quot;&quot;&quot;Test clipping a points GDF with a generic polygon geometry.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        clip_pts = clip(point_gdf, mask)</span>
<span class="gi">+        pts = np.array([[2, 2], [3, 4], [9, 8]])</span>
<span class="gi">+        exp = GeoDataFrame(</span>
<span class="gi">+            [Point(xy) for xy in pts], columns=[&quot;geometry&quot;], crs=&quot;EPSG:3857&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+        assert_geodataframe_equal(clip_pts, exp)</span>

<span class="w"> </span>    def test_clip_points_geom_col_rename(self, point_gdf, mask):
<span class="w"> </span>        &quot;&quot;&quot;Test clipping a points GDF with a generic polygon geometry.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        point_gdf_geom_col_rename = point_gdf.rename_geometry(&quot;geometry2&quot;)</span>
<span class="gi">+        clip_pts = clip(point_gdf_geom_col_rename, mask)</span>
<span class="gi">+        pts = np.array([[2, 2], [3, 4], [9, 8]])</span>
<span class="gi">+        exp = GeoDataFrame(</span>
<span class="gi">+            [Point(xy) for xy in pts],</span>
<span class="gi">+            columns=[&quot;geometry2&quot;],</span>
<span class="gi">+            crs=&quot;EPSG:3857&quot;,</span>
<span class="gi">+            geometry=&quot;geometry2&quot;,</span>
<span class="gi">+        )</span>
<span class="gi">+        assert_geodataframe_equal(clip_pts, exp)</span>

<span class="w"> </span>    def test_clip_poly(self, buffered_locations, mask):
<span class="w"> </span>        &quot;&quot;&quot;Test clipping a polygon GDF with a generic polygon geometry.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        clipped_poly = clip(buffered_locations, mask)</span>
<span class="gi">+        assert len(clipped_poly.geometry) == 3</span>
<span class="gi">+        assert all(clipped_poly.geom_type == &quot;Polygon&quot;)</span>

<span class="w"> </span>    def test_clip_poly_geom_col_rename(self, buffered_locations, mask):
<span class="w"> </span>        &quot;&quot;&quot;Test clipping a polygon GDF with a generic polygon geometry.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+</span>
<span class="gi">+        poly_gdf_geom_col_rename = buffered_locations.rename_geometry(&quot;geometry2&quot;)</span>
<span class="gi">+        clipped_poly = clip(poly_gdf_geom_col_rename, mask)</span>
<span class="gi">+        assert len(clipped_poly.geometry) == 3</span>
<span class="gi">+        assert &quot;geometry&quot; not in clipped_poly.keys()</span>
<span class="gi">+        assert &quot;geometry2&quot; in clipped_poly.keys()</span>

<span class="w"> </span>    def test_clip_poly_series(self, buffered_locations, mask):
<span class="w"> </span>        &quot;&quot;&quot;Test clipping a polygon GDF with a generic polygon geometry.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        clipped_poly = clip(buffered_locations.geometry, mask)</span>
<span class="gi">+        assert len(clipped_poly) == 3</span>
<span class="gi">+        assert all(clipped_poly.geom_type == &quot;Polygon&quot;)</span>

<span class="w"> </span>    def test_clip_multipoly_keep_geom_type(self, multi_poly_gdf, mask):
<span class="w"> </span>        &quot;&quot;&quot;Test a multi poly object where the return includes a sliver.
<span class="w"> </span>        Also the bounds of the object should == the bounds of the clip object
<span class="w"> </span>        if they fully overlap (as they do in these fixtures).&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        clipped = clip(multi_poly_gdf, mask, keep_geom_type=True)</span>
<span class="gi">+        expected_bounds = (</span>
<span class="gi">+            mask if _mask_is_list_like_rectangle(mask) else mask.total_bounds</span>
<span class="gi">+        )</span>
<span class="gi">+        assert np.array_equal(clipped.total_bounds, expected_bounds)</span>
<span class="gi">+        # Assert returned data is a not geometry collection</span>
<span class="gi">+        assert (clipped.geom_type.isin([&quot;Polygon&quot;, &quot;MultiPolygon&quot;])).all()</span>

<span class="w"> </span>    def test_clip_multiline(self, multi_line, mask):
<span class="w"> </span>        &quot;&quot;&quot;Test that clipping a multiline feature with a poly returns expected
<span class="w"> </span>        output.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        clipped = clip(multi_line, mask)</span>
<span class="gi">+        assert clipped.geom_type[0] == &quot;MultiLineString&quot;</span>

<span class="w"> </span>    def test_clip_multipoint(self, multi_point, mask):
<span class="w"> </span>        &quot;&quot;&quot;Clipping a multipoint feature with a polygon works as expected.
<span class="w"> </span>        should return a geodataframe with a single multi point feature&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        clipped = clip(multi_point, mask)</span>
<span class="gi">+        assert clipped.geom_type[0] == &quot;MultiPoint&quot;</span>
<span class="gi">+        assert hasattr(clipped, &quot;attr&quot;)</span>
<span class="gi">+        # All points should intersect the clip geom</span>
<span class="gi">+        assert len(clipped) == 2</span>
<span class="gi">+        clipped_mutltipoint = MultiPoint(</span>
<span class="gi">+            [</span>
<span class="gi">+                Point(2, 2),</span>
<span class="gi">+                Point(3, 4),</span>
<span class="gi">+                Point(9, 8),</span>
<span class="gi">+            ]</span>
<span class="gi">+        )</span>
<span class="gi">+        assert clipped.iloc[0].geometry.wkt == clipped_mutltipoint.wkt</span>
<span class="gi">+        shape_for_points = (</span>
<span class="gi">+            box(*mask) if _mask_is_list_like_rectangle(mask) else mask.union_all()</span>
<span class="gi">+        )</span>
<span class="gi">+        assert all(clipped.intersects(shape_for_points))</span>

<span class="w"> </span>    def test_clip_lines(self, two_line_gdf, mask):
<span class="w"> </span>        &quot;&quot;&quot;Test what happens when you give the clip_extent a line GDF.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        clip_line = clip(two_line_gdf, mask)</span>
<span class="gi">+        assert len(clip_line.geometry) == 2</span>

<span class="w"> </span>    def test_mixed_geom(self, mixed_gdf, mask):
<span class="w"> </span>        &quot;&quot;&quot;Test clipping a mixed GeoDataFrame&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        clipped = clip(mixed_gdf, mask)</span>
<span class="gi">+        assert (</span>
<span class="gi">+            clipped.geom_type[0] == &quot;Point&quot;</span>
<span class="gi">+            and clipped.geom_type[1] == &quot;Polygon&quot;</span>
<span class="gi">+            and clipped.geom_type[2] == &quot;LineString&quot;</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def test_mixed_series(self, mixed_gdf, mask):
<span class="w"> </span>        &quot;&quot;&quot;Test clipping a mixed GeoSeries&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        clipped = clip(mixed_gdf.geometry, mask)</span>
<span class="gi">+        assert (</span>
<span class="gi">+            clipped.geom_type[0] == &quot;Point&quot;</span>
<span class="gi">+            and clipped.geom_type[1] == &quot;Polygon&quot;</span>
<span class="gi">+            and clipped.geom_type[2] == &quot;LineString&quot;</span>
<span class="gi">+        )</span>

<span class="w"> </span>    def test_clip_with_line_extra_geom(self, sliver_line, mask):
<span class="w"> </span>        &quot;&quot;&quot;When the output of a clipped line returns a geom collection,
<span class="w"> </span>        and keep_geom_type is True, no geometry collections should be returned.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        clipped = clip(sliver_line, mask, keep_geom_type=True)</span>
<span class="gi">+        assert len(clipped.geometry) == 1</span>
<span class="gi">+        # Assert returned data is a not geometry collection</span>
<span class="gi">+        assert not (clipped.geom_type == &quot;GeometryCollection&quot;).any()</span>

<span class="w"> </span>    def test_clip_no_box_overlap(self, pointsoutside_nooverlap_gdf, mask):
<span class="w"> </span>        &quot;&quot;&quot;Test clip when intersection is empty and boxes do not overlap.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        clipped = clip(pointsoutside_nooverlap_gdf, mask)</span>
<span class="gi">+        assert len(clipped) == 0</span>

<span class="w"> </span>    def test_clip_box_overlap(self, pointsoutside_overlap_gdf, mask):
<span class="w"> </span>        &quot;&quot;&quot;Test clip when intersection is empty and boxes do overlap.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        clipped = clip(pointsoutside_overlap_gdf, mask)</span>
<span class="gi">+        assert len(clipped) == 0</span>

<span class="w"> </span>    def test_warning_extra_geoms_mixed(self, mixed_gdf, mask):
<span class="w"> </span>        &quot;&quot;&quot;Test the correct warnings are raised if keep_geom_type is
<span class="w"> </span>        called on a mixed GDF&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with pytest.warns(UserWarning):</span>
<span class="gi">+            clip(mixed_gdf, mask, keep_geom_type=True)</span>

<span class="w"> </span>    def test_warning_geomcoll(self, geomcol_gdf, mask):
<span class="w"> </span>        &quot;&quot;&quot;Test the correct warnings are raised if keep_geom_type is
<span class="w"> </span>        called on a GDF with GeometryCollection&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        with pytest.warns(UserWarning):</span>
<span class="gi">+            clip(geomcol_gdf, mask, keep_geom_type=True)</span>


<span class="w"> </span>def test_clip_line_keep_slivers(sliver_line, single_rectangle_gdf):
<span class="w"> </span>    &quot;&quot;&quot;Test the correct output if a point is returned
<span class="w"> </span>    from a line only geometry type.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    clipped = clip(sliver_line, single_rectangle_gdf)</span>
<span class="gi">+    # Assert returned data is a geometry collection given sliver geoms</span>
<span class="gi">+    assert &quot;Point&quot; == clipped.geom_type[0]</span>
<span class="gi">+    assert &quot;LineString&quot; == clipped.geom_type[1]</span>


<span class="w"> </span>def test_clip_multipoly_keep_slivers(multi_poly_gdf, single_rectangle_gdf):
<span class="w"> </span>    &quot;&quot;&quot;Test a multi poly object where the return includes a sliver.
<span class="w"> </span>    Also the bounds of the object should == the bounds of the clip object
<span class="w"> </span>    if they fully overlap (as they do in these fixtures).&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    clipped = clip(multi_poly_gdf, single_rectangle_gdf)</span>
<span class="gi">+    assert np.array_equal(clipped.total_bounds, single_rectangle_gdf.total_bounds)</span>
<span class="gi">+    # Assert returned data is a geometry collection given sliver geoms</span>
<span class="gi">+    assert &quot;GeometryCollection&quot; in clipped.geom_type[0]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.skipif(not HAS_PYPROJ, reason=&quot;pyproj not available&quot;)</span>
<span class="gi">+def test_warning_crs_mismatch(point_gdf, single_rectangle_gdf):</span>
<span class="gi">+    with pytest.warns(UserWarning, match=&quot;CRS mismatch between the CRS&quot;):</span>
<span class="gi">+        clip(point_gdf, single_rectangle_gdf.to_crs(4326))</span>


<span class="w"> </span>def test_clip_with_polygon(single_rectangle_gdf):
<span class="w"> </span>    &quot;&quot;&quot;Test clip when using a shapely object&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    polygon = Polygon([(0, 0), (5, 12), (10, 0), (0, 0)])</span>
<span class="gi">+    clipped = clip(single_rectangle_gdf, polygon)</span>
<span class="gi">+    exp_poly = polygon.intersection(</span>
<span class="gi">+        Polygon([(0, 0), (0, 10), (10, 10), (10, 0), (0, 0)])</span>
<span class="gi">+    )</span>
<span class="gi">+    exp = GeoDataFrame([1], geometry=[exp_poly], crs=&quot;EPSG:3857&quot;)</span>
<span class="gi">+    exp[&quot;attr2&quot;] = &quot;site-boundary&quot;</span>
<span class="gi">+    assert_geodataframe_equal(clipped, exp)</span>


<span class="w"> </span>def test_clip_with_multipolygon(buffered_locations, single_rectangle_gdf):
<span class="w"> </span>    &quot;&quot;&quot;Test clipping a polygon with a multipolygon.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-@pytest.mark.parametrize(&#39;mask_fixture_name&#39;, mask_variants_large_rectangle)</span>
<span class="gd">-def test_clip_single_multipoly_no_extra_geoms(buffered_locations,</span>
<span class="gd">-    mask_fixture_name, request):</span>
<span class="gi">+    multi = buffered_locations.dissolve(by=&quot;type&quot;).reset_index()</span>
<span class="gi">+    clipped = clip(single_rectangle_gdf, multi)</span>
<span class="gi">+    assert clipped.geom_type[0] == &quot;Polygon&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;mask_fixture_name&quot;,</span>
<span class="gi">+    mask_variants_large_rectangle,</span>
<span class="gi">+)</span>
<span class="gi">+def test_clip_single_multipoly_no_extra_geoms(</span>
<span class="gi">+    buffered_locations, mask_fixture_name, request</span>
<span class="gi">+):</span>
<span class="w"> </span>    &quot;&quot;&quot;When clipping a multi-polygon feature, no additional geom types
<span class="w"> </span>    should be returned.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-@pytest.mark.filterwarnings(&#39;ignore:All-NaN slice encountered&#39;)</span>
<span class="gd">-@pytest.mark.parametrize(&#39;mask&#39;, [Polygon(), (np.nan,) * 4, (np.nan, 0, np.</span>
<span class="gd">-    nan, 1), GeoSeries([Polygon(), Polygon()], crs=&#39;EPSG:3857&#39;), GeoSeries(</span>
<span class="gd">-    [Polygon(), Polygon()], crs=&#39;EPSG:3857&#39;).to_frame(), GeoSeries([], crs=</span>
<span class="gd">-    &#39;EPSG:3857&#39;), GeoSeries([], crs=&#39;EPSG:3857&#39;).to_frame()])</span>
<span class="gi">+    masks = request.getfixturevalue(mask_fixture_name)</span>
<span class="gi">+    multi = buffered_locations.dissolve(by=&quot;type&quot;).reset_index()</span>
<span class="gi">+    clipped = clip(multi, masks)</span>
<span class="gi">+    assert clipped.geom_type[0] == &quot;Polygon&quot;</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.filterwarnings(&quot;ignore:All-NaN slice encountered&quot;)</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;mask&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        Polygon(),</span>
<span class="gi">+        (np.nan,) * 4,</span>
<span class="gi">+        (np.nan, 0, np.nan, 1),</span>
<span class="gi">+        GeoSeries([Polygon(), Polygon()], crs=&quot;EPSG:3857&quot;),</span>
<span class="gi">+        GeoSeries([Polygon(), Polygon()], crs=&quot;EPSG:3857&quot;).to_frame(),</span>
<span class="gi">+        GeoSeries([], crs=&quot;EPSG:3857&quot;),</span>
<span class="gi">+        GeoSeries([], crs=&quot;EPSG:3857&quot;).to_frame(),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="w"> </span>def test_clip_empty_mask(buffered_locations, mask):
<span class="w"> </span>    &quot;&quot;&quot;Test that clipping with empty mask returns an empty result.&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    clipped = clip(buffered_locations, mask)</span>
<span class="gi">+    assert_geodataframe_equal(</span>
<span class="gi">+        clipped,</span>
<span class="gi">+        GeoDataFrame([], columns=[&quot;geometry&quot;, &quot;type&quot;], crs=&quot;EPSG:3857&quot;),</span>
<span class="gi">+        check_index_type=False,</span>
<span class="gi">+    )</span>
<span class="gi">+    clipped = clip(buffered_locations.geometry, mask)</span>
<span class="gi">+    assert_geoseries_equal(clipped, GeoSeries([], crs=&quot;EPSG:3857&quot;))</span>


<span class="w"> </span>def test_clip_sorting(point_gdf2):
<span class="w"> </span>    &quot;&quot;&quot;Test the sorting kwarg in clip&quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    bbox = shapely.geometry.box(0, 0, 2, 2)</span>
<span class="gi">+    unsorted_clipped_gdf = point_gdf2.clip(bbox)</span>
<span class="gi">+    sorted_clipped_gdf = point_gdf2.clip(bbox, sort=True)</span>
<span class="gi">+</span>
<span class="gi">+    expected_sorted_index = pd.Index([1, 3, 5])</span>
<span class="gi">+</span>
<span class="gi">+    assert not (sorted(unsorted_clipped_gdf.index) == unsorted_clipped_gdf.index).all()</span>
<span class="gi">+    assert (sorted(sorted_clipped_gdf.index) == sorted_clipped_gdf.index).all()</span>
<span class="gi">+    assert_index_equal(expected_sorted_index, sorted_clipped_gdf.index)</span>
<span class="gh">diff --git a/geopandas/tools/tests/test_hilbert_curve.py b/geopandas/tools/tests/test_hilbert_curve.py</span>
<span class="gh">index 38de871e..3d79a84c 100644</span>
<span class="gd">--- a/geopandas/tools/tests/test_hilbert_curve.py</span>
<span class="gi">+++ b/geopandas/tools/tests/test_hilbert_curve.py</span>
<span class="gu">@@ -1,6 +1,76 @@</span>
<span class="w"> </span>import numpy as np
<span class="gi">+</span>
<span class="w"> </span>from shapely.geometry import Point
<span class="w"> </span>from shapely.wkt import loads
<span class="gi">+</span>
<span class="w"> </span>import geopandas
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="w"> </span>from pandas.testing import assert_series_equal
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_hilbert_distance():</span>
<span class="gi">+    # test the actual Hilbert Code algorithm against some hardcoded values</span>
<span class="gi">+    geoms = geopandas.GeoSeries.from_wkt(</span>
<span class="gi">+        [</span>
<span class="gi">+            &quot;POINT (0 0)&quot;,</span>
<span class="gi">+            &quot;POINT (1 1)&quot;,</span>
<span class="gi">+            &quot;POINT (1 0)&quot;,</span>
<span class="gi">+            &quot;POLYGON ((0 0, 0 1, 1 1, 1 0, 0 0))&quot;,</span>
<span class="gi">+        ]</span>
<span class="gi">+    )</span>
<span class="gi">+    result = geoms.hilbert_distance(total_bounds=(0, 0, 1, 1), level=2)</span>
<span class="gi">+    assert result.tolist() == [0, 10, 15, 2]</span>
<span class="gi">+</span>
<span class="gi">+    result = geoms.hilbert_distance(total_bounds=(0, 0, 1, 1), level=3)</span>
<span class="gi">+    assert result.tolist() == [0, 42, 63, 10]</span>
<span class="gi">+</span>
<span class="gi">+    result = geoms.hilbert_distance(total_bounds=(0, 0, 1, 1), level=16)</span>
<span class="gi">+    assert result.tolist() == [0, 2863311530, 4294967295, 715827882]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def geoseries_points():</span>
<span class="gi">+    p1 = Point(1, 2)</span>
<span class="gi">+    p2 = Point(2, 3)</span>
<span class="gi">+    p3 = Point(3, 4)</span>
<span class="gi">+    p4 = Point(4, 1)</span>
<span class="gi">+    return geopandas.GeoSeries([p1, p2, p3, p4])</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_hilbert_distance_level(geoseries_points):</span>
<span class="gi">+    with pytest.raises(ValueError):</span>
<span class="gi">+        geoseries_points.hilbert_distance(level=20)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_specified_total_bounds(geoseries_points):</span>
<span class="gi">+    result = geoseries_points.hilbert_distance(</span>
<span class="gi">+        total_bounds=geoseries_points.total_bounds</span>
<span class="gi">+    )</span>
<span class="gi">+    expected = geoseries_points.hilbert_distance()</span>
<span class="gi">+    assert_series_equal(result, expected)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;empty&quot;,</span>
<span class="gi">+    [</span>
<span class="gi">+        None,</span>
<span class="gi">+        loads(&quot;POLYGON EMPTY&quot;),</span>
<span class="gi">+    ],</span>
<span class="gi">+)</span>
<span class="gi">+def test_empty(geoseries_points, empty):</span>
<span class="gi">+    s = geoseries_points</span>
<span class="gi">+    s.iloc[-1] = empty</span>
<span class="gi">+    with pytest.raises(</span>
<span class="gi">+        ValueError, match=&quot;cannot be computed on a GeoSeries with empty&quot;</span>
<span class="gi">+    ):</span>
<span class="gi">+        s.hilbert_distance()</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_zero_width():</span>
<span class="gi">+    # special case of all points on the same line -&gt; avoid warnings because</span>
<span class="gi">+    # of division by 0 and introducing NaN</span>
<span class="gi">+    s = geopandas.GeoSeries([Point(0, 0), Point(0, 2), Point(0, 1)])</span>
<span class="gi">+    with np.errstate(all=&quot;raise&quot;):</span>
<span class="gi">+        result = s.hilbert_distance()</span>
<span class="gi">+    assert np.array(result).argsort().tolist() == [0, 2, 1]</span>
<span class="gh">diff --git a/geopandas/tools/tests/test_random.py b/geopandas/tools/tests/test_random.py</span>
<span class="gh">index ada7295a..a8d9a4fb 100644</span>
<span class="gd">--- a/geopandas/tools/tests/test_random.py</span>
<span class="gi">+++ b/geopandas/tools/tests/test_random.py</span>
<span class="gu">@@ -1,4 +1,67 @@</span>
<span class="w"> </span>import numpy
<span class="gi">+</span>
<span class="w"> </span>import geopandas
<span class="w"> </span>from geopandas.tools._random import uniform
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def multipolygons(nybb_filename):</span>
<span class="gi">+    return geopandas.read_file(nybb_filename).geometry</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def polygons(multipolygons):</span>
<span class="gi">+    return multipolygons.explode(ignore_index=True).geometry</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def multilinestrings(multipolygons):</span>
<span class="gi">+    return multipolygons.boundary</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def linestrings(polygons):</span>
<span class="gi">+    return polygons.boundary</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def points(multipolygons):</span>
<span class="gi">+    return multipolygons.centroid</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.parametrize(&quot;size&quot;, [10, 100])</span>
<span class="gi">+@pytest.mark.parametrize(</span>
<span class="gi">+    &quot;geom_fixture&quot;, [&quot;multipolygons&quot;, &quot;polygons&quot;, &quot;multilinestrings&quot;, &quot;linestrings&quot;]</span>
<span class="gi">+)</span>
<span class="gi">+def test_uniform(geom_fixture, size, request):</span>
<span class="gi">+    geom = request.getfixturevalue(geom_fixture)[0]</span>
<span class="gi">+    sample = uniform(geom, size=size, rng=1)</span>
<span class="gi">+    sample_series = (</span>
<span class="gi">+        geopandas.GeoSeries(sample).explode(index_parts=True).reset_index(drop=True)</span>
<span class="gi">+    )</span>
<span class="gi">+    assert len(sample_series) == size</span>
<span class="gi">+    sample_in_geom = sample_series.buffer(0.00000001).sindex.query(</span>
<span class="gi">+        geom, predicate=&quot;intersects&quot;</span>
<span class="gi">+    )</span>
<span class="gi">+    assert len(sample_in_geom) == size</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_uniform_unsupported(points):</span>
<span class="gi">+    with pytest.warns(UserWarning, match=&quot;Sampling is not supported&quot;):</span>
<span class="gi">+        sample = uniform(points[0], size=10, rng=1)</span>
<span class="gi">+    assert sample.is_empty</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_uniform_generator(polygons):</span>
<span class="gi">+    sample = uniform(polygons[0], size=10, rng=1)</span>
<span class="gi">+    sample2 = uniform(polygons[0], size=10, rng=1)</span>
<span class="gi">+    assert sample.equals(sample2)</span>
<span class="gi">+</span>
<span class="gi">+    generator = numpy.random.default_rng(seed=1)</span>
<span class="gi">+    gen_sample = uniform(polygons[0], size=10, rng=generator)</span>
<span class="gi">+    gen_sample2 = uniform(polygons[0], size=10, rng=generator)</span>
<span class="gi">+</span>
<span class="gi">+    assert sample.equals(gen_sample)</span>
<span class="gi">+    assert not sample.equals(gen_sample2)</span>
<span class="gh">diff --git a/geopandas/tools/tests/test_sjoin.py b/geopandas/tools/tests/test_sjoin.py</span>
<span class="gh">index a4a880cd..0e44f87b 100644</span>
<span class="gd">--- a/geopandas/tools/tests/test_sjoin.py</span>
<span class="gi">+++ b/geopandas/tools/tests/test_sjoin.py</span>
<span class="gu">@@ -1,33 +1,1352 @@</span>
<span class="w"> </span>import math
<span class="w"> </span>from typing import Sequence
<span class="gi">+</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>import pandas as pd
<span class="gi">+</span>
<span class="w"> </span>import shapely
<span class="w"> </span>from shapely.geometry import GeometryCollection, Point, Polygon, box
<span class="gi">+</span>
<span class="w"> </span>import geopandas
<span class="w"> </span>import geopandas._compat as compat
<span class="gd">-from geopandas import GeoDataFrame, GeoSeries, points_from_xy, read_file, sjoin, sjoin_nearest</span>
<span class="gi">+from geopandas import (</span>
<span class="gi">+    GeoDataFrame,</span>
<span class="gi">+    GeoSeries,</span>
<span class="gi">+    points_from_xy,</span>
<span class="gi">+    read_file,</span>
<span class="gi">+    sjoin,</span>
<span class="gi">+    sjoin_nearest,</span>
<span class="gi">+)</span>
<span class="gi">+</span>
<span class="w"> </span>import pytest
<span class="w"> </span>from geopandas.testing import assert_geodataframe_equal, assert_geoseries_equal
<span class="w"> </span>from pandas.testing import assert_frame_equal, assert_index_equal, assert_series_equal


<span class="gi">+@pytest.fixture()</span>
<span class="gi">+def dfs(request):</span>
<span class="gi">+    polys1 = GeoSeries(</span>
<span class="gi">+        [</span>
<span class="gi">+            Polygon([(0, 0), (5, 0), (5, 5), (0, 5)]),</span>
<span class="gi">+            Polygon([(5, 5), (6, 5), (6, 6), (5, 6)]),</span>
<span class="gi">+            Polygon([(6, 0), (9, 0), (9, 3), (6, 3)]),</span>
<span class="gi">+        ]</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    polys2 = GeoSeries(</span>
<span class="gi">+        [</span>
<span class="gi">+            Polygon([(1, 1), (4, 1), (4, 4), (1, 4)]),</span>
<span class="gi">+            Polygon([(4, 4), (7, 4), (7, 7), (4, 7)]),</span>
<span class="gi">+            Polygon([(7, 7), (10, 7), (10, 10), (7, 10)]),</span>
<span class="gi">+        ]</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    df1 = GeoDataFrame({&quot;geometry&quot;: polys1, &quot;df1&quot;: [0, 1, 2]})</span>
<span class="gi">+    df2 = GeoDataFrame({&quot;geometry&quot;: polys2, &quot;df2&quot;: [3, 4, 5]})</span>
<span class="gi">+</span>
<span class="gi">+    if request.param == &quot;string-index&quot;:</span>
<span class="gi">+        df1.index = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]</span>
<span class="gi">+        df2.index = [&quot;d&quot;, &quot;e&quot;, &quot;f&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    if request.param == &quot;named-index&quot;:</span>
<span class="gi">+        df1.index.name = &quot;df1_ix&quot;</span>
<span class="gi">+        df2.index.name = &quot;df2_ix&quot;</span>
<span class="gi">+</span>
<span class="gi">+    if request.param == &quot;multi-index&quot;:</span>
<span class="gi">+        i1 = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]</span>
<span class="gi">+        i2 = [&quot;d&quot;, &quot;e&quot;, &quot;f&quot;]</span>
<span class="gi">+        df1 = df1.set_index([i1, i2])</span>
<span class="gi">+        df2 = df2.set_index([i2, i1])</span>
<span class="gi">+</span>
<span class="gi">+    if request.param == &quot;named-multi-index&quot;:</span>
<span class="gi">+        i1 = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]</span>
<span class="gi">+        i2 = [&quot;d&quot;, &quot;e&quot;, &quot;f&quot;]</span>
<span class="gi">+        df1 = df1.set_index([i1, i2])</span>
<span class="gi">+        df2 = df2.set_index([i2, i1])</span>
<span class="gi">+        df1.index.names = [&quot;df1_ix1&quot;, &quot;df1_ix2&quot;]</span>
<span class="gi">+        df2.index.names = [&quot;df2_ix1&quot;, &quot;df2_ix2&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    # construction expected frames</span>
<span class="gi">+    expected = {}</span>
<span class="gi">+</span>
<span class="gi">+    part1 = df1.copy().reset_index().rename(columns={&quot;index&quot;: &quot;index_left&quot;})</span>
<span class="gi">+    part2 = (</span>
<span class="gi">+        df2.copy()</span>
<span class="gi">+        .iloc[[0, 1, 1, 2]]</span>
<span class="gi">+        .reset_index()</span>
<span class="gi">+        .rename(columns={&quot;index&quot;: &quot;index_right&quot;})</span>
<span class="gi">+    )</span>
<span class="gi">+    part1[&quot;_merge&quot;] = [0, 1, 2]</span>
<span class="gi">+    part2[&quot;_merge&quot;] = [0, 0, 1, 3]</span>
<span class="gi">+    exp = pd.merge(part1, part2, on=&quot;_merge&quot;, how=&quot;outer&quot;)</span>
<span class="gi">+    expected[&quot;intersects&quot;] = exp.drop(&quot;_merge&quot;, axis=1).copy()</span>
<span class="gi">+</span>
<span class="gi">+    part1 = df1.copy().reset_index().rename(columns={&quot;index&quot;: &quot;index_left&quot;})</span>
<span class="gi">+    part2 = df2.copy().reset_index().rename(columns={&quot;index&quot;: &quot;index_right&quot;})</span>
<span class="gi">+    part1[&quot;_merge&quot;] = [0, 1, 2]</span>
<span class="gi">+    part2[&quot;_merge&quot;] = [0, 3, 3]</span>
<span class="gi">+    exp = pd.merge(part1, part2, on=&quot;_merge&quot;, how=&quot;outer&quot;)</span>
<span class="gi">+    expected[&quot;contains&quot;] = exp.drop(&quot;_merge&quot;, axis=1).copy()</span>
<span class="gi">+</span>
<span class="gi">+    part1[&quot;_merge&quot;] = [0, 1, 2]</span>
<span class="gi">+    part2[&quot;_merge&quot;] = [3, 1, 3]</span>
<span class="gi">+    exp = pd.merge(part1, part2, on=&quot;_merge&quot;, how=&quot;outer&quot;)</span>
<span class="gi">+    expected[&quot;within&quot;] = exp.drop(&quot;_merge&quot;, axis=1).copy()</span>
<span class="gi">+</span>
<span class="gi">+    return [request.param, df1, df2, expected]</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture()</span>
<span class="gi">+def dfs_shared_attribute():</span>
<span class="gi">+    geo_left = [</span>
<span class="gi">+        Point(0, 0),</span>
<span class="gi">+        Point(1, 1),</span>
<span class="gi">+        Point(2, 2),</span>
<span class="gi">+        Point(3, 3),</span>
<span class="gi">+        Point(4, 4),</span>
<span class="gi">+        Point(5, 5),</span>
<span class="gi">+        Point(6, 6),</span>
<span class="gi">+        Point(7, 7),</span>
<span class="gi">+    ]</span>
<span class="gi">+    geo_right = [</span>
<span class="gi">+        Point(0, 0),</span>
<span class="gi">+        Point(1, 1),</span>
<span class="gi">+        Point(2, 2),</span>
<span class="gi">+        Point(3, 3),</span>
<span class="gi">+        Point(4, 4),</span>
<span class="gi">+        Point(5, 5),</span>
<span class="gi">+        Point(6, 6),</span>
<span class="gi">+        Point(7, 7),</span>
<span class="gi">+    ]</span>
<span class="gi">+    attr_tracker = [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;, &quot;G&quot;, &quot;H&quot;]</span>
<span class="gi">+</span>
<span class="gi">+    left_gdf = geopandas.GeoDataFrame(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;geometry&quot;: geo_left,</span>
<span class="gi">+            &quot;attr_tracker&quot;: attr_tracker,</span>
<span class="gi">+            &quot;duplicate_column&quot;: [0, 1, 2, 3, 4, 5, 6, 7],</span>
<span class="gi">+            &quot;attr1&quot;: [True, True, True, True, True, True, True, True],</span>
<span class="gi">+            &quot;attr2&quot;: [True, True, True, True, True, True, True, True],</span>
<span class="gi">+        }</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    right_gdf = geopandas.GeoDataFrame(</span>
<span class="gi">+        {</span>
<span class="gi">+            &quot;geometry&quot;: geo_right,</span>
<span class="gi">+            &quot;duplicate_column&quot;: [0, 1, 2, 3, 4, 5, 6, 7],</span>
<span class="gi">+            &quot;attr1&quot;: [True, True, False, False, True, True, False, False],</span>
<span class="gi">+            &quot;attr2&quot;: [True, True, False, False, False, False, False, False],</span>
<span class="gi">+        }</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="gi">+    return left_gdf, right_gdf</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="w"> </span>class TestSpatialJoin:
<span class="gd">-    pass</span>
<span class="gi">+    @pytest.mark.parametrize(</span>
<span class="gi">+        &quot;how, lsuffix, rsuffix, expected_cols&quot;,</span>
<span class="gi">+        [</span>
<span class="gi">+            (&quot;left&quot;, &quot;left&quot;, &quot;right&quot;, {&quot;col_left&quot;, &quot;col_right&quot;, &quot;index_right&quot;}),</span>
<span class="gi">+            (&quot;inner&quot;, &quot;left&quot;, &quot;right&quot;, {&quot;col_left&quot;, &quot;col_right&quot;, &quot;index_right&quot;}),</span>
<span class="gi">+            (&quot;right&quot;, &quot;left&quot;, &quot;right&quot;, {&quot;col_left&quot;, &quot;col_right&quot;, &quot;index_left&quot;}),</span>
<span class="gi">+            (&quot;left&quot;, &quot;lft&quot;, &quot;rgt&quot;, {&quot;col_lft&quot;, &quot;col_rgt&quot;, &quot;index_rgt&quot;}),</span>
<span class="gi">+            (&quot;inner&quot;, &quot;lft&quot;, &quot;rgt&quot;, {&quot;col_lft&quot;, &quot;col_rgt&quot;, &quot;index_rgt&quot;}),</span>
<span class="gi">+            (&quot;right&quot;, &quot;lft&quot;, &quot;rgt&quot;, {&quot;col_lft&quot;, &quot;col_rgt&quot;, &quot;index_lft&quot;}),</span>
<span class="gi">+        ],</span>
<span class="gi">+    )</span>
<span class="gi">+    def test_suffixes(self, how: str, lsuffix: str, rsuffix: str, expected_cols):</span>
<span class="gi">+        left = GeoDataFrame({&quot;col&quot;: [1], &quot;geometry&quot;: [Point(0, 0)]})</span>
<span class="gi">+        right = GeoDataFrame({&quot;col&quot;: [1], &quot;geometry&quot;: [Point(0, 0)]})</span>
<span class="gi">+        joined = sjoin(left, right, how=how, lsuffix=lsuffix, rsuffix=rsuffix)</span>
<span class="gi">+        assert set(joined.columns) == expected_cols | {&quot;geometry&quot;}</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.skipif(not compat.HAS_PYPROJ, reason=&quot;pyproj not available&quot;)</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;dfs&quot;, [&quot;default-index&quot;, &quot;string-index&quot;], indirect=True)</span>
<span class="gi">+    def test_crs_mismatch(self, dfs):</span>
<span class="gi">+        index, df1, df2, expected = dfs</span>
<span class="gi">+        df1.crs = &quot;epsg:4326&quot;</span>
<span class="gi">+        with pytest.warns(UserWarning, match=&quot;CRS mismatch between the CRS&quot;):</span>
<span class="gi">+            sjoin(df1, df2)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;dfs&quot;, [&quot;default-index&quot;], indirect=True)</span>
<span class="gi">+    def test_unknown_kwargs(self, dfs):</span>
<span class="gi">+        _, df1, df2, _ = dfs</span>
<span class="gi">+        with pytest.raises(</span>
<span class="gi">+            TypeError,</span>
<span class="gi">+            match=r&quot;sjoin\(\) got an unexpected keyword argument &#39;extra_param&#39;&quot;,</span>
<span class="gi">+        ):</span>
<span class="gi">+            sjoin(df1, df2, extra_param=&quot;test&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(</span>
<span class="gi">+        &quot;dfs&quot;,</span>
<span class="gi">+        [</span>
<span class="gi">+            &quot;default-index&quot;,</span>
<span class="gi">+            &quot;string-index&quot;,</span>
<span class="gi">+            &quot;named-index&quot;,</span>
<span class="gi">+            &quot;multi-index&quot;,</span>
<span class="gi">+            &quot;named-multi-index&quot;,</span>
<span class="gi">+        ],</span>
<span class="gi">+        indirect=True,</span>
<span class="gi">+    )</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;predicate&quot;, [&quot;intersects&quot;, &quot;contains&quot;, &quot;within&quot;])</span>
<span class="gi">+    def test_inner(self, predicate, dfs):</span>
<span class="gi">+        index, df1, df2, expected = dfs</span>
<span class="gi">+</span>
<span class="gi">+        res = sjoin(df1, df2, how=&quot;inner&quot;, predicate=predicate)</span>
<span class="gi">+        exp = expected[predicate].dropna().copy()</span>
<span class="gi">+        exp = exp.drop(&quot;geometry_y&quot;, axis=1).rename(columns={&quot;geometry_x&quot;: &quot;geometry&quot;})</span>
<span class="gi">+        exp[[&quot;df1&quot;, &quot;df2&quot;]] = exp[[&quot;df1&quot;, &quot;df2&quot;]].astype(&quot;int64&quot;)</span>
<span class="gi">+        if index == &quot;default-index&quot;:</span>
<span class="gi">+            exp[[&quot;index_left&quot;, &quot;index_right&quot;]] = exp[</span>
<span class="gi">+                [&quot;index_left&quot;, &quot;index_right&quot;]</span>
<span class="gi">+            ].astype(&quot;int64&quot;)</span>
<span class="gi">+        if index == &quot;named-index&quot;:</span>
<span class="gi">+            exp[[&quot;df1_ix&quot;, &quot;df2_ix&quot;]] = exp[[&quot;df1_ix&quot;, &quot;df2_ix&quot;]].astype(&quot;int64&quot;)</span>
<span class="gi">+            exp = exp.set_index(&quot;df1_ix&quot;)</span>
<span class="gi">+        if index in [&quot;default-index&quot;, &quot;string-index&quot;]:</span>
<span class="gi">+            exp = exp.set_index(&quot;index_left&quot;)</span>
<span class="gi">+            exp.index.name = None</span>
<span class="gi">+        if index == &quot;multi-index&quot;:</span>
<span class="gi">+            exp = exp.set_index([&quot;level_0_x&quot;, &quot;level_1_x&quot;]).rename(</span>
<span class="gi">+                columns={&quot;level_0_y&quot;: &quot;index_right0&quot;, &quot;level_1_y&quot;: &quot;index_right1&quot;}</span>
<span class="gi">+            )</span>
<span class="gi">+            exp.index.names = df1.index.names</span>
<span class="gi">+        if index == &quot;named-multi-index&quot;:</span>
<span class="gi">+            exp = exp.set_index([&quot;df1_ix1&quot;, &quot;df1_ix2&quot;])</span>
<span class="gi">+        assert_frame_equal(res, exp)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(</span>
<span class="gi">+        &quot;dfs&quot;,</span>
<span class="gi">+        [</span>
<span class="gi">+            &quot;default-index&quot;,</span>
<span class="gi">+            &quot;string-index&quot;,</span>
<span class="gi">+            &quot;named-index&quot;,</span>
<span class="gi">+            &quot;multi-index&quot;,</span>
<span class="gi">+            &quot;named-multi-index&quot;,</span>
<span class="gi">+        ],</span>
<span class="gi">+        indirect=True,</span>
<span class="gi">+    )</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;predicate&quot;, [&quot;intersects&quot;, &quot;contains&quot;, &quot;within&quot;])</span>
<span class="gi">+    def test_left(self, predicate, dfs):</span>
<span class="gi">+        index, df1, df2, expected = dfs</span>
<span class="gi">+</span>
<span class="gi">+        res = sjoin(df1, df2, how=&quot;left&quot;, predicate=predicate)</span>
<span class="gi">+</span>
<span class="gi">+        if index in [&quot;default-index&quot;, &quot;string-index&quot;]:</span>
<span class="gi">+            exp = expected[predicate].dropna(subset=[&quot;index_left&quot;]).copy()</span>
<span class="gi">+        elif index == &quot;named-index&quot;:</span>
<span class="gi">+            exp = expected[predicate].dropna(subset=[&quot;df1_ix&quot;]).copy()</span>
<span class="gi">+        elif index == &quot;multi-index&quot;:</span>
<span class="gi">+            exp = expected[predicate].dropna(subset=[&quot;level_0_x&quot;]).copy()</span>
<span class="gi">+        elif index == &quot;named-multi-index&quot;:</span>
<span class="gi">+            exp = expected[predicate].dropna(subset=[&quot;df1_ix1&quot;]).copy()</span>
<span class="gi">+        exp = exp.drop(&quot;geometry_y&quot;, axis=1).rename(columns={&quot;geometry_x&quot;: &quot;geometry&quot;})</span>
<span class="gi">+        exp[&quot;df1&quot;] = exp[&quot;df1&quot;].astype(&quot;int64&quot;)</span>
<span class="gi">+        if index == &quot;default-index&quot;:</span>
<span class="gi">+            exp[&quot;index_left&quot;] = exp[&quot;index_left&quot;].astype(&quot;int64&quot;)</span>
<span class="gi">+            # TODO: in result the dtype is object</span>
<span class="gi">+            res[&quot;index_right&quot;] = res[&quot;index_right&quot;].astype(float)</span>
<span class="gi">+        elif index == &quot;named-index&quot;:</span>
<span class="gi">+            exp[[&quot;df1_ix&quot;]] = exp[[&quot;df1_ix&quot;]].astype(&quot;int64&quot;)</span>
<span class="gi">+            exp = exp.set_index(&quot;df1_ix&quot;)</span>
<span class="gi">+        if index in [&quot;default-index&quot;, &quot;string-index&quot;]:</span>
<span class="gi">+            exp = exp.set_index(&quot;index_left&quot;)</span>
<span class="gi">+            exp.index.name = None</span>
<span class="gi">+        if index == &quot;multi-index&quot;:</span>
<span class="gi">+            exp = exp.set_index([&quot;level_0_x&quot;, &quot;level_1_x&quot;]).rename(</span>
<span class="gi">+                columns={&quot;level_0_y&quot;: &quot;index_right0&quot;, &quot;level_1_y&quot;: &quot;index_right1&quot;}</span>
<span class="gi">+            )</span>
<span class="gi">+            exp.index.names = df1.index.names</span>
<span class="gi">+        if index == &quot;named-multi-index&quot;:</span>
<span class="gi">+            exp = exp.set_index([&quot;df1_ix1&quot;, &quot;df1_ix2&quot;])</span>
<span class="gi">+</span>
<span class="gi">+        assert_frame_equal(res, exp)</span>
<span class="gi">+</span>
<span class="gi">+    def test_empty_join(self):</span>
<span class="gi">+        # Check joins resulting in empty gdfs.</span>
<span class="gi">+        polygons = geopandas.GeoDataFrame(</span>
<span class="gi">+            {</span>
<span class="gi">+                &quot;col2&quot;: [1, 2],</span>
<span class="gi">+                &quot;geometry&quot;: [</span>
<span class="gi">+                    Polygon([(0, 0), (1, 0), (1, 1), (0, 1)]),</span>
<span class="gi">+                    Polygon([(1, 0), (2, 0), (2, 1), (1, 1)]),</span>
<span class="gi">+                ],</span>
<span class="gi">+            }</span>
<span class="gi">+        )</span>
<span class="gi">+        not_in = geopandas.GeoDataFrame({&quot;col1&quot;: [1], &quot;geometry&quot;: [Point(-0.5, 0.5)]})</span>
<span class="gi">+        empty = sjoin(not_in, polygons, how=&quot;left&quot;, predicate=&quot;intersects&quot;)</span>
<span class="gi">+        assert empty.index_right.isnull().all()</span>
<span class="gi">+        empty = sjoin(not_in, polygons, how=&quot;right&quot;, predicate=&quot;intersects&quot;)</span>
<span class="gi">+        assert empty.index_left.isnull().all()</span>
<span class="gi">+        empty = sjoin(not_in, polygons, how=&quot;inner&quot;, predicate=&quot;intersects&quot;)</span>
<span class="gi">+        assert empty.empty</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(</span>
<span class="gi">+        &quot;predicate&quot;,</span>
<span class="gi">+        [</span>
<span class="gi">+            &quot;contains&quot;,</span>
<span class="gi">+            &quot;contains_properly&quot;,</span>
<span class="gi">+            &quot;covered_by&quot;,</span>
<span class="gi">+            &quot;covers&quot;,</span>
<span class="gi">+            &quot;crosses&quot;,</span>
<span class="gi">+            &quot;intersects&quot;,</span>
<span class="gi">+            &quot;touches&quot;,</span>
<span class="gi">+            &quot;within&quot;,</span>
<span class="gi">+        ],</span>
<span class="gi">+    )</span>
<span class="gi">+    @pytest.mark.parametrize(</span>
<span class="gi">+        &quot;empty&quot;,</span>
<span class="gi">+        [</span>
<span class="gi">+            GeoDataFrame(geometry=[GeometryCollection(), GeometryCollection()]),</span>
<span class="gi">+            GeoDataFrame(geometry=GeoSeries()),</span>
<span class="gi">+        ],</span>
<span class="gi">+    )</span>
<span class="gi">+    def test_join_with_empty(self, predicate, empty):</span>
<span class="gi">+        # Check joins with empty geometry columns/dataframes.</span>
<span class="gi">+        polygons = geopandas.GeoDataFrame(</span>
<span class="gi">+            {</span>
<span class="gi">+                &quot;col2&quot;: [1, 2],</span>
<span class="gi">+                &quot;geometry&quot;: [</span>
<span class="gi">+                    Polygon([(0, 0), (1, 0), (1, 1), (0, 1)]),</span>
<span class="gi">+                    Polygon([(1, 0), (2, 0), (2, 1), (1, 1)]),</span>
<span class="gi">+                ],</span>
<span class="gi">+            }</span>
<span class="gi">+        )</span>
<span class="gi">+        result = sjoin(empty, polygons, how=&quot;left&quot;, predicate=predicate)</span>
<span class="gi">+        assert result.index_right.isnull().all()</span>
<span class="gi">+        result = sjoin(empty, polygons, how=&quot;right&quot;, predicate=predicate)</span>
<span class="gi">+        assert result.index_left.isnull().all()</span>
<span class="gi">+        result = sjoin(empty, polygons, how=&quot;inner&quot;, predicate=predicate)</span>
<span class="gi">+        assert result.empty</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;dfs&quot;, [&quot;default-index&quot;, &quot;string-index&quot;], indirect=True)</span>
<span class="gi">+    def test_sjoin_invalid_args(self, dfs):</span>
<span class="gi">+        index, df1, df2, expected = dfs</span>
<span class="gi">+</span>
<span class="gi">+        with pytest.raises(ValueError, match=&quot;&#39;left_df&#39; should be GeoDataFrame&quot;):</span>
<span class="gi">+            sjoin(df1.geometry, df2)</span>
<span class="gi">+</span>
<span class="gi">+        with pytest.raises(ValueError, match=&quot;&#39;right_df&#39; should be GeoDataFrame&quot;):</span>
<span class="gi">+            sjoin(df1, df2.geometry)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(</span>
<span class="gi">+        &quot;dfs&quot;,</span>
<span class="gi">+        [</span>
<span class="gi">+            &quot;default-index&quot;,</span>
<span class="gi">+            &quot;string-index&quot;,</span>
<span class="gi">+            &quot;named-index&quot;,</span>
<span class="gi">+            &quot;multi-index&quot;,</span>
<span class="gi">+            &quot;named-multi-index&quot;,</span>
<span class="gi">+        ],</span>
<span class="gi">+        indirect=True,</span>
<span class="gi">+    )</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;predicate&quot;, [&quot;intersects&quot;, &quot;contains&quot;, &quot;within&quot;])</span>
<span class="gi">+    def test_right(self, predicate, dfs):</span>
<span class="gi">+        index, df1, df2, expected = dfs</span>
<span class="gi">+</span>
<span class="gi">+        res = sjoin(df1, df2, how=&quot;right&quot;, predicate=predicate)</span>
<span class="gi">+</span>
<span class="gi">+        if index in [&quot;default-index&quot;, &quot;string-index&quot;]:</span>
<span class="gi">+            exp = expected[predicate].dropna(subset=[&quot;index_right&quot;]).copy()</span>
<span class="gi">+        elif index == &quot;named-index&quot;:</span>
<span class="gi">+            exp = expected[predicate].dropna(subset=[&quot;df2_ix&quot;]).copy()</span>
<span class="gi">+        elif index == &quot;multi-index&quot;:</span>
<span class="gi">+            exp = expected[predicate].dropna(subset=[&quot;level_0_y&quot;]).copy()</span>
<span class="gi">+        elif index == &quot;named-multi-index&quot;:</span>
<span class="gi">+            exp = expected[predicate].dropna(subset=[&quot;df2_ix1&quot;]).copy()</span>
<span class="gi">+        exp = exp.drop(&quot;geometry_x&quot;, axis=1).rename(columns={&quot;geometry_y&quot;: &quot;geometry&quot;})</span>
<span class="gi">+        exp[&quot;df2&quot;] = exp[&quot;df2&quot;].astype(&quot;int64&quot;)</span>
<span class="gi">+        if index == &quot;default-index&quot;:</span>
<span class="gi">+            exp[&quot;index_right&quot;] = exp[&quot;index_right&quot;].astype(&quot;int64&quot;)</span>
<span class="gi">+            res[&quot;index_left&quot;] = res[&quot;index_left&quot;].astype(float)</span>
<span class="gi">+        elif index == &quot;named-index&quot;:</span>
<span class="gi">+            exp[[&quot;df2_ix&quot;]] = exp[[&quot;df2_ix&quot;]].astype(&quot;int64&quot;)</span>
<span class="gi">+            exp = exp.set_index(&quot;df2_ix&quot;)</span>
<span class="gi">+        if index in [&quot;default-index&quot;, &quot;string-index&quot;]:</span>
<span class="gi">+            exp = exp.set_index(&quot;index_right&quot;)</span>
<span class="gi">+            exp = exp.reindex(columns=res.columns)</span>
<span class="gi">+            exp.index.name = None</span>
<span class="gi">+        if index == &quot;multi-index&quot;:</span>
<span class="gi">+            exp = exp.set_index([&quot;level_0_y&quot;, &quot;level_1_y&quot;]).rename(</span>
<span class="gi">+                columns={&quot;level_0_x&quot;: &quot;index_left0&quot;, &quot;level_1_x&quot;: &quot;index_left1&quot;}</span>
<span class="gi">+            )</span>
<span class="gi">+            exp.index.names = df2.index.names</span>
<span class="gi">+        if index == &quot;named-multi-index&quot;:</span>
<span class="gi">+            exp = exp.set_index([&quot;df2_ix1&quot;, &quot;df2_ix2&quot;])</span>
<span class="gi">+</span>
<span class="gi">+        if predicate == &quot;within&quot;:</span>
<span class="gi">+            exp = exp.sort_index()</span>
<span class="gi">+</span>
<span class="gi">+        assert_frame_equal(res, exp, check_index_type=False)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.skipif(not compat.GEOS_GE_310, reason=&quot;`dwithin` requires GEOS 3.10&quot;)</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;how&quot;, [&quot;inner&quot;])</span>
<span class="gi">+    @pytest.mark.parametrize(</span>
<span class="gi">+        &quot;geo_left, geo_right, expected_left, expected_right, distance&quot;,</span>
<span class="gi">+        [</span>
<span class="gi">+            (</span>
<span class="gi">+                # Distance is number, 2x1</span>
<span class="gi">+                [Point(0, 0), Point(1, 1)],</span>
<span class="gi">+                [Point(1, 1)],</span>
<span class="gi">+                [0, 1],</span>
<span class="gi">+                [0, 0],</span>
<span class="gi">+                math.sqrt(2),</span>
<span class="gi">+            ),</span>
<span class="gi">+            # Distance is number, 2x2</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(1, 1)],</span>
<span class="gi">+                [Point(0, 0), Point(1, 1)],</span>
<span class="gi">+                [0, 1, 0, 1],</span>
<span class="gi">+                [0, 0, 1, 1],</span>
<span class="gi">+                math.sqrt(2),</span>
<span class="gi">+            ),</span>
<span class="gi">+            # Distance is array, matches len(left)</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(0, 0), Point(-1, -1)],</span>
<span class="gi">+                [Point(1, 1)],</span>
<span class="gi">+                [1, 2],</span>
<span class="gi">+                [0, 0],</span>
<span class="gi">+                [0, math.sqrt(2), math.sqrt(8)],</span>
<span class="gi">+            ),</span>
<span class="gi">+            # Distance is np.array, matches len(left),</span>
<span class="gi">+            # inner join sorts the right GeoDataFrame</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(0, 0), Point(-1, -1)],</span>
<span class="gi">+                [Point(1, 1), Point(0.5, 0.5)],</span>
<span class="gi">+                [1, 2, 1, 2],</span>
<span class="gi">+                [1, 1, 0, 0],</span>
<span class="gi">+                np.array([0, math.sqrt(2), math.sqrt(8)]),</span>
<span class="gi">+            ),</span>
<span class="gi">+        ],</span>
<span class="gi">+    )</span>
<span class="gi">+    def test_sjoin_dwithin(</span>
<span class="gi">+        self,</span>
<span class="gi">+        geo_left,</span>
<span class="gi">+        geo_right,</span>
<span class="gi">+        expected_left: Sequence[int],</span>
<span class="gi">+        expected_right: Sequence[int],</span>
<span class="gi">+        distance,</span>
<span class="gi">+        how,</span>
<span class="gi">+    ):</span>
<span class="gi">+        left = geopandas.GeoDataFrame({&quot;geometry&quot;: geo_left})</span>
<span class="gi">+        right = geopandas.GeoDataFrame({&quot;geometry&quot;: geo_right})</span>
<span class="gi">+        expected_gdf = left.iloc[expected_left].copy()</span>
<span class="gi">+        expected_gdf[&quot;index_right&quot;] = expected_right</span>
<span class="gi">+        joined = sjoin(left, right, how=how, predicate=&quot;dwithin&quot;, distance=distance)</span>
<span class="gi">+        assert_frame_equal(expected_gdf.sort_index(), joined.sort_index())</span>
<span class="gi">+</span>
<span class="gi">+    # GH3239</span>
<span class="gi">+    @pytest.mark.parametrize(</span>
<span class="gi">+        &quot;predicate&quot;,</span>
<span class="gi">+        [</span>
<span class="gi">+            &quot;contains&quot;,</span>
<span class="gi">+            &quot;contains_properly&quot;,</span>
<span class="gi">+            &quot;covered_by&quot;,</span>
<span class="gi">+            &quot;covers&quot;,</span>
<span class="gi">+            &quot;crosses&quot;,</span>
<span class="gi">+            &quot;intersects&quot;,</span>
<span class="gi">+            &quot;touches&quot;,</span>
<span class="gi">+            &quot;within&quot;,</span>
<span class="gi">+        ],</span>
<span class="gi">+    )</span>
<span class="gi">+    def test_sjoin_left_order(self, predicate):</span>
<span class="gi">+        # a set of points in random order -&gt; that order should be preserved</span>
<span class="gi">+        # with a left join</span>
<span class="gi">+        pts = GeoDataFrame(</span>
<span class="gi">+            geometry=points_from_xy([0.1, 0.4, 0.3, 0.7], [0.8, 0.6, 0.9, 0.1])</span>
<span class="gi">+        )</span>
<span class="gi">+        polys = GeoDataFrame(</span>
<span class="gi">+            {&quot;id&quot;: [1, 2, 3, 4]},</span>
<span class="gi">+            geometry=[</span>
<span class="gi">+                box(0, 0, 0.5, 0.5),</span>
<span class="gi">+                box(0, 0.5, 0.5, 1),</span>
<span class="gi">+                box(0.5, 0, 1, 0.5),</span>
<span class="gi">+                box(0.5, 0.5, 1, 1),</span>
<span class="gi">+            ],</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        joined = sjoin(pts, polys, predicate=predicate, how=&quot;left&quot;)</span>
<span class="gi">+        assert_index_equal(joined.index, pts.index)</span>
<span class="gi">+</span>
<span class="gi">+    def test_sjoin_shared_attribute(self, naturalearth_lowres, naturalearth_cities):</span>
<span class="gi">+        countries = read_file(naturalearth_lowres)</span>
<span class="gi">+        cities = read_file(naturalearth_cities)</span>
<span class="gi">+        countries = countries[[&quot;geometry&quot;, &quot;name&quot;]].rename(columns={&quot;name&quot;: &quot;country&quot;})</span>
<span class="gi">+</span>
<span class="gi">+        # Add first letter of country/city as an attribute column to be compared</span>
<span class="gi">+        countries[&quot;firstLetter&quot;] = countries[&quot;country&quot;].astype(str).str[0]</span>
<span class="gi">+        cities[&quot;firstLetter&quot;] = cities[&quot;name&quot;].astype(str).str[0]</span>
<span class="gi">+</span>
<span class="gi">+        result = sjoin(cities, countries, on_attribute=&quot;firstLetter&quot;)</span>
<span class="gi">+        assert (</span>
<span class="gi">+            result[&quot;country&quot;].astype(str).str[0] == result[&quot;name&quot;].astype(str).str[0]</span>
<span class="gi">+        ).all()</span>
<span class="gi">+        assert result.shape == (23, 5)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(</span>
<span class="gi">+        &quot;attr1_key_change_dict, attr2_key_change_dict&quot;,</span>
<span class="gi">+        [</span>
<span class="gi">+            pytest.param(</span>
<span class="gi">+                {True: &quot;merge&quot;, False: &quot;no_merge&quot;},</span>
<span class="gi">+                {True: &quot;merge&quot;, False: &quot;no_merge&quot;},</span>
<span class="gi">+                id=&quot;merge on string attributes&quot;,</span>
<span class="gi">+            ),</span>
<span class="gi">+            pytest.param(</span>
<span class="gi">+                {True: 2, False: 1},</span>
<span class="gi">+                {True: 2, False: 1},</span>
<span class="gi">+                id=&quot;merge on integer attributes&quot;,</span>
<span class="gi">+            ),</span>
<span class="gi">+            pytest.param(</span>
<span class="gi">+                {True: True, False: False},</span>
<span class="gi">+                {True: True, False: False},</span>
<span class="gi">+                id=&quot;merge on boolean attributes&quot;,</span>
<span class="gi">+            ),</span>
<span class="gi">+            pytest.param(</span>
<span class="gi">+                {True: True, False: False},</span>
<span class="gi">+                {True: &quot;merge&quot;, False: &quot;no_merge&quot;},</span>
<span class="gi">+                id=&quot;merge on mixed attributes&quot;,</span>
<span class="gi">+            ),</span>
<span class="gi">+        ],</span>
<span class="gi">+    )</span>
<span class="gi">+    def test_sjoin_multiple_attributes_datatypes(</span>
<span class="gi">+        self, dfs_shared_attribute, attr1_key_change_dict, attr2_key_change_dict</span>
<span class="gi">+    ):</span>
<span class="gi">+        left_gdf, right_gdf = dfs_shared_attribute</span>
<span class="gi">+        left_gdf[&quot;attr1&quot;] = left_gdf[&quot;attr1&quot;].map(attr1_key_change_dict)</span>
<span class="gi">+        left_gdf[&quot;attr2&quot;] = left_gdf[&quot;attr2&quot;].map(attr2_key_change_dict)</span>
<span class="gi">+        right_gdf[&quot;attr1&quot;] = right_gdf[&quot;attr1&quot;].map(attr1_key_change_dict)</span>
<span class="gi">+        right_gdf[&quot;attr2&quot;] = right_gdf[&quot;attr2&quot;].map(attr2_key_change_dict)</span>
<span class="gi">+</span>
<span class="gi">+        joined = sjoin(left_gdf, right_gdf, on_attribute=(&quot;attr1&quot;, &quot;attr2&quot;))</span>
<span class="gi">+        assert ([&quot;A&quot;, &quot;B&quot;] == joined[&quot;attr_tracker&quot;].values).all()</span>
<span class="gi">+</span>
<span class="gi">+    def test_sjoin_multiple_attributes_check_header(self, dfs_shared_attribute):</span>
<span class="gi">+        left_gdf, right_gdf = dfs_shared_attribute</span>
<span class="gi">+        joined = sjoin(left_gdf, right_gdf, on_attribute=[&quot;attr1&quot;])</span>
<span class="gi">+</span>
<span class="gi">+        assert ([&quot;A&quot;, &quot;B&quot;, &quot;E&quot;, &quot;F&quot;] == joined[&quot;attr_tracker&quot;].values).all()</span>
<span class="gi">+        assert {&quot;attr2_left&quot;, &quot;attr2_right&quot;, &quot;attr1&quot;}.issubset(joined.columns)</span>
<span class="gi">+        assert &quot;attr1_left&quot; not in joined</span>
<span class="gi">+</span>
<span class="gi">+    def test_sjoin_error_column_does_not_exist(self, dfs_shared_attribute):</span>
<span class="gi">+        left_gdf, right_gdf = dfs_shared_attribute</span>
<span class="gi">+        right_gdf_dropped_attr = right_gdf.drop(&quot;attr1&quot;, axis=1)</span>
<span class="gi">+        left_gdf_dropped_attr = left_gdf.drop(&quot;attr1&quot;, axis=1)</span>
<span class="gi">+</span>
<span class="gi">+        with pytest.raises(</span>
<span class="gi">+            ValueError,</span>
<span class="gi">+            match=&quot;Expected column attr1 is missing from the right dataframe.&quot;,</span>
<span class="gi">+        ):</span>
<span class="gi">+            sjoin(left_gdf, right_gdf_dropped_attr, on_attribute=&quot;attr1&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        with pytest.raises(</span>
<span class="gi">+            ValueError,</span>
<span class="gi">+            match=&quot;Expected column attr1 is missing from the left dataframe.&quot;,</span>
<span class="gi">+        ):</span>
<span class="gi">+            sjoin(left_gdf_dropped_attr, right_gdf, on_attribute=&quot;attr1&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        with pytest.raises(</span>
<span class="gi">+            ValueError,</span>
<span class="gi">+            match=&quot;Expected column attr1 is missing from both of the dataframes.&quot;,</span>
<span class="gi">+        ):</span>
<span class="gi">+            sjoin(left_gdf_dropped_attr, right_gdf_dropped_attr, on_attribute=&quot;attr1&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def test_sjoin_error_use_geometry_column(self, dfs_shared_attribute):</span>
<span class="gi">+        left_gdf, right_gdf = dfs_shared_attribute</span>
<span class="gi">+        with pytest.raises(</span>
<span class="gi">+            ValueError,</span>
<span class="gi">+            match=&quot;Active geometry column cannot be used as an input for &quot;</span>
<span class="gi">+            &quot;on_attribute parameter.&quot;,</span>
<span class="gi">+        ):</span>
<span class="gi">+            sjoin(left_gdf, right_gdf, on_attribute=&quot;geometry&quot;)</span>
<span class="gi">+        with pytest.raises(</span>
<span class="gi">+            ValueError,</span>
<span class="gi">+            match=&quot;Active geometry column cannot be used as an input for &quot;</span>
<span class="gi">+            &quot;on_attribute parameter.&quot;,</span>
<span class="gi">+        ):</span>
<span class="gi">+            sjoin(left_gdf, right_gdf, on_attribute=[&quot;attr1&quot;, &quot;geometry&quot;])</span>


<span class="w"> </span>class TestIndexNames:
<span class="gd">-    pass</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;how&quot;, [&quot;inner&quot;, &quot;left&quot;, &quot;right&quot;])</span>
<span class="gi">+    def test_preserve_index_names(self, how):</span>
<span class="gi">+        # preserve names of both left and right index</span>
<span class="gi">+        geoms = [Point(1, 1), Point(2, 2)]</span>
<span class="gi">+        df1 = GeoDataFrame({&quot;geometry&quot;: geoms}, index=pd.Index([1, 2], name=&quot;myidx1&quot;))</span>
<span class="gi">+        df2 = GeoDataFrame(</span>
<span class="gi">+            {&quot;geometry&quot;: geoms}, index=pd.Index([&quot;a&quot;, &quot;b&quot;], name=&quot;myidx2&quot;)</span>
<span class="gi">+        )</span>
<span class="gi">+        result = sjoin(df1, df2, how=how)</span>
<span class="gi">+        if how in (&quot;inner&quot;, &quot;left&quot;):</span>
<span class="gi">+            expected = GeoDataFrame(</span>
<span class="gi">+                {&quot;myidx1&quot;: [1, 2], &quot;geometry&quot;: geoms, &quot;myidx2&quot;: [&quot;a&quot;, &quot;b&quot;]}</span>
<span class="gi">+            ).set_index(&quot;myidx1&quot;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            # right join</span>
<span class="gi">+            expected = GeoDataFrame(</span>
<span class="gi">+                {&quot;myidx2&quot;: [&quot;a&quot;, &quot;b&quot;], &quot;myidx1&quot;: [1, 2], &quot;geometry&quot;: geoms},</span>
<span class="gi">+            ).set_index(&quot;myidx2&quot;)</span>
<span class="gi">+        assert_geodataframe_equal(result, expected)</span>
<span class="gi">+</span>
<span class="gi">+        # but also add suffixes if both left and right have the same index</span>
<span class="gi">+        df1.index.name = &quot;myidx&quot;</span>
<span class="gi">+        df2.index.name = &quot;myidx&quot;</span>
<span class="gi">+        result = sjoin(df1, df2, how=how)</span>
<span class="gi">+        if how in (&quot;inner&quot;, &quot;left&quot;):</span>
<span class="gi">+            expected = GeoDataFrame(</span>
<span class="gi">+                {&quot;myidx_left&quot;: [1, 2], &quot;geometry&quot;: geoms, &quot;myidx_right&quot;: [&quot;a&quot;, &quot;b&quot;]}</span>
<span class="gi">+            ).set_index(&quot;myidx_left&quot;)</span>
<span class="gi">+        else:</span>
<span class="gi">+            # right join</span>
<span class="gi">+            expected = GeoDataFrame(</span>
<span class="gi">+                {&quot;myidx_right&quot;: [&quot;a&quot;, &quot;b&quot;], &quot;myidx_left&quot;: [1, 2], &quot;geometry&quot;: geoms},</span>
<span class="gi">+            ).set_index(&quot;myidx_right&quot;)</span>
<span class="gi">+        assert_geodataframe_equal(result, expected)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;how&quot;, [&quot;inner&quot;, &quot;left&quot;, &quot;right&quot;])</span>
<span class="gi">+    def test_preserve_index_names_multiindex(self, how):</span>
<span class="gi">+        # preserve names of both left and right index</span>
<span class="gi">+        geoms = [Point(1, 1), Point(2, 2)]</span>
<span class="gi">+        df1 = GeoDataFrame(</span>
<span class="gi">+            {&quot;geometry&quot;: geoms},</span>
<span class="gi">+            index=pd.MultiIndex.from_tuples(</span>
<span class="gi">+                [(&quot;a&quot;, 1), (&quot;b&quot;, 2)], names=[&quot;myidx1&quot;, &quot;level2&quot;]</span>
<span class="gi">+            ),</span>
<span class="gi">+        )</span>
<span class="gi">+        df2 = GeoDataFrame(</span>
<span class="gi">+            {&quot;geometry&quot;: geoms},</span>
<span class="gi">+            index=pd.MultiIndex.from_tuples(</span>
<span class="gi">+                [(&quot;c&quot;, 3), (&quot;d&quot;, 4)], names=[&quot;myidx2&quot;, None]</span>
<span class="gi">+            ),</span>
<span class="gi">+        )</span>
<span class="gi">+        result = sjoin(df1, df2, how=how)</span>
<span class="gi">+        expected_base = GeoDataFrame(</span>
<span class="gi">+            {</span>
<span class="gi">+                &quot;myidx1&quot;: [&quot;a&quot;, &quot;b&quot;],</span>
<span class="gi">+                &quot;level2&quot;: [1, 2],</span>
<span class="gi">+                &quot;geometry&quot;: geoms,</span>
<span class="gi">+                &quot;myidx2&quot;: [&quot;c&quot;, &quot;d&quot;],</span>
<span class="gi">+                &quot;index_right1&quot;: [3, 4],</span>
<span class="gi">+            }</span>
<span class="gi">+        )</span>
<span class="gi">+        if how in (&quot;inner&quot;, &quot;left&quot;):</span>
<span class="gi">+            expected = expected_base.set_index([&quot;myidx1&quot;, &quot;level2&quot;])</span>
<span class="gi">+        else:</span>
<span class="gi">+            # right join</span>
<span class="gi">+            expected = expected_base.set_index([&quot;myidx2&quot;, &quot;index_right1&quot;])</span>
<span class="gi">+            # if it was originally None, that is preserved</span>
<span class="gi">+            expected.index.names = [&quot;myidx2&quot;, None]</span>
<span class="gi">+        assert_geodataframe_equal(result, expected)</span>
<span class="gi">+</span>
<span class="gi">+        # but also add suffixes if both left and right have the same index</span>
<span class="gi">+        df1.index.names = [&quot;myidx&quot;, &quot;level2&quot;]</span>
<span class="gi">+        df2.index.names = [&quot;myidx&quot;, None]</span>
<span class="gi">+        result = sjoin(df1, df2, how=how)</span>
<span class="gi">+        expected_base = GeoDataFrame(</span>
<span class="gi">+            {</span>
<span class="gi">+                &quot;myidx_left&quot;: [&quot;a&quot;, &quot;b&quot;],</span>
<span class="gi">+                &quot;level2&quot;: [1, 2],</span>
<span class="gi">+                &quot;geometry&quot;: geoms,</span>
<span class="gi">+                &quot;myidx_right&quot;: [&quot;c&quot;, &quot;d&quot;],</span>
<span class="gi">+                &quot;index_right1&quot;: [3, 4],</span>
<span class="gi">+            }</span>
<span class="gi">+        )</span>
<span class="gi">+        if how in (&quot;inner&quot;, &quot;left&quot;):</span>
<span class="gi">+            expected = expected_base.set_index([&quot;myidx_left&quot;, &quot;level2&quot;])</span>
<span class="gi">+        else:</span>
<span class="gi">+            # right join</span>
<span class="gi">+            expected = expected_base.set_index([&quot;myidx_right&quot;, &quot;index_right1&quot;])</span>
<span class="gi">+            # if it was originally None, that is preserved</span>
<span class="gi">+            expected.index.names = [&quot;myidx_right&quot;, None]</span>
<span class="gi">+        assert_geodataframe_equal(result, expected)</span>

<span class="gi">+    @pytest.mark.parametrize(&quot;how&quot;, [&quot;inner&quot;, &quot;left&quot;, &quot;right&quot;])</span>
<span class="gi">+    def test_duplicate_column_index_name(self, how):</span>
<span class="gi">+        # case where a left column and the right index have the same name or the</span>
<span class="gi">+        # other way around -&gt; correctly add suffix or preserve index name</span>
<span class="gi">+        geoms = [Point(1, 1), Point(2, 2)]</span>
<span class="gi">+        df1 = GeoDataFrame({&quot;myidx&quot;: [1, 2], &quot;geometry&quot;: geoms})</span>
<span class="gi">+        df2 = GeoDataFrame(</span>
<span class="gi">+            {&quot;geometry&quot;: geoms}, index=pd.Index([&quot;a&quot;, &quot;b&quot;], name=&quot;myidx&quot;)</span>
<span class="gi">+        )</span>
<span class="gi">+        result = sjoin(df1, df2, how=how)</span>
<span class="gi">+        if how in (&quot;inner&quot;, &quot;left&quot;):</span>
<span class="gi">+            expected = GeoDataFrame(</span>
<span class="gi">+                {&quot;myidx_left&quot;: [1, 2], &quot;geometry&quot;: geoms, &quot;myidx_right&quot;: [&quot;a&quot;, &quot;b&quot;]}</span>
<span class="gi">+            )</span>
<span class="gi">+        else:</span>
<span class="gi">+            # right join</span>
<span class="gi">+            expected = GeoDataFrame(</span>
<span class="gi">+                {&quot;index_left&quot;: [0, 1], &quot;myidx_left&quot;: [1, 2], &quot;geometry&quot;: geoms},</span>
<span class="gi">+                index=pd.Index([&quot;a&quot;, &quot;b&quot;], name=&quot;myidx_right&quot;),</span>
<span class="gi">+            )</span>
<span class="gi">+        assert_geodataframe_equal(result, expected)</span>

<span class="gd">-@pytest.mark.usefixtures(&#39;_setup_class_nybb_filename&#39;)</span>
<span class="gi">+        result = sjoin(df2, df1, how=how)</span>
<span class="gi">+        if how in (&quot;inner&quot;, &quot;left&quot;):</span>
<span class="gi">+            expected = GeoDataFrame(</span>
<span class="gi">+                {&quot;geometry&quot;: geoms, &quot;index_right&quot;: [0, 1], &quot;myidx_right&quot;: [1, 2]},</span>
<span class="gi">+                index=pd.Index([&quot;a&quot;, &quot;b&quot;], name=&quot;myidx_left&quot;),</span>
<span class="gi">+            )</span>
<span class="gi">+        else:</span>
<span class="gi">+            # right join</span>
<span class="gi">+            expected = GeoDataFrame(</span>
<span class="gi">+                {&quot;myidx_left&quot;: [&quot;a&quot;, &quot;b&quot;], &quot;myidx_right&quot;: [1, 2], &quot;geometry&quot;: geoms},</span>
<span class="gi">+            )</span>
<span class="gi">+        assert_geodataframe_equal(result, expected)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;how&quot;, [&quot;inner&quot;, &quot;left&quot;, &quot;right&quot;])</span>
<span class="gi">+    def test_duplicate_column_index_name_multiindex(self, how):</span>
<span class="gi">+        # case where a left column and the right index have the same name or the</span>
<span class="gi">+        # other way around -&gt; correctly add suffix or preserve index name</span>
<span class="gi">+        geoms = [Point(1, 1), Point(2, 2)]</span>
<span class="gi">+        df1 = GeoDataFrame({&quot;myidx&quot;: [1, 2], &quot;geometry&quot;: geoms})</span>
<span class="gi">+        df2 = GeoDataFrame(</span>
<span class="gi">+            {&quot;geometry&quot;: geoms},</span>
<span class="gi">+            index=pd.MultiIndex.from_tuples(</span>
<span class="gi">+                [(&quot;a&quot;, 1), (&quot;b&quot;, 2)], names=[&quot;myidx&quot;, &quot;level2&quot;]</span>
<span class="gi">+            ),</span>
<span class="gi">+        )</span>
<span class="gi">+        result = sjoin(df1, df2, how=how)</span>
<span class="gi">+        if how in (&quot;inner&quot;, &quot;left&quot;):</span>
<span class="gi">+            expected = GeoDataFrame(</span>
<span class="gi">+                {</span>
<span class="gi">+                    &quot;myidx_left&quot;: [1, 2],</span>
<span class="gi">+                    &quot;geometry&quot;: geoms,</span>
<span class="gi">+                    &quot;myidx_right&quot;: [&quot;a&quot;, &quot;b&quot;],</span>
<span class="gi">+                    &quot;level2&quot;: [1, 2],</span>
<span class="gi">+                }</span>
<span class="gi">+            )</span>
<span class="gi">+        else:</span>
<span class="gi">+            # right join</span>
<span class="gi">+            expected = GeoDataFrame(</span>
<span class="gi">+                {&quot;index_left&quot;: [0, 1], &quot;myidx_left&quot;: [1, 2], &quot;geometry&quot;: geoms},</span>
<span class="gi">+                index=pd.MultiIndex.from_tuples(</span>
<span class="gi">+                    [(&quot;a&quot;, 1), (&quot;b&quot;, 2)], names=[&quot;myidx_right&quot;, &quot;level2&quot;]</span>
<span class="gi">+                ),</span>
<span class="gi">+            )</span>
<span class="gi">+        assert_geodataframe_equal(result, expected)</span>
<span class="gi">+</span>
<span class="gi">+        result = sjoin(df2, df1, how=how)</span>
<span class="gi">+        if how in (&quot;inner&quot;, &quot;left&quot;):</span>
<span class="gi">+            expected = GeoDataFrame(</span>
<span class="gi">+                {&quot;geometry&quot;: geoms, &quot;index_right&quot;: [0, 1], &quot;myidx_right&quot;: [1, 2]},</span>
<span class="gi">+                index=pd.MultiIndex.from_tuples(</span>
<span class="gi">+                    [(&quot;a&quot;, 1), (&quot;b&quot;, 2)], names=[&quot;myidx_left&quot;, &quot;level2&quot;]</span>
<span class="gi">+                ),</span>
<span class="gi">+            )</span>
<span class="gi">+        else:</span>
<span class="gi">+            # right join</span>
<span class="gi">+            expected = GeoDataFrame(</span>
<span class="gi">+                {</span>
<span class="gi">+                    &quot;myidx_left&quot;: [&quot;a&quot;, &quot;b&quot;],</span>
<span class="gi">+                    &quot;level2&quot;: [1, 2],</span>
<span class="gi">+                    &quot;myidx_right&quot;: [1, 2],</span>
<span class="gi">+                    &quot;geometry&quot;: geoms,</span>
<span class="gi">+                },</span>
<span class="gi">+            )</span>
<span class="gi">+        assert_geodataframe_equal(result, expected)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;how&quot;, [&quot;inner&quot;, &quot;left&quot;, &quot;right&quot;])</span>
<span class="gi">+    def test_conflicting_column_index_name(self, how):</span>
<span class="gi">+        # test case where the auto-generated index name conflicts</span>
<span class="gi">+        geoms = [Point(1, 1), Point(2, 2)]</span>
<span class="gi">+        df1 = GeoDataFrame({&quot;index_right&quot;: [1, 2], &quot;geometry&quot;: geoms})</span>
<span class="gi">+        df2 = GeoDataFrame({&quot;geometry&quot;: geoms})</span>
<span class="gi">+        with pytest.raises(ValueError, match=&quot;&#39;index_right&#39; cannot be a column name&quot;):</span>
<span class="gi">+            sjoin(df1, df2, how=how)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;how&quot;, [&quot;inner&quot;, &quot;left&quot;, &quot;right&quot;])</span>
<span class="gi">+    def test_conflicting_column_with_suffix(self, how):</span>
<span class="gi">+        # test case where the auto-generated index name conflicts</span>
<span class="gi">+        geoms = [Point(1, 1), Point(2, 2)]</span>
<span class="gi">+        df1 = GeoDataFrame(</span>
<span class="gi">+            {&quot;column&quot;: [1, 2], &quot;column_right&quot;: [&quot;a&quot;, &quot;b&quot;], &quot;geometry&quot;: geoms}</span>
<span class="gi">+        )</span>
<span class="gi">+        df2 = GeoDataFrame({&quot;column&quot;: [0.1, 0.2], &quot;geometry&quot;: geoms})</span>
<span class="gi">+</span>
<span class="gi">+        result = sjoin(df1, df2, how=how)</span>
<span class="gi">+        if how in (&quot;inner&quot;, &quot;left&quot;):</span>
<span class="gi">+            expected = GeoDataFrame(</span>
<span class="gi">+                {1: [1, 2], 2: [&quot;a&quot;, &quot;b&quot;], 3: geoms, 4: [0, 1], 5: [0.1, 0.2]}</span>
<span class="gi">+            )</span>
<span class="gi">+            expected.columns = [</span>
<span class="gi">+                &quot;column_left&quot;,</span>
<span class="gi">+                &quot;column_right&quot;,</span>
<span class="gi">+                &quot;geometry&quot;,</span>
<span class="gi">+                &quot;index_right&quot;,</span>
<span class="gi">+                &quot;column_right&quot;,</span>
<span class="gi">+            ]</span>
<span class="gi">+        else:</span>
<span class="gi">+            # right join</span>
<span class="gi">+            expected = GeoDataFrame(</span>
<span class="gi">+                {1: [0, 1], 2: [1, 2], 3: [&quot;a&quot;, &quot;b&quot;], 4: [0.1, 0.2], 5: geoms}</span>
<span class="gi">+            )</span>
<span class="gi">+            expected.columns = [</span>
<span class="gi">+                &quot;index_left&quot;,</span>
<span class="gi">+                &quot;column_left&quot;,</span>
<span class="gi">+                &quot;column_right&quot;,</span>
<span class="gi">+                &quot;column_right&quot;,</span>
<span class="gi">+                &quot;geometry&quot;,</span>
<span class="gi">+            ]</span>
<span class="gi">+        expected = expected.set_geometry(&quot;geometry&quot;)</span>
<span class="gi">+        assert_geodataframe_equal(result, expected)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.mark.usefixtures(&quot;_setup_class_nybb_filename&quot;)</span>
<span class="w"> </span>class TestSpatialJoinNYBB:
<span class="gi">+    def setup_method(self):</span>
<span class="gi">+        self.polydf = read_file(self.nybb_filename)</span>
<span class="gi">+        self.crs = self.polydf.crs</span>
<span class="gi">+        N = 20</span>
<span class="gi">+        b = [int(x) for x in self.polydf.total_bounds]</span>
<span class="gi">+        self.pointdf = GeoDataFrame(</span>
<span class="gi">+            [</span>
<span class="gi">+                {&quot;geometry&quot;: Point(x, y), &quot;pointattr1&quot;: x + y, &quot;pointattr2&quot;: x - y}</span>
<span class="gi">+                for x, y in zip(</span>
<span class="gi">+                    range(b[0], b[2], int((b[2] - b[0]) / N)),</span>
<span class="gi">+                    range(b[1], b[3], int((b[3] - b[1]) / N)),</span>
<span class="gi">+                )</span>
<span class="gi">+            ],</span>
<span class="gi">+            crs=self.crs,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+    def test_geometry_name(self):</span>
<span class="gi">+        # test sjoin is working with other geometry name</span>
<span class="gi">+        polydf_original_geom_name = self.polydf.geometry.name</span>
<span class="gi">+        self.polydf = self.polydf.rename(columns={&quot;geometry&quot;: &quot;new_geom&quot;}).set_geometry(</span>
<span class="gi">+            &quot;new_geom&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+        assert polydf_original_geom_name != self.polydf.geometry.name</span>
<span class="gi">+        res = sjoin(self.polydf, self.pointdf, how=&quot;left&quot;)</span>
<span class="gi">+        assert self.polydf.geometry.name == res.geometry.name</span>
<span class="gi">+</span>
<span class="gi">+    def test_sjoin_left(self):</span>
<span class="gi">+        df = sjoin(self.pointdf, self.polydf, how=&quot;left&quot;)</span>
<span class="gi">+        assert df.shape == (21, 8)</span>
<span class="gi">+        for i, row in df.iterrows():</span>
<span class="gi">+            assert row.geometry.geom_type == &quot;Point&quot;</span>
<span class="gi">+        assert &quot;pointattr1&quot; in df.columns</span>
<span class="gi">+        assert &quot;BoroCode&quot; in df.columns</span>
<span class="gi">+</span>
<span class="gi">+    def test_sjoin_right(self):</span>
<span class="gi">+        # the inverse of left</span>
<span class="gi">+        df = sjoin(self.pointdf, self.polydf, how=&quot;right&quot;)</span>
<span class="gi">+        df2 = sjoin(self.polydf, self.pointdf, how=&quot;left&quot;)</span>
<span class="gi">+        assert df.shape == (12, 8)</span>
<span class="gi">+        assert df.shape == df2.shape</span>
<span class="gi">+        for i, row in df.iterrows():</span>
<span class="gi">+            assert row.geometry.geom_type == &quot;MultiPolygon&quot;</span>
<span class="gi">+        for i, row in df2.iterrows():</span>
<span class="gi">+            assert row.geometry.geom_type == &quot;MultiPolygon&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def test_sjoin_inner(self):</span>
<span class="gi">+        df = sjoin(self.pointdf, self.polydf, how=&quot;inner&quot;)</span>
<span class="gi">+        assert df.shape == (11, 8)</span>
<span class="gi">+</span>
<span class="gi">+    def test_sjoin_predicate(self):</span>
<span class="gi">+        # points within polygons</span>
<span class="gi">+        df = sjoin(self.pointdf, self.polydf, how=&quot;left&quot;, predicate=&quot;within&quot;)</span>
<span class="gi">+        assert df.shape == (21, 8)</span>
<span class="gi">+        assert df.loc[1][&quot;BoroName&quot;] == &quot;Staten Island&quot;</span>
<span class="gi">+</span>
<span class="gi">+        # points contain polygons? never happens so we should have nulls</span>
<span class="gi">+        df = sjoin(self.pointdf, self.polydf, how=&quot;left&quot;, predicate=&quot;contains&quot;)</span>
<span class="gi">+        assert df.shape == (21, 8)</span>
<span class="gi">+        assert np.isnan(df.loc[1][&quot;Shape_Area&quot;])</span>
<span class="gi">+</span>
<span class="gi">+    def test_sjoin_bad_predicate(self):</span>
<span class="gi">+        # AttributeError: &#39;Point&#39; object has no attribute &#39;spandex&#39;</span>
<span class="gi">+        with pytest.raises(ValueError):</span>
<span class="gi">+            sjoin(self.pointdf, self.polydf, how=&quot;left&quot;, predicate=&quot;spandex&quot;)</span>
<span class="gi">+</span>
<span class="gi">+    def test_sjoin_duplicate_column_name(self):</span>
<span class="gi">+        pointdf2 = self.pointdf.rename(columns={&quot;pointattr1&quot;: &quot;Shape_Area&quot;})</span>
<span class="gi">+        df = sjoin(pointdf2, self.polydf, how=&quot;left&quot;)</span>
<span class="gi">+        assert &quot;Shape_Area_left&quot; in df.columns</span>
<span class="gi">+        assert &quot;Shape_Area_right&quot; in df.columns</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;how&quot;, [&quot;left&quot;, &quot;right&quot;, &quot;inner&quot;])</span>
<span class="gi">+    def test_sjoin_named_index(self, how):</span>
<span class="gi">+        # original index names should be unchanged</span>
<span class="gi">+        pointdf2 = self.pointdf.copy()</span>
<span class="gi">+        pointdf2.index.name = &quot;pointid&quot;</span>
<span class="gi">+        polydf = self.polydf.copy()</span>
<span class="gi">+        polydf.index.name = &quot;polyid&quot;</span>
<span class="gi">+</span>
<span class="gi">+        res = sjoin(pointdf2, polydf, how=how)</span>
<span class="gi">+        assert pointdf2.index.name == &quot;pointid&quot;</span>
<span class="gi">+        assert polydf.index.name == &quot;polyid&quot;</span>
<span class="gi">+</span>
<span class="gi">+        # original index name should pass through to result</span>
<span class="gi">+        if how == &quot;right&quot;:</span>
<span class="gi">+            assert res.index.name == &quot;polyid&quot;</span>
<span class="gi">+        else:  # how == &quot;left&quot;, how == &quot;inner&quot;</span>
<span class="gi">+            assert res.index.name == &quot;pointid&quot;</span>
<span class="gi">+</span>
<span class="gi">+    def test_sjoin_values(self):</span>
<span class="gi">+        # GH190</span>
<span class="gi">+        self.polydf.index = [1, 3, 4, 5, 6]</span>
<span class="gi">+        df = sjoin(self.pointdf, self.polydf, how=&quot;left&quot;)</span>
<span class="gi">+        assert df.shape == (21, 8)</span>
<span class="gi">+        df = sjoin(self.polydf, self.pointdf, how=&quot;left&quot;)</span>
<span class="gi">+        assert df.shape == (12, 8)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.xfail</span>
<span class="gi">+    def test_no_overlapping_geometry(self):</span>
<span class="gi">+        # Note: these tests are for correctly returning GeoDataFrame</span>
<span class="gi">+        # when result of the join is empty</span>
<span class="gi">+</span>
<span class="gi">+        df_inner = sjoin(self.pointdf.iloc[17:], self.polydf, how=&quot;inner&quot;)</span>
<span class="gi">+        df_left = sjoin(self.pointdf.iloc[17:], self.polydf, how=&quot;left&quot;)</span>
<span class="gi">+        df_right = sjoin(self.pointdf.iloc[17:], self.polydf, how=&quot;right&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        expected_inner_df = pd.concat(</span>
<span class="gi">+            [</span>
<span class="gi">+                self.pointdf.iloc[:0],</span>
<span class="gi">+                pd.Series(name=&quot;index_right&quot;, dtype=&quot;int64&quot;),</span>
<span class="gi">+                self.polydf.drop(&quot;geometry&quot;, axis=1).iloc[:0],</span>
<span class="gi">+            ],</span>
<span class="gi">+            axis=1,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        expected_inner = GeoDataFrame(expected_inner_df)</span>
<span class="gi">+</span>
<span class="gi">+        expected_right_df = pd.concat(</span>
<span class="gi">+            [</span>
<span class="gi">+                self.pointdf.drop(&quot;geometry&quot;, axis=1).iloc[:0],</span>
<span class="gi">+                pd.concat(</span>
<span class="gi">+                    [</span>
<span class="gi">+                        pd.Series(name=&quot;index_left&quot;, dtype=&quot;int64&quot;),</span>
<span class="gi">+                        pd.Series(name=&quot;index_right&quot;, dtype=&quot;int64&quot;),</span>
<span class="gi">+                    ],</span>
<span class="gi">+                    axis=1,</span>
<span class="gi">+                ),</span>
<span class="gi">+                self.polydf,</span>
<span class="gi">+            ],</span>
<span class="gi">+            axis=1,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        expected_right = GeoDataFrame(expected_right_df).set_index(&quot;index_right&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        expected_left_df = pd.concat(</span>
<span class="gi">+            [</span>
<span class="gi">+                self.pointdf.iloc[17:],</span>
<span class="gi">+                pd.Series(name=&quot;index_right&quot;, dtype=&quot;int64&quot;),</span>
<span class="gi">+                self.polydf.iloc[:0].drop(&quot;geometry&quot;, axis=1),</span>
<span class="gi">+            ],</span>
<span class="gi">+            axis=1,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        expected_left = GeoDataFrame(expected_left_df)</span>
<span class="gi">+</span>
<span class="gi">+        assert expected_inner.equals(df_inner)</span>
<span class="gi">+        assert expected_right.equals(df_right)</span>
<span class="gi">+        assert expected_left.equals(df_left)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.skip(&quot;Not implemented&quot;)</span>
<span class="gi">+    def test_sjoin_outer(self):</span>
<span class="gi">+        df = sjoin(self.pointdf, self.polydf, how=&quot;outer&quot;)</span>
<span class="gi">+        assert df.shape == (21, 8)</span>

<span class="gd">-    @pytest.mark.parametrize(&#39;predicate&#39;, [&#39;intersects&#39;, &#39;within&#39;, &#39;contains&#39;])</span>
<span class="gi">+    def test_sjoin_empty_geometries(self):</span>
<span class="gi">+        # https://github.com/geopandas/geopandas/issues/944</span>
<span class="gi">+        empty = GeoDataFrame(geometry=[GeometryCollection()] * 3, crs=self.crs)</span>
<span class="gi">+        df = sjoin(pd.concat([self.pointdf, empty]), self.polydf, how=&quot;left&quot;)</span>
<span class="gi">+        assert df.shape == (24, 8)</span>
<span class="gi">+        df2 = sjoin(self.pointdf, pd.concat([self.polydf, empty]), how=&quot;left&quot;)</span>
<span class="gi">+        assert df2.shape == (21, 8)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;predicate&quot;, [&quot;intersects&quot;, &quot;within&quot;, &quot;contains&quot;])</span>
<span class="w"> </span>    def test_sjoin_no_valid_geoms(self, predicate):
<span class="w"> </span>        &quot;&quot;&quot;Tests a completely empty GeoDataFrame.&quot;&quot;&quot;
<span class="gd">-        pass</span>
<span class="gi">+        empty = GeoDataFrame(geometry=[], crs=self.pointdf.crs)</span>
<span class="gi">+        assert sjoin(self.pointdf, empty, how=&quot;inner&quot;, predicate=predicate).empty</span>
<span class="gi">+        assert sjoin(self.pointdf, empty, how=&quot;right&quot;, predicate=predicate).empty</span>
<span class="gi">+        assert sjoin(empty, self.pointdf, how=&quot;inner&quot;, predicate=predicate).empty</span>
<span class="gi">+        assert sjoin(empty, self.pointdf, how=&quot;left&quot;, predicate=predicate).empty</span>
<span class="gi">+</span>
<span class="gi">+    def test_empty_sjoin_return_duplicated_columns(self, nybb_filename):</span>
<span class="gi">+        nybb = geopandas.read_file(nybb_filename)</span>
<span class="gi">+        nybb2 = nybb.copy()</span>
<span class="gi">+        nybb2.geometry = nybb2.translate(200000)  # to get non-overlapping</span>
<span class="gi">+</span>
<span class="gi">+        result = geopandas.sjoin(nybb, nybb2)</span>
<span class="gi">+</span>
<span class="gi">+        assert &quot;BoroCode_right&quot; in result.columns</span>
<span class="gi">+        assert &quot;BoroCode_left&quot; in result.columns</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def world(naturalearth_lowres):</span>
<span class="gi">+    return read_file(naturalearth_lowres)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+@pytest.fixture</span>
<span class="gi">+def cities(naturalearth_cities):</span>
<span class="gi">+    return read_file(naturalearth_cities)</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+def test_sjoin_inner(world, cities):</span>
<span class="gi">+    # GH637</span>
<span class="gi">+    countries = world[[&quot;geometry&quot;, &quot;name&quot;]]</span>
<span class="gi">+    countries = countries.rename(columns={&quot;name&quot;: &quot;country&quot;})</span>
<span class="gi">+    cities_with_country = sjoin(cities, countries, how=&quot;inner&quot;, predicate=&quot;intersects&quot;)</span>
<span class="gi">+    assert cities_with_country.shape == (213, 4)</span>


<span class="w"> </span>class TestNearest:
<span class="gd">-    pass</span>
<span class="gi">+    @pytest.mark.parametrize(</span>
<span class="gi">+        &quot;how_kwargs&quot;, ({}, {&quot;how&quot;: &quot;inner&quot;}, {&quot;how&quot;: &quot;left&quot;}, {&quot;how&quot;: &quot;right&quot;})</span>
<span class="gi">+    )</span>
<span class="gi">+    def test_allowed_hows(self, how_kwargs):</span>
<span class="gi">+        left = geopandas.GeoDataFrame({&quot;geometry&quot;: []})</span>
<span class="gi">+        right = geopandas.GeoDataFrame({&quot;geometry&quot;: []})</span>
<span class="gi">+        sjoin_nearest(left, right, **how_kwargs)  # no error</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;how&quot;, (&quot;outer&quot;, &quot;abcde&quot;))</span>
<span class="gi">+    def test_invalid_hows(self, how: str):</span>
<span class="gi">+        left = geopandas.GeoDataFrame({&quot;geometry&quot;: []})</span>
<span class="gi">+        right = geopandas.GeoDataFrame({&quot;geometry&quot;: []})</span>
<span class="gi">+        with pytest.raises(ValueError, match=&quot;`how` was&quot;):</span>
<span class="gi">+            sjoin_nearest(left, right, how=how)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;distance_col&quot;, (None, &quot;distance&quot;))</span>
<span class="gi">+    def test_empty_right_df_how_left(self, distance_col: str):</span>
<span class="gi">+        # all records from left and no results from right</span>
<span class="gi">+        left = geopandas.GeoDataFrame({&quot;geometry&quot;: [Point(0, 0), Point(1, 1)]})</span>
<span class="gi">+        right = geopandas.GeoDataFrame({&quot;geometry&quot;: []})</span>
<span class="gi">+        joined = sjoin_nearest(</span>
<span class="gi">+            left,</span>
<span class="gi">+            right,</span>
<span class="gi">+            how=&quot;left&quot;,</span>
<span class="gi">+            distance_col=distance_col,</span>
<span class="gi">+        )</span>
<span class="gi">+        assert_geoseries_equal(joined[&quot;geometry&quot;], left[&quot;geometry&quot;])</span>
<span class="gi">+        assert joined[&quot;index_right&quot;].isna().all()</span>
<span class="gi">+        if distance_col is not None:</span>
<span class="gi">+            assert joined[distance_col].isna().all()</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;distance_col&quot;, (None, &quot;distance&quot;))</span>
<span class="gi">+    def test_empty_right_df_how_right(self, distance_col: str):</span>
<span class="gi">+        # no records in joined</span>
<span class="gi">+        left = geopandas.GeoDataFrame({&quot;geometry&quot;: [Point(0, 0), Point(1, 1)]})</span>
<span class="gi">+        right = geopandas.GeoDataFrame({&quot;geometry&quot;: []})</span>
<span class="gi">+        joined = sjoin_nearest(</span>
<span class="gi">+            left,</span>
<span class="gi">+            right,</span>
<span class="gi">+            how=&quot;right&quot;,</span>
<span class="gi">+            distance_col=distance_col,</span>
<span class="gi">+        )</span>
<span class="gi">+        assert joined.empty</span>
<span class="gi">+        if distance_col is not None:</span>
<span class="gi">+            assert distance_col in joined</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;how&quot;, [&quot;inner&quot;, &quot;left&quot;])</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;distance_col&quot;, (None, &quot;distance&quot;))</span>
<span class="gi">+    def test_empty_left_df(self, how, distance_col: str):</span>
<span class="gi">+        right = geopandas.GeoDataFrame({&quot;geometry&quot;: [Point(0, 0), Point(1, 1)]})</span>
<span class="gi">+        left = geopandas.GeoDataFrame({&quot;geometry&quot;: []})</span>
<span class="gi">+        joined = sjoin_nearest(left, right, how=how, distance_col=distance_col)</span>
<span class="gi">+        assert joined.empty</span>
<span class="gi">+        if distance_col is not None:</span>
<span class="gi">+            assert distance_col in joined</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;distance_col&quot;, (None, &quot;distance&quot;))</span>
<span class="gi">+    def test_empty_left_df_how_right(self, distance_col: str):</span>
<span class="gi">+        right = geopandas.GeoDataFrame({&quot;geometry&quot;: [Point(0, 0), Point(1, 1)]})</span>
<span class="gi">+        left = geopandas.GeoDataFrame({&quot;geometry&quot;: []})</span>
<span class="gi">+        joined = sjoin_nearest(</span>
<span class="gi">+            left,</span>
<span class="gi">+            right,</span>
<span class="gi">+            how=&quot;right&quot;,</span>
<span class="gi">+            distance_col=distance_col,</span>
<span class="gi">+        )</span>
<span class="gi">+        assert_geoseries_equal(joined[&quot;geometry&quot;], right[&quot;geometry&quot;])</span>
<span class="gi">+        assert joined[&quot;index_left&quot;].isna().all()</span>
<span class="gi">+        if distance_col is not None:</span>
<span class="gi">+            assert joined[distance_col].isna().all()</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;how&quot;, [&quot;inner&quot;, &quot;left&quot;])</span>
<span class="gi">+    def test_empty_join_due_to_max_distance(self, how):</span>
<span class="gi">+        # after applying max_distance the join comes back empty</span>
<span class="gi">+        # (as in NaN in the joined columns)</span>
<span class="gi">+        left = geopandas.GeoDataFrame({&quot;geometry&quot;: [Point(0, 0)]})</span>
<span class="gi">+        right = geopandas.GeoDataFrame({&quot;geometry&quot;: [Point(1, 1), Point(2, 2)]})</span>
<span class="gi">+        joined = sjoin_nearest(</span>
<span class="gi">+            left,</span>
<span class="gi">+            right,</span>
<span class="gi">+            how=how,</span>
<span class="gi">+            max_distance=1,</span>
<span class="gi">+            distance_col=&quot;distances&quot;,</span>
<span class="gi">+        )</span>
<span class="gi">+        expected = left.copy()</span>
<span class="gi">+        expected[&quot;index_right&quot;] = [np.nan]</span>
<span class="gi">+        expected[&quot;distances&quot;] = [np.nan]</span>
<span class="gi">+        if how == &quot;inner&quot;:</span>
<span class="gi">+            expected = expected.dropna()</span>
<span class="gi">+            expected[&quot;index_right&quot;] = expected[&quot;index_right&quot;].astype(&quot;int64&quot;)</span>
<span class="gi">+        assert_geodataframe_equal(joined, expected)</span>
<span class="gi">+</span>
<span class="gi">+    def test_empty_join_due_to_max_distance_how_right(self):</span>
<span class="gi">+        # after applying max_distance the join comes back empty</span>
<span class="gi">+        # (as in NaN in the joined columns)</span>
<span class="gi">+        left = geopandas.GeoDataFrame({&quot;geometry&quot;: [Point(0, 0), Point(1, 1)]})</span>
<span class="gi">+        right = geopandas.GeoDataFrame({&quot;geometry&quot;: [Point(2, 2)]})</span>
<span class="gi">+        joined = sjoin_nearest(</span>
<span class="gi">+            left,</span>
<span class="gi">+            right,</span>
<span class="gi">+            how=&quot;right&quot;,</span>
<span class="gi">+            max_distance=1,</span>
<span class="gi">+            distance_col=&quot;distances&quot;,</span>
<span class="gi">+        )</span>
<span class="gi">+        expected = right.copy()</span>
<span class="gi">+        expected[&quot;index_left&quot;] = [np.nan]</span>
<span class="gi">+        expected[&quot;distances&quot;] = [np.nan]</span>
<span class="gi">+        expected = expected[[&quot;index_left&quot;, &quot;geometry&quot;, &quot;distances&quot;]]</span>
<span class="gi">+        assert_geodataframe_equal(joined, expected)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;how&quot;, [&quot;inner&quot;, &quot;left&quot;])</span>
<span class="gi">+    def test_max_distance(self, how):</span>
<span class="gi">+        left = geopandas.GeoDataFrame({&quot;geometry&quot;: [Point(0, 0), Point(1, 1)]})</span>
<span class="gi">+        right = geopandas.GeoDataFrame({&quot;geometry&quot;: [Point(1, 1), Point(2, 2)]})</span>
<span class="gi">+        joined = sjoin_nearest(</span>
<span class="gi">+            left,</span>
<span class="gi">+            right,</span>
<span class="gi">+            how=how,</span>
<span class="gi">+            max_distance=1,</span>
<span class="gi">+            distance_col=&quot;distances&quot;,</span>
<span class="gi">+        )</span>
<span class="gi">+        expected = left.copy()</span>
<span class="gi">+        expected[&quot;index_right&quot;] = [np.nan, 0]</span>
<span class="gi">+        expected[&quot;distances&quot;] = [np.nan, 0]</span>
<span class="gi">+        if how == &quot;inner&quot;:</span>
<span class="gi">+            expected = expected.dropna()</span>
<span class="gi">+            expected[&quot;index_right&quot;] = expected[&quot;index_right&quot;].astype(&quot;int64&quot;)</span>
<span class="gi">+        assert_geodataframe_equal(joined, expected)</span>
<span class="gi">+</span>
<span class="gi">+    def test_max_distance_how_right(self):</span>
<span class="gi">+        left = geopandas.GeoDataFrame({&quot;geometry&quot;: [Point(1, 1), Point(2, 2)]})</span>
<span class="gi">+        right = geopandas.GeoDataFrame({&quot;geometry&quot;: [Point(0, 0), Point(1, 1)]})</span>
<span class="gi">+        joined = sjoin_nearest(</span>
<span class="gi">+            left,</span>
<span class="gi">+            right,</span>
<span class="gi">+            how=&quot;right&quot;,</span>
<span class="gi">+            max_distance=1,</span>
<span class="gi">+            distance_col=&quot;distances&quot;,</span>
<span class="gi">+        )</span>
<span class="gi">+        expected = right.copy()</span>
<span class="gi">+        expected[&quot;index_left&quot;] = [np.nan, 0]</span>
<span class="gi">+        expected[&quot;distances&quot;] = [np.nan, 0]</span>
<span class="gi">+        expected = expected[[&quot;index_left&quot;, &quot;geometry&quot;, &quot;distances&quot;]]</span>
<span class="gi">+        assert_geodataframe_equal(joined, expected)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(&quot;how&quot;, [&quot;inner&quot;, &quot;left&quot;])</span>
<span class="gi">+    @pytest.mark.parametrize(</span>
<span class="gi">+        &quot;geo_left, geo_right, expected_left, expected_right, distances&quot;,</span>
<span class="gi">+        [</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(1, 1)],</span>
<span class="gi">+                [Point(1, 1)],</span>
<span class="gi">+                [0, 1],</span>
<span class="gi">+                [0, 0],</span>
<span class="gi">+                [math.sqrt(2), 0],</span>
<span class="gi">+            ),</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(1, 1)],</span>
<span class="gi">+                [Point(1, 1), Point(0, 0)],</span>
<span class="gi">+                [0, 1],</span>
<span class="gi">+                [1, 0],</span>
<span class="gi">+                [0, 0],</span>
<span class="gi">+            ),</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(1, 1)],</span>
<span class="gi">+                [Point(1, 1), Point(0, 0), Point(0, 0)],</span>
<span class="gi">+                [0, 0, 1],</span>
<span class="gi">+                [1, 2, 0],</span>
<span class="gi">+                [0, 0, 0],</span>
<span class="gi">+            ),</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(1, 1)],</span>
<span class="gi">+                [Point(1, 1), Point(0, 0), Point(2, 2)],</span>
<span class="gi">+                [0, 1],</span>
<span class="gi">+                [1, 0],</span>
<span class="gi">+                [0, 0],</span>
<span class="gi">+            ),</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(1, 1)],</span>
<span class="gi">+                [Point(1, 1), Point(0.25, 1)],</span>
<span class="gi">+                [0, 1],</span>
<span class="gi">+                [1, 0],</span>
<span class="gi">+                [math.sqrt(0.25**2 + 1), 0],</span>
<span class="gi">+            ),</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(1, 1)],</span>
<span class="gi">+                [Point(-10, -10), Point(100, 100)],</span>
<span class="gi">+                [0, 1],</span>
<span class="gi">+                [0, 0],</span>
<span class="gi">+                [math.sqrt(10**2 + 10**2), math.sqrt(11**2 + 11**2)],</span>
<span class="gi">+            ),</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(1, 1)],</span>
<span class="gi">+                [Point(x, y) for x, y in zip(np.arange(10), np.arange(10))],</span>
<span class="gi">+                [0, 1],</span>
<span class="gi">+                [0, 1],</span>
<span class="gi">+                [0, 0],</span>
<span class="gi">+            ),</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(1, 1), Point(0, 0)],</span>
<span class="gi">+                [Point(1.1, 1.1), Point(0, 0)],</span>
<span class="gi">+                [0, 1, 2],</span>
<span class="gi">+                [1, 0, 1],</span>
<span class="gi">+                [0, np.sqrt(0.1**2 + 0.1**2), 0],</span>
<span class="gi">+            ),</span>
<span class="gi">+        ],</span>
<span class="gi">+    )</span>
<span class="gi">+    def test_sjoin_nearest_left(</span>
<span class="gi">+        self,</span>
<span class="gi">+        geo_left,</span>
<span class="gi">+        geo_right,</span>
<span class="gi">+        expected_left: Sequence[int],</span>
<span class="gi">+        expected_right: Sequence[int],</span>
<span class="gi">+        distances: Sequence[float],</span>
<span class="gi">+        how,</span>
<span class="gi">+    ):</span>
<span class="gi">+        left = geopandas.GeoDataFrame({&quot;geometry&quot;: geo_left})</span>
<span class="gi">+        right = geopandas.GeoDataFrame({&quot;geometry&quot;: geo_right})</span>
<span class="gi">+        expected_gdf = left.iloc[expected_left].copy()</span>
<span class="gi">+        expected_gdf[&quot;index_right&quot;] = expected_right</span>
<span class="gi">+        # without distance col</span>
<span class="gi">+        joined = sjoin_nearest(left, right, how=how)</span>
<span class="gi">+        # inner / left join give a different row order</span>
<span class="gi">+        check_like = how == &quot;inner&quot;</span>
<span class="gi">+        assert_geodataframe_equal(expected_gdf, joined, check_like=check_like)</span>
<span class="gi">+        # with distance col</span>
<span class="gi">+        expected_gdf[&quot;distance_col&quot;] = np.array(distances, dtype=float)</span>
<span class="gi">+        joined = sjoin_nearest(left, right, how=how, distance_col=&quot;distance_col&quot;)</span>
<span class="gi">+        assert_geodataframe_equal(expected_gdf, joined, check_like=check_like)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(</span>
<span class="gi">+        &quot;geo_left, geo_right, expected_left, expected_right, distances&quot;,</span>
<span class="gi">+        [</span>
<span class="gi">+            ([Point(0, 0), Point(1, 1)], [Point(1, 1)], [1], [0], [0]),</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(1, 1)],</span>
<span class="gi">+                [Point(1, 1), Point(0, 0)],</span>
<span class="gi">+                [1, 0],</span>
<span class="gi">+                [0, 1],</span>
<span class="gi">+                [0, 0],</span>
<span class="gi">+            ),</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(1, 1)],</span>
<span class="gi">+                [Point(1, 1), Point(0, 0), Point(0, 0)],</span>
<span class="gi">+                [1, 0, 0],</span>
<span class="gi">+                [0, 1, 2],</span>
<span class="gi">+                [0, 0, 0],</span>
<span class="gi">+            ),</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(1, 1)],</span>
<span class="gi">+                [Point(1, 1), Point(0, 0), Point(2, 2)],</span>
<span class="gi">+                [1, 0, 1],</span>
<span class="gi">+                [0, 1, 2],</span>
<span class="gi">+                [0, 0, math.sqrt(2)],</span>
<span class="gi">+            ),</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(1, 1)],</span>
<span class="gi">+                [Point(1, 1), Point(0.25, 1)],</span>
<span class="gi">+                [1, 1],</span>
<span class="gi">+                [0, 1],</span>
<span class="gi">+                [0, 0.75],</span>
<span class="gi">+            ),</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(1, 1)],</span>
<span class="gi">+                [Point(-10, -10), Point(100, 100)],</span>
<span class="gi">+                [0, 1],</span>
<span class="gi">+                [0, 1],</span>
<span class="gi">+                [math.sqrt(10**2 + 10**2), math.sqrt(99**2 + 99**2)],</span>
<span class="gi">+            ),</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(1, 1)],</span>
<span class="gi">+                [Point(x, y) for x, y in zip(np.arange(10), np.arange(10))],</span>
<span class="gi">+                [0, 1] + [1] * 8,</span>
<span class="gi">+                list(range(10)),</span>
<span class="gi">+                [0, 0] + [np.sqrt(x**2 + x**2) for x in np.arange(1, 9)],</span>
<span class="gi">+            ),</span>
<span class="gi">+            (</span>
<span class="gi">+                [Point(0, 0), Point(1, 1), Point(0, 0)],</span>
<span class="gi">+                [Point(1.1, 1.1), Point(0, 0)],</span>
<span class="gi">+                [1, 0, 2],</span>
<span class="gi">+                [0, 1, 1],</span>
<span class="gi">+                [np.sqrt(0.1**2 + 0.1**2), 0, 0],</span>
<span class="gi">+            ),</span>
<span class="gi">+        ],</span>
<span class="gi">+    )</span>
<span class="gi">+    def test_sjoin_nearest_right(</span>
<span class="gi">+        self,</span>
<span class="gi">+        geo_left,</span>
<span class="gi">+        geo_right,</span>
<span class="gi">+        expected_left: Sequence[int],</span>
<span class="gi">+        expected_right: Sequence[int],</span>
<span class="gi">+        distances: Sequence[float],</span>
<span class="gi">+    ):</span>
<span class="gi">+        left = geopandas.GeoDataFrame({&quot;geometry&quot;: geo_left})</span>
<span class="gi">+        right = geopandas.GeoDataFrame({&quot;geometry&quot;: geo_right})</span>
<span class="gi">+        expected_gdf = right.iloc[expected_right].copy()</span>
<span class="gi">+        expected_gdf[&quot;index_left&quot;] = expected_left</span>
<span class="gi">+        expected_gdf = expected_gdf[[&quot;index_left&quot;, &quot;geometry&quot;]]</span>
<span class="gi">+        # without distance col</span>
<span class="gi">+        joined = sjoin_nearest(left, right, how=&quot;right&quot;)</span>
<span class="gi">+        assert_geodataframe_equal(expected_gdf, joined)</span>
<span class="gi">+        # with distance col</span>
<span class="gi">+        expected_gdf[&quot;distance_col&quot;] = np.array(distances, dtype=float)</span>
<span class="gi">+        joined = sjoin_nearest(left, right, how=&quot;right&quot;, distance_col=&quot;distance_col&quot;)</span>
<span class="gi">+        assert_geodataframe_equal(expected_gdf, joined)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.filterwarnings(&quot;ignore:Geometry is in a geographic CRS&quot;)</span>
<span class="gi">+    def test_sjoin_nearest_inner(self, naturalearth_lowres, naturalearth_cities):</span>
<span class="gi">+        # check equivalency of left and inner join</span>
<span class="gi">+        countries = read_file(naturalearth_lowres)</span>
<span class="gi">+        cities = read_file(naturalearth_cities)</span>
<span class="gi">+        countries = countries[[&quot;geometry&quot;, &quot;name&quot;]].rename(columns={&quot;name&quot;: &quot;country&quot;})</span>
<span class="gi">+</span>
<span class="gi">+        # default: inner and left give the same result</span>
<span class="gi">+        result1 = sjoin_nearest(cities, countries, distance_col=&quot;dist&quot;)</span>
<span class="gi">+        assert result1.shape[0] == cities.shape[0]</span>
<span class="gi">+        result2 = sjoin_nearest(cities, countries, distance_col=&quot;dist&quot;, how=&quot;inner&quot;)</span>
<span class="gi">+        assert_geodataframe_equal(result2, result1)</span>
<span class="gi">+        result3 = sjoin_nearest(cities, countries, distance_col=&quot;dist&quot;, how=&quot;left&quot;)</span>
<span class="gi">+        assert_geodataframe_equal(result3, result1, check_like=True)</span>
<span class="gi">+</span>
<span class="gi">+        # with max_distance: rows that go above are dropped in case of inner</span>
<span class="gi">+        result4 = sjoin_nearest(cities, countries, distance_col=&quot;dist&quot;, max_distance=1)</span>
<span class="gi">+        assert_geodataframe_equal(</span>
<span class="gi">+            result4, result1[result1[&quot;dist&quot;] &lt; 1], check_like=True</span>
<span class="gi">+        )</span>
<span class="gi">+        result5 = sjoin_nearest(</span>
<span class="gi">+            cities, countries, distance_col=&quot;dist&quot;, max_distance=1, how=&quot;left&quot;</span>
<span class="gi">+        )</span>
<span class="gi">+        assert result5.shape[0] == cities.shape[0]</span>
<span class="gi">+        result5 = result5.dropna()</span>
<span class="gi">+        result5[&quot;index_right&quot;] = result5[&quot;index_right&quot;].astype(&quot;int64&quot;)</span>
<span class="gi">+        assert_geodataframe_equal(result5, result4, check_like=True)</span>
<span class="gi">+</span>
<span class="gi">+    @pytest.mark.parametrize(</span>
<span class="gi">+        &quot;max_distance,expected&quot;, [(None, [1, 3, 3, 1, 2]), (1.1, [3, 3, 1, 2])]</span>
<span class="gi">+    )</span>
<span class="gi">+    def test_sjoin_nearest_exclusive(self, max_distance, expected):</span>
<span class="gi">+        geoms = shapely.points(np.arange(3), np.arange(3))</span>
<span class="gi">+        geoms = np.append(geoms, [Point(1, 2)])</span>
<span class="gi">+</span>
<span class="gi">+        df = geopandas.GeoDataFrame({&quot;geometry&quot;: geoms})</span>
<span class="gi">+        result = df.sjoin_nearest(</span>
<span class="gi">+            df, max_distance=max_distance, distance_col=&quot;dist&quot;, exclusive=True</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        assert_series_equal(</span>
<span class="gi">+            result[&quot;index_right&quot;].reset_index(drop=True),</span>
<span class="gi">+            pd.Series(expected),</span>
<span class="gi">+            check_names=False,</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        if max_distance:</span>
<span class="gi">+            assert result[&quot;dist&quot;].max() &lt;= max_distance</span>
<span class="gh">diff --git a/geopandas/tools/tests/test_tools.py b/geopandas/tools/tests/test_tools.py</span>
<span class="gh">index a51978e3..603aad0d 100644</span>
<span class="gd">--- a/geopandas/tools/tests/test_tools.py</span>
<span class="gi">+++ b/geopandas/tools/tests/test_tools.py</span>
<span class="gu">@@ -1,8 +1,51 @@</span>
<span class="w"> </span>from shapely.geometry import LineString, MultiPoint, Point
<span class="gi">+</span>
<span class="w"> </span>from geopandas import GeoSeries
<span class="w"> </span>from geopandas.tools import collect
<span class="gi">+</span>
<span class="w"> </span>import pytest


<span class="w"> </span>class TestTools:
<span class="gd">-    pass</span>
<span class="gi">+    def setup_method(self):</span>
<span class="gi">+        self.p1 = Point(0, 0)</span>
<span class="gi">+        self.p2 = Point(1, 1)</span>
<span class="gi">+        self.p3 = Point(2, 2)</span>
<span class="gi">+        self.mpc = MultiPoint([self.p1, self.p2, self.p3])</span>
<span class="gi">+</span>
<span class="gi">+        self.mp1 = MultiPoint([self.p1, self.p2])</span>
<span class="gi">+        self.line1 = LineString([(3, 3), (4, 4)])</span>
<span class="gi">+</span>
<span class="gi">+    def test_collect_single(self):</span>
<span class="gi">+        result = collect(self.p1)</span>
<span class="gi">+        assert self.p1.equals(result)</span>
<span class="gi">+</span>
<span class="gi">+    def test_collect_single_force_multi(self):</span>
<span class="gi">+        result = collect(self.p1, multi=True)</span>
<span class="gi">+        expected = MultiPoint([self.p1])</span>
<span class="gi">+        assert expected.equals(result)</span>
<span class="gi">+</span>
<span class="gi">+    def test_collect_multi(self):</span>
<span class="gi">+        result = collect(self.mp1)</span>
<span class="gi">+        assert self.mp1.equals(result)</span>
<span class="gi">+</span>
<span class="gi">+    def test_collect_multi_force_multi(self):</span>
<span class="gi">+        result = collect(self.mp1)</span>
<span class="gi">+        assert self.mp1.equals(result)</span>
<span class="gi">+</span>
<span class="gi">+    def test_collect_list(self):</span>
<span class="gi">+        result = collect([self.p1, self.p2, self.p3])</span>
<span class="gi">+        assert self.mpc.equals(result)</span>
<span class="gi">+</span>
<span class="gi">+    def test_collect_GeoSeries(self):</span>
<span class="gi">+        s = GeoSeries([self.p1, self.p2, self.p3])</span>
<span class="gi">+        result = collect(s)</span>
<span class="gi">+        assert self.mpc.equals(result)</span>
<span class="gi">+</span>
<span class="gi">+    def test_collect_mixed_types(self):</span>
<span class="gi">+        with pytest.raises(ValueError):</span>
<span class="gi">+            collect([self.p1, self.line1])</span>
<span class="gi">+</span>
<span class="gi">+    def test_collect_mixed_multi(self):</span>
<span class="gi">+        with pytest.raises(ValueError):</span>
<span class="gi">+            collect([self.mpc, self.mp1])</span>
<span class="gh">diff --git a/geopandas/tools/util.py b/geopandas/tools/util.py</span>
<span class="gh">index bea1b2db..5d4c507e 100644</span>
<span class="gd">--- a/geopandas/tools/util.py</span>
<span class="gi">+++ b/geopandas/tools/util.py</span>
<span class="gu">@@ -1,8 +1,13 @@</span>
<span class="w"> </span>import pandas as pd
<span class="gi">+</span>
<span class="w"> </span>from shapely.geometry import MultiLineString, MultiPoint, MultiPolygon
<span class="w"> </span>from shapely.geometry.base import BaseGeometry
<span class="gd">-_multi_type_map = {&#39;Point&#39;: MultiPoint, &#39;LineString&#39;: MultiLineString,</span>
<span class="gd">-    &#39;Polygon&#39;: MultiPolygon}</span>
<span class="gi">+</span>
<span class="gi">+_multi_type_map = {</span>
<span class="gi">+    &quot;Point&quot;: MultiPoint,</span>
<span class="gi">+    &quot;LineString&quot;: MultiLineString,</span>
<span class="gi">+    &quot;Polygon&quot;: MultiPolygon,</span>
<span class="gi">+}</span>


<span class="w"> </span>def collect(x, multi=False):
<span class="gu">@@ -18,4 +23,23 @@ def collect(x, multi=False):</span>
<span class="w"> </span>        only have one component.

<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    pass</span>
<span class="gi">+    if isinstance(x, BaseGeometry):</span>
<span class="gi">+        x = [x]</span>
<span class="gi">+    elif isinstance(x, pd.Series):</span>
<span class="gi">+        x = list(x)</span>
<span class="gi">+</span>
<span class="gi">+    # We cannot create GeometryCollection here so all types</span>
<span class="gi">+    # must be the same. If there is more than one element,</span>
<span class="gi">+    # they cannot be Multi*, i.e., can&#39;t pass in combination of</span>
<span class="gi">+    # Point and MultiPoint... or even just MultiPoint</span>
<span class="gi">+    t = x[0].geom_type</span>
<span class="gi">+    if not all(g.geom_type == t for g in x):</span>
<span class="gi">+        raise ValueError(&quot;Geometry type must be homogeneous&quot;)</span>
<span class="gi">+    if len(x) &gt; 1 and t.startswith(&quot;Multi&quot;):</span>
<span class="gi">+        raise ValueError(&quot;Cannot collect {0}. Must have single geometries&quot;.format(t))</span>
<span class="gi">+</span>
<span class="gi">+    if len(x) == 1 and (t.startswith(&quot;Multi&quot;) or not multi):</span>
<span class="gi">+        # If there&#39;s only one single part geom and we&#39;re not forcing to</span>
<span class="gi">+        # multi, then just return it</span>
<span class="gi">+        return x[0]</span>
<span class="gi">+    return _multi_type_map[t](x)</span>
</code></pre></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.d6f25eb3.min.js"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../javascripts/tablesort.js"></script>
      
    
  </body>
</html>