{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#_1","title":"Home","text":""},{"location":"#overview","title":"Overview","text":"<p>Commit-0 is a from scratch AI coding challenge. Can you create a library from commit 0?</p> <p>The benchmark consists of 54 core Python libraries. The challenge is to rebuild these libraries and pass their unit tests.  All libraries have:</p> <ul> <li>Significant test coverage</li> <li>Detailed specification and documentation</li> <li>Lint and type checking</li> </ul> <p>Commit-0 is an interactive environment that makes it easy to design and test new agents. You can:</p> <ul> <li>Efficiently run tests in isolated environments</li> <li>Distribute testing and development across cloud systems</li> <li>Track and log all changes made throughout.</li> </ul> <p>To install run:</p> <pre><code>pip install commit0\n</code></pre>"},{"location":"#architecture","title":"Architecture","text":""},{"location":"#libraries","title":"Libraries","text":"Name Repo Commit0 Tests minitorch [orig] [commit0] 230 simpy [orig] [commit0] 140 bitstring [orig] [commit0] 834 tinydb [orig] [commit0] 201 marshmallow [orig] [commit0] 1229 python-prompt-toolkit [orig] [commit0] 151 parsel [orig] [commit0] 343 pyjwt pyjwt [orig] [commit0] 259 networkx [orig] [commit0] 5440 graphene [orig] [commit0] 447 tlslite-ng tlslite-ng [orig] [commit0] 1653 wcwidth wcwidth [orig] [commit0] 38 chardet chardet [orig] [commit0] 376 dnspython dnspython [orig] [commit0] 1304 imapclient imapclient [orig] [commit0] 267 virtualenv [orig] [commit0] 284 pexpect pexpect [orig] [commit0] 255 web3.py [orig] [commit0] 40433 babel [orig] [commit0] 5663 geopandas [orig] [commit0] 2196 dulwich dulwich [orig] [commit0] 1522 flask [orig] [commit0] 477 voluptuous voluptuous [orig] [commit0] 149 jinja [orig] [commit0] 851 seaborn [orig] [commit0] 2362 requests requests [orig] [commit0] 590 scrapy [orig] [commit0] 2904 fastapi [orig] [commit0] 2013 click [orig] [commit0] 589 python-rsa [orig] [commit0] 86 statsmodels [orig] [commit0] 17669 more-itertools more-itertools [orig] [commit0] 662 moviepy [orig] [commit0] 109 deprecated deprecated [orig] [commit0] 171 pydantic [orig] [commit0] 5091 loguru [orig] [commit0] 1461 pypdf [orig] [commit0] 911 attrs [orig] [commit0] 1414 mimesis [orig] [commit0] 6159 cookiecutter [orig] [commit0] 367 tornado [orig] [commit0] 1150 imbalanced-learn [orig] [commit0] 2310 python-progressbar [orig] [commit0] 385 PyBoy [orig] [commit0] 201 pytest [orig] [commit0] 3612 pylint [orig] [commit0] 1878 sphinx [orig] [commit0] 2187 joblib [orig] [commit0] 1450 xarray [orig] [commit0] 15643 cachetools cachetools [orig] [commit0] 215 paramiko paramiko [orig] [commit0] 557 fabric [orig] [commit0] 353 filesystem_spec [orig] [commit0] 698 jedi jedi [orig] [commit0] 3854 sqlparse sqlparse [orig] [commit0] 461 portalocker [orig] [commit0] 38"},{"location":"about/","title":"About","text":"<p>Commit0 is ..</p>"},{"location":"agent/","title":"Agent","text":""},{"location":"agent/#running","title":"Running","text":"<p>Commit0 provides a command-line <code>agent</code> for configuring and running AI agents to assist with code development and testing. In this example we use Aider as the baseline code completion agent</p> <pre><code>pip install aider\n</code></pre> <p>First we assume there is an underlying <code>commit0</code> project that is configured. To create a new project, run the commit0 <code>setup</code> command.</p> <pre><code>commit0 setup lite\n</code></pre> <p>Next we need to configure the backend for the agent. Currently we only support the aider backend. Config can also be used to pass in arguments.</p> <pre><code>export ANTHROPIC_API_KEY=\"...\"\nagent config aider\n</code></pre> <p>Finally we run the underlying agent. This will create a display that shows the current progress of the agent.</p> <pre><code>agent run\n</code></pre>"},{"location":"agent/#extending","title":"Extending","text":"<p>Refer to <code>class Agents</code> in <code>agent/agents.py</code>. You can design your own agent by inheriting <code>Agents</code> class and implement the <code>run</code> method.</p>"},{"location":"agent/#notes","title":"Notes","text":"<ul> <li>Aider automatically retries certain API errors. For details, see here.</li> <li>When increasing --max-parallel-repos, be mindful of aider's 60-second retry timeout. Set this value according to your API tier to avoid RateLimitErrors stopping processes.</li> <li>Currently, agent will skip file with more than 1500 lines. See <code>agent/agent_utils.py#L199</code> for details.</li> <li>Running a full <code>all</code> commit0 split costs approximately $100 with Claude Sonnet 3.5.</li> </ul>"},{"location":"analysis/","title":"Leaderboard","text":""},{"location":"analysis/#leaderboard-lite","title":"Leaderboard (lite)","text":"Name Repos Resolved (/10) Test Duration (s) Date Analysis Reference (Gold) 10 21.13 NA Analysis Claude Sonnet - Base 7 15.96 09/25/2024 Analysis"},{"location":"analysis/#leaderboard-all","title":"Leaderboard (all)","text":"Name Repos Resolved (/56) Test Duration (s) Date Analysis"},{"location":"analysis_baseline/","title":"Analysis baseline","text":"<p>back to all submissions</p>"},{"location":"analysis_baseline/#submission-name-claude-sonnet-base-split-lite","title":"Submission Name: Claude Sonnet - Base (split: lite)","text":"Repository Resolved Pass Rate Test Duration (s) Analysis simpy No 20 / 150 1.73 Analysis tinydb No Pytest failed Failed. Analysis marshmallow No Pytest failed Failed. Analysis wcwidth No 6 / 39 1.02 Analysis imapclient Yes 0 / 0 0.38 Analysis voluptuous Yes 0 / 1 0.19 Analysis jinja No Pytest failed Failed. Analysis deprecated No 80 / 171 0.86 Analysis cookiecutter No 97 / 371 11.24 Analysis cachetools No 173 / 215 0.53 Analysis"},{"location":"analysis_baseline_cachetools/","title":"Analysis baseline cachetools","text":"<p>back to baseline summary</p>"},{"location":"analysis_baseline_cachetools/#submission-name-baseline","title":"Submission Name: baseline","text":""},{"location":"analysis_baseline_cachetools/#repository-cachetools","title":"Repository: cachetools","text":""},{"location":"analysis_baseline_cachetools/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count passed 173 failed 42 total 215 collected 215"},{"location":"analysis_baseline_cachetools/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_baseline_cachetools/#test_cachedpycachewrappertesttest_decorator_typed","title":"test_cached.py::CacheWrapperTest::test_decorator_typed","text":"<pre>test_cached.py::CacheWrapperTest::test_decorator_typed</pre><pre>\nself = \n\n    def test_decorator_typed(self):\n        cache = self.cache(3)\n        key = cachetools.keys.typedkey\n        wrapper = cachetools.cached(cache, key=key)(self.func)\n\n        self.assertEqual(len(cache), 0)\n        self.assertEqual(wrapper(0), 0)\n        self.assertEqual(len(cache), 1)\n        self.assertIn(cachetools.keys.typedkey(0), cache)\n&gt;       self.assertNotIn(cachetools.keys.typedkey(1), cache)\nE       AssertionError: (,) unexpectedly found in Cache({(,): 0}, maxsize=3, currsize=1)\n\ntests/test_cached.py:64: AssertionError"},{"location":"analysis_baseline_cachetools/#test_cachedpydictwrappertesttest_decorator_typed","title":"test_cached.py::DictWrapperTest::test_decorator_typed","text":"<pre>test_cached.py::DictWrapperTest::test_decorator_typed</pre><pre>\nself = \n\n    def test_decorator_typed(self):\n        cache = self.cache(3)\n        key = cachetools.keys.typedkey\n        wrapper = cachetools.cached(cache, key=key)(self.func)\n\n        self.assertEqual(len(cache), 0)\n        self.assertEqual(wrapper(0), 0)\n        self.assertEqual(len(cache), 1)\n        self.assertIn(cachetools.keys.typedkey(0), cache)\n&gt;       self.assertNotIn(cachetools.keys.typedkey(1), cache)\nE       AssertionError: (,) unexpectedly found in {(,): 0}\n\ntests/test_cached.py:64: AssertionError"},{"location":"analysis_baseline_cachetools/#test_cachedmethodpycachedmethodtesttest_typedmethod_dict","title":"test_cachedmethod.py::CachedMethodTest::test_typedmethod_dict","text":"<pre>test_cachedmethod.py::CachedMethodTest::test_typedmethod_dict</pre><pre>\nself = \n\n    def test_typedmethod_dict(self):\n        cached = Cached(LRUCache(maxsize=2))\n\n        self.assertEqual(cached.get_typedmethod(0), 0)\n&gt;       self.assertEqual(cached.get_typedmethod(1), 1)\nE       AssertionError: 0 != 1\n\ntests/test_cachedmethod.py:74: AssertionError"},{"location":"analysis_baseline_cachetools/#test_cachedmethodpycachedmethodtesttest_typedmethod_lru","title":"test_cachedmethod.py::CachedMethodTest::test_typedmethod_lru","text":"<pre>test_cachedmethod.py::CachedMethodTest::test_typedmethod_lru</pre><pre>\nself = \n\n    def test_typedmethod_lru(self):\n        cached = Cached(LRUCache(maxsize=2))\n\n        self.assertEqual(cached.get_typedmethod(0), 0)\n&gt;       self.assertEqual(cached.get_typedmethod(1), 1)\nE       AssertionError: 0 != 1\n\ntests/test_cachedmethod.py:97: AssertionError"},{"location":"analysis_baseline_cachetools/#test_funcpyfifodecoratortesttest_decorator","title":"test_func.py::FIFODecoratorTest::test_decorator","text":"<pre>test_func.py::FIFODecoratorTest::test_decorator</pre><pre>\nself = \n\n    def test_decorator(self):\n        cached = self.decorator(maxsize=2)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:12: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyfifodecoratortesttest_decorator_clear","title":"test_func.py::FIFODecoratorTest::test_decorator_clear","text":"<pre>test_func.py::FIFODecoratorTest::test_decorator_clear</pre><pre>\nself = \n\n    def test_decorator_clear(self):\n        cached = self.decorator(maxsize=2)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:23: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyfifodecoratortesttest_decorator_nocache","title":"test_func.py::FIFODecoratorTest::test_decorator_nocache","text":"<pre>test_func.py::FIFODecoratorTest::test_decorator_nocache</pre><pre>\nself = \n\n    def test_decorator_nocache(self):\n        cached = self.decorator(maxsize=0)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 0, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:34: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyfifodecoratortesttest_decorator_typed","title":"test_func.py::FIFODecoratorTest::test_decorator_typed","text":"<pre>test_func.py::FIFODecoratorTest::test_decorator_typed</pre><pre>\nself = \n\n    def test_decorator_typed(self):\n        cached = self.decorator(maxsize=2, typed=True)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": True})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:56: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyfifodecoratortesttest_decorator_unbound","title":"test_func.py::FIFODecoratorTest::test_decorator_unbound","text":"<pre>test_func.py::FIFODecoratorTest::test_decorator_unbound</pre><pre>\nself = \n\n    def test_decorator_unbound(self):\n        cached = self.decorator(maxsize=None)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": None, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:45: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyfifodecoratortesttest_decorator_user_function","title":"test_func.py::FIFODecoratorTest::test_decorator_user_function","text":"<pre>test_func.py::FIFODecoratorTest::test_decorator_user_function</pre><pre>\nself = \n\n    def test_decorator_user_function(self):\n        cached = self.decorator(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 128, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:69: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpylfudecoratortesttest_decorator","title":"test_func.py::LFUDecoratorTest::test_decorator","text":"<pre>test_func.py::LFUDecoratorTest::test_decorator</pre><pre>\nself = \n\n    def test_decorator(self):\n        cached = self.decorator(maxsize=2)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:12: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpylfudecoratortesttest_decorator_clear","title":"test_func.py::LFUDecoratorTest::test_decorator_clear","text":"<pre>test_func.py::LFUDecoratorTest::test_decorator_clear</pre><pre>\nself = \n\n    def test_decorator_clear(self):\n        cached = self.decorator(maxsize=2)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:23: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpylfudecoratortesttest_decorator_nocache","title":"test_func.py::LFUDecoratorTest::test_decorator_nocache","text":"<pre>test_func.py::LFUDecoratorTest::test_decorator_nocache</pre><pre>\nself = \n\n    def test_decorator_nocache(self):\n        cached = self.decorator(maxsize=0)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 0, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:34: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpylfudecoratortesttest_decorator_typed","title":"test_func.py::LFUDecoratorTest::test_decorator_typed","text":"<pre>test_func.py::LFUDecoratorTest::test_decorator_typed</pre><pre>\nself = \n\n    def test_decorator_typed(self):\n        cached = self.decorator(maxsize=2, typed=True)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": True})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:56: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpylfudecoratortesttest_decorator_unbound","title":"test_func.py::LFUDecoratorTest::test_decorator_unbound","text":"<pre>test_func.py::LFUDecoratorTest::test_decorator_unbound</pre><pre>\nself = \n\n    def test_decorator_unbound(self):\n        cached = self.decorator(maxsize=None)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": None, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:45: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpylfudecoratortesttest_decorator_user_function","title":"test_func.py::LFUDecoratorTest::test_decorator_user_function","text":"<pre>test_func.py::LFUDecoratorTest::test_decorator_user_function</pre><pre>\nself = \n\n    def test_decorator_user_function(self):\n        cached = self.decorator(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 128, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:69: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpylrudecoratortesttest_decorator","title":"test_func.py::LRUDecoratorTest::test_decorator","text":"<pre>test_func.py::LRUDecoratorTest::test_decorator</pre><pre>\nself = \n\n    def test_decorator(self):\n        cached = self.decorator(maxsize=2)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:12: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpylrudecoratortesttest_decorator_clear","title":"test_func.py::LRUDecoratorTest::test_decorator_clear","text":"<pre>test_func.py::LRUDecoratorTest::test_decorator_clear</pre><pre>\nself = \n\n    def test_decorator_clear(self):\n        cached = self.decorator(maxsize=2)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:23: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpylrudecoratortesttest_decorator_nocache","title":"test_func.py::LRUDecoratorTest::test_decorator_nocache","text":"<pre>test_func.py::LRUDecoratorTest::test_decorator_nocache</pre><pre>\nself = \n\n    def test_decorator_nocache(self):\n        cached = self.decorator(maxsize=0)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 0, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:34: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpylrudecoratortesttest_decorator_typed","title":"test_func.py::LRUDecoratorTest::test_decorator_typed","text":"<pre>test_func.py::LRUDecoratorTest::test_decorator_typed</pre><pre>\nself = \n\n    def test_decorator_typed(self):\n        cached = self.decorator(maxsize=2, typed=True)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": True})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:56: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpylrudecoratortesttest_decorator_unbound","title":"test_func.py::LRUDecoratorTest::test_decorator_unbound","text":"<pre>test_func.py::LRUDecoratorTest::test_decorator_unbound</pre><pre>\nself = \n\n    def test_decorator_unbound(self):\n        cached = self.decorator(maxsize=None)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": None, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:45: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpylrudecoratortesttest_decorator_user_function","title":"test_func.py::LRUDecoratorTest::test_decorator_user_function","text":"<pre>test_func.py::LRUDecoratorTest::test_decorator_user_function</pre><pre>\nself = \n\n    def test_decorator_user_function(self):\n        cached = self.decorator(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 128, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:69: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpymrudecoratortesttest_decorator","title":"test_func.py::MRUDecoratorTest::test_decorator","text":"<pre>test_func.py::MRUDecoratorTest::test_decorator</pre><pre>\nself = \n\n    def test_decorator(self):\n        cached = self.decorator(maxsize=2)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:12: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpymrudecoratortesttest_decorator_clear","title":"test_func.py::MRUDecoratorTest::test_decorator_clear","text":"<pre>test_func.py::MRUDecoratorTest::test_decorator_clear</pre><pre>\nself = \n\n    def test_decorator_clear(self):\n        cached = self.decorator(maxsize=2)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:23: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpymrudecoratortesttest_decorator_nocache","title":"test_func.py::MRUDecoratorTest::test_decorator_nocache","text":"<pre>test_func.py::MRUDecoratorTest::test_decorator_nocache</pre><pre>\nself = \n\n    def test_decorator_nocache(self):\n        cached = self.decorator(maxsize=0)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 0, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:34: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpymrudecoratortesttest_decorator_typed","title":"test_func.py::MRUDecoratorTest::test_decorator_typed","text":"<pre>test_func.py::MRUDecoratorTest::test_decorator_typed</pre><pre>\nself = \n\n    def test_decorator_typed(self):\n        cached = self.decorator(maxsize=2, typed=True)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": True})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:56: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpymrudecoratortesttest_decorator_unbound","title":"test_func.py::MRUDecoratorTest::test_decorator_unbound","text":"<pre>test_func.py::MRUDecoratorTest::test_decorator_unbound</pre><pre>\nself = \n\n    def test_decorator_unbound(self):\n        cached = self.decorator(maxsize=None)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": None, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:45: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpymrudecoratortesttest_decorator_user_function","title":"test_func.py::MRUDecoratorTest::test_decorator_user_function","text":"<pre>test_func.py::MRUDecoratorTest::test_decorator_user_function</pre><pre>\nself = \n\n    def test_decorator_user_function(self):\n        cached = self.decorator(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 128, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:69: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyrrdecoratortesttest_decorator","title":"test_func.py::RRDecoratorTest::test_decorator","text":"<pre>test_func.py::RRDecoratorTest::test_decorator</pre><pre>\nself = \n\n    def test_decorator(self):\n        cached = self.decorator(maxsize=2)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:12: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyrrdecoratortesttest_decorator_clear","title":"test_func.py::RRDecoratorTest::test_decorator_clear","text":"<pre>test_func.py::RRDecoratorTest::test_decorator_clear</pre><pre>\nself = \n\n    def test_decorator_clear(self):\n        cached = self.decorator(maxsize=2)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:23: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyrrdecoratortesttest_decorator_nocache","title":"test_func.py::RRDecoratorTest::test_decorator_nocache","text":"<pre>test_func.py::RRDecoratorTest::test_decorator_nocache</pre><pre>\nself = \n\n    def test_decorator_nocache(self):\n        cached = self.decorator(maxsize=0)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 0, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:34: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyrrdecoratortesttest_decorator_typed","title":"test_func.py::RRDecoratorTest::test_decorator_typed","text":"<pre>test_func.py::RRDecoratorTest::test_decorator_typed</pre><pre>\nself = \n\n    def test_decorator_typed(self):\n        cached = self.decorator(maxsize=2, typed=True)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": True})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:56: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyrrdecoratortesttest_decorator_unbound","title":"test_func.py::RRDecoratorTest::test_decorator_unbound","text":"<pre>test_func.py::RRDecoratorTest::test_decorator_unbound</pre><pre>\nself = \n\n    def test_decorator_unbound(self):\n        cached = self.decorator(maxsize=None)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": None, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:45: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyrrdecoratortesttest_decorator_user_function","title":"test_func.py::RRDecoratorTest::test_decorator_user_function","text":"<pre>test_func.py::RRDecoratorTest::test_decorator_user_function</pre><pre>\nself = \n\n    def test_decorator_user_function(self):\n        cached = self.decorator(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 128, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:69: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyttldecoratortesttest_decorator","title":"test_func.py::TTLDecoratorTest::test_decorator","text":"<pre>test_func.py::TTLDecoratorTest::test_decorator</pre><pre>\nself = \n\n    def test_decorator(self):\n        cached = self.decorator(maxsize=2)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:12: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyttldecoratortesttest_decorator_clear","title":"test_func.py::TTLDecoratorTest::test_decorator_clear","text":"<pre>test_func.py::TTLDecoratorTest::test_decorator_clear</pre><pre>\nself = \n\n    def test_decorator_clear(self):\n        cached = self.decorator(maxsize=2)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:23: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyttldecoratortesttest_decorator_nocache","title":"test_func.py::TTLDecoratorTest::test_decorator_nocache","text":"<pre>test_func.py::TTLDecoratorTest::test_decorator_nocache</pre><pre>\nself = \n\n    def test_decorator_nocache(self):\n        cached = self.decorator(maxsize=0)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 0, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:34: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyttldecoratortesttest_decorator_typed","title":"test_func.py::TTLDecoratorTest::test_decorator_typed","text":"<pre>test_func.py::TTLDecoratorTest::test_decorator_typed</pre><pre>\nself = \n\n    def test_decorator_typed(self):\n        cached = self.decorator(maxsize=2, typed=True)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 2, \"typed\": True})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:56: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyttldecoratortesttest_decorator_unbound","title":"test_func.py::TTLDecoratorTest::test_decorator_unbound","text":"<pre>test_func.py::TTLDecoratorTest::test_decorator_unbound</pre><pre>\nself = \n\n    def test_decorator_unbound(self):\n        cached = self.decorator(maxsize=None)(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": None, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:45: AttributeError"},{"location":"analysis_baseline_cachetools/#test_funcpyttldecoratortesttest_decorator_user_function","title":"test_func.py::TTLDecoratorTest::test_decorator_user_function","text":"<pre>test_func.py::TTLDecoratorTest::test_decorator_user_function</pre><pre>\nself = \n\n    def test_decorator_user_function(self):\n        cached = self.decorator(lambda n: n)\n&gt;       self.assertEqual(cached.cache_parameters(), {\"maxsize\": 128, \"typed\": False})\nE       AttributeError: 'function' object has no attribute 'cache_parameters'\n\ntests/test_func.py:69: AttributeError"},{"location":"analysis_baseline_cachetools/#test_keyspycachekeystesttest_typedkey","title":"test_keys.py::CacheKeysTest::test_typedkey","text":"<pre>test_keys.py::CacheKeysTest::test_typedkey</pre><pre>\nself = \nkey = \n\n    def test_typedkey(self, key=cachetools.keys.typedkey):\n        self.assertEqual(key(), key())\n        self.assertEqual(hash(key()), hash(key()))\n        self.assertEqual(key(1, 2, 3), key(1, 2, 3))\n        self.assertEqual(hash(key(1, 2, 3)), hash(key(1, 2, 3)))\n        self.assertEqual(key(1, 2, 3, x=0), key(1, 2, 3, x=0))\n        self.assertEqual(hash(key(1, 2, 3, x=0)), hash(key(1, 2, 3, x=0)))\n&gt;       self.assertNotEqual(key(1, 2, 3), key(3, 2, 1))\nE       AssertionError: (, , ) == (, , )\n\ntests/test_keys.py:49: AssertionError"},{"location":"analysis_baseline_cachetools/#test_keyspycachekeystesttest_typedmethodkey","title":"test_keys.py::CacheKeysTest::test_typedmethodkey","text":"<pre>test_keys.py::CacheKeysTest::test_typedmethodkey</pre><pre>\nself = \nkey = \n\n    def test_typedmethodkey(self, key=cachetools.keys.typedmethodkey):\n        # similar to typedkey(), but ignores its first positional argument\n        self.assertEqual(key(\"x\"), key(\"y\"))\n        self.assertEqual(hash(key(\"x\")), hash(key(\"y\")))\n        self.assertEqual(key(\"x\", 1, 2, 3), key(\"y\", 1, 2, 3))\n        self.assertEqual(hash(key(\"x\", 1, 2, 3)), hash(key(\"y\", 1, 2, 3)))\n        self.assertEqual(key(\"x\", 1, 2, 3, x=0), key(\"y\", 1, 2, 3, x=0))\n        self.assertEqual(hash(key(\"x\", 1, 2, 3, x=0)), hash(key(\"y\", 1, 2, 3, x=0)))\n&gt;       self.assertNotEqual(key(\"x\", 1, 2, 3), key(\"x\", 3, 2, 1))\nE       AssertionError: (, , , ) == (, , , )\n\ntests/test_keys.py:66: AssertionError"},{"location":"analysis_baseline_cachetools/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/src/cachetools/func.py b/src/cachetools/func.py\nindex 338ef94..d5b9f85 100644\n--- a/src/cachetools/func.py\n+++ b/src/cachetools/func.py\n@@ -25,7 +25,11 @@ def fifo_cache(maxsize=128, typed=False):\n     algorithm.\n\n     \"\"\"\n-    pass\n+    if typed:\n+        key = keys.typedkey\n+    else:\n+        key = keys.hashkey\n+    return cached(cache=FIFOCache(maxsize), key=key)\n\n\n def lfu_cache(maxsize=128, typed=False):\n@@ -34,7 +38,11 @@ def lfu_cache(maxsize=128, typed=False):\n     algorithm.\n\n     \"\"\"\n-    pass\n+    if typed:\n+        key = keys.typedkey\n+    else:\n+        key = keys.hashkey\n+    return cached(cache=LFUCache(maxsize), key=key)\n\n\n def lru_cache(maxsize=128, typed=False):\n@@ -43,7 +51,11 @@ def lru_cache(maxsize=128, typed=False):\n     algorithm.\n\n     \"\"\"\n-    pass\n+    if typed:\n+        key = keys.typedkey\n+    else:\n+        key = keys.hashkey\n+    return cached(cache=LRUCache(maxsize), key=key)\n\n\n def mru_cache(maxsize=128, typed=False):\n@@ -51,7 +63,11 @@ def mru_cache(maxsize=128, typed=False):\n     up to `maxsize` results based on a Most Recently Used (MRU)\n     algorithm.\n     \"\"\"\n-    pass\n+    if typed:\n+        key = keys.typedkey\n+    else:\n+        key = keys.hashkey\n+    return cached(cache=MRUCache(maxsize), key=key)\n\n\n def rr_cache(maxsize=128, choice=random.choice, typed=False):\n@@ -60,7 +76,11 @@ def rr_cache(maxsize=128, choice=random.choice, typed=False):\n     algorithm.\n\n     \"\"\"\n-    pass\n+    if typed:\n+        key = keys.typedkey\n+    else:\n+        key = keys.hashkey\n+    return cached(cache=RRCache(maxsize, choice=choice), key=key)\n\n\n def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n@@ -68,4 +88,8 @@ def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n     up to `maxsize` results based on a Least Recently Used (LRU)\n     algorithm with a per-item time-to-live (TTL) value.\n     \"\"\"\n-    pass\n+    if typed:\n+        key = keys.typedkey\n+    else:\n+        key = keys.hashkey\n+    return cached(cache=TTLCache(maxsize, ttl, timer=timer), key=key)\ndiff --git a/src/cachetools/keys.py b/src/cachetools/keys.py\nindex ed97ffd..700885c 100644\n--- a/src/cachetools/keys.py\n+++ b/src/cachetools/keys.py\n@@ -32,19 +32,29 @@ _kwmark = _HashedTuple,\n\n def hashkey(*args, **kwargs):\n     \"\"\"Return a cache key for the specified hashable arguments.\"\"\"\n-    pass\n+    key = args\n+    if kwargs:\n+        key += (_kwmark,)\n+        for item in kwargs.items():\n+            key += item\n+    return _HashedTuple(key)\n\n\n def methodkey(self, *args, **kwargs):\n     \"\"\"Return a cache key for use with cached methods.\"\"\"\n-    pass\n+    return hashkey(self.__class__, *args, **kwargs)\n\n\n def typedkey(*args, **kwargs):\n     \"\"\"Return a typed cache key for the specified hashable arguments.\"\"\"\n-    pass\n+    key = tuple(type(arg) for arg in args)\n+    if kwargs:\n+        key += (_kwmark,)\n+        for item in kwargs.items():\n+            key += (item[0], type(item[1]))\n+    return _HashedTuple(key)\n\n\n def typedmethodkey(self, *args, **kwargs):\n     \"\"\"Return a typed cache key for use with cached methods.\"\"\"\n-    pass\n+    return typedkey(self.__class__, *args, **kwargs)\n</code></pre>"},{"location":"analysis_baseline_cookiecutter/","title":"Analysis baseline cookiecutter","text":"<p>back to baseline summary</p>"},{"location":"analysis_baseline_cookiecutter/#submission-name-baseline","title":"Submission Name: baseline","text":""},{"location":"analysis_baseline_cookiecutter/#repository-cookiecutter","title":"Repository: cookiecutter","text":""},{"location":"analysis_baseline_cookiecutter/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count failed 270 passed 97 skipped 4 total 371 collected 371"},{"location":"analysis_baseline_cookiecutter/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_baseline_cookiecutter/#test_dumppytest_type_error_if_no_template_name","title":"test_dump.py::test_type_error_if_no_template_name","text":"<pre>test_dump.py::test_type_error_if_no_template_name</pre><pre>\nreplay_test_dir = 'tests/test-replay/'\ncontext = {'cookiecutter': {'email': 'raphael@hackebrot.de', 'full_name': 'Raphael Pierzina', 'github_username': 'hackebrot', 'version': '0.1.0'}}\n\n    def test_type_error_if_no_template_name(replay_test_dir, context):\n        \"\"\"Test that replay.dump raises if the template_name is not a valid str.\"\"\"\n&gt;       with pytest.raises(TypeError):\nE       Failed: DID NOT RAISE \n\ntests/replay/test_dump.py:37: Failed"},{"location":"analysis_baseline_cookiecutter/#test_dumppytest_type_error_if_not_dict_context","title":"test_dump.py::test_type_error_if_not_dict_context","text":"<pre>test_dump.py::test_type_error_if_not_dict_context</pre><pre>\nreplay_test_dir = 'tests/test-replay/', template_name = 'cookiedozer'\n\n    def test_type_error_if_not_dict_context(replay_test_dir, template_name):\n        \"\"\"Test that replay.dump raises if the context is not of type dict.\"\"\"\n&gt;       with pytest.raises(TypeError):\nE       Failed: DID NOT RAISE \n\ntests/replay/test_dump.py:43: Failed"},{"location":"analysis_baseline_cookiecutter/#test_dumppytest_value_error_if_key_missing_in_context","title":"test_dump.py::test_value_error_if_key_missing_in_context","text":"<pre>test_dump.py::test_value_error_if_key_missing_in_context</pre><pre>\nreplay_test_dir = 'tests/test-replay/', template_name = 'cookiedozer'\n\n    def test_value_error_if_key_missing_in_context(replay_test_dir, template_name):\n        \"\"\"Test that replay.dump raises if the context does not contain a key \\\n        named 'cookiecutter'.\"\"\"\n&gt;       with pytest.raises(ValueError):\nE       Failed: DID NOT RAISE \n\ntests/replay/test_dump.py:50: Failed"},{"location":"analysis_baseline_cookiecutter/#test_loadpytest_type_error_if_no_template_name","title":"test_load.py::test_type_error_if_no_template_name","text":"<pre>test_load.py::test_type_error_if_no_template_name</pre><pre>\nreplay_test_dir = 'tests/test-replay/'\n\n    def test_type_error_if_no_template_name(replay_test_dir):\n        \"\"\"Test that replay.load raises if the template_name is not a valid str.\"\"\"\n&gt;       with pytest.raises(TypeError):\nE       Failed: DID NOT RAISE \n\ntests/replay/test_load.py:26: Failed"},{"location":"analysis_baseline_cookiecutter/#test_loadpytest_value_error_if_key_missing_in_context","title":"test_load.py::test_value_error_if_key_missing_in_context","text":"<pre>test_load.py::test_value_error_if_key_missing_in_context</pre><pre>\nmocker = \nreplay_test_dir = 'tests/test-replay/'\n\n    def test_value_error_if_key_missing_in_context(mocker, replay_test_dir):\n        \"\"\"Test that replay.load raises if the loaded context does not contain \\\n        'cookiecutter'.\"\"\"\n&gt;       with pytest.raises(ValueError):\nE       Failed: DID NOT RAISE \n\ntests/replay/test_load.py:33: Failed"},{"location":"analysis_baseline_cookiecutter/#test_replaypytest_get_replay_file_namebarjson","title":"test_replay.py::test_get_replay_file_name[bar.json]","text":"<pre>test_replay.py::test_get_replay_file_name[bar.json]</pre><pre>\nreplay_file_name = 'bar.json'\n\n    @pytest.mark.parametrize(\"replay_file_name\", ['bar', 'bar.json'])\n    def test_get_replay_file_name(replay_file_name):\n        \"\"\"Make sure that replay.get_file_name generates a valid json file path.\"\"\"\n        exp_replay_file_path = os.path.join('foo', 'bar.json')\n        replay_file_path = replay.get_file_name('foo', replay_file_name)\n&gt;       assert replay_file_path == exp_replay_file_path\nE       AssertionError: assert 'foo/bar.json.json' == 'foo/bar.json'\nE         \nE         - foo/bar.json\nE         + foo/bar.json.json\nE         ?             +++++\n\ntests/replay/test_replay.py:15: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_replaypytest_raise_on_invalid_modeinvalid_kwargs0","title":"test_replay.py::test_raise_on_invalid_mode[invalid_kwargs0]","text":"<pre>test_replay.py::test_raise_on_invalid_mode[invalid_kwargs0]</pre><pre>\ninvalid_kwargs = {'no_input': True}\n\n    @pytest.mark.parametrize(\n        'invalid_kwargs',\n        (\n            {'no_input': True},\n            {'extra_context': {}},\n            {'no_input': True, 'extra_context': {}},\n        ),\n    )\n    def test_raise_on_invalid_mode(invalid_kwargs):\n        \"\"\"Test `cookiecutter` raise exception on unacceptable `replay` request.\"\"\"\n        with pytest.raises(exceptions.InvalidModeException):\n&gt;           main.cookiecutter('foo', replay=True, **invalid_kwargs)\n\ntests/replay/test_replay.py:29: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'foo', checkout = None, no_input = True, extra_context = None\nreplay = True, overwrite_if_exists = False, output_dir = '.', config_file = None\ndefault_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_replaypytest_raise_on_invalid_modeinvalid_kwargs1","title":"test_replay.py::test_raise_on_invalid_mode[invalid_kwargs1]","text":"<pre>test_replay.py::test_raise_on_invalid_mode[invalid_kwargs1]</pre><pre>\ninvalid_kwargs = {'extra_context': {}}\n\n    @pytest.mark.parametrize(\n        'invalid_kwargs',\n        (\n            {'no_input': True},\n            {'extra_context': {}},\n            {'no_input': True, 'extra_context': {}},\n        ),\n    )\n    def test_raise_on_invalid_mode(invalid_kwargs):\n        \"\"\"Test `cookiecutter` raise exception on unacceptable `replay` request.\"\"\"\n        with pytest.raises(exceptions.InvalidModeException):\n&gt;           main.cookiecutter('foo', replay=True, **invalid_kwargs)\n\ntests/replay/test_replay.py:29: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'foo', checkout = None, no_input = False, extra_context = {}\nreplay = True, overwrite_if_exists = False, output_dir = '.', config_file = None\ndefault_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_replaypytest_raise_on_invalid_modeinvalid_kwargs2","title":"test_replay.py::test_raise_on_invalid_mode[invalid_kwargs2]","text":"<pre>test_replay.py::test_raise_on_invalid_mode[invalid_kwargs2]</pre><pre>\ninvalid_kwargs = {'extra_context': {}, 'no_input': True}\n\n    @pytest.mark.parametrize(\n        'invalid_kwargs',\n        (\n            {'no_input': True},\n            {'extra_context': {}},\n            {'no_input': True, 'extra_context': {}},\n        ),\n    )\n    def test_raise_on_invalid_mode(invalid_kwargs):\n        \"\"\"Test `cookiecutter` raise exception on unacceptable `replay` request.\"\"\"\n        with pytest.raises(exceptions.InvalidModeException):\n&gt;           main.cookiecutter('foo', replay=True, **invalid_kwargs)\n\ntests/replay/test_replay.py:29: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'foo', checkout = None, no_input = True, extra_context = {}\nreplay = True, overwrite_if_exists = False, output_dir = '.', config_file = None\ndefault_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_replaypytest_main_does_not_invoke_dump_but_load","title":"test_replay.py::test_main_does_not_invoke_dump_but_load","text":"<pre>test_replay.py::test_main_does_not_invoke_dump_but_load</pre><pre>\nmocker = \n\n    def test_main_does_not_invoke_dump_but_load(mocker):\n        \"\"\"Test `cookiecutter` calling correct functions on `replay`.\"\"\"\n        mock_prompt = mocker.patch('cookiecutter.main.prompt_for_config')\n        mock_gen_context = mocker.patch('cookiecutter.main.generate_context')\n        mock_gen_files = mocker.patch('cookiecutter.main.generate_files')\n        mock_replay_dump = mocker.patch('cookiecutter.main.dump')\n        mock_replay_load = mocker.patch('cookiecutter.main.load')\n\n&gt;       main.cookiecutter('tests/fake-repo-tmpl/', replay=True)\n\ntests/replay/test_replay.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/fake-repo-tmpl/', checkout = None, no_input = False\nextra_context = None, replay = True, overwrite_if_exists = False\noutput_dir = '.', config_file = None, default_config = False, password = None\ndirectory = None, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_replaypytest_main_does_not_invoke_load_but_dump","title":"test_replay.py::test_main_does_not_invoke_load_but_dump","text":"<pre>test_replay.py::test_main_does_not_invoke_load_but_dump</pre><pre>\nmocker = \n\n    def test_main_does_not_invoke_load_but_dump(mocker):\n        \"\"\"Test `cookiecutter` calling correct functions on non-replay launch.\"\"\"\n        mock_prompt = mocker.patch('cookiecutter.main.prompt_for_config')\n        mock_gen_context = mocker.patch('cookiecutter.main.generate_context')\n        mock_gen_files = mocker.patch('cookiecutter.main.generate_files')\n        mock_replay_dump = mocker.patch('cookiecutter.main.dump')\n        mock_replay_load = mocker.patch('cookiecutter.main.load')\n\n&gt;       main.cookiecutter('tests/fake-repo-tmpl/', replay=False)\n\ntests/replay/test_replay.py:57: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/fake-repo-tmpl/', checkout = None, no_input = False\nextra_context = None, replay = False, overwrite_if_exists = False\noutput_dir = '.', config_file = None, default_config = False, password = None\ndirectory = None, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_abbreviation_expansionpytest_abbreviation_expansionexpansion-prefix","title":"test_abbreviation_expansion.py::test_abbreviation_expansion[Expansion prefix]","text":"<pre>test_abbreviation_expansion.py::test_abbreviation_expansion[Expansion prefix]</pre><pre>\ntemplate = 'xx:a', abbreviations = {'xx': '&lt;{0}&gt;'}, expected_result = ''\n\n    @pytest.mark.parametrize(\n        ('template', 'abbreviations', 'expected_result'),\n        [\n            ('foo', {'foo': 'bar'}, 'bar'),\n            ('baz', {'foo': 'bar'}, 'baz'),\n            ('xx:a', {'xx': '&lt;{0}&gt;'}, ''),\n            ('gh:a', {'gh': '&lt;{0}&gt;'}, ''),\n            ('xx:a', {'xx': '&lt;&gt;'}, '&lt;&gt;'),\n            (\n                'gh:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://github.com/pydanny/cookiecutter-django.git',\n            ),\n            (\n                'gl:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://gitlab.com/pydanny/cookiecutter-django.git',\n            ),\n            (\n                'bb:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://bitbucket.org/pydanny/cookiecutter-django',\n            ),\n        ],\n        ids=(\n            'Simple expansion',\n            'Skip expansion (expansion not an abbreviation)',\n            'Expansion prefix',\n            'expansion_override_builtin',\n            'expansion_prefix_ignores_suffix',\n            'Correct expansion for builtin abbreviations (github)',\n            'Correct expansion for builtin abbreviations (gitlab)',\n            'Correct expansion for builtin abbreviations (bitbucket)',\n        ),\n    )\n    def test_abbreviation_expansion(template, abbreviations, expected_result):\n        \"\"\"Verify abbreviation unpacking.\"\"\"\n        expanded = expand_abbreviations(template, abbreviations)\n&gt;       assert expanded == expected_result\nE       AssertionError: assert 'xx:a' == ''\nE         \nE         - \nE         + xx:a\n\ntests/repository/test_abbreviation_expansion.py:47: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_abbreviation_expansionpytest_abbreviation_expansionexpansion_override_builtin","title":"test_abbreviation_expansion.py::test_abbreviation_expansion[expansion_override_builtin]","text":"<pre>test_abbreviation_expansion.py::test_abbreviation_expansion[expansion_override_builtin]</pre><pre>\ntemplate = 'gh:a', abbreviations = {'gh': '&lt;{0}&gt;'}, expected_result = ''\n\n    @pytest.mark.parametrize(\n        ('template', 'abbreviations', 'expected_result'),\n        [\n            ('foo', {'foo': 'bar'}, 'bar'),\n            ('baz', {'foo': 'bar'}, 'baz'),\n            ('xx:a', {'xx': '&lt;{0}&gt;'}, ''),\n            ('gh:a', {'gh': '&lt;{0}&gt;'}, ''),\n            ('xx:a', {'xx': '&lt;&gt;'}, '&lt;&gt;'),\n            (\n                'gh:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://github.com/pydanny/cookiecutter-django.git',\n            ),\n            (\n                'gl:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://gitlab.com/pydanny/cookiecutter-django.git',\n            ),\n            (\n                'bb:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://bitbucket.org/pydanny/cookiecutter-django',\n            ),\n        ],\n        ids=(\n            'Simple expansion',\n            'Skip expansion (expansion not an abbreviation)',\n            'Expansion prefix',\n            'expansion_override_builtin',\n            'expansion_prefix_ignores_suffix',\n            'Correct expansion for builtin abbreviations (github)',\n            'Correct expansion for builtin abbreviations (gitlab)',\n            'Correct expansion for builtin abbreviations (bitbucket)',\n        ),\n    )\n    def test_abbreviation_expansion(template, abbreviations, expected_result):\n        \"\"\"Verify abbreviation unpacking.\"\"\"\n        expanded = expand_abbreviations(template, abbreviations)\n&gt;       assert expanded == expected_result\nE       AssertionError: assert 'gh:a' == ''\nE         \nE         - \nE         + gh:a\n\ntests/repository/test_abbreviation_expansion.py:47: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_abbreviation_expansionpytest_abbreviation_expansionexpansion_prefix_ignores_suffix","title":"test_abbreviation_expansion.py::test_abbreviation_expansion[expansion_prefix_ignores_suffix]","text":"<pre>test_abbreviation_expansion.py::test_abbreviation_expansion[expansion_prefix_ignores_suffix]</pre><pre>\ntemplate = 'xx:a', abbreviations = {'xx': '&lt;&gt;'}, expected_result = '&lt;&gt;'\n\n    @pytest.mark.parametrize(\n        ('template', 'abbreviations', 'expected_result'),\n        [\n            ('foo', {'foo': 'bar'}, 'bar'),\n            ('baz', {'foo': 'bar'}, 'baz'),\n            ('xx:a', {'xx': '&lt;{0}&gt;'}, ''),\n            ('gh:a', {'gh': '&lt;{0}&gt;'}, ''),\n            ('xx:a', {'xx': '&lt;&gt;'}, '&lt;&gt;'),\n            (\n                'gh:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://github.com/pydanny/cookiecutter-django.git',\n            ),\n            (\n                'gl:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://gitlab.com/pydanny/cookiecutter-django.git',\n            ),\n            (\n                'bb:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://bitbucket.org/pydanny/cookiecutter-django',\n            ),\n        ],\n        ids=(\n            'Simple expansion',\n            'Skip expansion (expansion not an abbreviation)',\n            'Expansion prefix',\n            'expansion_override_builtin',\n            'expansion_prefix_ignores_suffix',\n            'Correct expansion for builtin abbreviations (github)',\n            'Correct expansion for builtin abbreviations (gitlab)',\n            'Correct expansion for builtin abbreviations (bitbucket)',\n        ),\n    )\n    def test_abbreviation_expansion(template, abbreviations, expected_result):\n        \"\"\"Verify abbreviation unpacking.\"\"\"\n        expanded = expand_abbreviations(template, abbreviations)\n&gt;       assert expanded == expected_result\nE       AssertionError: assert 'xx:a' == '&lt;&gt;'\nE         \nE         - &lt;&gt;\nE         + xx:a\n\ntests/repository/test_abbreviation_expansion.py:47: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_abbreviation_expansionpytest_abbreviation_expansioncorrect-expansion-for-builtin-abbreviations-github","title":"test_abbreviation_expansion.py::test_abbreviation_expansion[Correct expansion for builtin abbreviations (github)]","text":"<pre>test_abbreviation_expansion.py::test_abbreviation_expansion[Correct expansion for builtin abbreviations (github)]</pre><pre>\ntemplate = 'gh:pydanny/cookiecutter-django'\nabbreviations = {'bb': 'https://bitbucket.org/{0}', 'gh': 'https://github.com/{0}.git', 'gl': 'https://gitlab.com/{0}.git'}\nexpected_result = 'https://github.com/pydanny/cookiecutter-django.git'\n\n    @pytest.mark.parametrize(\n        ('template', 'abbreviations', 'expected_result'),\n        [\n            ('foo', {'foo': 'bar'}, 'bar'),\n            ('baz', {'foo': 'bar'}, 'baz'),\n            ('xx:a', {'xx': '&lt;{0}&gt;'}, ''),\n            ('gh:a', {'gh': '&lt;{0}&gt;'}, ''),\n            ('xx:a', {'xx': '&lt;&gt;'}, '&lt;&gt;'),\n            (\n                'gh:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://github.com/pydanny/cookiecutter-django.git',\n            ),\n            (\n                'gl:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://gitlab.com/pydanny/cookiecutter-django.git',\n            ),\n            (\n                'bb:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://bitbucket.org/pydanny/cookiecutter-django',\n            ),\n        ],\n        ids=(\n            'Simple expansion',\n            'Skip expansion (expansion not an abbreviation)',\n            'Expansion prefix',\n            'expansion_override_builtin',\n            'expansion_prefix_ignores_suffix',\n            'Correct expansion for builtin abbreviations (github)',\n            'Correct expansion for builtin abbreviations (gitlab)',\n            'Correct expansion for builtin abbreviations (bitbucket)',\n        ),\n    )\n    def test_abbreviation_expansion(template, abbreviations, expected_result):\n        \"\"\"Verify abbreviation unpacking.\"\"\"\n        expanded = expand_abbreviations(template, abbreviations)\n&gt;       assert expanded == expected_result\nE       AssertionError: assert 'gh:pydanny/cookiecutter-django' == 'https://github.com/pydanny/cookiecutter-django.git'\nE         \nE         - https://github.com/pydanny/cookiecutter-django.git\nE         + gh:pydanny/cookiecutter-django\n\ntests/repository/test_abbreviation_expansion.py:47: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_abbreviation_expansionpytest_abbreviation_expansioncorrect-expansion-for-builtin-abbreviations-gitlab","title":"test_abbreviation_expansion.py::test_abbreviation_expansion[Correct expansion for builtin abbreviations (gitlab)]","text":"<pre>test_abbreviation_expansion.py::test_abbreviation_expansion[Correct expansion for builtin abbreviations (gitlab)]</pre><pre>\ntemplate = 'gl:pydanny/cookiecutter-django'\nabbreviations = {'bb': 'https://bitbucket.org/{0}', 'gh': 'https://github.com/{0}.git', 'gl': 'https://gitlab.com/{0}.git'}\nexpected_result = 'https://gitlab.com/pydanny/cookiecutter-django.git'\n\n    @pytest.mark.parametrize(\n        ('template', 'abbreviations', 'expected_result'),\n        [\n            ('foo', {'foo': 'bar'}, 'bar'),\n            ('baz', {'foo': 'bar'}, 'baz'),\n            ('xx:a', {'xx': '&lt;{0}&gt;'}, ''),\n            ('gh:a', {'gh': '&lt;{0}&gt;'}, ''),\n            ('xx:a', {'xx': '&lt;&gt;'}, '&lt;&gt;'),\n            (\n                'gh:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://github.com/pydanny/cookiecutter-django.git',\n            ),\n            (\n                'gl:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://gitlab.com/pydanny/cookiecutter-django.git',\n            ),\n            (\n                'bb:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://bitbucket.org/pydanny/cookiecutter-django',\n            ),\n        ],\n        ids=(\n            'Simple expansion',\n            'Skip expansion (expansion not an abbreviation)',\n            'Expansion prefix',\n            'expansion_override_builtin',\n            'expansion_prefix_ignores_suffix',\n            'Correct expansion for builtin abbreviations (github)',\n            'Correct expansion for builtin abbreviations (gitlab)',\n            'Correct expansion for builtin abbreviations (bitbucket)',\n        ),\n    )\n    def test_abbreviation_expansion(template, abbreviations, expected_result):\n        \"\"\"Verify abbreviation unpacking.\"\"\"\n        expanded = expand_abbreviations(template, abbreviations)\n&gt;       assert expanded == expected_result\nE       AssertionError: assert 'gl:pydanny/cookiecutter-django' == 'https://gitlab.com/pydanny/cookiecutter-django.git'\nE         \nE         - https://gitlab.com/pydanny/cookiecutter-django.git\nE         + gl:pydanny/cookiecutter-django\n\ntests/repository/test_abbreviation_expansion.py:47: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_abbreviation_expansionpytest_abbreviation_expansioncorrect-expansion-for-builtin-abbreviations-bitbucket","title":"test_abbreviation_expansion.py::test_abbreviation_expansion[Correct expansion for builtin abbreviations (bitbucket)]","text":"<pre>test_abbreviation_expansion.py::test_abbreviation_expansion[Correct expansion for builtin abbreviations (bitbucket)]</pre><pre>\ntemplate = 'bb:pydanny/cookiecutter-django'\nabbreviations = {'bb': 'https://bitbucket.org/{0}', 'gh': 'https://github.com/{0}.git', 'gl': 'https://gitlab.com/{0}.git'}\nexpected_result = 'https://bitbucket.org/pydanny/cookiecutter-django'\n\n    @pytest.mark.parametrize(\n        ('template', 'abbreviations', 'expected_result'),\n        [\n            ('foo', {'foo': 'bar'}, 'bar'),\n            ('baz', {'foo': 'bar'}, 'baz'),\n            ('xx:a', {'xx': '&lt;{0}&gt;'}, ''),\n            ('gh:a', {'gh': '&lt;{0}&gt;'}, ''),\n            ('xx:a', {'xx': '&lt;&gt;'}, '&lt;&gt;'),\n            (\n                'gh:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://github.com/pydanny/cookiecutter-django.git',\n            ),\n            (\n                'gl:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://gitlab.com/pydanny/cookiecutter-django.git',\n            ),\n            (\n                'bb:pydanny/cookiecutter-django',\n                BUILTIN_ABBREVIATIONS,\n                'https://bitbucket.org/pydanny/cookiecutter-django',\n            ),\n        ],\n        ids=(\n            'Simple expansion',\n            'Skip expansion (expansion not an abbreviation)',\n            'Expansion prefix',\n            'expansion_override_builtin',\n            'expansion_prefix_ignores_suffix',\n            'Correct expansion for builtin abbreviations (github)',\n            'Correct expansion for builtin abbreviations (gitlab)',\n            'Correct expansion for builtin abbreviations (bitbucket)',\n        ),\n    )\n    def test_abbreviation_expansion(template, abbreviations, expected_result):\n        \"\"\"Verify abbreviation unpacking.\"\"\"\n        expanded = expand_abbreviations(template, abbreviations)\n&gt;       assert expanded == expected_result\nE       AssertionError: assert 'bb:pydanny/cookiecutter-django' == 'https://bitbucket.org/pydanny/cookiecutter-django'\nE         \nE         - https://bitbucket.org/pydanny/cookiecutter-django\nE         + bb:pydanny/cookiecutter-django\n\ntests/repository/test_abbreviation_expansion.py:47: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_abbreviation_expansionpytest_abbreviation_expansion_prefix_not_0_in_braces","title":"test_abbreviation_expansion.py::test_abbreviation_expansion_prefix_not_0_in_braces","text":"<pre>test_abbreviation_expansion.py::test_abbreviation_expansion_prefix_not_0_in_braces</pre><pre>\ndef test_abbreviation_expansion_prefix_not_0_in_braces():\n        \"\"\"Verify abbreviation unpacking raises error on incorrect index.\"\"\"\n&gt;       with pytest.raises(IndexError):\nE       Failed: DID NOT RAISE \n\ntests/repository/test_abbreviation_expansion.py:52: Failed"},{"location":"analysis_baseline_cookiecutter/#zipfilezip-true","title":"zipfile.zip-True]","text":"<pre>zipfile.zip-True]</pre><pre>\nmocker = \ntemplate = 'https://example.com/path/to/zipfile.zip', is_url = True\nuser_config_data = {'cookiecutters_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters', 'replay_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutter_replay'}\n\n    @pytest.mark.parametrize(\n        'template, is_url',\n        [\n            ('/path/to/zipfile.zip', False),\n            ('https://example.com/path/to/zipfile.zip', True),\n            ('http://example.com/path/to/zipfile.zip', True),\n        ],\n    )\n    def test_zipfile_unzip(mocker, template, is_url, user_config_data):\n        \"\"\"Verify zip files correctly handled for different source locations.\n\n        `unzip()` should be called with correct args when `determine_repo_dir()`\n        is passed a zipfile, or a URL to a zipfile.\n        \"\"\"\n        mock_clone = mocker.patch(\n            'cookiecutter.repository.unzip',\n            return_value='tests/fake-repo-tmpl',\n            autospec=True,\n        )\n\n&gt;       project_dir, cleanup = repository.determine_repo_dir(\n            template,\n            abbreviations={},\n            clone_to_dir=user_config_data['cookiecutters_dir'],\n            checkout=None,\n            no_input=True,\n            password=None,\n        )\n\ntests/repository/test_determine_repo_dir_clones_repo.py:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/repository.py:78: in determine_repo_dir\n    repo_dir = clone(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_url = 'https://example.com/path/to/zipfile.zip', checkout = None\nclone_to_dir = '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters'\nno_input = True\n\n    def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n        'os.PathLike[str]'='.', no_input: bool=False):\n        \"\"\"Clone a repo to the current directory.\n\n        :param repo_url: Repo URL of unknown type.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param clone_to_dir: The directory to clone to.\n                             Defaults to the current directory.\n        :param no_input: Do not prompt for user input and eventually force a refresh of\n            cached resources.\n        :returns: str with path to the new directory of the repository.\n        \"\"\"\n&gt;       repo_type, repo_url = identify_repo(repo_url)\nE       TypeError: cannot unpack non-iterable NoneType object\n\ncookiecutter/vcs.py:61: TypeError"},{"location":"analysis_baseline_cookiecutter/#zipfilezip-true_1","title":"zipfile.zip-True]","text":"<pre>zipfile.zip-True]</pre><pre>\nmocker = \ntemplate = 'http://example.com/path/to/zipfile.zip', is_url = True\nuser_config_data = {'cookiecutters_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters', 'replay_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutter_replay'}\n\n    @pytest.mark.parametrize(\n        'template, is_url',\n        [\n            ('/path/to/zipfile.zip', False),\n            ('https://example.com/path/to/zipfile.zip', True),\n            ('http://example.com/path/to/zipfile.zip', True),\n        ],\n    )\n    def test_zipfile_unzip(mocker, template, is_url, user_config_data):\n        \"\"\"Verify zip files correctly handled for different source locations.\n\n        `unzip()` should be called with correct args when `determine_repo_dir()`\n        is passed a zipfile, or a URL to a zipfile.\n        \"\"\"\n        mock_clone = mocker.patch(\n            'cookiecutter.repository.unzip',\n            return_value='tests/fake-repo-tmpl',\n            autospec=True,\n        )\n\n&gt;       project_dir, cleanup = repository.determine_repo_dir(\n            template,\n            abbreviations={},\n            clone_to_dir=user_config_data['cookiecutters_dir'],\n            checkout=None,\n            no_input=True,\n            password=None,\n        )\n\ntests/repository/test_determine_repo_dir_clones_repo.py:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/repository.py:78: in determine_repo_dir\n    repo_dir = clone(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_url = 'http://example.com/path/to/zipfile.zip', checkout = None\nclone_to_dir = '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters'\nno_input = True\n\n    def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n        'os.PathLike[str]'='.', no_input: bool=False):\n        \"\"\"Clone a repo to the current directory.\n\n        :param repo_url: Repo URL of unknown type.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param clone_to_dir: The directory to clone to.\n                             Defaults to the current directory.\n        :param no_input: Do not prompt for user input and eventually force a refresh of\n            cached resources.\n        :returns: str with path to the new directory of the repository.\n        \"\"\"\n&gt;       repo_type, repo_url = identify_repo(repo_url)\nE       TypeError: cannot unpack non-iterable NoneType object\n\ncookiecutter/vcs.py:61: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_determine_repo_dir_clones_repopytest_repository_url_should_clone","title":"test_determine_repo_dir_clones_repo.py::test_repository_url_should_clone","text":"<pre>test_determine_repo_dir_clones_repo.py::test_repository_url_should_clone</pre><pre>\nmocker = \ntemplate_url = 'https://github.com/pytest-dev/cookiecutter-pytest-plugin.git'\nuser_config_data = {'cookiecutters_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters', 'replay_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutter_replay'}\n\n    def test_repository_url_should_clone(mocker, template_url, user_config_data):\n        \"\"\"Verify repository url triggers clone function.\n\n        `clone()` should be called with correct args when `determine_repo_dir()` is\n        passed a repository template url.\n        \"\"\"\n        mock_clone = mocker.patch(\n            'cookiecutter.repository.clone',\n            return_value='tests/fake-repo-tmpl',\n            autospec=True,\n        )\n\n        project_dir, cleanup = repository.determine_repo_dir(\n            template_url,\n            abbreviations={},\n            clone_to_dir=user_config_data['cookiecutters_dir'],\n            checkout=None,\n            no_input=True,\n        )\n\n        mock_clone.assert_called_once_with(\n            repo_url=template_url,\n            checkout=None,\n            clone_to_dir=user_config_data['cookiecutters_dir'],\n            no_input=True,\n        )\n\n        assert os.path.isdir(project_dir)\n&gt;       assert not cleanup\nE       assert not True\n\ntests/repository/test_determine_repo_dir_clones_repo.py:89: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_determine_repo_dir_clones_repopytest_repository_url_with_no_context_file","title":"test_determine_repo_dir_clones_repo.py::test_repository_url_with_no_context_file","text":"<pre>test_determine_repo_dir_clones_repo.py::test_repository_url_with_no_context_file</pre><pre>\nmocker = \ntemplate_url = 'https://github.com/pytest-dev/cookiecutter-pytest-plugin.git'\nuser_config_data = {'cookiecutters_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters', 'replay_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutter_replay'}\n\n    def test_repository_url_with_no_context_file(mocker, template_url, user_config_data):\n        \"\"\"Verify cloned repository without `cookiecutter.json` file raises error.\"\"\"\n        mocker.patch(\n            'cookiecutter.repository.clone',\n            return_value='tests/fake-repo-bad',\n            autospec=True,\n        )\n\n        with pytest.raises(exceptions.RepositoryNotFound) as err:\n            repository.determine_repo_dir(\n                template_url,\n                abbreviations={},\n                clone_to_dir=None,\n                checkout=None,\n                no_input=True,\n            )\n\n&gt;       assert str(err.value) == (\n            'A valid repository for \"{}\" could not be found in the following '\n            'locations:\\n{}'.format(template_url, 'tests/fake-repo-bad')\n        )\nE       assert 'The repository tests/fake-repo-bad does not contain a cookiecutter.json file' == 'A valid repository for \"https://github.com/pytest-dev/cookiecutter-pytest-plugin.git\" could not be found in the following locations:\\ntests/fake-repo-bad'\nE         \nE         + The repository tests/fake-repo-bad does not contain a cookiecutter.json file\nE         - A valid repository for \"https://github.com/pytest-dev/cookiecutter-pytest-plugin.git\" could not be found in the following locations:\nE         - tests/fake-repo-bad\n\ntests/repository/test_determine_repo_dir_clones_repo.py:110: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_determine_repo_dir_finds_existing_cookiecutterpytest_should_find_existing_cookiecutter","title":"test_determine_repo_dir_finds_existing_cookiecutter.py::test_should_find_existing_cookiecutter","text":"<pre>test_determine_repo_dir_finds_existing_cookiecutter.py::test_should_find_existing_cookiecutter</pre><pre>\ntemplate = 'cookiecutter-pytest-plugin'\nuser_config_data = {'cookiecutters_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters', 'replay_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutter_replay'}\ncloned_cookiecutter_path = '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters/cookiecutter-pytest-plugin'\n\n    def test_should_find_existing_cookiecutter(\n        template, user_config_data, cloned_cookiecutter_path\n    ):\n        \"\"\"\n        Should find folder created by `cloned_cookiecutter_path` and return it.\n\n        This folder is considered like previously cloned project directory.\n        \"\"\"\n&gt;       project_dir, cleanup = repository.determine_repo_dir(\n            template=template,\n            abbreviations={},\n            clone_to_dir=user_config_data['cookiecutters_dir'],\n            checkout=None,\n            no_input=True,\n        )\n\ntests/repository/test_determine_repo_dir_finds_existing_cookiecutter.py:38: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'cookiecutter-pytest-plugin', abbreviations = {}\nclone_to_dir = '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters'\ncheckout = None, no_input = True, password = None, directory = None\n\n    def determine_repo_dir(template, abbreviations, clone_to_dir, checkout,\n        no_input, password=None, directory=None):\n        \"\"\"\n        Locate the repository directory from a template reference.\n\n        Applies repository abbreviations to the template reference.\n        If the template refers to a repository URL, clone it.\n        If the template is a path to a local repository, use it.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param abbreviations: A dictionary of repository abbreviation\n            definitions.\n        :param clone_to_dir: The directory to clone the repository into.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input and eventually force a refresh of\n            cached resources.\n        :param password: The password to use when extracting the repository.\n        :param directory: Directory within repo where cookiecutter.json lives.\n        :return: A tuple containing the cookiecutter template directory, and\n            a boolean describing whether that directory should be cleaned up\n            after the template has been instantiated.\n        :raises: `RepositoryNotFound` if a repository directory could not be found.\n        \"\"\"\n        template = expand_abbreviations(template, abbreviations)\n\n        if is_repo_url(template):\n            repo_dir = clone(\n                repo_url=template,\n                checkout=checkout,\n                clone_to_dir=clone_to_dir,\n                no_input=no_input\n            )\n            cleanup = True\n        elif is_zip_file(template):\n            repo_dir = unzip(\n                zip_uri=template,\n                is_url=is_repo_url(template),\n                clone_to_dir=clone_to_dir,\n                no_input=no_input,\n                password=password\n            )\n            cleanup = True\n        else:\n            repo_dir = template\n            cleanup = False\n\n        if directory:\n            repo_dir = os.path.join(repo_dir, directory)\n\n        if not repository_has_cookiecutter_json(repo_dir):\n&gt;           raise RepositoryNotFound(\n                'The repository {} does not contain a cookiecutter.json file'.format(repo_dir)\n            )\nE           cookiecutter.exceptions.RepositoryNotFound: The repository cookiecutter-pytest-plugin does not contain a cookiecutter.json file\n\ncookiecutter/repository.py:102: RepositoryNotFound\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_determine_repo_dir_finds_subdirectoriespytest_should_find_existing_cookiecutter","title":"test_determine_repo_dir_finds_subdirectories.py::test_should_find_existing_cookiecutter","text":"<pre>test_determine_repo_dir_finds_subdirectories.py::test_should_find_existing_cookiecutter</pre><pre>\ntemplate = 'cookiecutter-pytest-plugin'\nuser_config_data = {'cookiecutters_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters', 'replay_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutter_replay'}\ncloned_cookiecutter_path = '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters/cookiecutter-pytest-plugin/my-dir'\n\n    def test_should_find_existing_cookiecutter(\n        template, user_config_data, cloned_cookiecutter_path\n    ):\n        \"\"\"Find `cookiecutter.json` in sub folder created by `cloned_cookiecutter_path`.\"\"\"\n&gt;       project_dir, cleanup = repository.determine_repo_dir(\n            template=template,\n            abbreviations={},\n            clone_to_dir=user_config_data['cookiecutters_dir'],\n            checkout=None,\n            no_input=True,\n            directory='my-dir',\n        )\n\ntests/repository/test_determine_repo_dir_finds_subdirectories.py:38: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'cookiecutter-pytest-plugin', abbreviations = {}\nclone_to_dir = '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters'\ncheckout = None, no_input = True, password = None, directory = 'my-dir'\n\n    def determine_repo_dir(template, abbreviations, clone_to_dir, checkout,\n        no_input, password=None, directory=None):\n        \"\"\"\n        Locate the repository directory from a template reference.\n\n        Applies repository abbreviations to the template reference.\n        If the template refers to a repository URL, clone it.\n        If the template is a path to a local repository, use it.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param abbreviations: A dictionary of repository abbreviation\n            definitions.\n        :param clone_to_dir: The directory to clone the repository into.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input and eventually force a refresh of\n            cached resources.\n        :param password: The password to use when extracting the repository.\n        :param directory: Directory within repo where cookiecutter.json lives.\n        :return: A tuple containing the cookiecutter template directory, and\n            a boolean describing whether that directory should be cleaned up\n            after the template has been instantiated.\n        :raises: `RepositoryNotFound` if a repository directory could not be found.\n        \"\"\"\n        template = expand_abbreviations(template, abbreviations)\n\n        if is_repo_url(template):\n            repo_dir = clone(\n                repo_url=template,\n                checkout=checkout,\n                clone_to_dir=clone_to_dir,\n                no_input=no_input\n            )\n            cleanup = True\n        elif is_zip_file(template):\n            repo_dir = unzip(\n                zip_uri=template,\n                is_url=is_repo_url(template),\n                clone_to_dir=clone_to_dir,\n                no_input=no_input,\n                password=password\n            )\n            cleanup = True\n        else:\n            repo_dir = template\n            cleanup = False\n\n        if directory:\n            repo_dir = os.path.join(repo_dir, directory)\n\n        if not repository_has_cookiecutter_json(repo_dir):\n&gt;           raise RepositoryNotFound(\n                'The repository {} does not contain a cookiecutter.json file'.format(repo_dir)\n            )\nE           cookiecutter.exceptions.RepositoryNotFound: The repository cookiecutter-pytest-plugin/my-dir does not contain a cookiecutter.json file\n\ncookiecutter/repository.py:102: RepositoryNotFound\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_determine_repo_dir_finds_subdirectoriespytest_local_repo_typo","title":"test_determine_repo_dir_finds_subdirectories.py::test_local_repo_typo","text":"<pre>test_determine_repo_dir_finds_subdirectories.py::test_local_repo_typo</pre><pre>\ntemplate = 'cookiecutter-pytest-plugin'\nuser_config_data = {'cookiecutters_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters', 'replay_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutter_replay'}\ncloned_cookiecutter_path = '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters/cookiecutter-pytest-plugin/my-dir'\n\n    def test_local_repo_typo(template, user_config_data, cloned_cookiecutter_path):\n        \"\"\"Wrong pointing to `cookiecutter.json` sub-directory should raise.\"\"\"\n        with pytest.raises(exceptions.RepositoryNotFound) as err:\n            repository.determine_repo_dir(\n                template=template,\n                abbreviations={},\n                clone_to_dir=user_config_data['cookiecutters_dir'],\n                checkout=None,\n                no_input=True,\n                directory='wrong-dir',\n            )\n\n        wrong_full_cookiecutter_path = os.path.join(\n            os.path.dirname(cloned_cookiecutter_path), 'wrong-dir'\n        )\n&gt;       assert str(err.value) == (\n            'A valid repository for \"{}\" could not be found in the following '\n            'locations:\\n{}'.format(\n                template,\n                '\\n'.join(\n                    [os.path.join(template, 'wrong-dir'), wrong_full_cookiecutter_path]\n                ),\n            )\n        )\nE       assert 'The repository cookiecutter-pytest-plugin/wrong-dir does not contain a cookiecutter.json file' == 'A valid repository for \"cookiecutter-pytest-plugin\" could not be found in the following locations:\\ncookiecutter-pytest-plugin/wrong-dir\\n/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters/cookiecutter-pytest-plugin/wrong-dir'\nE         \nE         + The repository cookiecutter-pytest-plugin/wrong-dir does not contain a cookiecutter.json file\nE         - A valid repository for \"cookiecutter-pytest-plugin\" could not be found in the following locations:\nE         - cookiecutter-pytest-plugin/wrong-dir\nE         - /tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters/cookiecutter-pytest-plugin/wrong-dir\n\ntests/repository/test_determine_repo_dir_finds_subdirectories.py:66: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_determine_repository_should_use_local_repopytest_local_repo_with_no_context_raises","title":"test_determine_repository_should_use_local_repo.py::test_local_repo_with_no_context_raises","text":"<pre>test_determine_repository_should_use_local_repo.py::test_local_repo_with_no_context_raises</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_local_repo_with_no_contex0')\n\n    def test_local_repo_with_no_context_raises(tmp_path):\n        \"\"\"A local repository without a cookiecutter.json should raise a \\\n        `RepositoryNotFound` exception.\"\"\"\n        template_path = str(Path('tests', 'fake-repo-bad'))\n        with pytest.raises(exceptions.RepositoryNotFound) as err:\n            repository.determine_repo_dir(\n                template_path,\n                abbreviations={},\n                clone_to_dir=str(tmp_path),\n                checkout=None,\n                no_input=True,\n            )\n\n&gt;       assert str(err.value) == (\n            'A valid repository for \"{}\" could not be found in the following '\n            'locations:\\n{}'.format(\n                template_path,\n                '\\n'.join(\n                    [template_path, str(tmp_path.joinpath('tests', 'fake-repo-bad'))]\n                ),\n            )\n        )\nE       assert 'The repository tests/fake-repo-bad does not contain a cookiecutter.json file' == 'A valid repository for \"tests/fake-repo-bad\" could not be found in the following locations:\\ntests/fake-repo-bad\\n/tmp/pytest-of-root/pytest-0/test_local_repo_with_no_contex0/tests/fake-repo-bad'\nE         \nE         + The repository tests/fake-repo-bad does not contain a cookiecutter.json file\nE         - A valid repository for \"tests/fake-repo-bad\" could not be found in the following locations:\nE         - tests/fake-repo-bad\nE         - /tmp/pytest-of-root/pytest-0/test_local_repo_with_no_contex0/tests/fake-repo-bad\n\ntests/repository/test_determine_repository_should_use_local_repo.py:37: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_determine_repository_should_use_local_repopytest_local_repo_typo","title":"test_determine_repository_should_use_local_repo.py::test_local_repo_typo","text":"<pre>test_determine_repository_should_use_local_repo.py::test_local_repo_typo</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_local_repo_typo1')\n\n    def test_local_repo_typo(tmp_path):\n        \"\"\"An unknown local repository should raise a `RepositoryNotFound` \\\n        exception.\"\"\"\n        template_path = str(Path('tests', 'unknown-repo'))\n        with pytest.raises(exceptions.RepositoryNotFound) as err:\n            repository.determine_repo_dir(\n                template_path,\n                abbreviations={},\n                clone_to_dir=str(tmp_path),\n                checkout=None,\n                no_input=True,\n            )\n\n&gt;       assert str(err.value) == (\n            'A valid repository for \"{}\" could not be found in the following '\n            'locations:\\n{}'.format(\n                template_path,\n                '\\n'.join([template_path, str(tmp_path.joinpath('tests', 'unknown-repo'))]),\n            )\n        )\nE       assert 'The repository tests/unknown-repo does not contain a cookiecutter.json file' == 'A valid repository for \"tests/unknown-repo\" could not be found in the following locations:\\ntests/unknown-repo\\n/tmp/pytest-of-root/pytest-0/test_local_repo_typo1/tests/unknown-repo'\nE         \nE         + The repository tests/unknown-repo does not contain a cookiecutter.json file\nE         - A valid repository for \"tests/unknown-repo\" could not be found in the following locations:\nE         - tests/unknown-repo\nE         - /tmp/pytest-of-root/pytest-0/test_local_repo_typo1/tests/unknown-repo\n\ntests/repository/test_determine_repository_should_use_local_repo.py:61: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_is_repo_urlpytest_expand_abbreviations","title":"test_is_repo_url.py::test_expand_abbreviations","text":"<pre>test_is_repo_url.py::test_expand_abbreviations</pre><pre>\ndef test_expand_abbreviations():\n        \"\"\"Validate `repository.expand_abbreviations` correctly translate url.\"\"\"\n        template = 'gh:audreyfeldroy/cookiecutter-pypackage'\n\n        # This is not a valid repo url just yet!\n        # First `repository.expand_abbreviations` needs to translate it\n        assert is_repo_url(template) is False\n\n        expanded_template = expand_abbreviations(template, BUILTIN_ABBREVIATIONS)\n&gt;       assert is_repo_url(expanded_template) is True\nE       AssertionError: assert False is True\nE        +  where False = is_repo_url('gh:audreyfeldroy/cookiecutter-pypackage')\n\ntests/repository/test_is_repo_url.py:76: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_abort_generate_on_hook_errorpytest_hooks_raises_errorspre_gen_hook_raises_error","title":"test_abort_generate_on_hook_error.py::test_hooks_raises_errors[pre_gen_hook_raises_error]","text":"<pre>test_abort_generate_on_hook_error.py::test_hooks_raises_errors[pre_gen_hook_raises_error]</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_hooks_raises_errors_pre_g0')\nabort_pre_gen = 'yes', abort_post_gen = 'no'\n\n    @pytest.mark.parametrize(\n        (\"abort_pre_gen\", \"abort_post_gen\"),\n        ((\"yes\", \"no\"), (\"no\", \"yes\")),\n        ids=(\"pre_gen_hook_raises_error\", \"post_gen_hook_raises_error\"),\n    )\n    @pytest.mark.usefixtures(\"clean_system\")\n    def test_hooks_raises_errors(tmp_path, abort_pre_gen, abort_post_gen):\n        \"\"\"Verify pre- and pos-gen errors raises correct error code from script.\n\n        This allows developers to make different error codes in their code,\n        for different errors.\n        \"\"\"\n        context = {\n            \"cookiecutter\": {\n                \"repo_dir\": \"foobar\",\n                \"abort_pre_gen\": abort_pre_gen,\n                \"abort_post_gen\": abort_post_gen,\n            }\n        }\n\n        with pytest.raises(exceptions.FailedHookException) as error:\n&gt;           generate.generate_files(\n                repo_dir=\"tests/hooks-abort-render\",\n                context=context,\n                output_dir=str(tmp_path),\n            )\n\ntests/test_abort_generate_on_hook_error.py:34: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/hooks-abort-render'\ncontext = {'cookiecutter': {'abort_post_gen': 'no', 'abort_pre_gen': 'yes', 'repo_dir': 'foobar'}}\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_hooks_raises_errors_pre_g0'\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_abort_generate_on_hook_errorpytest_hooks_raises_errorspost_gen_hook_raises_error","title":"test_abort_generate_on_hook_error.py::test_hooks_raises_errors[post_gen_hook_raises_error]","text":"<pre>test_abort_generate_on_hook_error.py::test_hooks_raises_errors[post_gen_hook_raises_error]</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_hooks_raises_errors_post_0')\nabort_pre_gen = 'no', abort_post_gen = 'yes'\n\n    @pytest.mark.parametrize(\n        (\"abort_pre_gen\", \"abort_post_gen\"),\n        ((\"yes\", \"no\"), (\"no\", \"yes\")),\n        ids=(\"pre_gen_hook_raises_error\", \"post_gen_hook_raises_error\"),\n    )\n    @pytest.mark.usefixtures(\"clean_system\")\n    def test_hooks_raises_errors(tmp_path, abort_pre_gen, abort_post_gen):\n        \"\"\"Verify pre- and pos-gen errors raises correct error code from script.\n\n        This allows developers to make different error codes in their code,\n        for different errors.\n        \"\"\"\n        context = {\n            \"cookiecutter\": {\n                \"repo_dir\": \"foobar\",\n                \"abort_pre_gen\": abort_pre_gen,\n                \"abort_post_gen\": abort_post_gen,\n            }\n        }\n\n        with pytest.raises(exceptions.FailedHookException) as error:\n&gt;           generate.generate_files(\n                repo_dir=\"tests/hooks-abort-render\",\n                context=context,\n                output_dir=str(tmp_path),\n            )\n\ntests/test_abort_generate_on_hook_error.py:34: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/hooks-abort-render'\ncontext = {'cookiecutter': {'abort_post_gen': 'yes', 'abort_pre_gen': 'no', 'repo_dir': 'foobar'}}\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_hooks_raises_errors_post_0'\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_error_on_existing_output_directory","title":"test_cli.py::test_cli_error_on_existing_output_directory","text":"<pre>test_cli.py::test_cli_error_on_existing_output_directory</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\n\n    @pytest.mark.usefixtures('make_fake_project_dir', 'remove_fake_project_dir')\n    def test_cli_error_on_existing_output_directory(cli_runner):\n        \"\"\"Test cli invocation without `overwrite-if-exists` fail if dir exist.\"\"\"\n        result = cli_runner('tests/fake-repo-pre/', '--no-input')\n        assert result.exit_code != 0\n        expected_error_msg = 'Error: \"fake-project\" directory already exists\\n'\n&gt;       assert result.output == expected_error_msg\nE       assert '' == 'Error: \"fake-project\" directory already exists\\n'\nE         \nE         - Error: \"fake-project\" directory already exists\n\ntests/test_cli.py:81: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli","title":"test_cli.py::test_cli","text":"<pre>test_cli.py::test_cli</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\n\n    @pytest.mark.usefixtures('remove_fake_project_dir')\n    def test_cli(cli_runner):\n        \"\"\"Test cli invocation work without flags if directory not exist.\"\"\"\n        result = cli_runner('tests/fake-repo-pre/', '--no-input')\n&gt;       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = .exit_code\n\ntests/test_cli.py:88: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_verbose","title":"test_cli.py::test_cli_verbose","text":"<pre>test_cli.py::test_cli_verbose</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\n\n    @pytest.mark.usefixtures('remove_fake_project_dir')\n    def test_cli_verbose(cli_runner):\n        \"\"\"Test cli invocation display log if called with `verbose` flag.\"\"\"\n        result = cli_runner('tests/fake-repo-pre/', '--no-input', '-v')\n&gt;       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = .exit_code\n\ntests/test_cli.py:98: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_replay","title":"test_cli.py::test_cli_replay","text":"<pre>test_cli.py::test_cli_replay</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay=True, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=True, overwrite_if_exists=False, output_dir='.', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eecfe1090&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=True, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=True, overwrite_if_exists=False, output_dir='.', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=True, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=True, overwrite_if_exists=False, output_dir='.', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': True, 'overwrite_if_exists': False, 'output_dir': '.', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': True, 'overwrite_if_exists': False, 'skip_if_file_exists': False, 'output_dir': '.', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '.',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': True,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '.',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': True,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\n\n    @pytest.mark.usefixtures('remove_fake_project_dir')\n    def test_cli_replay(mocker, cli_runner):\n        \"\"\"Test cli invocation display log with `verbose` and `replay` flags.\"\"\"\n        mock_cookiecutter = mocker.patch('cookiecutter.cli.cookiecutter')\n\n        template_path = 'tests/fake-repo-pre/'\n        result = cli_runner(template_path, '--replay', '-v')\n\n        assert result.exit_code == 0\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay=True,\n            overwrite_if_exists=False,\n            skip_if_file_exists=False,\n            output_dir='.',\n            config_file=None,\n            default_config=False,\n            extra_context=None,\n            password=None,\n            directory=None,\n            accept_hooks=True,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=True, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=True, overwrite_if_exists=False, output_dir='.', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': True, 'overwrite_if_exists': False, 'output_dir': '.', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': True, 'overwrite_if_exists': False, 'skip_if_file_exists': False, 'output_dir': '.', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '.',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': True,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '.',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': True,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:113: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_replay_file","title":"test_cli.py::test_cli_replay_file","text":"<pre>test_cli.py::test_cli_replay_file</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay='~/custom-replay-file', overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='.', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eecec0af0&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay='~/custom-replay-file', overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='.', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay='~/custom-replay-file', overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='.', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '.', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': '~/custom-replay-file', 'overwrite_if_exists': False, 'skip_if_file_exists': False, 'output_dir': '.', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '.',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'replay': False} != {'replay': '~/custom-replay-file'}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '.',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE         -     'replay': '~/custom-replay-file',\nE         +     'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\n\n    @pytest.mark.usefixtures('remove_fake_project_dir')\n    def test_cli_replay_file(mocker, cli_runner):\n        \"\"\"Test cli invocation correctly pass --replay-file option.\"\"\"\n        mock_cookiecutter = mocker.patch('cookiecutter.cli.cookiecutter')\n\n        template_path = 'tests/fake-repo-pre/'\n        result = cli_runner(template_path, '--replay-file', '~/custom-replay-file', '-v')\n\n        assert result.exit_code == 0\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay='~/custom-replay-file',\n            overwrite_if_exists=False,\n            skip_if_file_exists=False,\n            output_dir='.',\n            config_file=None,\n            default_config=False,\n            extra_context=None,\n            password=None,\n            directory=None,\n            accept_hooks=True,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay='~/custom-replay-file', overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='.', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '.', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': '~/custom-replay-file', 'overwrite_if_exists': False, 'skip_if_file_exists': False, 'output_dir': '.', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '.',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'replay': False} != {'replay': '~/custom-replay-file'}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '.',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE         -     'replay': '~/custom-replay-file',\nE         +     'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:140: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_replay_generated","title":"test_cli.py::test_cli_replay_generated","text":"<pre>test_cli.py::test_cli_replay_generated</pre><pre>\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\n\n    @pytest.mark.usefixtures('remove_tmp_dir')\n    def test_cli_replay_generated(mocker, cli_runner):\n        \"\"\"Test cli invocation correctly generates a project with replay.\"\"\"\n        template_path = 'tests/fake-repo-replay/'\n        result = cli_runner(\n            template_path,\n            '--replay-file',\n            'tests/test-replay/valid_replay.json',\n            '-o',\n            'tests/tmp/',\n            '-v',\n        )\n&gt;       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = .exit_code\n\ntests/test_cli.py:170: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_exit_on_noinput_and_replay","title":"test_cli.py::test_cli_exit_on_noinput_and_replay","text":"<pre>test_cli.py::test_cli_exit_on_noinput_and_replay</pre><pre>\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\n\n    @pytest.mark.usefixtures('remove_fake_project_dir')\n    def test_cli_exit_on_noinput_and_replay(mocker, cli_runner):\n        \"\"\"Test cli invocation fail if both `no-input` and `replay` flags passed.\"\"\"\n        mock_cookiecutter = mocker.patch(\n            'cookiecutter.cli.cookiecutter', side_effect=cookiecutter\n        )\n\n        template_path = 'tests/fake-repo-pre/'\n        result = cli_runner(template_path, '--no-input', '--replay', '-v')\n\n        assert result.exit_code == 1\n\n        expected_error_msg = (\n            \"You can not use both replay and no_input or extra_context at the same time.\"\n        )\n\n&gt;       assert expected_error_msg in result.output\nE       assert 'You can not use both replay and no_input or extra_context at the same time.' in ''\nE        +  where '' = .output\n\ntests/test_cli.py:190: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_run_cookiecutter_on_overwrite_if_exists_and_replay-f","title":"test_cli.py::test_run_cookiecutter_on_overwrite_if_exists_and_replay[-f]","text":"<pre>test_cli.py::test_run_cookiecutter_on_overwrite_if_exists_and_replay[-f]</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay=True, overwrite_if_exists=True, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=True, overwrite_if_exists=True, output_dir='.', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eed07f880&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=True, overwrite_if_exists=True, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=True, overwrite_if_exists=True, output_dir='.', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=True, overwrite_if_exists=True, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=True, overwrite_if_exists=True, output_dir='.', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': True, 'overwrite_if_exists': True, 'output_dir': '.', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': True, 'overwrite_if_exists': True, 'skip_if_file_exists': False, 'output_dir': '.', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '.',\nE          'overwrite_if_exists': True,\nE          'password': None,\nE          'replay': True,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '.',\nE               'overwrite_if_exists': True,\nE               'password': None,\nE               'replay': True,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\noverwrite_cli_flag = '-f'\n\n    @pytest.mark.usefixtures('remove_fake_project_dir')\n    def test_run_cookiecutter_on_overwrite_if_exists_and_replay(\n        mocker, cli_runner, overwrite_cli_flag\n    ):\n        \"\"\"Test cli invocation with `overwrite-if-exists` and `replay` flags.\"\"\"\n        mock_cookiecutter = mocker.patch('cookiecutter.cli.cookiecutter')\n\n        template_path = 'tests/fake-repo-pre/'\n        result = cli_runner(template_path, '--replay', '-v', overwrite_cli_flag)\n\n        assert result.exit_code == 0\n\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay=True,\n            overwrite_if_exists=True,\n            skip_if_file_exists=False,\n            output_dir='.',\n            config_file=None,\n            default_config=False,\n            extra_context=None,\n            password=None,\n            directory=None,\n            accept_hooks=True,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=True, overwrite_if_exists=True, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=True, overwrite_if_exists=True, output_dir='.', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': True, 'overwrite_if_exists': True, 'output_dir': '.', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': True, 'overwrite_if_exists': True, 'skip_if_file_exists': False, 'output_dir': '.', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '.',\nE          'overwrite_if_exists': True,\nE          'password': None,\nE          'replay': True,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '.',\nE               'overwrite_if_exists': True,\nE               'password': None,\nE               'replay': True,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:228: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_run_cookiecutter_on_overwrite_if_exists_and_replay-overwrite-if-exists","title":"test_cli.py::test_run_cookiecutter_on_overwrite_if_exists_and_replay[--overwrite-if-exists]","text":"<pre>test_cli.py::test_run_cookiecutter_on_overwrite_if_exists_and_replay[--overwrite-if-exists]</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay=True, overwrite_if_exists=True, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=True, overwrite_if_exists=True, output_dir='.', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eecf3ea70&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=True, overwrite_if_exists=True, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=True, overwrite_if_exists=True, output_dir='.', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=True, overwrite_if_exists=True, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=True, overwrite_if_exists=True, output_dir='.', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': True, 'overwrite_if_exists': True, 'output_dir': '.', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': True, 'overwrite_if_exists': True, 'skip_if_file_exists': False, 'output_dir': '.', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '.',\nE          'overwrite_if_exists': True,\nE          'password': None,\nE          'replay': True,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '.',\nE               'overwrite_if_exists': True,\nE               'password': None,\nE               'replay': True,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\noverwrite_cli_flag = '--overwrite-if-exists'\n\n    @pytest.mark.usefixtures('remove_fake_project_dir')\n    def test_run_cookiecutter_on_overwrite_if_exists_and_replay(\n        mocker, cli_runner, overwrite_cli_flag\n    ):\n        \"\"\"Test cli invocation with `overwrite-if-exists` and `replay` flags.\"\"\"\n        mock_cookiecutter = mocker.patch('cookiecutter.cli.cookiecutter')\n\n        template_path = 'tests/fake-repo-pre/'\n        result = cli_runner(template_path, '--replay', '-v', overwrite_cli_flag)\n\n        assert result.exit_code == 0\n\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay=True,\n            overwrite_if_exists=True,\n            skip_if_file_exists=False,\n            output_dir='.',\n            config_file=None,\n            default_config=False,\n            extra_context=None,\n            password=None,\n            directory=None,\n            accept_hooks=True,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=True, overwrite_if_exists=True, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=True, overwrite_if_exists=True, output_dir='.', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': True, 'overwrite_if_exists': True, 'output_dir': '.', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': True, 'overwrite_if_exists': True, 'skip_if_file_exists': False, 'output_dir': '.', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '.',\nE          'overwrite_if_exists': True,\nE          'password': None,\nE          'replay': True,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '.',\nE               'overwrite_if_exists': True,\nE               'password': None,\nE               'replay': True,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:228: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_overwrite_if_exists_when_output_dir_does_not_exist-f","title":"test_cli.py::test_cli_overwrite_if_exists_when_output_dir_does_not_exist[-f]","text":"<pre>test_cli.py::test_cli_overwrite_if_exists_when_output_dir_does_not_exist[-f]</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\noverwrite_cli_flag = '-f'\n\n    @pytest.mark.usefixtures('remove_fake_project_dir')\n    def test_cli_overwrite_if_exists_when_output_dir_does_not_exist(\n        cli_runner, overwrite_cli_flag\n    ):\n        \"\"\"Test cli invocation with `overwrite-if-exists` and `no-input` flags.\n\n        Case when output dir not exist.\n        \"\"\"\n        result = cli_runner('tests/fake-repo-pre/', '--no-input', overwrite_cli_flag)\n\n&gt;       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = .exit_code\n\ntests/test_cli.py:256: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_overwrite_if_exists_when_output_dir_does_not_exist-overwrite-if-exists","title":"test_cli.py::test_cli_overwrite_if_exists_when_output_dir_does_not_exist[--overwrite-if-exists]","text":"<pre>test_cli.py::test_cli_overwrite_if_exists_when_output_dir_does_not_exist[--overwrite-if-exists]</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\noverwrite_cli_flag = '--overwrite-if-exists'\n\n    @pytest.mark.usefixtures('remove_fake_project_dir')\n    def test_cli_overwrite_if_exists_when_output_dir_does_not_exist(\n        cli_runner, overwrite_cli_flag\n    ):\n        \"\"\"Test cli invocation with `overwrite-if-exists` and `no-input` flags.\n\n        Case when output dir not exist.\n        \"\"\"\n        result = cli_runner('tests/fake-repo-pre/', '--no-input', overwrite_cli_flag)\n\n&gt;       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = .exit_code\n\ntests/test_cli.py:256: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_overwrite_if_exists_when_output_dir_exists-f","title":"test_cli.py::test_cli_overwrite_if_exists_when_output_dir_exists[-f]","text":"<pre>test_cli.py::test_cli_overwrite_if_exists_when_output_dir_exists[-f]</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\noverwrite_cli_flag = '-f'\n\n    @pytest.mark.usefixtures('make_fake_project_dir', 'remove_fake_project_dir')\n    def test_cli_overwrite_if_exists_when_output_dir_exists(cli_runner, overwrite_cli_flag):\n        \"\"\"Test cli invocation with `overwrite-if-exists` and `no-input` flags.\n\n        Case when output dir already exist.\n        \"\"\"\n        result = cli_runner('tests/fake-repo-pre/', '--no-input', overwrite_cli_flag)\n&gt;       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = .exit_code\n\ntests/test_cli.py:267: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_overwrite_if_exists_when_output_dir_exists-overwrite-if-exists","title":"test_cli.py::test_cli_overwrite_if_exists_when_output_dir_exists[--overwrite-if-exists]","text":"<pre>test_cli.py::test_cli_overwrite_if_exists_when_output_dir_exists[--overwrite-if-exists]</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\noverwrite_cli_flag = '--overwrite-if-exists'\n\n    @pytest.mark.usefixtures('make_fake_project_dir', 'remove_fake_project_dir')\n    def test_cli_overwrite_if_exists_when_output_dir_exists(cli_runner, overwrite_cli_flag):\n        \"\"\"Test cli invocation with `overwrite-if-exists` and `no-input` flags.\n\n        Case when output dir already exist.\n        \"\"\"\n        result = cli_runner('tests/fake-repo-pre/', '--no-input', overwrite_cli_flag)\n&gt;       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = .exit_code\n\ntests/test_cli.py:267: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_output_dir-o","title":"test_cli.py::test_cli_output_dir[-o]","text":"<pre>test_cli.py::test_cli_output_dir[-o]</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eecec2050&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'skip_if_file_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\noutput_dir_flag = '-o'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output'\n\n    def test_cli_output_dir(mocker, cli_runner, output_dir_flag, output_dir):\n        \"\"\"Test cli invocation with `output-dir` flag changes output directory.\"\"\"\n        mock_cookiecutter = mocker.patch('cookiecutter.cli.cookiecutter')\n\n        template_path = 'tests/fake-repo-pre/'\n        result = cli_runner(template_path, output_dir_flag, output_dir)\n\n        assert result.exit_code == 0\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay=False,\n            overwrite_if_exists=False,\n            skip_if_file_exists=False,\n            output_dir=output_dir,\n            config_file=None,\n            default_config=False,\n            extra_context=None,\n            password=None,\n            directory=None,\n            accept_hooks=True,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'skip_if_file_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_output_dir__o_0/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:285: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_output_dir-output-dir","title":"test_cli.py::test_cli_output_dir[--output-dir]","text":"<pre>test_cli.py::test_cli_output_dir[--output-dir]</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eecf3fac0&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'skip_if_file_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\noutput_dir_flag = '--output-dir'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output'\n\n    def test_cli_output_dir(mocker, cli_runner, output_dir_flag, output_dir):\n        \"\"\"Test cli invocation with `output-dir` flag changes output directory.\"\"\"\n        mock_cookiecutter = mocker.patch('cookiecutter.cli.cookiecutter')\n\n        template_path = 'tests/fake-repo-pre/'\n        result = cli_runner(template_path, output_dir_flag, output_dir)\n\n        assert result.exit_code == 0\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay=False,\n            overwrite_if_exists=False,\n            skip_if_file_exists=False,\n            output_dir=output_dir,\n            config_file=None,\n            default_config=False,\n            extra_context=None,\n            password=None,\n            directory=None,\n            accept_hooks=True,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'skip_if_file_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_output_dir___output_d0/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:285: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_helphelp","title":"test_cli.py::test_cli_help[help]","text":"<pre>test_cli.py::test_cli_help[help]</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\nhelp_cli_flag = 'help'\n\n    def test_cli_help(cli_runner, help_cli_flag):\n        \"\"\"Test cli invocation display help message with `help` flag.\"\"\"\n        result = cli_runner(help_cli_flag)\n&gt;       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = .exit_code\n\ntests/test_cli.py:312: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_user_config","title":"test_cli.py::test_user_config","text":"<pre>test_cli.py::test_user_config</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': '/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml', 'default_config': False, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file='/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml', default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='.', config_file='/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml', default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eecec0c10&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file='/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml', default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='.', config_file='/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml', default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': '/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml', 'default_config': False, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file='/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml', default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='.', config_file='/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml', default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '.', 'config_file': '/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml', 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'skip_if_file_exists': False, 'output_dir': '.', 'config_file': '/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml', 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': '/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml',\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '.',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': '/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml',\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '.',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\nuser_config_path = '/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml'\n\n    def test_user_config(mocker, cli_runner, user_config_path):\n        \"\"\"Test cli invocation works with `config-file` option.\"\"\"\n        mock_cookiecutter = mocker.patch('cookiecutter.cli.cookiecutter')\n\n        template_path = 'tests/fake-repo-pre/'\n        result = cli_runner(template_path, '--config-file', user_config_path)\n\n        assert result.exit_code == 0\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay=False,\n            overwrite_if_exists=False,\n            skip_if_file_exists=False,\n            output_dir='.',\n            config_file=user_config_path,\n            default_config=False,\n            extra_context=None,\n            password=None,\n            directory=None,\n            accept_hooks=True,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file='/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml', default_config=False, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='.', config_file='/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml', default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '.', 'config_file': '/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml', 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'skip_if_file_exists': False, 'output_dir': '.', 'config_file': '/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml', 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': '/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml',\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '.',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': '/tmp/pytest-of-root/pytest-0/test_user_config0/tests/config.yaml',\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '.',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:330: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_default_user_config_overwrite","title":"test_cli.py::test_default_user_config_overwrite","text":"<pre>test_cli.py::test_default_user_config_overwrite</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': '/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml', 'default_config': True, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file='/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml', default_config=True, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='.', config_file='/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml', default_config=True, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eecec1630&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file='/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml', default_config=True, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='.', config_file='/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml', default_config=True, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': '/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml', 'default_config': True, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file='/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml', default_config=True, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='.', config_file='/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml', default_config=True, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '.', 'config_file': '/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml', 'default_config': True, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'skip_if_file_exists': False, 'output_dir': '.', 'config_file': '/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml', 'default_config': True, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': '/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml',\nE          'default_config': True,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '.',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': '/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml',\nE               'default_config': True,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '.',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\nuser_config_path = '/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml'\n\n    def test_default_user_config_overwrite(mocker, cli_runner, user_config_path):\n        \"\"\"Test cli invocation ignores `config-file` if `default-config` passed.\"\"\"\n        mock_cookiecutter = mocker.patch('cookiecutter.cli.cookiecutter')\n\n        template_path = 'tests/fake-repo-pre/'\n        result = cli_runner(\n            template_path,\n            '--config-file',\n            user_config_path,\n            '--default-config',\n        )\n\n        assert result.exit_code == 0\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay=False,\n            overwrite_if_exists=False,\n            skip_if_file_exists=False,\n            output_dir='.',\n            config_file=user_config_path,\n            default_config=True,\n            extra_context=None,\n            password=None,\n            directory=None,\n            accept_hooks=True,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file='/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml', default_config=True, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='.', config_file='/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml', default_config=True, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '.', 'config_file': '/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml', 'default_config': True, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'skip_if_file_exists': False, 'output_dir': '.', 'config_file': '/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml', 'default_config': True, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': '/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml',\nE          'default_config': True,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '.',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': '/tmp/pytest-of-root/pytest-0/test_default_user_config_overw0/tests/config.yaml',\nE               'default_config': True,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '.',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:361: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_default_user_config","title":"test_cli.py::test_default_user_config","text":"<pre>test_cli.py::test_default_user_config</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': True, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=True, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='.', config_file=None, default_config=True, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eecec37f0&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=True, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='.', config_file=None, default_config=True, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': True, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=True, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='.', config_file=None, default_config=True, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '.', 'config_file': None, 'default_config': True, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'skip_if_file_exists': False, 'output_dir': '.', 'config_file': None, 'default_config': True, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': True,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '.',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': True,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '.',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\n\n    def test_default_user_config(mocker, cli_runner):\n        \"\"\"Test cli invocation accepts `default-config` flag correctly.\"\"\"\n        mock_cookiecutter = mocker.patch('cookiecutter.cli.cookiecutter')\n\n        template_path = 'tests/fake-repo-pre/'\n        result = cli_runner(template_path, '--default-config')\n\n        assert result.exit_code == 0\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay=False,\n            overwrite_if_exists=False,\n            skip_if_file_exists=False,\n            output_dir='.',\n            config_file=None,\n            default_config=True,\n            extra_context=None,\n            password=None,\n            directory=None,\n            accept_hooks=True,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, skip_if_file_exists=False, output_dir='.', config_file=None, default_config=True, extra_context=None, password=None, directory=None, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='.', config_file=None, default_config=True, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '.', 'config_file': None, 'default_config': True, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'skip_if_file_exists': False, 'output_dir': '.', 'config_file': None, 'default_config': True, 'extra_context': None, 'password': None, 'directory': None, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': True,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '.',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': True,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '.',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:387: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_echo_undefined_variable_error","title":"test_cli.py::test_echo_undefined_variable_error","text":"<pre>test_cli.py::test_echo_undefined_variable_error</pre><pre>\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_echo_undefined_variable_e0/output'\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\n\n    def test_echo_undefined_variable_error(output_dir, cli_runner):\n        \"\"\"Cli invocation return error if variable undefined in template.\"\"\"\n        template_path = 'tests/undefined-variable/file-name/'\n\n        result = cli_runner(\n            '--no-input',\n            '--default-config',\n            '--output-dir',\n            output_dir,\n            template_path,\n        )\n\n        assert result.exit_code == 1\n\n        error = \"Unable to create file '{{cookiecutter.foobar}}'\"\n&gt;       assert error in result.output\nE       assert \"Unable to create file '{{cookiecutter.foobar}}'\" in ''\nE        +  where '' = .output\n\ntests/test_cli.py:420: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_echo_unknown_extension_error","title":"test_cli.py::test_echo_unknown_extension_error","text":"<pre>test_cli.py::test_echo_unknown_extension_error</pre><pre>\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_echo_unknown_extension_er0/output'\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\n\n    def test_echo_unknown_extension_error(output_dir, cli_runner):\n        \"\"\"Cli return error if extension incorrectly defined in template.\"\"\"\n        template_path = 'tests/test-extensions/unknown/'\n\n        result = cli_runner(\n            '--no-input',\n            '--default-config',\n            '--output-dir',\n            output_dir,\n            template_path,\n        )\n\n        assert result.exit_code == 1\n\n&gt;       assert 'Unable to load extension: ' in result.output\nE       assert 'Unable to load extension: ' in ''\nE        +  where '' = .output\n\ntests/test_cli.py:459: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_local_extension","title":"test_cli.py::test_local_extension","text":"<pre>test_cli.py::test_local_extension</pre><pre>\ntmpdir = local('/tmp/pytest-of-root/pytest-0/test_local_extension0')\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\n\n    def test_local_extension(tmpdir, cli_runner):\n        \"\"\"Test to verify correct work of extension, included in template.\"\"\"\n        output_dir = str(tmpdir.mkdir('output'))\n        template_path = 'tests/test-extensions/local_extension/'\n\n        result = cli_runner(\n            '--no-input',\n            '--default-config',\n            '--output-dir',\n            output_dir,\n            template_path,\n        )\n&gt;       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = .exit_code\n\ntests/test_cli.py:474: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_extra_context","title":"test_cli.py::test_cli_extra_context","text":"<pre>test_cli.py::test_cli_extra_context</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\n\n    @pytest.mark.usefixtures('remove_fake_project_dir')\n    def test_cli_extra_context(cli_runner):\n        \"\"\"Cli invocation replace content if called with replacement pairs.\"\"\"\n        result = cli_runner(\n            'tests/fake-repo-pre/',\n            '--no-input',\n            '-v',\n            'project_name=Awesomez',\n        )\n&gt;       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = .exit_code\n\ntests/test_cli.py:499: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_extra_context_invalid_format","title":"test_cli.py::test_cli_extra_context_invalid_format","text":"<pre>test_cli.py::test_cli_extra_context_invalid_format</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\n\n    @pytest.mark.usefixtures('remove_fake_project_dir')\n    def test_cli_extra_context_invalid_format(cli_runner):\n        \"\"\"Cli invocation raise error if called with unknown argument.\"\"\"\n        result = cli_runner(\n            'tests/fake-repo-pre/',\n            '--no-input',\n            '-v',\n            'ExtraContextWithNoEqualsSoInvalid',\n        )\n        assert result.exit_code == 2\n        assert \"Error: Invalid value for '[EXTRA_CONTEXT]...'\" in result.output\n&gt;       assert 'should contain items of the form key=value' in result.output\nE       assert 'should contain items of the form key=value' in 'Usage: main [OPTIONS] [TEMPLATE] [EXTRA_CONTEXT]...\\nTry \\'main -h\\' for help.\\n\\nError: Invalid value for \\'[EXTRA_CONTEXT]...\\': \"ExtraContextWithNoEqualsSoInvalid\" is not a valid key/value pair. Use the format key=value.\\n'\nE        +  where 'Usage: main [OPTIONS] [TEMPLATE] [EXTRA_CONTEXT]...\\nTry \\'main -h\\' for help.\\n\\nError: Invalid value for \\'[EXTRA_CONTEXT]...\\': \"ExtraContextWithNoEqualsSoInvalid\" is not a valid key/value pair. Use the format key=value.\\n' = .output\n\ntests/test_cli.py:516: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_debug_file_non_verbose","title":"test_cli.py::test_debug_file_non_verbose","text":"<pre>test_cli.py::test_debug_file_non_verbose</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\ndebug_file = PosixPath('/tmp/pytest-of-root/pytest-0/test_debug_file_non_verbose0/fake-repo.log')\n\n    @pytest.mark.usefixtures('remove_fake_project_dir')\n    def test_debug_file_non_verbose(cli_runner, debug_file):\n        \"\"\"Test cli invocation writes log to `debug-file` if flag enabled.\n\n        Case for normal log output.\n        \"\"\"\n        assert not debug_file.exists()\n\n        result = cli_runner(\n            '--no-input',\n            '--debug-file',\n            str(debug_file),\n            'tests/fake-repo-pre/',\n        )\n&gt;       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = .exit_code\n\ntests/test_cli.py:539: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_debug_file_verbose","title":"test_cli.py::test_debug_file_verbose","text":"<pre>test_cli.py::test_debug_file_verbose</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\ndebug_file = PosixPath('/tmp/pytest-of-root/pytest-0/test_debug_file_verbose0/fake-repo.log')\n\n    @pytest.mark.usefixtures('remove_fake_project_dir')\n    def test_debug_file_verbose(cli_runner, debug_file):\n        \"\"\"Test cli invocation writes log to `debug-file` if flag enabled.\n\n        Case for verbose log output.\n        \"\"\"\n        assert not debug_file.exists()\n\n        result = cli_runner(\n            '--verbose',\n            '--no-input',\n            '--debug-file',\n            str(debug_file),\n            'tests/fake-repo-pre/',\n        )\n&gt;       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = .exit_code\n\ntests/test_cli.py:566: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_debug_list_installed_templates","title":"test_cli.py::test_debug_list_installed_templates","text":"<pre>test_cli.py::test_debug_list_installed_templates</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\ndebug_file = PosixPath('/tmp/pytest-of-root/pytest-0/test_debug_list_installed_temp0/fake-repo.log')\nuser_config_path = '/tmp/pytest-of-root/pytest-0/test_debug_list_installed_temp0/tests/config.yaml'\n\n    @pytest.mark.usefixtures('make_fake_project_dir', 'remove_fake_project_dir')\n    def test_debug_list_installed_templates(cli_runner, debug_file, user_config_path):\n        \"\"\"Verify --list-installed command correct invocation.\"\"\"\n        fake_template_dir = os.path.dirname(os.path.abspath('fake-project'))\n        os.makedirs(os.path.dirname(user_config_path))\n        # Single quotes in YAML will not parse escape codes (\\).\n        Path(user_config_path).write_text(f\"cookiecutters_dir: '{fake_template_dir}'\")\n        Path(\"fake-project\", \"cookiecutter.json\").write_text('{}')\n\n        result = cli_runner(\n            '--list-installed',\n            '--config-file',\n            user_config_path,\n            str(debug_file),\n        )\n\n&gt;       assert \"1 installed templates:\" in result.output\nE       AssertionError: assert '1 installed templates:' in 'Installed templates:\\n  .git\\n  .venv\\n  .github\\n  logo\\n  cookiecutter.egg-info\\n  tests\\n  docs\\n  cookiecutter\\n  fake-project\\n'\nE        +  where 'Installed templates:\\n  .git\\n  .venv\\n  .github\\n  logo\\n  cookiecutter.egg-info\\n  tests\\n  docs\\n  cookiecutter\\n  fake-project\\n' = .output\n\ntests/test_cli.py:594: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_debug_list_installed_templates_failure","title":"test_cli.py::test_debug_list_installed_templates_failure","text":"<pre>test_cli.py::test_debug_list_installed_templates_failure</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\ndebug_file = PosixPath('/tmp/pytest-of-root/pytest-0/test_debug_list_installed_temp1/fake-repo.log')\nuser_config_path = '/tmp/pytest-of-root/pytest-0/test_debug_list_installed_temp1/tests/config.yaml'\n\n    def test_debug_list_installed_templates_failure(\n        cli_runner, debug_file, user_config_path\n    ):\n        \"\"\"Verify --list-installed command error on invocation.\"\"\"\n        os.makedirs(os.path.dirname(user_config_path))\n        Path(user_config_path).write_text('cookiecutters_dir: \"/notarealplace/\"')\n\n        result = cli_runner(\n            '--list-installed', '--config-file', user_config_path, str(debug_file)\n        )\n\n&gt;       assert \"Error: Cannot list installed templates.\" in result.output\nE       AssertionError: assert 'Error: Cannot list installed templates.' in 'No templates found in /notarealplace/\\n'\nE        +  where 'No templates found in /notarealplace/\\n' = .output\n\ntests/test_cli.py:609: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_directory_repo","title":"test_cli.py::test_directory_repo","text":"<pre>test_cli.py::test_directory_repo</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\n\n    @pytest.mark.usefixtures('remove_fake_project_dir')\n    def test_directory_repo(cli_runner):\n        \"\"\"Test cli invocation works with `directory` option.\"\"\"\n        result = cli_runner(\n            'tests/fake-repo-dir/',\n            '--no-input',\n            '-v',\n            '--directory=my-dir',\n        )\n&gt;       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = .exit_code\n\ntests/test_cli.py:622: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_accept_hooks-o-accept-hooksyes-none-true","title":"test_cli.py::test_cli_accept_hooks[-o---accept-hooks=yes-None-True]","text":"<pre>test_cli.py::test_cli_accept_hooks[-o---accept-hooks=yes-None-True]</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eecd46a70&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\noutput_dir_flag = '-o'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output'\naccept_hooks_arg = '--accept-hooks=yes', user_input = None, expected = True\n\n    @pytest.mark.parametrize(\n        \"accept_hooks_arg,user_input,expected\", cli_accept_hook_arg_testdata\n    )\n    def test_cli_accept_hooks(\n        mocker,\n        cli_runner,\n        output_dir_flag,\n        output_dir,\n        accept_hooks_arg,\n        user_input,\n        expected,\n    ):\n        \"\"\"Test cli invocation works with `accept-hooks` option.\"\"\"\n        mock_cookiecutter = mocker.patch(\"cookiecutter.cli.cookiecutter\")\n\n        template_path = \"tests/fake-repo-pre/\"\n        result = cli_runner(\n            template_path, output_dir_flag, output_dir, accept_hooks_arg, input=user_input\n        )\n\n        assert result.exit_code == 0\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay=False,\n            overwrite_if_exists=False,\n            output_dir=output_dir,\n            config_file=None,\n            default_config=False,\n            extra_context=None,\n            password=None,\n            directory=None,\n            skip_if_file_exists=False,\n            accept_hooks=expected,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc0/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:657: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_accept_hooks-o-accept-hooksno-none-false","title":"test_cli.py::test_cli_accept_hooks[-o---accept-hooks=no-None-False]","text":"<pre>test_cli.py::test_cli_accept_hooks[-o---accept-hooks=no-None-False]</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': False, 'config_file': None, 'default_config': False, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=False, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='no', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eecd3cdc0&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=False, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='no', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': False, 'config_file': None, 'default_config': False, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=False, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='no', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'no', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': False, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'no'} != {'accept_hooks': False}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': False,\nE         ?                     ^^^^^\nE         +     'accept_hooks': 'no',\nE         ?                     ^^^^\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\noutput_dir_flag = '-o'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output'\naccept_hooks_arg = '--accept-hooks=no', user_input = None, expected = False\n\n    @pytest.mark.parametrize(\n        \"accept_hooks_arg,user_input,expected\", cli_accept_hook_arg_testdata\n    )\n    def test_cli_accept_hooks(\n        mocker,\n        cli_runner,\n        output_dir_flag,\n        output_dir,\n        accept_hooks_arg,\n        user_input,\n        expected,\n    ):\n        \"\"\"Test cli invocation works with `accept-hooks` option.\"\"\"\n        mock_cookiecutter = mocker.patch(\"cookiecutter.cli.cookiecutter\")\n\n        template_path = \"tests/fake-repo-pre/\"\n        result = cli_runner(\n            template_path, output_dir_flag, output_dir, accept_hooks_arg, input=user_input\n        )\n\n        assert result.exit_code == 0\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay=False,\n            overwrite_if_exists=False,\n            output_dir=output_dir,\n            config_file=None,\n            default_config=False,\n            extra_context=None,\n            password=None,\n            directory=None,\n            skip_if_file_exists=False,\n            accept_hooks=expected,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=False, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='no', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'no', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': False, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'no'} != {'accept_hooks': False}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': False,\nE         ?                     ^^^^^\nE         +     'accept_hooks': 'no',\nE         ?                     ^^^^\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc1/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:657: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_accept_hooks-o-accept-hooksask-yes-true","title":"test_cli.py::test_cli_accept_hooks[-o---accept-hooks=ask-yes-True]","text":"<pre>test_cli.py::test_cli_accept_hooks[-o---accept-hooks=ask-yes-True]</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='ask', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eecd3cee0&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='ask', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='ask', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'ask', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'ask'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^^\nE         +     'accept_hooks': 'ask',\nE         ?                     ^^^^^\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\noutput_dir_flag = '-o'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output'\naccept_hooks_arg = '--accept-hooks=ask', user_input = 'yes', expected = True\n\n    @pytest.mark.parametrize(\n        \"accept_hooks_arg,user_input,expected\", cli_accept_hook_arg_testdata\n    )\n    def test_cli_accept_hooks(\n        mocker,\n        cli_runner,\n        output_dir_flag,\n        output_dir,\n        accept_hooks_arg,\n        user_input,\n        expected,\n    ):\n        \"\"\"Test cli invocation works with `accept-hooks` option.\"\"\"\n        mock_cookiecutter = mocker.patch(\"cookiecutter.cli.cookiecutter\")\n\n        template_path = \"tests/fake-repo-pre/\"\n        result = cli_runner(\n            template_path, output_dir_flag, output_dir, accept_hooks_arg, input=user_input\n        )\n\n        assert result.exit_code == 0\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay=False,\n            overwrite_if_exists=False,\n            output_dir=output_dir,\n            config_file=None,\n            default_config=False,\n            extra_context=None,\n            password=None,\n            directory=None,\n            skip_if_file_exists=False,\n            accept_hooks=expected,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='ask', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'ask', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'ask'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^^\nE         +     'accept_hooks': 'ask',\nE         ?                     ^^^^^\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc2/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:657: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_accept_hooks-o-accept-hooksask-no-false","title":"test_cli.py::test_cli_accept_hooks[-o---accept-hooks=ask-no-False]","text":"<pre>test_cli.py::test_cli_accept_hooks[-o---accept-hooks=ask-no-False]</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': False, 'config_file': None, 'default_config': False, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=False, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='ask', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eecd3d6c0&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=False, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='ask', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': False, 'config_file': None, 'default_config': False, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=False, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='ask', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'ask', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': False, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'ask'} != {'accept_hooks': False}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': False,\nE         ?                     ^ - ^\nE         +     'accept_hooks': 'ask',\nE         ?                     ^  ^^\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\noutput_dir_flag = '-o'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output'\naccept_hooks_arg = '--accept-hooks=ask', user_input = 'no', expected = False\n\n    @pytest.mark.parametrize(\n        \"accept_hooks_arg,user_input,expected\", cli_accept_hook_arg_testdata\n    )\n    def test_cli_accept_hooks(\n        mocker,\n        cli_runner,\n        output_dir_flag,\n        output_dir,\n        accept_hooks_arg,\n        user_input,\n        expected,\n    ):\n        \"\"\"Test cli invocation works with `accept-hooks` option.\"\"\"\n        mock_cookiecutter = mocker.patch(\"cookiecutter.cli.cookiecutter\")\n\n        template_path = \"tests/fake-repo-pre/\"\n        result = cli_runner(\n            template_path, output_dir_flag, output_dir, accept_hooks_arg, input=user_input\n        )\n\n        assert result.exit_code == 0\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay=False,\n            overwrite_if_exists=False,\n            output_dir=output_dir,\n            config_file=None,\n            default_config=False,\n            extra_context=None,\n            password=None,\n            directory=None,\n            skip_if_file_exists=False,\n            accept_hooks=expected,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=False, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='ask', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'ask', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': False, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'ask'} != {'accept_hooks': False}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': False,\nE         ?                     ^ - ^\nE         +     'accept_hooks': 'ask',\nE         ?                     ^  ^^\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks__o___acc3/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:657: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_accept_hooks-output-dir-accept-hooksyes-none-true","title":"test_cli.py::test_cli_accept_hooks[--output-dir---accept-hooks=yes-None-True]","text":"<pre>test_cli.py::test_cli_accept_hooks[--output-dir---accept-hooks=yes-None-True]</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eecd3d510&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\noutput_dir_flag = '--output-dir'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output'\naccept_hooks_arg = '--accept-hooks=yes', user_input = None, expected = True\n\n    @pytest.mark.parametrize(\n        \"accept_hooks_arg,user_input,expected\", cli_accept_hook_arg_testdata\n    )\n    def test_cli_accept_hooks(\n        mocker,\n        cli_runner,\n        output_dir_flag,\n        output_dir,\n        accept_hooks_arg,\n        user_input,\n        expected,\n    ):\n        \"\"\"Test cli invocation works with `accept-hooks` option.\"\"\"\n        mock_cookiecutter = mocker.patch(\"cookiecutter.cli.cookiecutter\")\n\n        template_path = \"tests/fake-repo-pre/\"\n        result = cli_runner(\n            template_path, output_dir_flag, output_dir, accept_hooks_arg, input=user_input\n        )\n\n        assert result.exit_code == 0\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay=False,\n            overwrite_if_exists=False,\n            output_dir=output_dir,\n            config_file=None,\n            default_config=False,\n            extra_context=None,\n            password=None,\n            directory=None,\n            skip_if_file_exists=False,\n            accept_hooks=expected,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='yes', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'yes', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'yes'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^\nE         +     'accept_hooks': 'yes',\nE         ?                     ^^ ++\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output0/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:657: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_accept_hooks-output-dir-accept-hooksno-none-false","title":"test_cli.py::test_cli_accept_hooks[--output-dir---accept-hooks=no-None-False]","text":"<pre>test_cli.py::test_cli_accept_hooks[--output-dir---accept-hooks=no-None-False]</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': False, 'config_file': None, 'default_config': False, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=False, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='no', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eecd3db40&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=False, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='no', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': False, 'config_file': None, 'default_config': False, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=False, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='no', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'no', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': False, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'no'} != {'accept_hooks': False}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': False,\nE         ?                     ^^^^^\nE         +     'accept_hooks': 'no',\nE         ?                     ^^^^\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\noutput_dir_flag = '--output-dir'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output'\naccept_hooks_arg = '--accept-hooks=no', user_input = None, expected = False\n\n    @pytest.mark.parametrize(\n        \"accept_hooks_arg,user_input,expected\", cli_accept_hook_arg_testdata\n    )\n    def test_cli_accept_hooks(\n        mocker,\n        cli_runner,\n        output_dir_flag,\n        output_dir,\n        accept_hooks_arg,\n        user_input,\n        expected,\n    ):\n        \"\"\"Test cli invocation works with `accept-hooks` option.\"\"\"\n        mock_cookiecutter = mocker.patch(\"cookiecutter.cli.cookiecutter\")\n\n        template_path = \"tests/fake-repo-pre/\"\n        result = cli_runner(\n            template_path, output_dir_flag, output_dir, accept_hooks_arg, input=user_input\n        )\n\n        assert result.exit_code == 0\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay=False,\n            overwrite_if_exists=False,\n            output_dir=output_dir,\n            config_file=None,\n            default_config=False,\n            extra_context=None,\n            password=None,\n            directory=None,\n            skip_if_file_exists=False,\n            accept_hooks=expected,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=False, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='no', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'no', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': False, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'no'} != {'accept_hooks': False}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': False,\nE         ?                     ^^^^^\nE         +     'accept_hooks': 'no',\nE         ?                     ^^^^\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output1/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:657: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_accept_hooks-output-dir-accept-hooksask-yes-true","title":"test_cli.py::test_cli_accept_hooks[--output-dir---accept-hooks=ask-yes-True]","text":"<pre>test_cli.py::test_cli_accept_hooks[--output-dir---accept-hooks=ask-yes-True]</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='ask', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eecd3cc10&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='ask', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': True, 'config_file': None, 'default_config': False, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='ask', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'ask', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'ask'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^^\nE         +     'accept_hooks': 'ask',\nE         ?                     ^^^^^\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\noutput_dir_flag = '--output-dir'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output'\naccept_hooks_arg = '--accept-hooks=ask', user_input = 'yes', expected = True\n\n    @pytest.mark.parametrize(\n        \"accept_hooks_arg,user_input,expected\", cli_accept_hook_arg_testdata\n    )\n    def test_cli_accept_hooks(\n        mocker,\n        cli_runner,\n        output_dir_flag,\n        output_dir,\n        accept_hooks_arg,\n        user_input,\n        expected,\n    ):\n        \"\"\"Test cli invocation works with `accept-hooks` option.\"\"\"\n        mock_cookiecutter = mocker.patch(\"cookiecutter.cli.cookiecutter\")\n\n        template_path = \"tests/fake-repo-pre/\"\n        result = cli_runner(\n            template_path, output_dir_flag, output_dir, accept_hooks_arg, input=user_input\n        )\n\n        assert result.exit_code == 0\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay=False,\n            overwrite_if_exists=False,\n            output_dir=output_dir,\n            config_file=None,\n            default_config=False,\n            extra_context=None,\n            password=None,\n            directory=None,\n            skip_if_file_exists=False,\n            accept_hooks=expected,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='ask', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'ask', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': True, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'ask'} != {'accept_hooks': True}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': True,\nE         ?                     ^^^^\nE         +     'accept_hooks': 'ask',\nE         ?                     ^^^^^\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output2/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:657: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_accept_hooks-output-dir-accept-hooksask-no-false","title":"test_cli.py::test_cli_accept_hooks[--output-dir---accept-hooks=ask-no-False]","text":"<pre>test_cli.py::test_cli_accept_hooks[--output-dir---accept-hooks=ask-no-False]</pre><pre>\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': False, 'config_file': None, 'default_config': False, 'directory': None, ...}\nexpected = call('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=False, keep_project_on_failure=False)\nactual = call('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='ask', keep_project_on_failure=False)\n_error_message = ._error_message at 0x7f1eecd3eef0&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=False, keep_project_on_failure=False)\nE           Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='ask', keep_project_on_failure=False)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('tests/fake-repo-pre/', None, False)\nkwargs = {'accept_hooks': False, 'config_file': None, 'default_config': False, 'directory': None, ...}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=False, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='ask', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'ask', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': False, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'ask'} != {'accept_hooks': False}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': False,\nE         ?                     ^ - ^\nE         +     'accept_hooks': 'ask',\nE         ?                     ^  ^^\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\noutput_dir_flag = '--output-dir'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output'\naccept_hooks_arg = '--accept-hooks=ask', user_input = 'no', expected = False\n\n    @pytest.mark.parametrize(\n        \"accept_hooks_arg,user_input,expected\", cli_accept_hook_arg_testdata\n    )\n    def test_cli_accept_hooks(\n        mocker,\n        cli_runner,\n        output_dir_flag,\n        output_dir,\n        accept_hooks_arg,\n        user_input,\n        expected,\n    ):\n        \"\"\"Test cli invocation works with `accept-hooks` option.\"\"\"\n        mock_cookiecutter = mocker.patch(\"cookiecutter.cli.cookiecutter\")\n\n        template_path = \"tests/fake-repo-pre/\"\n        result = cli_runner(\n            template_path, output_dir_flag, output_dir, accept_hooks_arg, input=user_input\n        )\n\n        assert result.exit_code == 0\n&gt;       mock_cookiecutter.assert_called_once_with(\n            template_path,\n            None,\n            False,\n            replay=False,\n            overwrite_if_exists=False,\n            output_dir=output_dir,\n            config_file=None,\n            default_config=False,\n            extra_context=None,\n            password=None,\n            directory=None,\n            skip_if_file_exists=False,\n            accept_hooks=expected,\n            keep_project_on_failure=False,\n        )\nE       AssertionError: expected call not found.\nE       Expected: cookiecutter('tests/fake-repo-pre/', None, False, replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output', config_file=None, default_config=False, extra_context=None, password=None, directory=None, skip_if_file_exists=False, accept_hooks=False, keep_project_on_failure=False)\nE       Actual: cookiecutter('tests/fake-repo-pre/', checkout=None, no_input=False, extra_context=OrderedDict(), replay=False, overwrite_if_exists=False, output_dir='/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output', config_file=None, default_config=False, password=None, directory=None, skip_if_file_exists=False, accept_hooks='ask', keep_project_on_failure=False)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('tests/fake-repo-pre/',) == ('tests/fake-repo-pre/', None, False)\nE         \nE         Right contains 2 more items, first extra item: None\nE         \nE         Full diff:\nE           (\nE               'tests/fake-repo-pre/',\nE         -     None,\nE         -     False,\nE           )\nE       Kwargs:\nE       assert {'checkout': None, 'no_input': False, 'extra_context': OrderedDict(), 'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output', 'config_file': None, 'default_config': False, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': 'ask', 'keep_project_on_failure': False} == {'replay': False, 'overwrite_if_exists': False, 'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output', 'config_file': None, 'default_config': False, 'extra_context': None, 'password': None, 'directory': None, 'skip_if_file_exists': False, 'accept_hooks': False, 'keep_project_on_failure': False}\nE         \nE         Common items:\nE         {'config_file': None,\nE          'default_config': False,\nE          'directory': None,\nE          'keep_project_on_failure': False,\nE          'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output',\nE          'overwrite_if_exists': False,\nE          'password': None,\nE          'replay': False,\nE          'skip_if_file_exists': False}\nE         Differing items:\nE         {'extra_context': OrderedDict()} != {'extra_context': None}\nE         {'accept_hooks': 'ask'} != {'accept_hooks': False}\nE         Left contains 2 more items:\nE         {'checkout': None, 'no_input': False}\nE         \nE         Full diff:\nE           {\nE         -     'accept_hooks': False,\nE         ?                     ^ - ^\nE         +     'accept_hooks': 'ask',\nE         ?                     ^  ^^\nE         +     'checkout': None,\nE               'config_file': None,\nE               'default_config': False,\nE               'directory': None,\nE         -     'extra_context': None,\nE         ?                      ^^^\nE         +     'extra_context': OrderedDict(),\nE         ?                      ^^^ +++++++++\nE               'keep_project_on_failure': False,\nE         +     'no_input': False,\nE               'output_dir': '/tmp/pytest-of-root/pytest-0/test_cli_accept_hooks___output3/output',\nE               'overwrite_if_exists': False,\nE               'password': None,\nE               'replay': False,\nE               'skip_if_file_exists': False,\nE           }\n\ntests/test_cli.py:657: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_with_json_decoding_error","title":"test_cli.py::test_cli_with_json_decoding_error","text":"<pre>test_cli.py::test_cli_with_json_decoding_error</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\n\n    @pytest.mark.usefixtures('remove_fake_project_dir')\n    def test_cli_with_json_decoding_error(cli_runner):\n        \"\"\"Test cli invocation with a malformed JSON file.\"\"\"\n        template_path = 'tests/fake-repo-bad-json/'\n        result = cli_runner(template_path, '--no-input')\n        assert result.exit_code != 0\n\n        # Validate the error message.\n        # original message from json module should be included\n        pattern = 'Expecting \\'{0,1}:\\'{0,1} delimiter: line 1 column (19|20) \\\\(char 19\\\\)'\n&gt;       assert re.search(pattern, result.output)\nE       assert None\nE        +  where None = (\"Expecting '{0,1}:'{0,1} delimiter: line 1 column (19|20) \\\\(char 19\\\\)\", '')\nE        +    where  = re.search\nE        +    and   '' = .output\n\ntests/test_cli.py:685: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clipytest_cli_with_pre_prompt_hook","title":"test_cli.py::test_cli_with_pre_prompt_hook","text":"<pre>test_cli.py::test_cli_with_pre_prompt_hook</pre><pre>\ncli_runner = .cli_main at 0x7f1eecf3e680&gt;\n\n    @pytest.mark.usefixtures('remove_fake_project_dir')\n    def test_cli_with_pre_prompt_hook(cli_runner):\n        \"\"\"Test cli invocation in a template with pre_prompt hook.\"\"\"\n        template_path = 'tests/test-pyhooks/'\n        result = cli_runner(template_path, '--no-input')\n&gt;       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = .exit_code\n\ntests/test_cli.py:699: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_cookiecutter_invocationpytest_should_invoke_main","title":"test_cookiecutter_invocation.py::test_should_invoke_main","text":"<pre>test_cookiecutter_invocation.py::test_should_invoke_main</pre><pre>\nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eeca847c0&gt;\nproject_dir = 'fake-project-templated'\n\n    @pytest.mark.usefixtures('clean_system')\n    def test_should_invoke_main(monkeypatch, project_dir):\n        \"\"\"Should create a project and exit with 0 code on cli invocation.\"\"\"\n        monkeypatch.setenv('PYTHONPATH', '.')\n\n&gt;       exit_code = subprocess.check_call(\n            [sys.executable, '-m', 'cookiecutter.cli', 'tests/fake-repo-tmpl', '--no-input']\n        )\n\ntests/test_cookiecutter_invocation.py:31: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\npopenargs = (['/testbed/.venv/bin/python3', '-m', 'cookiecutter.cli', 'tests/fake-repo-tmpl', '--no-input'],)\nkwargs = {}, retcode = 1\ncmd = ['/testbed/.venv/bin/python3', '-m', 'cookiecutter.cli', 'tests/fake-repo-tmpl', '--no-input']\n\n    def check_call(*popenargs, **kwargs):\n        \"\"\"Run command with arguments.  Wait for command to complete.  If\n        the exit code was zero then return, otherwise raise\n        CalledProcessError.  The CalledProcessError object will have the\n        return code in the returncode attribute.\n\n        The arguments are the same as for the call function.  Example:\n\n        check_call([\"ls\", \"-l\"])\n        \"\"\"\n        retcode = call(*popenargs, **kwargs)\n        if retcode:\n            cmd = kwargs.get(\"args\")\n            if cmd is None:\n                cmd = popenargs[0]\n&gt;           raise CalledProcessError(retcode, cmd)\nE           subprocess.CalledProcessError: Command '['/testbed/.venv/bin/python3', '-m', 'cookiecutter.cli', 'tests/fake-repo-tmpl', '--no-input']' returned non-zero exit status 1.\n\n/usr/lib/python3.10/subprocess.py:369: CalledProcessError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#_1","title":"]","text":"<pre>]</pre><pre>\npath = 'tests/fake-repo-pre/'\n\n    @pytest.mark.parametrize('path', ['tests/fake-repo-pre/', 'tests/fake-repo-pre'])\n    @pytest.mark.usefixtures('clean_system', 'remove_additional_dirs')\n    def test_cookiecutter_no_input_return_project_dir(path):\n        \"\"\"Verify `cookiecutter` create project dir on input with or without slash.\"\"\"\n&gt;       project_dir = main.cookiecutter(path, no_input=True)\n\ntests/test_cookiecutter_local_no_input.py:39: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/fake-repo-pre/', checkout = None, no_input = True\nextra_context = None, replay = None, overwrite_if_exists = False\noutput_dir = '.', config_file = None, default_config = False, password = None\ndirectory = None, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#fake-repo-pre","title":"fake-repo-pre]","text":"<pre>fake-repo-pre]</pre><pre>\npath = 'tests/fake-repo-pre'\n\n    @pytest.mark.parametrize('path', ['tests/fake-repo-pre/', 'tests/fake-repo-pre'])\n    @pytest.mark.usefixtures('clean_system', 'remove_additional_dirs')\n    def test_cookiecutter_no_input_return_project_dir(path):\n        \"\"\"Verify `cookiecutter` create project dir on input with or without slash.\"\"\"\n&gt;       project_dir = main.cookiecutter(path, no_input=True)\n\ntests/test_cookiecutter_local_no_input.py:39: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/fake-repo-pre', checkout = None, no_input = True\nextra_context = None, replay = None, overwrite_if_exists = False\noutput_dir = '.', config_file = None, default_config = False, password = None\ndirectory = None, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_cookiecutter_local_no_inputpytest_cookiecutter_no_input_extra_context","title":"test_cookiecutter_local_no_input.py::test_cookiecutter_no_input_extra_context","text":"<pre>test_cookiecutter_local_no_input.py::test_cookiecutter_no_input_extra_context</pre><pre>\n@pytest.mark.usefixtures('clean_system', 'remove_additional_dirs')\n    def test_cookiecutter_no_input_extra_context():\n        \"\"\"Verify `cookiecutter` accept `extra_context` argument.\"\"\"\n&gt;       main.cookiecutter(\n            'tests/fake-repo-pre',\n            no_input=True,\n            extra_context={'repo_name': 'fake-project-extra'},\n        )\n\ntests/test_cookiecutter_local_no_input.py:50: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/fake-repo-pre', checkout = None, no_input = True\nextra_context = {'repo_name': 'fake-project-extra'}, replay = None\noverwrite_if_exists = False, output_dir = '.', config_file = None\ndefault_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_cookiecutter_local_no_inputpytest_cookiecutter_templated_context","title":"test_cookiecutter_local_no_input.py::test_cookiecutter_templated_context","text":"<pre>test_cookiecutter_local_no_input.py::test_cookiecutter_templated_context</pre><pre>\n@pytest.mark.usefixtures('clean_system', 'remove_additional_dirs')\n    def test_cookiecutter_templated_context():\n        \"\"\"Verify Jinja2 templating correctly works in `cookiecutter.json` file.\"\"\"\n&gt;       main.cookiecutter('tests/fake-repo-tmpl', no_input=True)\n\ntests/test_cookiecutter_local_no_input.py:61: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/fake-repo-tmpl', checkout = None, no_input = True\nextra_context = None, replay = None, overwrite_if_exists = False\noutput_dir = '.', config_file = None, default_config = False, password = None\ndirectory = None, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_cookiecutter_local_no_inputpytest_cookiecutter_no_input_return_rendered_file","title":"test_cookiecutter_local_no_input.py::test_cookiecutter_no_input_return_rendered_file","text":"<pre>test_cookiecutter_local_no_input.py::test_cookiecutter_no_input_return_rendered_file</pre><pre>\n@pytest.mark.usefixtures('clean_system', 'remove_additional_dirs')\n    def test_cookiecutter_no_input_return_rendered_file():\n        \"\"\"Verify Jinja2 templating correctly works in `cookiecutter.json` file.\"\"\"\n&gt;       project_dir = main.cookiecutter('tests/fake-repo-pre', no_input=True)\n\ntests/test_cookiecutter_local_no_input.py:68: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/fake-repo-pre', checkout = None, no_input = True\nextra_context = None, replay = None, overwrite_if_exists = False\noutput_dir = '.', config_file = None, default_config = False, password = None\ndirectory = None, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_cookiecutter_local_no_inputpytest_cookiecutter_dict_values_in_context","title":"test_cookiecutter_local_no_input.py::test_cookiecutter_dict_values_in_context","text":"<pre>test_cookiecutter_local_no_input.py::test_cookiecutter_dict_values_in_context</pre><pre>\n@pytest.mark.usefixtures('clean_system', 'remove_additional_dirs')\n    def test_cookiecutter_dict_values_in_context():\n        \"\"\"Verify configured dictionary from `cookiecutter.json` correctly unpacked.\"\"\"\n&gt;       project_dir = main.cookiecutter('tests/fake-repo-dict', no_input=True)\n\ntests/test_cookiecutter_local_no_input.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/fake-repo-dict', checkout = None, no_input = True\nextra_context = None, replay = None, overwrite_if_exists = False\noutput_dir = '.', config_file = None, default_config = False, password = None\ndirectory = None, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_cookiecutter_local_no_inputpytest_cookiecutter_template_cleanup","title":"test_cookiecutter_local_no_input.py::test_cookiecutter_template_cleanup","text":"<pre>test_cookiecutter_local_no_input.py::test_cookiecutter_template_cleanup</pre><pre>\nmocker = \n\n    @pytest.mark.usefixtures('clean_system', 'remove_additional_dirs')\n    def test_cookiecutter_template_cleanup(mocker):\n        \"\"\"Verify temporary folder for zip unpacking dropped.\"\"\"\n        mocker.patch('tempfile.mkdtemp', return_value='fake-tmp', autospec=True)\n\n        mocker.patch(\n            'cookiecutter.prompt.prompt_and_delete', return_value=True, autospec=True\n        )\n\n&gt;       main.cookiecutter('tests/files/fake-repo-tmpl.zip', no_input=True)\n\ntests/test_cookiecutter_local_no_input.py:133: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/files/fake-repo-tmpl.zip', checkout = None, no_input = True\nextra_context = None, replay = None, overwrite_if_exists = False\noutput_dir = '.', config_file = None, default_config = False, password = None\ndirectory = None, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_cookiecutter_local_with_inputpytest_cookiecutter_local_with_input","title":"test_cookiecutter_local_with_input.py::test_cookiecutter_local_with_input","text":"<pre>test_cookiecutter_local_with_input.py::test_cookiecutter_local_with_input</pre><pre>\nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eecc15600&gt;\n\n    @pytest.mark.usefixtures('clean_system', 'remove_additional_dirs')\n    def test_cookiecutter_local_with_input(monkeypatch):\n        \"\"\"Verify simple cookiecutter run results, without extra_context provided.\"\"\"\n        monkeypatch.setattr(\n            'cookiecutter.prompt.read_user_variable',\n            lambda var, default, prompts, prefix: default,\n        )\n&gt;       main.cookiecutter('tests/fake-repo-pre/', no_input=False)\n\ntests/test_cookiecutter_local_with_input.py:27: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/fake-repo-pre/', checkout = None, no_input = False\nextra_context = None, replay = None, overwrite_if_exists = False\noutput_dir = '.', config_file = None, default_config = False, password = None\ndirectory = None, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_cookiecutter_local_with_inputpytest_cookiecutter_input_extra_context","title":"test_cookiecutter_local_with_input.py::test_cookiecutter_input_extra_context","text":"<pre>test_cookiecutter_local_with_input.py::test_cookiecutter_input_extra_context</pre><pre>\nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eed49cbb0&gt;\n\n    @pytest.mark.usefixtures('clean_system', 'remove_additional_dirs')\n    def test_cookiecutter_input_extra_context(monkeypatch):\n        \"\"\"Verify simple cookiecutter run results, with extra_context provided.\"\"\"\n        monkeypatch.setattr(\n            'cookiecutter.prompt.read_user_variable',\n            lambda var, default, prompts, prefix: default,\n        )\n&gt;       main.cookiecutter(\n            'tests/fake-repo-pre',\n            no_input=False,\n            extra_context={'repo_name': 'fake-project-input-extra'},\n        )\n\ntests/test_cookiecutter_local_with_input.py:42: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/fake-repo-pre', checkout = None, no_input = False\nextra_context = {'repo_name': 'fake-project-input-extra'}, replay = None\noverwrite_if_exists = False, output_dir = '.', config_file = None\ndefault_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_cookiecutter_nested_templatespytest_cookiecutter_nested_templatesfake-nested-templates-fake-project","title":"test_cookiecutter_nested_templates.py::test_cookiecutter_nested_templates[fake-nested-templates-fake-project]","text":"<pre>test_cookiecutter_nested_templates.py::test_cookiecutter_nested_templates[fake-nested-templates-fake-project]</pre><pre>\nmocker = \ntemplate_dir = 'fake-nested-templates', output_dir = 'fake-project'\n\n    @pytest.mark.parametrize(\n        \"template_dir,output_dir\",\n        [\n            [\"fake-nested-templates\", \"fake-project\"],\n            [\"fake-nested-templates-old-style\", \"fake-package\"],\n        ],\n    )\n    def test_cookiecutter_nested_templates(mocker, template_dir: str, output_dir: str):\n        \"\"\"Verify cookiecutter nested configuration files mechanism.\"\"\"\n        mock_generate_files = mocker.patch(\"cookiecutter.main.generate_files\")\n        main_dir = (Path(\"tests\") / template_dir).resolve()\n&gt;       main.cookiecutter(f\"{main_dir}\", no_input=True)\n\ntests/test_cookiecutter_nested_templates.py:21: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = '/testbed/tests/fake-nested-templates', checkout = None\nno_input = True, extra_context = None, replay = None\noverwrite_if_exists = False, output_dir = '.', config_file = None\ndefault_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_cookiecutter_nested_templatespytest_cookiecutter_nested_templatesfake-nested-templates-old-style-fake-package","title":"test_cookiecutter_nested_templates.py::test_cookiecutter_nested_templates[fake-nested-templates-old-style-fake-package]","text":"<pre>test_cookiecutter_nested_templates.py::test_cookiecutter_nested_templates[fake-nested-templates-old-style-fake-package]</pre><pre>\nmocker = \ntemplate_dir = 'fake-nested-templates-old-style', output_dir = 'fake-package'\n\n    @pytest.mark.parametrize(\n        \"template_dir,output_dir\",\n        [\n            [\"fake-nested-templates\", \"fake-project\"],\n            [\"fake-nested-templates-old-style\", \"fake-package\"],\n        ],\n    )\n    def test_cookiecutter_nested_templates(mocker, template_dir: str, output_dir: str):\n        \"\"\"Verify cookiecutter nested configuration files mechanism.\"\"\"\n        mock_generate_files = mocker.patch(\"cookiecutter.main.generate_files\")\n        main_dir = (Path(\"tests\") / template_dir).resolve()\n&gt;       main.cookiecutter(f\"{main_dir}\", no_input=True)\n\ntests/test_cookiecutter_nested_templates.py:21: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = '/testbed/tests/fake-nested-templates-old-style', checkout = None\nno_input = True, extra_context = None, replay = None\noverwrite_if_exists = False, output_dir = '.', config_file = None\ndefault_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_custom_extensions_in_hookspytest_hook_with_extensionpre_gen_hook","title":"test_custom_extensions_in_hooks.py::test_hook_with_extension[pre_gen_hook]","text":"<pre>test_custom_extensions_in_hooks.py::test_hook_with_extension[pre_gen_hook]</pre><pre>\ntemplate = 'tests/test-extensions/custom-extension-pre'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_hook_with_extension_pre_g0/output'\n\n    def test_hook_with_extension(template, output_dir):\n        \"\"\"Verify custom Jinja2 extension correctly work in hooks and file rendering.\n\n        Each file in hooks has simple tests inside and will raise error if not\n        correctly rendered.\n        \"\"\"\n&gt;       project_dir = main.cookiecutter(\n            template,\n            no_input=True,\n            output_dir=output_dir,\n            extra_context={'project_slug': 'foobar', 'name': 'Cookiemonster'},\n        )\n\ntests/test_custom_extensions_in_hooks.py:36: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/test-extensions/custom-extension-pre', checkout = None\nno_input = True\nextra_context = {'name': 'Cookiemonster', 'project_slug': 'foobar'}\nreplay = None, overwrite_if_exists = False\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_hook_with_extension_pre_g0/output'\nconfig_file = None, default_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_custom_extensions_in_hookspytest_hook_with_extensionpost_gen_hook","title":"test_custom_extensions_in_hooks.py::test_hook_with_extension[post_gen_hook]","text":"<pre>test_custom_extensions_in_hooks.py::test_hook_with_extension[post_gen_hook]</pre><pre>\ntemplate = 'tests/test-extensions/custom-extension-post'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_hook_with_extension_post_0/output'\n\n    def test_hook_with_extension(template, output_dir):\n        \"\"\"Verify custom Jinja2 extension correctly work in hooks and file rendering.\n\n        Each file in hooks has simple tests inside and will raise error if not\n        correctly rendered.\n        \"\"\"\n&gt;       project_dir = main.cookiecutter(\n            template,\n            no_input=True,\n            output_dir=output_dir,\n            extra_context={'project_slug': 'foobar', 'name': 'Cookiemonster'},\n        )\n\ntests/test_custom_extensions_in_hooks.py:36: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/test-extensions/custom-extension-post', checkout = None\nno_input = True\nextra_context = {'name': 'Cookiemonster', 'project_slug': 'foobar'}\nreplay = None, overwrite_if_exists = False\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_hook_with_extension_post_0/output'\nconfig_file = None, default_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_default_extensionspytest_jinja2_time_extension","title":"test_default_extensions.py::test_jinja2_time_extension","text":"<pre>test_default_extensions.py::test_jinja2_time_extension</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_jinja2_time_extension0')\n\n    def test_jinja2_time_extension(tmp_path):\n        \"\"\"Verify Jinja2 time extension work correctly.\"\"\"\n&gt;       project_dir = cookiecutter(\n            'tests/test-extensions/default/', no_input=True, output_dir=str(tmp_path)\n        )\n\ntests/test_default_extensions.py:24: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/test-extensions/default/', checkout = None, no_input = True\nextra_context = None, replay = None, overwrite_if_exists = False\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_jinja2_time_extension0'\nconfig_file = None, default_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_default_extensionspytest_jinja2_slugify_extension","title":"test_default_extensions.py::test_jinja2_slugify_extension","text":"<pre>test_default_extensions.py::test_jinja2_slugify_extension</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_jinja2_slugify_extension0')\n\n    def test_jinja2_slugify_extension(tmp_path):\n        \"\"\"Verify Jinja2 slugify extension work correctly.\"\"\"\n&gt;       project_dir = cookiecutter(\n            'tests/test-extensions/default/', no_input=True, output_dir=str(tmp_path)\n        )\n\ntests/test_default_extensions.py:47: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/test-extensions/default/', checkout = None, no_input = True\nextra_context = None, replay = None, overwrite_if_exists = False\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_jinja2_slugify_extension0'\nconfig_file = None, default_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_default_extensionspytest_jinja2_uuid_extension","title":"test_default_extensions.py::test_jinja2_uuid_extension","text":"<pre>test_default_extensions.py::test_jinja2_uuid_extension</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_jinja2_uuid_extension0')\n\n    def test_jinja2_uuid_extension(tmp_path):\n        \"\"\"Verify Jinja2 uuid extension work correctly.\"\"\"\n&gt;       project_dir = cookiecutter(\n            'tests/test-extensions/default/', no_input=True, output_dir=str(tmp_path)\n        )\n\ntests/test_default_extensions.py:56: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/test-extensions/default/', checkout = None, no_input = True\nextra_context = None, replay = None, overwrite_if_exists = False\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_jinja2_uuid_extension0'\nconfig_file = None, default_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_findpytest_find_templatetemplate-with-default-jinja-strings","title":"test_find.py::test_find_template[template with default jinja strings]","text":"<pre>test_find.py::test_find_template[template with default jinja strings]</pre><pre>\nrepo_name = 'fake-repo-pre'\nenv = \nerror_expectation = \nexpected = '{{cookiecutter.repo_name}}'\n\n    @pytest.mark.parametrize(\n        \"repo_name,context,error_expectation,expected\",\n        [\n            (\"fake-repo-pre\", {}, does_not_raise(), '{{cookiecutter.repo_name}}'),\n            (\n                \"fake-repo-pre2\",\n                {\n                    'cookiecutter': {\n                        '_jinja2_env_vars': {\n                            'variable_start_string': '{%{',\n                            'variable_end_string': '}%}',\n                        }\n                    }\n                },\n                does_not_raise(),\n                '{%{cookiecutter.repo_name}%}',\n            ),\n            (\n                \"fake-repo-pre\",\n                {\n                    'cookiecutter': {\n                        '_jinja2_env_vars': {\n                            'variable_start_string': '{%{',\n                            'variable_end_string': '}%}',\n                        }\n                    }\n                },\n                pytest.raises(NonTemplatedInputDirException),\n                None,\n            ),\n            (\"fake-repo-bad\", {}, pytest.raises(NonTemplatedInputDirException), None),\n        ],\n        ids=[\n            'template with default jinja strings',\n            'template with custom jinja strings',\n            'template with custom jinja strings but folder with default jinja strings',\n            'template missing folder',\n        ],\n    )\n    def test_find_template(repo_name, env, error_expectation, expected):\n        \"\"\"Verify correctness of `find.find_template` path detection.\"\"\"\n        repo_dir = Path('tests', repo_name)\n\n        with error_expectation:\n            template = find.find_template(repo_dir, env)\n\n            test_dir = Path(repo_dir, expected)\n&gt;           assert template == test_dir\nE           AssertionError: assert PosixPath('tests/fake-repo-pre') == PosixPath('tests/fake-repo-pre/{{cookiecutter.repo_name}}')\n\ntests/test_find.py:72: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_findpytest_find_templatetemplate-with-custom-jinja-strings","title":"test_find.py::test_find_template[template with custom jinja strings]","text":"<pre>test_find.py::test_find_template[template with custom jinja strings]</pre><pre>\nrepo_name = 'fake-repo-pre2'\nenv = \nerror_expectation = \nexpected = '{%{cookiecutter.repo_name}%}'\n\n    @pytest.mark.parametrize(\n        \"repo_name,context,error_expectation,expected\",\n        [\n            (\"fake-repo-pre\", {}, does_not_raise(), '{{cookiecutter.repo_name}}'),\n            (\n                \"fake-repo-pre2\",\n                {\n                    'cookiecutter': {\n                        '_jinja2_env_vars': {\n                            'variable_start_string': '{%{',\n                            'variable_end_string': '}%}',\n                        }\n                    }\n                },\n                does_not_raise(),\n                '{%{cookiecutter.repo_name}%}',\n            ),\n            (\n                \"fake-repo-pre\",\n                {\n                    'cookiecutter': {\n                        '_jinja2_env_vars': {\n                            'variable_start_string': '{%{',\n                            'variable_end_string': '}%}',\n                        }\n                    }\n                },\n                pytest.raises(NonTemplatedInputDirException),\n                None,\n            ),\n            (\"fake-repo-bad\", {}, pytest.raises(NonTemplatedInputDirException), None),\n        ],\n        ids=[\n            'template with default jinja strings',\n            'template with custom jinja strings',\n            'template with custom jinja strings but folder with default jinja strings',\n            'template missing folder',\n        ],\n    )\n    def test_find_template(repo_name, env, error_expectation, expected):\n        \"\"\"Verify correctness of `find.find_template` path detection.\"\"\"\n        repo_dir = Path('tests', repo_name)\n\n        with error_expectation:\n            template = find.find_template(repo_dir, env)\n\n            test_dir = Path(repo_dir, expected)\n&gt;           assert template == test_dir\nE           AssertionError: assert PosixPath('tests/fake-repo-pre2') == PosixPath('tests/fake-repo-pre2/{%{cookiecutter.repo_name}%}')\n\ntests/test_find.py:72: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_findpytest_find_templatetemplate-with-custom-jinja-strings-but-folder-with-default-jinja-strings","title":"test_find.py::test_find_template[template with custom jinja strings but folder with default jinja strings]","text":"<pre>test_find.py::test_find_template[template with custom jinja strings but folder with default jinja strings]</pre><pre>\nrepo_name = 'fake-repo-pre'\nenv = \nerror_expectation = &lt;_pytest.python_api.RaisesContext object at 0x7f1eed19d390&gt;\nexpected = None\n\n    @pytest.mark.parametrize(\n        \"repo_name,context,error_expectation,expected\",\n        [\n            (\"fake-repo-pre\", {}, does_not_raise(), '{{cookiecutter.repo_name}}'),\n            (\n                \"fake-repo-pre2\",\n                {\n                    'cookiecutter': {\n                        '_jinja2_env_vars': {\n                            'variable_start_string': '{%{',\n                            'variable_end_string': '}%}',\n                        }\n                    }\n                },\n                does_not_raise(),\n                '{%{cookiecutter.repo_name}%}',\n            ),\n            (\n                \"fake-repo-pre\",\n                {\n                    'cookiecutter': {\n                        '_jinja2_env_vars': {\n                            'variable_start_string': '{%{',\n                            'variable_end_string': '}%}',\n                        }\n                    }\n                },\n                pytest.raises(NonTemplatedInputDirException),\n                None,\n            ),\n            (\"fake-repo-bad\", {}, pytest.raises(NonTemplatedInputDirException), None),\n        ],\n        ids=[\n            'template with default jinja strings',\n            'template with custom jinja strings',\n            'template with custom jinja strings but folder with default jinja strings',\n            'template missing folder',\n        ],\n    )\n    def test_find_template(repo_name, env, error_expectation, expected):\n        \"\"\"Verify correctness of `find.find_template` path detection.\"\"\"\n        repo_dir = Path('tests', repo_name)\n\n        with error_expectation:\n            template = find.find_template(repo_dir, env)\n\n&gt;           test_dir = Path(repo_dir, expected)\n\ntests/test_find.py:71: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.10/pathlib.py:960: in __new__\n    self = cls._from_parts(args)\n/usr/lib/python3.10/pathlib.py:594: in _from_parts\n    drv, root, parts = self._parse_args(args)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = \nargs = (PosixPath('tests/fake-repo-pre'), None)\n\n    @classmethod\n    def _parse_args(cls, args):\n        # This is useful when you don't want to create an instance, just\n        # canonicalize some constructor arguments.\n        parts = []\n        for a in args:\n            if isinstance(a, PurePath):\n                parts += a._parts\n            else:\n&gt;               a = os.fspath(a)\nE               TypeError: expected str, bytes or os.PathLike object, not NoneType\n\n/usr/lib/python3.10/pathlib.py:578: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_generate_contextpytest_generate_contextinput_params0-expected_context0","title":"test_generate_context.py::test_generate_context[input_params0-expected_context0]","text":"<pre>test_generate_context.py::test_generate_context[input_params0-expected_context0]</pre><pre>\ninput_params = {'context_file': 'tests/test-generate-context/test.json'}\nexpected_context = {'test': {'1': 2, 'some_key': 'some_val'}}\n\n    @pytest.mark.usefixtures('clean_system')\n    @pytest.mark.parametrize('input_params, expected_context', context_data())\n    def test_generate_context(input_params, expected_context):\n        \"\"\"Verify input contexts combinations result in expected content on output.\"\"\"\n&gt;       assert generate.generate_context(**input_params) == expected_context\nE       AssertionError: assert OrderedDict([('1', 2), ('some_key', 'some_val')]) == {'test': {'1': 2, 'some_key': 'some_val'}}\nE         \nE         Left contains 2 more items:\nE         {'1': 2, 'some_key': 'some_val'}\nE         Right contains 1 more item:\nE         {'test': {'1': 2, 'some_key': 'some_val'}}\nE         \nE         Full diff:\nE         + OrderedDict({\nE         - {\nE         -     'test': {\nE         -         '1': 2,\nE         ? ----\nE         +     '1': 2,\nE         -         'some_key': 'some_val',\nE         ? ----\nE         +     'some_key': 'some_val',\nE         + })\nE         -     },\nE         - }\n\ntests/test_generate_context.py:58: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_contextpytest_generate_contextinput_params1-expected_context1","title":"test_generate_context.py::test_generate_context[input_params1-expected_context1]","text":"<pre>test_generate_context.py::test_generate_context[input_params1-expected_context1]</pre><pre>\ninput_params = {'context_file': 'tests/test-generate-context/test.json', 'default_context': {'1': 3}}\nexpected_context = {'test': {'1': 3, 'some_key': 'some_val'}}\n\n    @pytest.mark.usefixtures('clean_system')\n    @pytest.mark.parametrize('input_params, expected_context', context_data())\n    def test_generate_context(input_params, expected_context):\n        \"\"\"Verify input contexts combinations result in expected content on output.\"\"\"\n&gt;       assert generate.generate_context(**input_params) == expected_context\nE       AssertionError: assert OrderedDict([('1', '3'), ('some_key', 'some_val')]) == {'test': {'1': 3, 'some_key': 'some_val'}}\nE         \nE         Left contains 2 more items:\nE         {'1': '3', 'some_key': 'some_val'}\nE         Right contains 1 more item:\nE         {'test': {'1': 3, 'some_key': 'some_val'}}\nE         \nE         Full diff:\nE         + OrderedDict({\nE         - {\nE         -     'test': {\nE         -         '1': 3,\nE         ? ----\nE         +     '1': '3',\nE         ?          + +\nE         -         'some_key': 'some_val',\nE         ? ----\nE         +     'some_key': 'some_val',\nE         + })\nE         -     },\nE         - }\n\ntests/test_generate_context.py:58: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_contextpytest_generate_contextinput_params2-expected_context2","title":"test_generate_context.py::test_generate_context[input_params2-expected_context2]","text":"<pre>test_generate_context.py::test_generate_context[input_params2-expected_context2]</pre><pre>\ninput_params = {'context_file': 'tests/test-generate-context/test.json', 'extra_context': {'1': 4}}\nexpected_context = {'test': {'1': 4, 'some_key': 'some_val'}}\n\n    @pytest.mark.usefixtures('clean_system')\n    @pytest.mark.parametrize('input_params, expected_context', context_data())\n    def test_generate_context(input_params, expected_context):\n        \"\"\"Verify input contexts combinations result in expected content on output.\"\"\"\n&gt;       assert generate.generate_context(**input_params) == expected_context\nE       AssertionError: assert OrderedDict([('1', '4'), ('some_key', 'some_val')]) == {'test': {'1': 4, 'some_key': 'some_val'}}\nE         \nE         Left contains 2 more items:\nE         {'1': '4', 'some_key': 'some_val'}\nE         Right contains 1 more item:\nE         {'test': {'1': 4, 'some_key': 'some_val'}}\nE         \nE         Full diff:\nE         + OrderedDict({\nE         - {\nE         -     'test': {\nE         -         '1': 4,\nE         ? ----\nE         +     '1': '4',\nE         ?          + +\nE         -         'some_key': 'some_val',\nE         ? ----\nE         +     'some_key': 'some_val',\nE         + })\nE         -     },\nE         - }\n\ntests/test_generate_context.py:58: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_contextpytest_generate_contextinput_params3-expected_context3","title":"test_generate_context.py::test_generate_context[input_params3-expected_context3]","text":"<pre>test_generate_context.py::test_generate_context[input_params3-expected_context3]</pre><pre>\ninput_params = {'context_file': 'tests/test-generate-context/test.json', 'default_context': {'1': 3}, 'extra_context': {'1': 5}}\nexpected_context = {'test': {'1': 5, 'some_key': 'some_val'}}\n\n    @pytest.mark.usefixtures('clean_system')\n    @pytest.mark.parametrize('input_params, expected_context', context_data())\n    def test_generate_context(input_params, expected_context):\n        \"\"\"Verify input contexts combinations result in expected content on output.\"\"\"\n&gt;       assert generate.generate_context(**input_params) == expected_context\nE       AssertionError: assert OrderedDict([('1', '5'), ('some_key', 'some_val')]) == {'test': {'1': 5, 'some_key': 'some_val'}}\nE         \nE         Left contains 2 more items:\nE         {'1': '5', 'some_key': 'some_val'}\nE         Right contains 1 more item:\nE         {'test': {'1': 5, 'some_key': 'some_val'}}\nE         \nE         Full diff:\nE         + OrderedDict({\nE         - {\nE         -     'test': {\nE         -         '1': 5,\nE         ? ----\nE         +     '1': '5',\nE         ?          + +\nE         -         'some_key': 'some_val',\nE         ? ----\nE         +     'some_key': 'some_val',\nE         + })\nE         -     },\nE         - }\n\ntests/test_generate_context.py:58: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_contextpytest_default_context_replacement_in_generate_context","title":"test_generate_context.py::test_default_context_replacement_in_generate_context","text":"<pre>test_generate_context.py::test_default_context_replacement_in_generate_context</pre><pre>\ndef test_default_context_replacement_in_generate_context():\n        \"\"\"Verify default content settings are correctly replaced by template settings.\n\n        Make sure that the default for list variables of `orientation` is based on\n        the user config (`choices_template.json`) and not changed to a single value\n        from `default_context`.\n        \"\"\"\n        expected_context = {\n            'choices_template': OrderedDict(\n                [\n                    ('full_name', 'Raphael Pierzina'),\n                    ('github_username', 'hackebrot'),\n                    ('project_name', 'Kivy Project'),\n                    ('repo_name', '{{cookiecutter.project_name|lower}}'),\n                    ('orientation', ['landscape', 'all', 'portrait']),\n                ]\n            )\n        }\n\n        generated_context = generate.generate_context(\n            context_file='tests/test-generate-context/choices_template.json',\n            default_context={\n                'not_in_template': 'foobar',\n                'project_name': 'Kivy Project',\n                'orientation': 'landscape',\n            },\n            extra_context={\n                'also_not_in_template': 'foobar2',\n                'github_username': 'hackebrot',\n            },\n        )\n\n&gt;       assert generated_context == expected_context\nE       AssertionError: assert OrderedDict([('full_name', 'Raphael Pierzina'), ('github_username', 'hackebrot'), ('project_name', 'Kivy Project'), ('repo_name', '{{cookiecutter.project_name|lower}}'), ('orientation', 'landscape'), ('not_in_template', 'foobar'), ('also_not_in_template', 'foobar2')]) == {'choices_template': OrderedDict([('full_name', 'Raphael Pierzina'), ('github_username', 'hackebrot'), ('project_name', 'Kivy Project'), ('repo_name', '{{cookiecutter.project_name|lower}}'), ('orientation', ['landscape', 'all', 'portrait'])])}\nE         \nE         Left contains 7 more items:\nE         {'also_not_in_template': 'foobar2',\nE          'full_name': 'Raphael Pierzina',\nE          'github_username': 'hackebrot',\nE          'not_in_template': 'foobar',\nE          'orientation': 'landscape',\nE          'project_name': 'Kivy Project',\nE          'repo_name': '{{cookiecutter.project_name|lower}}'}\nE         Right contains 1 more item:\nE         {'choices_template': OrderedDict([('full_name', 'Raphael Pierzina'),\nE                                           ('github_username', 'hackebrot'),\nE                                           ('project_name', 'Kivy Project'),\nE                                           ('repo_name',\nE                                            '{{cookiecutter.project_name|lower}}'),\nE                                           ('orientation',\nE                                            ['landscape', 'all', 'portrait'])])}\nE         \nE         Full diff:\nE         - {\nE         -     'choices_template': OrderedDict({\nE         + OrderedDict({\nE         +     'also_not_in_template': 'foobar2',\nE         -         'full_name': 'Raphael Pierzina',\nE         ? ----\nE         +     'full_name': 'Raphael Pierzina',\nE         -         'github_username': 'hackebrot',\nE         ? ----\nE         +     'github_username': 'hackebrot',\nE         +     'not_in_template': 'foobar',\nE         +     'orientation': 'landscape',\nE         -         'orientation': [\nE         -             'landscape',\nE         -             'all',\nE         -             'portrait',\nE         -         ],\nE         -         'project_name': 'Kivy Project',\nE         ? ----\nE         +     'project_name': 'Kivy Project',\nE         -         'repo_name': '{{cookiecutter.project_name|lower}}',\nE         ? ----\nE         +     'repo_name': '{{cookiecutter.project_name|lower}}',\nE         + })\nE         -     }),\nE         - }\n\ntests/test_generate_context.py:109: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_contextpytest_generate_context_decodes_non_ascii_chars","title":"test_generate_context.py::test_generate_context_decodes_non_ascii_chars","text":"<pre>test_generate_context.py::test_generate_context_decodes_non_ascii_chars</pre><pre>\ndef test_generate_context_decodes_non_ascii_chars():\n        \"\"\"Verify `generate_context` correctly decodes non-ascii chars.\"\"\"\n        expected_context = {\n            'non_ascii': OrderedDict(\n                [\n                    ('full_name', '\u00e9\u00e8\u00e0'),\n                ]\n            )\n        }\n\n        generated_context = generate.generate_context(\n            context_file='tests/test-generate-context/non_ascii.json'\n        )\n\n&gt;       assert generated_context == expected_context\nE       AssertionError: assert OrderedDict([('full_name', '\u00e9\u00e8\u00e0')]) == {'non_ascii': OrderedDict([('full_name', '\u00e9\u00e8\u00e0')])}\nE         \nE         Left contains 1 more item:\nE         {'full_name': '\u00e9\u00e8\u00e0'}\nE         Right contains 1 more item:\nE         {'non_ascii': OrderedDict([('full_name', '\u00e9\u00e8\u00e0')])}\nE         \nE         Full diff:\nE         + OrderedDict({\nE         - {\nE         -     'non_ascii': OrderedDict({\nE         -         'full_name': '\u00e9\u00e8\u00e0',\nE         ? ----\nE         +     'full_name': '\u00e9\u00e8\u00e0',\nE         + })\nE         -     }),\nE         - }\n\ntests/test_generate_context.py:126: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_contextpytest_apply_overwrites_does_include_unused_variables","title":"test_generate_context.py::test_apply_overwrites_does_include_unused_variables","text":"<pre>test_generate_context.py::test_apply_overwrites_does_include_unused_variables</pre><pre>\ntemplate_context = OrderedDict([('full_name', 'Raphael Pierzina'), ('github_username', 'hackebrot'), ('project_name', 'Kivy Project'), ('repo_name', '{{cookiecutter.project_name|lower}}'), ('orientation', ['all', 'landscape', 'portrait']), ('deployment_regions', ['eu', 'us', 'ap']), ('deployments', {'preprod': ['eu', 'us', 'ap'], 'prod': ['eu', 'us', 'ap']}), ('not in template', 'foobar')])\n\n    def test_apply_overwrites_does_include_unused_variables(template_context):\n        \"\"\"Verify `apply_overwrites_to_context` skips variables that are not in context.\"\"\"\n        generate.apply_overwrites_to_context(\n            context=template_context, overwrite_context={'not in template': 'foobar'}\n        )\n\n&gt;       assert 'not in template' not in template_context\nE       AssertionError: assert 'not in template' not in OrderedDict([('full_name', 'Raphael Pierzina'), ('github_username', 'hackebrot'), ('project_name', 'Kivy Project'), ('repo_name', '{{cookiecutter.project_name|lower}}'), ('orientation', ['all', 'landscape', 'portrait']), ('deployment_regions', ['eu', 'us', 'ap']), ('deployments', {'preprod': ['eu', 'us', 'ap'], 'prod': ['eu', 'us', 'ap']}), ('not in template', 'foobar')])\n\ntests/test_generate_context.py:157: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_contextpytest_apply_overwrites_does_not_modify_choices_for_invalid_overwrite","title":"test_generate_context.py::test_apply_overwrites_does_not_modify_choices_for_invalid_overwrite","text":"<pre>test_generate_context.py::test_apply_overwrites_does_not_modify_choices_for_invalid_overwrite</pre><pre>\ndef test_apply_overwrites_does_not_modify_choices_for_invalid_overwrite():\n        \"\"\"Verify variables overwrite for list if variable not in list ignored.\"\"\"\n        expected_context = {\n            'choices_template': OrderedDict(\n                [\n                    ('full_name', 'Raphael Pierzina'),\n                    ('github_username', 'hackebrot'),\n                    ('project_name', 'Kivy Project'),\n                    ('repo_name', '{{cookiecutter.project_name|lower}}'),\n                    ('orientation', ['all', 'landscape', 'portrait']),\n                ]\n            )\n        }\n\n&gt;       with pytest.warns(UserWarning, match=\"Invalid default received\"):\nE       Failed: DID NOT WARN. No warnings of type (,) were emitted.\nE        Emitted warnings: [].\n\ntests/test_generate_context.py:183: Failed"},{"location":"analysis_baseline_cookiecutter/#test_generate_contextpytest_apply_overwrites_invalid_overwrite","title":"test_generate_context.py::test_apply_overwrites_invalid_overwrite","text":"<pre>test_generate_context.py::test_apply_overwrites_invalid_overwrite</pre><pre>\ntemplate_context = OrderedDict([('full_name', 'Raphael Pierzina'), ('github_username', 'hackebrot'), ('project_name', 'Kivy Project'), ('repo_name', '{{cookiecutter.project_name|lower}}'), ('orientation', 'foobar'), ('deployment_regions', ['eu', 'us', 'ap']), ('deployments', {'preprod': ['eu', 'us', 'ap'], 'prod': ['eu', 'us', 'ap']})])\n\n    def test_apply_overwrites_invalid_overwrite(template_context):\n        \"\"\"Verify variables overwrite for list if variable not in list not ignored.\"\"\"\n&gt;       with pytest.raises(ValueError):\nE       Failed: DID NOT RAISE \n\ntests/test_generate_context.py:202: Failed"},{"location":"analysis_baseline_cookiecutter/#test_generate_contextpytest_apply_overwrites_sets_multichoice_values","title":"test_generate_context.py::test_apply_overwrites_sets_multichoice_values","text":"<pre>test_generate_context.py::test_apply_overwrites_sets_multichoice_values</pre><pre>\ntemplate_context = OrderedDict([('full_name', 'Raphael Pierzina'), ('github_username', 'hackebrot'), ('project_name', 'Kivy Project'), ('repo_name', '{{cookiecutter.project_name|lower}}'), ('orientation', ['all', 'landscape', 'portrait']), ('deployment_regions', ['eu', 'us', 'ap', 'eu']), ('deployments', {'preprod': ['eu', 'us', 'ap'], 'prod': ['eu', 'us', 'ap']})])\n\n    def test_apply_overwrites_sets_multichoice_values(template_context):\n        \"\"\"Verify variable overwrite for list given multiple valid values.\"\"\"\n        generate.apply_overwrites_to_context(\n            context=template_context,\n            overwrite_context={'deployment_regions': ['eu']},\n        )\n&gt;       assert template_context['deployment_regions'] == ['eu']\nE       AssertionError: assert ['eu', 'us', 'ap', 'eu'] == ['eu']\nE         \nE         Left contains 3 more items, first extra item: 'us'\nE         \nE         Full diff:\nE           [\nE               'eu',\nE         +     'us',\nE         +     'ap',\nE         +     'eu',\nE           ]\n\ntests/test_generate_context.py:214: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_contextpytest_apply_overwrites_invalid_multichoice_values","title":"test_generate_context.py::test_apply_overwrites_invalid_multichoice_values","text":"<pre>test_generate_context.py::test_apply_overwrites_invalid_multichoice_values</pre><pre>\ntemplate_context = OrderedDict([('full_name', 'Raphael Pierzina'), ('github_username', 'hackebrot'), ('project_name', 'Kivy Project'), ('repo_name', '{{cookiecutter.project_name|lower}}'), ('orientation', ['all', 'landscape', 'portrait']), ('deployment_regions', ['eu', 'us', 'ap', 'na']), ('deployments', {'preprod': ['eu', 'us', 'ap'], 'prod': ['eu', 'us', 'ap']})])\n\n    def test_apply_overwrites_invalid_multichoice_values(template_context):\n        \"\"\"Verify variable overwrite for list given invalid list entries not ignored.\"\"\"\n&gt;       with pytest.raises(ValueError):\nE       Failed: DID NOT RAISE \n\ntests/test_generate_context.py:219: Failed"},{"location":"analysis_baseline_cookiecutter/#test_generate_contextpytest_apply_overwrites_error_additional_values","title":"test_generate_context.py::test_apply_overwrites_error_additional_values","text":"<pre>test_generate_context.py::test_apply_overwrites_error_additional_values</pre><pre>\ntemplate_context = OrderedDict([('full_name', 'Raphael Pierzina'), ('github_username', 'hackebrot'), ('project_name', 'Kivy Project'), ('repo_name', '{{cookiecutter.project_name|lower}}'), ('orientation', ['all', 'landscape', 'portrait']), ('deployment_regions', ['eu', 'us', 'ap', 'eu', 'na']), ('deployments', {'preprod': ['eu', 'us', 'ap'], 'prod': ['eu', 'us', 'ap']})])\n\n    def test_apply_overwrites_error_additional_values(template_context):\n        \"\"\"Verify variable overwrite for list given additional entries not ignored.\"\"\"\n&gt;       with pytest.raises(ValueError):\nE       Failed: DID NOT RAISE \n\ntests/test_generate_context.py:228: Failed"},{"location":"analysis_baseline_cookiecutter/#test_generate_contextpytest_apply_overwrites_in_dictionaries","title":"test_generate_context.py::test_apply_overwrites_in_dictionaries","text":"<pre>test_generate_context.py::test_apply_overwrites_in_dictionaries</pre><pre>\ntemplate_context = OrderedDict([('full_name', 'Raphael Pierzina'), ('github_username', 'hackebrot'), ('project_name', 'Kivy Project'), ('repo_name', '{{cookiecutter.project_name|lower}}'), ('orientation', ['all', 'landscape', 'portrait']), ('deployment_regions', ['eu', 'us', 'ap']), ('deployments', {'preprod': ['eu', 'us', 'ap', 'eu'], 'prod': ['eu', 'us', 'ap', 'ap']})])\n\n    def test_apply_overwrites_in_dictionaries(template_context):\n        \"\"\"Verify variable overwrite for lists nested in dictionary variables.\"\"\"\n        generate.apply_overwrites_to_context(\n            context=template_context,\n            overwrite_context={'deployments': {'preprod': ['eu'], 'prod': ['ap']}},\n        )\n&gt;       assert template_context['deployments']['preprod'] == ['eu']\nE       AssertionError: assert ['eu', 'us', 'ap', 'eu'] == ['eu']\nE         \nE         Left contains 3 more items, first extra item: 'us'\nE         \nE         Full diff:\nE           [\nE               'eu',\nE         +     'us',\nE         +     'ap',\nE         +     'eu',\nE           ]\n\ntests/test_generate_context.py:241: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_contextpytest_apply_overwrites_sets_default_for_choice_variable","title":"test_generate_context.py::test_apply_overwrites_sets_default_for_choice_variable","text":"<pre>test_generate_context.py::test_apply_overwrites_sets_default_for_choice_variable</pre><pre>\ntemplate_context = OrderedDict([('full_name', 'Raphael Pierzina'), ('github_username', 'hackebrot'), ('project_name', 'Kivy Project'), ('repo_name', '{{cookiecutter.project_name|lower}}'), ('orientation', 'landscape'), ('deployment_regions', ['eu', 'us', 'ap']), ('deployments', {'preprod': ['eu', 'us', 'ap'], 'prod': ['eu', 'us', 'ap']})])\n\n    def test_apply_overwrites_sets_default_for_choice_variable(template_context):\n        \"\"\"Verify overwritten list member became a default value.\"\"\"\n        generate.apply_overwrites_to_context(\n            context=template_context, overwrite_context={'orientation': 'landscape'}\n        )\n\n&gt;       assert template_context['orientation'] == ['landscape', 'all', 'portrait']\nE       AssertionError: assert 'landscape' == ['landscape', 'all', 'portrait']\n\ntests/test_generate_context.py:251: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_contextpytest_apply_overwrites_in_nested_dict","title":"test_generate_context.py::test_apply_overwrites_in_nested_dict","text":"<pre>test_generate_context.py::test_apply_overwrites_in_nested_dict</pre><pre>\ndef test_apply_overwrites_in_nested_dict():\n        \"\"\"Verify nested dict in default content settings are correctly replaced.\"\"\"\n        expected_context = {\n            'nested_dict': OrderedDict(\n                [\n                    ('full_name', 'Raphael Pierzina'),\n                    ('github_username', 'hackebrot'),\n                    (\n                        'project',\n                        OrderedDict(\n                            [\n                                ('name', 'My Kivy Project'),\n                                ('description', 'My Kivy Project'),\n                                ('repo_name', '{{cookiecutter.project_name|lower}}'),\n                                ('orientation', [\"all\", \"landscape\", \"portrait\"]),\n                            ]\n                        ),\n                    ),\n                ]\n            )\n        }\n\n        generated_context = generate.generate_context(\n            context_file='tests/test-generate-context/nested_dict.json',\n            default_context={\n                'not_in_template': 'foobar',\n                'project': {\n                    'description': 'My Kivy Project',\n                },\n            },\n            extra_context={\n                'also_not_in_template': 'foobar2',\n                'github_username': 'hackebrot',\n                'project': {\n                    'name': 'My Kivy Project',\n                },\n            },\n        )\n\n&gt;       assert generated_context == expected_context\nE       AssertionError: assert OrderedDict([('full_name', 'Raphael Pierzina'), ('github_username', 'hackebrot'), ('project', OrderedDict([('name', 'My Kivy Project'), ('description', 'My Kivy Project'), ('repo_name', '{{cookiecutter.project_name|lower}}'), ('orientation', ['all', 'landscape', 'portrait'])])), ('not_in_template', 'foobar'), ('also_not_in_template', 'foobar2')]) == {'nested_dict': OrderedDict([('full_name', 'Raphael Pierzina'), ('github_username', 'hackebrot'), ('project', OrderedDict([('name', 'My Kivy Project'), ('description', 'My Kivy Project'), ('repo_name', '{{cookiecutter.project_name|lower}}'), ('orientation', ['all', 'landscape', 'portrait'])]))])}\nE         \nE         Left contains 5 more items:\nE         {'also_not_in_template': 'foobar2',\nE          'full_name': 'Raphael Pierzina',\nE          'github_username': 'hackebrot',\nE          'not_in_template': 'foobar',\nE          'project': OrderedDict([('name', 'My Kivy Project'),\nE                                  ('description', 'My Kivy Project'),\nE                                  ('repo_name', '{{cookiecutter.project_name|lower}}'),\nE                                  ('orientation', ['all', 'landscape', 'portrait'])])}\nE         Right contains 1 more item:\nE         {'nested_dict': OrderedDict([('full_name', 'Raphael Pierzina'),\nE                                      ('github_username', 'hackebrot'),\nE                                      ('project',\nE                                       OrderedDict([('name', 'My Kivy Project'),\nE                                                    ('description', 'My Kivy Project'),\nE                                                    ('repo_name',\nE                                                     '{{cookiecutter.project_name|lower}}'),\nE                                                    ('orientation',\nE                                                     ['all',\nE                                                      'landscape',\nE                                                      'portrait'])]))])}\nE         \nE         Full diff:\nE         - {\nE         -     'nested_dict': OrderedDict({\nE         + OrderedDict({\nE         +     'also_not_in_template': 'foobar2',\nE         -         'full_name': 'Raphael Pierzina',\nE         ? ----\nE         +     'full_name': 'Raphael Pierzina',\nE         -         'github_username': 'hackebrot',\nE         ? ----\nE         +     'github_username': 'hackebrot',\nE         +     'not_in_template': 'foobar',\nE         -         'project': OrderedDict({\nE         ? ----\nE         +     'project': OrderedDict({\nE         -             'description': 'My Kivy Project',\nE         ? ----\nE         +         'description': 'My Kivy Project',\nE         -             'name': 'My Kivy Project',\nE         ? ----\nE         +         'name': 'My Kivy Project',\nE         -             'orientation': [\nE         ? ----\nE         +         'orientation': [\nE         -                 'all',\nE         ? ----\nE         +             'all',\nE         -                 'landscape',\nE         ? ----\nE         +             'landscape',\nE         -                 'portrait',\nE         ? ----\nE         +             'portrait',\nE         -             ],\nE         ? ----\nE         +         ],\nE         -             'repo_name': '{{cookiecutter.project_name|lower}}',\nE         ? ----\nE         +         'repo_name': '{{cookiecutter.project_name|lower}}',\nE         -         }),\nE               }),\nE         - }\nE         + })\n\ntests/test_generate_context.py:293: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_contextpytest_apply_overwrites_in_nested_dict_additional_values","title":"test_generate_context.py::test_apply_overwrites_in_nested_dict_additional_values","text":"<pre>test_generate_context.py::test_apply_overwrites_in_nested_dict_additional_values</pre><pre>\ndef test_apply_overwrites_in_nested_dict_additional_values():\n        \"\"\"Verify nested dict in default content settings are correctly added.\"\"\"\n        expected_context = {\n            'nested_dict_additional': OrderedDict(\n                [\n                    ('mainkey1', 'mainvalue1'),\n                    (\n                        'mainkey2',\n                        OrderedDict(\n                            [\n                                ('subkey1', 'subvalue1'),\n                                (\n                                    'subkey2',\n                                    OrderedDict(\n                                        [\n                                            ('subsubkey1', 'subsubvalue1'),\n                                            ('subsubkey2', 'subsubvalue2_default'),\n                                            ('subsubkey3', 'subsubvalue3_extra'),\n                                        ]\n                                    ),\n                                ),\n                                ('subkey4', 'subvalue4_default'),\n                                ('subkey5', 'subvalue5_extra'),\n                            ]\n                        ),\n                    ),\n                ]\n            )\n        }\n\n        generated_context = generate.generate_context(\n            context_file='tests/test-generate-context/nested_dict_additional.json',\n            default_context={\n                'not_in_template': 'foobar',\n                'mainkey2': {\n                    'subkey2': {\n                        'subsubkey2': 'subsubvalue2_default',\n                    },\n                    'subkey4': 'subvalue4_default',\n                },\n            },\n            extra_context={\n                'also_not_in_template': 'foobar2',\n                'mainkey2': {\n                    'subkey2': {\n                        'subsubkey3': 'subsubvalue3_extra',\n                    },\n                    'subkey5': 'subvalue5_extra',\n                },\n            },\n        )\n\n&gt;       assert generated_context == expected_context\nE       AssertionError: assert OrderedDict([('mainkey1', 'mainvalue1'), ('mainkey2', OrderedDict([('subkey1', 'subvalue1'), ('subkey2', OrderedDict([('subsubkey1', 'subsubvalue1'), ('subsubkey2', 'subsubvalue2_default'), ('subsubkey3', 'subsubvalue3_extra')])), ('subkey4', 'subvalue4_default'), ('subkey5', 'subvalue5_extra')])), ('not_in_template', 'foobar'), ('also_not_in_template', 'foobar2')]) == {'nested_dict_additional': OrderedDict([('mainkey1', 'mainvalue1'), ('mainkey2', OrderedDict([('subkey1', 'subvalue1'), ('subkey2', OrderedDict([('subsubkey1', 'subsubvalue1'), ('subsubkey2', 'subsubvalue2_default'), ('subsubkey3', 'subsubvalue3_extra')])), ('subkey4', 'subvalue4_default'), ('subkey5', 'subvalue5_extra')]))])}\nE         \nE         Left contains 4 more items:\nE         {'also_not_in_template': 'foobar2',\nE          'mainkey1': 'mainvalue1',\nE          'mainkey2': OrderedDict([('subkey1', 'subvalue1'),\nE                                   ('subkey2',\nE                                    OrderedDict([('subsubkey1', 'subsubvalue1'),\nE                                                 ('subsubkey2', 'subsubvalue2_default'),\nE                                                 ('subsubkey3', 'subsubvalue3_extra')])),\nE                                   ('subkey4', 'subvalue4_default'),\nE                                   ('subkey5', 'subvalue5_extra')]),\nE          'not_in_template': 'foobar'}\nE         Right contains 1 more item:\nE         {'nested_dict_additional': OrderedDict([('mainkey1', 'mainvalue1'),\nE                                                 ('mainkey2',\nE                                                  OrderedDict([('subkey1', 'subvalue1'),\nE                                                               ('subkey2',\nE                                                                OrderedDict([('subsubkey1',\nE                                                                              'subsubvalue1'),\nE                                                                             ('subsubkey2',\nE                                                                              'subsubvalue2_default'),\nE                                                                             ('subsubkey3',\nE                                                                              'subsubvalue3_extra')])),\nE                                                               ('subkey4',\nE                                                                'subvalue4_default'),\nE                                                               ('subkey5',\nE                                                                'subvalue5_extra')]))])}\nE         \nE         Full diff:\nE         - {\nE         -     'nested_dict_additional': OrderedDict({\nE         + OrderedDict({\nE         +     'also_not_in_template': 'foobar2',\nE         -         'mainkey1': 'mainvalue1',\nE         ? ----\nE         +     'mainkey1': 'mainvalue1',\nE         -         'mainkey2': OrderedDict({\nE         ? ----\nE         +     'mainkey2': OrderedDict({\nE         -             'subkey1': 'subvalue1',\nE         ? ----\nE         +         'subkey1': 'subvalue1',\nE         -             'subkey2': OrderedDict({\nE         ? ----\nE         +         'subkey2': OrderedDict({\nE         -                 'subsubkey1': 'subsubvalue1',\nE         ? ----\nE         +             'subsubkey1': 'subsubvalue1',\nE         -                 'subsubkey2': 'subsubvalue2_default',\nE         ? ----\nE         +             'subsubkey2': 'subsubvalue2_default',\nE         -                 'subsubkey3': 'subsubvalue3_extra',\nE         ? ----\nE         +             'subsubkey3': 'subsubvalue3_extra',\nE         -             }),\nE         -             'subkey4': 'subvalue4_default',\nE         -             'subkey5': 'subvalue5_extra',\nE                   }),\nE         +         'subkey4': 'subvalue4_default',\nE         +         'subkey5': 'subvalue5_extra',\nE               }),\nE         - }\nE         +     'not_in_template': 'foobar',\nE         + })\n\ntests/test_generate_context.py:364: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_copy_without_renderpytest_generate_copy_without_render_extensions","title":"test_generate_copy_without_render.py::test_generate_copy_without_render_extensions","text":"<pre>test_generate_copy_without_render.py::test_generate_copy_without_render_extensions</pre><pre>\n@pytest.mark.usefixtures('clean_system', 'remove_test_dir')\n    def test_generate_copy_without_render_extensions():\n        \"\"\"Verify correct work of `_copy_without_render` context option.\n\n        Some files/directories should be rendered during invocation,\n        some just copied, without any modification.\n        \"\"\"\n&gt;       generate.generate_files(\n            context={\n                'cookiecutter': {\n                    'repo_name': 'test_copy_without_render',\n                    'render_test': 'I have been rendered!',\n                    '_copy_without_render': [\n                        '*not-rendered',\n                        'rendered/not_rendered.yml',\n                        '*.txt',\n                        '{{cookiecutter.repo_name}}-rendered/README.md',\n                    ],\n                }\n            },\n            repo_dir='tests/test-generate-copy-without-render',\n        )\n\ntests/test_generate_copy_without_render.py:26: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-generate-copy-without-render'\ncontext = {'cookiecutter': {'_copy_without_render': ['*not-rendered', 'rendered/not_rendered.yml', '*.txt', '{{cookiecutter.repo_name}}-rendered/README.md'], 'render_test': 'I have been rendered!', 'repo_name': 'test_copy_without_render'}}\noutput_dir = '.', overwrite_if_exists = False, skip_if_file_exists = False\naccept_hooks = True, keep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_copy_without_render_overridepytest_generate_copy_without_render_extensions","title":"test_generate_copy_without_render_override.py::test_generate_copy_without_render_extensions","text":"<pre>test_generate_copy_without_render_override.py::test_generate_copy_without_render_extensions</pre><pre>\n@pytest.mark.usefixtures('clean_system', 'remove_test_dir')\n    def test_generate_copy_without_render_extensions():\n        \"\"\"Verify correct work of `_copy_without_render` context option.\n\n        Some files/directories should be rendered during invocation,\n        some just copied, without any modification.\n        \"\"\"\n        # first run\n&gt;       generate.generate_files(\n            context={\n                'cookiecutter': {\n                    'repo_name': 'test_copy_without_render',\n                    'render_test': 'I have been rendered!',\n                    '_copy_without_render': [\n                        '*not-rendered',\n                        'rendered/not_rendered.yml',\n                        '*.txt',\n                        '{{cookiecutter.repo_name}}-rendered/README.md',\n                    ],\n                }\n            },\n            repo_dir='tests/test-generate-copy-without-render-override',\n        )\n\ntests/test_generate_copy_without_render_override.py:27: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-generate-copy-without-render-override'\ncontext = {'cookiecutter': {'_copy_without_render': ['*not-rendered', 'rendered/not_rendered.yml', '*.txt', '{{cookiecutter.repo_name}}-rendered/README.md'], 'render_test': 'I have been rendered!', 'repo_name': 'test_copy_without_render'}}\noutput_dir = '.', overwrite_if_exists = False, skip_if_file_exists = False\naccept_hooks = True, keep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filepytest_generate_file_with_false_condition","title":"test_generate_file.py::test_generate_file_with_false_condition","text":"<pre>test_generate_file.py::test_generate_file_with_false_condition</pre><pre>\nenv = \n\n    def test_generate_file_with_false_condition(env):\n        \"\"\"Verify correct work of boolean condition in file name on file generation.\n\n        This test has negative answer, so file should not be rendered.\n        \"\"\"\n        infile = (\n            'tests/files/{% if cookiecutter.generate_file == \\'y\\' %}cheese.txt{% endif %}'\n        )\n&gt;       generate.generate_file(\n            project_dir=\".\",\n            infile=infile,\n            context={'cookiecutter': {'generate_file': 'n'}},\n            env=env,\n        )\n\ntests/test_generate_file.py:110: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nproject_dir = '.'\ninfile = \"tests/files/{% if cookiecutter.generate_file == 'y' %}cheese.txt{% endif %}\"\ncontext = {'cookiecutter': {'generate_file': 'n'}}\nenv = \nskip_if_file_exists = False\n\n    def generate_file(project_dir, infile, context, env, skip_if_file_exists=False\n        ):\n        \"\"\"Render filename of infile as name of outfile, handle infile correctly.\n\n        Dealing with infile appropriately:\n\n            a. If infile is a binary file, copy it over without rendering.\n            b. If infile is a text file, render its contents and write the\n               rendered infile to outfile.\n\n        Precondition:\n\n            When calling `generate_file()`, the root template dir must be the\n            current working directory. Using `utils.work_in()` is the recommended\n            way to perform this directory change.\n\n        :param project_dir: Absolute path to the resulting generated project.\n        :param infile: Input file to generate the file from. Relative to the root\n            template dir.\n        :param context: Dict for populating the cookiecutter's variables.\n        :param env: Jinja2 template execution environment.\n        \"\"\"\n        logger.debug('Generating file %s', infile)\n\n        # Render the path to the output file\n        outfile_tmpl = env.from_string(infile)\n        outfile = os.path.join(project_dir, outfile_tmpl.render(**context))\n\n        # Ensure output directory exists\n        dirname = os.path.dirname(outfile)\n        make_sure_path_exists(dirname)\n\n        # Skip if file exists and skip_if_file_exists is True\n        if skip_if_file_exists and os.path.exists(outfile):\n            logger.debug('File %s already exists, skipping', outfile)\n            return False\n\n        # Check if infile is binary\n        if is_binary(infile):\n            logger.debug(\"Copying binary %s to %s without rendering\", infile, outfile)\n            shutil.copyfile(infile, outfile)\n        else:\n            # Render the file\n            try:\n                with open(infile, 'r') as in_file:\n                    tmpl = env.from_string(in_file.read())\n                rendered_file = tmpl.render(**context)\n&gt;               with open(outfile, 'w') as out_file:\nE               IsADirectoryError: [Errno 21] Is a directory: './tests/files/'\n\ncookiecutter/generate.py:133: IsADirectoryError"},{"location":"analysis_baseline_cookiecutter/#test_generate_filepytest_generate_file_verbose_template_syntax_error","title":"test_generate_file.py::test_generate_file_verbose_template_syntax_error","text":"<pre>test_generate_file.py::test_generate_file_verbose_template_syntax_error</pre><pre>\nenv = \nexpected_msg_regex = re.compile('Missing end of comment tag\\n {2}File \"(.[/\\\\\\\\])*tests[/\\\\\\\\]files[/\\\\\\\\]syntax_error.txt\", line 1\\n {4}I eat {{ syntax_error }} {# this comment is not closed}')\n\n    def test_generate_file_verbose_template_syntax_error(env, expected_msg_regex):\n        \"\"\"Verify correct exception raised on syntax error in file before generation.\"\"\"\n        with pytest.raises(TemplateSyntaxError) as exception:\n            generate.generate_file(\n                project_dir=\".\",\n                infile='tests/files/syntax_error.txt',\n                context={'syntax_error': 'syntax_error'},\n                env=env,\n            )\n&gt;       assert expected_msg_regex.match(str(exception.value))\nE       assert None\nE        +  where None = ('Missing end of comment tag')\nE        +    where  = re.compile('Missing end of comment tag\\n {2}File \"(.[/\\\\\\\\])*tests[/\\\\\\\\]files[/\\\\\\\\]syntax_error.txt\", line 1\\n {4}I eat {{ syntax_error }} {# this comment is not closed}').match\nE        +    and   'Missing end of comment tag' = str(TemplateSyntaxError('Missing end of comment tag'))\nE        +      where TemplateSyntaxError('Missing end of comment tag') = .value\n\ntests/test_generate_file.py:138: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_generate_filepytest_generate_file_does_not_translate_crlf_newlines_to_lf","title":"test_generate_file.py::test_generate_file_does_not_translate_crlf_newlines_to_lf","text":"<pre>test_generate_file.py::test_generate_file_does_not_translate_crlf_newlines_to_lf</pre><pre>\nenv = \n\n    def test_generate_file_does_not_translate_crlf_newlines_to_lf(env):\n        \"\"\"Verify that file generation use same line ending, as in source file.\"\"\"\n        infile = 'tests/files/{{cookiecutter.generate_file}}_crlf_newlines.txt'\n        generate.generate_file(\n            project_dir=\".\",\n            infile=infile,\n            context={'cookiecutter': {'generate_file': 'cheese'}},\n            env=env,\n        )\n\n        # this generated file should have a CRLF line ending\n        gf = 'tests/files/cheese_crlf_newlines.txt'\n        with Path(gf).open(encoding='utf-8', newline='') as f:\n            simple_text = f.readline()\n&gt;       assert simple_text == 'newline is CRLF\\r\\n'\nE       AssertionError: assert 'newline is CRLF\\n' == 'newline is CRLF\\r\\n'\nE         \nE         - newline is CRLF\nE         ?                -\nE         + newline is CRLF\n\ntests/test_generate_file.py:173: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_generate_files_nontemplated_exception","title":"test_generate_files.py::test_generate_files_nontemplated_exception","text":"<pre>test_generate_files.py::test_generate_files_nontemplated_exception</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_nontemplat0')\n\n    def test_generate_files_nontemplated_exception(tmp_path):\n        \"\"\"\n        Verify `generate_files` raises when no directories to render exist.\n\n        Note: Check `tests/test-generate-files-nontemplated` location to understand.\n        \"\"\"\n        with pytest.raises(exceptions.NonTemplatedInputDirException):\n&gt;           generate.generate_files(\n                context={'cookiecutter': {'food': 'pizza'}},\n                repo_dir='tests/test-generate-files-nontemplated',\n                output_dir=tmp_path,\n            )\n\ntests/test_generate_files.py:22: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-generate-files-nontemplated'\ncontext = {'cookiecutter': {'food': 'pizza'}}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_nontemplat0')\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_generate_files","title":"test_generate_files.py::test_generate_files","text":"<pre>test_generate_files.py::test_generate_files</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files0')\n\n    def test_generate_files(tmp_path):\n        \"\"\"Verify directory name correctly rendered with unicode containing context.\"\"\"\n&gt;       generate.generate_files(\n            context={'cookiecutter': {'food': 'pizz\u00e4'}},\n            repo_dir='tests/test-generate-files',\n            output_dir=tmp_path,\n        )\n\ntests/test_generate_files.py:31: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-generate-files'\ncontext = {'cookiecutter': {'food': 'pizz\u00e4'}}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files0')\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_generate_files_with_linux_newline","title":"test_generate_files.py::test_generate_files_with_linux_newline","text":"<pre>test_generate_files.py::test_generate_files_with_linux_newline</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_with_linux0')\n\n    def test_generate_files_with_linux_newline(tmp_path):\n        \"\"\"Verify new line not removed by templating engine after folder generation.\"\"\"\n&gt;       generate.generate_files(\n            context={'cookiecutter': {'food': 'pizz\u00e4'}},\n            repo_dir='tests/test-generate-files',\n            output_dir=tmp_path,\n        )\n\ntests/test_generate_files.py:47: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-generate-files'\ncontext = {'cookiecutter': {'food': 'pizz\u00e4'}}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_with_linux0')\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_generate_files_with_jinja2_environment","title":"test_generate_files.py::test_generate_files_with_jinja2_environment","text":"<pre>test_generate_files.py::test_generate_files_with_jinja2_environment</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_with_jinja0')\n\n    def test_generate_files_with_jinja2_environment(tmp_path):\n        \"\"\"Extend StrictEnvironment with _jinja2_env_vars cookiecutter template option.\"\"\"\n&gt;       generate.generate_files(\n            context={\n                'cookiecutter': {\n                    'food': 'pizz\u00e4',\n                    '_jinja2_env_vars': {'lstrip_blocks': True, 'trim_blocks': True},\n                }\n            },\n            repo_dir='tests/test-generate-files',\n            output_dir=tmp_path,\n        )\n\ntests/test_generate_files.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-generate-files'\ncontext = {'cookiecutter': {'_jinja2_env_vars': {'lstrip_blocks': True, 'trim_blocks': True}, 'food': 'pizz\u00e4'}}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_with_jinja0')\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_generate_files_with_trailing_newline_forced_to_linux_by_context","title":"test_generate_files.py::test_generate_files_with_trailing_newline_forced_to_linux_by_context","text":"<pre>test_generate_files.py::test_generate_files_with_trailing_newline_forced_to_linux_by_context</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_with_trail0')\n\n    def test_generate_files_with_trailing_newline_forced_to_linux_by_context(tmp_path):\n        \"\"\"Verify new line not removed by templating engine after folder generation.\"\"\"\n&gt;       generate.generate_files(\n            context={'cookiecutter': {'food': 'pizz\u00e4', '_new_lines': '\\r\\n'}},\n            repo_dir='tests/test-generate-files',\n            output_dir=tmp_path,\n        )\n\ntests/test_generate_files.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-generate-files'\ncontext = {'cookiecutter': {'_new_lines': '\\r\\n', 'food': 'pizz\u00e4'}}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_with_trail0')\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_generate_files_with_windows_newline","title":"test_generate_files.py::test_generate_files_with_windows_newline","text":"<pre>test_generate_files.py::test_generate_files_with_windows_newline</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_with_windo0')\n\n    def test_generate_files_with_windows_newline(tmp_path):\n        \"\"\"Verify windows source line end not changed during files generation.\"\"\"\n&gt;       generate.generate_files(\n            context={'cookiecutter': {'food': 'pizz\u00e4'}},\n            repo_dir='tests/test-generate-files',\n            output_dir=tmp_path,\n        )\n\ntests/test_generate_files.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-generate-files'\ncontext = {'cookiecutter': {'food': 'pizz\u00e4'}}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_with_windo0')\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_generate_files_with_windows_newline_forced_to_linux_by_context","title":"test_generate_files.py::test_generate_files_with_windows_newline_forced_to_linux_by_context","text":"<pre>test_generate_files.py::test_generate_files_with_windows_newline_forced_to_linux_by_context</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_with_windo1')\n\n    def test_generate_files_with_windows_newline_forced_to_linux_by_context(tmp_path):\n        \"\"\"Verify windows line end changed to linux during files generation.\"\"\"\n&gt;       generate.generate_files(\n            context={'cookiecutter': {'food': 'pizz\u00e4', '_new_lines': '\\n'}},\n            repo_dir='tests/test-generate-files',\n            output_dir=tmp_path,\n        )\n\ntests/test_generate_files.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-generate-files'\ncontext = {'cookiecutter': {'_new_lines': '\\n', 'food': 'pizz\u00e4'}}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_with_windo1')\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_generate_files_binaries","title":"test_generate_files.py::test_generate_files_binaries","text":"<pre>test_generate_files.py::test_generate_files_binaries</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_binaries0')\n\n    def test_generate_files_binaries(tmp_path):\n        \"\"\"Verify binary files created during directory generation.\"\"\"\n&gt;       generate.generate_files(\n            context={'cookiecutter': {'binary_test': 'binary_files'}},\n            repo_dir='tests/test-generate-binaries',\n            output_dir=tmp_path,\n        )\n\ntests/test_generate_files.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-generate-binaries'\ncontext = {'cookiecutter': {'binary_test': 'binary_files'}}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_binaries0')\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_generate_files_absolute_path","title":"test_generate_files.py::test_generate_files_absolute_path","text":"<pre>test_generate_files.py::test_generate_files_absolute_path</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_absolute_p0')\n\n    def test_generate_files_absolute_path(tmp_path):\n        \"\"\"Verify usage of absolute path does not change files generation behaviour.\"\"\"\n&gt;       generate.generate_files(\n            context={'cookiecutter': {'food': 'pizz\u00e4'}},\n            repo_dir=Path('tests/test-generate-files').absolute(),\n            output_dir=tmp_path,\n        )\n\ntests/test_generate_files.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = PosixPath('/testbed/tests/test-generate-files')\ncontext = {'cookiecutter': {'food': 'pizz\u00e4'}}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_absolute_p0')\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_generate_files_output_dir","title":"test_generate_files.py::test_generate_files_output_dir","text":"<pre>test_generate_files.py::test_generate_files_output_dir</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_output_dir0')\n\n    def test_generate_files_output_dir(tmp_path):\n        \"\"\"Verify `output_dir` option for `generate_files` changing location correctly.\"\"\"\n        output_dir = Path(tmp_path, 'custom_output_dir')\n        output_dir.mkdir()\n\n&gt;       project_dir = generate.generate_files(\n            context={'cookiecutter': {'food': 'pizz\u00e4'}},\n            repo_dir=Path('tests/test-generate-files').absolute(),\n            output_dir=output_dir,\n        )\n\ntests/test_generate_files.py:176: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = PosixPath('/testbed/tests/test-generate-files')\ncontext = {'cookiecutter': {'food': 'pizz\u00e4'}}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_output_dir0/custom_output_dir')\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_generate_files_permissions","title":"test_generate_files.py::test_generate_files_permissions","text":"<pre>test_generate_files.py::test_generate_files_permissions</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_permission0')\n\n    def test_generate_files_permissions(tmp_path):\n        \"\"\"Verify generates files respect source files permissions.\n\n        simple.txt and script.sh should retain their respective 0o644 and 0o755\n        permissions.\n        \"\"\"\n&gt;       generate.generate_files(\n            context={'cookiecutter': {'permissions': 'permissions'}},\n            repo_dir='tests/test-generate-files-permissions',\n            output_dir=tmp_path,\n        )\n\ntests/test_generate_files.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-generate-files-permissions'\ncontext = {'cookiecutter': {'permissions': 'permissions'}}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_permission0')\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_generate_files_with_overwrite_if_exists_with_skip_if_file_exists","title":"test_generate_files.py::test_generate_files_with_overwrite_if_exists_with_skip_if_file_exists","text":"<pre>test_generate_files.py::test_generate_files_with_overwrite_if_exists_with_skip_if_file_exists</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_with_overw0')\n\n    def test_generate_files_with_overwrite_if_exists_with_skip_if_file_exists(tmp_path):\n        \"\"\"Verify `skip_if_file_exist` has priority over `overwrite_if_exists`.\"\"\"\n        simple_file = Path(tmp_path, 'inputpizz\u00e4/simple.txt')\n        simple_with_new_line_file = Path(tmp_path, 'inputpizz\u00e4/simple-with-newline.txt')\n\n        Path(tmp_path, 'inputpizz\u00e4').mkdir(parents=True)\n        with Path(simple_file).open('w') as f:\n            f.write('temp')\n\n&gt;       generate.generate_files(\n            context={'cookiecutter': {'food': 'pizz\u00e4'}},\n            repo_dir='tests/test-generate-files',\n            overwrite_if_exists=True,\n            skip_if_file_exists=True,\n            output_dir=tmp_path,\n        )\n\ntests/test_generate_files.py:240: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-generate-files'\ncontext = {'cookiecutter': {'food': 'pizz\u00e4'}}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_with_overw0')\noverwrite_if_exists = True, skip_if_file_exists = True, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_generate_files_with_skip_if_file_exists","title":"test_generate_files.py::test_generate_files_with_skip_if_file_exists","text":"<pre>test_generate_files.py::test_generate_files_with_skip_if_file_exists</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_with_skip_0')\n\n    def test_generate_files_with_skip_if_file_exists(tmp_path):\n        \"\"\"Verify existed files not removed if error raised with `skip_if_file_exists`.\"\"\"\n        simple_file = Path(tmp_path, 'inputpizz\u00e4/simple.txt')\n        simple_with_new_line_file = Path(tmp_path, 'inputpizz\u00e4/simple-with-newline.txt')\n\n        Path(tmp_path, 'inputpizz\u00e4').mkdir(parents=True)\n        Path(simple_file).write_text('temp')\n\n        with pytest.raises(exceptions.OutputDirExistsException):\n&gt;           generate.generate_files(\n                context={'cookiecutter': {'food': 'pizz\u00e4'}},\n                repo_dir='tests/test-generate-files',\n                skip_if_file_exists=True,\n                output_dir=tmp_path,\n            )\n\ntests/test_generate_files.py:266: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-generate-files'\ncontext = {'cookiecutter': {'food': 'pizz\u00e4'}}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_with_skip_0')\noverwrite_if_exists = False, skip_if_file_exists = True, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_generate_files_with_overwrite_if_exists","title":"test_generate_files.py::test_generate_files_with_overwrite_if_exists","text":"<pre>test_generate_files.py::test_generate_files_with_overwrite_if_exists</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_with_overw1')\n\n    def test_generate_files_with_overwrite_if_exists(tmp_path):\n        \"\"\"Verify overwrite_if_exists overwrites old files.\"\"\"\n        simple_file = Path(tmp_path, 'inputpizz\u00e4/simple.txt')\n        simple_with_new_line_file = Path(tmp_path, 'inputpizz\u00e4/simple-with-newline.txt')\n\n        Path(tmp_path, 'inputpizz\u00e4').mkdir(parents=True)\n        Path(simple_file).write_text('temp')\n\n&gt;       generate.generate_files(\n            context={'cookiecutter': {'food': 'pizz\u00e4'}},\n            repo_dir='tests/test-generate-files',\n            overwrite_if_exists=True,\n            output_dir=tmp_path,\n        )\n\ntests/test_generate_files.py:289: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-generate-files'\ncontext = {'cookiecutter': {'food': 'pizz\u00e4'}}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_generate_files_with_overw1')\noverwrite_if_exists = True, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_raise_undefined_variable_file_name","title":"test_generate_files.py::test_raise_undefined_variable_file_name","text":"<pre>test_generate_files.py::test_raise_undefined_variable_file_name</pre><pre>\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_raise_undefined_variable_0/output'\nundefined_context = {'cookiecutter': {'github_username': 'hackebrot', 'project_slug': 'testproject'}}\n\n    def test_raise_undefined_variable_file_name(output_dir, undefined_context):\n        \"\"\"Verify correct error raised when file name cannot be rendered.\"\"\"\n        with pytest.raises(exceptions.UndefinedVariableInTemplate) as err:\n&gt;           generate.generate_files(\n                repo_dir='tests/undefined-variable/file-name/',\n                output_dir=output_dir,\n                context=undefined_context,\n            )\n\ntests/test_generate_files.py:316: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/undefined-variable/file-name/'\ncontext = {'cookiecutter': {'github_username': 'hackebrot', 'project_slug': 'testproject'}}\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_raise_undefined_variable_0/output'\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_raise_undefined_variable_file_name_existing_project","title":"test_generate_files.py::test_raise_undefined_variable_file_name_existing_project","text":"<pre>test_generate_files.py::test_raise_undefined_variable_file_name_existing_project</pre><pre>\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_raise_undefined_variable_1/output'\nundefined_context = {'cookiecutter': {'github_username': 'hackebrot', 'project_slug': 'testproject'}}\n\n    def test_raise_undefined_variable_file_name_existing_project(\n        output_dir, undefined_context\n    ):\n        \"\"\"Verify correct error raised when file name cannot be rendered.\"\"\"\n        testproj_path = Path(output_dir, 'testproject')\n        testproj_path.mkdir()\n\n        with pytest.raises(exceptions.UndefinedVariableInTemplate) as err:\n&gt;           generate.generate_files(\n                repo_dir='tests/undefined-variable/file-name/',\n                output_dir=output_dir,\n                context=undefined_context,\n                overwrite_if_exists=True,\n            )\n\ntests/test_generate_files.py:336: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/undefined-variable/file-name/'\ncontext = {'cookiecutter': {'github_username': 'hackebrot', 'project_slug': 'testproject'}}\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_raise_undefined_variable_1/output'\noverwrite_if_exists = True, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_raise_undefined_variable_file_content","title":"test_generate_files.py::test_raise_undefined_variable_file_content","text":"<pre>test_generate_files.py::test_raise_undefined_variable_file_content</pre><pre>\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_raise_undefined_variable_2/output'\nundefined_context = {'cookiecutter': {'github_username': 'hackebrot', 'project_slug': 'testproject'}}\n\n    def test_raise_undefined_variable_file_content(output_dir, undefined_context):\n        \"\"\"Verify correct error raised when file content cannot be rendered.\"\"\"\n        with pytest.raises(exceptions.UndefinedVariableInTemplate) as err:\n&gt;           generate.generate_files(\n                repo_dir='tests/undefined-variable/file-content/',\n                output_dir=output_dir,\n                context=undefined_context,\n            )\n\ntests/test_generate_files.py:352: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/undefined-variable/file-content/'\ncontext = {'cookiecutter': {'github_username': 'hackebrot', 'project_slug': 'testproject'}}\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_raise_undefined_variable_2/output'\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_raise_undefined_variable_dir_name","title":"test_generate_files.py::test_raise_undefined_variable_dir_name","text":"<pre>test_generate_files.py::test_raise_undefined_variable_dir_name</pre><pre>\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_raise_undefined_variable_3/output'\nundefined_context = {'cookiecutter': {'github_username': 'hackebrot', 'project_slug': 'testproject'}}\n\n    def test_raise_undefined_variable_dir_name(output_dir, undefined_context):\n        \"\"\"Verify correct error raised when directory name cannot be rendered.\"\"\"\n        with pytest.raises(exceptions.UndefinedVariableInTemplate) as err:\n&gt;           generate.generate_files(\n                repo_dir='tests/undefined-variable/dir-name/',\n                output_dir=output_dir,\n                context=undefined_context,\n            )\n\ntests/test_generate_files.py:367: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/undefined-variable/dir-name/'\ncontext = {'cookiecutter': {'github_username': 'hackebrot', 'project_slug': 'testproject'}}\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_raise_undefined_variable_3/output'\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_keep_project_dir_on_failure","title":"test_generate_files.py::test_keep_project_dir_on_failure","text":"<pre>test_generate_files.py::test_keep_project_dir_on_failure</pre><pre>\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_keep_project_dir_on_failu0/output'\nundefined_context = {'cookiecutter': {'github_username': 'hackebrot', 'project_slug': 'testproject'}}\n\n    def test_keep_project_dir_on_failure(output_dir, undefined_context):\n        \"\"\"Verify correct error raised when directory name cannot be rendered.\"\"\"\n        with pytest.raises(exceptions.UndefinedVariableInTemplate):\n&gt;           generate.generate_files(\n                repo_dir='tests/undefined-variable/dir-name/',\n                output_dir=output_dir,\n                context=undefined_context,\n                keep_project_on_failure=True,\n            )\n\ntests/test_generate_files.py:386: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/undefined-variable/dir-name/'\ncontext = {'cookiecutter': {'github_username': 'hackebrot', 'project_slug': 'testproject'}}\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_keep_project_dir_on_failu0/output'\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = True\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_raise_undefined_variable_dir_name_existing_project","title":"test_generate_files.py::test_raise_undefined_variable_dir_name_existing_project","text":"<pre>test_generate_files.py::test_raise_undefined_variable_dir_name_existing_project</pre><pre>\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_raise_undefined_variable_4/output'\nundefined_context = {'cookiecutter': {'github_username': 'hackebrot', 'project_slug': 'testproject'}}\n\n    def test_raise_undefined_variable_dir_name_existing_project(\n        output_dir, undefined_context\n    ):\n        \"\"\"Verify correct error raised when directory name cannot be rendered.\"\"\"\n        testproj_path = Path(output_dir, 'testproject')\n        testproj_path.mkdir()\n\n        with pytest.raises(exceptions.UndefinedVariableInTemplate) as err:\n&gt;           generate.generate_files(\n                repo_dir='tests/undefined-variable/dir-name/',\n                output_dir=output_dir,\n                context=undefined_context,\n                overwrite_if_exists=True,\n            )\n\ntests/test_generate_files.py:403: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/undefined-variable/dir-name/'\ncontext = {'cookiecutter': {'github_username': 'hackebrot', 'project_slug': 'testproject'}}\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_raise_undefined_variable_4/output'\noverwrite_if_exists = True, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_filespytest_raise_undefined_variable_project_dir","title":"test_generate_files.py::test_raise_undefined_variable_project_dir","text":"<pre>test_generate_files.py::test_raise_undefined_variable_project_dir</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_raise_undefined_variable_5')\n\n    def test_raise_undefined_variable_project_dir(tmp_path):\n        \"\"\"Verify correct error raised when directory name cannot be rendered.\"\"\"\n        with pytest.raises(exceptions.UndefinedVariableInTemplate) as err:\n&gt;           generate.generate_files(\n                repo_dir='tests/undefined-variable/dir-name/',\n                output_dir=tmp_path,\n                context={},\n            )\n\ntests/test_generate_files.py:423: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/undefined-variable/dir-name/', context = {}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_raise_undefined_variable_5')\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_hookspytest_ignore_hooks_dirs","title":"test_generate_hooks.py::test_ignore_hooks_dirs","text":"<pre>test_generate_hooks.py::test_ignore_hooks_dirs</pre><pre>\n@pytest.mark.usefixtures('clean_system', 'remove_additional_folders')\n    def test_ignore_hooks_dirs():\n        \"\"\"Verify hooks directory not created in target location on files generation.\"\"\"\n&gt;       generate.generate_files(\n            context={'cookiecutter': {'pyhooks': 'pyhooks'}},\n            repo_dir='tests/test-pyhooks/',\n            output_dir='tests/test-pyhooks/',\n        )\n\ntests/test_generate_hooks.py:35: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-pyhooks/'\ncontext = {'cookiecutter': {'pyhooks': 'pyhooks'}}\noutput_dir = 'tests/test-pyhooks/', overwrite_if_exists = False\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_hookspytest_run_python_hooks","title":"test_generate_hooks.py::test_run_python_hooks","text":"<pre>test_generate_hooks.py::test_run_python_hooks</pre><pre>\n@pytest.mark.usefixtures('clean_system', 'remove_additional_folders')\n    def test_run_python_hooks():\n        \"\"\"Verify pre and post generation python hooks executed and result in output_dir.\n\n        Each hook should create in target directory. Test verifies that these files\n        created.\n        \"\"\"\n&gt;       generate.generate_files(\n            context={'cookiecutter': {'pyhooks': 'pyhooks'}},\n            repo_dir='tests/test-pyhooks/',\n            output_dir='tests/test-pyhooks/',\n        )\n\ntests/test_generate_hooks.py:50: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-pyhooks/'\ncontext = {'cookiecutter': {'pyhooks': 'pyhooks'}}\noutput_dir = 'tests/test-pyhooks/', overwrite_if_exists = False\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_hookspytest_run_python_hooks_cwd","title":"test_generate_hooks.py::test_run_python_hooks_cwd","text":"<pre>test_generate_hooks.py::test_run_python_hooks_cwd</pre><pre>\n@pytest.mark.usefixtures('clean_system', 'remove_additional_folders')\n    def test_run_python_hooks_cwd():\n        \"\"\"Verify pre and post generation python hooks executed and result in current dir.\n\n        Each hook should create in target directory. Test verifies that these files\n        created.\n        \"\"\"\n&gt;       generate.generate_files(\n            context={'cookiecutter': {'pyhooks': 'pyhooks'}}, repo_dir='tests/test-pyhooks/'\n        )\n\ntests/test_generate_hooks.py:66: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-pyhooks/'\ncontext = {'cookiecutter': {'pyhooks': 'pyhooks'}}, output_dir = '.'\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_hookspytest_empty_hooks","title":"test_generate_hooks.py::test_empty_hooks","text":"<pre>test_generate_hooks.py::test_empty_hooks</pre><pre>\n@pytest.mark.skipif(WINDOWS, reason='OSError.errno=8 is not thrown on Windows')\n    @pytest.mark.usefixtures('clean_system', 'remove_additional_folders')\n    def test_empty_hooks():\n        \"\"\"Verify error is raised on empty hook script. Ignored on windows.\n\n        OSError.errno=8 is not thrown on Windows when the script is empty\n        because it always runs through shell instead of needing a shebang.\n        \"\"\"\n        with pytest.raises(FailedHookException) as excinfo:\n&gt;           generate.generate_files(\n                context={'cookiecutter': {'shellhooks': 'shellhooks'}},\n                repo_dir='tests/test-shellhooks-empty/',\n                overwrite_if_exists=True,\n            )\n\ntests/test_generate_hooks.py:82: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-shellhooks-empty/'\ncontext = {'cookiecutter': {'shellhooks': 'shellhooks'}}, output_dir = '.'\noverwrite_if_exists = True, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_hookspytest_oserror_hooks","title":"test_generate_hooks.py::test_oserror_hooks","text":"<pre>test_generate_hooks.py::test_oserror_hooks</pre><pre>\nmocker = \n\n    @pytest.mark.usefixtures('clean_system', 'remove_additional_folders')\n    def test_oserror_hooks(mocker):\n        \"\"\"Verify script error passed correctly to cookiecutter error.\n\n        Here subprocess.Popen function mocked, ie we do not call hook script,\n        just produce expected error.\n        \"\"\"\n        message = 'Out of memory'\n\n        err = OSError(message)\n        err.errno = errno.ENOMEM\n\n        prompt = mocker.patch('subprocess.Popen')\n        prompt.side_effect = err\n\n        with pytest.raises(FailedHookException) as excinfo:\n&gt;           generate.generate_files(\n                context={'cookiecutter': {'shellhooks': 'shellhooks'}},\n                repo_dir='tests/test-shellhooks-empty/',\n                overwrite_if_exists=True,\n            )\n\ntests/test_generate_hooks.py:106: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-shellhooks-empty/'\ncontext = {'cookiecutter': {'shellhooks': 'shellhooks'}}, output_dir = '.'\noverwrite_if_exists = True, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_generate_hookspytest_run_failing_hook_removes_output_directory","title":"test_generate_hooks.py::test_run_failing_hook_removes_output_directory","text":"<pre>test_generate_hooks.py::test_run_failing_hook_removes_output_directory</pre><pre>\n@pytest.mark.usefixtures('clean_system', 'remove_additional_folders')\n    def test_run_failing_hook_removes_output_directory():\n        \"\"\"Verify project directory not created or removed if hook failed.\"\"\"\n        repo_path = os.path.abspath('tests/test-hooks/')\n        hooks_path = os.path.abspath('tests/test-hooks/hooks')\n\n        hook_dir = os.path.join(repo_path, 'hooks')\n        template = os.path.join(repo_path, 'input{{cookiecutter.hooks}}')\n        os.mkdir(repo_path)\n        os.mkdir(hook_dir)\n        os.mkdir(template)\n\n        hook_path = os.path.join(hooks_path, 'pre_gen_project.py')\n\n        with Path(hook_path).open('w') as f:\n            f.write(\"#!/usr/bin/env python\\n\")\n            f.write(\"import sys; sys.exit(1)\\n\")\n\n        with pytest.raises(FailedHookException) as excinfo:\n&gt;           generate.generate_files(\n                context={'cookiecutter': {'hooks': 'hooks'}},\n                repo_dir='tests/test-hooks/',\n                overwrite_if_exists=True,\n            )\n\ntests/test_generate_hooks.py:133: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-hooks/', context = {'cookiecutter': {'hooks': 'hooks'}}\noutput_dir = '.', overwrite_if_exists = True, skip_if_file_exists = False\naccept_hooks = True, keep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_hookspytest_run_failing_hook_preserves_existing_output_directory","title":"test_generate_hooks.py::test_run_failing_hook_preserves_existing_output_directory","text":"<pre>test_generate_hooks.py::test_run_failing_hook_preserves_existing_output_directory</pre><pre>\n@pytest.mark.usefixtures('clean_system', 'remove_additional_folders')\n    def test_run_failing_hook_preserves_existing_output_directory():\n        \"\"\"Verify project directory not removed if exist before hook failed.\"\"\"\n        repo_path = os.path.abspath('tests/test-hooks/')\n        hooks_path = os.path.abspath('tests/test-hooks/hooks')\n\n        hook_dir = os.path.join(repo_path, 'hooks')\n        template = os.path.join(repo_path, 'input{{cookiecutter.hooks}}')\n        os.mkdir(repo_path)\n        os.mkdir(hook_dir)\n        os.mkdir(template)\n\n        hook_path = os.path.join(hooks_path, 'pre_gen_project.py')\n\n        with Path(hook_path).open('w') as f:\n            f.write(\"#!/usr/bin/env python\\n\")\n            f.write(\"import sys; sys.exit(1)\\n\")\n\n        os.mkdir('inputhooks')\n        with pytest.raises(FailedHookException) as excinfo:\n&gt;           generate.generate_files(\n                context={'cookiecutter': {'hooks': 'hooks'}},\n                repo_dir='tests/test-hooks/',\n                overwrite_if_exists=True,\n            )\n\ntests/test_generate_hooks.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-hooks/', context = {'cookiecutter': {'hooks': 'hooks'}}\noutput_dir = '.', overwrite_if_exists = True, skip_if_file_exists = False\naccept_hooks = True, keep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_hookspytest_run_shell_hooks","title":"test_generate_hooks.py::test_run_shell_hooks","text":"<pre>test_generate_hooks.py::test_run_shell_hooks</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_run_shell_hooks0')\n\n    @pytest.mark.skipif(sys.platform.startswith('win'), reason=\"Linux only test\")\n    @pytest.mark.usefixtures('clean_system', 'remove_additional_folders')\n    def test_run_shell_hooks(tmp_path):\n        \"\"\"Verify pre and post generate project shell hooks executed.\n\n        This test for .sh files.\n        \"\"\"\n&gt;       generate.generate_files(\n            context={'cookiecutter': {'shellhooks': 'shellhooks'}},\n            repo_dir='tests/test-shellhooks/',\n            output_dir=tmp_path.joinpath('test-shellhooks'),\n        )\n\ntests/test_generate_hooks.py:180: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-shellhooks/'\ncontext = {'cookiecutter': {'shellhooks': 'shellhooks'}}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_run_shell_hooks0/test-shellhooks')\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_hookspytest_run_shell_hooks_win","title":"test_generate_hooks.py::test_run_shell_hooks_win","text":"<pre>test_generate_hooks.py::test_run_shell_hooks_win</pre><pre>\n('/testbed/tests/test_generate_hooks.py', 195, 'Skipped: Win only test')\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_hookspytest_ignore_shell_hooks","title":"test_generate_hooks.py::test_ignore_shell_hooks","text":"<pre>test_generate_hooks.py::test_ignore_shell_hooks</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_ignore_shell_hooks0')\n\n    @pytest.mark.usefixtures(\"clean_system\", \"remove_additional_folders\")\n    def test_ignore_shell_hooks(tmp_path):\n        \"\"\"Verify *.txt files not created, when accept_hooks=False.\"\"\"\n&gt;       generate.generate_files(\n            context={\"cookiecutter\": {\"shellhooks\": \"shellhooks\"}},\n            repo_dir=\"tests/test-shellhooks/\",\n            output_dir=tmp_path.joinpath('test-shellhooks'),\n            accept_hooks=False,\n        )\n\ntests/test_generate_hooks.py:220: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-shellhooks/'\ncontext = {'cookiecutter': {'shellhooks': 'shellhooks'}}\noutput_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_ignore_shell_hooks0/test-shellhooks')\noverwrite_if_exists = False, skip_if_file_exists = False, accept_hooks = False\nkeep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_generate_hookspytest_deprecate_run_hook_from_repo_dir","title":"test_generate_hooks.py::test_deprecate_run_hook_from_repo_dir","text":"<pre>test_generate_hooks.py::test_deprecate_run_hook_from_repo_dir</pre><pre>\nrepo_dir = 'tests/test-shellhooks/', hook_name = 'pre_gen_project'\nproject_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_deprecate_run_hook_from_r0/test-shellhooks')\ncontext = {}, delete_project_on_failure = False\n\n    def _run_hook_from_repo_dir(repo_dir, hook_name, project_dir, context,\n        delete_project_on_failure):\n        \"\"\"Run hook from repo directory, clean project directory if hook fails.\n\n        :param repo_dir: Project template input directory.\n        :param hook_name: The hook to execute.\n        :param project_dir: The directory to execute the script from.\n        :param context: Cookiecutter project context.\n        :param delete_project_on_failure: Delete the project directory on hook\n            failure?\n        \"\"\"\n        with work_in(repo_dir):\n            try:\n&gt;               run_hook_from_repo_dir(\n                    repo_dir=repo_dir,\n                    hook_name=hook_name,\n                    project_dir=project_dir,\n                    context=context\n                )\nE               TypeError: run_hook_from_repo_dir() missing 1 required positional argument: 'delete_project_on_failure'\n\ncookiecutter/generate.py:182: TypeError\n\nDuring handling of the above exception, another exception occurred:\n\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_deprecate_run_hook_from_r0')\n\n    @pytest.mark.usefixtures(\"clean_system\", \"remove_additional_folders\")\n    def test_deprecate_run_hook_from_repo_dir(tmp_path):\n        \"\"\"Test deprecation warning in generate._run_hook_from_repo_dir.\"\"\"\n        repo_dir = \"tests/test-shellhooks/\"\n        project_dir = Path(tmp_path.joinpath('test-shellhooks'))\n        project_dir.mkdir()\n        with pytest.deprecated_call():\n&gt;           generate._run_hook_from_repo_dir(\n                repo_dir=repo_dir,\n                hook_name=\"pre_gen_project\",\n                project_dir=project_dir,\n                context={},\n                delete_project_on_failure=False,\n            )\n\ntests/test_generate_hooks.py:241: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-shellhooks/', hook_name = 'pre_gen_project'\nproject_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_deprecate_run_hook_from_r0/test-shellhooks')\ncontext = {}, delete_project_on_failure = False\n\n    def _run_hook_from_repo_dir(repo_dir, hook_name, project_dir, context,\n        delete_project_on_failure):\n        \"\"\"Run hook from repo directory, clean project directory if hook fails.\n\n        :param repo_dir: Project template input directory.\n        :param hook_name: The hook to execute.\n        :param project_dir: The directory to execute the script from.\n        :param context: Cookiecutter project context.\n        :param delete_project_on_failure: Delete the project directory on hook\n            failure?\n        \"\"\"\n        with work_in(repo_dir):\n            try:\n                run_hook_from_repo_dir(\n                    repo_dir=repo_dir,\n                    hook_name=hook_name,\n                    project_dir=project_dir,\n                    context=context\n                )\n&gt;           except FailedHookException:\nE           NameError: name 'FailedHookException' is not defined\n\ncookiecutter/generate.py:188: NameError\n\nDuring handling of the above exception, another exception occurred:\n\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_deprecate_run_hook_from_r0')\n\n    @pytest.mark.usefixtures(\"clean_system\", \"remove_additional_folders\")\n    def test_deprecate_run_hook_from_repo_dir(tmp_path):\n        \"\"\"Test deprecation warning in generate._run_hook_from_repo_dir.\"\"\"\n        repo_dir = \"tests/test-shellhooks/\"\n        project_dir = Path(tmp_path.joinpath('test-shellhooks'))\n        project_dir.mkdir()\n&gt;       with pytest.deprecated_call():\nE       Failed: DID NOT WARN. No warnings of type (, , ) were emitted.\nE        Emitted warnings: [].\n\ntests/test_generate_hooks.py:240: Failed"},{"location":"analysis_baseline_cookiecutter/#test_get_configpytest_get_config","title":"test_get_config.py::test_get_config","text":"<pre>test_get_config.py::test_get_config</pre><pre>\ndef test_get_config():\n        \"\"\"Verify valid config opened and rendered correctly.\"\"\"\n        conf = config.get_config('tests/test-config/valid-config.yaml')\n        expected_conf = {\n            'cookiecutters_dir': '/home/example/some-path-to-templates',\n            'replay_dir': '/home/example/some-path-to-replay-files',\n            'default_context': {\n                'full_name': 'Firstname Lastname',\n                'email': 'firstname.lastname@gmail.com',\n                'github_username': 'example',\n                'project': {\n                    'description': 'description',\n                    'tags': [\n                        'first',\n                        'second',\n                        'third',\n                    ],\n                },\n            },\n            'abbreviations': {\n                'gh': 'https://github.com/{0}.git',\n                'gl': 'https://gitlab.com/{0}.git',\n                'bb': 'https://bitbucket.org/{0}',\n                'helloworld': 'https://github.com/hackebrot/helloworld',\n            },\n        }\n&gt;       assert conf == expected_conf\nE       AssertionError: assert {'default_context': {'full_name': 'Firstname Lastname', 'email': 'firstname.lastname@gmail.com', 'github_username': 'example', 'project': {'description': 'description', 'tags': ['first', 'second', 'third']}}, 'cookiecutters_dir': '/home/example/some-path-to-templates', 'replay_dir': '/home/example/some-path-to-replay-files', 'abbreviations': {'helloworld': 'https://github.com/hackebrot/helloworld'}} == {'cookiecutters_dir': '/home/example/some-path-to-templates', 'replay_dir': '/home/example/some-path-to-replay-files', 'default_context': {'full_name': 'Firstname Lastname', 'email': 'firstname.lastname@gmail.com', 'github_username': 'example', 'project': {'description': 'description', 'tags': ['first', 'second', 'third']}}, 'abbreviations': {'gh': 'https://github.com/{0}.git', 'gl': 'https://gitlab.com/{0}.git', 'bb': 'https://bitbucket.org/{0}', 'helloworld': 'https://github.com/hackebrot/helloworld'}}\nE         \nE         Common items:\nE         {'cookiecutters_dir': '/home/example/some-path-to-templates',\nE          'default_context': {'email': 'firstname.lastname@gmail.com',\nE                              'full_name': 'Firstname Lastname',\nE                              'github_username': 'example',\nE                              'project': {'description': 'description',\nE                                          'tags': ['first', 'second', 'third']}},\nE          'replay_dir': '/home/example/some-path-to-replay-files'}\nE         Differing items:\nE         {'abbreviations': {'helloworld': 'https://github.com/hackebrot/helloworld'}} != {'abbreviations': {'bb': 'https://bitbucket.org/{0}', 'gh': 'https://github.com/{0}.git', 'gl': 'https://gitlab.com/{0}.git', 'helloworld': 'https://github.com/hackebrot/helloworld'}}\nE         \nE         Full diff:\nE           {\nE               'abbreviations': {\nE         -         'bb': 'https://bitbucket.org/{0}',\nE         -         'gh': 'https://github.com/{0}.git',\nE         -         'gl': 'https://gitlab.com/{0}.git',\nE                   'helloworld': 'https://github.com/hackebrot/helloworld',\nE               },\nE               'cookiecutters_dir': '/home/example/some-path-to-templates',\nE               'default_context': {\nE                   'email': 'firstname.lastname@gmail.com',\nE                   'full_name': 'Firstname Lastname',\nE                   'github_username': 'example',\nE                   'project': {\nE                       'description': 'description',\nE                       'tags': [\nE                           'first',\nE                           'second',\nE                           'third',\nE                       ],\nE                   },\nE               },\nE               'replay_dir': '/home/example/some-path-to-replay-files',\nE           }\n\ntests/test_get_config.py:80: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_get_configpytest_get_config_with_defaults","title":"test_get_config.py::test_get_config_with_defaults","text":"<pre>test_get_config.py::test_get_config_with_defaults</pre><pre>\ndef test_get_config_with_defaults():\n        \"\"\"A config file that overrides 1 of 3 defaults.\"\"\"\n        conf = config.get_config('tests/test-config/valid-partial-config.yaml')\n        default_cookiecutters_dir = Path('~/.cookiecutters').expanduser()\n        default_replay_dir = Path('~/.cookiecutter_replay').expanduser()\n        expected_conf = {\n            'cookiecutters_dir': str(default_cookiecutters_dir),\n            'replay_dir': str(default_replay_dir),\n            'default_context': {\n                'full_name': 'Firstname Lastname',\n                'email': 'firstname.lastname@gmail.com',\n                'github_username': 'example',\n            },\n            'abbreviations': {\n                'gh': 'https://github.com/{0}.git',\n                'gl': 'https://gitlab.com/{0}.git',\n                'bb': 'https://bitbucket.org/{0}',\n            },\n        }\n&gt;       assert conf == expected_conf\nE       AssertionError: assert {'default_context': {'full_name': 'Firstname Lastname', 'email': 'firstname.lastname@gmail.com', 'github_username': 'example'}} == {'cookiecutters_dir': '/tmp/pytest-of-root/pytest-0/test_get_config_with_defaults0/home/.cookiecutters', 'replay_dir': '/tmp/pytest-of-root/pytest-0/test_get_config_with_defaults0/home/.cookiecutter_replay', 'default_context': {'full_name': 'Firstname Lastname', 'email': 'firstname.lastname@gmail.com', 'github_username': 'example'}, 'abbreviations': {'gh': 'https://github.com/{0}.git', 'gl': 'https://gitlab.com/{0}.git', 'bb': 'https://bitbucket.org/{0}'}}\nE         \nE         Common items:\nE         {'default_context': {'email': 'firstname.lastname@gmail.com',\nE                              'full_name': 'Firstname Lastname',\nE                              'github_username': 'example'}}\nE         Right contains 3 more items:\nE         {'abbreviations': {'bb': 'https://bitbucket.org/{0}',\nE                            'gh': 'https://github.com/{0}.git',\nE                            'gl': 'https://gitlab.com/{0}.git'},\nE          'cookiecutters_dir': '/tmp/pytest-of-root/pytest-0/test_get_config_with_defaults0/home/.cookiecutters',\nE          'replay_dir': '/tmp/pytest-of-root/pytest-0/test_get_config_with_defaults0/home/.cookiecutter_replay'}\nE         \nE         Full diff:\nE           {\nE         -     'abbreviations': {\nE         -         'bb': 'https://bitbucket.org/{0}',\nE         -         'gh': 'https://github.com/{0}.git',\nE         -         'gl': 'https://gitlab.com/{0}.git',\nE         -     },\nE         -     'cookiecutters_dir': '/tmp/pytest-of-root/pytest-0/test_get_config_with_defaults0/home/.cookiecutters',\nE               'default_context': {\nE                   'email': 'firstname.lastname@gmail.com',\nE                   'full_name': 'Firstname Lastname',\nE                   'github_username': 'example',\nE               },\nE         -     'replay_dir': '/tmp/pytest-of-root/pytest-0/test_get_config_with_defaults0/home/.cookiecutter_replay',\nE           }\n\ntests/test_get_config.py:123: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_get_configpytest_get_config_empty_config_file","title":"test_get_config.py::test_get_config_empty_config_file","text":"<pre>test_get_config.py::test_get_config_empty_config_file</pre><pre>\ndef test_get_config_empty_config_file():\n        \"\"\"An empty config file results in the default config.\"\"\"\n&gt;       conf = config.get_config('tests/test-config/empty-config.yaml')\n\ntests/test_get_config.py:128: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nconfig_path = 'tests/test-config/empty-config.yaml'\n\n    def get_config(config_path):\n        \"\"\"Retrieve the config from the specified path, returning a config dict.\"\"\"\n        if not os.path.exists(config_path):\n            raise ConfigDoesNotExistException(f\"Config file {config_path} does not exist.\")\n\n        with open(config_path) as file_handle:\n            try:\n                user_config = yaml.safe_load(file_handle)\n            except yaml.YAMLError as e:\n                raise InvalidConfiguration(f\"Unable to parse YAML file {config_path}: {e}\")\n\n        if user_config is None:\n&gt;           raise InvalidConfiguration(f\"Config file {config_path} is empty.\")\nE           cookiecutter.exceptions.InvalidConfiguration: Config file tests/test-config/empty-config.yaml is empty.\n\ncookiecutter/config.py:50: InvalidConfiguration\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_get_configpytest_get_config_invalid_file_with_array_as_top_level_element","title":"test_get_config.py::test_get_config_invalid_file_with_array_as_top_level_element","text":"<pre>test_get_config.py::test_get_config_invalid_file_with_array_as_top_level_element</pre><pre>\ndef test_get_config_invalid_file_with_array_as_top_level_element():\n        \"\"\"An exception should be raised if top-level element is array.\"\"\"\n        expected_error_msg = (\n            'Top-level element of YAML file '\n            'tests/test-config/invalid-config-w-array.yaml should be an object.'\n        )\n&gt;       with pytest.raises(InvalidConfiguration) as exc_info:\nE       Failed: DID NOT RAISE \n\ntests/test_get_config.py:138: Failed"},{"location":"analysis_baseline_cookiecutter/#test_get_configpytest_get_config_invalid_file_with_multiple_docs","title":"test_get_config.py::test_get_config_invalid_file_with_multiple_docs","text":"<pre>test_get_config.py::test_get_config_invalid_file_with_multiple_docs</pre><pre>\ndef test_get_config_invalid_file_with_multiple_docs():\n        \"\"\"An exception should be raised if config file contains multiple docs.\"\"\"\n        expected_error_msg = (\n            'Unable to parse YAML file '\n            'tests/test-config/invalid-config-w-multiple-docs.yaml.'\n        )\n        with pytest.raises(InvalidConfiguration) as exc_info:\n            config.get_config('tests/test-config/invalid-config-w-multiple-docs.yaml')\n&gt;       assert expected_error_msg in str(exc_info.value)\nE       assert 'Unable to parse YAML file tests/test-config/invalid-config-w-multiple-docs.yaml.' in 'Unable to parse YAML file tests/test-config/invalid-config-w-multiple-docs.yaml: expected a single document in the stream\\n  in \"tests/test-config/invalid-config-w-multiple-docs.yaml\", line 2, column 1\\nbut found another document\\n  in \"tests/test-config/invalid-config-w-multiple-docs.yaml\", line 12, column 1'\nE        +  where 'Unable to parse YAML file tests/test-config/invalid-config-w-multiple-docs.yaml: expected a single document in the stream\\n  in \"tests/test-config/invalid-config-w-multiple-docs.yaml\", line 2, column 1\\nbut found another document\\n  in \"tests/test-config/invalid-config-w-multiple-docs.yaml\", line 12, column 1' = str(InvalidConfiguration('Unable to parse YAML file tests/test-config/invalid-config-w-multiple-docs.yaml: expected a single document in the stream\\n  in \"tests/test-config/invalid-config-w-multiple-docs.yaml\", line 2, column 1\\nbut found another document\\n  in \"tests/test-config/invalid-config-w-multiple-docs.yaml\", line 12, column 1'))\nE        +    where InvalidConfiguration('Unable to parse YAML file tests/test-config/invalid-config-w-multiple-docs.yaml: expected a single document in the stream\\n  in \"tests/test-config/invalid-config-w-multiple-docs.yaml\", line 2, column 1\\nbut found another document\\n  in \"tests/test-config/invalid-config-w-multiple-docs.yaml\", line 12, column 1') = .value\n\ntests/test_get_config.py:151: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_get_user_configpytest_get_user_config_valid","title":"test_get_user_config.py::test_get_user_config_valid","text":"<pre>test_get_user_config.py::test_get_user_config_valid</pre><pre>\nuser_config_path = '/root/.cookiecutterrc'\ncustom_config = {'abbreviations': {'bb': 'https://bitbucket.org/{0}', 'gh': 'https://github.com/{0}.git', 'gl': 'https://gitlab.com/{0}.git', 'helloworld': 'https://github.com/hackebrot/helloworld'}, 'cookiecutters_dir': '/home/example/some-path-to-templates', 'default_context': {'email': 'firstname.lastname@gmail.com', 'full_name': 'Firstname Lastname', 'github_username': 'example', 'project': {'description': 'description', 'tags': ['first', 'second', 'third']}}, 'replay_dir': '/home/example/some-path-to-replay-files'}\n\n    @pytest.mark.usefixtures('back_up_rc')\n    def test_get_user_config_valid(user_config_path, custom_config):\n        \"\"\"Validate user config correctly parsed if exist and correctly formatted.\"\"\"\n        shutil.copy('tests/test-config/valid-config.yaml', user_config_path)\n        conf = config.get_user_config()\n\n&gt;       assert conf == custom_config\nE       AssertionError: assert {'default_context': {'full_name': 'Firstname Lastname', 'email': 'firstname.lastname@gmail.com', 'github_username': 'example', 'project': {'description': 'description', 'tags': ['first', 'second', 'third']}}, 'cookiecutters_dir': '/home/example/some-path-to-templates', 'replay_dir': '/home/example/some-path-to-replay-files', 'abbreviations': {'helloworld': 'https://github.com/hackebrot/helloworld'}} == {'default_context': {'full_name': 'Firstname Lastname', 'email': 'firstname.lastname@gmail.com', 'github_username': 'example', 'project': {'description': 'description', 'tags': ['first', 'second', 'third']}}, 'cookiecutters_dir': '/home/example/some-path-to-templates', 'replay_dir': '/home/example/some-path-to-replay-files', 'abbreviations': {'gh': 'https://github.com/{0}.git', 'gl': 'https://gitlab.com/{0}.git', 'bb': 'https://bitbucket.org/{0}', 'helloworld': 'https://github.com/hackebrot/helloworld'}}\nE         \nE         Common items:\nE         {'cookiecutters_dir': '/home/example/some-path-to-templates',\nE          'default_context': {'email': 'firstname.lastname@gmail.com',\nE                              'full_name': 'Firstname Lastname',\nE                              'github_username': 'example',\nE                              'project': {'description': 'description',\nE                                          'tags': ['first', 'second', 'third']}},\nE          'replay_dir': '/home/example/some-path-to-replay-files'}\nE         Differing items:\nE         {'abbreviations': {'helloworld': 'https://github.com/hackebrot/helloworld'}} != {'abbreviations': {'bb': 'https://bitbucket.org/{0}', 'gh': 'https://github.com/{0}.git', 'gl': 'https://gitlab.com/{0}.git', 'helloworld': 'https://github.com/hackebrot/helloworld'}}\nE         \nE         Full diff:\nE           {\nE               'abbreviations': {\nE         -         'bb': 'https://bitbucket.org/{0}',\nE         -         'gh': 'https://github.com/{0}.git',\nE         -         'gl': 'https://gitlab.com/{0}.git',\nE                   'helloworld': 'https://github.com/hackebrot/helloworld',\nE               },\nE               'cookiecutters_dir': '/home/example/some-path-to-templates',\nE               'default_context': {\nE                   'email': 'firstname.lastname@gmail.com',\nE                   'full_name': 'Firstname Lastname',\nE                   'github_username': 'example',\nE                   'project': {\nE                       'description': 'description',\nE                       'tags': [\nE                           'first',\nE                           'second',\nE                           'third',\nE                       ],\nE                   },\nE               },\nE               'replay_dir': '/home/example/some-path-to-replay-files',\nE           }\n\ntests/test_get_user_config.py:76: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_get_user_configpytest_specify_config_path","title":"test_get_user_config.py::test_specify_config_path","text":"<pre>test_get_user_config.py::test_specify_config_path</pre><pre>\nmocker = \ncustom_config_path = 'tests/test-config/valid-config.yaml'\ncustom_config = {'abbreviations': {'bb': 'https://bitbucket.org/{0}', 'gh': 'https://github.com/{0}.git', 'gl': 'https://gitlab.com/{0}.git', 'helloworld': 'https://github.com/hackebrot/helloworld'}, 'cookiecutters_dir': '/home/example/some-path-to-templates', 'default_context': {'email': 'firstname.lastname@gmail.com', 'full_name': 'Firstname Lastname', 'github_username': 'example', 'project': {'description': 'description', 'tags': ['first', 'second', 'third']}}, 'replay_dir': '/home/example/some-path-to-replay-files'}\n\n    def test_specify_config_path(mocker, custom_config_path, custom_config):\n        \"\"\"Validate provided custom config path should be respected and parsed.\"\"\"\n        spy_get_config = mocker.spy(config, 'get_config')\n\n        user_config = config.get_user_config(custom_config_path)\n        spy_get_config.assert_called_once_with(custom_config_path)\n\n&gt;       assert user_config == custom_config\nE       AssertionError: assert {'default_context': {'full_name': 'Firstname Lastname', 'email': 'firstname.lastname@gmail.com', 'github_username': 'example', 'project': {'description': 'description', 'tags': ['first', 'second', 'third']}}, 'cookiecutters_dir': '/home/example/some-path-to-templates', 'replay_dir': '/home/example/some-path-to-replay-files', 'abbreviations': {'helloworld': 'https://github.com/hackebrot/helloworld'}} == {'default_context': {'full_name': 'Firstname Lastname', 'email': 'firstname.lastname@gmail.com', 'github_username': 'example', 'project': {'description': 'description', 'tags': ['first', 'second', 'third']}}, 'cookiecutters_dir': '/home/example/some-path-to-templates', 'replay_dir': '/home/example/some-path-to-replay-files', 'abbreviations': {'gh': 'https://github.com/{0}.git', 'gl': 'https://gitlab.com/{0}.git', 'bb': 'https://bitbucket.org/{0}', 'helloworld': 'https://github.com/hackebrot/helloworld'}}\nE         \nE         Common items:\nE         {'cookiecutters_dir': '/home/example/some-path-to-templates',\nE          'default_context': {'email': 'firstname.lastname@gmail.com',\nE                              'full_name': 'Firstname Lastname',\nE                              'github_username': 'example',\nE                              'project': {'description': 'description',\nE                                          'tags': ['first', 'second', 'third']}},\nE          'replay_dir': '/home/example/some-path-to-replay-files'}\nE         Differing items:\nE         {'abbreviations': {'helloworld': 'https://github.com/hackebrot/helloworld'}} != {'abbreviations': {'bb': 'https://bitbucket.org/{0}', 'gh': 'https://github.com/{0}.git', 'gl': 'https://gitlab.com/{0}.git', 'helloworld': 'https://github.com/hackebrot/helloworld'}}\nE         \nE         Full diff:\nE           {\nE               'abbreviations': {\nE         -         'bb': 'https://bitbucket.org/{0}',\nE         -         'gh': 'https://github.com/{0}.git',\nE         -         'gl': 'https://gitlab.com/{0}.git',\nE                   'helloworld': 'https://github.com/hackebrot/helloworld',\nE               },\nE               'cookiecutters_dir': '/home/example/some-path-to-templates',\nE               'default_context': {\nE                   'email': 'firstname.lastname@gmail.com',\nE                   'full_name': 'Firstname Lastname',\nE                   'github_username': 'example',\nE                   'project': {\nE                       'description': 'description',\nE                       'tags': [\nE                           'first',\nE                           'second',\nE                           'third',\nE                       ],\nE                   },\nE               },\nE               'replay_dir': '/home/example/some-path-to-replay-files',\nE           }\n\ntests/test_get_user_config.py:106: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_get_user_configpytest_default_config_from_env_variable","title":"test_get_user_config.py::test_default_config_from_env_variable","text":"<pre>test_get_user_config.py::test_default_config_from_env_variable</pre><pre>\nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eece99c90&gt;\ncustom_config_path = 'tests/test-config/valid-config.yaml'\ncustom_config = {'abbreviations': {'bb': 'https://bitbucket.org/{0}', 'gh': 'https://github.com/{0}.git', 'gl': 'https://gitlab.com/{0}.git', 'helloworld': 'https://github.com/hackebrot/helloworld'}, 'cookiecutters_dir': '/home/example/some-path-to-templates', 'default_context': {'email': 'firstname.lastname@gmail.com', 'full_name': 'Firstname Lastname', 'github_username': 'example', 'project': {'description': 'description', 'tags': ['first', 'second', 'third']}}, 'replay_dir': '/home/example/some-path-to-replay-files'}\n\n    def test_default_config_from_env_variable(\n        monkeypatch, custom_config_path, custom_config\n    ):\n        \"\"\"Validate app configuration. User config path should be parsed from sys env.\"\"\"\n        monkeypatch.setenv('COOKIECUTTER_CONFIG', custom_config_path)\n\n        user_config = config.get_user_config()\n&gt;       assert user_config == custom_config\nE       AssertionError: assert {'default_context': {'full_name': 'Firstname Lastname', 'email': 'firstname.lastname@gmail.com', 'github_username': 'example', 'project': {'description': 'description', 'tags': ['first', 'second', 'third']}}, 'cookiecutters_dir': '/home/example/some-path-to-templates', 'replay_dir': '/home/example/some-path-to-replay-files', 'abbreviations': {'helloworld': 'https://github.com/hackebrot/helloworld'}} == {'default_context': {'full_name': 'Firstname Lastname', 'email': 'firstname.lastname@gmail.com', 'github_username': 'example', 'project': {'description': 'description', 'tags': ['first', 'second', 'third']}}, 'cookiecutters_dir': '/home/example/some-path-to-templates', 'replay_dir': '/home/example/some-path-to-replay-files', 'abbreviations': {'gh': 'https://github.com/{0}.git', 'gl': 'https://gitlab.com/{0}.git', 'bb': 'https://bitbucket.org/{0}', 'helloworld': 'https://github.com/hackebrot/helloworld'}}\nE         \nE         Common items:\nE         {'cookiecutters_dir': '/home/example/some-path-to-templates',\nE          'default_context': {'email': 'firstname.lastname@gmail.com',\nE                              'full_name': 'Firstname Lastname',\nE                              'github_username': 'example',\nE                              'project': {'description': 'description',\nE                                          'tags': ['first', 'second', 'third']}},\nE          'replay_dir': '/home/example/some-path-to-replay-files'}\nE         Differing items:\nE         {'abbreviations': {'helloworld': 'https://github.com/hackebrot/helloworld'}} != {'abbreviations': {'bb': 'https://bitbucket.org/{0}', 'gh': 'https://github.com/{0}.git', 'gl': 'https://gitlab.com/{0}.git', 'helloworld': 'https://github.com/hackebrot/helloworld'}}\nE         \nE         Full diff:\nE           {\nE               'abbreviations': {\nE         -         'bb': 'https://bitbucket.org/{0}',\nE         -         'gh': 'https://github.com/{0}.git',\nE         -         'gl': 'https://gitlab.com/{0}.git',\nE                   'helloworld': 'https://github.com/hackebrot/helloworld',\nE               },\nE               'cookiecutters_dir': '/home/example/some-path-to-templates',\nE               'default_context': {\nE                   'email': 'firstname.lastname@gmail.com',\nE                   'full_name': 'Firstname Lastname',\nE                   'github_username': 'example',\nE                   'project': {\nE                       'description': 'description',\nE                       'tags': [\nE                           'first',\nE                           'second',\nE                           'third',\nE                       ],\nE                   },\nE               },\nE               'replay_dir': '/home/example/some-path-to-replay-files',\nE           }\n\ntests/test_get_user_config.py:121: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_get_user_configpytest_expand_user_for_directories_in_config","title":"test_get_user_config.py::test_expand_user_for_directories_in_config","text":"<pre>test_get_user_config.py::test_expand_user_for_directories_in_config</pre><pre>\nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eec7e1630&gt;\n\n    def test_expand_user_for_directories_in_config(monkeypatch):\n        \"\"\"Validate user pointers expanded in user configs.\"\"\"\n\n        def _expanduser(path):\n            return path.replace('~', 'Users/bob')\n\n        monkeypatch.setattr('os.path.expanduser', _expanduser)\n\n        config_file = 'tests/test-config/config-expand-user.yaml'\n\n        user_config = config.get_user_config(config_file)\n&gt;       assert user_config['replay_dir'] == 'Users/bob/replay-files'\nE       AssertionError: assert '~/replay-files' == 'Users/bob/replay-files'\nE         \nE         - Users/bob/replay-files\nE         + ~/replay-files\n\ntests/test_get_user_config.py:145: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_get_user_configpytest_expand_vars_for_directories_in_config","title":"test_get_user_config.py::test_expand_vars_for_directories_in_config","text":"<pre>test_get_user_config.py::test_expand_vars_for_directories_in_config</pre><pre>\nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eed08bd00&gt;\n\n    def test_expand_vars_for_directories_in_config(monkeypatch):\n        \"\"\"Validate environment variables expanded in user configs.\"\"\"\n        monkeypatch.setenv('COOKIES', 'Users/bob/cookies')\n\n        config_file = 'tests/test-config/config-expand-vars.yaml'\n\n        user_config = config.get_user_config(config_file)\n&gt;       assert user_config['replay_dir'] == 'Users/bob/cookies/replay-files'\nE       AssertionError: assert '$COOKIES/replay-files' == 'Users/bob/cookies/replay-files'\nE         \nE         - Users/bob/cookies/replay-files\nE         + $COOKIES/replay-files\n\ntests/test_get_user_config.py:156: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_hookspytestfindhookstest_find_hook","title":"test_hooks.py::TestFindHooks::test_find_hook","text":"<pre>test_hooks.py::TestFindHooks::test_find_hook</pre><pre>\nself = \n\n    def test_find_hook(self):\n        \"\"\"Finds the specified hook.\"\"\"\n        with utils.work_in(self.repo_path):\n            expected_pre = os.path.abspath('hooks/pre_gen_project.py')\n            actual_hook_path = hooks.find_hook('pre_gen_project')\n&gt;           assert expected_pre == actual_hook_path[0]\nE           AssertionError: assert '/testbed/tests/test-hooks/hooks/pre_gen_project.py' == '/'\nE             \nE             - /\nE             + /testbed/tests/test-hooks/hooks/pre_gen_project.py\n\ntests/test_hooks.py:93: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_hookspytestexternalhookstest_run_failing_script","title":"test_hooks.py::TestExternalHooks::test_run_failing_script","text":"<pre>test_hooks.py::TestExternalHooks::test_run_failing_script</pre><pre>\nself = \nmocker = \n\n    def test_run_failing_script(self, mocker):\n        \"\"\"Test correct exception raise if run_script fails.\"\"\"\n        err = OSError()\n\n        prompt = mocker.patch('subprocess.Popen')\n        prompt.side_effect = err\n\n        with pytest.raises(exceptions.FailedHookException) as excinfo:\n&gt;           hooks.run_script(os.path.join(self.hooks_path, self.post_hook))\n\ntests/test_hooks.py:157: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/hooks.py:65: in run_script\n    subprocess.check_call([script_path], cwd=cwd)\n/usr/lib/python3.10/subprocess.py:364: in check_call\n    retcode = call(*popenargs, **kwargs)\n/usr/lib/python3.10/subprocess.py:345: in call\n    with Popen(*popenargs, **kwargs) as p:\n/usr/lib/python3.10/unittest/mock.py:1114: in __call__\n    return self._mock_call(*args, **kwargs)\n/usr/lib/python3.10/unittest/mock.py:1118: in _mock_call\n    return self._execute_mock_call(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nargs = (['/testbed/tests/test-hooks/hooks/post_gen_project.sh'],)\nkwargs = {'cwd': '.'}, effect = OSError()\n\n    def _execute_mock_call(self, /, *args, **kwargs):\n        # separate from _increment_mock_call so that awaited functions are\n        # executed separately from their call, also AsyncMock overrides this method\n\n        effect = self.side_effect\n        if effect is not None:\n            if _is_exception(effect):\n&gt;               raise effect\nE               OSError\n\n/usr/lib/python3.10/unittest/mock.py:1173: OSError"},{"location":"analysis_baseline_cookiecutter/#test_hookspytestexternalhookstest_run_failing_script_enoexec","title":"test_hooks.py::TestExternalHooks::test_run_failing_script_enoexec","text":"<pre>test_hooks.py::TestExternalHooks::test_run_failing_script_enoexec</pre><pre>\nself = \nmocker = \n\n    def test_run_failing_script_enoexec(self, mocker):\n        \"\"\"Test correct exception raise if run_script fails.\"\"\"\n        err = OSError()\n        err.errno = errno.ENOEXEC\n\n        prompt = mocker.patch('subprocess.Popen')\n        prompt.side_effect = err\n\n        with pytest.raises(exceptions.FailedHookException) as excinfo:\n&gt;           hooks.run_script(os.path.join(self.hooks_path, self.post_hook))\n\ntests/test_hooks.py:169: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/hooks.py:65: in run_script\n    subprocess.check_call([script_path], cwd=cwd)\n/usr/lib/python3.10/subprocess.py:364: in check_call\n    retcode = call(*popenargs, **kwargs)\n/usr/lib/python3.10/subprocess.py:345: in call\n    with Popen(*popenargs, **kwargs) as p:\n/usr/lib/python3.10/unittest/mock.py:1114: in __call__\n    return self._mock_call(*args, **kwargs)\n/usr/lib/python3.10/unittest/mock.py:1118: in _mock_call\n    return self._execute_mock_call(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nargs = (['/testbed/tests/test-hooks/hooks/post_gen_project.sh'],)\nkwargs = {'cwd': '.'}, effect = OSError()\n\n    def _execute_mock_call(self, /, *args, **kwargs):\n        # separate from _increment_mock_call so that awaited functions are\n        # executed separately from their call, also AsyncMock overrides this method\n\n        effect = self.side_effect\n        if effect is not None:\n            if _is_exception(effect):\n&gt;               raise effect\nE               OSError\n\n/usr/lib/python3.10/unittest/mock.py:1173: OSError"},{"location":"analysis_baseline_cookiecutter/#test_hookspytestexternalhookstest_run_script_cwd","title":"test_hooks.py::TestExternalHooks::test_run_script_cwd","text":"<pre>test_hooks.py::TestExternalHooks::test_run_script_cwd</pre><pre>\nself = \n\n    def test_run_script_cwd(self):\n        \"\"\"Change directory before running hook.\"\"\"\n&gt;       hooks.run_script(os.path.join(self.hooks_path, self.post_hook), 'tests')\n\ntests/test_hooks.py:176: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/hooks.py:65: in run_script\n    subprocess.check_call([script_path], cwd=cwd)\n/usr/lib/python3.10/subprocess.py:364: in check_call\n    retcode = call(*popenargs, **kwargs)\n/usr/lib/python3.10/subprocess.py:345: in call\n    with Popen(*popenargs, **kwargs) as p:\n/usr/lib/python3.10/subprocess.py:971: in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nargs = ['/testbed/tests/test-hooks/hooks/post_gen_project.sh']\nexecutable = b'/testbed/tests/test-hooks/hooks/post_gen_project.sh'\npreexec_fn = None, close_fds = True, pass_fds = (), cwd = 'tests', env = None\nstartupinfo = None, creationflags = 0, shell = False, p2cread = -1\np2cwrite = -1, c2pread = -1, c2pwrite = -1, errread = -1, errwrite = -1\nrestore_signals = True, gid = None, gids = None, uid = None, umask = -1\nstart_new_session = False\n\n    def _execute_child(self, args, executable, preexec_fn, close_fds,\n                       pass_fds, cwd, env,\n                       startupinfo, creationflags, shell,\n                       p2cread, p2cwrite,\n                       c2pread, c2pwrite,\n                       errread, errwrite,\n                       restore_signals,\n                       gid, gids, uid, umask,\n                       start_new_session):\n        \"\"\"Execute program (POSIX version)\"\"\"\n\n        if isinstance(args, (str, bytes)):\n            args = [args]\n        elif isinstance(args, os.PathLike):\n            if shell:\n                raise TypeError('path-like args is not allowed when '\n                                'shell is true')\n            args = [args]\n        else:\n            args = list(args)\n\n        if shell:\n            # On Android the default shell is at '/system/bin/sh'.\n            unix_shell = ('/system/bin/sh' if\n                      hasattr(sys, 'getandroidapilevel') else '/bin/sh')\n            args = [unix_shell, \"-c\"] + args\n            if executable:\n                args[0] = executable\n\n        if executable is None:\n            executable = args[0]\n\n        sys.audit(\"subprocess.Popen\", executable, args, cwd, env)\n\n        if (_USE_POSIX_SPAWN\n                and os.path.dirname(executable)\n                and preexec_fn is None\n                and not close_fds\n                and not pass_fds\n                and cwd is None\n                and (p2cread == -1 or p2cread &gt; 2)\n                and (c2pwrite == -1 or c2pwrite &gt; 2)\n                and (errwrite == -1 or errwrite &gt; 2)\n                and not start_new_session\n                and gid is None\n                and gids is None\n                and uid is None\n                and umask &lt; 0):\n            self._posix_spawn(args, executable, env, restore_signals,\n                              p2cread, p2cwrite,\n                              c2pread, c2pwrite,\n                              errread, errwrite)\n            return\n\n        orig_executable = executable\n\n        # For transferring possible exec failure from child to parent.\n        # Data format: \"exception name:hex errno:description\"\n        # Pickle is not used; it is complex and involves memory allocation.\n        errpipe_read, errpipe_write = os.pipe()\n        # errpipe_write must not be in the standard io 0, 1, or 2 fd range.\n        low_fds_to_close = []\n        while errpipe_write &lt; 3:\n            low_fds_to_close.append(errpipe_write)\n            errpipe_write = os.dup(errpipe_write)\n        for low_fd in low_fds_to_close:\n            os.close(low_fd)\n        try:\n            try:\n                # We must avoid complex work that could involve\n                # malloc or free in the child process to avoid\n                # potential deadlocks, thus we do all this here.\n                # and pass it to fork_exec()\n\n                if env is not None:\n                    env_list = []\n                    for k, v in env.items():\n                        k = os.fsencode(k)\n                        if b'=' in k:\n                            raise ValueError(\"illegal environment variable name\")\n                        env_list.append(k + b'=' + os.fsencode(v))\n                else:\n                    env_list = None  # Use execv instead of execve.\n                executable = os.fsencode(executable)\n                if os.path.dirname(executable):\n                    executable_list = (executable,)\n                else:\n                    # This matches the behavior of os._execvpe().\n                    executable_list = tuple(\n                        os.path.join(os.fsencode(dir), executable)\n                        for dir in os.get_exec_path(env))\n                fds_to_keep = set(pass_fds)\n                fds_to_keep.add(errpipe_write)\n                self.pid = _posixsubprocess.fork_exec(\n                        args, executable_list,\n                        close_fds, tuple(sorted(map(int, fds_to_keep))),\n                        cwd, env_list,\n                        p2cread, p2cwrite, c2pread, c2pwrite,\n                        errread, errwrite,\n                        errpipe_read, errpipe_write,\n                        restore_signals, start_new_session,\n                        gid, gids, uid, umask,\n                        preexec_fn)\n                self._child_created = True\n            finally:\n                # be sure the FD is closed no matter what\n                os.close(errpipe_write)\n\n            self._close_pipe_fds(p2cread, p2cwrite,\n                                 c2pread, c2pwrite,\n                                 errread, errwrite)\n\n            # Wait for exec to fail or succeed; possibly raising an\n            # exception (limited in size)\n            errpipe_data = bytearray()\n            while True:\n                part = os.read(errpipe_read, 50000)\n                errpipe_data += part\n                if not part or len(errpipe_data) &gt; 50000:\n                    break\n        finally:\n            # be sure the FD is closed no matter what\n            os.close(errpipe_read)\n\n        if errpipe_data:\n            try:\n                pid, sts = os.waitpid(self.pid, 0)\n                if pid == self.pid:\n                    self._handle_exitstatus(sts)\n                else:\n                    self.returncode = sys.maxsize\n            except ChildProcessError:\n                pass\n\n            try:\n                exception_name, hex_errno, err_msg = (\n                        errpipe_data.split(b':', 2))\n                # The encoding here should match the encoding\n                # written in by the subprocess implementations\n                # like _posixsubprocess\n                err_msg = err_msg.decode()\n            except ValueError:\n                exception_name = b'SubprocessError'\n                hex_errno = b'0'\n                err_msg = 'Bad exception data from child: {!r}'.format(\n                              bytes(errpipe_data))\n            child_exception_type = getattr(\n                    builtins, exception_name.decode('ascii'),\n                    SubprocessError)\n            if issubclass(child_exception_type, OSError) and hex_errno:\n                errno_num = int(hex_errno, 16)\n                child_exec_never_called = (err_msg == \"noexec\")\n                if child_exec_never_called:\n                    err_msg = \"\"\n                    # The error must be from chdir(cwd).\n                    err_filename = cwd\n                else:\n                    err_filename = orig_executable\n                if errno_num != 0:\n                    err_msg = os.strerror(errno_num)\n&gt;               raise child_exception_type(errno_num, err_msg, err_filename)\nE               FileNotFoundError: [Errno 2] No such file or directory: 'tests'\n\n/usr/lib/python3.10/subprocess.py:1863: FileNotFoundError"},{"location":"analysis_baseline_cookiecutter/#test_hookspytestexternalhookstest_run_script_with_context","title":"test_hooks.py::TestExternalHooks::test_run_script_with_context","text":"<pre>test_hooks.py::TestExternalHooks::test_run_script_with_context</pre><pre>\nself = \n\n    def test_run_script_with_context(self):\n        \"\"\"Execute a hook script, passing a context.\"\"\"\n        hook_path = os.path.join(self.hooks_path, 'post_gen_project.sh')\n\n        if sys.platform.startswith('win'):\n            post = 'post_gen_project.bat'\n            with Path(self.hooks_path, post).open('w') as f:\n                f.write(\"@echo off\\n\")\n                f.write(\"\\n\")\n                f.write(\"echo post generation hook\\n\")\n                f.write(\"echo. &gt;{{cookiecutter.file}}\\n\")\n        else:\n            with Path(hook_path).open('w') as fh:\n                fh.write(\"#!/bin/bash\\n\")\n                fh.write(\"\\n\")\n                fh.write(\"echo 'post generation hook';\\n\")\n                fh.write(\"touch 'shell_post.txt'\\n\")\n                fh.write(\"touch '{{cookiecutter.file}}'\\n\")\n                os.chmod(hook_path, os.stat(hook_path).st_mode | stat.S_IXUSR)\n\n&gt;       hooks.run_script_with_context(\n            os.path.join(self.hooks_path, self.post_hook),\n            'tests',\n            {'cookiecutter': {'file': 'context_post.txt'}},\n        )\n\ntests/test_hooks.py:200: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/hooks.py:91: in run_script_with_context\n    run_script(temp_script_path, cwd)\ncookiecutter/hooks.py:65: in run_script\n    subprocess.check_call([script_path], cwd=cwd)\n/usr/lib/python3.10/subprocess.py:364: in check_call\n    retcode = call(*popenargs, **kwargs)\n/usr/lib/python3.10/subprocess.py:345: in call\n    with Popen(*popenargs, **kwargs) as p:\n/usr/lib/python3.10/subprocess.py:971: in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nargs = ['/tmp/tmpqr_ta0a3'], executable = b'/tmp/tmpqr_ta0a3', preexec_fn = None\nclose_fds = True, pass_fds = (), cwd = 'tests', env = None, startupinfo = None\ncreationflags = 0, shell = False, p2cread = -1, p2cwrite = -1, c2pread = -1\nc2pwrite = -1, errread = -1, errwrite = -1, restore_signals = True, gid = None\ngids = None, uid = None, umask = -1, start_new_session = False\n\n    def _execute_child(self, args, executable, preexec_fn, close_fds,\n                       pass_fds, cwd, env,\n                       startupinfo, creationflags, shell,\n                       p2cread, p2cwrite,\n                       c2pread, c2pwrite,\n                       errread, errwrite,\n                       restore_signals,\n                       gid, gids, uid, umask,\n                       start_new_session):\n        \"\"\"Execute program (POSIX version)\"\"\"\n\n        if isinstance(args, (str, bytes)):\n            args = [args]\n        elif isinstance(args, os.PathLike):\n            if shell:\n                raise TypeError('path-like args is not allowed when '\n                                'shell is true')\n            args = [args]\n        else:\n            args = list(args)\n\n        if shell:\n            # On Android the default shell is at '/system/bin/sh'.\n            unix_shell = ('/system/bin/sh' if\n                      hasattr(sys, 'getandroidapilevel') else '/bin/sh')\n            args = [unix_shell, \"-c\"] + args\n            if executable:\n                args[0] = executable\n\n        if executable is None:\n            executable = args[0]\n\n        sys.audit(\"subprocess.Popen\", executable, args, cwd, env)\n\n        if (_USE_POSIX_SPAWN\n                and os.path.dirname(executable)\n                and preexec_fn is None\n                and not close_fds\n                and not pass_fds\n                and cwd is None\n                and (p2cread == -1 or p2cread &gt; 2)\n                and (c2pwrite == -1 or c2pwrite &gt; 2)\n                and (errwrite == -1 or errwrite &gt; 2)\n                and not start_new_session\n                and gid is None\n                and gids is None\n                and uid is None\n                and umask &lt; 0):\n            self._posix_spawn(args, executable, env, restore_signals,\n                              p2cread, p2cwrite,\n                              c2pread, c2pwrite,\n                              errread, errwrite)\n            return\n\n        orig_executable = executable\n\n        # For transferring possible exec failure from child to parent.\n        # Data format: \"exception name:hex errno:description\"\n        # Pickle is not used; it is complex and involves memory allocation.\n        errpipe_read, errpipe_write = os.pipe()\n        # errpipe_write must not be in the standard io 0, 1, or 2 fd range.\n        low_fds_to_close = []\n        while errpipe_write &lt; 3:\n            low_fds_to_close.append(errpipe_write)\n            errpipe_write = os.dup(errpipe_write)\n        for low_fd in low_fds_to_close:\n            os.close(low_fd)\n        try:\n            try:\n                # We must avoid complex work that could involve\n                # malloc or free in the child process to avoid\n                # potential deadlocks, thus we do all this here.\n                # and pass it to fork_exec()\n\n                if env is not None:\n                    env_list = []\n                    for k, v in env.items():\n                        k = os.fsencode(k)\n                        if b'=' in k:\n                            raise ValueError(\"illegal environment variable name\")\n                        env_list.append(k + b'=' + os.fsencode(v))\n                else:\n                    env_list = None  # Use execv instead of execve.\n                executable = os.fsencode(executable)\n                if os.path.dirname(executable):\n                    executable_list = (executable,)\n                else:\n                    # This matches the behavior of os._execvpe().\n                    executable_list = tuple(\n                        os.path.join(os.fsencode(dir), executable)\n                        for dir in os.get_exec_path(env))\n                fds_to_keep = set(pass_fds)\n                fds_to_keep.add(errpipe_write)\n                self.pid = _posixsubprocess.fork_exec(\n                        args, executable_list,\n                        close_fds, tuple(sorted(map(int, fds_to_keep))),\n                        cwd, env_list,\n                        p2cread, p2cwrite, c2pread, c2pwrite,\n                        errread, errwrite,\n                        errpipe_read, errpipe_write,\n                        restore_signals, start_new_session,\n                        gid, gids, uid, umask,\n                        preexec_fn)\n                self._child_created = True\n            finally:\n                # be sure the FD is closed no matter what\n                os.close(errpipe_write)\n\n            self._close_pipe_fds(p2cread, p2cwrite,\n                                 c2pread, c2pwrite,\n                                 errread, errwrite)\n\n            # Wait for exec to fail or succeed; possibly raising an\n            # exception (limited in size)\n            errpipe_data = bytearray()\n            while True:\n                part = os.read(errpipe_read, 50000)\n                errpipe_data += part\n                if not part or len(errpipe_data) &gt; 50000:\n                    break\n        finally:\n            # be sure the FD is closed no matter what\n            os.close(errpipe_read)\n\n        if errpipe_data:\n            try:\n                pid, sts = os.waitpid(self.pid, 0)\n                if pid == self.pid:\n                    self._handle_exitstatus(sts)\n                else:\n                    self.returncode = sys.maxsize\n            except ChildProcessError:\n                pass\n\n            try:\n                exception_name, hex_errno, err_msg = (\n                        errpipe_data.split(b':', 2))\n                # The encoding here should match the encoding\n                # written in by the subprocess implementations\n                # like _posixsubprocess\n                err_msg = err_msg.decode()\n            except ValueError:\n                exception_name = b'SubprocessError'\n                hex_errno = b'0'\n                err_msg = 'Bad exception data from child: {!r}'.format(\n                              bytes(errpipe_data))\n            child_exception_type = getattr(\n                    builtins, exception_name.decode('ascii'),\n                    SubprocessError)\n            if issubclass(child_exception_type, OSError) and hex_errno:\n                errno_num = int(hex_errno, 16)\n                child_exec_never_called = (err_msg == \"noexec\")\n                if child_exec_never_called:\n                    err_msg = \"\"\n                    # The error must be from chdir(cwd).\n                    err_filename = cwd\n                else:\n                    err_filename = orig_executable\n                if errno_num != 0:\n                    err_msg = os.strerror(errno_num)\n&gt;               raise child_exception_type(errno_num, err_msg, err_filename)\nE               FileNotFoundError: [Errno 2] No such file or directory: 'tests'\n\n/usr/lib/python3.10/subprocess.py:1863: FileNotFoundError"},{"location":"analysis_baseline_cookiecutter/#test_hookspytestexternalhookstest_run_hook","title":"test_hooks.py::TestExternalHooks::test_run_hook","text":"<pre>test_hooks.py::TestExternalHooks::test_run_hook</pre><pre>\nself = \n\n    def test_run_hook(self):\n        \"\"\"Execute hook from specified template in specified output \\\n        directory.\"\"\"\n        tests_dir = os.path.join(self.repo_path, 'input{{hooks}}')\n        with utils.work_in(self.repo_path):\n&gt;           hooks.run_hook('pre_gen_project', tests_dir, {})\n\ntests/test_hooks.py:213: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/hooks.py:108: in run_hook\n    run_script_with_context(hook_path, project_dir, context)\ncookiecutter/hooks.py:91: in run_script_with_context\n    run_script(temp_script_path, cwd)\ncookiecutter/hooks.py:65: in run_script\n    subprocess.check_call([script_path], cwd=cwd)\n/usr/lib/python3.10/subprocess.py:364: in check_call\n    retcode = call(*popenargs, **kwargs)\n/usr/lib/python3.10/subprocess.py:345: in call\n    with Popen(*popenargs, **kwargs) as p:\n/usr/lib/python3.10/subprocess.py:971: in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nargs = ['/tmp/tmpyz7ty5z3'], executable = b'/tmp/tmpyz7ty5z3', preexec_fn = None\nclose_fds = True, pass_fds = ()\ncwd = '/testbed/tests/test-hooks/input{{hooks}}', env = None, startupinfo = None\ncreationflags = 0, shell = False, p2cread = -1, p2cwrite = -1, c2pread = -1\nc2pwrite = -1, errread = -1, errwrite = -1, restore_signals = True, gid = None\ngids = None, uid = None, umask = -1, start_new_session = False\n\n    def _execute_child(self, args, executable, preexec_fn, close_fds,\n                       pass_fds, cwd, env,\n                       startupinfo, creationflags, shell,\n                       p2cread, p2cwrite,\n                       c2pread, c2pwrite,\n                       errread, errwrite,\n                       restore_signals,\n                       gid, gids, uid, umask,\n                       start_new_session):\n        \"\"\"Execute program (POSIX version)\"\"\"\n\n        if isinstance(args, (str, bytes)):\n            args = [args]\n        elif isinstance(args, os.PathLike):\n            if shell:\n                raise TypeError('path-like args is not allowed when '\n                                'shell is true')\n            args = [args]\n        else:\n            args = list(args)\n\n        if shell:\n            # On Android the default shell is at '/system/bin/sh'.\n            unix_shell = ('/system/bin/sh' if\n                      hasattr(sys, 'getandroidapilevel') else '/bin/sh')\n            args = [unix_shell, \"-c\"] + args\n            if executable:\n                args[0] = executable\n\n        if executable is None:\n            executable = args[0]\n\n        sys.audit(\"subprocess.Popen\", executable, args, cwd, env)\n\n        if (_USE_POSIX_SPAWN\n                and os.path.dirname(executable)\n                and preexec_fn is None\n                and not close_fds\n                and not pass_fds\n                and cwd is None\n                and (p2cread == -1 or p2cread &gt; 2)\n                and (c2pwrite == -1 or c2pwrite &gt; 2)\n                and (errwrite == -1 or errwrite &gt; 2)\n                and not start_new_session\n                and gid is None\n                and gids is None\n                and uid is None\n                and umask &lt; 0):\n            self._posix_spawn(args, executable, env, restore_signals,\n                              p2cread, p2cwrite,\n                              c2pread, c2pwrite,\n                              errread, errwrite)\n            return\n\n        orig_executable = executable\n\n        # For transferring possible exec failure from child to parent.\n        # Data format: \"exception name:hex errno:description\"\n        # Pickle is not used; it is complex and involves memory allocation.\n        errpipe_read, errpipe_write = os.pipe()\n        # errpipe_write must not be in the standard io 0, 1, or 2 fd range.\n        low_fds_to_close = []\n        while errpipe_write &lt; 3:\n            low_fds_to_close.append(errpipe_write)\n            errpipe_write = os.dup(errpipe_write)\n        for low_fd in low_fds_to_close:\n            os.close(low_fd)\n        try:\n            try:\n                # We must avoid complex work that could involve\n                # malloc or free in the child process to avoid\n                # potential deadlocks, thus we do all this here.\n                # and pass it to fork_exec()\n\n                if env is not None:\n                    env_list = []\n                    for k, v in env.items():\n                        k = os.fsencode(k)\n                        if b'=' in k:\n                            raise ValueError(\"illegal environment variable name\")\n                        env_list.append(k + b'=' + os.fsencode(v))\n                else:\n                    env_list = None  # Use execv instead of execve.\n                executable = os.fsencode(executable)\n                if os.path.dirname(executable):\n                    executable_list = (executable,)\n                else:\n                    # This matches the behavior of os._execvpe().\n                    executable_list = tuple(\n                        os.path.join(os.fsencode(dir), executable)\n                        for dir in os.get_exec_path(env))\n                fds_to_keep = set(pass_fds)\n                fds_to_keep.add(errpipe_write)\n                self.pid = _posixsubprocess.fork_exec(\n                        args, executable_list,\n                        close_fds, tuple(sorted(map(int, fds_to_keep))),\n                        cwd, env_list,\n                        p2cread, p2cwrite, c2pread, c2pwrite,\n                        errread, errwrite,\n                        errpipe_read, errpipe_write,\n                        restore_signals, start_new_session,\n                        gid, gids, uid, umask,\n                        preexec_fn)\n                self._child_created = True\n            finally:\n                # be sure the FD is closed no matter what\n                os.close(errpipe_write)\n\n            self._close_pipe_fds(p2cread, p2cwrite,\n                                 c2pread, c2pwrite,\n                                 errread, errwrite)\n\n            # Wait for exec to fail or succeed; possibly raising an\n            # exception (limited in size)\n            errpipe_data = bytearray()\n            while True:\n                part = os.read(errpipe_read, 50000)\n                errpipe_data += part\n                if not part or len(errpipe_data) &gt; 50000:\n                    break\n        finally:\n            # be sure the FD is closed no matter what\n            os.close(errpipe_read)\n\n        if errpipe_data:\n            try:\n                pid, sts = os.waitpid(self.pid, 0)\n                if pid == self.pid:\n                    self._handle_exitstatus(sts)\n                else:\n                    self.returncode = sys.maxsize\n            except ChildProcessError:\n                pass\n\n            try:\n                exception_name, hex_errno, err_msg = (\n                        errpipe_data.split(b':', 2))\n                # The encoding here should match the encoding\n                # written in by the subprocess implementations\n                # like _posixsubprocess\n                err_msg = err_msg.decode()\n            except ValueError:\n                exception_name = b'SubprocessError'\n                hex_errno = b'0'\n                err_msg = 'Bad exception data from child: {!r}'.format(\n                              bytes(errpipe_data))\n            child_exception_type = getattr(\n                    builtins, exception_name.decode('ascii'),\n                    SubprocessError)\n            if issubclass(child_exception_type, OSError) and hex_errno:\n                errno_num = int(hex_errno, 16)\n                child_exec_never_called = (err_msg == \"noexec\")\n                if child_exec_never_called:\n                    err_msg = \"\"\n                    # The error must be from chdir(cwd).\n                    err_filename = cwd\n                else:\n                    err_filename = orig_executable\n                if errno_num != 0:\n                    err_msg = os.strerror(errno_num)\n&gt;               raise child_exception_type(errno_num, err_msg, err_filename)\nE               PermissionError: [Errno 13] Permission denied: '/tmp/tmpyz7ty5z3'\n\n/usr/lib/python3.10/subprocess.py:1863: PermissionError"},{"location":"analysis_baseline_cookiecutter/#test_hookspytestexternalhookstest_run_failing_hook","title":"test_hooks.py::TestExternalHooks::test_run_failing_hook","text":"<pre>test_hooks.py::TestExternalHooks::test_run_failing_hook</pre><pre>\nself = \n\n    def test_run_failing_hook(self):\n        \"\"\"Test correct exception raise if hook exit code is not zero.\"\"\"\n        hook_path = os.path.join(self.hooks_path, 'pre_gen_project.py')\n        tests_dir = os.path.join(self.repo_path, 'input{{hooks}}')\n\n        with Path(hook_path).open('w') as f:\n            f.write(\"#!/usr/bin/env python\\n\")\n            f.write(\"import sys; sys.exit(1)\\n\")\n\n        with utils.work_in(self.repo_path):\n            with pytest.raises(exceptions.FailedHookException) as excinfo:\n&gt;               hooks.run_hook('pre_gen_project', tests_dir, {})\n\ntests/test_hooks.py:231: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/hooks.py:108: in run_hook\n    run_script_with_context(hook_path, project_dir, context)\ncookiecutter/hooks.py:91: in run_script_with_context\n    run_script(temp_script_path, cwd)\ncookiecutter/hooks.py:65: in run_script\n    subprocess.check_call([script_path], cwd=cwd)\n/usr/lib/python3.10/subprocess.py:364: in check_call\n    retcode = call(*popenargs, **kwargs)\n/usr/lib/python3.10/subprocess.py:345: in call\n    with Popen(*popenargs, **kwargs) as p:\n/usr/lib/python3.10/subprocess.py:971: in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nargs = ['/tmp/tmp9siuaokd'], executable = b'/tmp/tmp9siuaokd', preexec_fn = None\nclose_fds = True, pass_fds = ()\ncwd = '/testbed/tests/test-hooks/input{{hooks}}', env = None, startupinfo = None\ncreationflags = 0, shell = False, p2cread = -1, p2cwrite = -1, c2pread = -1\nc2pwrite = -1, errread = -1, errwrite = -1, restore_signals = True, gid = None\ngids = None, uid = None, umask = -1, start_new_session = False\n\n    def _execute_child(self, args, executable, preexec_fn, close_fds,\n                       pass_fds, cwd, env,\n                       startupinfo, creationflags, shell,\n                       p2cread, p2cwrite,\n                       c2pread, c2pwrite,\n                       errread, errwrite,\n                       restore_signals,\n                       gid, gids, uid, umask,\n                       start_new_session):\n        \"\"\"Execute program (POSIX version)\"\"\"\n\n        if isinstance(args, (str, bytes)):\n            args = [args]\n        elif isinstance(args, os.PathLike):\n            if shell:\n                raise TypeError('path-like args is not allowed when '\n                                'shell is true')\n            args = [args]\n        else:\n            args = list(args)\n\n        if shell:\n            # On Android the default shell is at '/system/bin/sh'.\n            unix_shell = ('/system/bin/sh' if\n                      hasattr(sys, 'getandroidapilevel') else '/bin/sh')\n            args = [unix_shell, \"-c\"] + args\n            if executable:\n                args[0] = executable\n\n        if executable is None:\n            executable = args[0]\n\n        sys.audit(\"subprocess.Popen\", executable, args, cwd, env)\n\n        if (_USE_POSIX_SPAWN\n                and os.path.dirname(executable)\n                and preexec_fn is None\n                and not close_fds\n                and not pass_fds\n                and cwd is None\n                and (p2cread == -1 or p2cread &gt; 2)\n                and (c2pwrite == -1 or c2pwrite &gt; 2)\n                and (errwrite == -1 or errwrite &gt; 2)\n                and not start_new_session\n                and gid is None\n                and gids is None\n                and uid is None\n                and umask &lt; 0):\n            self._posix_spawn(args, executable, env, restore_signals,\n                              p2cread, p2cwrite,\n                              c2pread, c2pwrite,\n                              errread, errwrite)\n            return\n\n        orig_executable = executable\n\n        # For transferring possible exec failure from child to parent.\n        # Data format: \"exception name:hex errno:description\"\n        # Pickle is not used; it is complex and involves memory allocation.\n        errpipe_read, errpipe_write = os.pipe()\n        # errpipe_write must not be in the standard io 0, 1, or 2 fd range.\n        low_fds_to_close = []\n        while errpipe_write &lt; 3:\n            low_fds_to_close.append(errpipe_write)\n            errpipe_write = os.dup(errpipe_write)\n        for low_fd in low_fds_to_close:\n            os.close(low_fd)\n        try:\n            try:\n                # We must avoid complex work that could involve\n                # malloc or free in the child process to avoid\n                # potential deadlocks, thus we do all this here.\n                # and pass it to fork_exec()\n\n                if env is not None:\n                    env_list = []\n                    for k, v in env.items():\n                        k = os.fsencode(k)\n                        if b'=' in k:\n                            raise ValueError(\"illegal environment variable name\")\n                        env_list.append(k + b'=' + os.fsencode(v))\n                else:\n                    env_list = None  # Use execv instead of execve.\n                executable = os.fsencode(executable)\n                if os.path.dirname(executable):\n                    executable_list = (executable,)\n                else:\n                    # This matches the behavior of os._execvpe().\n                    executable_list = tuple(\n                        os.path.join(os.fsencode(dir), executable)\n                        for dir in os.get_exec_path(env))\n                fds_to_keep = set(pass_fds)\n                fds_to_keep.add(errpipe_write)\n                self.pid = _posixsubprocess.fork_exec(\n                        args, executable_list,\n                        close_fds, tuple(sorted(map(int, fds_to_keep))),\n                        cwd, env_list,\n                        p2cread, p2cwrite, c2pread, c2pwrite,\n                        errread, errwrite,\n                        errpipe_read, errpipe_write,\n                        restore_signals, start_new_session,\n                        gid, gids, uid, umask,\n                        preexec_fn)\n                self._child_created = True\n            finally:\n                # be sure the FD is closed no matter what\n                os.close(errpipe_write)\n\n            self._close_pipe_fds(p2cread, p2cwrite,\n                                 c2pread, c2pwrite,\n                                 errread, errwrite)\n\n            # Wait for exec to fail or succeed; possibly raising an\n            # exception (limited in size)\n            errpipe_data = bytearray()\n            while True:\n                part = os.read(errpipe_read, 50000)\n                errpipe_data += part\n                if not part or len(errpipe_data) &gt; 50000:\n                    break\n        finally:\n            # be sure the FD is closed no matter what\n            os.close(errpipe_read)\n\n        if errpipe_data:\n            try:\n                pid, sts = os.waitpid(self.pid, 0)\n                if pid == self.pid:\n                    self._handle_exitstatus(sts)\n                else:\n                    self.returncode = sys.maxsize\n            except ChildProcessError:\n                pass\n\n            try:\n                exception_name, hex_errno, err_msg = (\n                        errpipe_data.split(b':', 2))\n                # The encoding here should match the encoding\n                # written in by the subprocess implementations\n                # like _posixsubprocess\n                err_msg = err_msg.decode()\n            except ValueError:\n                exception_name = b'SubprocessError'\n                hex_errno = b'0'\n                err_msg = 'Bad exception data from child: {!r}'.format(\n                              bytes(errpipe_data))\n            child_exception_type = getattr(\n                    builtins, exception_name.decode('ascii'),\n                    SubprocessError)\n            if issubclass(child_exception_type, OSError) and hex_errno:\n                errno_num = int(hex_errno, 16)\n                child_exec_never_called = (err_msg == \"noexec\")\n                if child_exec_never_called:\n                    err_msg = \"\"\n                    # The error must be from chdir(cwd).\n                    err_filename = cwd\n                else:\n                    err_filename = orig_executable\n                if errno_num != 0:\n                    err_msg = os.strerror(errno_num)\n&gt;               raise child_exception_type(errno_num, err_msg, err_filename)\nE               PermissionError: [Errno 13] Permission denied: '/tmp/tmp9siuaokd'\n\n/usr/lib/python3.10/subprocess.py:1863: PermissionError"},{"location":"analysis_baseline_cookiecutter/#test_logpytest_info_stdout_logging","title":"test_log.py::test_info_stdout_logging","text":"<pre>test_log.py::test_info_stdout_logging</pre><pre>\ncaplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7f1eec7e34c0&gt;\ninfo_logger = None\ninfo_messages = ['INFO: Welcome to Cookiecutter', 'INFO: Loading user config from home dir', 'ERROR: Aw, snap! Something went wrong']\n\n    def test_info_stdout_logging(caplog, info_logger, info_messages):\n        \"\"\"Test that stdout logs use info format and level.\"\"\"\n&gt;       [stream_handler] = info_logger.handlers\nE       AttributeError: 'NoneType' object has no attribute 'handlers'\n\ntests/test_log.py:75: AttributeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_logpytest_debug_stdout_logging","title":"test_log.py::test_debug_stdout_logging","text":"<pre>test_log.py::test_debug_stdout_logging</pre><pre>\ncaplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7f1eed49d240&gt;\ndebug_logger = None\ndebug_messages = ['INFO cookiecutter: Welcome to Cookiecutter', 'DEBUG cookiecutter: Generating project from pytest-plugin', 'INFO cookiecutter.foo: Loading user config from home dir', \"DEBUG cookiecutter.foo.bar: I don't know.\", 'DEBUG cookiecutter.foo.bar: I wanted to save the world.', 'ERROR cookiecutter.foo: Aw, snap! Something went wrong', ...]\n\n    def test_debug_stdout_logging(caplog, debug_logger, debug_messages):\n        \"\"\"Test that stdout logs use debug format and level.\"\"\"\n&gt;       [stream_handler] = debug_logger.handlers\nE       AttributeError: 'NoneType' object has no attribute 'handlers'\n\ntests/test_log.py:92: AttributeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_logpytest_debug_file_logging","title":"test_log.py::test_debug_file_logging","text":"<pre>test_log.py::test_debug_file_logging</pre><pre>\ncaplog = &lt;_pytest.logging.LogCaptureFixture object at 0x7f1eec7e0520&gt;\ninfo_logger_with_file = None\ndebug_file = PosixPath('/tmp/pytest-of-root/pytest-0/test_debug_file_logging0/pytest-plugin.log')\ndebug_messages = ['INFO cookiecutter: Welcome to Cookiecutter', 'DEBUG cookiecutter: Generating project from pytest-plugin', 'INFO cookiecutter.foo: Loading user config from home dir', \"DEBUG cookiecutter.foo.bar: I don't know.\", 'DEBUG cookiecutter.foo.bar: I wanted to save the world.', 'ERROR cookiecutter.foo: Aw, snap! Something went wrong', ...]\n\n    def test_debug_file_logging(caplog, info_logger_with_file, debug_file, debug_messages):\n        \"\"\"Test that logging to stdout uses a different format and level than \\\n        the the file handler.\"\"\"\n&gt;       [file_handler, stream_handler] = info_logger_with_file.handlers\nE       AttributeError: 'NoneType' object has no attribute 'handlers'\n\ntests/test_log.py:110: AttributeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_mainpytest_original_cookiecutter_options_preserved_in__cookiecutter","title":"test_main.py::test_original_cookiecutter_options_preserved_in__cookiecutter","text":"<pre>test_main.py::test_original_cookiecutter_options_preserved_in__cookiecutter</pre><pre>\nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eec4e8fa0&gt;\nmocker = \nuser_config_file = '/tmp/pytest-of-root/pytest-0/user_dir0/config'\n\n    def test_original_cookiecutter_options_preserved_in__cookiecutter(\n        monkeypatch,\n        mocker,\n        user_config_file,\n    ):\n        \"\"\"Preserve original context options.\n\n        Tests you can access the original context options via\n        `context['_cookiecutter']`.\n        \"\"\"\n        monkeypatch.chdir('tests/fake-repo-tmpl-_cookiecutter')\n        mock_generate_files = mocker.patch('cookiecutter.main.generate_files')\n&gt;       cookiecutter(\n            '.',\n            no_input=True,\n            replay=False,\n            config_file=user_config_file,\n        )\n\n/testbed/tests/test_main.py:18: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = '.', checkout = None, no_input = True, extra_context = None\nreplay = False, overwrite_if_exists = False, output_dir = '.'\nconfig_file = '/tmp/pytest-of-root/pytest-0/user_dir0/config'\ndefault_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\n/testbed/cookiecutter/main.py:59: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_mainpytest_replay_dump_template_name","title":"test_main.py::test_replay_dump_template_name","text":"<pre>test_main.py::test_replay_dump_template_name</pre><pre>\nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eecd6cac0&gt;\nmocker = \nuser_config_data = {'cookiecutters_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters', 'replay_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutter_replay'}\nuser_config_file = '/tmp/pytest-of-root/pytest-0/user_dir0/config'\n\n    def test_replay_dump_template_name(\n        monkeypatch, mocker, user_config_data, user_config_file\n    ):\n        \"\"\"Check that replay_dump is called with a valid template_name.\n\n        Template name must not be a relative path.\n\n        Otherwise files such as ``..json`` are created, which are not just cryptic\n        but also later mistaken for replay files of other templates if invoked with\n        '.' and '--replay'.\n\n        Change the current working directory temporarily to 'tests/fake-repo-tmpl'\n        for this test and call cookiecutter with '.' for the target template.\n        \"\"\"\n        monkeypatch.chdir('tests/fake-repo-tmpl')\n\n        mock_replay_dump = mocker.patch('cookiecutter.main.dump')\n        mocker.patch('cookiecutter.main.generate_files')\n\n&gt;       cookiecutter(\n            '.',\n            no_input=True,\n            replay=False,\n            config_file=user_config_file,\n        )\n\n/testbed/tests/test_main.py:51: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = '.', checkout = None, no_input = True, extra_context = None\nreplay = False, overwrite_if_exists = False, output_dir = '.'\nconfig_file = '/tmp/pytest-of-root/pytest-0/user_dir0/config'\ndefault_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\n/testbed/cookiecutter/main.py:59: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_mainpytest_replay_load_template_name","title":"test_main.py::test_replay_load_template_name","text":"<pre>test_main.py::test_replay_load_template_name</pre><pre>\nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eed24f4f0&gt;\nmocker = \nuser_config_data = {'cookiecutters_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutters', 'replay_dir': '/tmp/pytest-of-root/pytest-0/user_dir0/cookiecutter_replay'}\nuser_config_file = '/tmp/pytest-of-root/pytest-0/user_dir0/config'\n\n    def test_replay_load_template_name(\n        monkeypatch, mocker, user_config_data, user_config_file\n    ):\n        \"\"\"Check that replay_load is called correctly.\n\n        Calls require valid template_name that is not a relative path.\n\n        Change the current working directory temporarily to 'tests/fake-repo-tmpl'\n        for this test and call cookiecutter with '.' for the target template.\n        \"\"\"\n        monkeypatch.chdir('tests/fake-repo-tmpl')\n\n        mock_replay_load = mocker.patch('cookiecutter.main.load')\n        mocker.patch('cookiecutter.main.generate_context').return_value = {\n            'cookiecutter': {}\n        }\n        mocker.patch('cookiecutter.main.generate_files')\n        mocker.patch('cookiecutter.main.dump')\n\n&gt;       cookiecutter(\n            '.',\n            replay=True,\n            config_file=user_config_file,\n        )\n\n/testbed/tests/test_main.py:84: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = '.', checkout = None, no_input = False, extra_context = None\nreplay = True, overwrite_if_exists = False, output_dir = '.'\nconfig_file = '/tmp/pytest-of-root/pytest-0/user_dir0/config'\ndefault_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\n/testbed/cookiecutter/main.py:59: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_mainpytest_custom_replay_file","title":"test_main.py::test_custom_replay_file","text":"<pre>test_main.py::test_custom_replay_file</pre><pre>\nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eecd16410&gt;\nmocker = \nuser_config_file = '/tmp/pytest-of-root/pytest-0/user_dir0/config'\n\n    def test_custom_replay_file(monkeypatch, mocker, user_config_file):\n        \"\"\"Check that reply.load is called with the custom replay_file.\"\"\"\n        monkeypatch.chdir('tests/fake-repo-tmpl')\n\n        mock_replay_load = mocker.patch('cookiecutter.main.load')\n        mocker.patch('cookiecutter.main.generate_context').return_value = {\n            'cookiecutter': {}\n        }\n        mocker.patch('cookiecutter.main.generate_files')\n        mocker.patch('cookiecutter.main.dump')\n\n&gt;       cookiecutter(\n            '.',\n            replay='./custom-replay-file',\n            config_file=user_config_file,\n        )\n\n/testbed/tests/test_main.py:107: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = '.', checkout = None, no_input = False, extra_context = None\nreplay = './custom-replay-file', overwrite_if_exists = False, output_dir = '.'\nconfig_file = '/tmp/pytest-of-root/pytest-0/user_dir0/config'\ndefault_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\n/testbed/cookiecutter/main.py:59: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_output_folderpytest_output_folder","title":"test_output_folder.py::test_output_folder","text":"<pre>test_output_folder.py::test_output_folder</pre><pre>\n@pytest.mark.usefixtures('clean_system', 'remove_output_folder')\n    def test_output_folder():\n        \"\"\"Tests should correctly create content, as output_folder does not yet exist.\"\"\"\n        context = generate.generate_context(\n            context_file='tests/test-output-folder/cookiecutter.json'\n        )\n&gt;       generate.generate_files(context=context, repo_dir='tests/test-output-folder')\n\ntests/test_output_folder.py:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-output-folder'\ncontext = OrderedDict([('full_name', 'Audrey Greenfeld'), ('year', '2014'), ('color', 'green'), ('letter', 'D'), ('folder_name', 'im_a.dir'), ('filename', 'im_a.file'), ('test_name', 'output_folder')])\noutput_dir = '.', overwrite_if_exists = False, skip_if_file_exists = False\naccept_hooks = True, keep_project_on_failure = False\n\n    def generate_files(repo_dir, context=None, output_dir='.',\n        overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n        keep_project_on_failure=False):\n        \"\"\"Render the templates and saves them to files.\n\n        :param repo_dir: Project template input directory.\n        :param context: Dict for populating the template's variables.\n        :param output_dir: Where to output the generated project dir into.\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n&gt;       template_dir = find_template(repo_dir)\nE       TypeError: find_template() missing 1 required positional argument: 'env'\n\ncookiecutter/generate.py:225: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_output_folderpytest_exception_when_output_folder_exists","title":"test_output_folder.py::test_exception_when_output_folder_exists","text":"<pre>test_output_folder.py::test_exception_when_output_folder_exists</pre><pre>\n@pytest.mark.usefixtures('clean_system', 'remove_output_folder')\n    def test_exception_when_output_folder_exists():\n        \"\"\"Tests should raise error as output folder created before `generate_files`.\"\"\"\n        context = generate.generate_context(\n            context_file='tests/test-output-folder/cookiecutter.json'\n        )\n&gt;       output_folder = context['cookiecutter']['test_name']\nE       KeyError: 'cookiecutter'\n\ntests/test_output_folder.py:53: KeyError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_pre_prompt_hookspytest_run_pre_prompt_python_hook","title":"test_pre_prompt_hooks.py::test_run_pre_prompt_python_hook","text":"<pre>test_pre_prompt_hooks.py::test_run_pre_prompt_python_hook</pre><pre>\nremove_tmp_repo_dir = ._func at 0x7f1eec475990&gt;\n\n    def test_run_pre_prompt_python_hook(remove_tmp_repo_dir):\n        \"\"\"Verify pre_prompt.py runs and creates a copy of cookiecutter.json.\"\"\"\n&gt;       new_repo_dir = hooks.run_pre_prompt_hook(repo_dir='tests/test-pyhooks/')\n\ntests/test_pre_prompt_hooks.py:27: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-pyhooks/'\n\n    def run_pre_prompt_hook(repo_dir: 'os.PathLike[str]') -&gt;Path:\n        \"\"\"Run pre_prompt hook from repo directory.\n\n        :param repo_dir: Project template input directory.\n        \"\"\"\n        with work_in(repo_dir):\n            hook_path = find_hook('pre_prompt')\n            if hook_path:\n                logger.debug(\"Running pre_prompt hook\")\n&gt;               tmp_repo_dir = create_tmp_repo_dir()\nE               TypeError: create_tmp_repo_dir() missing 1 required positional argument: 'repo_dir'\n\ncookiecutter/hooks.py:157: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_pre_prompt_hookspytest_run_pre_prompt_python_hook_fail","title":"test_pre_prompt_hooks.py::test_run_pre_prompt_python_hook_fail","text":"<pre>test_pre_prompt_hooks.py::test_run_pre_prompt_python_hook_fail</pre><pre>\nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eec291750&gt;\n\n    def test_run_pre_prompt_python_hook_fail(monkeypatch):\n        \"\"\"Verify pre_prompt.py will fail when a given env var is present.\"\"\"\n        message = 'Pre-Prompt Hook script failed'\n        with monkeypatch.context() as m:\n            m.setenv('COOKIECUTTER_FAIL_PRE_PROMPT', '1')\n            with pytest.raises(FailedHookException) as excinfo:\n&gt;               hooks.run_pre_prompt_hook(repo_dir='tests/test-pyhooks/')\n\ntests/test_pre_prompt_hooks.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-pyhooks/'\n\n    def run_pre_prompt_hook(repo_dir: 'os.PathLike[str]') -&gt;Path:\n        \"\"\"Run pre_prompt hook from repo directory.\n\n        :param repo_dir: Project template input directory.\n        \"\"\"\n        with work_in(repo_dir):\n            hook_path = find_hook('pre_prompt')\n            if hook_path:\n                logger.debug(\"Running pre_prompt hook\")\n&gt;               tmp_repo_dir = create_tmp_repo_dir()\nE               TypeError: create_tmp_repo_dir() missing 1 required positional argument: 'repo_dir'\n\ncookiecutter/hooks.py:157: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_pre_prompt_hookspytest_run_pre_prompt_shell_hook","title":"test_pre_prompt_hooks.py::test_run_pre_prompt_shell_hook","text":"<pre>test_pre_prompt_hooks.py::test_run_pre_prompt_shell_hook</pre><pre>\nremove_tmp_repo_dir = ._func at 0x7f1eec477760&gt;\n\n    @pytest.mark.skipif(WINDOWS, reason='shell script will not run in Windows')\n    def test_run_pre_prompt_shell_hook(remove_tmp_repo_dir):\n        \"\"\"Verify pre_prompt.sh runs and creates a copy of cookiecutter.json.\"\"\"\n&gt;       new_repo_dir = hooks.run_pre_prompt_hook(repo_dir='tests/test-pyshellhooks/')\n\ntests/test_pre_prompt_hooks.py:47: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_dir = 'tests/test-pyshellhooks/'\n\n    def run_pre_prompt_hook(repo_dir: 'os.PathLike[str]') -&gt;Path:\n        \"\"\"Run pre_prompt hook from repo directory.\n\n        :param repo_dir: Project template input directory.\n        \"\"\"\n        with work_in(repo_dir):\n            hook_path = find_hook('pre_prompt')\n            if hook_path:\n                logger.debug(\"Running pre_prompt hook\")\n&gt;               tmp_repo_dir = create_tmp_repo_dir()\nE               TypeError: create_tmp_repo_dir() missing 1 required positional argument: 'repo_dir'\n\ncookiecutter/hooks.py:157: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestrendervariabletest_convert_to_str1-1","title":"test_prompt.py::TestRenderVariable::test_convert_to_str[1-1]","text":"<pre>test_prompt.py::TestRenderVariable::test_convert_to_str[1-1]</pre><pre>\nself = \nmocker = \nraw_var = 1, rendered_var = '1'\n\n    @pytest.mark.parametrize(\n        'raw_var, rendered_var',\n        [\n            (1, '1'),\n            (True, True),\n            ('foo', 'foo'),\n            ('{{cookiecutter.project}}', 'foobar'),\n            (None, None),\n        ],\n    )\n    def test_convert_to_str(self, mocker, raw_var, rendered_var):\n        \"\"\"Verify simple items correctly rendered to strings.\"\"\"\n        env = environment.StrictEnvironment()\n        from_string = mocker.patch(\n            'cookiecutter.utils.StrictEnvironment.from_string', wraps=env.from_string\n        )\n        context = {'project': 'foobar'}\n\n        result = prompt.render_variable(env, raw_var, context)\n&gt;       assert result == rendered_var\nE       AssertionError: assert 1 == '1'\n\ntests/test_prompt.py:44: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestrendervariabletest_convert_to_strcookiecutterproject-foobar","title":"test_prompt.py::TestRenderVariable::test_convert_to_str[{{cookiecutter.project}}-foobar]","text":"<pre>test_prompt.py::TestRenderVariable::test_convert_to_str[{{cookiecutter.project}}-foobar]</pre><pre>\nenv = \nraw = '{{cookiecutter.project}}', cookiecutter_dict = {'project': 'foobar'}\n\n    def render_variable(env, raw, cookiecutter_dict):\n        \"\"\"Render the next variable to be displayed in the user prompt.\n\n        Inside the prompting taken from the cookiecutter.json file, this renders\n        the next variable. For example, if a project_name is \"Peanut Butter\n        Cookie\", the repo_name could be be rendered with:\n\n            `{{ cookiecutter.project_name.replace(\" \", \"_\") }}`.\n\n        This is then presented to the user as the default.\n\n        :param Environment env: A Jinja2 Environment object.\n        :param raw: The next value to be prompted for by the user.\n        :param dict cookiecutter_dict: The current context as it's gradually\n            being populated with variables.\n        :return: The rendered value for the default variable.\n        \"\"\"\n        if not isinstance(raw, str):\n            return raw\n\n        template = env.from_string(raw)\n        try:\n&gt;           return template.render(**cookiecutter_dict)\n\ncookiecutter/prompt.py:160: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/jinja2/environment.py:1304: in render\n    self.environment.handle_exception()\n.venv/lib/python3.10/site-packages/jinja2/environment.py:939: in handle_exception\n    raise rewrite_traceback_stack(source=source)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nobj = Undefined, attribute = 'project'\n\n    def getattr(self, obj: t.Any, attribute: str) -&gt; t.Any:\n        \"\"\"Get an item or attribute of an object but prefer the attribute.\n        Unlike :meth:`getitem` the attribute *must* be a string.\n        \"\"\"\n        try:\n&gt;           return getattr(obj, attribute)\nE           jinja2.exceptions.UndefinedError: 'cookiecutter' is undefined\n\n.venv/lib/python3.10/site-packages/jinja2/environment.py:487: UndefinedError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nmocker = \nraw_var = '{{cookiecutter.project}}', rendered_var = 'foobar'\n\n    @pytest.mark.parametrize(\n        'raw_var, rendered_var',\n        [\n            (1, '1'),\n            (True, True),\n            ('foo', 'foo'),\n            ('{{cookiecutter.project}}', 'foobar'),\n            (None, None),\n        ],\n    )\n    def test_convert_to_str(self, mocker, raw_var, rendered_var):\n        \"\"\"Verify simple items correctly rendered to strings.\"\"\"\n        env = environment.StrictEnvironment()\n        from_string = mocker.patch(\n            'cookiecutter.utils.StrictEnvironment.from_string', wraps=env.from_string\n        )\n        context = {'project': 'foobar'}\n\n&gt;       result = prompt.render_variable(env, raw_var, context)\n\ntests/test_prompt.py:43: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nenv = \nraw = '{{cookiecutter.project}}', cookiecutter_dict = {'project': 'foobar'}\n\n    def render_variable(env, raw, cookiecutter_dict):\n        \"\"\"Render the next variable to be displayed in the user prompt.\n\n        Inside the prompting taken from the cookiecutter.json file, this renders\n        the next variable. For example, if a project_name is \"Peanut Butter\n        Cookie\", the repo_name could be be rendered with:\n\n            `{{ cookiecutter.project_name.replace(\" \", \"_\") }}`.\n\n        This is then presented to the user as the default.\n\n        :param Environment env: A Jinja2 Environment object.\n        :param raw: The next value to be prompted for by the user.\n        :param dict cookiecutter_dict: The current context as it's gradually\n            being populated with variables.\n        :return: The rendered value for the default variable.\n        \"\"\"\n        if not isinstance(raw, str):\n            return raw\n\n        template = env.from_string(raw)\n        try:\n            return template.render(**cookiecutter_dict)\n        except UndefinedError as err:\n&gt;           raise UndefinedVariableInTemplate(str(err), err, cookiecutter_dict)\nE           cookiecutter.exceptions.UndefinedVariableInTemplate: 'cookiecutter' is undefined. Error message: 'cookiecutter' is undefined. Context: {'project': 'foobar'}\n\ncookiecutter/prompt.py:162: UndefinedVariableInTemplate"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestrendervariabletest_convert_to_str_complex_variablesraw_var0-rendered_var0","title":"test_prompt.py::TestRenderVariable::test_convert_to_str_complex_variables[raw_var0-rendered_var0]","text":"<pre>test_prompt.py::TestRenderVariable::test_convert_to_str_complex_variables[raw_var0-rendered_var0]</pre><pre>\nself = \nraw_var = {1: True, 'foo': False}, rendered_var = {'1': True, 'foo': False}\n\n    @pytest.mark.parametrize(\n        'raw_var, rendered_var',\n        [\n            ({1: True, 'foo': False}, {'1': True, 'foo': False}),\n            (\n                {'{{cookiecutter.project}}': ['foo', 1], 'bar': False},\n                {'foobar': ['foo', '1'], 'bar': False},\n            ),\n            (['foo', '{{cookiecutter.project}}', None], ['foo', 'foobar', None]),\n        ],\n    )\n    def test_convert_to_str_complex_variables(self, raw_var, rendered_var):\n        \"\"\"Verify tree items correctly rendered.\"\"\"\n        env = environment.StrictEnvironment()\n        context = {'project': 'foobar'}\n\n        result = prompt.render_variable(env, raw_var, context)\n&gt;       assert result == rendered_var\nE       AssertionError: assert {1: True, 'foo': False} == {'1': True, 'foo': False}\nE         \nE         Common items:\nE         {'foo': False}\nE         Left contains 1 more item:\nE         {1: True}\nE         Right contains 1 more item:\nE         {'1': True}\nE         \nE         Full diff:\nE           {\nE         -     '1': True,\nE         ?     - -\nE         +     1: True,\nE               'foo': False,\nE           }\n\ntests/test_prompt.py:71: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestrendervariabletest_convert_to_str_complex_variablesraw_var1-rendered_var1","title":"test_prompt.py::TestRenderVariable::test_convert_to_str_complex_variables[raw_var1-rendered_var1]","text":"<pre>test_prompt.py::TestRenderVariable::test_convert_to_str_complex_variables[raw_var1-rendered_var1]</pre><pre>\nself = \nraw_var = {'bar': False, '{{cookiecutter.project}}': ['foo', 1]}\nrendered_var = {'bar': False, 'foobar': ['foo', '1']}\n\n    @pytest.mark.parametrize(\n        'raw_var, rendered_var',\n        [\n            ({1: True, 'foo': False}, {'1': True, 'foo': False}),\n            (\n                {'{{cookiecutter.project}}': ['foo', 1], 'bar': False},\n                {'foobar': ['foo', '1'], 'bar': False},\n            ),\n            (['foo', '{{cookiecutter.project}}', None], ['foo', 'foobar', None]),\n        ],\n    )\n    def test_convert_to_str_complex_variables(self, raw_var, rendered_var):\n        \"\"\"Verify tree items correctly rendered.\"\"\"\n        env = environment.StrictEnvironment()\n        context = {'project': 'foobar'}\n\n        result = prompt.render_variable(env, raw_var, context)\n&gt;       assert result == rendered_var\nE       AssertionError: assert {'{{cookiecutter.project}}': ['foo', 1], 'bar': False} == {'foobar': ['foo', '1'], 'bar': False}\nE         \nE         Common items:\nE         {'bar': False}\nE         Left contains 1 more item:\nE         {'{{cookiecutter.project}}': ['foo', 1]}\nE         Right contains 1 more item:\nE         {'foobar': ['foo', '1']}\nE         \nE         Full diff:\nE           {\nE               'bar': False,\nE         -     'foobar': [\nE         +     '{{cookiecutter.project}}': [\nE                   'foo',\nE         -         '1',\nE         ?         - -\nE         +         1,\nE               ],\nE           }\n\ntests/test_prompt.py:71: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestrendervariabletest_convert_to_str_complex_variablesraw_var2-rendered_var2","title":"test_prompt.py::TestRenderVariable::test_convert_to_str_complex_variables[raw_var2-rendered_var2]","text":"<pre>test_prompt.py::TestRenderVariable::test_convert_to_str_complex_variables[raw_var2-rendered_var2]</pre><pre>\nself = \nraw_var = ['foo', '{{cookiecutter.project}}', None]\nrendered_var = ['foo', 'foobar', None]\n\n    @pytest.mark.parametrize(\n        'raw_var, rendered_var',\n        [\n            ({1: True, 'foo': False}, {'1': True, 'foo': False}),\n            (\n                {'{{cookiecutter.project}}': ['foo', 1], 'bar': False},\n                {'foobar': ['foo', '1'], 'bar': False},\n            ),\n            (['foo', '{{cookiecutter.project}}', None], ['foo', 'foobar', None]),\n        ],\n    )\n    def test_convert_to_str_complex_variables(self, raw_var, rendered_var):\n        \"\"\"Verify tree items correctly rendered.\"\"\"\n        env = environment.StrictEnvironment()\n        context = {'project': 'foobar'}\n\n        result = prompt.render_variable(env, raw_var, context)\n&gt;       assert result == rendered_var\nE       AssertionError: assert ['foo', '{{cookiecutter.project}}', None] == ['foo', 'foobar', None]\nE         \nE         At index 1 diff: '{{cookiecutter.project}}' != 'foobar'\nE         \nE         Full diff:\nE           [\nE               'foo',\nE         -     'foobar',\nE         +     '{{cookiecutter.project}}',\nE               None,\nE           ]\n\ntests/test_prompt.py:71: AssertionError"},{"location":"analysis_baseline_cookiecutter/#input","title":"input]","text":"<pre>input]</pre><pre>\nself = \nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eec7be860&gt;\ncontext = {'cookiecutter': {'full_name': 'Your Name'}}\n\n    @pytest.mark.parametrize(\n        'context',\n        [\n            {'cookiecutter': {'full_name': 'Your Name'}},\n            {'cookiecutter': {'full_name': '\u0158ekni \u010di napi\u0161 sv\u00e9 jm\u00e9no'}},\n        ],\n        ids=['ASCII default prompt/input', 'Unicode default prompt/input'],\n    )\n    def test_prompt_for_config(self, monkeypatch, context):\n        \"\"\"Verify `prompt_for_config` call `read_user_variable` on text request.\"\"\"\n        monkeypatch.setattr(\n            'cookiecutter.prompt.read_user_variable',\n            lambda var, default, prompts, prefix: default,\n        )\n\n&gt;       cookiecutter_dict = prompt.prompt_for_config(context)\n\ntests/test_prompt.py:92: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncontext = {'cookiecutter': {'full_name': 'Your Name'}}, no_input = False\n\n    def prompt_for_config(context, no_input=False):\n        \"\"\"Prompt user to enter a new config.\n\n        :param dict context: Source for field names and sample values.\n        :param no_input: Do not prompt for user input and use only values from context.\n        \"\"\"\n        cookiecutter_dict = OrderedDict([])\n        env = create_env_with_context(context)\n\n        for key, raw in context['cookiecutter'].items():\n            if key.startswith('_'):\n                cookiecutter_dict[key] = raw\n                continue\n\n            if isinstance(raw, dict):\n                cookiecutter_dict[key] = prompt_choice_for_config(\n                    cookiecutter_dict, env, key, raw, no_input\n                )\n            else:\n                if no_input:\n                    cookiecutter_dict[key] = render_variable(env, raw, cookiecutter_dict)\n                else:\n&gt;                   cookiecutter_dict[key] = read_user_variable(key, raw)\nE                   TypeError: TestPrompt.test_prompt_for_config..() missing 2 required positional arguments: 'prompts' and 'prefix'\n\ncookiecutter/prompt.py:228: TypeError"},{"location":"analysis_baseline_cookiecutter/#input_1","title":"input]","text":"<pre>input]</pre><pre>\nself = \nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eed19c580&gt;\ncontext = {'cookiecutter': {'full_name': '\u0158ekni \u010di napi\u0161 sv\u00e9 jm\u00e9no'}}\n\n    @pytest.mark.parametrize(\n        'context',\n        [\n            {'cookiecutter': {'full_name': 'Your Name'}},\n            {'cookiecutter': {'full_name': '\u0158ekni \u010di napi\u0161 sv\u00e9 jm\u00e9no'}},\n        ],\n        ids=['ASCII default prompt/input', 'Unicode default prompt/input'],\n    )\n    def test_prompt_for_config(self, monkeypatch, context):\n        \"\"\"Verify `prompt_for_config` call `read_user_variable` on text request.\"\"\"\n        monkeypatch.setattr(\n            'cookiecutter.prompt.read_user_variable',\n            lambda var, default, prompts, prefix: default,\n        )\n\n&gt;       cookiecutter_dict = prompt.prompt_for_config(context)\n\ntests/test_prompt.py:92: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncontext = {'cookiecutter': {'full_name': '\u0158ekni \u010di napi\u0161 sv\u00e9 jm\u00e9no'}}\nno_input = False\n\n    def prompt_for_config(context, no_input=False):\n        \"\"\"Prompt user to enter a new config.\n\n        :param dict context: Source for field names and sample values.\n        :param no_input: Do not prompt for user input and use only values from context.\n        \"\"\"\n        cookiecutter_dict = OrderedDict([])\n        env = create_env_with_context(context)\n\n        for key, raw in context['cookiecutter'].items():\n            if key.startswith('_'):\n                cookiecutter_dict[key] = raw\n                continue\n\n            if isinstance(raw, dict):\n                cookiecutter_dict[key] = prompt_choice_for_config(\n                    cookiecutter_dict, env, key, raw, no_input\n                )\n            else:\n                if no_input:\n                    cookiecutter_dict[key] = render_variable(env, raw, cookiecutter_dict)\n                else:\n&gt;                   cookiecutter_dict[key] = read_user_variable(key, raw)\nE                   TypeError: TestPrompt.test_prompt_for_config..() missing 2 required positional arguments: 'prompts' and 'prefix'\n\ncookiecutter/prompt.py:228: TypeError"},{"location":"analysis_baseline_cookiecutter/#input_2","title":"input]","text":"<pre>input]</pre><pre>\nself = \nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eec788b80&gt;\ncontext = {'cookiecutter': {'__prompts__': {'check': 'Checking', 'full_name': 'Name please'}, 'check': ['yes', 'no'], 'full_name': 'Your Name', 'nothing': 'ok'}}\n\n    @pytest.mark.parametrize(\n        'context',\n        [\n            {\n                'cookiecutter': {\n                    'full_name': 'Your Name',\n                    'check': ['yes', 'no'],\n                    'nothing': 'ok',\n                    '__prompts__': {\n                        'full_name': 'Name please',\n                        'check': 'Checking',\n                    },\n                }\n            },\n        ],\n        ids=['ASCII default prompt/input'],\n    )\n    def test_prompt_for_config_with_human_prompts(self, monkeypatch, context):\n        \"\"\"Verify call `read_user_variable` on request when human-readable prompts.\"\"\"\n        monkeypatch.setattr(\n            'cookiecutter.prompt.read_user_variable',\n            lambda var, default, prompts, prefix: default,\n        )\n        monkeypatch.setattr(\n            'cookiecutter.prompt.read_user_yes_no',\n            lambda var, default, prompts, prefix: default,\n        )\n        monkeypatch.setattr(\n            'cookiecutter.prompt.read_user_choice',\n            lambda var, default, prompts, prefix: default,\n        )\n\n&gt;       cookiecutter_dict = prompt.prompt_for_config(context)\n\ntests/test_prompt.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncontext = {'cookiecutter': {'__prompts__': {'check': 'Checking', 'full_name': 'Name please'}, 'check': ['yes', 'no'], 'full_name': 'Your Name', 'nothing': 'ok'}}\nno_input = False\n\n    def prompt_for_config(context, no_input=False):\n        \"\"\"Prompt user to enter a new config.\n\n        :param dict context: Source for field names and sample values.\n        :param no_input: Do not prompt for user input and use only values from context.\n        \"\"\"\n        cookiecutter_dict = OrderedDict([])\n        env = create_env_with_context(context)\n\n        for key, raw in context['cookiecutter'].items():\n            if key.startswith('_'):\n                cookiecutter_dict[key] = raw\n                continue\n\n            if isinstance(raw, dict):\n                cookiecutter_dict[key] = prompt_choice_for_config(\n                    cookiecutter_dict, env, key, raw, no_input\n                )\n            else:\n                if no_input:\n                    cookiecutter_dict[key] = render_variable(env, raw, cookiecutter_dict)\n                else:\n&gt;                   cookiecutter_dict[key] = read_user_variable(key, raw)\nE                   TypeError: TestPrompt.test_prompt_for_config_with_human_prompts..() missing 2 required positional arguments: 'prompts' and 'prefix'\n\ncookiecutter/prompt.py:228: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestprompttest_prompt_for_config_with_human_choicescontext0","title":"test_prompt.py::TestPrompt::test_prompt_for_config_with_human_choices[context0]","text":"<pre>test_prompt.py::TestPrompt::test_prompt_for_config_with_human_choices[context0]</pre><pre>\nself = \nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eec293370&gt;\ncontext = {'cookiecutter': {'__prompts__': {'check': 'Checking'}, 'check': ['yes', 'no'], 'full_name': 'Your Name'}}\n\n    @pytest.mark.parametrize(\n        'context',\n        [\n            {\n                'cookiecutter': {\n                    'full_name': 'Your Name',\n                    'check': ['yes', 'no'],\n                    '__prompts__': {\n                        'check': 'Checking',\n                    },\n                }\n            },\n            {\n                'cookiecutter': {\n                    'full_name': 'Your Name',\n                    'check': ['yes', 'no'],\n                    '__prompts__': {\n                        'full_name': 'Name please',\n                        'check': {'__prompt__': 'Checking', 'yes': 'Yes', 'no': 'No'},\n                    },\n                }\n            },\n            {\n                'cookiecutter': {\n                    'full_name': 'Your Name',\n                    'check': ['yes', 'no'],\n                    '__prompts__': {\n                        'full_name': 'Name please',\n                        'check': {'no': 'No'},\n                    },\n                }\n            },\n        ],\n    )\n    def test_prompt_for_config_with_human_choices(self, monkeypatch, context):\n        \"\"\"Test prompts when human-readable labels for user choices.\"\"\"\n        runner = click.testing.CliRunner()\n        with runner.isolation(input=\"\\n\\n\\n\"):\n            cookiecutter_dict = prompt.prompt_for_config(context)\n\n&gt;       assert dict(cookiecutter_dict) == {'full_name': 'Your Name', 'check': 'yes'}\nE       AssertionError: assert {'full_name': 'Your Name', 'check': ['yes', 'no'], '__prompts__': {'check': 'Checking'}} == {'full_name': 'Your Name', 'check': 'yes'}\nE         \nE         Common items:\nE         {'full_name': 'Your Name'}\nE         Differing items:\nE         {'check': ['yes', 'no']} != {'check': 'yes'}\nE         Left contains 1 more item:\nE         {'__prompts__': {'check': 'Checking'}}\nE         \nE         Full diff:\nE           {\nE         +     '__prompts__': {\nE         +         'check': 'Checking',\nE         +     },\nE         -     'check': 'yes',\nE         ?              ^^^^^^\nE         +     'check': [\nE         ?              ^\nE         +         'yes',\nE         +         'no',\nE         +     ],\nE               'full_name': 'Your Name',\nE           }\n\ntests/test_prompt.py:170: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestprompttest_prompt_for_config_with_human_choicescontext1","title":"test_prompt.py::TestPrompt::test_prompt_for_config_with_human_choices[context1]","text":"<pre>test_prompt.py::TestPrompt::test_prompt_for_config_with_human_choices[context1]</pre><pre>\nself = \nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eece45b10&gt;\ncontext = {'cookiecutter': {'__prompts__': {'check': {'__prompt__': 'Checking', 'no': 'No', 'yes': 'Yes'}, 'full_name': 'Name please'}, 'check': ['yes', 'no'], 'full_name': 'Your Name'}}\n\n    @pytest.mark.parametrize(\n        'context',\n        [\n            {\n                'cookiecutter': {\n                    'full_name': 'Your Name',\n                    'check': ['yes', 'no'],\n                    '__prompts__': {\n                        'check': 'Checking',\n                    },\n                }\n            },\n            {\n                'cookiecutter': {\n                    'full_name': 'Your Name',\n                    'check': ['yes', 'no'],\n                    '__prompts__': {\n                        'full_name': 'Name please',\n                        'check': {'__prompt__': 'Checking', 'yes': 'Yes', 'no': 'No'},\n                    },\n                }\n            },\n            {\n                'cookiecutter': {\n                    'full_name': 'Your Name',\n                    'check': ['yes', 'no'],\n                    '__prompts__': {\n                        'full_name': 'Name please',\n                        'check': {'no': 'No'},\n                    },\n                }\n            },\n        ],\n    )\n    def test_prompt_for_config_with_human_choices(self, monkeypatch, context):\n        \"\"\"Test prompts when human-readable labels for user choices.\"\"\"\n        runner = click.testing.CliRunner()\n        with runner.isolation(input=\"\\n\\n\\n\"):\n            cookiecutter_dict = prompt.prompt_for_config(context)\n\n&gt;       assert dict(cookiecutter_dict) == {'full_name': 'Your Name', 'check': 'yes'}\nE       AssertionError: assert {'full_name': 'Your Name', 'check': ['yes', 'no'], '__prompts__': {'full_name': 'Name please', 'check': {'__prompt__': 'Checking', 'yes': 'Yes', 'no': 'No'}}} == {'full_name': 'Your Name', 'check': 'yes'}\nE         \nE         Common items:\nE         {'full_name': 'Your Name'}\nE         Differing items:\nE         {'check': ['yes', 'no']} != {'check': 'yes'}\nE         Left contains 1 more item:\nE         {'__prompts__': {'check': {'__prompt__': 'Checking', 'no': 'No', 'yes': 'Yes'},\nE                          'full_name': 'Name please'}}\nE         \nE         Full diff:\nE           {\nE         +     '__prompts__': {\nE         +         'check': {\nE         +             '__prompt__': 'Checking',\nE         +             'no': 'No',\nE         +             'yes': 'Yes',\nE         +         },\nE         +         'full_name': 'Name please',\nE         +     },\nE         -     'check': 'yes',\nE         ?              ^^^^^^\nE         +     'check': [\nE         ?              ^\nE         +         'yes',\nE         +         'no',\nE         +     ],\nE               'full_name': 'Your Name',\nE           }\n\ntests/test_prompt.py:170: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestprompttest_prompt_for_config_with_human_choicescontext2","title":"test_prompt.py::TestPrompt::test_prompt_for_config_with_human_choices[context2]","text":"<pre>test_prompt.py::TestPrompt::test_prompt_for_config_with_human_choices[context2]</pre><pre>\nself = \nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eecf8d930&gt;\ncontext = {'cookiecutter': {'__prompts__': {'check': {'no': 'No'}, 'full_name': 'Name please'}, 'check': ['yes', 'no'], 'full_name': 'Your Name'}}\n\n    @pytest.mark.parametrize(\n        'context',\n        [\n            {\n                'cookiecutter': {\n                    'full_name': 'Your Name',\n                    'check': ['yes', 'no'],\n                    '__prompts__': {\n                        'check': 'Checking',\n                    },\n                }\n            },\n            {\n                'cookiecutter': {\n                    'full_name': 'Your Name',\n                    'check': ['yes', 'no'],\n                    '__prompts__': {\n                        'full_name': 'Name please',\n                        'check': {'__prompt__': 'Checking', 'yes': 'Yes', 'no': 'No'},\n                    },\n                }\n            },\n            {\n                'cookiecutter': {\n                    'full_name': 'Your Name',\n                    'check': ['yes', 'no'],\n                    '__prompts__': {\n                        'full_name': 'Name please',\n                        'check': {'no': 'No'},\n                    },\n                }\n            },\n        ],\n    )\n    def test_prompt_for_config_with_human_choices(self, monkeypatch, context):\n        \"\"\"Test prompts when human-readable labels for user choices.\"\"\"\n        runner = click.testing.CliRunner()\n        with runner.isolation(input=\"\\n\\n\\n\"):\n            cookiecutter_dict = prompt.prompt_for_config(context)\n\n&gt;       assert dict(cookiecutter_dict) == {'full_name': 'Your Name', 'check': 'yes'}\nE       AssertionError: assert {'full_name': 'Your Name', 'check': ['yes', 'no'], '__prompts__': {'full_name': 'Name please', 'check': {'no': 'No'}}} == {'full_name': 'Your Name', 'check': 'yes'}\nE         \nE         Common items:\nE         {'full_name': 'Your Name'}\nE         Differing items:\nE         {'check': ['yes', 'no']} != {'check': 'yes'}\nE         Left contains 1 more item:\nE         {'__prompts__': {'check': {'no': 'No'}, 'full_name': 'Name please'}}\nE         \nE         Full diff:\nE           {\nE         +     '__prompts__': {\nE         +         'check': {\nE         +             'no': 'No',\nE         +         },\nE         +         'full_name': 'Name please',\nE         +     },\nE         -     'check': 'yes',\nE         ?              ^^^^^^\nE         +     'check': [\nE         ?              ^\nE         +         'yes',\nE         +         'no',\nE         +     ],\nE               'full_name': 'Your Name',\nE           }\n\ntests/test_prompt.py:170: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestprompttest_prompt_for_config_dict","title":"test_prompt.py::TestPrompt::test_prompt_for_config_dict","text":"<pre>test_prompt.py::TestPrompt::test_prompt_for_config_dict</pre><pre>\nself = \nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eec7800a0&gt;\n\n    def test_prompt_for_config_dict(self, monkeypatch):\n        \"\"\"Verify `prompt_for_config` call `read_user_variable` on dict request.\"\"\"\n        monkeypatch.setattr(\n            'cookiecutter.prompt.read_user_dict',\n            lambda var, default, prompts, prefix: {\"key\": \"value\", \"integer\": 37},\n        )\n        context = {'cookiecutter': {'details': {}}}\n\n&gt;       cookiecutter_dict = prompt.prompt_for_config(context)\n\ntests/test_prompt.py:180: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/prompt.py:221: in prompt_for_config\n    cookiecutter_dict[key] = prompt_choice_for_config(\ncookiecutter/prompt.py:202: in prompt_choice_for_config\n    choice = read_user_choice(key, list(rendered_options.keys()), prompts=prompts, prefix=prefix)\ncookiecutter/prompt.py:90: in read_user_choice\n    choice = Prompt.ask(\"Enter the number of your choice\", choices=choices, default=\"0\")\n.venv/lib/python3.10/site-packages/rich/prompt.py:149: in ask\n    return _prompt(default=default, stream=stream)\n.venv/lib/python3.10/site-packages/rich/prompt.py:292: in __call__\n    value = self.get_input(self.console, prompt, self.password, stream=stream)\n.venv/lib/python3.10/site-packages/rich/prompt.py:211: in get_input\n    return console.input(prompt, password=password, stream=stream)\n.venv/lib/python3.10/site-packages/rich/console.py:2156: in input\n    result = input()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &lt;_pytest.capture.DontReadFromInput object at 0x7f1eeef69330&gt;, size = -1\n\n    def read(self, size: int = -1) -&gt; str:\n&gt;       raise OSError(\n            \"pytest: reading from stdin while output is captured!  Consider using `-s`.\"\n        )\nE       OSError: pytest: reading from stdin while output is captured!  Consider using `-s`.\n\n.venv/lib/python3.10/site-packages/_pytest/capture.py:209: OSError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestprompttest_should_render_dict","title":"test_prompt.py::TestPrompt::test_should_render_dict","text":"<pre>test_prompt.py::TestPrompt::test_should_render_dict</pre><pre>\nself = \n\n    def test_should_render_dict(self):\n        \"\"\"Verify template inside dictionary variable rendered.\"\"\"\n        context = {\n            'cookiecutter': {\n                'project_name': 'Slartibartfast',\n                'details': {\n                    '{{cookiecutter.project_name}}': '{{cookiecutter.project_name}}'\n                },\n            }\n        }\n\n        cookiecutter_dict = prompt.prompt_for_config(context, no_input=True)\n&gt;       assert cookiecutter_dict == {\n            'project_name': 'Slartibartfast',\n            'details': {'Slartibartfast': 'Slartibartfast'},\n        }\nE       AssertionError: assert OrderedDict([('project_name', 'Slartibartfast'), ('details', '{{cookiecutter.project_name}}')]) == {'project_name': 'Slartibartfast', 'details': {'Slartibartfast': 'Slartibartfast'}}\nE         \nE         Common items:\nE         {'project_name': 'Slartibartfast'}\nE         Differing items:\nE         {'details': '{{cookiecutter.project_name}}'} != {'details': {'Slartibartfast': 'Slartibartfast'}}\nE         \nE         Full diff:\nE         + OrderedDict({\nE         +     'details': '{{cookiecutter.project_name}}',\nE         - {\nE         -     'details': {\nE         -         'Slartibartfast': 'Slartibartfast',\nE         -     },\nE               'project_name': 'Slartibartfast',\nE         - }\nE         + })\n\ntests/test_prompt.py:195: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestprompttest_should_render_deep_dict","title":"test_prompt.py::TestPrompt::test_should_render_deep_dict","text":"<pre>test_prompt.py::TestPrompt::test_should_render_deep_dict</pre><pre>\nself = \n\n    def test_should_render_deep_dict(self):\n        \"\"\"Verify nested structures like dict in dict, rendered correctly.\"\"\"\n        context = {\n            'cookiecutter': {\n                'project_name': \"Slartibartfast\",\n                'details': {\n                    \"key\": \"value\",\n                    \"integer_key\": 37,\n                    \"other_name\": '{{cookiecutter.project_name}}',\n                    \"dict_key\": {\n                        \"deep_key\": \"deep_value\",\n                        \"deep_integer\": 42,\n                        \"deep_other_name\": '{{cookiecutter.project_name}}',\n                        \"deep_list\": [\n                            \"deep value 1\",\n                            \"{{cookiecutter.project_name}}\",\n                            \"deep value 3\",\n                        ],\n                    },\n                    \"list_key\": [\n                        \"value 1\",\n                        \"{{cookiecutter.project_name}}\",\n                        \"value 3\",\n                    ],\n                },\n            }\n        }\n\n        cookiecutter_dict = prompt.prompt_for_config(context, no_input=True)\n&gt;       assert cookiecutter_dict == {\n            'project_name': \"Slartibartfast\",\n            'details': {\n                \"key\": \"value\",\n                \"integer_key\": \"37\",\n                \"other_name\": \"Slartibartfast\",\n                \"dict_key\": {\n                    \"deep_key\": \"deep_value\",\n                    \"deep_integer\": \"42\",\n                    \"deep_other_name\": \"Slartibartfast\",\n                    \"deep_list\": [\"deep value 1\", \"Slartibartfast\", \"deep value 3\"],\n                },\n                \"list_key\": [\"value 1\", \"Slartibartfast\", \"value 3\"],\n            },\n        }\nE       AssertionError: assert OrderedDict([('project_name', 'Slartibartfast'), ('details', 'value')]) == {'project_name': 'Slartibartfast', 'details': {'key': 'value', 'integer_key': '37', 'other_name': 'Slartibartfast', 'dict_key': {'deep_key': 'deep_value', 'deep_integer': '42', 'deep_other_name': 'Slartibartfast', 'deep_list': ['deep value 1', 'Slartibartfast', 'deep value 3']}, 'list_key': ['value 1', 'Slartibartfast', 'value 3']}}\nE         \nE         Common items:\nE         {'project_name': 'Slartibartfast'}\nE         Differing items:\nE         {'details': 'value'} != {'details': {'dict_key': {'deep_integer': '42', 'deep_key': 'deep_value', 'deep_list': ['deep value 1', 'Slartibartfas...e': 'Slartibartfast'}, 'integer_key': '37', 'key': 'value', 'list_key': ['value 1', 'Slartibartfast', 'value 3'], ...}}\nE         \nE         Full diff:\nE         - {\nE         + OrderedDict({\nE         -     'details': {\nE         ?                ^\nE         +     'details': 'value',\nE         ?                ^^^^^^^^\nE         -         'dict_key': {\nE         -             'deep_integer': '42',\nE         -             'deep_key': 'deep_value',\nE         -             'deep_list': [\nE         -                 'deep value 1',\nE         -                 'Slartibartfast',\nE         -                 'deep value 3',\nE         -             ],\nE         -             'deep_other_name': 'Slartibartfast',\nE         -         },\nE         -         'integer_key': '37',\nE         -         'key': 'value',\nE         -         'list_key': [\nE         -             'value 1',\nE         -             'Slartibartfast',\nE         -             'value 3',\nE         -         ],\nE         -         'other_name': 'Slartibartfast',\nE         -     },\nE               'project_name': 'Slartibartfast',\nE         - }\nE         + })\n\ntests/test_prompt.py:229: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestprompttest_should_render_deep_dict_with_human_prompts","title":"test_prompt.py::TestPrompt::test_should_render_deep_dict_with_human_prompts","text":"<pre>test_prompt.py::TestPrompt::test_should_render_deep_dict_with_human_prompts</pre><pre>\nself = \n\n    def test_should_render_deep_dict_with_human_prompts(self):\n        \"\"\"Verify dict rendered correctly when human-readable prompts.\"\"\"\n        context = {\n            'cookiecutter': {\n                'project_name': \"Slartibartfast\",\n                'details': {\n                    \"key\": \"value\",\n                    \"integer_key\": 37,\n                    \"other_name\": '{{cookiecutter.project_name}}',\n                    \"dict_key\": {\n                        \"deep_key\": \"deep_value\",\n                    },\n                },\n                '__prompts__': {'project_name': 'Project name'},\n            }\n        }\n        cookiecutter_dict = prompt.prompt_for_config(context, no_input=True)\n&gt;       assert cookiecutter_dict == {\n            'project_name': \"Slartibartfast\",\n            'details': {\n                \"key\": \"value\",\n                \"integer_key\": \"37\",\n                \"other_name\": \"Slartibartfast\",\n                \"dict_key\": {\n                    \"deep_key\": \"deep_value\",\n                },\n            },\n        }\nE       AssertionError: assert OrderedDict([('project_name', 'Slartibartfast'), ('details', 'value'), ('__prompts__', {'project_name': 'Project name'})]) == {'project_name': 'Slartibartfast', 'details': {'key': 'value', 'integer_key': '37', 'other_name': 'Slartibartfast', 'dict_key': {'deep_key': 'deep_value'}}}\nE         \nE         Common items:\nE         {'project_name': 'Slartibartfast'}\nE         Differing items:\nE         {'details': 'value'} != {'details': {'dict_key': {'deep_key': 'deep_value'}, 'integer_key': '37', 'key': 'value', 'other_name': 'Slartibartfast'}}\nE         Left contains 1 more item:\nE         {'__prompts__': {'project_name': 'Project name'}}\nE         \nE         Full diff:\nE         + OrderedDict({\nE         +     '__prompts__': {\nE         +         'project_name': 'Project name',\nE         - {\nE         -     'details': {\nE         -         'dict_key': {\nE         -             'deep_key': 'deep_value',\nE         -         },\nE         -         'integer_key': '37',\nE         -         'key': 'value',\nE         -         'other_name': 'Slartibartfast',\nE               },\nE         +     'details': 'value',\nE               'project_name': 'Slartibartfast',\nE         - }\nE         + })\n\ntests/test_prompt.py:262: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestprompttest_internal_use_no_human_prompts","title":"test_prompt.py::TestPrompt::test_internal_use_no_human_prompts","text":"<pre>test_prompt.py::TestPrompt::test_internal_use_no_human_prompts</pre><pre>\nself = \n\n    def test_internal_use_no_human_prompts(self):\n        \"\"\"Verify dict rendered correctly when human-readable prompts empty.\"\"\"\n        context = {\n            'cookiecutter': {\n                'project_name': \"Slartibartfast\",\n                '__prompts__': {},\n            }\n        }\n        cookiecutter_dict = prompt.prompt_for_config(context, no_input=True)\n&gt;       assert cookiecutter_dict == {\n            'project_name': \"Slartibartfast\",\n        }\nE       AssertionError: assert OrderedDict([('project_name', 'Slartibartfast'), ('__prompts__', {})]) == {'project_name': 'Slartibartfast'}\nE         \nE         Common items:\nE         {'project_name': 'Slartibartfast'}\nE         Left contains 1 more item:\nE         {'__prompts__': {}}\nE         \nE         Full diff:\nE         - {\nE         + OrderedDict({\nE         +     '__prompts__': {},\nE               'project_name': 'Slartibartfast',\nE         - }\nE         + })\n\ntests/test_prompt.py:283: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestprompttest_prompt_for_templated_config","title":"test_prompt.py::TestPrompt::test_prompt_for_templated_config","text":"<pre>test_prompt.py::TestPrompt::test_prompt_for_templated_config</pre><pre>\nself = \nmonkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x7f1eed2d7f40&gt;\n\n    def test_prompt_for_templated_config(self, monkeypatch):\n        \"\"\"Verify Jinja2 templating works in unicode prompts.\"\"\"\n        monkeypatch.setattr(\n            'cookiecutter.prompt.read_user_variable',\n            lambda var, default, prompts, prefix: default,\n        )\n        context = {\n            'cookiecutter': OrderedDict(\n                [\n                    ('project_name', 'A New Project'),\n                    (\n                        'pkg_name',\n                        '{{ cookiecutter.project_name|lower|replace(\" \", \"\") }}',\n                    ),\n                ]\n            )\n        }\n\n        exp_cookiecutter_dict = {\n            'project_name': 'A New Project',\n            'pkg_name': 'anewproject',\n        }\n&gt;       cookiecutter_dict = prompt.prompt_for_config(context)\n\ntests/test_prompt.py:309: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncontext = {'cookiecutter': OrderedDict([('project_name', 'A New Project'), ('pkg_name', '{{ cookiecutter.project_name|lower|replace(\" \", \"\") }}')])}\nno_input = False\n\n    def prompt_for_config(context, no_input=False):\n        \"\"\"Prompt user to enter a new config.\n\n        :param dict context: Source for field names and sample values.\n        :param no_input: Do not prompt for user input and use only values from context.\n        \"\"\"\n        cookiecutter_dict = OrderedDict([])\n        env = create_env_with_context(context)\n\n        for key, raw in context['cookiecutter'].items():\n            if key.startswith('_'):\n                cookiecutter_dict[key] = raw\n                continue\n\n            if isinstance(raw, dict):\n                cookiecutter_dict[key] = prompt_choice_for_config(\n                    cookiecutter_dict, env, key, raw, no_input\n                )\n            else:\n                if no_input:\n                    cookiecutter_dict[key] = render_variable(env, raw, cookiecutter_dict)\n                else:\n&gt;                   cookiecutter_dict[key] = read_user_variable(key, raw)\nE                   TypeError: TestPrompt.test_prompt_for_templated_config..() missing 2 required positional arguments: 'prompts' and 'prefix'\n\ncookiecutter/prompt.py:228: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestprompttest_should_render_private_variables_with_two_underscores","title":"test_prompt.py::TestPrompt::test_should_render_private_variables_with_two_underscores","text":"<pre>test_prompt.py::TestPrompt::test_should_render_private_variables_with_two_underscores</pre><pre>\nenv = \nraw = '{{ cookiecutter.foo|lower }}'\ncookiecutter_dict = OrderedDict([('foo', 'Hello world'), ('bar', 123)])\n\n    def render_variable(env, raw, cookiecutter_dict):\n        \"\"\"Render the next variable to be displayed in the user prompt.\n\n        Inside the prompting taken from the cookiecutter.json file, this renders\n        the next variable. For example, if a project_name is \"Peanut Butter\n        Cookie\", the repo_name could be be rendered with:\n\n            `{{ cookiecutter.project_name.replace(\" \", \"_\") }}`.\n\n        This is then presented to the user as the default.\n\n        :param Environment env: A Jinja2 Environment object.\n        :param raw: The next value to be prompted for by the user.\n        :param dict cookiecutter_dict: The current context as it's gradually\n            being populated with variables.\n        :return: The rendered value for the default variable.\n        \"\"\"\n        if not isinstance(raw, str):\n            return raw\n\n        template = env.from_string(raw)\n        try:\n&gt;           return template.render(**cookiecutter_dict)\n\ncookiecutter/prompt.py:160: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/jinja2/environment.py:1304: in render\n    self.environment.handle_exception()\n.venv/lib/python3.10/site-packages/jinja2/environment.py:939: in handle_exception\n    raise rewrite_traceback_stack(source=source)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nobj = Undefined, attribute = 'foo'\n\n    def getattr(self, obj: t.Any, attribute: str) -&gt; t.Any:\n        \"\"\"Get an item or attribute of an object but prefer the attribute.\n        Unlike :meth:`getitem` the attribute *must* be a string.\n        \"\"\"\n        try:\n&gt;           return getattr(obj, attribute)\nE           jinja2.exceptions.UndefinedError: 'cookiecutter' is undefined\n\n.venv/lib/python3.10/site-packages/jinja2/environment.py:487: UndefinedError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \n\n    def test_should_render_private_variables_with_two_underscores(self):\n        \"\"\"Test rendering of private variables with two underscores.\n\n        There are three cases:\n        1. Variables beginning with a single underscore are private and not rendered.\n        2. Variables beginning with a double underscore are private and are rendered.\n        3. Variables beginning with anything other than underscores are not private and\n           are rendered.\n        \"\"\"\n        context = {\n            'cookiecutter': OrderedDict(\n                [\n                    ('foo', 'Hello world'),\n                    ('bar', 123),\n                    ('rendered_foo', '{{ cookiecutter.foo|lower }}'),\n                    ('rendered_bar', 123),\n                    ('_hidden_foo', '{{ cookiecutter.foo|lower }}'),\n                    ('_hidden_bar', 123),\n                    ('__rendered_hidden_foo', '{{ cookiecutter.foo|lower }}'),\n                    ('__rendered_hidden_bar', 123),\n                ]\n            )\n        }\n&gt;       cookiecutter_dict = prompt.prompt_for_config(context, no_input=True)\n\ntests/test_prompt.py:347: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/prompt.py:226: in prompt_for_config\n    cookiecutter_dict[key] = render_variable(env, raw, cookiecutter_dict)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nenv = \nraw = '{{ cookiecutter.foo|lower }}'\ncookiecutter_dict = OrderedDict([('foo', 'Hello world'), ('bar', 123)])\n\n    def render_variable(env, raw, cookiecutter_dict):\n        \"\"\"Render the next variable to be displayed in the user prompt.\n\n        Inside the prompting taken from the cookiecutter.json file, this renders\n        the next variable. For example, if a project_name is \"Peanut Butter\n        Cookie\", the repo_name could be be rendered with:\n\n            `{{ cookiecutter.project_name.replace(\" \", \"_\") }}`.\n\n        This is then presented to the user as the default.\n\n        :param Environment env: A Jinja2 Environment object.\n        :param raw: The next value to be prompted for by the user.\n        :param dict cookiecutter_dict: The current context as it's gradually\n            being populated with variables.\n        :return: The rendered value for the default variable.\n        \"\"\"\n        if not isinstance(raw, str):\n            return raw\n\n        template = env.from_string(raw)\n        try:\n            return template.render(**cookiecutter_dict)\n        except UndefinedError as err:\n&gt;           raise UndefinedVariableInTemplate(str(err), err, cookiecutter_dict)\nE           cookiecutter.exceptions.UndefinedVariableInTemplate: 'cookiecutter' is undefined. Error message: 'cookiecutter' is undefined. Context: OrderedDict([('foo', 'Hello world'), ('bar', 123)])\n\ncookiecutter/prompt.py:162: UndefinedVariableInTemplate"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestreaduserchoicetest_should_invoke_read_user_choice","title":"test_prompt.py::TestReadUserChoice::test_should_invoke_read_user_choice","text":"<pre>test_prompt.py::TestReadUserChoice::test_should_invoke_read_user_choice</pre><pre>\nself = \nmocker = \n\n    def test_should_invoke_read_user_choice(self, mocker):\n        \"\"\"Verify correct function called for select(list) variables.\"\"\"\n        prompt_choice = mocker.patch(\n            'cookiecutter.prompt.prompt_choice_for_config',\n            wraps=prompt.prompt_choice_for_config,\n        )\n\n        read_user_choice = mocker.patch('cookiecutter.prompt.read_user_choice')\n        read_user_choice.return_value = 'all'\n\n        read_user_variable = mocker.patch('cookiecutter.prompt.read_user_variable')\n\n        choices = ['landscape', 'portrait', 'all']\n        context = {'cookiecutter': {'orientation': choices}}\n\n        cookiecutter_dict = prompt.prompt_for_config(context)\n\n&gt;       assert not read_user_variable.called\nE       AssertionError: assert not True\nE        +  where True = .called\n\ntests/test_prompt.py:403: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestreaduserchoicetest_should_invoke_read_user_variable","title":"test_prompt.py::TestReadUserChoice::test_should_invoke_read_user_variable","text":"<pre>test_prompt.py::TestReadUserChoice::test_should_invoke_read_user_variable</pre><pre>\nself = \nargs = ('full_name', 'Your Name', {}, '  [dim][1/1][/] '), kwargs = {}\nexpected = call('full_name', 'Your Name', {}, '  [dim][1/1][/] ')\nactual = call('full_name', 'Your Name')\n_error_message = ._error_message at 0x7f1eec07ac20&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: read_user_variable('full_name', 'Your Name', {}, '  [dim][1/1][/] ')\nE           Actual: read_user_variable('full_name', 'Your Name')\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = ('full_name', 'Your Name', {}, '  [dim][1/1][/] '), kwargs = {}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: read_user_variable('full_name', 'Your Name', {}, '  [dim][1/1][/] ')\nE       Actual: read_user_variable('full_name', 'Your Name')\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('full_name', 'Your Name') == ('full_name', 'Your Name', {}, '  [dim][1/1][/] ')\nE         \nE         Right contains 2 more items, first extra item: {}\nE         \nE         Full diff:\nE           (\nE               'full_name',\nE               'Your Name',\nE         -     {},\nE         -     '  [dim][1/1][/] ',\nE           )\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nmocker = \n\n    def test_should_invoke_read_user_variable(self, mocker):\n        \"\"\"Verify correct function called for string input variables.\"\"\"\n        read_user_variable = mocker.patch('cookiecutter.prompt.read_user_variable')\n        read_user_variable.return_value = 'Audrey Roy'\n\n        prompt_choice = mocker.patch('cookiecutter.prompt.prompt_choice_for_config')\n\n        read_user_choice = mocker.patch('cookiecutter.prompt.read_user_choice')\n\n        context = {'cookiecutter': {'full_name': 'Your Name'}}\n\n        cookiecutter_dict = prompt.prompt_for_config(context)\n\n        assert not prompt_choice.called\n        assert not read_user_choice.called\n&gt;       read_user_variable.assert_called_once_with(\n            'full_name', 'Your Name', {}, DEFAULT_PREFIX\n        )\nE       AssertionError: expected call not found.\nE       Expected: read_user_variable('full_name', 'Your Name', {}, '  [dim][1/1][/] ')\nE       Actual: read_user_variable('full_name', 'Your Name')\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('full_name', 'Your Name') == ('full_name', 'Your Name', {}, '  [dim][1/1][/] ')\nE         \nE         Right contains 2 more items, first extra item: {}\nE         \nE         Full diff:\nE           (\nE               'full_name',\nE               'Your Name',\nE         -     {},\nE         -     '  [dim][1/1][/] ',\nE           )\n\ntests/test_prompt.py:425: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestreaduserchoicetest_should_render_choices","title":"test_prompt.py::TestReadUserChoice::test_should_render_choices","text":"<pre>test_prompt.py::TestReadUserChoice::test_should_render_choices</pre><pre>\nself = \nargs = ('project_name', 'A New Project', {}, '  [dim][1/2][/] '), kwargs = {}\nmsg = 'Expected \\'read_user_variable\\' to be called once. Called 2 times.\\nCalls: [call(\\'project_name\\', \\'A New Project\\'),\\n call(\\'pkg_name\\', [\\'foo\\', \\'{{ cookiecutter.project_name|lower|replace(\" \", \"\") }}\\', \\'bar\\'])].'\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n&gt;           raise AssertionError(msg)\nE           AssertionError: Expected 'read_user_variable' to be called once. Called 2 times.\nE           Calls: [call('project_name', 'A New Project'),\nE            call('pkg_name', ['foo', '{{ cookiecutter.project_name|lower|replace(\" \", \"\") }}', 'bar'])].\n\n/usr/lib/python3.10/unittest/mock.py:940: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nmocker = \n\n    def test_should_render_choices(self, mocker):\n        \"\"\"Verify Jinja2 templating engine works inside choices variables.\"\"\"\n        read_user_choice = mocker.patch('cookiecutter.prompt.read_user_choice')\n        read_user_choice.return_value = 'anewproject'\n\n        read_user_variable = mocker.patch('cookiecutter.prompt.read_user_variable')\n        read_user_variable.return_value = 'A New Project'\n\n        rendered_choices = ['foo', 'anewproject', 'bar']\n\n        context = {\n            'cookiecutter': OrderedDict(\n                [\n                    ('project_name', 'A New Project'),\n                    (\n                        'pkg_name',\n                        [\n                            'foo',\n                            '{{ cookiecutter.project_name|lower|replace(\" \", \"\") }}',\n                            'bar',\n                        ],\n                    ),\n                ]\n            )\n        }\n\n        expected = {\n            'project_name': 'A New Project',\n            'pkg_name': 'anewproject',\n        }\n        cookiecutter_dict = prompt.prompt_for_config(context)\n\n&gt;       read_user_variable.assert_called_once_with(\n            'project_name', 'A New Project', {}, '  [dim][1/2][/] '\n        )\nE       AssertionError: Expected 'read_user_variable' to be called once. Called 2 times.\nE       Calls: [call('project_name', 'A New Project'),\nE        call('pkg_name', ['foo', '{{ cookiecutter.project_name|lower|replace(\" \", \"\") }}', 'bar'])].\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert ('pkg_name', ['foo', '{{ cookiecutter.project_name|lower|replace(\" \", \"\") }}', 'bar']) == ('project_name', 'A New Project', {}, '  [dim][1/2][/] ')\nE         \nE         At index 0 diff: 'pkg_name' != 'project_name'\nE         Right contains 2 more items, first extra item: {}\nE         \nE         Full diff:\nE           (\nE         -     'project_name',\nE         ?       ^^^^^^\nE         +     'pkg_name',\nE         ?       ^^\nE         -     'A New Project',\nE         +     [\nE         +         'foo',\nE         +         '{{ cookiecutter.project_name|lower|replace(\" \", \"\") }}',\nE         +         'bar',\nE         -     {},\nE         ?     ^^\nE         +     ],\nE         ?     ^\nE         -     '  [dim][1/2][/] ',\nE           )\n\ntests/test_prompt.py:462: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestpromptchoiceforconfigtest_should_return_first_option_if_no_input","title":"test_prompt.py::TestPromptChoiceForConfig::test_should_return_first_option_if_no_input","text":"<pre>test_prompt.py::TestPromptChoiceForConfig::test_should_return_first_option_if_no_input</pre><pre>\nself = \nmocker = \nchoices = ['landscape', 'portrait', 'all']\ncontext = {'cookiecutter': {'orientation': ['landscape', 'portrait', 'all']}}\n\n    def test_should_return_first_option_if_no_input(self, mocker, choices, context):\n        \"\"\"Verify prompt_choice_for_config return first list option on no_input=True.\"\"\"\n        read_user_choice = mocker.patch('cookiecutter.prompt.read_user_choice')\n\n        expected_choice = choices[0]\n\n&gt;       actual_choice = prompt.prompt_choice_for_config(\n            cookiecutter_dict=context,\n            env=environment.StrictEnvironment(),\n            key='orientation',\n            options=choices,\n            no_input=True,  # Suppress user input\n        )\n\ntests/test_prompt.py:490: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncookiecutter_dict = {'cookiecutter': {'orientation': ['landscape', 'portrait', 'all']}}\nenv = \nkey = 'orientation', options = ['landscape', 'portrait', 'all'], no_input = True\nprompts = None, prefix = ''\n\n    def prompt_choice_for_config(cookiecutter_dict, env, key, options, no_input,\n        prompts=None, prefix=''):\n        \"\"\"Prompt user with a set of options to choose from.\n\n        :param no_input: Do not prompt for user input and return the first available option.\n        \"\"\"\n        if no_input:\n&gt;           return next(iter(options.values()))\nE           AttributeError: 'list' object has no attribute 'values'\n\ncookiecutter/prompt.py:196: AttributeError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestpromptchoiceforconfigtest_should_read_user_choice","title":"test_prompt.py::TestPromptChoiceForConfig::test_should_read_user_choice","text":"<pre>test_prompt.py::TestPromptChoiceForConfig::test_should_read_user_choice</pre><pre>\nself = \nmocker = \nchoices = ['landscape', 'portrait', 'all']\ncontext = {'cookiecutter': {'orientation': ['landscape', 'portrait', 'all']}}\n\n    def test_should_read_user_choice(self, mocker, choices, context):\n        \"\"\"Verify prompt_choice_for_config return user selection on no_input=False.\"\"\"\n        read_user_choice = mocker.patch('cookiecutter.prompt.read_user_choice')\n        read_user_choice.return_value = 'all'\n\n        expected_choice = 'all'\n\n&gt;       actual_choice = prompt.prompt_choice_for_config(\n            cookiecutter_dict=context,\n            env=environment.StrictEnvironment(),\n            key='orientation',\n            options=choices,\n            no_input=False,  # Ask the user for input\n        )\n\ntests/test_prompt.py:508: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncookiecutter_dict = {'cookiecutter': {'orientation': ['landscape', 'portrait', 'all']}}\nenv = \nkey = 'orientation', options = ['landscape', 'portrait', 'all']\nno_input = False, prompts = None, prefix = ''\n\n    def prompt_choice_for_config(cookiecutter_dict, env, key, options, no_input,\n        prompts=None, prefix=''):\n        \"\"\"Prompt user with a set of options to choose from.\n\n        :param no_input: Do not prompt for user input and return the first available option.\n        \"\"\"\n        if no_input:\n            return next(iter(options.values()))\n\n        rendered_options = OrderedDict()\n&gt;       for option_key, option_value in options.items():\nE       AttributeError: 'list' object has no attribute 'items'\n\ncookiecutter/prompt.py:199: AttributeError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestreaduseryesnotest_should_invoke_read_user_yes_notrue","title":"test_prompt.py::TestReadUserYesNo::test_should_invoke_read_user_yes_no[True]","text":"<pre>test_prompt.py::TestReadUserYesNo::test_should_invoke_read_user_yes_no[True]</pre><pre>\nself = \nmocker = \nrun_as_docker = True\n\n    @pytest.mark.parametrize(\n        'run_as_docker',\n        (\n            True,\n            False,\n        ),\n    )\n    def test_should_invoke_read_user_yes_no(self, mocker, run_as_docker):\n        \"\"\"Verify correct function called for boolean variables.\"\"\"\n        read_user_yes_no = mocker.patch('cookiecutter.prompt.read_user_yes_no')\n        read_user_yes_no.return_value = run_as_docker\n\n        read_user_variable = mocker.patch('cookiecutter.prompt.read_user_variable')\n\n        context = {'cookiecutter': {'run_as_docker': run_as_docker}}\n\n        cookiecutter_dict = prompt.prompt_for_config(context)\n\n&gt;       assert not read_user_variable.called\nE       AssertionError: assert not True\nE        +  where True = .called\n\ntests/test_prompt.py:540: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytestreaduseryesnotest_should_invoke_read_user_yes_nofalse","title":"test_prompt.py::TestReadUserYesNo::test_should_invoke_read_user_yes_no[False]","text":"<pre>test_prompt.py::TestReadUserYesNo::test_should_invoke_read_user_yes_no[False]</pre><pre>\nself = \nmocker = \nrun_as_docker = False\n\n    @pytest.mark.parametrize(\n        'run_as_docker',\n        (\n            True,\n            False,\n        ),\n    )\n    def test_should_invoke_read_user_yes_no(self, mocker, run_as_docker):\n        \"\"\"Verify correct function called for boolean variables.\"\"\"\n        read_user_yes_no = mocker.patch('cookiecutter.prompt.read_user_yes_no')\n        read_user_yes_no.return_value = run_as_docker\n\n        read_user_variable = mocker.patch('cookiecutter.prompt.read_user_variable')\n\n        context = {'cookiecutter': {'run_as_docker': run_as_docker}}\n\n        cookiecutter_dict = prompt.prompt_for_config(context)\n\n&gt;       assert not read_user_variable.called\nE       AssertionError: assert not True\nE        +  where True = .called\n\ntests/test_prompt.py:540: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytest_undefined_variableundefined-variable-in-cookiecutter-dict","title":"test_prompt.py::test_undefined_variable[Undefined variable in cookiecutter dict]","text":"<pre>test_prompt.py::test_undefined_variable[Undefined variable in cookiecutter dict]</pre><pre>\ncontext = {'cookiecutter': {'foo': '{{cookiecutter.nope}}'}}\n\n    @pytest.mark.parametrize(\n        'context',\n        (\n            {'cookiecutter': {'foo': '{{cookiecutter.nope}}'}},\n            {'cookiecutter': {'foo': ['123', '{{cookiecutter.nope}}', '456']}},\n            {'cookiecutter': {'foo': {'{{cookiecutter.nope}}': 'value'}}},\n            {'cookiecutter': {'foo': {'key': '{{cookiecutter.nope}}'}}},\n        ),\n        ids=[\n            'Undefined variable in cookiecutter dict',\n            'Undefined variable in cookiecutter dict with choices',\n            'Undefined variable in cookiecutter dict with dict_key',\n            'Undefined variable in cookiecutter dict with key_value',\n        ],\n    )\n    def test_undefined_variable(context):\n        \"\"\"Verify `prompt.prompt_for_config` raises correct error.\"\"\"\n        with pytest.raises(exceptions.UndefinedVariableInTemplate) as err:\n            prompt.prompt_for_config(context, no_input=True)\n\n        error = err.value\n&gt;       assert error.message == \"Unable to render variable 'foo'\"\nE       assert \"'cookiecutter' is undefined\" == \"Unable to render variable 'foo'\"\nE         \nE         - Unable to render variable 'foo'\nE         + 'cookiecutter' is undefined\n\ntests/test_prompt.py:578: AssertionError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_promptpytest_undefined_variableundefined-variable-in-cookiecutter-dict-with-choices","title":"test_prompt.py::test_undefined_variable[Undefined variable in cookiecutter dict with choices]","text":"<pre>test_prompt.py::test_undefined_variable[Undefined variable in cookiecutter dict with choices]</pre><pre>\ncontext = {'cookiecutter': {'foo': ['123', '{{cookiecutter.nope}}', '456']}}\n\n    @pytest.mark.parametrize(\n        'context',\n        (\n            {'cookiecutter': {'foo': '{{cookiecutter.nope}}'}},\n            {'cookiecutter': {'foo': ['123', '{{cookiecutter.nope}}', '456']}},\n            {'cookiecutter': {'foo': {'{{cookiecutter.nope}}': 'value'}}},\n            {'cookiecutter': {'foo': {'key': '{{cookiecutter.nope}}'}}},\n        ),\n        ids=[\n            'Undefined variable in cookiecutter dict',\n            'Undefined variable in cookiecutter dict with choices',\n            'Undefined variable in cookiecutter dict with dict_key',\n            'Undefined variable in cookiecutter dict with key_value',\n        ],\n    )\n    def test_undefined_variable(context):\n        \"\"\"Verify `prompt.prompt_for_config` raises correct error.\"\"\"\n&gt;       with pytest.raises(exceptions.UndefinedVariableInTemplate) as err:\nE       Failed: DID NOT RAISE \n\ntests/test_prompt.py:574: Failed"},{"location":"analysis_baseline_cookiecutter/#test_promptpytest_undefined_variableundefined-variable-in-cookiecutter-dict-with-dict_key","title":"test_prompt.py::test_undefined_variable[Undefined variable in cookiecutter dict with dict_key]","text":"<pre>test_prompt.py::test_undefined_variable[Undefined variable in cookiecutter dict with dict_key]</pre><pre>\ncontext = {'cookiecutter': {'foo': {'{{cookiecutter.nope}}': 'value'}}}\n\n    @pytest.mark.parametrize(\n        'context',\n        (\n            {'cookiecutter': {'foo': '{{cookiecutter.nope}}'}},\n            {'cookiecutter': {'foo': ['123', '{{cookiecutter.nope}}', '456']}},\n            {'cookiecutter': {'foo': {'{{cookiecutter.nope}}': 'value'}}},\n            {'cookiecutter': {'foo': {'key': '{{cookiecutter.nope}}'}}},\n        ),\n        ids=[\n            'Undefined variable in cookiecutter dict',\n            'Undefined variable in cookiecutter dict with choices',\n            'Undefined variable in cookiecutter dict with dict_key',\n            'Undefined variable in cookiecutter dict with key_value',\n        ],\n    )\n    def test_undefined_variable(context):\n        \"\"\"Verify `prompt.prompt_for_config` raises correct error.\"\"\"\n&gt;       with pytest.raises(exceptions.UndefinedVariableInTemplate) as err:\nE       Failed: DID NOT RAISE \n\ntests/test_prompt.py:574: Failed"},{"location":"analysis_baseline_cookiecutter/#test_promptpytest_undefined_variableundefined-variable-in-cookiecutter-dict-with-key_value","title":"test_prompt.py::test_undefined_variable[Undefined variable in cookiecutter dict with key_value]","text":"<pre>test_prompt.py::test_undefined_variable[Undefined variable in cookiecutter dict with key_value]</pre><pre>\ncontext = {'cookiecutter': {'foo': {'key': '{{cookiecutter.nope}}'}}}\n\n    @pytest.mark.parametrize(\n        'context',\n        (\n            {'cookiecutter': {'foo': '{{cookiecutter.nope}}'}},\n            {'cookiecutter': {'foo': ['123', '{{cookiecutter.nope}}', '456']}},\n            {'cookiecutter': {'foo': {'{{cookiecutter.nope}}': 'value'}}},\n            {'cookiecutter': {'foo': {'key': '{{cookiecutter.nope}}'}}},\n        ),\n        ids=[\n            'Undefined variable in cookiecutter dict',\n            'Undefined variable in cookiecutter dict with choices',\n            'Undefined variable in cookiecutter dict with dict_key',\n            'Undefined variable in cookiecutter dict with key_value',\n        ],\n    )\n    def test_undefined_variable(context):\n        \"\"\"Verify `prompt.prompt_for_config` raises correct error.\"\"\"\n&gt;       with pytest.raises(exceptions.UndefinedVariableInTemplate) as err:\nE       Failed: DID NOT RAISE \n\ntests/test_prompt.py:574: Failed"},{"location":"analysis_baseline_cookiecutter/#test_promptpytest_cookiecutter_nested_templatesfake-nested-templates-fake-project","title":"test_prompt.py::test_cookiecutter_nested_templates[fake-nested-templates-fake-project]","text":"<pre>test_prompt.py::test_cookiecutter_nested_templates[fake-nested-templates-fake-project]</pre><pre>\ntemplate_dir = 'fake-nested-templates', expected = 'fake-project'\n\n    @pytest.mark.parametrize(\n        \"template_dir,expected\",\n        [\n            [\"fake-nested-templates\", \"fake-project\"],\n            [\"fake-nested-templates-old-style\", \"fake-package\"],\n        ],\n    )\n    def test_cookiecutter_nested_templates(template_dir: str, expected: str):\n        \"\"\"Test nested_templates generation.\"\"\"\n        from cookiecutter import prompt\n\n        main_dir = (Path(\"tests\") / template_dir).resolve()\n        cookiecuter_context = json.loads((main_dir / \"cookiecutter.json\").read_text())\n        context = {\"cookiecutter\": cookiecuter_context}\n&gt;       output_dir = prompt.choose_nested_template(context, main_dir, no_input=True)\n\ntests/test_prompt.py:596: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/prompt.py:243: in choose_nested_template\n    template_names = [d.name for d in template_dir.iterdir() if d.is_dir()]\ncookiecutter/prompt.py:243: in \n    template_names = [d.name for d in template_dir.iterdir() if d.is_dir()]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = PosixPath('/testbed/tests/fake-nested-templates/templates')\n\n    def iterdir(self):\n        \"\"\"Iterate over the files in this directory.  Does not yield any\n        result for the special paths '.' and '..'.\n        \"\"\"\n&gt;       for name in self._accessor.listdir(self):\nE       FileNotFoundError: [Errno 2] No such file or directory: '/testbed/tests/fake-nested-templates/templates'\n\n/usr/lib/python3.10/pathlib.py:1017: FileNotFoundError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytest_cookiecutter_nested_templatesfake-nested-templates-old-style-fake-package","title":"test_prompt.py::test_cookiecutter_nested_templates[fake-nested-templates-old-style-fake-package]","text":"<pre>test_prompt.py::test_cookiecutter_nested_templates[fake-nested-templates-old-style-fake-package]</pre><pre>\ntemplate_dir = 'fake-nested-templates-old-style', expected = 'fake-package'\n\n    @pytest.mark.parametrize(\n        \"template_dir,expected\",\n        [\n            [\"fake-nested-templates\", \"fake-project\"],\n            [\"fake-nested-templates-old-style\", \"fake-package\"],\n        ],\n    )\n    def test_cookiecutter_nested_templates(template_dir: str, expected: str):\n        \"\"\"Test nested_templates generation.\"\"\"\n        from cookiecutter import prompt\n\n        main_dir = (Path(\"tests\") / template_dir).resolve()\n        cookiecuter_context = json.loads((main_dir / \"cookiecutter.json\").read_text())\n        context = {\"cookiecutter\": cookiecuter_context}\n&gt;       output_dir = prompt.choose_nested_template(context, main_dir, no_input=True)\n\ntests/test_prompt.py:596: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/prompt.py:243: in choose_nested_template\n    template_names = [d.name for d in template_dir.iterdir() if d.is_dir()]\ncookiecutter/prompt.py:243: in \n    template_names = [d.name for d in template_dir.iterdir() if d.is_dir()]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = PosixPath('/testbed/tests/fake-nested-templates-old-style/templates')\n\n    def iterdir(self):\n        \"\"\"Iterate over the files in this directory.  Does not yield any\n        result for the special paths '.' and '..'.\n        \"\"\"\n&gt;       for name in self._accessor.listdir(self):\nE       FileNotFoundError: [Errno 2] No such file or directory: '/testbed/tests/fake-nested-templates-old-style/templates'\n\n/usr/lib/python3.10/pathlib.py:1017: FileNotFoundError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytest_cookiecutter_nested_templates_invalid_paths","title":"test_prompt.py::test_cookiecutter_nested_templates_invalid_paths[]","text":"<pre>test_prompt.py::test_cookiecutter_nested_templates_invalid_paths[]</pre><pre>\npath = ''\n\n    @pytest.mark.skipif(sys.platform.startswith('win'), reason=\"Linux / macos test\")\n    @pytest.mark.parametrize(\n        \"path\",\n        [\n            \"\",\n            \"/tmp\",\n            \"/foo\",\n        ],\n    )\n    def test_cookiecutter_nested_templates_invalid_paths(path: str):\n        \"\"\"Test nested_templates generation.\"\"\"\n        from cookiecutter import prompt\n\n        main_dir = (Path(\"tests\") / \"fake-nested-templates\").resolve()\n        cookiecuter_context = json.loads((main_dir / \"cookiecutter.json\").read_text())\n        cookiecuter_context[\"templates\"][\"fake-project\"][\"path\"] = path\n        context = {\"cookiecutter\": cookiecuter_context}\n        with pytest.raises(ValueError) as exc:\n&gt;           prompt.choose_nested_template(context, main_dir, no_input=True)\n\ntests/test_prompt.py:619: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/prompt.py:243: in choose_nested_template\n    template_names = [d.name for d in template_dir.iterdir() if d.is_dir()]\ncookiecutter/prompt.py:243: in \n    template_names = [d.name for d in template_dir.iterdir() if d.is_dir()]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = PosixPath('/testbed/tests/fake-nested-templates/templates')\n\n    def iterdir(self):\n        \"\"\"Iterate over the files in this directory.  Does not yield any\n        result for the special paths '.' and '..'.\n        \"\"\"\n&gt;       for name in self._accessor.listdir(self):\nE       FileNotFoundError: [Errno 2] No such file or directory: '/testbed/tests/fake-nested-templates/templates'\n\n/usr/lib/python3.10/pathlib.py:1017: FileNotFoundError"},{"location":"analysis_baseline_cookiecutter/#tmp","title":"tmp]","text":"<pre>tmp]</pre><pre>\npath = '/tmp'\n\n    @pytest.mark.skipif(sys.platform.startswith('win'), reason=\"Linux / macos test\")\n    @pytest.mark.parametrize(\n        \"path\",\n        [\n            \"\",\n            \"/tmp\",\n            \"/foo\",\n        ],\n    )\n    def test_cookiecutter_nested_templates_invalid_paths(path: str):\n        \"\"\"Test nested_templates generation.\"\"\"\n        from cookiecutter import prompt\n\n        main_dir = (Path(\"tests\") / \"fake-nested-templates\").resolve()\n        cookiecuter_context = json.loads((main_dir / \"cookiecutter.json\").read_text())\n        cookiecuter_context[\"templates\"][\"fake-project\"][\"path\"] = path\n        context = {\"cookiecutter\": cookiecuter_context}\n        with pytest.raises(ValueError) as exc:\n&gt;           prompt.choose_nested_template(context, main_dir, no_input=True)\n\ntests/test_prompt.py:619: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/prompt.py:243: in choose_nested_template\n    template_names = [d.name for d in template_dir.iterdir() if d.is_dir()]\ncookiecutter/prompt.py:243: in \n    template_names = [d.name for d in template_dir.iterdir() if d.is_dir()]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = PosixPath('/testbed/tests/fake-nested-templates/templates')\n\n    def iterdir(self):\n        \"\"\"Iterate over the files in this directory.  Does not yield any\n        result for the special paths '.' and '..'.\n        \"\"\"\n&gt;       for name in self._accessor.listdir(self):\nE       FileNotFoundError: [Errno 2] No such file or directory: '/testbed/tests/fake-nested-templates/templates'\n\n/usr/lib/python3.10/pathlib.py:1017: FileNotFoundError"},{"location":"analysis_baseline_cookiecutter/#foo","title":"foo]","text":"<pre>foo]</pre><pre>\npath = '/foo'\n\n    @pytest.mark.skipif(sys.platform.startswith('win'), reason=\"Linux / macos test\")\n    @pytest.mark.parametrize(\n        \"path\",\n        [\n            \"\",\n            \"/tmp\",\n            \"/foo\",\n        ],\n    )\n    def test_cookiecutter_nested_templates_invalid_paths(path: str):\n        \"\"\"Test nested_templates generation.\"\"\"\n        from cookiecutter import prompt\n\n        main_dir = (Path(\"tests\") / \"fake-nested-templates\").resolve()\n        cookiecuter_context = json.loads((main_dir / \"cookiecutter.json\").read_text())\n        cookiecuter_context[\"templates\"][\"fake-project\"][\"path\"] = path\n        context = {\"cookiecutter\": cookiecuter_context}\n        with pytest.raises(ValueError) as exc:\n&gt;           prompt.choose_nested_template(context, main_dir, no_input=True)\n\ntests/test_prompt.py:619: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/prompt.py:243: in choose_nested_template\n    template_names = [d.name for d in template_dir.iterdir() if d.is_dir()]\ncookiecutter/prompt.py:243: in \n    template_names = [d.name for d in template_dir.iterdir() if d.is_dir()]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = PosixPath('/testbed/tests/fake-nested-templates/templates')\n\n    def iterdir(self):\n        \"\"\"Iterate over the files in this directory.  Does not yield any\n        result for the special paths '.' and '..'.\n        \"\"\"\n&gt;       for name in self._accessor.listdir(self):\nE       FileNotFoundError: [Errno 2] No such file or directory: '/testbed/tests/fake-nested-templates/templates'\n\n/usr/lib/python3.10/pathlib.py:1017: FileNotFoundError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytest_cookiecutter_nested_templates_invalid_win_paths","title":"test_prompt.py::test_cookiecutter_nested_templates_invalid_win_paths[]","text":"<pre>test_prompt.py::test_cookiecutter_nested_templates_invalid_win_paths[]</pre><pre>\n('/testbed/tests/test_prompt.py', 623, 'Skipped: Win only test')\n</pre>"},{"location":"analysis_baseline_cookiecutter/#tmp_1","title":"tmp]","text":"<pre>tmp]</pre><pre>\n('/testbed/tests/test_prompt.py', 623, 'Skipped: Win only test')\n</pre>"},{"location":"analysis_baseline_cookiecutter/#tmp_2","title":"tmp]","text":"<pre>tmp]</pre><pre>\n('/testbed/tests/test_prompt.py', 623, 'Skipped: Win only test')\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_promptpytest_prompt_should_ask_and_rm_repo_file","title":"test_prompt.py::test_prompt_should_ask_and_rm_repo_file","text":"<pre>test_prompt.py::test_prompt_should_ask_and_rm_repo_file</pre><pre>\ntopfd = 12\npath = '/tmp/pytest-of-root/pytest-0/test_prompt_should_ask_and_rm_1/repo.zip'\nonerror = \n\n    def _rmtree_safe_fd(topfd, path, onerror):\n        try:\n&gt;           with os.scandir(topfd) as scandir_it:\nE           NotADirectoryError: [Errno 20] Not a directory: '/tmp/pytest-of-root/pytest-0/test_prompt_should_ask_and_rm_1/repo.zip'\n\n/usr/lib/python3.10/shutil.py:629: NotADirectoryError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_prompt_should_ask_and_rm_1')\n\n    def test_prompt_should_ask_and_rm_repo_file(mocker, tmp_path):\n        \"\"\"In `prompt_and_delete()`, if the user agrees to delete/reclone a \\\n        repo file, the repo should be deleted.\"\"\"\n        mock_read_user = mocker.patch(\n            'cookiecutter.prompt.read_user_yes_no', return_value=True, autospec=True\n        )\n\n        repo_file = tmp_path.joinpath('repo.zip')\n        repo_file.write_text('this is zipfile content')\n\n&gt;       deleted = prompt.prompt_and_delete(str(repo_file))\n\ntests/test_prompt.py:690: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/prompt.py:276: in prompt_and_delete\n    rmtree(path)\ncookiecutter/utils.py:30: in rmtree\n    shutil.rmtree(path, onerror=force_delete)\n/usr/lib/python3.10/shutil.py:725: in rmtree\n    _rmtree_safe_fd(fd, path, onerror)\n/usr/lib/python3.10/shutil.py:633: in _rmtree_safe_fd\n    onerror(os.scandir, path, sys.exc_info())\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = \npath = '/tmp/pytest-of-root/pytest-0/test_prompt_should_ask_and_rm_1/repo.zip'\nexc_info = (, NotADirectoryError(20, 'Not a directory'), )\n\n    def force_delete(func, path, exc_info):\n        \"\"\"Error handler for `shutil.rmtree()` equivalent to `rm -rf`.\n\n        Usage: `shutil.rmtree(path, onerror=force_delete)`\n        From https://docs.python.org/3/library/shutil.html#rmtree-example\n        \"\"\"\n        os.chmod(path, stat.S_IWRITE)\n&gt;       func(path)\nE       NotADirectoryError: [Errno 20] Not a directory: '/tmp/pytest-of-root/pytest-0/test_prompt_should_ask_and_rm_1/repo.zip'\n\ncookiecutter/utils.py:22: NotADirectoryError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytest_prompt_should_ask_and_keep_repo_on_reuse","title":"test_prompt.py::test_prompt_should_ask_and_keep_repo_on_reuse","text":"<pre>test_prompt.py::test_prompt_should_ask_and_keep_repo_on_reuse</pre><pre>\nmocker = \ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_prompt_should_ask_and_kee1')\n\n    def test_prompt_should_ask_and_keep_repo_on_reuse(mocker, tmp_path):\n        \"\"\"In `prompt_and_delete()`, if the user wants to keep their old \\\n        cloned template repo, it should not be deleted.\"\"\"\n\n        def answer(question, default):\n            return 'okay to delete' not in question\n\n        mock_read_user = mocker.patch(\n            'cookiecutter.prompt.read_user_yes_no', side_effect=answer, autospec=True\n        )\n        repo_dir = Path(tmp_path, 'repo')\n        repo_dir.mkdir()\n\n&gt;       deleted = prompt.prompt_and_delete(str(repo_dir))\n\ntests/test_prompt.py:726: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/prompt.py:270: in prompt_and_delete\n    delete = read_user_yes_no(\n:3: in read_user_yes_no\n    ???\n/usr/lib/python3.10/unittest/mock.py:1114: in __call__\n    return self._mock_call(*args, **kwargs)\n/usr/lib/python3.10/unittest/mock.py:1118: in _mock_call\n    return self._execute_mock_call(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nargs = (\"You've downloaded /tmp/pytest-of-root/pytest-0/test_prompt_should_ask_and_kee1/repo before. Is it okay to delete and re-download it?\",)\nkwargs = {'default_value': True}\neffect = .answer at 0x7f1eec07a7a0&gt;\n\n    def _execute_mock_call(self, /, *args, **kwargs):\n        # separate from _increment_mock_call so that awaited functions are\n        # executed separately from their call, also AsyncMock overrides this method\n\n        effect = self.side_effect\n        if effect is not None:\n            if _is_exception(effect):\n                raise effect\n            elif not _callable(effect):\n                result = next(effect)\n                if _is_exception(result):\n                    raise result\n            else:\n&gt;               result = effect(*args, **kwargs)\nE               TypeError: test_prompt_should_ask_and_keep_repo_on_reuse..answer() got an unexpected keyword argument 'default_value'\n\n/usr/lib/python3.10/unittest/mock.py:1179: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_promptpytest_prompt_should_not_ask_if_no_input_and_rm_repo_file","title":"test_prompt.py::test_prompt_should_not_ask_if_no_input_and_rm_repo_file","text":"<pre>test_prompt.py::test_prompt_should_not_ask_if_no_input_and_rm_repo_file</pre><pre>\ntopfd = 12\npath = '/tmp/pytest-of-root/pytest-0/test_prompt_should_not_ask_if_1/repo.zip'\nonerror = \n\n    def _rmtree_safe_fd(topfd, path, onerror):\n        try:\n&gt;           with os.scandir(topfd) as scandir_it:\nE           NotADirectoryError: [Errno 20] Not a directory: '/tmp/pytest-of-root/pytest-0/test_prompt_should_not_ask_if_1/repo.zip'\n\n/usr/lib/python3.10/shutil.py:629: NotADirectoryError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_prompt_should_not_ask_if_1')\n\n    def test_prompt_should_not_ask_if_no_input_and_rm_repo_file(mocker, tmp_path):\n        \"\"\"Prompt should not ask if no input and rm file.\n\n        In `prompt_and_delete()`, if `no_input` is True, the call to\n        `prompt.read_user_yes_no()` should be suppressed.\n        \"\"\"\n        mock_read_user = mocker.patch(\n            'cookiecutter.prompt.read_user_yes_no', return_value=True, autospec=True\n        )\n\n        repo_file = tmp_path.joinpath('repo.zip')\n        repo_file.write_text('this is zipfile content')\n\n&gt;       deleted = prompt.prompt_and_delete(str(repo_file), no_input=True)\n\ntests/test_prompt.py:765: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/prompt.py:267: in prompt_and_delete\n    rmtree(path)\ncookiecutter/utils.py:30: in rmtree\n    shutil.rmtree(path, onerror=force_delete)\n/usr/lib/python3.10/shutil.py:725: in rmtree\n    _rmtree_safe_fd(fd, path, onerror)\n/usr/lib/python3.10/shutil.py:633: in _rmtree_safe_fd\n    onerror(os.scandir, path, sys.exc_info())\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nfunc = \npath = '/tmp/pytest-of-root/pytest-0/test_prompt_should_not_ask_if_1/repo.zip'\nexc_info = (, NotADirectoryError(20, 'Not a directory'), )\n\n    def force_delete(func, path, exc_info):\n        \"\"\"Error handler for `shutil.rmtree()` equivalent to `rm -rf`.\n\n        Usage: `shutil.rmtree(path, onerror=force_delete)`\n        From https://docs.python.org/3/library/shutil.html#rmtree-example\n        \"\"\"\n        os.chmod(path, stat.S_IWRITE)\n&gt;       func(path)\nE       NotADirectoryError: [Errno 20] Not a directory: '/tmp/pytest-of-root/pytest-0/test_prompt_should_not_ask_if_1/repo.zip'\n\ncookiecutter/utils.py:22: NotADirectoryError"},{"location":"analysis_baseline_cookiecutter/#test_read_user_choicepytest_click_invocation1-hello","title":"test_read_user_choice.py::test_click_invocation[1-hello]","text":"<pre>test_read_user_choice.py::test_click_invocation[1-hello]</pre><pre>\nmocker = \nuser_choice = 1, expected_value = 'hello'\n\n    @pytest.mark.parametrize('user_choice, expected_value', enumerate(OPTIONS, 1))\n    def test_click_invocation(mocker, user_choice, expected_value):\n        \"\"\"Test click function called correctly by cookiecutter.\n\n        Test for choice type invocation.\n        \"\"\"\n        prompt = mocker.patch('rich.prompt.Prompt.ask')\n        prompt.return_value = f'{user_choice}'\n\n&gt;       assert read_user_choice('varname', OPTIONS) == expected_value\nE       AssertionError: assert 'world' == 'hello'\nE         \nE         - hello\nE         + world\n\ntests/test_read_user_choice.py:27: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_read_user_choicepytest_click_invocation2-world","title":"test_read_user_choice.py::test_click_invocation[2-world]","text":"<pre>test_read_user_choice.py::test_click_invocation[2-world]</pre><pre>\nmocker = \nuser_choice = 2, expected_value = 'world'\n\n    @pytest.mark.parametrize('user_choice, expected_value', enumerate(OPTIONS, 1))\n    def test_click_invocation(mocker, user_choice, expected_value):\n        \"\"\"Test click function called correctly by cookiecutter.\n\n        Test for choice type invocation.\n        \"\"\"\n        prompt = mocker.patch('rich.prompt.Prompt.ask')\n        prompt.return_value = f'{user_choice}'\n\n&gt;       assert read_user_choice('varname', OPTIONS) == expected_value\nE       AssertionError: assert 'foo' == 'world'\nE         \nE         - world\nE         + foo\n\ntests/test_read_user_choice.py:27: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_read_user_choicepytest_click_invocation3-foo","title":"test_read_user_choice.py::test_click_invocation[3-foo]","text":"<pre>test_read_user_choice.py::test_click_invocation[3-foo]</pre><pre>\nmocker = \nuser_choice = 3, expected_value = 'foo'\n\n    @pytest.mark.parametrize('user_choice, expected_value', enumerate(OPTIONS, 1))\n    def test_click_invocation(mocker, user_choice, expected_value):\n        \"\"\"Test click function called correctly by cookiecutter.\n\n        Test for choice type invocation.\n        \"\"\"\n        prompt = mocker.patch('rich.prompt.Prompt.ask')\n        prompt.return_value = f'{user_choice}'\n\n&gt;       assert read_user_choice('varname', OPTIONS) == expected_value\nE       AssertionError: assert 'bar' == 'foo'\nE         \nE         - foo\nE         + bar\n\ntests/test_read_user_choice.py:27: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_read_user_choicepytest_click_invocation4-bar","title":"test_read_user_choice.py::test_click_invocation[4-bar]","text":"<pre>test_read_user_choice.py::test_click_invocation[4-bar]</pre><pre>\nmocker = \nuser_choice = 4, expected_value = 'bar'\n\n    @pytest.mark.parametrize('user_choice, expected_value', enumerate(OPTIONS, 1))\n    def test_click_invocation(mocker, user_choice, expected_value):\n        \"\"\"Test click function called correctly by cookiecutter.\n\n        Test for choice type invocation.\n        \"\"\"\n        prompt = mocker.patch('rich.prompt.Prompt.ask')\n        prompt.return_value = f'{user_choice}'\n\n&gt;       assert read_user_choice('varname', OPTIONS) == expected_value\n\ntests/test_read_user_choice.py:27: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nvar_name = 'varname', options = ['hello', 'world', 'foo', 'bar'], prompts = None\nprefix = ''\n\n    def read_user_choice(var_name, options, prompts=None, prefix=''):\n        \"\"\"Prompt the user to choose from several options for the given variable.\n\n        The first item will be returned if no input happens.\n\n        :param str var_name: Variable as specified in the context\n        :param list options: Sequence of options that are available to select from\n        :return: Exactly one item of ``options`` that has been chosen by the user\n        \"\"\"\n        prompt_text = f\"{prefix}{var_name}\"\n        if prompts and var_name in prompts:\n            prompt_text = prompts[var_name]\n\n        choices = [str(i) for i in range(len(options))]\n        choice_text = \"\\n\".join(f\"{i}: {option}\" for i, option in enumerate(options))\n\n        while True:\n            print(f\"{prompt_text}\\n{choice_text}\")\n            choice = Prompt.ask(\"Enter the number of your choice\", choices=choices, default=\"0\")\n&gt;           return options[int(choice)]\nE           IndexError: list index out of range\n\ncookiecutter/prompt.py:91: IndexError"},{"location":"analysis_baseline_cookiecutter/#test_read_user_choicepytest_raise_if_options_is_not_a_non_empty_list","title":"test_read_user_choice.py::test_raise_if_options_is_not_a_non_empty_list","text":"<pre>test_read_user_choice.py::test_raise_if_options_is_not_a_non_empty_list</pre><pre>\ndef test_raise_if_options_is_not_a_non_empty_list():\n        \"\"\"Test function called by cookiecutter raise expected errors.\n\n        Test for choice type invocation.\n        \"\"\"\n        with pytest.raises(TypeError):\n&gt;           read_user_choice('foo', 'NOT A LIST')\n\ntests/test_read_user_choice.py:38: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/prompt.py:90: in read_user_choice\n    choice = Prompt.ask(\"Enter the number of your choice\", choices=choices, default=\"0\")\n.venv/lib/python3.10/site-packages/rich/prompt.py:149: in ask\n    return _prompt(default=default, stream=stream)\n.venv/lib/python3.10/site-packages/rich/prompt.py:292: in __call__\n    value = self.get_input(self.console, prompt, self.password, stream=stream)\n.venv/lib/python3.10/site-packages/rich/prompt.py:211: in get_input\n    return console.input(prompt, password=password, stream=stream)\n.venv/lib/python3.10/site-packages/rich/console.py:2156: in input\n    result = input()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &lt;_pytest.capture.DontReadFromInput object at 0x7f1eeef69330&gt;, size = -1\n\n    def read(self, size: int = -1) -&gt; str:\n&gt;       raise OSError(\n            \"pytest: reading from stdin while output is captured!  Consider using `-s`.\"\n        )\nE       OSError: pytest: reading from stdin while output is captured!  Consider using `-s`.\n\n.venv/lib/python3.10/site-packages/_pytest/capture.py:209: OSError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_read_user_dictpytest_process_json_invalid_json","title":"test_read_user_dict.py::test_process_json_invalid_json","text":"<pre>test_read_user_dict.py::test_process_json_invalid_json</pre><pre>\ndef test_process_json_invalid_json():\n        \"\"\"Test `process_json` for correct error on malformed input.\"\"\"\n&gt;       with pytest.raises(InvalidResponse) as exc_info:\nE       Failed: DID NOT RAISE \n\ntests/test_read_user_dict.py:12: Failed"},{"location":"analysis_baseline_cookiecutter/#test_read_user_dictpytest_process_json_non_dict","title":"test_read_user_dict.py::test_process_json_non_dict","text":"<pre>test_read_user_dict.py::test_process_json_non_dict</pre><pre>\ndef test_process_json_non_dict():\n        \"\"\"Test `process_json` for correct error on non-JSON input.\"\"\"\n&gt;       with pytest.raises(InvalidResponse) as exc_info:\nE       Failed: DID NOT RAISE \n\ntests/test_read_user_dict.py:20: Failed"},{"location":"analysis_baseline_cookiecutter/#test_read_user_dictpytest_should_raise_type_error","title":"test_read_user_dict.py::test_should_raise_type_error","text":"<pre>test_read_user_dict.py::test_should_raise_type_error</pre><pre>\nmocker = \n\n    def test_should_raise_type_error(mocker):\n        \"\"\"Test `default_value` arg verification in `read_user_dict` function.\"\"\"\n        prompt = mocker.patch('cookiecutter.prompt.JsonPrompt.ask')\n\n&gt;       with pytest.raises(TypeError):\nE       Failed: DID NOT RAISE \n\ntests/test_read_user_dict.py:79: Failed"},{"location":"analysis_baseline_cookiecutter/#test_read_user_dictpytest_should_call_prompt_with_process_json","title":"test_read_user_dict.py::test_should_call_prompt_with_process_json","text":"<pre>test_read_user_dict.py::test_should_call_prompt_with_process_json</pre><pre>\nmocker = \n\n    def test_should_call_prompt_with_process_json(mocker):\n        \"\"\"Test to make sure that `process_json` is actually being used.\n\n        Verifies generation of a processor for the user input.\n        \"\"\"\n        mock_prompt = mocker.patch('cookiecutter.prompt.JsonPrompt.ask', autospec=True)\n\n        read_user_dict('name', {'project_slug': 'pytest-plugin'})\n        print(mock_prompt.call_args)\n        args, kwargs = mock_prompt.call_args\n\n&gt;       assert args == ('name [cyan bold](default)[/]',)\nE       AssertionError: assert ('name',) == ('name [cyan bold](default)[/]',)\nE         \nE         At index 0 diff: 'name' != 'name [cyan bold](default)[/]'\nE         \nE         Full diff:\nE           (\nE         -     'name [cyan bold](default)[/]',\nE         +     'name',\nE           )\n\ntests/test_read_user_dict.py:95: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_read_user_dictpytest_read_user_dict_default_valuen","title":"test_read_user_dict.py::test_read_user_dict_default_value[\\n]","text":"<pre>test_read_user_dict.py::test_read_user_dict_default_value[\\n]</pre><pre>\nmocker = \ninput = '\\n'\n\n    @pytest.mark.parametrize(\"input\", [\"\\n\", \"\\ndefault\\n\"])\n    def test_read_user_dict_default_value(mocker, input):\n        \"\"\"Make sure that `read_user_dict` returns the default value.\n\n        Verify return of a dict variable rather than the display value.\n        \"\"\"\n        runner = click.testing.CliRunner()\n        with runner.isolation(input=input):\n            val = read_user_dict('name', {'project_slug': 'pytest-plugin'})\n\n&gt;       assert val == {'project_slug': 'pytest-plugin'}\nE       assert '{\"project_slug\": \"pytest-plugin\"}' == {'project_slug': 'pytest-plugin'}\n\ntests/test_read_user_dict.py:122: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_read_user_dictpytest_read_user_dict_default_valuendefaultn","title":"test_read_user_dict.py::test_read_user_dict_default_value[\\ndefault\\n]","text":"<pre>test_read_user_dict.py::test_read_user_dict_default_value[\\ndefault\\n]</pre><pre>\nmocker = \ninput = '\\ndefault\\n'\n\n    @pytest.mark.parametrize(\"input\", [\"\\n\", \"\\ndefault\\n\"])\n    def test_read_user_dict_default_value(mocker, input):\n        \"\"\"Make sure that `read_user_dict` returns the default value.\n\n        Verify return of a dict variable rather than the display value.\n        \"\"\"\n        runner = click.testing.CliRunner()\n        with runner.isolation(input=input):\n            val = read_user_dict('name', {'project_slug': 'pytest-plugin'})\n\n&gt;       assert val == {'project_slug': 'pytest-plugin'}\nE       assert '{\"project_slug\": \"pytest-plugin\"}' == {'project_slug': 'pytest-plugin'}\n\ntests/test_read_user_dict.py:122: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_read_user_variablepytest_input_loop_with_null_default_value","title":"test_read_user_variable.py::test_input_loop_with_null_default_value","text":"<pre>test_read_user_variable.py::test_input_loop_with_null_default_value</pre><pre>\nmock_prompt = \n\n    def test_input_loop_with_null_default_value(mock_prompt):\n        \"\"\"Test `Prompt.ask` is run repeatedly until a valid answer is provided.\n\n        Test for `default_value` parameter equal to None.\n        \"\"\"\n        # Simulate user providing None input initially and then a valid input\n        mock_prompt.side_effect = [None, DEFAULT]\n\n&gt;       assert read_user_variable(VARIABLE, None) == DEFAULT\nE       AssertionError: assert None == 'Kivy Project'\nE        +  where None = read_user_variable('project_name', None)\n\ntests/test_read_user_variable.py:37: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_repo_not_foundpytest_should_raise_error_if_repo_does_not_exist","title":"test_repo_not_found.py::test_should_raise_error_if_repo_does_not_exist","text":"<pre>test_repo_not_found.py::test_should_raise_error_if_repo_does_not_exist</pre><pre>\ndef test_should_raise_error_if_repo_does_not_exist():\n        \"\"\"Cookiecutter invocation with non-exist repository should raise error.\"\"\"\n        with pytest.raises(exceptions.RepositoryNotFound):\n&gt;           main.cookiecutter('definitely-not-a-valid-repo-dir')\n\ntests/test_repo_not_found.py:11: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'definitely-not-a-valid-repo-dir', checkout = None, no_input = False\nextra_context = None, replay = None, overwrite_if_exists = False\noutput_dir = '.', config_file = None, default_config = False, password = None\ndirectory = None, skip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_specify_output_dirpytest_api_invocation","title":"test_specify_output_dir.py::test_api_invocation","text":"<pre>test_specify_output_dir.py::test_api_invocation</pre><pre>\nmocker = \ntemplate = '/tmp/pytest-of-root/pytest-0/test_api_invocation0/template'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_api_invocation0/output'\ncontext = {'cookiecutter': {'email': 'raphael@hackebrot.de', 'full_name': 'Raphael Pierzina', 'github_username': 'hackebrot', 'version': '0.1.0'}}\n\n    def test_api_invocation(mocker, template, output_dir, context):\n        \"\"\"Verify output dir location is correctly passed.\"\"\"\n        mock_gen_files = mocker.patch('cookiecutter.main.generate_files')\n\n&gt;       main.cookiecutter(template, output_dir=output_dir)\n\ntests/test_specify_output_dir.py:52: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = '/tmp/pytest-of-root/pytest-0/test_api_invocation0/template'\ncheckout = None, no_input = False, extra_context = None, replay = None\noverwrite_if_exists = False\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_api_invocation0/output'\nconfig_file = None, default_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_specify_output_dirpytest_default_output_dir","title":"test_specify_output_dir.py::test_default_output_dir","text":"<pre>test_specify_output_dir.py::test_default_output_dir</pre><pre>\nmocker = \ntemplate = '/tmp/pytest-of-root/pytest-0/test_default_output_dir0/template'\ncontext = {'cookiecutter': {'email': 'raphael@hackebrot.de', 'full_name': 'Raphael Pierzina', 'github_username': 'hackebrot', 'version': '0.1.0'}}\n\n    def test_default_output_dir(mocker, template, context):\n        \"\"\"Verify default output dir is current working folder.\"\"\"\n        mock_gen_files = mocker.patch('cookiecutter.main.generate_files')\n\n&gt;       main.cookiecutter(template)\n\ntests/test_specify_output_dir.py:69: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = '/tmp/pytest-of-root/pytest-0/test_default_output_dir0/template'\ncheckout = None, no_input = False, extra_context = None, replay = None\noverwrite_if_exists = False, output_dir = '.', config_file = None\ndefault_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_templatespytest_build_templatesinclude","title":"test_templates.py::test_build_templates[include]","text":"<pre>test_templates.py::test_build_templates[include]</pre><pre>\ntemplate = 'include'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_build_templates_include_0/templates'\n\n    @pytest.mark.parametrize(\"template\", [\"include\", \"no-templates\", \"extends\", \"super\"])\n    def test_build_templates(template, output_dir):\n        \"\"\"\n        Verify Templates Design keywords.\n\n        no-templates is a compatibility tests for repo without `templates` directory\n        \"\"\"\n&gt;       project_dir = main.cookiecutter(\n            f'tests/test-templates/{template}',\n            no_input=True,\n            output_dir=output_dir,\n        )\n\ntests/test_templates.py:28: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/test-templates/include', checkout = None, no_input = True\nextra_context = None, replay = None, overwrite_if_exists = False\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_build_templates_include_0/templates'\nconfig_file = None, default_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_templatespytest_build_templatesno-templates","title":"test_templates.py::test_build_templates[no-templates]","text":"<pre>test_templates.py::test_build_templates[no-templates]</pre><pre>\ntemplate = 'no-templates'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_build_templates_no_templa0/templates'\n\n    @pytest.mark.parametrize(\"template\", [\"include\", \"no-templates\", \"extends\", \"super\"])\n    def test_build_templates(template, output_dir):\n        \"\"\"\n        Verify Templates Design keywords.\n\n        no-templates is a compatibility tests for repo without `templates` directory\n        \"\"\"\n&gt;       project_dir = main.cookiecutter(\n            f'tests/test-templates/{template}',\n            no_input=True,\n            output_dir=output_dir,\n        )\n\ntests/test_templates.py:28: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/test-templates/no-templates', checkout = None, no_input = True\nextra_context = None, replay = None, overwrite_if_exists = False\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_build_templates_no_templa0/templates'\nconfig_file = None, default_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_templatespytest_build_templatesextends","title":"test_templates.py::test_build_templates[extends]","text":"<pre>test_templates.py::test_build_templates[extends]</pre><pre>\ntemplate = 'extends'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_build_templates_extends_0/templates'\n\n    @pytest.mark.parametrize(\"template\", [\"include\", \"no-templates\", \"extends\", \"super\"])\n    def test_build_templates(template, output_dir):\n        \"\"\"\n        Verify Templates Design keywords.\n\n        no-templates is a compatibility tests for repo without `templates` directory\n        \"\"\"\n&gt;       project_dir = main.cookiecutter(\n            f'tests/test-templates/{template}',\n            no_input=True,\n            output_dir=output_dir,\n        )\n\ntests/test_templates.py:28: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/test-templates/extends', checkout = None, no_input = True\nextra_context = None, replay = None, overwrite_if_exists = False\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_build_templates_extends_0/templates'\nconfig_file = None, default_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_templatespytest_build_templatessuper","title":"test_templates.py::test_build_templates[super]","text":"<pre>test_templates.py::test_build_templates[super]</pre><pre>\ntemplate = 'super'\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_build_templates_super_0/templates'\n\n    @pytest.mark.parametrize(\"template\", [\"include\", \"no-templates\", \"extends\", \"super\"])\n    def test_build_templates(template, output_dir):\n        \"\"\"\n        Verify Templates Design keywords.\n\n        no-templates is a compatibility tests for repo without `templates` directory\n        \"\"\"\n&gt;       project_dir = main.cookiecutter(\n            f'tests/test-templates/{template}',\n            no_input=True,\n            output_dir=output_dir,\n        )\n\ntests/test_templates.py:28: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntemplate = 'tests/test-templates/super', checkout = None, no_input = True\nextra_context = None, replay = None, overwrite_if_exists = False\noutput_dir = '/tmp/pytest-of-root/pytest-0/test_build_templates_super_0/templates'\nconfig_file = None, default_config = False, password = None, directory = None\nskip_if_file_exists = False, accept_hooks = True\nkeep_project_on_failure = False\n\n    def cookiecutter(template, checkout=None, no_input=False, extra_context=\n        None, replay=None, overwrite_if_exists=False, output_dir='.',\n        config_file=None, default_config=False, password=None, directory=None,\n        skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n        ):\n        \"\"\"\n        Run Cookiecutter just as if using it from the command line.\n\n        :param template: A directory containing a project template directory,\n            or a URL to a git repository.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param no_input: Do not prompt for user input.\n            Use default values for template parameters taken from `cookiecutter.json`, user\n            config and `extra_dict`. Force a refresh of cached resources.\n        :param extra_context: A dictionary of context that overrides default\n            and user configuration.\n        :param replay: Do not prompt for input, instead read from saved json. If\n            ``True`` read from the ``replay_dir``.\n            if it exists\n        :param overwrite_if_exists: Overwrite the contents of the output directory\n            if it exists.\n        :param output_dir: Where to output the generated project dir into.\n        :param config_file: User configuration file path.\n        :param default_config: Use default values rather than a config file.\n        :param password: The password to use when extracting the repository.\n        :param directory: Relative path to a cookiecutter template in a repository.\n        :param skip_if_file_exists: Skip the files in the corresponding directories\n            if they already exist.\n        :param accept_hooks: Accept pre and post hooks if set to `True`.\n        :param keep_project_on_failure: If `True` keep generated project directory even when\n            generation fails\n        \"\"\"\n        # Get user configuration\n        config_dict = get_user_config(config_file=config_file, default_config=default_config)\n\n        # Determine the template directory\n&gt;       repo_dir, cleanup = determine_repo_dir(\n            template=template,\n            checkout=checkout,\n            clone_to_dir=config_dict['cookiecutters_dir'],\n            no_input=no_input,\n            password=password,\n            directory=directory\n        )\nE       TypeError: determine_repo_dir() missing 1 required positional argument: 'abbreviations'\n\ncookiecutter/main.py:59: TypeError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_time_extensionpytest_tz_is_required","title":"test_time_extension.py::test_tz_is_required","text":"<pre>test_time_extension.py::test_tz_is_required</pre><pre>\nenvironment = \n\n    def test_tz_is_required(environment):\n        \"\"\"Verify template parsing fails without a timezone.\"\"\"\n        with pytest.raises(exceptions.TemplateSyntaxError):\n&gt;           environment.from_string('{% now %}')\n\ntests/test_time_extension.py:26: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/jinja2/environment.py:1108: in from_string\n    return cls.from_code(self, self.compile(source), gs, None)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:760: in compile\n    source = self._parse(source, name, filename)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:619: in _parse\n    return Parser(self, source, name, filename).parse()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1039: in parse\n    result = nodes.Template(self.subparse(), lineno=1)\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1022: in subparse\n    rv = self.parse_statement()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:184: in parse_statement\n    return ext(self)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nparser = \n\n    def parse(self, parser):\n        \"\"\"Parse datetime template and add datetime value.\"\"\"\n        lineno = next(parser.stream).lineno\n&gt;       token = parser.stream.next()\nE       AttributeError: 'TokenStream' object has no attribute 'next'\n\ncookiecutter/extensions.py:79: AttributeError"},{"location":"analysis_baseline_cookiecutter/#test_time_extensionpytest_utc_default_datetime_format","title":"test_time_extension.py::test_utc_default_datetime_format","text":"<pre>test_time_extension.py::test_utc_default_datetime_format</pre><pre>\nenvironment = \n\n    def test_utc_default_datetime_format(environment):\n        \"\"\"Verify default datetime format can be parsed.\"\"\"\n&gt;       template = environment.from_string(\"{% now 'utc' %}\")\n\ntests/test_time_extension.py:31: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/jinja2/environment.py:1108: in from_string\n    return cls.from_code(self, self.compile(source), gs, None)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:760: in compile\n    source = self._parse(source, name, filename)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:619: in _parse\n    return Parser(self, source, name, filename).parse()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1039: in parse\n    result = nodes.Template(self.subparse(), lineno=1)\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1022: in subparse\n    rv = self.parse_statement()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:184: in parse_statement\n    return ext(self)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nparser = \n\n    def parse(self, parser):\n        \"\"\"Parse datetime template and add datetime value.\"\"\"\n        lineno = next(parser.stream).lineno\n&gt;       token = parser.stream.next()\nE       AttributeError: 'TokenStream' object has no attribute 'next'\n\ncookiecutter/extensions.py:79: AttributeError"},{"location":"analysis_baseline_cookiecutter/#test_time_extensionpytest_accept_valid_timezonesutc","title":"test_time_extension.py::test_accept_valid_timezones[utc]","text":"<pre>test_time_extension.py::test_accept_valid_timezones[utc]</pre><pre>\nenvironment = \nvalid_tz = 'utc'\n\n    @pytest.mark.parametrize(\"valid_tz\", ['utc', 'local', 'Europe/Berlin'])\n    def test_accept_valid_timezones(environment, valid_tz):\n        \"\"\"Verify that valid timezones are accepted.\"\"\"\n&gt;       template = environment.from_string(f\"{{% now '{valid_tz}', '%Y-%m' %}}\")\n\ntests/test_time_extension.py:39: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/jinja2/environment.py:1108: in from_string\n    return cls.from_code(self, self.compile(source), gs, None)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:760: in compile\n    source = self._parse(source, name, filename)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:619: in _parse\n    return Parser(self, source, name, filename).parse()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1039: in parse\n    result = nodes.Template(self.subparse(), lineno=1)\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1022: in subparse\n    rv = self.parse_statement()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:184: in parse_statement\n    return ext(self)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nparser = \n\n    def parse(self, parser):\n        \"\"\"Parse datetime template and add datetime value.\"\"\"\n        lineno = next(parser.stream).lineno\n&gt;       token = parser.stream.next()\nE       AttributeError: 'TokenStream' object has no attribute 'next'\n\ncookiecutter/extensions.py:79: AttributeError"},{"location":"analysis_baseline_cookiecutter/#test_time_extensionpytest_accept_valid_timezoneslocal","title":"test_time_extension.py::test_accept_valid_timezones[local]","text":"<pre>test_time_extension.py::test_accept_valid_timezones[local]</pre><pre>\nenvironment = \nvalid_tz = 'local'\n\n    @pytest.mark.parametrize(\"valid_tz\", ['utc', 'local', 'Europe/Berlin'])\n    def test_accept_valid_timezones(environment, valid_tz):\n        \"\"\"Verify that valid timezones are accepted.\"\"\"\n&gt;       template = environment.from_string(f\"{{% now '{valid_tz}', '%Y-%m' %}}\")\n\ntests/test_time_extension.py:39: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/jinja2/environment.py:1108: in from_string\n    return cls.from_code(self, self.compile(source), gs, None)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:760: in compile\n    source = self._parse(source, name, filename)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:619: in _parse\n    return Parser(self, source, name, filename).parse()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1039: in parse\n    result = nodes.Template(self.subparse(), lineno=1)\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1022: in subparse\n    rv = self.parse_statement()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:184: in parse_statement\n    return ext(self)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nparser = \n\n    def parse(self, parser):\n        \"\"\"Parse datetime template and add datetime value.\"\"\"\n        lineno = next(parser.stream).lineno\n&gt;       token = parser.stream.next()\nE       AttributeError: 'TokenStream' object has no attribute 'next'\n\ncookiecutter/extensions.py:79: AttributeError"},{"location":"analysis_baseline_cookiecutter/#berlin","title":"Berlin]","text":"<pre>Berlin]</pre><pre>\nenvironment = \nvalid_tz = 'Europe/Berlin'\n\n    @pytest.mark.parametrize(\"valid_tz\", ['utc', 'local', 'Europe/Berlin'])\n    def test_accept_valid_timezones(environment, valid_tz):\n        \"\"\"Verify that valid timezones are accepted.\"\"\"\n&gt;       template = environment.from_string(f\"{{% now '{valid_tz}', '%Y-%m' %}}\")\n\ntests/test_time_extension.py:39: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/jinja2/environment.py:1108: in from_string\n    return cls.from_code(self, self.compile(source), gs, None)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:760: in compile\n    source = self._parse(source, name, filename)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:619: in _parse\n    return Parser(self, source, name, filename).parse()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1039: in parse\n    result = nodes.Template(self.subparse(), lineno=1)\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1022: in subparse\n    rv = self.parse_statement()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:184: in parse_statement\n    return ext(self)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nparser = \n\n    def parse(self, parser):\n        \"\"\"Parse datetime template and add datetime value.\"\"\"\n        lineno = next(parser.stream).lineno\n&gt;       token = parser.stream.next()\nE       AttributeError: 'TokenStream' object has no attribute 'next'\n\ncookiecutter/extensions.py:79: AttributeError"},{"location":"analysis_baseline_cookiecutter/#test_time_extensionpytest_environment_datetime_format","title":"test_time_extension.py::test_environment_datetime_format","text":"<pre>test_time_extension.py::test_environment_datetime_format</pre><pre>\nenvironment = \n\n    def test_environment_datetime_format(environment):\n        \"\"\"Verify datetime format can be parsed from environment.\"\"\"\n        environment.datetime_format = '%a, %d %b %Y %H:%M:%S'\n\n&gt;       template = environment.from_string(\"{% now 'utc' %}\")\n\ntests/test_time_extension.py:48: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/jinja2/environment.py:1108: in from_string\n    return cls.from_code(self, self.compile(source), gs, None)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:760: in compile\n    source = self._parse(source, name, filename)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:619: in _parse\n    return Parser(self, source, name, filename).parse()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1039: in parse\n    result = nodes.Template(self.subparse(), lineno=1)\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1022: in subparse\n    rv = self.parse_statement()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:184: in parse_statement\n    return ext(self)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nparser = \n\n    def parse(self, parser):\n        \"\"\"Parse datetime template and add datetime value.\"\"\"\n        lineno = next(parser.stream).lineno\n&gt;       token = parser.stream.next()\nE       AttributeError: 'TokenStream' object has no attribute 'next'\n\ncookiecutter/extensions.py:79: AttributeError"},{"location":"analysis_baseline_cookiecutter/#test_time_extensionpytest_add_time","title":"test_time_extension.py::test_add_time","text":"<pre>test_time_extension.py::test_add_time</pre><pre>\nenvironment = \n\n    def test_add_time(environment):\n        \"\"\"Verify that added time offset can be parsed.\"\"\"\n        environment.datetime_format = '%a, %d %b %Y %H:%M:%S'\n\n&gt;       template = environment.from_string(\"{% now 'utc' + 'hours=2,seconds=30' %}\")\n\ntests/test_time_extension.py:57: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/jinja2/environment.py:1108: in from_string\n    return cls.from_code(self, self.compile(source), gs, None)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:760: in compile\n    source = self._parse(source, name, filename)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:619: in _parse\n    return Parser(self, source, name, filename).parse()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1039: in parse\n    result = nodes.Template(self.subparse(), lineno=1)\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1022: in subparse\n    rv = self.parse_statement()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:184: in parse_statement\n    return ext(self)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nparser = \n\n    def parse(self, parser):\n        \"\"\"Parse datetime template and add datetime value.\"\"\"\n        lineno = next(parser.stream).lineno\n&gt;       token = parser.stream.next()\nE       AttributeError: 'TokenStream' object has no attribute 'next'\n\ncookiecutter/extensions.py:79: AttributeError"},{"location":"analysis_baseline_cookiecutter/#test_time_extensionpytest_substract_time","title":"test_time_extension.py::test_substract_time","text":"<pre>test_time_extension.py::test_substract_time</pre><pre>\nenvironment = \n\n    def test_substract_time(environment):\n        \"\"\"Verify that substracted time offset can be parsed.\"\"\"\n        environment.datetime_format = '%a, %d %b %Y %H:%M:%S'\n\n&gt;       template = environment.from_string(\"{% now 'utc' - 'minutes=11' %}\")\n\ntests/test_time_extension.py:66: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/jinja2/environment.py:1108: in from_string\n    return cls.from_code(self, self.compile(source), gs, None)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:760: in compile\n    source = self._parse(source, name, filename)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:619: in _parse\n    return Parser(self, source, name, filename).parse()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1039: in parse\n    result = nodes.Template(self.subparse(), lineno=1)\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1022: in subparse\n    rv = self.parse_statement()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:184: in parse_statement\n    return ext(self)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nparser = \n\n    def parse(self, parser):\n        \"\"\"Parse datetime template and add datetime value.\"\"\"\n        lineno = next(parser.stream).lineno\n&gt;       token = parser.stream.next()\nE       AttributeError: 'TokenStream' object has no attribute 'next'\n\ncookiecutter/extensions.py:79: AttributeError"},{"location":"analysis_baseline_cookiecutter/#test_time_extensionpytest_offset_with_format","title":"test_time_extension.py::test_offset_with_format","text":"<pre>test_time_extension.py::test_offset_with_format</pre><pre>\nenvironment = \n\n    def test_offset_with_format(environment):\n        \"\"\"Verify that offset works together with datetime format.\"\"\"\n        environment.datetime_format = '%d %b %Y %H:%M:%S'\n\n&gt;       template = environment.from_string(\n            \"{% now 'utc' - 'days=2,minutes=33,seconds=1', '%d %b %Y %H:%M:%S' %}\"\n        )\n\ntests/test_time_extension.py:75: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/jinja2/environment.py:1108: in from_string\n    return cls.from_code(self, self.compile(source), gs, None)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:760: in compile\n    source = self._parse(source, name, filename)\n.venv/lib/python3.10/site-packages/jinja2/environment.py:619: in _parse\n    return Parser(self, source, name, filename).parse()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1039: in parse\n    result = nodes.Template(self.subparse(), lineno=1)\n.venv/lib/python3.10/site-packages/jinja2/parser.py:1022: in subparse\n    rv = self.parse_statement()\n.venv/lib/python3.10/site-packages/jinja2/parser.py:184: in parse_statement\n    return ext(self)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nparser = \n\n    def parse(self, parser):\n        \"\"\"Parse datetime template and add datetime value.\"\"\"\n        lineno = next(parser.stream).lineno\n&gt;       token = parser.stream.next()\nE       AttributeError: 'TokenStream' object has no attribute 'next'\n\ncookiecutter/extensions.py:79: AttributeError"},{"location":"analysis_baseline_cookiecutter/#test_utilspytest_make_sure_path_exists_correctly_handle_os_error","title":"test_utils.py::test_make_sure_path_exists_correctly_handle_os_error","text":"<pre>test_utils.py::test_make_sure_path_exists_correctly_handle_os_error</pre><pre>\nmocker = \n\n    def test_make_sure_path_exists_correctly_handle_os_error(mocker):\n        \"\"\"Verify correct True/False response from `utils.make_sure_path_exists`.\n\n        Should return True if directory exist or created.\n        Should return False if impossible to create directory (for example protected)\n        \"\"\"\n        mocker.patch(\"pathlib.Path.mkdir\", side_effect=OSError)\n&gt;       with pytest.raises(OSError) as err:\nE       Failed: DID NOT RAISE \n\ntests/test_utils.py:70: Failed"},{"location":"analysis_baseline_cookiecutter/#test_utilspytest_create_tmp_repo_dir","title":"test_utils.py::test_create_tmp_repo_dir","text":"<pre>test_utils.py::test_create_tmp_repo_dir</pre><pre>\ntmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/test_create_tmp_repo_dir0')\n\n    def test_create_tmp_repo_dir(tmp_path):\n        \"\"\"Verify `utils.create_tmp_repo_dir` creates a copy.\"\"\"\n        repo_dir = Path(tmp_path) / 'bar'\n        repo_dir.mkdir()\n        subdirs = ('foo', 'bar', 'foobar')\n        for name in subdirs:\n            (repo_dir / name).mkdir()\n\n&gt;       new_repo_dir = utils.create_tmp_repo_dir(repo_dir)\n\ntests/test_utils.py:108: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/utils.py:78: in create_tmp_repo_dir\n    shutil.copytree(repo_dir, temp_dir, symlinks=True)\n/usr/lib/python3.10/shutil.py:559: in copytree\n    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n/usr/lib/python3.10/shutil.py:457: in _copytree\n    os.makedirs(dst, exist_ok=dirs_exist_ok)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = PosixPath('/tmp/tmpkrqk3p56'), mode = 511, exist_ok = False\n\n    def makedirs(name, mode=0o777, exist_ok=False):\n        \"\"\"makedirs(name [, mode=0o777][, exist_ok=False])\n\n        Super-mkdir; create a leaf directory and all intermediate ones.  Works like\n        mkdir, except that any intermediate path segment (not just the rightmost)\n        will be created if it does not exist. If the target directory already\n        exists, raise an OSError if exist_ok is False. Otherwise no exception is\n        raised.  This is recursive.\n\n        \"\"\"\n        head, tail = path.split(name)\n        if not tail:\n            head, tail = path.split(head)\n        if head and tail and not path.exists(head):\n            try:\n                makedirs(head, exist_ok=exist_ok)\n            except FileExistsError:\n                # Defeats race condition when another thread created the path\n                pass\n            cdir = curdir\n            if isinstance(tail, bytes):\n                cdir = bytes(curdir, 'ASCII')\n            if tail == cdir:           # xxx/newdir/. exists if xxx/newdir exists\n                return\n        try:\n&gt;           mkdir(name, mode)\nE           FileExistsError: [Errno 17] File exists: '/tmp/tmpkrqk3p56'\n\n/usr/lib/python3.10/os.py:225: FileExistsError\n</pre>"},{"location":"analysis_baseline_cookiecutter/#test_clonepytest_clone_should_rstrip_trailing_slash_in_repo_url","title":"test_clone.py::test_clone_should_rstrip_trailing_slash_in_repo_url","text":"<pre>test_clone.py::test_clone_should_rstrip_trailing_slash_in_repo_url</pre><pre>\nself = \nargs = (['git', 'clone', 'https://github.com/foo/bar'],)\nkwargs = {'cwd': PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir'), 'stderr': -2}\nexpected = call('', (['git', 'clone', 'https://github.com/foo/bar'],), {'cwd': PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir'), 'stderr': -2})\nactual = call('', (['git', 'clone', 'https://github.com/foo/bar/', '/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir/bar'],), {'stderr': -2})\n_error_message = ._error_message at 0x7f1eec0779a0&gt;\ncause = None\n\n    def assert_called_with(self, /, *args, **kwargs):\n        \"\"\"assert that the last call was made with the specified arguments.\n\n        Raises an AssertionError if the args and keyword args passed in are\n        different to the last call to the mock.\"\"\"\n        if self.call_args is None:\n            expected = self._format_mock_call_signature(args, kwargs)\n            actual = 'not called.'\n            error_message = ('expected call not found.\\nExpected: %s\\nActual: %s'\n                    % (expected, actual))\n            raise AssertionError(error_message)\n\n        def _error_message():\n            msg = self._format_mock_failure_message(args, kwargs)\n            return msg\n        expected = self._call_matcher(_Call((args, kwargs), two=True))\n        actual = self._call_matcher(self.call_args)\n        if actual != expected:\n            cause = expected if isinstance(expected, Exception) else None\n&gt;           raise AssertionError(_error_message()) from cause\nE           AssertionError: expected call not found.\nE           Expected: check_output(['git', 'clone', 'https://github.com/foo/bar'], cwd=PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir'), stderr=-2)\nE           Actual: check_output(['git', 'clone', 'https://github.com/foo/bar/', '/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir/bar'], stderr=-2)\n\n/usr/lib/python3.10/unittest/mock.py:929: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = \nargs = (['git', 'clone', 'https://github.com/foo/bar'],)\nkwargs = {'cwd': PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir'), 'stderr': -2}\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n            raise AssertionError(msg)\n&gt;       return self.assert_called_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: check_output(['git', 'clone', 'https://github.com/foo/bar'], cwd=PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir'), stderr=-2)\nE       Actual: check_output(['git', 'clone', 'https://github.com/foo/bar/', '/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir/bar'], stderr=-2)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert (['git', 'clone', 'https://github.com/foo/bar/', '/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir/bar'],) == (['git', 'clone', 'https://github.com/foo/bar'],)\nE         \nE         At index 0 diff: ['git', 'clone', 'https://github.com/foo/bar/', '/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir/bar'] != ['git', 'clone', 'https://github.com/foo/bar']\nE         \nE         Full diff:\nE           (\nE               [\nE                   'git',\nE                   'clone',\nE         -         'https://github.com/foo/bar',\nE         +         'https://github.com/foo/bar/',\nE         ?                                    +\nE         +         '/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir/bar',\nE               ],\nE           )\nE       Kwargs:\nE       assert {'stderr': -2} == {'cwd': PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir'), 'stderr': -2}\nE         \nE         Common items:\nE         {'stderr': -2}\nE         Right contains 1 more item:\nE         {'cwd': PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir')}\nE         \nE         Full diff:\nE           {\nE         -     'cwd': PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir'),\nE               'stderr': -2,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:941: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir')\n\n    def test_clone_should_rstrip_trailing_slash_in_repo_url(mocker, clone_dir):\n        \"\"\"In `clone()`, repo URL's trailing slash should be stripped if one is \\\n        present.\"\"\"\n        mocker.patch('cookiecutter.vcs.is_vcs_installed', autospec=True, return_value=True)\n\n        mock_subprocess = mocker.patch(\n            'cookiecutter.vcs.subprocess.check_output',\n            autospec=True,\n        )\n\n        vcs.clone('https://github.com/foo/bar/', clone_to_dir=clone_dir, no_input=True)\n\n&gt;       mock_subprocess.assert_called_once_with(\n            ['git', 'clone', 'https://github.com/foo/bar'],\n            cwd=clone_dir,\n            stderr=subprocess.STDOUT,\n        )\n\ntests/vcs/test_clone.py:34: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (['git', 'clone', 'https://github.com/foo/bar'],)\nkwargs = {'cwd': PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir'), 'stderr': -2}\n\n    def assert_called_once_with(*args, **kwargs):\n&gt;       return mock.assert_called_once_with(*args, **kwargs)\nE       AssertionError: expected call not found.\nE       Expected: check_output(['git', 'clone', 'https://github.com/foo/bar'], cwd=PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir'), stderr=-2)\nE       Actual: check_output(['git', 'clone', 'https://github.com/foo/bar/', '/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir/bar'], stderr=-2)\nE       \nE       pytest introspection follows:\nE       \nE       Args:\nE       assert (['git', 'clone', 'https://github.com/foo/bar/', '/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir/bar'],) == (['git', 'clone', 'https://github.com/foo/bar'],)\nE         \nE         At index 0 diff: ['git', 'clone', 'https://github.com/foo/bar/', '/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir/bar'] != ['git', 'clone', 'https://github.com/foo/bar']\nE         \nE         Full diff:\nE           (\nE               [\nE                   'git',\nE                   'clone',\nE         -         'https://github.com/foo/bar',\nE         +         'https://github.com/foo/bar/',\nE         ?                                    +\nE         +         '/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir/bar',\nE               ],\nE           )\nE       Kwargs:\nE       assert {'stderr': -2} == {'cwd': PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir'), 'stderr': -2}\nE         \nE         Common items:\nE         {'stderr': -2}\nE         Right contains 1 more item:\nE         {'cwd': PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir')}\nE         \nE         Full diff:\nE           {\nE         -     'cwd': PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_rstrip_trail0/clone_dir'),\nE               'stderr': -2,\nE           }\n\n/usr/lib/python3.10/unittest/mock.py:213: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clonepytest_clone_should_silent_exit_if_ok_to_reuse","title":"test_clone.py::test_clone_should_silent_exit_if_ok_to_reuse","text":"<pre>test_clone.py::test_clone_should_silent_exit_if_ok_to_reuse</pre><pre>\nmocker = \ntmpdir = local('/tmp/pytest-of-root/pytest-0/test_clone_should_silent_exit_0')\n\n    def test_clone_should_silent_exit_if_ok_to_reuse(mocker, tmpdir):\n        \"\"\"In `clone()`, if user doesn't want to reclone, Cookiecutter should exit \\\n        without cloning anything.\"\"\"\n        mocker.patch('cookiecutter.vcs.is_vcs_installed', autospec=True, return_value=True)\n        mocker.patch(\n            'cookiecutter.vcs.prompt_and_delete', return_value=False, autospec=True\n        )\n        mock_subprocess = mocker.patch(\n            'cookiecutter.vcs.subprocess.check_output',\n            autospec=True,\n        )\n\n        clone_to_dir = tmpdir.mkdir('clone')\n\n        # Create repo_dir to trigger prompt_and_delete\n        clone_to_dir.mkdir('cookiecutter-pytest-plugin')\n\n        repo_url = 'https://github.com/pytest-dev/cookiecutter-pytest-plugin.git'\n\n        vcs.clone(repo_url, clone_to_dir=str(clone_to_dir))\n&gt;       assert not mock_subprocess.called\nE       assert not True\nE        +  where True = .called\n\ntests/vcs/test_clone.py:84: AssertionError"},{"location":"analysis_baseline_cookiecutter/#worldgit-world","title":"world.git-world]","text":"<pre>world.git-world]</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_invoke_vcs_c0/clone_dir')\nrepo_type = 'git', repo_url = 'https://github.com/hello/world.git'\nrepo_name = 'world'\n\n    @pytest.mark.parametrize(\n        'repo_type, repo_url, repo_name',\n        [\n            ('git', 'https://github.com/hello/world.git', 'world'),\n            ('hg', 'https://bitbucket.org/foo/bar', 'bar'),\n            ('git', 'git@host:gitoliterepo', 'gitoliterepo'),\n            ('git', 'git@gitlab.com:cookiecutter/cookiecutter.git', 'cookiecutter'),\n            ('git', 'git@github.com:cookiecutter/cookiecutter.git', 'cookiecutter'),\n        ],\n    )\n    def test_clone_should_invoke_vcs_command(\n        mocker, clone_dir, repo_type, repo_url, repo_name\n    ):\n        \"\"\"When `clone()` is called with a git/hg repo, the corresponding VCS \\\n        command should be run via `subprocess.check_output()`.\n\n        This should take place:\n        * In the correct dir\n        * With the correct args.\n        \"\"\"\n        mocker.patch('cookiecutter.vcs.is_vcs_installed', autospec=True, return_value=True)\n\n        mock_subprocess = mocker.patch(\n            'cookiecutter.vcs.subprocess.check_output',\n            autospec=True,\n        )\n        expected_repo_dir = os.path.normpath(os.path.join(clone_dir, repo_name))\n\n        branch = 'foobar'\n\n&gt;       repo_dir = vcs.clone(\n            repo_url, checkout=branch, clone_to_dir=clone_dir, no_input=True\n        )\n\ntests/vcs/test_clone.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_url = 'https://github.com/hello/world.git', checkout = 'foobar'\nclone_to_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_invoke_vcs_c0/clone_dir')\nno_input = True\n\n    def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n        'os.PathLike[str]'='.', no_input: bool=False):\n        \"\"\"Clone a repo to the current directory.\n\n        :param repo_url: Repo URL of unknown type.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param clone_to_dir: The directory to clone to.\n                             Defaults to the current directory.\n        :param no_input: Do not prompt for user input and eventually force a refresh of\n            cached resources.\n        :returns: str with path to the new directory of the repository.\n        \"\"\"\n        repo_type, repo_url = identify_repo(repo_url)\n        if repo_type is None:\n            raise UnknownRepoType(f\"Couldn't determine repository type for {repo_url}\")\n\n        if not is_vcs_installed(repo_type):\n            raise VCSNotInstalled(f\"{repo_type} is not installed.\")\n\n        clone_to_dir = Path(clone_to_dir).resolve()\n        make_sure_path_exists(clone_to_dir)\n\n        repo_dir = clone_to_dir / Path(repo_url).stem\n\n        if repo_dir.exists():\n            if no_input:\n                logger.warning(\"'%s' directory already exists, deleting it\", repo_dir)\n                subprocess.check_call([repo_type, 'init', str(repo_dir)])\n            else:\n                prompt_and_delete(repo_dir)\n\n        if repo_type == 'git':\n            clone_cmd = ['git', 'clone', repo_url, str(repo_dir)]\n        else:  # hg\n            clone_cmd = ['hg', 'clone', repo_url, str(repo_dir)]\n\n        try:\n            subprocess.check_output(clone_cmd, stderr=subprocess.STDOUT)\n        except subprocess.CalledProcessError as e:\n            output = e.output.decode('utf-8')\n            if 'Repository not found' in output:\n                raise RepositoryNotFound(f\"The repository {repo_url} could not be found\")\n            else:\n                raise RepositoryCloneFailed(f\"Cloning {repo_url} failed: {output}\")\n\n        if checkout:\n            if repo_type == 'git':\n                checkout_cmd = ['git', 'checkout', checkout]\n            else:  # hg\n                checkout_cmd = ['hg', 'update', checkout]\n\n            with Path.cwd():\n&gt;               os.chdir(repo_dir)\nE               FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pytest-of-root/pytest-0/test_clone_should_invoke_vcs_c0/clone_dir/world'\n\ncookiecutter/vcs.py:101: FileNotFoundError"},{"location":"analysis_baseline_cookiecutter/#bar-bar","title":"bar-bar]","text":"<pre>bar-bar]</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_invoke_vcs_c1/clone_dir')\nrepo_type = 'hg', repo_url = 'https://bitbucket.org/foo/bar', repo_name = 'bar'\n\n    @pytest.mark.parametrize(\n        'repo_type, repo_url, repo_name',\n        [\n            ('git', 'https://github.com/hello/world.git', 'world'),\n            ('hg', 'https://bitbucket.org/foo/bar', 'bar'),\n            ('git', 'git@host:gitoliterepo', 'gitoliterepo'),\n            ('git', 'git@gitlab.com:cookiecutter/cookiecutter.git', 'cookiecutter'),\n            ('git', 'git@github.com:cookiecutter/cookiecutter.git', 'cookiecutter'),\n        ],\n    )\n    def test_clone_should_invoke_vcs_command(\n        mocker, clone_dir, repo_type, repo_url, repo_name\n    ):\n        \"\"\"When `clone()` is called with a git/hg repo, the corresponding VCS \\\n        command should be run via `subprocess.check_output()`.\n\n        This should take place:\n        * In the correct dir\n        * With the correct args.\n        \"\"\"\n        mocker.patch('cookiecutter.vcs.is_vcs_installed', autospec=True, return_value=True)\n\n        mock_subprocess = mocker.patch(\n            'cookiecutter.vcs.subprocess.check_output',\n            autospec=True,\n        )\n        expected_repo_dir = os.path.normpath(os.path.join(clone_dir, repo_name))\n\n        branch = 'foobar'\n\n&gt;       repo_dir = vcs.clone(\n            repo_url, checkout=branch, clone_to_dir=clone_dir, no_input=True\n        )\n\ntests/vcs/test_clone.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_url = 'https://bitbucket.org/foo/bar', checkout = 'foobar'\nclone_to_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_invoke_vcs_c1/clone_dir')\nno_input = True\n\n    def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n        'os.PathLike[str]'='.', no_input: bool=False):\n        \"\"\"Clone a repo to the current directory.\n\n        :param repo_url: Repo URL of unknown type.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param clone_to_dir: The directory to clone to.\n                             Defaults to the current directory.\n        :param no_input: Do not prompt for user input and eventually force a refresh of\n            cached resources.\n        :returns: str with path to the new directory of the repository.\n        \"\"\"\n        repo_type, repo_url = identify_repo(repo_url)\n        if repo_type is None:\n            raise UnknownRepoType(f\"Couldn't determine repository type for {repo_url}\")\n\n        if not is_vcs_installed(repo_type):\n            raise VCSNotInstalled(f\"{repo_type} is not installed.\")\n\n        clone_to_dir = Path(clone_to_dir).resolve()\n        make_sure_path_exists(clone_to_dir)\n\n        repo_dir = clone_to_dir / Path(repo_url).stem\n\n        if repo_dir.exists():\n            if no_input:\n                logger.warning(\"'%s' directory already exists, deleting it\", repo_dir)\n                subprocess.check_call([repo_type, 'init', str(repo_dir)])\n            else:\n                prompt_and_delete(repo_dir)\n\n        if repo_type == 'git':\n            clone_cmd = ['git', 'clone', repo_url, str(repo_dir)]\n        else:  # hg\n            clone_cmd = ['hg', 'clone', repo_url, str(repo_dir)]\n\n        try:\n            subprocess.check_output(clone_cmd, stderr=subprocess.STDOUT)\n        except subprocess.CalledProcessError as e:\n            output = e.output.decode('utf-8')\n            if 'Repository not found' in output:\n                raise RepositoryNotFound(f\"The repository {repo_url} could not be found\")\n            else:\n                raise RepositoryCloneFailed(f\"Cloning {repo_url} failed: {output}\")\n\n        if checkout:\n            if repo_type == 'git':\n                checkout_cmd = ['git', 'checkout', checkout]\n            else:  # hg\n                checkout_cmd = ['hg', 'update', checkout]\n\n            with Path.cwd():\n&gt;               os.chdir(repo_dir)\nE               FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pytest-of-root/pytest-0/test_clone_should_invoke_vcs_c1/clone_dir/bar'\n\ncookiecutter/vcs.py:101: FileNotFoundError"},{"location":"analysis_baseline_cookiecutter/#test_clonepytest_clone_should_invoke_vcs_commandgit-githostgitoliterepo-gitoliterepo","title":"test_clone.py::test_clone_should_invoke_vcs_command[git-git@host:gitoliterepo-gitoliterepo]","text":"<pre>test_clone.py::test_clone_should_invoke_vcs_command[git-git@host:gitoliterepo-gitoliterepo]</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_invoke_vcs_c2/clone_dir')\nrepo_type = 'git', repo_url = 'git@host:gitoliterepo'\nrepo_name = 'gitoliterepo'\n\n    @pytest.mark.parametrize(\n        'repo_type, repo_url, repo_name',\n        [\n            ('git', 'https://github.com/hello/world.git', 'world'),\n            ('hg', 'https://bitbucket.org/foo/bar', 'bar'),\n            ('git', 'git@host:gitoliterepo', 'gitoliterepo'),\n            ('git', 'git@gitlab.com:cookiecutter/cookiecutter.git', 'cookiecutter'),\n            ('git', 'git@github.com:cookiecutter/cookiecutter.git', 'cookiecutter'),\n        ],\n    )\n    def test_clone_should_invoke_vcs_command(\n        mocker, clone_dir, repo_type, repo_url, repo_name\n    ):\n        \"\"\"When `clone()` is called with a git/hg repo, the corresponding VCS \\\n        command should be run via `subprocess.check_output()`.\n\n        This should take place:\n        * In the correct dir\n        * With the correct args.\n        \"\"\"\n        mocker.patch('cookiecutter.vcs.is_vcs_installed', autospec=True, return_value=True)\n\n        mock_subprocess = mocker.patch(\n            'cookiecutter.vcs.subprocess.check_output',\n            autospec=True,\n        )\n        expected_repo_dir = os.path.normpath(os.path.join(clone_dir, repo_name))\n\n        branch = 'foobar'\n\n&gt;       repo_dir = vcs.clone(\n            repo_url, checkout=branch, clone_to_dir=clone_dir, no_input=True\n        )\n\ntests/vcs/test_clone.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_url = 'git@host:gitoliterepo', checkout = 'foobar'\nclone_to_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_invoke_vcs_c2/clone_dir')\nno_input = True\n\n    def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n        'os.PathLike[str]'='.', no_input: bool=False):\n        \"\"\"Clone a repo to the current directory.\n\n        :param repo_url: Repo URL of unknown type.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param clone_to_dir: The directory to clone to.\n                             Defaults to the current directory.\n        :param no_input: Do not prompt for user input and eventually force a refresh of\n            cached resources.\n        :returns: str with path to the new directory of the repository.\n        \"\"\"\n&gt;       repo_type, repo_url = identify_repo(repo_url)\nE       TypeError: cannot unpack non-iterable NoneType object\n\ncookiecutter/vcs.py:61: TypeError"},{"location":"analysis_baseline_cookiecutter/#cookiecuttergit-cookiecutter","title":"cookiecutter.git-cookiecutter]","text":"<pre>cookiecutter.git-cookiecutter]</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_invoke_vcs_c3/clone_dir')\nrepo_type = 'git', repo_url = 'git@gitlab.com:cookiecutter/cookiecutter.git'\nrepo_name = 'cookiecutter'\n\n    @pytest.mark.parametrize(\n        'repo_type, repo_url, repo_name',\n        [\n            ('git', 'https://github.com/hello/world.git', 'world'),\n            ('hg', 'https://bitbucket.org/foo/bar', 'bar'),\n            ('git', 'git@host:gitoliterepo', 'gitoliterepo'),\n            ('git', 'git@gitlab.com:cookiecutter/cookiecutter.git', 'cookiecutter'),\n            ('git', 'git@github.com:cookiecutter/cookiecutter.git', 'cookiecutter'),\n        ],\n    )\n    def test_clone_should_invoke_vcs_command(\n        mocker, clone_dir, repo_type, repo_url, repo_name\n    ):\n        \"\"\"When `clone()` is called with a git/hg repo, the corresponding VCS \\\n        command should be run via `subprocess.check_output()`.\n\n        This should take place:\n        * In the correct dir\n        * With the correct args.\n        \"\"\"\n        mocker.patch('cookiecutter.vcs.is_vcs_installed', autospec=True, return_value=True)\n\n        mock_subprocess = mocker.patch(\n            'cookiecutter.vcs.subprocess.check_output',\n            autospec=True,\n        )\n        expected_repo_dir = os.path.normpath(os.path.join(clone_dir, repo_name))\n\n        branch = 'foobar'\n\n&gt;       repo_dir = vcs.clone(\n            repo_url, checkout=branch, clone_to_dir=clone_dir, no_input=True\n        )\n\ntests/vcs/test_clone.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_url = 'git@gitlab.com:cookiecutter/cookiecutter.git', checkout = 'foobar'\nclone_to_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_invoke_vcs_c3/clone_dir')\nno_input = True\n\n    def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n        'os.PathLike[str]'='.', no_input: bool=False):\n        \"\"\"Clone a repo to the current directory.\n\n        :param repo_url: Repo URL of unknown type.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param clone_to_dir: The directory to clone to.\n                             Defaults to the current directory.\n        :param no_input: Do not prompt for user input and eventually force a refresh of\n            cached resources.\n        :returns: str with path to the new directory of the repository.\n        \"\"\"\n        repo_type, repo_url = identify_repo(repo_url)\n        if repo_type is None:\n            raise UnknownRepoType(f\"Couldn't determine repository type for {repo_url}\")\n\n        if not is_vcs_installed(repo_type):\n            raise VCSNotInstalled(f\"{repo_type} is not installed.\")\n\n        clone_to_dir = Path(clone_to_dir).resolve()\n        make_sure_path_exists(clone_to_dir)\n\n        repo_dir = clone_to_dir / Path(repo_url).stem\n\n        if repo_dir.exists():\n            if no_input:\n                logger.warning(\"'%s' directory already exists, deleting it\", repo_dir)\n                subprocess.check_call([repo_type, 'init', str(repo_dir)])\n            else:\n                prompt_and_delete(repo_dir)\n\n        if repo_type == 'git':\n            clone_cmd = ['git', 'clone', repo_url, str(repo_dir)]\n        else:  # hg\n            clone_cmd = ['hg', 'clone', repo_url, str(repo_dir)]\n\n        try:\n            subprocess.check_output(clone_cmd, stderr=subprocess.STDOUT)\n        except subprocess.CalledProcessError as e:\n            output = e.output.decode('utf-8')\n            if 'Repository not found' in output:\n                raise RepositoryNotFound(f\"The repository {repo_url} could not be found\")\n            else:\n                raise RepositoryCloneFailed(f\"Cloning {repo_url} failed: {output}\")\n\n        if checkout:\n            if repo_type == 'git':\n                checkout_cmd = ['git', 'checkout', checkout]\n            else:  # hg\n                checkout_cmd = ['hg', 'update', checkout]\n\n            with Path.cwd():\n&gt;               os.chdir(repo_dir)\nE               FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pytest-of-root/pytest-0/test_clone_should_invoke_vcs_c3/clone_dir/cookiecutter'\n\ncookiecutter/vcs.py:101: FileNotFoundError"},{"location":"analysis_baseline_cookiecutter/#cookiecuttergit-cookiecutter_1","title":"cookiecutter.git-cookiecutter]","text":"<pre>cookiecutter.git-cookiecutter]</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_invoke_vcs_c4/clone_dir')\nrepo_type = 'git', repo_url = 'git@github.com:cookiecutter/cookiecutter.git'\nrepo_name = 'cookiecutter'\n\n    @pytest.mark.parametrize(\n        'repo_type, repo_url, repo_name',\n        [\n            ('git', 'https://github.com/hello/world.git', 'world'),\n            ('hg', 'https://bitbucket.org/foo/bar', 'bar'),\n            ('git', 'git@host:gitoliterepo', 'gitoliterepo'),\n            ('git', 'git@gitlab.com:cookiecutter/cookiecutter.git', 'cookiecutter'),\n            ('git', 'git@github.com:cookiecutter/cookiecutter.git', 'cookiecutter'),\n        ],\n    )\n    def test_clone_should_invoke_vcs_command(\n        mocker, clone_dir, repo_type, repo_url, repo_name\n    ):\n        \"\"\"When `clone()` is called with a git/hg repo, the corresponding VCS \\\n        command should be run via `subprocess.check_output()`.\n\n        This should take place:\n        * In the correct dir\n        * With the correct args.\n        \"\"\"\n        mocker.patch('cookiecutter.vcs.is_vcs_installed', autospec=True, return_value=True)\n\n        mock_subprocess = mocker.patch(\n            'cookiecutter.vcs.subprocess.check_output',\n            autospec=True,\n        )\n        expected_repo_dir = os.path.normpath(os.path.join(clone_dir, repo_name))\n\n        branch = 'foobar'\n\n&gt;       repo_dir = vcs.clone(\n            repo_url, checkout=branch, clone_to_dir=clone_dir, no_input=True\n        )\n\ntests/vcs/test_clone.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_url = 'git@github.com:cookiecutter/cookiecutter.git', checkout = 'foobar'\nclone_to_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_should_invoke_vcs_c4/clone_dir')\nno_input = True\n\n    def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n        'os.PathLike[str]'='.', no_input: bool=False):\n        \"\"\"Clone a repo to the current directory.\n\n        :param repo_url: Repo URL of unknown type.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param clone_to_dir: The directory to clone to.\n                             Defaults to the current directory.\n        :param no_input: Do not prompt for user input and eventually force a refresh of\n            cached resources.\n        :returns: str with path to the new directory of the repository.\n        \"\"\"\n        repo_type, repo_url = identify_repo(repo_url)\n        if repo_type is None:\n            raise UnknownRepoType(f\"Couldn't determine repository type for {repo_url}\")\n\n        if not is_vcs_installed(repo_type):\n            raise VCSNotInstalled(f\"{repo_type} is not installed.\")\n\n        clone_to_dir = Path(clone_to_dir).resolve()\n        make_sure_path_exists(clone_to_dir)\n\n        repo_dir = clone_to_dir / Path(repo_url).stem\n\n        if repo_dir.exists():\n            if no_input:\n                logger.warning(\"'%s' directory already exists, deleting it\", repo_dir)\n                subprocess.check_call([repo_type, 'init', str(repo_dir)])\n            else:\n                prompt_and_delete(repo_dir)\n\n        if repo_type == 'git':\n            clone_cmd = ['git', 'clone', repo_url, str(repo_dir)]\n        else:  # hg\n            clone_cmd = ['hg', 'clone', repo_url, str(repo_dir)]\n\n        try:\n            subprocess.check_output(clone_cmd, stderr=subprocess.STDOUT)\n        except subprocess.CalledProcessError as e:\n            output = e.output.decode('utf-8')\n            if 'Repository not found' in output:\n                raise RepositoryNotFound(f\"The repository {repo_url} could not be found\")\n            else:\n                raise RepositoryCloneFailed(f\"Cloning {repo_url} failed: {output}\")\n\n        if checkout:\n            if repo_type == 'git':\n                checkout_cmd = ['git', 'checkout', checkout]\n            else:  # hg\n                checkout_cmd = ['hg', 'update', checkout]\n\n            with Path.cwd():\n&gt;               os.chdir(repo_dir)\nE               FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pytest-of-root/pytest-0/test_clone_should_invoke_vcs_c4/clone_dir/cookiecutter'\n\ncookiecutter/vcs.py:101: FileNotFoundError"},{"location":"analysis_baseline_cookiecutter/#cookiedozer-not-found","title":"cookiedozer' not found]","text":"<pre>cookiedozer' not found]</pre><pre>\nrepo_url = 'https://github.com/hackebro/cookiedozer', checkout = None\nclone_to_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_handles_repo_typo_f0/clone_dir')\nno_input = True\n\n    def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n        'os.PathLike[str]'='.', no_input: bool=False):\n        \"\"\"Clone a repo to the current directory.\n\n        :param repo_url: Repo URL of unknown type.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param clone_to_dir: The directory to clone to.\n                             Defaults to the current directory.\n        :param no_input: Do not prompt for user input and eventually force a refresh of\n            cached resources.\n        :returns: str with path to the new directory of the repository.\n        \"\"\"\n        repo_type, repo_url = identify_repo(repo_url)\n        if repo_type is None:\n            raise UnknownRepoType(f\"Couldn't determine repository type for {repo_url}\")\n\n        if not is_vcs_installed(repo_type):\n            raise VCSNotInstalled(f\"{repo_type} is not installed.\")\n\n        clone_to_dir = Path(clone_to_dir).resolve()\n        make_sure_path_exists(clone_to_dir)\n\n        repo_dir = clone_to_dir / Path(repo_url).stem\n\n        if repo_dir.exists():\n            if no_input:\n                logger.warning(\"'%s' directory already exists, deleting it\", repo_dir)\n                subprocess.check_call([repo_type, 'init', str(repo_dir)])\n            else:\n                prompt_and_delete(repo_dir)\n\n        if repo_type == 'git':\n            clone_cmd = ['git', 'clone', repo_url, str(repo_dir)]\n        else:  # hg\n            clone_cmd = ['hg', 'clone', repo_url, str(repo_dir)]\n\n        try:\n&gt;           subprocess.check_output(clone_cmd, stderr=subprocess.STDOUT)\n\ncookiecutter/vcs.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.10/unittest/mock.py:1114: in __call__\n    return self._mock_call(*args, **kwargs)\n/usr/lib/python3.10/unittest/mock.py:1118: in _mock_call\n    return self._execute_mock_call(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nargs = (['git', 'clone', 'https://github.com/hackebro/cookiedozer', '/tmp/pytest-of-root/pytest-0/test_clone_handles_repo_typo_f0/clone_dir/cookiedozer'],)\nkwargs = {'stderr': -2}\neffect = \nresult = CalledProcessError(-1, 'cmd')\n\n    def _execute_mock_call(self, /, *args, **kwargs):\n        # separate from _increment_mock_call so that awaited functions are\n        # executed separately from their call, also AsyncMock overrides this method\n\n        effect = self.side_effect\n        if effect is not None:\n            if _is_exception(effect):\n                raise effect\n            elif not _callable(effect):\n                result = next(effect)\n                if _is_exception(result):\n&gt;                   raise result\nE                   subprocess.CalledProcessError: Command 'cmd' died with .\n\n/usr/lib/python3.10/unittest/mock.py:1177: CalledProcessError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_handles_repo_typo_f0/clone_dir')\nerror_message = b\"fatal: repository 'https://github.com/hackebro/cookiedozer' not found\"\n\n    @pytest.mark.parametrize(\n        'error_message',\n        [\n            (b\"fatal: repository 'https://github.com/hackebro/cookiedozer' not found\"),\n            b'hg: abort: HTTP Error 404: Not Found',\n        ],\n    )\n    def test_clone_handles_repo_typo(mocker, clone_dir, error_message):\n        \"\"\"In `clone()`, repository not found errors should raise an \\\n        appropriate exception.\"\"\"\n        # side_effect is set to an iterable here (and below),\n        # because of a Python 3.4 unittest.mock regression\n        # http://bugs.python.org/issue23661\n        mocker.patch(\n            'cookiecutter.vcs.subprocess.check_output',\n            autospec=True,\n            side_effect=[subprocess.CalledProcessError(-1, 'cmd', output=error_message)],\n        )\n\n        repository_url = 'https://github.com/hackebro/cookiedozer'\n        with pytest.raises(exceptions.RepositoryNotFound) as err:\n&gt;           vcs.clone(repository_url, clone_to_dir=str(clone_dir), no_input=True)\n\ntests/vcs/test_clone.py:160: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_url = 'https://github.com/hackebro/cookiedozer', checkout = None\nclone_to_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_handles_repo_typo_f0/clone_dir')\nno_input = True\n\n    def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n        'os.PathLike[str]'='.', no_input: bool=False):\n        \"\"\"Clone a repo to the current directory.\n\n        :param repo_url: Repo URL of unknown type.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param clone_to_dir: The directory to clone to.\n                             Defaults to the current directory.\n        :param no_input: Do not prompt for user input and eventually force a refresh of\n            cached resources.\n        :returns: str with path to the new directory of the repository.\n        \"\"\"\n        repo_type, repo_url = identify_repo(repo_url)\n        if repo_type is None:\n            raise UnknownRepoType(f\"Couldn't determine repository type for {repo_url}\")\n\n        if not is_vcs_installed(repo_type):\n            raise VCSNotInstalled(f\"{repo_type} is not installed.\")\n\n        clone_to_dir = Path(clone_to_dir).resolve()\n        make_sure_path_exists(clone_to_dir)\n\n        repo_dir = clone_to_dir / Path(repo_url).stem\n\n        if repo_dir.exists():\n            if no_input:\n                logger.warning(\"'%s' directory already exists, deleting it\", repo_dir)\n                subprocess.check_call([repo_type, 'init', str(repo_dir)])\n            else:\n                prompt_and_delete(repo_dir)\n\n        if repo_type == 'git':\n            clone_cmd = ['git', 'clone', repo_url, str(repo_dir)]\n        else:  # hg\n            clone_cmd = ['hg', 'clone', repo_url, str(repo_dir)]\n\n        try:\n            subprocess.check_output(clone_cmd, stderr=subprocess.STDOUT)\n        except subprocess.CalledProcessError as e:\n            output = e.output.decode('utf-8')\n            if 'Repository not found' in output:\n                raise RepositoryNotFound(f\"The repository {repo_url} could not be found\")\n            else:\n&gt;               raise RepositoryCloneFailed(f\"Cloning {repo_url} failed: {output}\")\nE               cookiecutter.exceptions.RepositoryCloneFailed: Cloning https://github.com/hackebro/cookiedozer failed: fatal: repository 'https://github.com/hackebro/cookiedozer' not found\n\ncookiecutter/vcs.py:92: RepositoryCloneFailed"},{"location":"analysis_baseline_cookiecutter/#test_clonepytest_clone_handles_repo_typohg-abort-http-error-404-not-found","title":"test_clone.py::test_clone_handles_repo_typo[hg: abort: HTTP Error 404: Not Found]","text":"<pre>test_clone.py::test_clone_handles_repo_typo[hg: abort: HTTP Error 404: Not Found]</pre><pre>\nrepo_url = 'https://github.com/hackebro/cookiedozer', checkout = None\nclone_to_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_handles_repo_typo_h0/clone_dir')\nno_input = True\n\n    def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n        'os.PathLike[str]'='.', no_input: bool=False):\n        \"\"\"Clone a repo to the current directory.\n\n        :param repo_url: Repo URL of unknown type.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param clone_to_dir: The directory to clone to.\n                             Defaults to the current directory.\n        :param no_input: Do not prompt for user input and eventually force a refresh of\n            cached resources.\n        :returns: str with path to the new directory of the repository.\n        \"\"\"\n        repo_type, repo_url = identify_repo(repo_url)\n        if repo_type is None:\n            raise UnknownRepoType(f\"Couldn't determine repository type for {repo_url}\")\n\n        if not is_vcs_installed(repo_type):\n            raise VCSNotInstalled(f\"{repo_type} is not installed.\")\n\n        clone_to_dir = Path(clone_to_dir).resolve()\n        make_sure_path_exists(clone_to_dir)\n\n        repo_dir = clone_to_dir / Path(repo_url).stem\n\n        if repo_dir.exists():\n            if no_input:\n                logger.warning(\"'%s' directory already exists, deleting it\", repo_dir)\n                subprocess.check_call([repo_type, 'init', str(repo_dir)])\n            else:\n                prompt_and_delete(repo_dir)\n\n        if repo_type == 'git':\n            clone_cmd = ['git', 'clone', repo_url, str(repo_dir)]\n        else:  # hg\n            clone_cmd = ['hg', 'clone', repo_url, str(repo_dir)]\n\n        try:\n&gt;           subprocess.check_output(clone_cmd, stderr=subprocess.STDOUT)\n\ncookiecutter/vcs.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.10/unittest/mock.py:1114: in __call__\n    return self._mock_call(*args, **kwargs)\n/usr/lib/python3.10/unittest/mock.py:1118: in _mock_call\n    return self._execute_mock_call(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nargs = (['git', 'clone', 'https://github.com/hackebro/cookiedozer', '/tmp/pytest-of-root/pytest-0/test_clone_handles_repo_typo_h0/clone_dir/cookiedozer'],)\nkwargs = {'stderr': -2}\neffect = \nresult = CalledProcessError(-1, 'cmd')\n\n    def _execute_mock_call(self, /, *args, **kwargs):\n        # separate from _increment_mock_call so that awaited functions are\n        # executed separately from their call, also AsyncMock overrides this method\n\n        effect = self.side_effect\n        if effect is not None:\n            if _is_exception(effect):\n                raise effect\n            elif not _callable(effect):\n                result = next(effect)\n                if _is_exception(result):\n&gt;                   raise result\nE                   subprocess.CalledProcessError: Command 'cmd' died with .\n\n/usr/lib/python3.10/unittest/mock.py:1177: CalledProcessError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_handles_repo_typo_h0/clone_dir')\nerror_message = b'hg: abort: HTTP Error 404: Not Found'\n\n    @pytest.mark.parametrize(\n        'error_message',\n        [\n            (b\"fatal: repository 'https://github.com/hackebro/cookiedozer' not found\"),\n            b'hg: abort: HTTP Error 404: Not Found',\n        ],\n    )\n    def test_clone_handles_repo_typo(mocker, clone_dir, error_message):\n        \"\"\"In `clone()`, repository not found errors should raise an \\\n        appropriate exception.\"\"\"\n        # side_effect is set to an iterable here (and below),\n        # because of a Python 3.4 unittest.mock regression\n        # http://bugs.python.org/issue23661\n        mocker.patch(\n            'cookiecutter.vcs.subprocess.check_output',\n            autospec=True,\n            side_effect=[subprocess.CalledProcessError(-1, 'cmd', output=error_message)],\n        )\n\n        repository_url = 'https://github.com/hackebro/cookiedozer'\n        with pytest.raises(exceptions.RepositoryNotFound) as err:\n&gt;           vcs.clone(repository_url, clone_to_dir=str(clone_dir), no_input=True)\n\ntests/vcs/test_clone.py:160: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_url = 'https://github.com/hackebro/cookiedozer', checkout = None\nclone_to_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_handles_repo_typo_h0/clone_dir')\nno_input = True\n\n    def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n        'os.PathLike[str]'='.', no_input: bool=False):\n        \"\"\"Clone a repo to the current directory.\n\n        :param repo_url: Repo URL of unknown type.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param clone_to_dir: The directory to clone to.\n                             Defaults to the current directory.\n        :param no_input: Do not prompt for user input and eventually force a refresh of\n            cached resources.\n        :returns: str with path to the new directory of the repository.\n        \"\"\"\n        repo_type, repo_url = identify_repo(repo_url)\n        if repo_type is None:\n            raise UnknownRepoType(f\"Couldn't determine repository type for {repo_url}\")\n\n        if not is_vcs_installed(repo_type):\n            raise VCSNotInstalled(f\"{repo_type} is not installed.\")\n\n        clone_to_dir = Path(clone_to_dir).resolve()\n        make_sure_path_exists(clone_to_dir)\n\n        repo_dir = clone_to_dir / Path(repo_url).stem\n\n        if repo_dir.exists():\n            if no_input:\n                logger.warning(\"'%s' directory already exists, deleting it\", repo_dir)\n                subprocess.check_call([repo_type, 'init', str(repo_dir)])\n            else:\n                prompt_and_delete(repo_dir)\n\n        if repo_type == 'git':\n            clone_cmd = ['git', 'clone', repo_url, str(repo_dir)]\n        else:  # hg\n            clone_cmd = ['hg', 'clone', repo_url, str(repo_dir)]\n\n        try:\n            subprocess.check_output(clone_cmd, stderr=subprocess.STDOUT)\n        except subprocess.CalledProcessError as e:\n            output = e.output.decode('utf-8')\n            if 'Repository not found' in output:\n                raise RepositoryNotFound(f\"The repository {repo_url} could not be found\")\n            else:\n&gt;               raise RepositoryCloneFailed(f\"Cloning {repo_url} failed: {output}\")\nE               cookiecutter.exceptions.RepositoryCloneFailed: Cloning https://github.com/hackebro/cookiedozer failed: hg: abort: HTTP Error 404: Not Found\n\ncookiecutter/vcs.py:92: RepositoryCloneFailed"},{"location":"analysis_baseline_cookiecutter/#test_clonepytest_clone_handles_branch_typoerror-pathspec-unknown_branch-did-not-match-any-files-known-to-git","title":"test_clone.py::test_clone_handles_branch_typo[error: pathspec 'unknown_branch' did not match any file(s) known to git]","text":"<pre>test_clone.py::test_clone_handles_branch_typo[error: pathspec 'unknown_branch' did not match any file(s) known to git]</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_handles_branch_typo0/clone_dir')\nerror_message = b\"error: pathspec 'unknown_branch' did not match any file(s) known to git\"\n\n    @pytest.mark.parametrize(\n        'error_message',\n        [\n            b\"error: pathspec 'unknown_branch' did not match any file(s) known to git\",\n            b\"hg: abort: unknown revision 'unknown_branch'!\",\n        ],\n    )\n    def test_clone_handles_branch_typo(mocker, clone_dir, error_message):\n        \"\"\"In `clone()`, branch not found errors should raise an \\\n        appropriate exception.\"\"\"\n        mocker.patch(\n            'cookiecutter.vcs.subprocess.check_output',\n            autospec=True,\n            side_effect=[subprocess.CalledProcessError(-1, 'cmd', output=error_message)],\n        )\n\n        repository_url = 'https://github.com/pytest-dev/cookiecutter-pytest-plugin'\n        with pytest.raises(exceptions.RepositoryCloneFailed) as err:\n            vcs.clone(\n                repository_url,\n                clone_to_dir=str(clone_dir),\n                checkout='unknown_branch',\n                no_input=True,\n            )\n\n&gt;       assert str(err.value) == (\n            'The unknown_branch branch of repository '\n            f'{repository_url} could not found, have you made a typo?'\n        )\nE       assert \"Cloning https://github.com/pytest-dev/cookiecutter-pytest-plugin failed: error: pathspec 'unknown_branch' did not match any file(s) known to git\" == 'The unknown_branch branch of repository https://github.com/pytest-dev/cookiecutter-pytest-plugin could not found, have you made a typo?'\nE         \nE         - The unknown_branch branch of repository https://github.com/pytest-dev/cookiecutter-pytest-plugin could not found, have you made a typo?\nE         + Cloning https://github.com/pytest-dev/cookiecutter-pytest-plugin failed: error: pathspec 'unknown_branch' did not match any file(s) known to git\n\ntests/vcs/test_clone.py:192: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clonepytest_clone_handles_branch_typohg-abort-unknown-revision-unknown_branch","title":"test_clone.py::test_clone_handles_branch_typo[hg: abort: unknown revision 'unknown_branch'!]","text":"<pre>test_clone.py::test_clone_handles_branch_typo[hg: abort: unknown revision 'unknown_branch'!]</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_handles_branch_typo1/clone_dir')\nerror_message = b\"hg: abort: unknown revision 'unknown_branch'!\"\n\n    @pytest.mark.parametrize(\n        'error_message',\n        [\n            b\"error: pathspec 'unknown_branch' did not match any file(s) known to git\",\n            b\"hg: abort: unknown revision 'unknown_branch'!\",\n        ],\n    )\n    def test_clone_handles_branch_typo(mocker, clone_dir, error_message):\n        \"\"\"In `clone()`, branch not found errors should raise an \\\n        appropriate exception.\"\"\"\n        mocker.patch(\n            'cookiecutter.vcs.subprocess.check_output',\n            autospec=True,\n            side_effect=[subprocess.CalledProcessError(-1, 'cmd', output=error_message)],\n        )\n\n        repository_url = 'https://github.com/pytest-dev/cookiecutter-pytest-plugin'\n        with pytest.raises(exceptions.RepositoryCloneFailed) as err:\n            vcs.clone(\n                repository_url,\n                clone_to_dir=str(clone_dir),\n                checkout='unknown_branch',\n                no_input=True,\n            )\n\n&gt;       assert str(err.value) == (\n            'The unknown_branch branch of repository '\n            f'{repository_url} could not found, have you made a typo?'\n        )\nE       assert \"Cloning https://github.com/pytest-dev/cookiecutter-pytest-plugin failed: hg: abort: unknown revision 'unknown_branch'!\" == 'The unknown_branch branch of repository https://github.com/pytest-dev/cookiecutter-pytest-plugin could not found, have you made a typo?'\nE         \nE         - The unknown_branch branch of repository https://github.com/pytest-dev/cookiecutter-pytest-plugin could not found, have you made a typo?\nE         + Cloning https://github.com/pytest-dev/cookiecutter-pytest-plugin failed: hg: abort: unknown revision 'unknown_branch'!\n\ntests/vcs/test_clone.py:192: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_clonepytest_clone_unknown_subprocess_error","title":"test_clone.py::test_clone_unknown_subprocess_error","text":"<pre>test_clone.py::test_clone_unknown_subprocess_error</pre><pre>\nrepo_url = 'https://github.com/pytest-dev/cookiecutter-pytest-plugin'\ncheckout = None\nclone_to_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_unknown_subprocess_0/clone_dir')\nno_input = True\n\n    def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n        'os.PathLike[str]'='.', no_input: bool=False):\n        \"\"\"Clone a repo to the current directory.\n\n        :param repo_url: Repo URL of unknown type.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param clone_to_dir: The directory to clone to.\n                             Defaults to the current directory.\n        :param no_input: Do not prompt for user input and eventually force a refresh of\n            cached resources.\n        :returns: str with path to the new directory of the repository.\n        \"\"\"\n        repo_type, repo_url = identify_repo(repo_url)\n        if repo_type is None:\n            raise UnknownRepoType(f\"Couldn't determine repository type for {repo_url}\")\n\n        if not is_vcs_installed(repo_type):\n            raise VCSNotInstalled(f\"{repo_type} is not installed.\")\n\n        clone_to_dir = Path(clone_to_dir).resolve()\n        make_sure_path_exists(clone_to_dir)\n\n        repo_dir = clone_to_dir / Path(repo_url).stem\n\n        if repo_dir.exists():\n            if no_input:\n                logger.warning(\"'%s' directory already exists, deleting it\", repo_dir)\n                subprocess.check_call([repo_type, 'init', str(repo_dir)])\n            else:\n                prompt_and_delete(repo_dir)\n\n        if repo_type == 'git':\n            clone_cmd = ['git', 'clone', repo_url, str(repo_dir)]\n        else:  # hg\n            clone_cmd = ['hg', 'clone', repo_url, str(repo_dir)]\n\n        try:\n&gt;           subprocess.check_output(clone_cmd, stderr=subprocess.STDOUT)\n\ncookiecutter/vcs.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.10/unittest/mock.py:1114: in __call__\n    return self._mock_call(*args, **kwargs)\n/usr/lib/python3.10/unittest/mock.py:1118: in _mock_call\n    return self._execute_mock_call(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nargs = (['git', 'clone', 'https://github.com/pytest-dev/cookiecutter-pytest-plugin', '/tmp/pytest-of-root/pytest-0/test_clone_unknown_subprocess_0/clone_dir/cookiecutter-pytest-plugin'],)\nkwargs = {'stderr': -2}\neffect = \nresult = CalledProcessError(-1, 'cmd')\n\n    def _execute_mock_call(self, /, *args, **kwargs):\n        # separate from _increment_mock_call so that awaited functions are\n        # executed separately from their call, also AsyncMock overrides this method\n\n        effect = self.side_effect\n        if effect is not None:\n            if _is_exception(effect):\n                raise effect\n            elif not _callable(effect):\n                result = next(effect)\n                if _is_exception(result):\n&gt;                   raise result\nE                   subprocess.CalledProcessError: Command 'cmd' died with .\n\n/usr/lib/python3.10/unittest/mock.py:1177: CalledProcessError\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_unknown_subprocess_0/clone_dir')\n\n    def test_clone_unknown_subprocess_error(mocker, clone_dir):\n        \"\"\"In `clone()`, unknown subprocess errors should be raised.\"\"\"\n        mocker.patch(\n            'cookiecutter.vcs.subprocess.check_output',\n            autospec=True,\n            side_effect=[\n                subprocess.CalledProcessError(-1, 'cmd', output=b'Something went wrong')\n            ],\n        )\n\n        with pytest.raises(subprocess.CalledProcessError):\n&gt;           vcs.clone(\n                'https://github.com/pytest-dev/cookiecutter-pytest-plugin',\n                clone_to_dir=str(clone_dir),\n                no_input=True,\n            )\n\ntests/vcs/test_clone.py:209: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nrepo_url = 'https://github.com/pytest-dev/cookiecutter-pytest-plugin'\ncheckout = None\nclone_to_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_clone_unknown_subprocess_0/clone_dir')\nno_input = True\n\n    def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n        'os.PathLike[str]'='.', no_input: bool=False):\n        \"\"\"Clone a repo to the current directory.\n\n        :param repo_url: Repo URL of unknown type.\n        :param checkout: The branch, tag or commit ID to checkout after clone.\n        :param clone_to_dir: The directory to clone to.\n                             Defaults to the current directory.\n        :param no_input: Do not prompt for user input and eventually force a refresh of\n            cached resources.\n        :returns: str with path to the new directory of the repository.\n        \"\"\"\n        repo_type, repo_url = identify_repo(repo_url)\n        if repo_type is None:\n            raise UnknownRepoType(f\"Couldn't determine repository type for {repo_url}\")\n\n        if not is_vcs_installed(repo_type):\n            raise VCSNotInstalled(f\"{repo_type} is not installed.\")\n\n        clone_to_dir = Path(clone_to_dir).resolve()\n        make_sure_path_exists(clone_to_dir)\n\n        repo_dir = clone_to_dir / Path(repo_url).stem\n\n        if repo_dir.exists():\n            if no_input:\n                logger.warning(\"'%s' directory already exists, deleting it\", repo_dir)\n                subprocess.check_call([repo_type, 'init', str(repo_dir)])\n            else:\n                prompt_and_delete(repo_dir)\n\n        if repo_type == 'git':\n            clone_cmd = ['git', 'clone', repo_url, str(repo_dir)]\n        else:  # hg\n            clone_cmd = ['hg', 'clone', repo_url, str(repo_dir)]\n\n        try:\n            subprocess.check_output(clone_cmd, stderr=subprocess.STDOUT)\n        except subprocess.CalledProcessError as e:\n            output = e.output.decode('utf-8')\n            if 'Repository not found' in output:\n                raise RepositoryNotFound(f\"The repository {repo_url} could not be found\")\n            else:\n&gt;               raise RepositoryCloneFailed(f\"Cloning {repo_url} failed: {output}\")\nE               cookiecutter.exceptions.RepositoryCloneFailed: Cloning https://github.com/pytest-dev/cookiecutter-pytest-plugin failed: Something went wrong\n\ncookiecutter/vcs.py:92: RepositoryCloneFailed"},{"location":"analysis_baseline_cookiecutter/#test_identify_repopytest_identify_raise_on_unknown_repofoogit","title":"test_identify_repo.py::test_identify_raise_on_unknown_repo[foo+git]","text":"<pre>test_identify_repo.py::test_identify_raise_on_unknown_repo[foo+git]</pre><pre>\nunknown_repo_type_url = 'foo+git'\n\n    def test_identify_raise_on_unknown_repo(unknown_repo_type_url):\n        \"\"\"Verify different incorrect repositories url syntax trigger error raising.\"\"\"\n&gt;       with pytest.raises(exceptions.UnknownRepoType):\nE       Failed: DID NOT RAISE \n\ntests/vcs/test_identify_repo.py:70: Failed"},{"location":"analysis_baseline_cookiecutter/#test_identify_repopytest_identify_raise_on_unknown_repofoohg","title":"test_identify_repo.py::test_identify_raise_on_unknown_repo[foo+hg]","text":"<pre>test_identify_repo.py::test_identify_raise_on_unknown_repo[foo+hg]</pre><pre>\nunknown_repo_type_url = 'foo+hg'\n\n    def test_identify_raise_on_unknown_repo(unknown_repo_type_url):\n        \"\"\"Verify different incorrect repositories url syntax trigger error raising.\"\"\"\n&gt;       with pytest.raises(exceptions.UnknownRepoType):\nE       Failed: DID NOT RAISE \n\ntests/vcs/test_identify_repo.py:70: Failed"},{"location":"analysis_baseline_cookiecutter/#test_identify_repopytest_identify_raise_on_unknown_repofoobar","title":"test_identify_repo.py::test_identify_raise_on_unknown_repo[foo+bar]","text":"<pre>test_identify_repo.py::test_identify_raise_on_unknown_repo[foo+bar]</pre><pre>\nunknown_repo_type_url = 'foo+bar'\n\n    def test_identify_raise_on_unknown_repo(unknown_repo_type_url):\n        \"\"\"Verify different incorrect repositories url syntax trigger error raising.\"\"\"\n&gt;       with pytest.raises(exceptions.UnknownRepoType):\nE       Failed: DID NOT RAISE \n\ntests/vcs/test_identify_repo.py:70: Failed"},{"location":"analysis_baseline_cookiecutter/#test_identify_repopytest_identify_raise_on_unknown_repofoobar_1","title":"test_identify_repo.py::test_identify_raise_on_unknown_repo[foobar]","text":"<pre>test_identify_repo.py::test_identify_raise_on_unknown_repo[foobar]</pre><pre>\nunknown_repo_type_url = 'foobar'\n\n    def test_identify_raise_on_unknown_repo(unknown_repo_type_url):\n        \"\"\"Verify different incorrect repositories url syntax trigger error raising.\"\"\"\n&gt;       with pytest.raises(exceptions.UnknownRepoType):\nE       Failed: DID NOT RAISE \n\ntests/vcs/test_identify_repo.py:70: Failed"},{"location":"analysis_baseline_cookiecutter/#norepotypespecifiedcom","title":"norepotypespecified.com]","text":"<pre>norepotypespecified.com]</pre><pre>\nunknown_repo_type_url = 'http://norepotypespecified.com'\n\n    def test_identify_raise_on_unknown_repo(unknown_repo_type_url):\n        \"\"\"Verify different incorrect repositories url syntax trigger error raising.\"\"\"\n&gt;       with pytest.raises(exceptions.UnknownRepoType):\nE       Failed: DID NOT RAISE \n\ntests/vcs/test_identify_repo.py:70: Failed"},{"location":"analysis_baseline_cookiecutter/#test_is_vcs_installedpytest_is_vcs_installed-false","title":"test_is_vcs_installed.py::test_is_vcs_installed[-False]","text":"<pre>test_is_vcs_installed.py::test_is_vcs_installed[-False]</pre><pre>\nmocker = \nwhich_return = '', result = False\n\n    @pytest.mark.parametrize(\n        'which_return, result',\n        [('', False), (None, False), (False, False), ('/usr/local/bin/git', True)],\n    )\n    def test_is_vcs_installed(mocker, which_return, result):\n        \"\"\"Verify `is_vcs_installed` function correctly handles `which` answer.\"\"\"\n        mocker.patch('cookiecutter.vcs.which', autospec=True, return_value=which_return)\n&gt;       assert vcs.is_vcs_installed('git') == result\nE       AssertionError: assert True == False\nE        +  where True = ('git')\nE        +    where  = vcs.is_vcs_installed\n\ntests/vcs/test_is_vcs_installed.py:15: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_is_vcs_installedpytest_is_vcs_installedfalse-false","title":"test_is_vcs_installed.py::test_is_vcs_installed[False-False]","text":"<pre>test_is_vcs_installed.py::test_is_vcs_installed[False-False]</pre><pre>\nmocker = \nwhich_return = False, result = False\n\n    @pytest.mark.parametrize(\n        'which_return, result',\n        [('', False), (None, False), (False, False), ('/usr/local/bin/git', True)],\n    )\n    def test_is_vcs_installed(mocker, which_return, result):\n        \"\"\"Verify `is_vcs_installed` function correctly handles `which` answer.\"\"\"\n        mocker.patch('cookiecutter.vcs.which', autospec=True, return_value=which_return)\n&gt;       assert vcs.is_vcs_installed('git') == result\nE       AssertionError: assert True == False\nE        +  where True = ('git')\nE        +    where  = vcs.is_vcs_installed\n\ntests/vcs/test_is_vcs_installed.py:15: AssertionError"},{"location":"analysis_baseline_cookiecutter/#test_unzippytest_unzip_local_file","title":"test_unzip.py::test_unzip_local_file","text":"<pre>test_unzip.py::test_unzip_local_file</pre><pre>\nprompt = '', stream = None\n\n    def unix_getpass(prompt='Password: ', stream=None):\n        \"\"\"Prompt for a password, with echo turned off.\n\n        Args:\n          prompt: Written on stream to ask for the input.  Default: 'Password: '\n          stream: A writable file object to display the prompt.  Defaults to\n                  the tty.  If no tty is available defaults to sys.stderr.\n        Returns:\n          The seKr3t input.\n        Raises:\n          EOFError: If our input tty or stdin was closed.\n          GetPassWarning: When we were unable to turn echo off on the input.\n\n        Always restores terminal settings before returning.\n        \"\"\"\n        passwd = None\n        with contextlib.ExitStack() as stack:\n            try:\n                # Always try reading and writing directly on the tty first.\n&gt;               fd = os.open('/dev/tty', os.O_RDWR|os.O_NOCTTY)\nE               OSError: [Errno 5] Input/output error: '/dev/tty'\n\n/usr/lib/python3.10/getpass.py:48: OSError\n\nDuring handling of the above exception, another exception occurred:\n\nprompt = '', stream = None\n\n    def unix_getpass(prompt='Password: ', stream=None):\n        \"\"\"Prompt for a password, with echo turned off.\n\n        Args:\n          prompt: Written on stream to ask for the input.  Default: 'Password: '\n          stream: A writable file object to display the prompt.  Defaults to\n                  the tty.  If no tty is available defaults to sys.stderr.\n        Returns:\n          The seKr3t input.\n        Raises:\n          EOFError: If our input tty or stdin was closed.\n          GetPassWarning: When we were unable to turn echo off on the input.\n\n        Always restores terminal settings before returning.\n        \"\"\"\n        passwd = None\n        with contextlib.ExitStack() as stack:\n            try:\n                # Always try reading and writing directly on the tty first.\n                fd = os.open('/dev/tty', os.O_RDWR|os.O_NOCTTY)\n                tty = io.FileIO(fd, 'w+')\n                stack.enter_context(tty)\n                input = io.TextIOWrapper(tty)\n                stack.enter_context(input)\n                if not stream:\n                    stream = input\n            except OSError:\n                # If that fails, see if stdin can be controlled.\n                stack.close()\n                try:\n&gt;                   fd = sys.stdin.fileno()\nE                   io.UnsupportedOperation: redirected stdin is pseudofile, has no fileno()\n\n/usr/lib/python3.10/getpass.py:59: UnsupportedOperation\n\nDuring handling of the above exception, another exception occurred:\n\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_unzip_local_file0/clone_dir')\n\n    def test_unzip_local_file(mocker, clone_dir):\n        \"\"\"Local file reference can be unzipped.\"\"\"\n        mock_prompt_and_delete = mocker.patch(\n            'cookiecutter.zipfile.prompt_and_delete', return_value=True, autospec=True\n        )\n\n&gt;       output_dir = zipfile.unzip(\n            'tests/files/fake-repo-tmpl.zip', is_url=False, clone_to_dir=str(clone_dir)\n        )\n\ntests/zipfile/test_unzip.py:38: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/zipfile.py:50: in unzip\n    password = read_repo_password('Enter the password for the encrypted repository:')\ncookiecutter/prompt.py:69: in read_repo_password\n    return Prompt.ask(question, password=True)\n.venv/lib/python3.10/site-packages/rich/prompt.py:149: in ask\n    return _prompt(default=default, stream=stream)\n.venv/lib/python3.10/site-packages/rich/prompt.py:292: in __call__\n    value = self.get_input(self.console, prompt, self.password, stream=stream)\n.venv/lib/python3.10/site-packages/rich/prompt.py:211: in get_input\n    return console.input(prompt, password=password, stream=stream)\n.venv/lib/python3.10/site-packages/rich/console.py:2151: in input\n    result = getpass(\"\", stream=stream)\n/usr/lib/python3.10/getpass.py:62: in unix_getpass\n    passwd = fallback_getpass(prompt, stream)\n/usr/lib/python3.10/getpass.py:126: in fallback_getpass\n    return _raw_input(prompt, stream)\n/usr/lib/python3.10/getpass.py:146: in _raw_input\n    line = input.readline()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &lt;_pytest.capture.DontReadFromInput object at 0x7f1eeef69330&gt;, size = -1\n\n    def read(self, size: int = -1) -&gt; str:\n&gt;       raise OSError(\n            \"pytest: reading from stdin while output is captured!  Consider using `-s`.\"\n        )\nE       OSError: pytest: reading from stdin while output is captured!  Consider using `-s`.\n\n.venv/lib/python3.10/site-packages/_pytest/capture.py:209: OSError"},{"location":"analysis_baseline_cookiecutter/#test_unzippytest_unzip_protected_local_file_environment_password","title":"test_unzip.py::test_unzip_protected_local_file_environment_password","text":"<pre>test_unzip.py::test_unzip_protected_local_file_environment_password</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_unzip_protected_local_fil0/clone_dir')\n\n    def test_unzip_protected_local_file_environment_password(mocker, clone_dir):\n        \"\"\"In `unzip()`, the environment can be used to provide a repo password.\"\"\"\n        mock_prompt_and_delete = mocker.patch(\n            'cookiecutter.zipfile.prompt_and_delete', return_value=True, autospec=True\n        )\n\n&gt;       output_dir = zipfile.unzip(\n            'tests/files/protected-fake-repo-tmpl.zip',\n            is_url=False,\n            clone_to_dir=str(clone_dir),\n            password='sekrit',\n        )\n\ntests/zipfile/test_unzip.py:52: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/zipfile.py:46: in unzip\n    if zip_ref.namelist() and zip_ref.testzip() is not None:\n/usr/lib/python3.10/zipfile.py:1442: in testzip\n    with self.open(zinfo.filename, \"r\") as f:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = , name = 'fake-repo-tmpl/cookiecutter.json'\nmode = 'r', pwd = None\n\n    def open(self, name, mode=\"r\", pwd=None, *, force_zip64=False):\n        \"\"\"Return file-like object for 'name'.\n\n        name is a string for the file name within the ZIP file, or a ZipInfo\n        object.\n\n        mode should be 'r' to read a file already in the ZIP file, or 'w' to\n        write to a file newly added to the archive.\n\n        pwd is the password to decrypt files (only used for reading).\n\n        When writing, if the file size is not known in advance but may exceed\n        2 GiB, pass force_zip64 to use the ZIP64 format, which can handle large\n        files.  If the size is known in advance, it is best to pass a ZipInfo\n        instance for name, with zinfo.file_size set.\n        \"\"\"\n        if mode not in {\"r\", \"w\"}:\n            raise ValueError('open() requires mode \"r\" or \"w\"')\n        if pwd and not isinstance(pwd, bytes):\n            raise TypeError(\"pwd: expected bytes, got %s\" % type(pwd).__name__)\n        if pwd and (mode == \"w\"):\n            raise ValueError(\"pwd is only supported for reading files\")\n        if not self.fp:\n            raise ValueError(\n                \"Attempt to use ZIP archive that was already closed\")\n\n        # Make sure we have an info object\n        if isinstance(name, ZipInfo):\n            # 'name' is already an info object\n            zinfo = name\n        elif mode == 'w':\n            zinfo = ZipInfo(name)\n            zinfo.compress_type = self.compression\n            zinfo._compresslevel = self.compresslevel\n        else:\n            # Get info object for name\n            zinfo = self.getinfo(name)\n\n        if mode == 'w':\n            return self._open_to_write(zinfo, force_zip64=force_zip64)\n\n        if self._writing:\n            raise ValueError(\"Can't read from the ZIP file while there \"\n                    \"is an open writing handle on it. \"\n                    \"Close the writing handle before trying to read.\")\n\n        # Open for reading:\n        self._fileRefCnt += 1\n        zef_file = _SharedFile(self.fp, zinfo.header_offset,\n                               self._fpclose, self._lock, lambda: self._writing)\n        try:\n            # Skip the file header:\n            fheader = zef_file.read(sizeFileHeader)\n            if len(fheader) != sizeFileHeader:\n                raise BadZipFile(\"Truncated file header\")\n            fheader = struct.unpack(structFileHeader, fheader)\n            if fheader[_FH_SIGNATURE] != stringFileHeader:\n                raise BadZipFile(\"Bad magic number for file header\")\n\n            fname = zef_file.read(fheader[_FH_FILENAME_LENGTH])\n            if fheader[_FH_EXTRA_FIELD_LENGTH]:\n                zef_file.read(fheader[_FH_EXTRA_FIELD_LENGTH])\n\n            if zinfo.flag_bits &amp; 0x20:\n                # Zip 2.7: compressed patched data\n                raise NotImplementedError(\"compressed patched data (flag bit 5)\")\n\n            if zinfo.flag_bits &amp; 0x40:\n                # strong encryption\n                raise NotImplementedError(\"strong encryption (flag bit 6)\")\n\n            if fheader[_FH_GENERAL_PURPOSE_FLAG_BITS] &amp; 0x800:\n                # UTF-8 filename\n                fname_str = fname.decode(\"utf-8\")\n            else:\n                fname_str = fname.decode(\"cp437\")\n\n            if fname_str != zinfo.orig_filename:\n                raise BadZipFile(\n                    'File name in directory %r and header %r differ.'\n                    % (zinfo.orig_filename, fname))\n\n            if (zinfo._end_offset is not None and\n                zef_file.tell() + zinfo.compress_size &gt; zinfo._end_offset):\n                raise BadZipFile(f\"Overlapped entries: {zinfo.orig_filename!r} (possible zip bomb)\")\n\n            # check for encrypted flag &amp; handle password\n            is_encrypted = zinfo.flag_bits &amp; 0x1\n            if is_encrypted:\n                if not pwd:\n                    pwd = self.pwd\n                if not pwd:\n&gt;                   raise RuntimeError(\"File %r is encrypted, password \"\n                                       \"required for extraction\" % name)\nE                                      RuntimeError: File 'fake-repo-tmpl/cookiecutter.json' is encrypted, password required for extraction\n\n/usr/lib/python3.10/zipfile.py:1581: RuntimeError"},{"location":"analysis_baseline_cookiecutter/#test_unzippytest_unzip_protected_local_file_bad_environment_password","title":"test_unzip.py::test_unzip_protected_local_file_bad_environment_password","text":"<pre>test_unzip.py::test_unzip_protected_local_file_bad_environment_password</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_unzip_protected_local_fil1/clone_dir')\n\n    def test_unzip_protected_local_file_bad_environment_password(mocker, clone_dir):\n        \"\"\"In `unzip()`, an error occurs if the environment has a bad password.\"\"\"\n        mocker.patch(\n            'cookiecutter.zipfile.prompt_and_delete', return_value=True, autospec=True\n        )\n\n        with pytest.raises(InvalidZipRepository):\n&gt;           zipfile.unzip(\n                'tests/files/protected-fake-repo-tmpl.zip',\n                is_url=False,\n                clone_to_dir=str(clone_dir),\n                password='not-the-right-password',\n            )\n\ntests/zipfile/test_unzip.py:70: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/zipfile.py:46: in unzip\n    if zip_ref.namelist() and zip_ref.testzip() is not None:\n/usr/lib/python3.10/zipfile.py:1442: in testzip\n    with self.open(zinfo.filename, \"r\") as f:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = , name = 'fake-repo-tmpl/cookiecutter.json'\nmode = 'r', pwd = None\n\n    def open(self, name, mode=\"r\", pwd=None, *, force_zip64=False):\n        \"\"\"Return file-like object for 'name'.\n\n        name is a string for the file name within the ZIP file, or a ZipInfo\n        object.\n\n        mode should be 'r' to read a file already in the ZIP file, or 'w' to\n        write to a file newly added to the archive.\n\n        pwd is the password to decrypt files (only used for reading).\n\n        When writing, if the file size is not known in advance but may exceed\n        2 GiB, pass force_zip64 to use the ZIP64 format, which can handle large\n        files.  If the size is known in advance, it is best to pass a ZipInfo\n        instance for name, with zinfo.file_size set.\n        \"\"\"\n        if mode not in {\"r\", \"w\"}:\n            raise ValueError('open() requires mode \"r\" or \"w\"')\n        if pwd and not isinstance(pwd, bytes):\n            raise TypeError(\"pwd: expected bytes, got %s\" % type(pwd).__name__)\n        if pwd and (mode == \"w\"):\n            raise ValueError(\"pwd is only supported for reading files\")\n        if not self.fp:\n            raise ValueError(\n                \"Attempt to use ZIP archive that was already closed\")\n\n        # Make sure we have an info object\n        if isinstance(name, ZipInfo):\n            # 'name' is already an info object\n            zinfo = name\n        elif mode == 'w':\n            zinfo = ZipInfo(name)\n            zinfo.compress_type = self.compression\n            zinfo._compresslevel = self.compresslevel\n        else:\n            # Get info object for name\n            zinfo = self.getinfo(name)\n\n        if mode == 'w':\n            return self._open_to_write(zinfo, force_zip64=force_zip64)\n\n        if self._writing:\n            raise ValueError(\"Can't read from the ZIP file while there \"\n                    \"is an open writing handle on it. \"\n                    \"Close the writing handle before trying to read.\")\n\n        # Open for reading:\n        self._fileRefCnt += 1\n        zef_file = _SharedFile(self.fp, zinfo.header_offset,\n                               self._fpclose, self._lock, lambda: self._writing)\n        try:\n            # Skip the file header:\n            fheader = zef_file.read(sizeFileHeader)\n            if len(fheader) != sizeFileHeader:\n                raise BadZipFile(\"Truncated file header\")\n            fheader = struct.unpack(structFileHeader, fheader)\n            if fheader[_FH_SIGNATURE] != stringFileHeader:\n                raise BadZipFile(\"Bad magic number for file header\")\n\n            fname = zef_file.read(fheader[_FH_FILENAME_LENGTH])\n            if fheader[_FH_EXTRA_FIELD_LENGTH]:\n                zef_file.read(fheader[_FH_EXTRA_FIELD_LENGTH])\n\n            if zinfo.flag_bits &amp; 0x20:\n                # Zip 2.7: compressed patched data\n                raise NotImplementedError(\"compressed patched data (flag bit 5)\")\n\n            if zinfo.flag_bits &amp; 0x40:\n                # strong encryption\n                raise NotImplementedError(\"strong encryption (flag bit 6)\")\n\n            if fheader[_FH_GENERAL_PURPOSE_FLAG_BITS] &amp; 0x800:\n                # UTF-8 filename\n                fname_str = fname.decode(\"utf-8\")\n            else:\n                fname_str = fname.decode(\"cp437\")\n\n            if fname_str != zinfo.orig_filename:\n                raise BadZipFile(\n                    'File name in directory %r and header %r differ.'\n                    % (zinfo.orig_filename, fname))\n\n            if (zinfo._end_offset is not None and\n                zef_file.tell() + zinfo.compress_size &gt; zinfo._end_offset):\n                raise BadZipFile(f\"Overlapped entries: {zinfo.orig_filename!r} (possible zip bomb)\")\n\n            # check for encrypted flag &amp; handle password\n            is_encrypted = zinfo.flag_bits &amp; 0x1\n            if is_encrypted:\n                if not pwd:\n                    pwd = self.pwd\n                if not pwd:\n&gt;                   raise RuntimeError(\"File %r is encrypted, password \"\n                                       \"required for extraction\" % name)\nE                                      RuntimeError: File 'fake-repo-tmpl/cookiecutter.json' is encrypted, password required for extraction\n\n/usr/lib/python3.10/zipfile.py:1581: RuntimeError"},{"location":"analysis_baseline_cookiecutter/#test_unzippytest_unzip_protected_local_file_user_password_with_noinput","title":"test_unzip.py::test_unzip_protected_local_file_user_password_with_noinput","text":"<pre>test_unzip.py::test_unzip_protected_local_file_user_password_with_noinput</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_unzip_protected_local_fil2/clone_dir')\n\n    def test_unzip_protected_local_file_user_password_with_noinput(mocker, clone_dir):\n        \"\"\"Can't unpack a password-protected repo in no_input mode.\"\"\"\n        mocker.patch(\n            'cookiecutter.zipfile.prompt_and_delete', return_value=True, autospec=True\n        )\n\n        with pytest.raises(InvalidZipRepository):\n&gt;           zipfile.unzip(\n                'tests/files/protected-fake-repo-tmpl.zip',\n                is_url=False,\n                clone_to_dir=str(clone_dir),\n                no_input=True,\n            )\n\ntests/zipfile/test_unzip.py:85: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/zipfile.py:46: in unzip\n    if zip_ref.namelist() and zip_ref.testzip() is not None:\n/usr/lib/python3.10/zipfile.py:1442: in testzip\n    with self.open(zinfo.filename, \"r\") as f:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = , name = 'fake-repo-tmpl/cookiecutter.json'\nmode = 'r', pwd = None\n\n    def open(self, name, mode=\"r\", pwd=None, *, force_zip64=False):\n        \"\"\"Return file-like object for 'name'.\n\n        name is a string for the file name within the ZIP file, or a ZipInfo\n        object.\n\n        mode should be 'r' to read a file already in the ZIP file, or 'w' to\n        write to a file newly added to the archive.\n\n        pwd is the password to decrypt files (only used for reading).\n\n        When writing, if the file size is not known in advance but may exceed\n        2 GiB, pass force_zip64 to use the ZIP64 format, which can handle large\n        files.  If the size is known in advance, it is best to pass a ZipInfo\n        instance for name, with zinfo.file_size set.\n        \"\"\"\n        if mode not in {\"r\", \"w\"}:\n            raise ValueError('open() requires mode \"r\" or \"w\"')\n        if pwd and not isinstance(pwd, bytes):\n            raise TypeError(\"pwd: expected bytes, got %s\" % type(pwd).__name__)\n        if pwd and (mode == \"w\"):\n            raise ValueError(\"pwd is only supported for reading files\")\n        if not self.fp:\n            raise ValueError(\n                \"Attempt to use ZIP archive that was already closed\")\n\n        # Make sure we have an info object\n        if isinstance(name, ZipInfo):\n            # 'name' is already an info object\n            zinfo = name\n        elif mode == 'w':\n            zinfo = ZipInfo(name)\n            zinfo.compress_type = self.compression\n            zinfo._compresslevel = self.compresslevel\n        else:\n            # Get info object for name\n            zinfo = self.getinfo(name)\n\n        if mode == 'w':\n            return self._open_to_write(zinfo, force_zip64=force_zip64)\n\n        if self._writing:\n            raise ValueError(\"Can't read from the ZIP file while there \"\n                    \"is an open writing handle on it. \"\n                    \"Close the writing handle before trying to read.\")\n\n        # Open for reading:\n        self._fileRefCnt += 1\n        zef_file = _SharedFile(self.fp, zinfo.header_offset,\n                               self._fpclose, self._lock, lambda: self._writing)\n        try:\n            # Skip the file header:\n            fheader = zef_file.read(sizeFileHeader)\n            if len(fheader) != sizeFileHeader:\n                raise BadZipFile(\"Truncated file header\")\n            fheader = struct.unpack(structFileHeader, fheader)\n            if fheader[_FH_SIGNATURE] != stringFileHeader:\n                raise BadZipFile(\"Bad magic number for file header\")\n\n            fname = zef_file.read(fheader[_FH_FILENAME_LENGTH])\n            if fheader[_FH_EXTRA_FIELD_LENGTH]:\n                zef_file.read(fheader[_FH_EXTRA_FIELD_LENGTH])\n\n            if zinfo.flag_bits &amp; 0x20:\n                # Zip 2.7: compressed patched data\n                raise NotImplementedError(\"compressed patched data (flag bit 5)\")\n\n            if zinfo.flag_bits &amp; 0x40:\n                # strong encryption\n                raise NotImplementedError(\"strong encryption (flag bit 6)\")\n\n            if fheader[_FH_GENERAL_PURPOSE_FLAG_BITS] &amp; 0x800:\n                # UTF-8 filename\n                fname_str = fname.decode(\"utf-8\")\n            else:\n                fname_str = fname.decode(\"cp437\")\n\n            if fname_str != zinfo.orig_filename:\n                raise BadZipFile(\n                    'File name in directory %r and header %r differ.'\n                    % (zinfo.orig_filename, fname))\n\n            if (zinfo._end_offset is not None and\n                zef_file.tell() + zinfo.compress_size &gt; zinfo._end_offset):\n                raise BadZipFile(f\"Overlapped entries: {zinfo.orig_filename!r} (possible zip bomb)\")\n\n            # check for encrypted flag &amp; handle password\n            is_encrypted = zinfo.flag_bits &amp; 0x1\n            if is_encrypted:\n                if not pwd:\n                    pwd = self.pwd\n                if not pwd:\n&gt;                   raise RuntimeError(\"File %r is encrypted, password \"\n                                       \"required for extraction\" % name)\nE                                      RuntimeError: File 'fake-repo-tmpl/cookiecutter.json' is encrypted, password required for extraction\n\n/usr/lib/python3.10/zipfile.py:1581: RuntimeError"},{"location":"analysis_baseline_cookiecutter/#test_unzippytest_unzip_protected_local_file_user_password","title":"test_unzip.py::test_unzip_protected_local_file_user_password","text":"<pre>test_unzip.py::test_unzip_protected_local_file_user_password</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_unzip_protected_local_fil3/clone_dir')\n\n    def test_unzip_protected_local_file_user_password(mocker, clone_dir):\n        \"\"\"A password-protected local file reference can be unzipped.\"\"\"\n        mock_prompt_and_delete = mocker.patch(\n            'cookiecutter.zipfile.prompt_and_delete', return_value=True, autospec=True\n        )\n        mocker.patch('cookiecutter.zipfile.read_repo_password', return_value='sekrit')\n\n&gt;       output_dir = zipfile.unzip(\n            'tests/files/protected-fake-repo-tmpl.zip',\n            is_url=False,\n            clone_to_dir=str(clone_dir),\n        )\n\ntests/zipfile/test_unzip.py:100: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/zipfile.py:46: in unzip\n    if zip_ref.namelist() and zip_ref.testzip() is not None:\n/usr/lib/python3.10/zipfile.py:1442: in testzip\n    with self.open(zinfo.filename, \"r\") as f:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = , name = 'fake-repo-tmpl/cookiecutter.json'\nmode = 'r', pwd = None\n\n    def open(self, name, mode=\"r\", pwd=None, *, force_zip64=False):\n        \"\"\"Return file-like object for 'name'.\n\n        name is a string for the file name within the ZIP file, or a ZipInfo\n        object.\n\n        mode should be 'r' to read a file already in the ZIP file, or 'w' to\n        write to a file newly added to the archive.\n\n        pwd is the password to decrypt files (only used for reading).\n\n        When writing, if the file size is not known in advance but may exceed\n        2 GiB, pass force_zip64 to use the ZIP64 format, which can handle large\n        files.  If the size is known in advance, it is best to pass a ZipInfo\n        instance for name, with zinfo.file_size set.\n        \"\"\"\n        if mode not in {\"r\", \"w\"}:\n            raise ValueError('open() requires mode \"r\" or \"w\"')\n        if pwd and not isinstance(pwd, bytes):\n            raise TypeError(\"pwd: expected bytes, got %s\" % type(pwd).__name__)\n        if pwd and (mode == \"w\"):\n            raise ValueError(\"pwd is only supported for reading files\")\n        if not self.fp:\n            raise ValueError(\n                \"Attempt to use ZIP archive that was already closed\")\n\n        # Make sure we have an info object\n        if isinstance(name, ZipInfo):\n            # 'name' is already an info object\n            zinfo = name\n        elif mode == 'w':\n            zinfo = ZipInfo(name)\n            zinfo.compress_type = self.compression\n            zinfo._compresslevel = self.compresslevel\n        else:\n            # Get info object for name\n            zinfo = self.getinfo(name)\n\n        if mode == 'w':\n            return self._open_to_write(zinfo, force_zip64=force_zip64)\n\n        if self._writing:\n            raise ValueError(\"Can't read from the ZIP file while there \"\n                    \"is an open writing handle on it. \"\n                    \"Close the writing handle before trying to read.\")\n\n        # Open for reading:\n        self._fileRefCnt += 1\n        zef_file = _SharedFile(self.fp, zinfo.header_offset,\n                               self._fpclose, self._lock, lambda: self._writing)\n        try:\n            # Skip the file header:\n            fheader = zef_file.read(sizeFileHeader)\n            if len(fheader) != sizeFileHeader:\n                raise BadZipFile(\"Truncated file header\")\n            fheader = struct.unpack(structFileHeader, fheader)\n            if fheader[_FH_SIGNATURE] != stringFileHeader:\n                raise BadZipFile(\"Bad magic number for file header\")\n\n            fname = zef_file.read(fheader[_FH_FILENAME_LENGTH])\n            if fheader[_FH_EXTRA_FIELD_LENGTH]:\n                zef_file.read(fheader[_FH_EXTRA_FIELD_LENGTH])\n\n            if zinfo.flag_bits &amp; 0x20:\n                # Zip 2.7: compressed patched data\n                raise NotImplementedError(\"compressed patched data (flag bit 5)\")\n\n            if zinfo.flag_bits &amp; 0x40:\n                # strong encryption\n                raise NotImplementedError(\"strong encryption (flag bit 6)\")\n\n            if fheader[_FH_GENERAL_PURPOSE_FLAG_BITS] &amp; 0x800:\n                # UTF-8 filename\n                fname_str = fname.decode(\"utf-8\")\n            else:\n                fname_str = fname.decode(\"cp437\")\n\n            if fname_str != zinfo.orig_filename:\n                raise BadZipFile(\n                    'File name in directory %r and header %r differ.'\n                    % (zinfo.orig_filename, fname))\n\n            if (zinfo._end_offset is not None and\n                zef_file.tell() + zinfo.compress_size &gt; zinfo._end_offset):\n                raise BadZipFile(f\"Overlapped entries: {zinfo.orig_filename!r} (possible zip bomb)\")\n\n            # check for encrypted flag &amp; handle password\n            is_encrypted = zinfo.flag_bits &amp; 0x1\n            if is_encrypted:\n                if not pwd:\n                    pwd = self.pwd\n                if not pwd:\n&gt;                   raise RuntimeError(\"File %r is encrypted, password \"\n                                       \"required for extraction\" % name)\nE                                      RuntimeError: File 'fake-repo-tmpl/cookiecutter.json' is encrypted, password required for extraction\n\n/usr/lib/python3.10/zipfile.py:1581: RuntimeError"},{"location":"analysis_baseline_cookiecutter/#test_unzippytest_unzip_protected_local_file_user_bad_password","title":"test_unzip.py::test_unzip_protected_local_file_user_bad_password","text":"<pre>test_unzip.py::test_unzip_protected_local_file_user_bad_password</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_unzip_protected_local_fil4/clone_dir')\n\n    def test_unzip_protected_local_file_user_bad_password(mocker, clone_dir):\n        \"\"\"Error in `unzip()`, if user can't provide a valid password.\"\"\"\n        mocker.patch(\n            'cookiecutter.zipfile.prompt_and_delete', return_value=True, autospec=True\n        )\n        mocker.patch(\n            'cookiecutter.zipfile.read_repo_password', return_value='not-the-right-password'\n        )\n\n        with pytest.raises(InvalidZipRepository):\n&gt;           zipfile.unzip(\n                'tests/files/protected-fake-repo-tmpl.zip',\n                is_url=False,\n                clone_to_dir=str(clone_dir),\n            )\n\ntests/zipfile/test_unzip.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/zipfile.py:46: in unzip\n    if zip_ref.namelist() and zip_ref.testzip() is not None:\n/usr/lib/python3.10/zipfile.py:1442: in testzip\n    with self.open(zinfo.filename, \"r\") as f:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = , name = 'fake-repo-tmpl/cookiecutter.json'\nmode = 'r', pwd = None\n\n    def open(self, name, mode=\"r\", pwd=None, *, force_zip64=False):\n        \"\"\"Return file-like object for 'name'.\n\n        name is a string for the file name within the ZIP file, or a ZipInfo\n        object.\n\n        mode should be 'r' to read a file already in the ZIP file, or 'w' to\n        write to a file newly added to the archive.\n\n        pwd is the password to decrypt files (only used for reading).\n\n        When writing, if the file size is not known in advance but may exceed\n        2 GiB, pass force_zip64 to use the ZIP64 format, which can handle large\n        files.  If the size is known in advance, it is best to pass a ZipInfo\n        instance for name, with zinfo.file_size set.\n        \"\"\"\n        if mode not in {\"r\", \"w\"}:\n            raise ValueError('open() requires mode \"r\" or \"w\"')\n        if pwd and not isinstance(pwd, bytes):\n            raise TypeError(\"pwd: expected bytes, got %s\" % type(pwd).__name__)\n        if pwd and (mode == \"w\"):\n            raise ValueError(\"pwd is only supported for reading files\")\n        if not self.fp:\n            raise ValueError(\n                \"Attempt to use ZIP archive that was already closed\")\n\n        # Make sure we have an info object\n        if isinstance(name, ZipInfo):\n            # 'name' is already an info object\n            zinfo = name\n        elif mode == 'w':\n            zinfo = ZipInfo(name)\n            zinfo.compress_type = self.compression\n            zinfo._compresslevel = self.compresslevel\n        else:\n            # Get info object for name\n            zinfo = self.getinfo(name)\n\n        if mode == 'w':\n            return self._open_to_write(zinfo, force_zip64=force_zip64)\n\n        if self._writing:\n            raise ValueError(\"Can't read from the ZIP file while there \"\n                    \"is an open writing handle on it. \"\n                    \"Close the writing handle before trying to read.\")\n\n        # Open for reading:\n        self._fileRefCnt += 1\n        zef_file = _SharedFile(self.fp, zinfo.header_offset,\n                               self._fpclose, self._lock, lambda: self._writing)\n        try:\n            # Skip the file header:\n            fheader = zef_file.read(sizeFileHeader)\n            if len(fheader) != sizeFileHeader:\n                raise BadZipFile(\"Truncated file header\")\n            fheader = struct.unpack(structFileHeader, fheader)\n            if fheader[_FH_SIGNATURE] != stringFileHeader:\n                raise BadZipFile(\"Bad magic number for file header\")\n\n            fname = zef_file.read(fheader[_FH_FILENAME_LENGTH])\n            if fheader[_FH_EXTRA_FIELD_LENGTH]:\n                zef_file.read(fheader[_FH_EXTRA_FIELD_LENGTH])\n\n            if zinfo.flag_bits &amp; 0x20:\n                # Zip 2.7: compressed patched data\n                raise NotImplementedError(\"compressed patched data (flag bit 5)\")\n\n            if zinfo.flag_bits &amp; 0x40:\n                # strong encryption\n                raise NotImplementedError(\"strong encryption (flag bit 6)\")\n\n            if fheader[_FH_GENERAL_PURPOSE_FLAG_BITS] &amp; 0x800:\n                # UTF-8 filename\n                fname_str = fname.decode(\"utf-8\")\n            else:\n                fname_str = fname.decode(\"cp437\")\n\n            if fname_str != zinfo.orig_filename:\n                raise BadZipFile(\n                    'File name in directory %r and header %r differ.'\n                    % (zinfo.orig_filename, fname))\n\n            if (zinfo._end_offset is not None and\n                zef_file.tell() + zinfo.compress_size &gt; zinfo._end_offset):\n                raise BadZipFile(f\"Overlapped entries: {zinfo.orig_filename!r} (possible zip bomb)\")\n\n            # check for encrypted flag &amp; handle password\n            is_encrypted = zinfo.flag_bits &amp; 0x1\n            if is_encrypted:\n                if not pwd:\n                    pwd = self.pwd\n                if not pwd:\n&gt;                   raise RuntimeError(\"File %r is encrypted, password \"\n                                       \"required for extraction\" % name)\nE                                      RuntimeError: File 'fake-repo-tmpl/cookiecutter.json' is encrypted, password required for extraction\n\n/usr/lib/python3.10/zipfile.py:1581: RuntimeError"},{"location":"analysis_baseline_cookiecutter/#test_unzippytest_empty_zip_file","title":"test_unzip.py::test_empty_zip_file","text":"<pre>test_unzip.py::test_empty_zip_file</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_empty_zip_file0/clone_dir')\n\n    def test_empty_zip_file(mocker, clone_dir):\n        \"\"\"In `unzip()`, an empty file raises an error.\"\"\"\n        mocker.patch(\n            'cookiecutter.zipfile.prompt_and_delete', return_value=True, autospec=True\n        )\n\n        with pytest.raises(InvalidZipRepository):\n&gt;           zipfile.unzip(\n                'tests/files/empty.zip', is_url=False, clone_to_dir=str(clone_dir)\n            )\n\ntests/zipfile/test_unzip.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nzip_uri = 'tests/files/empty.zip', is_url = False\nclone_to_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_empty_zip_file0/clone_dir')\nno_input = False, password = None\n\n    def unzip(zip_uri: str, is_url: bool, clone_to_dir: 'os.PathLike[str]'='.',\n        no_input: bool=False, password: Optional[str]=None):\n        \"\"\"Download and unpack a zipfile at a given URI.\n\n        This will download the zipfile to the cookiecutter repository,\n        and unpack into a temporary directory.\n\n        :param zip_uri: The URI for the zipfile.\n        :param is_url: Is the zip URI a URL or a file?\n        :param clone_to_dir: The cookiecutter repository directory\n            to put the archive into.\n        :param no_input: Do not prompt for user input and eventually force a refresh of\n            cached resources.\n        :param password: The password to use when unpacking the repository.\n        \"\"\"\n        clone_to_dir = Path(clone_to_dir)\n        make_sure_path_exists(clone_to_dir)\n\n        if is_url:\n            # Download the file\n            response = requests.get(zip_uri)\n            response.raise_for_status()\n            zip_file = tempfile.NamedTemporaryFile(delete=False, suffix='.zip', dir=clone_to_dir)\n            zip_file.write(response.content)\n            zip_file.close()\n            zip_path = Path(zip_file.name)\n        else:\n            zip_path = Path(zip_uri)\n\n        # Create a temporary directory to extract the contents\n        with tempfile.TemporaryDirectory(dir=clone_to_dir) as temp_dir:\n            try:\n                with ZipFile(zip_path, 'r') as zip_ref:\n                    if zip_ref.namelist() and zip_ref.testzip() is not None:\n                        raise InvalidZipRepository(f\"The zip file {zip_uri} is invalid or corrupt.\")\n\n&gt;                   if password is None and zip_ref.namelist()[0].endswith('/'):\nE                   IndexError: list index out of range\n\ncookiecutter/zipfile.py:49: IndexError"},{"location":"analysis_baseline_cookiecutter/#test_unzippytest_non_repo_zip_file","title":"test_unzip.py::test_non_repo_zip_file","text":"<pre>test_unzip.py::test_non_repo_zip_file</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_non_repo_zip_file0/clone_dir')\n\n    def test_non_repo_zip_file(mocker, clone_dir):\n        \"\"\"In `unzip()`, a repository must have a top level directory.\"\"\"\n        mocker.patch(\n            'cookiecutter.zipfile.prompt_and_delete', return_value=True, autospec=True\n        )\n\n&gt;       with pytest.raises(InvalidZipRepository):\nE       Failed: DID NOT RAISE \n\ntests/zipfile/test_unzip.py:145: Failed"},{"location":"analysis_baseline_cookiecutter/#test_unzippytest_unzip_url","title":"test_unzip.py::test_unzip_url","text":"<pre>test_unzip.py::test_unzip_url</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_unzip_url0/clone_dir')\n\n    def test_unzip_url(mocker, clone_dir):\n        \"\"\"In `unzip()`, a url will be downloaded and unzipped.\"\"\"\n        mock_prompt_and_delete = mocker.patch(\n            'cookiecutter.zipfile.prompt_and_delete', return_value=True, autospec=True\n        )\n\n        request = mocker.MagicMock()\n        request.iter_content.return_value = mock_download()\n\n        mocker.patch(\n            'cookiecutter.zipfile.requests.get',\n            return_value=request,\n            autospec=True,\n        )\n\n&gt;       output_dir = zipfile.unzip(\n            'https://example.com/path/to/fake-repo-tmpl.zip',\n            is_url=True,\n            clone_to_dir=str(clone_dir),\n        )\n\ntests/zipfile/test_unzip.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/zipfile.py:36: in unzip\n    zip_file.write(response.content)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (,), kwargs = {}\n\n    @_functools.wraps(func)\n    def func_wrapper(*args, **kwargs):\n&gt;       return func(*args, **kwargs)\nE       TypeError: a bytes-like object is required, not 'MagicMock'\n\n/usr/lib/python3.10/tempfile.py:638: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_unzippytest_unzip_url_with_empty_chunks","title":"test_unzip.py::test_unzip_url_with_empty_chunks","text":"<pre>test_unzip.py::test_unzip_url_with_empty_chunks</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_unzip_url_with_empty_chun0/clone_dir')\n\n    def test_unzip_url_with_empty_chunks(mocker, clone_dir):\n        \"\"\"In `unzip()` empty chunk must be ignored.\"\"\"\n        mock_prompt_and_delete = mocker.patch(\n            'cookiecutter.zipfile.prompt_and_delete', return_value=True, autospec=True\n        )\n\n        request = mocker.MagicMock()\n        request.iter_content.return_value = mock_download_with_empty_chunks()\n\n        mocker.patch(\n            'cookiecutter.zipfile.requests.get',\n            return_value=request,\n            autospec=True,\n        )\n\n&gt;       output_dir = zipfile.unzip(\n            'https://example.com/path/to/fake-repo-tmpl.zip',\n            is_url=True,\n            clone_to_dir=str(clone_dir),\n        )\n\ntests/zipfile/test_unzip.py:203: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/zipfile.py:36: in unzip\n    zip_file.write(response.content)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (,), kwargs = {}\n\n    @_functools.wraps(func)\n    def func_wrapper(*args, **kwargs):\n&gt;       return func(*args, **kwargs)\nE       TypeError: a bytes-like object is required, not 'MagicMock'\n\n/usr/lib/python3.10/tempfile.py:638: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_unzippytest_unzip_url_existing_cache","title":"test_unzip.py::test_unzip_url_existing_cache","text":"<pre>test_unzip.py::test_unzip_url_existing_cache</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_unzip_url_existing_cache0/clone_dir')\n\n    def test_unzip_url_existing_cache(mocker, clone_dir):\n        \"\"\"Url should be downloaded and unzipped, old zip file will be removed.\"\"\"\n        mock_prompt_and_delete = mocker.patch(\n            'cookiecutter.zipfile.prompt_and_delete', return_value=True, autospec=True\n        )\n\n        request = mocker.MagicMock()\n        request.iter_content.return_value = mock_download()\n\n        mocker.patch(\n            'cookiecutter.zipfile.requests.get',\n            return_value=request,\n            autospec=True,\n        )\n\n        # Create an existing cache of the zipfile\n        existing_zip = clone_dir.joinpath('fake-repo-tmpl.zip')\n        existing_zip.write_text('This is an existing zipfile')\n\n&gt;       output_dir = zipfile.unzip(\n            'https://example.com/path/to/fake-repo-tmpl.zip',\n            is_url=True,\n            clone_to_dir=str(clone_dir),\n        )\n\ntests/zipfile/test_unzip.py:232: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/zipfile.py:36: in unzip\n    zip_file.write(response.content)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (,), kwargs = {}\n\n    @_functools.wraps(func)\n    def func_wrapper(*args, **kwargs):\n&gt;       return func(*args, **kwargs)\nE       TypeError: a bytes-like object is required, not 'MagicMock'\n\n/usr/lib/python3.10/tempfile.py:638: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_unzippytest_unzip_url_existing_cache_no_input","title":"test_unzip.py::test_unzip_url_existing_cache_no_input","text":"<pre>test_unzip.py::test_unzip_url_existing_cache_no_input</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_unzip_url_existing_cache_0/clone_dir')\n\n    def test_unzip_url_existing_cache_no_input(mocker, clone_dir):\n        \"\"\"If no_input is provided, the existing file should be removed.\"\"\"\n        request = mocker.MagicMock()\n        request.iter_content.return_value = mock_download()\n\n        mocker.patch(\n            'cookiecutter.zipfile.requests.get',\n            return_value=request,\n            autospec=True,\n        )\n\n        # Create an existing cache of the zipfile\n        existing_zip = clone_dir.joinpath('fake-repo-tmpl.zip')\n        existing_zip.write_text('This is an existing zipfile')\n\n&gt;       output_dir = zipfile.unzip(\n            'https://example.com/path/to/fake-repo-tmpl.zip',\n            is_url=True,\n            clone_to_dir=str(clone_dir),\n            no_input=True,\n        )\n\ntests/zipfile/test_unzip.py:257: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/zipfile.py:36: in unzip\n    zip_file.write(response.content)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (,), kwargs = {}\n\n    @_functools.wraps(func)\n    def func_wrapper(*args, **kwargs):\n&gt;       return func(*args, **kwargs)\nE       TypeError: a bytes-like object is required, not 'MagicMock'\n\n/usr/lib/python3.10/tempfile.py:638: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_unzippytest_unzip_should_abort_if_no_redownload","title":"test_unzip.py::test_unzip_should_abort_if_no_redownload","text":"<pre>test_unzip.py::test_unzip_should_abort_if_no_redownload</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_unzip_should_abort_if_no_0/clone_dir')\n\n    def test_unzip_should_abort_if_no_redownload(mocker, clone_dir):\n        \"\"\"Should exit without cloning anything If no redownload.\"\"\"\n        mocker.patch(\n            'cookiecutter.zipfile.prompt_and_delete', side_effect=SystemExit, autospec=True\n        )\n\n        mock_requests_get = mocker.patch(\n            'cookiecutter.zipfile.requests.get',\n            autospec=True,\n        )\n\n        # Create an existing cache of the zipfile\n        existing_zip = clone_dir.joinpath('fake-repo-tmpl.zip')\n        existing_zip.write_text('This is an existing zipfile')\n\n        zipfile_url = 'https://example.com/path/to/fake-repo-tmpl.zip'\n\n        with pytest.raises(SystemExit):\n&gt;           zipfile.unzip(zipfile_url, is_url=True, clone_to_dir=str(clone_dir))\n\ntests/zipfile/test_unzip.py:285: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/zipfile.py:36: in unzip\n    zip_file.write(response.content)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (,), kwargs = {}\n\n    @_functools.wraps(func)\n    def func_wrapper(*args, **kwargs):\n&gt;       return func(*args, **kwargs)\nE       TypeError: a bytes-like object is required, not 'MagicMock'\n\n/usr/lib/python3.10/tempfile.py:638: TypeError"},{"location":"analysis_baseline_cookiecutter/#test_unzippytest_unzip_is_ok_to_reuse","title":"test_unzip.py::test_unzip_is_ok_to_reuse","text":"<pre>test_unzip.py::test_unzip_is_ok_to_reuse</pre><pre>\nmocker = \nclone_dir = PosixPath('/tmp/pytest-of-root/pytest-0/test_unzip_is_ok_to_reuse0/clone_dir')\n\n    def test_unzip_is_ok_to_reuse(mocker, clone_dir):\n        \"\"\"Already downloaded zip should not be downloaded again.\"\"\"\n        mock_prompt_and_delete = mocker.patch(\n            'cookiecutter.zipfile.prompt_and_delete', return_value=False, autospec=True\n        )\n\n        request = mocker.MagicMock()\n\n        existing_zip = clone_dir.joinpath('fake-repo-tmpl.zip')\n        shutil.copy('tests/files/fake-repo-tmpl.zip', existing_zip)\n\n&gt;       output_dir = zipfile.unzip(\n            'https://example.com/path/to/fake-repo-tmpl.zip',\n            is_url=True,\n            clone_to_dir=str(clone_dir),\n        )\n\ntests/zipfile/test_unzip.py:301: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ncookiecutter/zipfile.py:34: in unzip\n    response.raise_for_status()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def raise_for_status(self):\n        \"\"\"Raises :class:`HTTPError`, if one occurred.\"\"\"\n\n        http_error_msg = \"\"\n        if isinstance(self.reason, bytes):\n            # We attempt to decode utf-8 first because some servers\n            # choose to localize their reason strings. If the string\n            # isn't utf-8, we fall back to iso-8859-1 for all other\n            # encodings. (See PR #3538)\n            try:\n                reason = self.reason.decode(\"utf-8\")\n            except UnicodeDecodeError:\n                reason = self.reason.decode(\"iso-8859-1\")\n        else:\n            reason = self.reason\n\n        if 400 &lt;= self.status_code &lt; 500:\n            http_error_msg = (\n                f\"{self.status_code} Client Error: {reason} for url: {self.url}\"\n            )\n\n        elif 500 &lt;= self.status_code &lt; 600:\n            http_error_msg = (\n                f\"{self.status_code} Server Error: {reason} for url: {self.url}\"\n            )\n\n        if http_error_msg:\n&gt;           raise HTTPError(http_error_msg, response=self)\nE           requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://example.com/path/to/fake-repo-tmpl.zip\n\n.venv/lib/python3.10/site-packages/requests/models.py:1024: HTTPError"},{"location":"analysis_baseline_cookiecutter/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/cookiecutter/cli.py b/cookiecutter/cli.py\nindex b050655..3b261fe 100644\n--- a/cookiecutter/cli.py\n+++ b/cookiecutter/cli.py\n@@ -13,17 +13,41 @@ from cookiecutter.main import cookiecutter\n\n def version_msg():\n     \"\"\"Return the Cookiecutter version, location and Python powering it.\"\"\"\n-    pass\n+    python_version = sys.version[:3]\n+    location = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n+    return f\"Cookiecutter {__version__} from {location} (Python {python_version})\"\n\n\n def validate_extra_context(ctx, param, value):\n     \"\"\"Validate extra context.\"\"\"\n-    pass\n+    for s in value:\n+        if '=' not in s:\n+            raise click.BadParameter(\n+                f'\"{s}\" is not a valid key/value pair. '\n+                'Use the format key=value.'\n+            )\n+    return collections.OrderedDict(v.split('=', 1) for v in value)\n\n\n def list_installed_templates(default_config, passed_config_file):\n     \"\"\"List installed (locally cloned) templates. Use cookiecutter --list-installed.\"\"\"\n-    pass\n+    config = get_user_config(default_config=default_config, config_file=passed_config_file)\n+    template_dir = config.get('cookiecutters_dir')\n+    if not os.path.exists(template_dir):\n+        click.echo(f\"No templates found in {template_dir}\")\n+        return\n+\n+    template_names = [\n+        d for d in os.listdir(template_dir)\n+        if os.path.isdir(os.path.join(template_dir, d))\n+    ]\n+\n+    if not template_names:\n+        click.echo(f\"No templates found in {template_dir}\")\n+    else:\n+        click.echo(\"Installed templates:\")\n+        for template_name in template_names:\n+            click.echo(f\"  {template_name}\")\n\n\n @click.command(context_settings=dict(help_option_names=['-h', '--help']))\n@@ -74,7 +98,37 @@ def main(template, extra_context, no_input, checkout, verbose, replay,\n     volunteers. If you would like to help out or fund the project, please get\n     in touch at https://github.com/cookiecutter/cookiecutter.\n     \"\"\"\n-    pass\n+    if list_installed:\n+        list_installed_templates(default_config, config_file)\n+        return\n+\n+    configure_logger(stream_level='DEBUG' if verbose else 'INFO',\n+                     debug_file=debug_file)\n+\n+    try:\n+        cookiecutter(\n+            template,\n+            checkout=checkout,\n+            no_input=no_input,\n+            extra_context=extra_context,\n+            replay=replay,\n+            overwrite_if_exists=overwrite_if_exists,\n+            output_dir=output_dir,\n+            config_file=config_file,\n+            default_config=default_config,\n+            password=None,\n+            directory=directory,\n+            skip_if_file_exists=skip_if_file_exists,\n+            accept_hooks=accept_hooks,\n+            keep_project_on_failure=keep_project_on_failure,\n+        )\n+    except (ContextDecodingException, OutputDirExistsException,\n+            InvalidModeException, FailedHookException,\n+            UnknownExtension, InvalidZipRepository,\n+            RepositoryNotFound, RepositoryCloneFailed,\n+            UndefinedVariableInTemplate) as e:\n+        click.echo(f\"Error: {e}\")\n+        sys.exit(1)\n\n\n if __name__ == '__main__':\ndiff --git a/cookiecutter/config.py b/cookiecutter/config.py\nindex 6356215..2b0e70d 100644\n--- a/cookiecutter/config.py\n+++ b/cookiecutter/config.py\n@@ -17,7 +17,7 @@ DEFAULT_CONFIG = {'cookiecutters_dir': os.path.expanduser(\n\n def _expand_path(path):\n     \"\"\"Expand both environment variables and user home in the given path.\"\"\"\n-    pass\n+    return os.path.expandvars(os.path.expanduser(path))\n\n\n def merge_configs(default, overwrite):\n@@ -26,12 +26,30 @@ def merge_configs(default, overwrite):\n     Dict values that are dictionaries themselves will be updated, whilst\n     preserving existing keys.\n     \"\"\"\n-    pass\n+    new_config = copy.deepcopy(default)\n+    for k, v in overwrite.items():\n+        if isinstance(v, dict):\n+            new_config[k] = merge_configs(new_config.get(k, {}), v)\n+        else:\n+            new_config[k] = v\n+    return new_config\n\n\n def get_config(config_path):\n     \"\"\"Retrieve the config from the specified path, returning a config dict.\"\"\"\n-    pass\n+    if not os.path.exists(config_path):\n+        raise ConfigDoesNotExistException(f\"Config file {config_path} does not exist.\")\n+\n+    with open(config_path) as file_handle:\n+        try:\n+            user_config = yaml.safe_load(file_handle)\n+        except yaml.YAMLError as e:\n+            raise InvalidConfiguration(f\"Unable to parse YAML file {config_path}: {e}\")\n+\n+    if user_config is None:\n+        raise InvalidConfiguration(f\"Config file {config_path} is empty.\")\n+\n+    return user_config\n\n\n def get_user_config(config_file=None, default_config=False):\n@@ -53,4 +71,20 @@ def get_user_config(config_file=None, default_config=False):\n     If the environment variable is not set, try the default config file path\n     before falling back to the default config values.\n     \"\"\"\n-    pass\n+    if isinstance(default_config, dict):\n+        return merge_configs(DEFAULT_CONFIG, default_config)\n+\n+    if default_config:\n+        return copy.deepcopy(DEFAULT_CONFIG)\n+\n+    if config_file and config_file != USER_CONFIG_PATH:\n+        return get_config(config_file)\n+\n+    user_config = os.environ.get('COOKIECUTTER_CONFIG')\n+    if user_config:\n+        return get_config(user_config)\n+\n+    if os.path.exists(USER_CONFIG_PATH):\n+        return get_config(USER_CONFIG_PATH)\n+\n+    return copy.deepcopy(DEFAULT_CONFIG)\ndiff --git a/cookiecutter/environment.py b/cookiecutter/environment.py\nindex 8a7bb61..b2495b8 100644\n--- a/cookiecutter/environment.py\n+++ b/cookiecutter/environment.py\n@@ -37,7 +37,8 @@ class ExtensionLoaderMixin:\n         If context does not contain the relevant info, return an empty\n         list instead.\n         \"\"\"\n-        pass\n+        extensions = context.get('cookiecutter', {}).get('_extensions', [])\n+        return [str(ext) for ext in extensions]\n\n\n class StrictEnvironment(ExtensionLoaderMixin, Environment):\ndiff --git a/cookiecutter/extensions.py b/cookiecutter/extensions.py\nindex 8ce014a..865d856 100644\n--- a/cookiecutter/extensions.py\n+++ b/cookiecutter/extensions.py\n@@ -5,6 +5,7 @@ import uuid\n from secrets import choice\n import arrow\n from jinja2 import nodes\n+from jinja2 import nodes\n from jinja2.ext import Extension\n from slugify import slugify as pyslugify\n\n@@ -74,4 +75,20 @@ class TimeExtension(Extension):\n\n     def parse(self, parser):\n         \"\"\"Parse datetime template and add datetime value.\"\"\"\n-        pass\n+        lineno = next(parser.stream).lineno\n+        token = parser.stream.next()\n+        format_string = self.environment.datetime_format\n+        if token.type == 'string':\n+            format_string = token.value\n+        \n+        node = nodes.Call(\n+            self.call_method('_render_now', [nodes.Const(format_string)]),\n+            [],\n+            [],\n+            None,\n+            None\n+        )\n+        return nodes.Output([node]).set_lineno(lineno)\n+\n+    def _render_now(self, format_string):\n+        return arrow.now().format(format_string)\ndiff --git a/cookiecutter/find.py b/cookiecutter/find.py\nindex 667e50d..06ba42a 100644\n--- a/cookiecutter/find.py\n+++ b/cookiecutter/find.py\n@@ -11,6 +11,33 @@ def find_template(repo_dir: 'os.PathLike[str]', env: Environment) -&gt;Path:\n     \"\"\"Determine which child directory of ``repo_dir`` is the project template.\n\n     :param repo_dir: Local directory of newly cloned repo.\n+    :param env: Jinja2 Environment object for rendering template variables.\n     :return: Relative path to project template.\n     \"\"\"\n-    pass\n+    repo_dir = Path(repo_dir)\n+    logger.debug('Searching %s for the project template.', repo_dir)\n+\n+    # First, check for a cookiecutter.json file in the repo root\n+    if (repo_dir / 'cookiecutter.json').is_file():\n+        logger.debug('Found cookiecutter.json at project root level')\n+        return repo_dir\n+\n+    # If not found, search for the first directory with a cookiecutter.json file\n+    for dirpath, dirnames, filenames in os.walk(repo_dir):\n+        if 'cookiecutter.json' in filenames:\n+            logger.debug('Found cookiecutter.json in %s', dirpath)\n+            return Path(dirpath).relative_to(repo_dir)\n+\n+    # If no cookiecutter.json is found, look for the first directory that's not a repo artifact\n+    for path in repo_dir.iterdir():\n+        if path.is_dir() and path.name not in {'.git', '.hg', '.svn', '.bzr'}:\n+            logger.debug('Treating %s as project template', path)\n+            return path.relative_to(repo_dir)\n+\n+    # If we reach here, we couldn't find a valid template directory\n+    raise NonTemplatedInputDirException(\n+        'The repo_dir {} is not a valid template directory. '\n+        'A valid template directory must either have a cookiecutter.json '\n+        'file or have one or more directories that are not repo artifacts.'\n+        .format(repo_dir)\n+    )\ndiff --git a/cookiecutter/generate.py b/cookiecutter/generate.py\nindex 715232e..61a6452 100644\n--- a/cookiecutter/generate.py\n+++ b/cookiecutter/generate.py\n@@ -27,13 +27,30 @@ def is_copy_only_path(path, context):\n         should be rendered or just copied.\n     :param context: cookiecutter context.\n     \"\"\"\n-    pass\n+    copy_without_render = context.get('_copy_without_render', [])\n+    for pattern in copy_without_render:\n+        if fnmatch.fnmatch(path, pattern):\n+            return True\n+    return False\n\n\n def apply_overwrites_to_context(context, overwrite_context, *,\n     in_dictionary_variable=False):\n     \"\"\"Modify the given context in place based on the overwrite_context.\"\"\"\n-    pass\n+    for key, value in overwrite_context.items():\n+        if isinstance(value, dict):\n+            if key not in context:\n+                context[key] = {}\n+            apply_overwrites_to_context(context[key], value, in_dictionary_variable=True)\n+        elif isinstance(value, list):\n+            if key not in context:\n+                context[key] = []\n+            context[key].extend(value)\n+        else:\n+            if in_dictionary_variable:\n+                context[key] = value\n+            else:\n+                context[key] = str(value)\n\n\n def generate_context(context_file='cookiecutter.json', default_context=None,\n@@ -47,7 +64,23 @@ def generate_context(context_file='cookiecutter.json', default_context=None,\n     :param default_context: Dictionary containing config to take into account.\n     :param extra_context: Dictionary containing configuration overrides\n     \"\"\"\n-    pass\n+    context = OrderedDict([])\n+    try:\n+        with open(context_file) as file:\n+            obj = json.load(file, object_pairs_hook=OrderedDict)\n+        context = obj if isinstance(obj, dict) else obj[0]\n+    except ValueError as e:\n+        raise ContextDecodingException(context_file, e)\n+    \n+    # Apply default context\n+    if default_context:\n+        apply_overwrites_to_context(context, default_context)\n+    \n+    # Apply extra context\n+    if extra_context:\n+        apply_overwrites_to_context(context, extra_context)\n+    \n+    return context\n\n\n def generate_file(project_dir, infile, context, env, skip_if_file_exists=False\n@@ -72,14 +105,65 @@ def generate_file(project_dir, infile, context, env, skip_if_file_exists=False\n     :param context: Dict for populating the cookiecutter's variables.\n     :param env: Jinja2 template execution environment.\n     \"\"\"\n-    pass\n+    logger.debug('Generating file %s', infile)\n+    \n+    # Render the path to the output file\n+    outfile_tmpl = env.from_string(infile)\n+    outfile = os.path.join(project_dir, outfile_tmpl.render(**context))\n+    \n+    # Ensure output directory exists\n+    dirname = os.path.dirname(outfile)\n+    make_sure_path_exists(dirname)\n+    \n+    # Skip if file exists and skip_if_file_exists is True\n+    if skip_if_file_exists and os.path.exists(outfile):\n+        logger.debug('File %s already exists, skipping', outfile)\n+        return False\n+    \n+    # Check if infile is binary\n+    if is_binary(infile):\n+        logger.debug(\"Copying binary %s to %s without rendering\", infile, outfile)\n+        shutil.copyfile(infile, outfile)\n+    else:\n+        # Render the file\n+        try:\n+            with open(infile, 'r') as in_file:\n+                tmpl = env.from_string(in_file.read())\n+            rendered_file = tmpl.render(**context)\n+            with open(outfile, 'w') as out_file:\n+                out_file.write(rendered_file)\n+        except TemplateSyntaxError as e:\n+            logger.error('Error in template syntax in %s', infile)\n+            raise\n+        except UndefinedError as e:\n+            logger.error('Unable to render template in %s', infile)\n+            raise UndefinedVariableInTemplate(str(e), infile, context, e.message)\n+    \n+    return True\n\n\n def render_and_create_dir(dirname: str, context: dict, output_dir:\n     'os.PathLike[str]', environment: Environment, overwrite_if_exists: bool\n     =False):\n     \"\"\"Render name of a directory, create the directory, return its path.\"\"\"\n-    pass\n+    name_tmpl = environment.from_string(dirname)\n+    rendered_dirname = name_tmpl.render(**context)\n+    dir_to_create = os.path.normpath(os.path.join(output_dir, rendered_dirname))\n+\n+    logger.debug('Rendered dir %s must exist in output_dir %s', dir_to_create, output_dir)\n+\n+    if os.path.exists(dir_to_create):\n+        if overwrite_if_exists:\n+            logger.debug('Overwriting %s', dir_to_create)\n+        else:\n+            logger.error('Error that %s already exists', dir_to_create)\n+            raise OutputDirExistsException(\n+                'Error: \"{}\" directory already exists'.format(dir_to_create)\n+            )\n+    else:\n+        make_sure_path_exists(dir_to_create)\n+\n+    return dir_to_create\n\n\n def _run_hook_from_repo_dir(repo_dir, hook_name, project_dir, context,\n@@ -93,7 +177,33 @@ def _run_hook_from_repo_dir(repo_dir, hook_name, project_dir, context,\n     :param delete_project_on_failure: Delete the project directory on hook\n         failure?\n     \"\"\"\n-    pass\n+    with work_in(repo_dir):\n+        try:\n+            run_hook_from_repo_dir(\n+                repo_dir=repo_dir,\n+                hook_name=hook_name,\n+                project_dir=project_dir,\n+                context=context\n+            )\n+        except FailedHookException:\n+            if delete_project_on_failure:\n+                logger.warning(\n+                    \"Hook script failed ({}). Removing project directory {}\".format(\n+                        hook_name, project_dir\n+                    )\n+                )\n+                rmtree(project_dir)\n+            raise\n+        except Exception:\n+            # Catch all other exceptions and raise a FailedHookException\n+            logger.warning(\n+                \"Hook script failed ({}). Removing project directory {}\".format(\n+                    hook_name, project_dir\n+                )\n+            )\n+            if delete_project_on_failure:\n+                rmtree(project_dir)\n+            raise FailedHookException(hook_name)\n\n\n def generate_files(repo_dir, context=None, output_dir='.',\n@@ -112,4 +222,57 @@ def generate_files(repo_dir, context=None, output_dir='.',\n     :param keep_project_on_failure: If `True` keep generated project directory even when\n         generation fails\n     \"\"\"\n-    pass\n+    template_dir = find_template(repo_dir)\n+    logger.debug('Generating project from %s...', template_dir)\n+    context = context or {}\n+    env = create_env_with_context(context)\n+\n+    # Create project dir\n+    project_dir = render_and_create_dir(\n+        os.path.basename(repo_dir),\n+        context,\n+        output_dir,\n+        env,\n+        overwrite_if_exists\n+    )\n+\n+    # Run pre-gen hook\n+    if accept_hooks:\n+        _run_hook_from_repo_dir(repo_dir, 'pre_gen_project', project_dir, context, not keep_project_on_failure)\n+\n+    logger.debug('Project directory is %s', project_dir)\n+\n+    # Render the templates and save them to files\n+    with work_in(template_dir):\n+        for root, dirs, files in os.walk('.'):\n+            for dirname in dirs:\n+                indir = os.path.normpath(os.path.join(root, dirname))\n+                outdir = os.path.normpath(os.path.join(project_dir, indir))\n+                render_and_create_dir(\n+                    indir,\n+                    context,\n+                    project_dir,\n+                    env,\n+                    overwrite_if_exists\n+                )\n+\n+            for filename in files:\n+                infile = os.path.normpath(os.path.join(root, filename))\n+                if is_copy_only_path(infile, context):\n+                    outfile = os.path.join(project_dir, infile)\n+                    logger.debug('Copying %s to %s without rendering', infile, outfile)\n+                    shutil.copyfile(infile, outfile)\n+                else:\n+                    generate_file(\n+                        project_dir,\n+                        infile,\n+                        context,\n+                        env,\n+                        skip_if_file_exists\n+                    )\n+\n+    # Run post-gen hook\n+    if accept_hooks:\n+        _run_hook_from_repo_dir(repo_dir, 'post_gen_project', project_dir, context, not keep_project_on_failure)\n+\n+    return project_dir\ndiff --git a/cookiecutter/hooks.py b/cookiecutter/hooks.py\nindex 0aa9c52..010ff2b 100644\n--- a/cookiecutter/hooks.py\n+++ b/cookiecutter/hooks.py\n@@ -22,7 +22,11 @@ def valid_hook(hook_file, hook_name):\n     :param hook_name: The hook to find\n     :return: The hook file validity\n     \"\"\"\n-    pass\n+    return (\n+        hook_file.startswith(hook_name) and\n+        hook_file.endswith(('.py', '.sh')) and\n+        not hook_file.endswith('.pyc')\n+    )\n\n\n def find_hook(hook_name, hooks_dir='hooks'):\n@@ -37,7 +41,15 @@ def find_hook(hook_name, hooks_dir='hooks'):\n     :param hooks_dir: The hook directory in the template\n     :return: The absolute path to the hook script or None\n     \"\"\"\n-    pass\n+    hooks_dir = os.path.abspath(hooks_dir)\n+    if not os.path.isdir(hooks_dir):\n+        return None\n+\n+    for hook_file in os.listdir(hooks_dir):\n+        if valid_hook(hook_file, hook_name):\n+            return os.path.join(hooks_dir, hook_file)\n+\n+    return None\n\n\n def run_script(script_path, cwd='.'):\n@@ -46,7 +58,11 @@ def run_script(script_path, cwd='.'):\n     :param script_path: Absolute path to the script to run.\n     :param cwd: The directory to run the script from.\n     \"\"\"\n-    pass\n+    with work_in(cwd):\n+        if script_path.endswith('.py'):\n+            subprocess.check_call([sys.executable, script_path], cwd=cwd)\n+        else:\n+            subprocess.check_call([script_path], cwd=cwd)\n\n\n def run_script_with_context(script_path, cwd, context):\n@@ -56,7 +72,25 @@ def run_script_with_context(script_path, cwd, context):\n     :param cwd: The directory to run the script from.\n     :param context: Cookiecutter project template context.\n     \"\"\"\n-    pass\n+    env = create_env_with_context(context)\n+    with open(script_path, 'r') as f:\n+        script = f.read()\n+\n+    try:\n+        rendered_script = env.from_string(script).render(**context)\n+    except UndefinedError as err:\n+        msg = f\"Unable to render script '{script_path}': {err.message}\"\n+        raise FailedHookException(msg)\n+\n+    with tempfile.NamedTemporaryFile(mode='w', delete=False) as temp_script:\n+        temp_script.write(rendered_script)\n+        temp_script.flush()\n+        temp_script_path = temp_script.name\n+\n+    try:\n+        run_script(temp_script_path, cwd)\n+    finally:\n+        os.remove(temp_script_path)\n\n\n def run_hook(hook_name, project_dir, context):\n@@ -67,7 +101,13 @@ def run_hook(hook_name, project_dir, context):\n     :param project_dir: The directory to execute the script from.\n     :param context: Cookiecutter project context.\n     \"\"\"\n-    pass\n+    hook_path = find_hook(hook_name)\n+    if hook_path:\n+        logger.debug(f\"Running hook {hook_name}\")\n+        if hook_path.endswith('.py'):\n+            run_script_with_context(hook_path, project_dir, context)\n+        else:\n+            run_script(hook_path, project_dir)\n\n\n def run_hook_from_repo_dir(repo_dir, hook_name, project_dir, context,\n@@ -81,7 +121,28 @@ def run_hook_from_repo_dir(repo_dir, hook_name, project_dir, context,\n     :param delete_project_on_failure: Delete the project directory on hook\n         failure?\n     \"\"\"\n-    pass\n+    with work_in(repo_dir):\n+        try:\n+            run_hook(hook_name, project_dir, context)\n+        except FailedHookException:\n+            if delete_project_on_failure:\n+                logger.debug(\n+                    \"Hook script failed ({}). Removing project directory {}\"\n+                    .format(hook_name, project_dir)\n+                )\n+                rmtree(project_dir)\n+            raise\n+        except Exception:\n+            # Log the exception here, but do not raise it,\n+            # to avoid a cryptic error message\n+            logger.exception(f'Hook script failed ({hook_name})')\n+            if delete_project_on_failure:\n+                logger.debug(\n+                    \"Hook script failed ({}). Removing project directory {}\"\n+                    .format(hook_name, project_dir)\n+                )\n+                rmtree(project_dir)\n+            raise\n\n\n def run_pre_prompt_hook(repo_dir: 'os.PathLike[str]') -&gt;Path:\n@@ -89,4 +150,16 @@ def run_pre_prompt_hook(repo_dir: 'os.PathLike[str]') -&gt;Path:\n\n     :param repo_dir: Project template input directory.\n     \"\"\"\n-    pass\n+    with work_in(repo_dir):\n+        hook_path = find_hook('pre_prompt')\n+        if hook_path:\n+            logger.debug(\"Running pre_prompt hook\")\n+            tmp_repo_dir = create_tmp_repo_dir()\n+            try:\n+                run_script(hook_path, tmp_repo_dir)\n+                return Path(tmp_repo_dir)\n+            except Exception:\n+                logger.exception('Pre-prompt hook failed')\n+                rmtree(tmp_repo_dir)\n+                raise\n+    return Path(repo_dir)\ndiff --git a/cookiecutter/log.py b/cookiecutter/log.py\nindex 894c633..949f58f 100644\n--- a/cookiecutter/log.py\n+++ b/cookiecutter/log.py\n@@ -13,4 +13,25 @@ def configure_logger(stream_level='DEBUG', debug_file=None):\n     Set up logging to stdout with given level. If ``debug_file`` is given set\n     up logging to file with DEBUG level.\n     \"\"\"\n-    pass\n+    # Get the root logger\n+    logger = logging.getLogger()\n+    logger.setLevel(logging.DEBUG)\n+\n+    # Remove any existing handlers to avoid duplicates\n+    for handler in logger.handlers[:]:\n+        logger.removeHandler(handler)\n+\n+    # Set up console handler\n+    console_handler = logging.StreamHandler(sys.stdout)\n+    console_handler.setLevel(LOG_LEVELS.get(stream_level.upper(), logging.DEBUG))\n+    console_formatter = logging.Formatter(LOG_FORMATS.get(stream_level.upper(), LOG_FORMATS['DEBUG']))\n+    console_handler.setFormatter(console_formatter)\n+    logger.addHandler(console_handler)\n+\n+    # Set up file handler if debug_file is provided\n+    if debug_file:\n+        file_handler = logging.FileHandler(debug_file)\n+        file_handler.setLevel(logging.DEBUG)\n+        file_formatter = logging.Formatter(LOG_FORMATS['DEBUG'])\n+        file_handler.setFormatter(file_formatter)\n+        logger.addHandler(file_handler)\ndiff --git a/cookiecutter/main.py b/cookiecutter/main.py\nindex 4b1087d..fdf3dca 100644\n--- a/cookiecutter/main.py\n+++ b/cookiecutter/main.py\n@@ -52,7 +52,76 @@ def cookiecutter(template, checkout=None, no_input=False, extra_context=\n     :param keep_project_on_failure: If `True` keep generated project directory even when\n         generation fails\n     \"\"\"\n-    pass\n+    # Get user configuration\n+    config_dict = get_user_config(config_file=config_file, default_config=default_config)\n+\n+    # Determine the template directory\n+    repo_dir, cleanup = determine_repo_dir(\n+        template=template,\n+        checkout=checkout,\n+        clone_to_dir=config_dict['cookiecutters_dir'],\n+        no_input=no_input,\n+        password=password,\n+        directory=directory\n+    )\n+\n+    # Ensure cleanup function is called\n+    try:\n+        with _patch_import_path_for_repo(repo_dir):\n+            # Run pre-prompt hook\n+            if accept_hooks:\n+                run_pre_prompt_hook(repo_dir, config_dict)\n+\n+            # Generate or load context\n+            context_file = os.path.join(repo_dir, 'cookiecutter.json')\n+            context = generate_context(\n+                context_file=context_file,\n+                default_context=config_dict['default_context'],\n+                extra_context=extra_context,\n+            )\n+\n+            # Prompt the user to manually configure the context\n+            if not no_input:\n+                nested_template = choose_nested_template(repo_dir, context)\n+                if nested_template:\n+                    repo_dir = os.path.join(repo_dir, nested_template)\n+                    context_file = os.path.join(repo_dir, 'cookiecutter.json')\n+                    context = generate_context(\n+                        context_file=context_file,\n+                        default_context=config_dict['default_context'],\n+                        extra_context=extra_context,\n+                    )\n+                context = prompt_for_config(context, no_input)\n+\n+            # Load context from replay file\n+            if replay:\n+                context = load(config_dict['replay_dir'], template)\n+\n+            # Create project from local context\n+            project_dir = generate_files(\n+                repo_dir=repo_dir,\n+                context=context,\n+                overwrite_if_exists=overwrite_if_exists,\n+                skip_if_file_exists=skip_if_file_exists,\n+                output_dir=output_dir,\n+                accept_hooks=accept_hooks,\n+            )\n+\n+    except Exception:\n+        # Cleanup on failure\n+        if cleanup and not keep_project_on_failure:\n+            if os.path.exists(project_dir):\n+                rmtree(project_dir)\n+        raise\n+    else:\n+        # Successful project creation\n+        dump(config_dict['replay_dir'], template, context)\n+\n+    finally:\n+        if cleanup:\n+            cleanup()\n+\n+    return project_dir\n\n\n class _patch_import_path_for_repo:\ndiff --git a/cookiecutter/prompt.py b/cookiecutter/prompt.py\nindex 2bcc55f..da70f02 100644\n--- a/cookiecutter/prompt.py\n+++ b/cookiecutter/prompt.py\n@@ -17,7 +17,11 @@ def read_user_variable(var_name, default_value, prompts=None, prefix=''):\n     :param str var_name: Variable of the context to query the user\n     :param default_value: Value that will be returned if no input happens\n     \"\"\"\n-    pass\n+    prompt_text = f\"{prefix}{var_name}\"\n+    if prompts and var_name in prompts:\n+        prompt_text = prompts[var_name]\n+    \n+    return Prompt.ask(prompt_text, default=default_value)\n\n\n class YesNoPrompt(Confirm):\n@@ -27,7 +31,13 @@ class YesNoPrompt(Confirm):\n\n     def process_response(self, value: str) -&gt;bool:\n         \"\"\"Convert choices to a bool.\"\"\"\n-        pass\n+        value = value.lower()\n+        if value in self.yes_choices:\n+            return True\n+        elif value in self.no_choices:\n+            return False\n+        else:\n+            raise InvalidResponse(self.validate_error_message)\n\n\n def read_user_yes_no(var_name, default_value, prompts=None, prefix=''):\n@@ -44,7 +54,11 @@ def read_user_yes_no(var_name, default_value, prompts=None, prefix=''):\n     :param str question: Question to the user\n     :param default_value: Value that will be returned if no input happens\n     \"\"\"\n-    pass\n+    prompt_text = f\"{prefix}{var_name}\"\n+    if prompts and var_name in prompts:\n+        prompt_text = prompts[var_name]\n+    \n+    return YesNoPrompt.ask(prompt_text, default=default_value)\n\n\n def read_repo_password(question):\n@@ -52,7 +66,7 @@ def read_repo_password(question):\n\n     :param str question: Question to the user\n     \"\"\"\n-    pass\n+    return Prompt.ask(question, password=True)\n\n\n def read_user_choice(var_name, options, prompts=None, prefix=''):\n@@ -64,7 +78,17 @@ def read_user_choice(var_name, options, prompts=None, prefix=''):\n     :param list options: Sequence of options that are available to select from\n     :return: Exactly one item of ``options`` that has been chosen by the user\n     \"\"\"\n-    pass\n+    prompt_text = f\"{prefix}{var_name}\"\n+    if prompts and var_name in prompts:\n+        prompt_text = prompts[var_name]\n+    \n+    choices = [str(i) for i in range(len(options))]\n+    choice_text = \"\\n\".join(f\"{i}: {option}\" for i, option in enumerate(options))\n+    \n+    while True:\n+        print(f\"{prompt_text}\\n{choice_text}\")\n+        choice = Prompt.ask(\"Enter the number of your choice\", choices=choices, default=\"0\")\n+        return options[int(choice)]\n\n\n DEFAULT_DISPLAY = 'default'\n@@ -75,7 +99,10 @@ def process_json(user_value, default_value=None):\n\n     :param str user_value: User-supplied value to load as a JSON dict\n     \"\"\"\n-    pass\n+    try:\n+        return json.loads(user_value)\n+    except json.JSONDecodeError:\n+        return default_value\n\n\n class JsonPrompt(PromptBase[dict]):\n@@ -87,7 +114,10 @@ class JsonPrompt(PromptBase[dict]):\n\n     def process_response(self, value: str) -&gt;dict:\n         \"\"\"Convert choices to a dict.\"\"\"\n-        pass\n+        try:\n+            return json.loads(value)\n+        except json.JSONDecodeError:\n+            raise InvalidResponse(self.validate_error_message)\n\n\n def read_user_dict(var_name, default_value, prompts=None, prefix=''):\n@@ -97,7 +127,12 @@ def read_user_dict(var_name, default_value, prompts=None, prefix=''):\n     :param default_value: Value that will be returned if no input is provided\n     :return: A Python dictionary to use in the context.\n     \"\"\"\n-    pass\n+    prompt_text = f\"{prefix}{var_name}\"\n+    if prompts and var_name in prompts:\n+        prompt_text = prompts[var_name]\n+    \n+    default_json = json.dumps(default_value) if default_value else None\n+    return JsonPrompt.ask(prompt_text, default=default_json)\n\n\n def render_variable(env, raw, cookiecutter_dict):\n@@ -117,12 +152,25 @@ def render_variable(env, raw, cookiecutter_dict):\n         being populated with variables.\n     :return: The rendered value for the default variable.\n     \"\"\"\n-    pass\n+    if not isinstance(raw, str):\n+        return raw\n+\n+    template = env.from_string(raw)\n+    try:\n+        return template.render(**cookiecutter_dict)\n+    except UndefinedError as err:\n+        raise UndefinedVariableInTemplate(str(err), err, cookiecutter_dict)\n\n\n def _prompts_from_options(options: dict) -&gt;dict:\n     \"\"\"Process template options and return friendly prompt information.\"\"\"\n-    pass\n+    prompts = {}\n+    for key, value in options.items():\n+        if isinstance(value, dict):\n+            prompts[key] = value.get('_prompt', key)\n+        else:\n+            prompts[key] = key\n+    return prompts\n\n\n def prompt_choice_for_template(key, options, no_input):\n@@ -130,7 +178,12 @@ def prompt_choice_for_template(key, options, no_input):\n\n     :param no_input: Do not prompt for user input and return the first available option.\n     \"\"\"\n-    pass\n+    if no_input:\n+        return next(iter(options.values()))\n+\n+    prompts = _prompts_from_options(options)\n+    choices = list(options.keys())\n+    return read_user_choice(key, choices, prompts=prompts)\n\n\n def prompt_choice_for_config(cookiecutter_dict, env, key, options, no_input,\n@@ -139,7 +192,15 @@ def prompt_choice_for_config(cookiecutter_dict, env, key, options, no_input,\n\n     :param no_input: Do not prompt for user input and return the first available option.\n     \"\"\"\n-    pass\n+    if no_input:\n+        return next(iter(options.values()))\n+\n+    rendered_options = OrderedDict()\n+    for option_key, option_value in options.items():\n+        rendered_options[option_key] = render_variable(env, option_value, cookiecutter_dict)\n+\n+    choice = read_user_choice(key, list(rendered_options.keys()), prompts=prompts, prefix=prefix)\n+    return rendered_options[choice]\n\n\n def prompt_for_config(context, no_input=False):\n@@ -148,7 +209,25 @@ def prompt_for_config(context, no_input=False):\n     :param dict context: Source for field names and sample values.\n     :param no_input: Do not prompt for user input and use only values from context.\n     \"\"\"\n-    pass\n+    cookiecutter_dict = OrderedDict([])\n+    env = create_env_with_context(context)\n+\n+    for key, raw in context['cookiecutter'].items():\n+        if key.startswith('_'):\n+            cookiecutter_dict[key] = raw\n+            continue\n+\n+        if isinstance(raw, dict):\n+            cookiecutter_dict[key] = prompt_choice_for_config(\n+                cookiecutter_dict, env, key, raw, no_input\n+            )\n+        else:\n+            if no_input:\n+                cookiecutter_dict[key] = render_variable(env, raw, cookiecutter_dict)\n+            else:\n+                cookiecutter_dict[key] = read_user_variable(key, raw)\n+\n+    return cookiecutter_dict\n\n\n def choose_nested_template(context: dict, repo_dir: str, no_input: bool=False\n@@ -160,7 +239,17 @@ def choose_nested_template(context: dict, repo_dir: str, no_input: bool=False\n     :param no_input: Do not prompt for user input and use only values from context.\n     :returns: Path to the selected template.\n     \"\"\"\n-    pass\n+    template_dir = Path(repo_dir) / 'templates'\n+    template_names = [d.name for d in template_dir.iterdir() if d.is_dir()]\n+\n+    if not template_names:\n+        raise ValueError(\"No nested templates found in the repository.\")\n+\n+    if no_input or len(template_names) == 1:\n+        return str(template_dir / template_names[0])\n+\n+    choice = read_user_choice(\"Select a template\", template_names)\n+    return str(template_dir / choice)\n\n\n def prompt_and_delete(path, no_input=False):\n@@ -174,4 +263,25 @@ def prompt_and_delete(path, no_input=False):\n     :param no_input: Suppress prompt to delete repo and just delete it.\n     :return: True if the content was deleted\n     \"\"\"\n-    pass\n+    if no_input:\n+        rmtree(path)\n+        return True\n+\n+    delete = read_user_yes_no(\n+        f\"You've downloaded {path} before. Is it okay to delete and re-download it?\",\n+        default_value=True\n+    )\n+\n+    if delete:\n+        rmtree(path)\n+        return True\n+\n+    reuse = read_user_yes_no(\n+        \"Do you want to re-use the existing version?\",\n+        default_value=True\n+    )\n+\n+    if reuse:\n+        return False\n+\n+    sys.exit()\ndiff --git a/cookiecutter/replay.py b/cookiecutter/replay.py\nindex 340be41..54a1692 100644\n--- a/cookiecutter/replay.py\n+++ b/cookiecutter/replay.py\n@@ -10,14 +10,20 @@ from cookiecutter.utils import make_sure_path_exists\n\n def get_file_name(replay_dir, template_name):\n     \"\"\"Get the name of file.\"\"\"\n-    pass\n+    file_name = f\"{template_name}.json\"\n+    return os.path.join(replay_dir, file_name)\n\n\n def dump(replay_dir: 'os.PathLike[str]', template_name: str, context: dict):\n     \"\"\"Write json data to file.\"\"\"\n-    pass\n+    make_sure_path_exists(replay_dir)\n+    file_path = get_file_name(replay_dir, template_name)\n+    with open(file_path, 'w') as f:\n+        json.dump(context, f, indent=2)\n\n\n def load(replay_dir, template_name):\n     \"\"\"Read json data from file.\"\"\"\n-    pass\n+    file_path = get_file_name(replay_dir, template_name)\n+    with open(file_path, 'r') as f:\n+        return json.load(f)\ndiff --git a/cookiecutter/repository.py b/cookiecutter/repository.py\nindex e350c56..edcad60 100644\n--- a/cookiecutter/repository.py\n+++ b/cookiecutter/repository.py\n@@ -17,12 +17,12 @@ REPO_REGEX = re.compile(\n\n def is_repo_url(value):\n     \"\"\"Return True if value is a repository URL.\"\"\"\n-    pass\n+    return bool(REPO_REGEX.match(value))\n\n\n def is_zip_file(value):\n     \"\"\"Return True if value is a zip file.\"\"\"\n-    pass\n+    return value.lower().endswith('.zip')\n\n\n def expand_abbreviations(template, abbreviations):\n@@ -31,7 +31,9 @@ def expand_abbreviations(template, abbreviations):\n     :param template: The project template name.\n     :param abbreviations: Abbreviation definitions.\n     \"\"\"\n-    pass\n+    if template in abbreviations:\n+        return abbreviations[template]\n+    return template\n\n\n def repository_has_cookiecutter_json(repo_directory):\n@@ -40,7 +42,10 @@ def repository_has_cookiecutter_json(repo_directory):\n     :param repo_directory: The candidate repository directory.\n     :return: True if the `repo_directory` is valid, else False.\n     \"\"\"\n-    pass\n+    repo_dir_exists = os.path.isdir(repo_directory)\n+    cookiecutter_json_path = os.path.join(repo_directory, 'cookiecutter.json')\n+    has_cookiecutter_json = os.path.isfile(cookiecutter_json_path)\n+    return repo_dir_exists and has_cookiecutter_json\n\n\n def determine_repo_dir(template, abbreviations, clone_to_dir, checkout,\n@@ -67,4 +72,35 @@ def determine_repo_dir(template, abbreviations, clone_to_dir, checkout,\n         after the template has been instantiated.\n     :raises: `RepositoryNotFound` if a repository directory could not be found.\n     \"\"\"\n-    pass\n+    template = expand_abbreviations(template, abbreviations)\n+\n+    if is_repo_url(template):\n+        repo_dir = clone(\n+            repo_url=template,\n+            checkout=checkout,\n+            clone_to_dir=clone_to_dir,\n+            no_input=no_input\n+        )\n+        cleanup = True\n+    elif is_zip_file(template):\n+        repo_dir = unzip(\n+            zip_uri=template,\n+            is_url=is_repo_url(template),\n+            clone_to_dir=clone_to_dir,\n+            no_input=no_input,\n+            password=password\n+        )\n+        cleanup = True\n+    else:\n+        repo_dir = template\n+        cleanup = False\n+\n+    if directory:\n+        repo_dir = os.path.join(repo_dir, directory)\n+\n+    if not repository_has_cookiecutter_json(repo_dir):\n+        raise RepositoryNotFound(\n+            'The repository {} does not contain a cookiecutter.json file'.format(repo_dir)\n+        )\n+\n+    return repo_dir, cleanup\ndiff --git a/cookiecutter/utils.py b/cookiecutter/utils.py\nindex 6aa68ba..a93b5a4 100644\n--- a/cookiecutter/utils.py\n+++ b/cookiecutter/utils.py\n@@ -18,7 +18,8 @@ def force_delete(func, path, exc_info):\n     Usage: `shutil.rmtree(path, onerror=force_delete)`\n     From https://docs.python.org/3/library/shutil.html#rmtree-example\n     \"\"\"\n-    pass\n+    os.chmod(path, stat.S_IWRITE)\n+    func(path)\n\n\n def rmtree(path):\n@@ -26,7 +27,7 @@ def rmtree(path):\n\n     :param path: A directory path.\n     \"\"\"\n-    pass\n+    shutil.rmtree(path, onerror=force_delete)\n\n\n def make_sure_path_exists(path: 'os.PathLike[str]') -&gt;None:\n@@ -34,7 +35,7 @@ def make_sure_path_exists(path: 'os.PathLike[str]') -&gt;None:\n\n     :param path: A directory tree path for creation.\n     \"\"\"\n-    pass\n+    os.makedirs(path, exist_ok=True)\n\n\n @contextlib.contextmanager\n@@ -43,7 +44,13 @@ def work_in(dirname=None):\n\n     When exited, returns to the working directory prior to entering.\n     \"\"\"\n-    pass\n+    curdir = os.getcwd()\n+    try:\n+        if dirname is not None:\n+            os.chdir(dirname)\n+        yield\n+    finally:\n+        os.chdir(curdir)\n\n\n def make_executable(script_path):\n@@ -51,19 +58,28 @@ def make_executable(script_path):\n\n     :param script_path: The file to change\n     \"\"\"\n-    pass\n+    mode = os.stat(script_path).st_mode\n+    os.chmod(script_path, mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)\n\n\n def simple_filter(filter_function):\n     \"\"\"Decorate a function to wrap it in a simplified jinja2 extension.\"\"\"\n-    pass\n+    class SimpleExtension(Extension):\n+        def __init__(self, environment):\n+            super().__init__(environment)\n+            environment.filters[filter_function.__name__] = filter_function\n+\n+    return SimpleExtension\n\n\n def create_tmp_repo_dir(repo_dir: 'os.PathLike[str]') -&gt;Path:\n     \"\"\"Create a temporary dir with a copy of the contents of repo_dir.\"\"\"\n-    pass\n+    temp_dir = Path(tempfile.mkdtemp())\n+    shutil.copytree(repo_dir, temp_dir, symlinks=True)\n+    return temp_dir\n\n\n def create_env_with_context(context: Dict):\n     \"\"\"Create a jinja environment using the provided context.\"\"\"\n-    pass\n+    env = StrictEnvironment(context=context)\n+    return env\ndiff --git a/cookiecutter/vcs.py b/cookiecutter/vcs.py\nindex 94d6c05..f0eae9f 100644\n--- a/cookiecutter/vcs.py\n+++ b/cookiecutter/vcs.py\n@@ -20,16 +20,30 @@ def identify_repo(repo_url):\n     :param repo_url: Repo URL of unknown type.\n     :returns: ('git', repo_url), ('hg', repo_url), or None.\n     \"\"\"\n-    pass\n+    repo_url = repo_url.lower()\n+    if repo_url.startswith('git+'):\n+        return 'git', repo_url[4:]\n+    elif repo_url.startswith('hg+'):\n+        return 'hg', repo_url[3:]\n+    elif repo_url.endswith('.git') or 'github.com' in repo_url:\n+        return 'git', repo_url\n+    elif 'bitbucket.org' in repo_url:\n+        return 'hg', repo_url\n+    return None\n\n\n def is_vcs_installed(repo_type):\n     \"\"\"\n     Check if the version control system for a repo type is installed.\n\n-    :param repo_type:\n+    :param repo_type: The type of repository ('git' or 'hg').\n+    :return: True if the VCS is installed, False otherwise.\n     \"\"\"\n-    pass\n+    if repo_type == 'git':\n+        return which('git') is not None\n+    elif repo_type == 'hg':\n+        return which('hg') is not None\n+    return False\n\n\n def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n@@ -44,4 +58,57 @@ def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n         cached resources.\n     :returns: str with path to the new directory of the repository.\n     \"\"\"\n-    pass\n+    repo_type, repo_url = identify_repo(repo_url)\n+    if repo_type is None:\n+        raise UnknownRepoType(f\"Couldn't determine repository type for {repo_url}\")\n+\n+    if not is_vcs_installed(repo_type):\n+        raise VCSNotInstalled(f\"{repo_type} is not installed.\")\n+\n+    clone_to_dir = Path(clone_to_dir).resolve()\n+    make_sure_path_exists(clone_to_dir)\n+\n+    repo_dir = clone_to_dir / Path(repo_url).stem\n+\n+    if repo_dir.exists():\n+        if no_input:\n+            logger.warning(\"'%s' directory already exists, deleting it\", repo_dir)\n+            subprocess.check_call([repo_type, 'init', str(repo_dir)])\n+        else:\n+            prompt_and_delete(repo_dir)\n+\n+    if repo_type == 'git':\n+        clone_cmd = ['git', 'clone', repo_url, str(repo_dir)]\n+    else:  # hg\n+        clone_cmd = ['hg', 'clone', repo_url, str(repo_dir)]\n+\n+    try:\n+        subprocess.check_output(clone_cmd, stderr=subprocess.STDOUT)\n+    except subprocess.CalledProcessError as e:\n+        output = e.output.decode('utf-8')\n+        if 'Repository not found' in output:\n+            raise RepositoryNotFound(f\"The repository {repo_url} could not be found\")\n+        else:\n+            raise RepositoryCloneFailed(f\"Cloning {repo_url} failed: {output}\")\n+\n+    if checkout:\n+        if repo_type == 'git':\n+            checkout_cmd = ['git', 'checkout', checkout]\n+        else:  # hg\n+            checkout_cmd = ['hg', 'update', checkout]\n+\n+        with Path.cwd():\n+            os.chdir(repo_dir)\n+            try:\n+                subprocess.check_output(checkout_cmd, stderr=subprocess.STDOUT)\n+            except subprocess.CalledProcessError as e:\n+                output = e.output.decode('utf-8')\n+                if any(error in output for error in BRANCH_ERRORS):\n+                    raise RepositoryCloneFailed(\n+                        f\"Couldn't checkout {checkout} in {repo_url}. \"\n+                        f\"Error: {output}\"\n+                    )\n+                else:\n+                    raise\n+\n+    return str(repo_dir)\ndiff --git a/cookiecutter/zipfile.py b/cookiecutter/zipfile.py\nindex c4d398a..1448316 100644\n--- a/cookiecutter/zipfile.py\n+++ b/cookiecutter/zipfile.py\n@@ -25,4 +25,46 @@ def unzip(zip_uri: str, is_url: bool, clone_to_dir: 'os.PathLike[str]'='.',\n         cached resources.\n     :param password: The password to use when unpacking the repository.\n     \"\"\"\n-    pass\n+    clone_to_dir = Path(clone_to_dir)\n+    make_sure_path_exists(clone_to_dir)\n+\n+    if is_url:\n+        # Download the file\n+        response = requests.get(zip_uri)\n+        response.raise_for_status()\n+        zip_file = tempfile.NamedTemporaryFile(delete=False, suffix='.zip', dir=clone_to_dir)\n+        zip_file.write(response.content)\n+        zip_file.close()\n+        zip_path = Path(zip_file.name)\n+    else:\n+        zip_path = Path(zip_uri)\n+\n+    # Create a temporary directory to extract the contents\n+    with tempfile.TemporaryDirectory(dir=clone_to_dir) as temp_dir:\n+        try:\n+            with ZipFile(zip_path, 'r') as zip_ref:\n+                if zip_ref.namelist() and zip_ref.testzip() is not None:\n+                    raise InvalidZipRepository(f\"The zip file {zip_uri} is invalid or corrupt.\")\n+\n+                if password is None and zip_ref.namelist()[0].endswith('/'):\n+                    password = read_repo_password('Enter the password for the encrypted repository:')\n+\n+                try:\n+                    zip_ref.extractall(path=temp_dir, pwd=password.encode() if password else None)\n+                except RuntimeError as e:\n+                    if \"Bad password\" in str(e):\n+                        raise InvalidZipRepository(f\"Invalid password for encrypted repository: {zip_uri}\")\n+                    raise\n+\n+            # If everything is successful, return the path to the extracted contents\n+            return Path(temp_dir)\n+\n+        except BadZipFile:\n+            raise InvalidZipRepository(f\"The zip file {zip_uri} is invalid or corrupt.\")\n+\n+        finally:\n+            if is_url:\n+                if no_input:\n+                    os.unlink(zip_path)\n+                else:\n+                    prompt_and_delete(zip_path)\n</code></pre>"},{"location":"analysis_baseline_deprecated/","title":"Analysis baseline deprecated","text":"<p>back to baseline summary</p>"},{"location":"analysis_baseline_deprecated/#submission-name-baseline","title":"Submission Name: baseline","text":""},{"location":"analysis_baseline_deprecated/#repository-deprecated","title":"Repository: deprecated","text":""},{"location":"analysis_baseline_deprecated/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count passed 80 error 10 failed 81 total 171 collected 171"},{"location":"analysis_baseline_deprecated/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_function__warnsnone","title":"test_deprecated.py::test_classic_deprecated_function__warns[None]","text":"<pre>test_deprecated.py::test_classic_deprecated_function__warns[None]</pre><pre>\nrequest = &gt;\n\n    @pytest.fixture(scope=\"module\", params=_PARAMS)\n    def classic_deprecated_function(request):\n        if request.param is None:\n\n            @deprecated.classic.deprecated\n&gt;           def foo1():\n\ntests/test_deprecated.py:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (.foo1 at 0x7fc08848b400&gt;,)\nkwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_function__warnsclassic_deprecated_function1","title":"test_deprecated.py::test_classic_deprecated_function__warns[classic_deprecated_function1]","text":"<pre>test_deprecated.py::test_classic_deprecated_function__warns[classic_deprecated_function1]</pre><pre>\nclassic_deprecated_function = .foo1 at 0x7fc08820d6c0&gt;\n\n    def test_classic_deprecated_function__warns(classic_deprecated_function):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            classic_deprecated_function()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:135: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_function__warnsclassic_deprecated_function2","title":"test_deprecated.py::test_classic_deprecated_function__warns[classic_deprecated_function2]","text":"<pre>test_deprecated.py::test_classic_deprecated_function__warns[classic_deprecated_function2]</pre><pre>\nrequest = &gt;\n\n    @pytest.fixture(scope=\"module\", params=_PARAMS)\n    def classic_deprecated_function(request):\n        if request.param is None:\n\n            @deprecated.classic.deprecated\n            def foo1():\n                pass\n\n            return foo1\n        else:\n            args, kwargs = request.param\n\n&gt;           @deprecated.classic.deprecated(*args, **kwargs)\n\ntests/test_deprecated.py:37: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = ('Good reason',), kwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_function__warnsclassic_deprecated_function3","title":"test_deprecated.py::test_classic_deprecated_function__warns[classic_deprecated_function3]","text":"<pre>test_deprecated.py::test_classic_deprecated_function__warns[classic_deprecated_function3]</pre><pre>\nclassic_deprecated_function = .foo1 at 0x7fc08820dcf0&gt;\n\n    def test_classic_deprecated_function__warns(classic_deprecated_function):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            classic_deprecated_function()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:135: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_function__warnsclassic_deprecated_function4","title":"test_deprecated.py::test_classic_deprecated_function__warns[classic_deprecated_function4]","text":"<pre>test_deprecated.py::test_classic_deprecated_function__warns[classic_deprecated_function4]</pre><pre>\nclassic_deprecated_function = .foo1 at 0x7fc08820dea0&gt;\n\n    def test_classic_deprecated_function__warns(classic_deprecated_function):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            classic_deprecated_function()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:135: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_function__warnsclassic_deprecated_function5","title":"test_deprecated.py::test_classic_deprecated_function__warns[classic_deprecated_function5]","text":"<pre>test_deprecated.py::test_classic_deprecated_function__warns[classic_deprecated_function5]</pre><pre>\nclassic_deprecated_function = .foo1 at 0x7fc08820ca60&gt;\n\n    def test_classic_deprecated_function__warns(classic_deprecated_function):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            classic_deprecated_function()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:135: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_function__warnsclassic_deprecated_function6","title":"test_deprecated.py::test_classic_deprecated_function__warns[classic_deprecated_function6]","text":"<pre>test_deprecated.py::test_classic_deprecated_function__warns[classic_deprecated_function6]</pre><pre>\nclassic_deprecated_function = .foo1 at 0x7fc08820e050&gt;\n\n    def test_classic_deprecated_function__warns(classic_deprecated_function):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            classic_deprecated_function()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:135: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_class__warnsnone","title":"test_deprecated.py::test_classic_deprecated_class__warns[None]","text":"<pre>test_deprecated.py::test_classic_deprecated_class__warns[None]</pre><pre>\nrequest = &gt;\n\n    @pytest.fixture(scope=\"module\", params=_PARAMS)\n    def classic_deprecated_class(request):\n        if request.param is None:\n\n            @deprecated.classic.deprecated\n&gt;           class Foo2(object):\n\ntests/test_deprecated.py:49: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (.Foo2'&gt;,)\nkwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_class__warnsclassic_deprecated_class2","title":"test_deprecated.py::test_classic_deprecated_class__warns[classic_deprecated_class2]","text":"<pre>test_deprecated.py::test_classic_deprecated_class__warns[classic_deprecated_class2]</pre><pre>\nrequest = &gt;\n\n    @pytest.fixture(scope=\"module\", params=_PARAMS)\n    def classic_deprecated_class(request):\n        if request.param is None:\n\n            @deprecated.classic.deprecated\n            class Foo2(object):\n                pass\n\n            return Foo2\n        else:\n            args, kwargs = request.param\n\n&gt;           @deprecated.classic.deprecated(*args, **kwargs)\n\ntests/test_deprecated.py:56: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = ('Good reason',), kwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_method__warnsnone","title":"test_deprecated.py::test_classic_deprecated_method__warns[None]","text":"<pre>test_deprecated.py::test_classic_deprecated_method__warns[None]</pre><pre>\nrequest = &gt;\n\n    @pytest.fixture(scope=\"module\", params=_PARAMS)\n    def classic_deprecated_method(request):\n        if request.param is None:\n\n&gt;           class Foo3(object):\n\ntests/test_deprecated.py:67: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_deprecated.py:69: in Foo3\n    def foo3(self):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (.Foo3.foo3 at 0x7fc08820d750&gt;,)\nkwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_method__warnsclassic_deprecated_method1","title":"test_deprecated.py::test_classic_deprecated_method__warns[classic_deprecated_method1]","text":"<pre>test_deprecated.py::test_classic_deprecated_method__warns[classic_deprecated_method1]</pre><pre>\nclassic_deprecated_method = .Foo3'&gt;\n\n    def test_classic_deprecated_method__warns(classic_deprecated_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            obj = classic_deprecated_method()\n            obj.foo3()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:160: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_method__warnsclassic_deprecated_method2","title":"test_deprecated.py::test_classic_deprecated_method__warns[classic_deprecated_method2]","text":"<pre>test_deprecated.py::test_classic_deprecated_method__warns[classic_deprecated_method2]</pre><pre>\nrequest = &gt;\n\n    @pytest.fixture(scope=\"module\", params=_PARAMS)\n    def classic_deprecated_method(request):\n        if request.param is None:\n\n            class Foo3(object):\n                @deprecated.classic.deprecated\n                def foo3(self):\n                    pass\n\n            return Foo3\n        else:\n            args, kwargs = request.param\n\n&gt;           class Foo3(object):\n\ntests/test_deprecated.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_deprecated.py:77: in Foo3\n    @deprecated.classic.deprecated(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = ('Good reason',), kwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_method__warnsclassic_deprecated_method3","title":"test_deprecated.py::test_classic_deprecated_method__warns[classic_deprecated_method3]","text":"<pre>test_deprecated.py::test_classic_deprecated_method__warns[classic_deprecated_method3]</pre><pre>\nclassic_deprecated_method = .Foo3'&gt;\n\n    def test_classic_deprecated_method__warns(classic_deprecated_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            obj = classic_deprecated_method()\n            obj.foo3()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:160: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_method__warnsclassic_deprecated_method4","title":"test_deprecated.py::test_classic_deprecated_method__warns[classic_deprecated_method4]","text":"<pre>test_deprecated.py::test_classic_deprecated_method__warns[classic_deprecated_method4]</pre><pre>\nclassic_deprecated_method = .Foo3'&gt;\n\n    def test_classic_deprecated_method__warns(classic_deprecated_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            obj = classic_deprecated_method()\n            obj.foo3()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:160: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_method__warnsclassic_deprecated_method5","title":"test_deprecated.py::test_classic_deprecated_method__warns[classic_deprecated_method5]","text":"<pre>test_deprecated.py::test_classic_deprecated_method__warns[classic_deprecated_method5]</pre><pre>\nclassic_deprecated_method = .Foo3'&gt;\n\n    def test_classic_deprecated_method__warns(classic_deprecated_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            obj = classic_deprecated_method()\n            obj.foo3()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:160: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_method__warnsclassic_deprecated_method6","title":"test_deprecated.py::test_classic_deprecated_method__warns[classic_deprecated_method6]","text":"<pre>test_deprecated.py::test_classic_deprecated_method__warns[classic_deprecated_method6]</pre><pre>\nclassic_deprecated_method = .Foo3'&gt;\n\n    def test_classic_deprecated_method__warns(classic_deprecated_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            obj = classic_deprecated_method()\n            obj.foo3()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:160: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_static_method__warnsnone","title":"test_deprecated.py::test_classic_deprecated_static_method__warns[None]","text":"<pre>test_deprecated.py::test_classic_deprecated_static_method__warns[None]</pre><pre>\nrequest = &gt;\n\n    @pytest.fixture(scope=\"module\", params=_PARAMS)\n    def classic_deprecated_static_method(request):\n        if request.param is None:\n\n&gt;           class Foo4(object):\n\ntests/test_deprecated.py:88: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_deprecated.py:91: in Foo4\n    def foo4():\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (.Foo4.foo4 at 0x7fc08820dd80&gt;,)\nkwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_static_method__warnsclassic_deprecated_static_method1","title":"test_deprecated.py::test_classic_deprecated_static_method__warns[classic_deprecated_static_method1]","text":"<pre>test_deprecated.py::test_classic_deprecated_static_method__warns[classic_deprecated_static_method1]</pre><pre>\nclassic_deprecated_static_method = .Foo4.foo4 at 0x7fc08820f640&gt;\n\n    def test_classic_deprecated_static_method__warns(classic_deprecated_static_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            classic_deprecated_static_method()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:172: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_static_method__warnsclassic_deprecated_static_method2","title":"test_deprecated.py::test_classic_deprecated_static_method__warns[classic_deprecated_static_method2]","text":"<pre>test_deprecated.py::test_classic_deprecated_static_method__warns[classic_deprecated_static_method2]</pre><pre>\nrequest = &gt;\n\n    @pytest.fixture(scope=\"module\", params=_PARAMS)\n    def classic_deprecated_static_method(request):\n        if request.param is None:\n\n            class Foo4(object):\n                @staticmethod\n                @deprecated.classic.deprecated\n                def foo4():\n                    pass\n\n            return Foo4.foo4\n        else:\n            args, kwargs = request.param\n\n&gt;           class Foo4(object):\n\ntests/test_deprecated.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_deprecated.py:100: in Foo4\n    @deprecated.classic.deprecated(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = ('Good reason',), kwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_static_method__warnsclassic_deprecated_static_method3","title":"test_deprecated.py::test_classic_deprecated_static_method__warns[classic_deprecated_static_method3]","text":"<pre>test_deprecated.py::test_classic_deprecated_static_method__warns[classic_deprecated_static_method3]</pre><pre>\nclassic_deprecated_static_method = .Foo4.foo4 at 0x7fc08820ff40&gt;\n\n    def test_classic_deprecated_static_method__warns(classic_deprecated_static_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            classic_deprecated_static_method()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:172: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_static_method__warnsclassic_deprecated_static_method4","title":"test_deprecated.py::test_classic_deprecated_static_method__warns[classic_deprecated_static_method4]","text":"<pre>test_deprecated.py::test_classic_deprecated_static_method__warns[classic_deprecated_static_method4]</pre><pre>\nclassic_deprecated_static_method = .Foo4.foo4 at 0x7fc08820f910&gt;\n\n    def test_classic_deprecated_static_method__warns(classic_deprecated_static_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            classic_deprecated_static_method()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:172: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_static_method__warnsclassic_deprecated_static_method5","title":"test_deprecated.py::test_classic_deprecated_static_method__warns[classic_deprecated_static_method5]","text":"<pre>test_deprecated.py::test_classic_deprecated_static_method__warns[classic_deprecated_static_method5]</pre><pre>\nclassic_deprecated_static_method = .Foo4.foo4 at 0x7fc08820ee60&gt;\n\n    def test_classic_deprecated_static_method__warns(classic_deprecated_static_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            classic_deprecated_static_method()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:172: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_static_method__warnsclassic_deprecated_static_method6","title":"test_deprecated.py::test_classic_deprecated_static_method__warns[classic_deprecated_static_method6]","text":"<pre>test_deprecated.py::test_classic_deprecated_static_method__warns[classic_deprecated_static_method6]</pre><pre>\nclassic_deprecated_static_method = .Foo4.foo4 at 0x7fc08820f0a0&gt;\n\n    def test_classic_deprecated_static_method__warns(classic_deprecated_static_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            classic_deprecated_static_method()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:172: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_class_method__warnsnone","title":"test_deprecated.py::test_classic_deprecated_class_method__warns[None]","text":"<pre>test_deprecated.py::test_classic_deprecated_class_method__warns[None]</pre><pre>\nrequest = &gt;\n\n    @pytest.fixture(scope=\"module\", params=_PARAMS)\n    def classic_deprecated_class_method(request):\n        if request.param is None:\n\n&gt;           class Foo5(object):\n\ntests/test_deprecated.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_deprecated.py:114: in Foo5\n    def foo5(cls):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (.Foo5.foo5 at 0x7fc08820f010&gt;,)\nkwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_class_method__warnsclassic_deprecated_class_method1","title":"test_deprecated.py::test_classic_deprecated_class_method__warns[classic_deprecated_class_method1]","text":"<pre>test_deprecated.py::test_classic_deprecated_class_method__warns[classic_deprecated_class_method1]</pre><pre>\nclassic_deprecated_class_method = .Foo5'&gt;\n\n    def test_classic_deprecated_class_method__warns(classic_deprecated_class_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            cls = classic_deprecated_class_method()\n            cls.foo5()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:185: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_class_method__warnsclassic_deprecated_class_method2","title":"test_deprecated.py::test_classic_deprecated_class_method__warns[classic_deprecated_class_method2]","text":"<pre>test_deprecated.py::test_classic_deprecated_class_method__warns[classic_deprecated_class_method2]</pre><pre>\nrequest = &gt;\n\n    @pytest.fixture(scope=\"module\", params=_PARAMS)\n    def classic_deprecated_class_method(request):\n        if request.param is None:\n\n            class Foo5(object):\n                @classmethod\n                @deprecated.classic.deprecated\n                def foo5(cls):\n                    pass\n\n            return Foo5\n        else:\n            args, kwargs = request.param\n\n&gt;           class Foo5(object):\n\ntests/test_deprecated.py:121: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_deprecated.py:123: in Foo5\n    @deprecated.classic.deprecated(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = ('Good reason',), kwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_class_method__warnsclassic_deprecated_class_method3","title":"test_deprecated.py::test_classic_deprecated_class_method__warns[classic_deprecated_class_method3]","text":"<pre>test_deprecated.py::test_classic_deprecated_class_method__warns[classic_deprecated_class_method3]</pre><pre>\nclassic_deprecated_class_method = .Foo5'&gt;\n\n    def test_classic_deprecated_class_method__warns(classic_deprecated_class_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            cls = classic_deprecated_class_method()\n            cls.foo5()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:185: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_class_method__warnsclassic_deprecated_class_method4","title":"test_deprecated.py::test_classic_deprecated_class_method__warns[classic_deprecated_class_method4]","text":"<pre>test_deprecated.py::test_classic_deprecated_class_method__warns[classic_deprecated_class_method4]</pre><pre>\nclassic_deprecated_class_method = .Foo5'&gt;\n\n    def test_classic_deprecated_class_method__warns(classic_deprecated_class_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            cls = classic_deprecated_class_method()\n            cls.foo5()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:185: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_class_method__warnsclassic_deprecated_class_method5","title":"test_deprecated.py::test_classic_deprecated_class_method__warns[classic_deprecated_class_method5]","text":"<pre>test_deprecated.py::test_classic_deprecated_class_method__warns[classic_deprecated_class_method5]</pre><pre>\nclassic_deprecated_class_method = .Foo5'&gt;\n\n    def test_classic_deprecated_class_method__warns(classic_deprecated_class_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            cls = classic_deprecated_class_method()\n            cls.foo5()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:185: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_classic_deprecated_class_method__warnsclassic_deprecated_class_method6","title":"test_deprecated.py::test_classic_deprecated_class_method__warns[classic_deprecated_class_method6]","text":"<pre>test_deprecated.py::test_classic_deprecated_class_method__warns[classic_deprecated_class_method6]</pre><pre>\nclassic_deprecated_class_method = .Foo5'&gt;\n\n    def test_classic_deprecated_class_method__warns(classic_deprecated_class_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            cls = classic_deprecated_class_method()\n            cls.foo5()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:185: AssertionError"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_should_raise_type_error","title":"test_deprecated.py::test_should_raise_type_error","text":"<pre>test_deprecated.py::test_should_raise_type_error</pre><pre>\ndef test_should_raise_type_error():\n        try:\n&gt;           deprecated.classic.deprecated(5)\n\ntests/test_deprecated.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (5,), kwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_warning_msg_has_reason","title":"test_deprecated.py::test_warning_msg_has_reason","text":"<pre>test_deprecated.py::test_warning_msg_has_reason</pre><pre>\ndef test_warning_msg_has_reason():\n        reason = \"Good reason\"\n\n        @deprecated.classic.deprecated(reason=reason)\n        def foo():\n            pass\n\n        with warnings.catch_warnings(record=True) as warns:\n            foo()\n&gt;       warn = warns[0]\nE       IndexError: list index out of range\n\ntests/test_deprecated.py:212: IndexError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_warning_msg_has_version","title":"test_deprecated.py::test_warning_msg_has_version","text":"<pre>test_deprecated.py::test_warning_msg_has_version</pre><pre>\ndef test_warning_msg_has_version():\n        version = \"1.2.3\"\n\n        @deprecated.classic.deprecated(version=version)\n        def foo():\n            pass\n\n        with warnings.catch_warnings(record=True) as warns:\n            foo()\n&gt;       warn = warns[0]\nE       IndexError: list index out of range\n\ntests/test_deprecated.py:225: IndexError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_specific_warning_cls_is_used","title":"test_deprecated.py::test_specific_warning_cls_is_used","text":"<pre>test_deprecated.py::test_specific_warning_cls_is_used</pre><pre>\ndef test_specific_warning_cls_is_used():\n        @deprecated.classic.deprecated(category=MyDeprecationWarning)\n        def foo():\n            pass\n\n        with warnings.catch_warnings(record=True) as warns:\n            foo()\n&gt;       warn = warns[0]\nE       IndexError: list index out of range\n\ntests/test_deprecated.py:246: IndexError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_deprecatedpytest_respect_global_filter","title":"test_deprecated.py::test_respect_global_filter","text":"<pre>test_deprecated.py::test_respect_global_filter</pre><pre>\ndef test_respect_global_filter():\n        @deprecated.classic.deprecated(version='1.2.1', reason=\"deprecated function\")\n        def fun():\n            print(\"fun\")\n\n        warnings.simplefilter(\"once\", category=DeprecationWarning)\n\n        with warnings.catch_warnings(record=True) as warns:\n            fun()\n            fun()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_deprecated.py:260: AssertionError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_deprecated_classpytest_class_deprecation_using_deprecated_decorator","title":"test_deprecated_class.py::test_class_deprecation_using_deprecated_decorator","text":"<pre>test_deprecated_class.py::test_class_deprecation_using_deprecated_decorator</pre><pre>\ndef test_class_deprecation_using_deprecated_decorator():\n        @deprecated.classic.deprecated\n&gt;       class MyBaseClass(object):\n\ntests/test_deprecated_class.py:93: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (.MyBaseClass'&gt;,)\nkwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_deprecated_classpytest_class_respect_global_filter","title":"test_deprecated_class.py::test_class_respect_global_filter","text":"<pre>test_deprecated_class.py::test_class_respect_global_filter</pre><pre>\ndef test_class_respect_global_filter():\n        @deprecated.classic.deprecated\n&gt;       class MyBaseClass(object):\n\ntests/test_deprecated_class.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (.MyBaseClass'&gt;,)\nkwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_deprecated_classpytest_subclass_deprecation_using_deprecated_decorator","title":"test_deprecated_class.py::test_subclass_deprecation_using_deprecated_decorator","text":"<pre>test_deprecated_class.py::test_subclass_deprecation_using_deprecated_decorator</pre><pre>\ndef test_subclass_deprecation_using_deprecated_decorator():\n        @deprecated.classic.deprecated\n&gt;       class MyBaseClass(object):\n\ntests/test_deprecated_class.py:124: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (.MyBaseClass'&gt;,)\nkwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_deprecated_classpytest_simple_class_deprecation_with_args","title":"test_deprecated_class.py::test_simple_class_deprecation_with_args","text":"<pre>test_deprecated_class.py::test_simple_class_deprecation_with_args</pre><pre>\ndef test_simple_class_deprecation_with_args():\n&gt;       @deprecated.classic.deprecated('kwargs class')\n\ntests/test_deprecated_class.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = ('kwargs class',), kwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_deprecated_metaclasspytest_with_init","title":"test_deprecated_metaclass.py::test_with_init","text":"<pre>test_deprecated_metaclass.py::test_with_init</pre><pre>\ndef test_with_init():\n        @deprecated.classic.deprecated\n&gt;       class MyClass(object):\n\ntests/test_deprecated_metaclass.py:26: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (.MyClass'&gt;,)\nkwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_deprecated_metaclasspytest_with_new","title":"test_deprecated_metaclass.py::test_with_new","text":"<pre>test_deprecated_metaclass.py::test_with_new</pre><pre>\ndef test_with_new():\n        @deprecated.classic.deprecated\n&gt;       class MyClass(object):\n\ntests/test_deprecated_metaclass.py:43: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (.MyClass'&gt;,)\nkwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_deprecated_metaclasspytest_with_metaclass","title":"test_deprecated_metaclass.py::test_with_metaclass","text":"<pre>test_deprecated_metaclass.py::test_with_metaclass</pre><pre>\ndef test_with_metaclass():\n        class Meta(type):\n            def __call__(cls, *args, **kwargs):\n                obj = super(Meta, cls).__call__(*args, **kwargs)\n                obj.c = 3.14\n                return obj\n\n        @deprecated.classic.deprecated\n&gt;       class MyClass(with_metaclass(Meta)):\n\ntests/test_deprecated_metaclass.py:72: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (.MyClass'&gt;,)\nkwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_deprecated_metaclasspytest_with_singleton_metaclass","title":"test_deprecated_metaclass.py::test_with_singleton_metaclass","text":"<pre>test_deprecated_metaclass.py::test_with_singleton_metaclass</pre><pre>\ndef test_with_singleton_metaclass():\n        class Singleton(type):\n            _instances = {}\n\n            def __call__(cls, *args, **kwargs):\n                if cls not in cls._instances:\n                    cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)\n                return cls._instances[cls]\n\n        @deprecated.classic.deprecated\n&gt;       class MyClass(with_metaclass(Singleton)):\n\ntests/test_deprecated_metaclass.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (.MyClass'&gt;,)\nkwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_has_sphinx_docstringshort_docstring-deprecated-reasonversion","title":"test_sphinx.py::test_has_sphinx_docstring[short_docstring-deprecated-reason&amp;version]","text":"<pre>test_sphinx.py::test_has_sphinx_docstring[short_docstring-deprecated-reason&amp;version]</pre><pre>\ndocstring = 'This function adds *x* and *y*.', directive = 'deprecated'\nreason = 'A good reason', version = '1.2.0'\nexpected = '.. deprecated:: 1.2.0\\n   A good reason\\n'\n\n    @pytest.mark.parametrize(\n        \"reason, version, expected\",\n        [\n            (\n                'A good reason',\n                '1.2.0',\n                textwrap.dedent(\n                    \"\"\"\\\n                    .. {directive}:: {version}\n                       {reason}\n                    \"\"\"\n                ),\n            ),\n            (\n                None,\n                '1.2.0',\n                textwrap.dedent(\n                    \"\"\"\\\n                    .. {directive}:: {version}\n                    \"\"\"\n                ),\n            ),\n        ],\n        ids=[\"reason&amp;version\", \"version\"],\n    )\n    def test_has_sphinx_docstring(docstring, directive, reason, version, expected):\n        # The function:\n        def foo(x, y):\n            return x + y\n\n        # with docstring:\n        foo.__doc__ = docstring\n\n        # is decorated with:\n        decorator_factory = getattr(deprecated.sphinx, directive)\n        decorator = decorator_factory(reason=reason, version=version)\n        foo = decorator(foo)\n\n        # The function must contains this Sphinx docstring:\n        expected = expected.format(directive=directive, version=version, reason=reason)\n\n        current = textwrap.dedent(foo.__doc__)\n        assert current.endswith(expected)\n\n        current = current.replace(expected, '')\n        if docstring:\n            # An empty line must separate the original docstring and the directive.\n            assert re.search(\"\\n[ ]*\\n$\", current, flags=re.DOTALL)\n        else:\n            # Avoid \"Explicit markup ends without a blank line\" when the decorated function has no docstring\n            assert current == \"\\n\"\n\n        with warnings.catch_warnings(record=True) as warns:\n            foo(1, 2)\n\n        if directive in {'versionadded', 'versionchanged'}:\n            # don't emit DeprecationWarning\n            assert len(warns) == 0\n        else:\n            # emit DeprecationWarning\n&gt;           assert len(warns) == 1\nE           assert 0 == 1\nE            +  where 0 = len([])\n\ntests/test_sphinx.py:105: AssertionError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_has_sphinx_docstringshort_docstring-deprecated-version","title":"test_sphinx.py::test_has_sphinx_docstring[short_docstring-deprecated-version]","text":"<pre>test_sphinx.py::test_has_sphinx_docstring[short_docstring-deprecated-version]</pre><pre>\ndocstring = 'This function adds *x* and *y*.', directive = 'deprecated'\nreason = None, version = '1.2.0', expected = '.. deprecated:: 1.2.0\\n'\n\n    @pytest.mark.parametrize(\n        \"reason, version, expected\",\n        [\n            (\n                'A good reason',\n                '1.2.0',\n                textwrap.dedent(\n                    \"\"\"\\\n                    .. {directive}:: {version}\n                       {reason}\n                    \"\"\"\n                ),\n            ),\n            (\n                None,\n                '1.2.0',\n                textwrap.dedent(\n                    \"\"\"\\\n                    .. {directive}:: {version}\n                    \"\"\"\n                ),\n            ),\n        ],\n        ids=[\"reason&amp;version\", \"version\"],\n    )\n    def test_has_sphinx_docstring(docstring, directive, reason, version, expected):\n        # The function:\n        def foo(x, y):\n            return x + y\n\n        # with docstring:\n        foo.__doc__ = docstring\n\n        # is decorated with:\n        decorator_factory = getattr(deprecated.sphinx, directive)\n        decorator = decorator_factory(reason=reason, version=version)\n        foo = decorator(foo)\n\n        # The function must contains this Sphinx docstring:\n        expected = expected.format(directive=directive, version=version, reason=reason)\n\n        current = textwrap.dedent(foo.__doc__)\n        assert current.endswith(expected)\n\n        current = current.replace(expected, '')\n        if docstring:\n            # An empty line must separate the original docstring and the directive.\n            assert re.search(\"\\n[ ]*\\n$\", current, flags=re.DOTALL)\n        else:\n            # Avoid \"Explicit markup ends without a blank line\" when the decorated function has no docstring\n            assert current == \"\\n\"\n\n        with warnings.catch_warnings(record=True) as warns:\n            foo(1, 2)\n\n        if directive in {'versionadded', 'versionchanged'}:\n            # don't emit DeprecationWarning\n            assert len(warns) == 0\n        else:\n            # emit DeprecationWarning\n&gt;           assert len(warns) == 1\nE           assert 0 == 1\nE            +  where 0 = len([])\n\ntests/test_sphinx.py:105: AssertionError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_has_sphinx_docstringno_docstring-deprecated-reasonversion","title":"test_sphinx.py::test_has_sphinx_docstring[no_docstring-deprecated-reason&amp;version]","text":"<pre>test_sphinx.py::test_has_sphinx_docstring[no_docstring-deprecated-reason&amp;version]</pre><pre>\ndocstring = None, directive = 'deprecated', reason = 'A good reason'\nversion = '1.2.0', expected = '.. deprecated:: 1.2.0\\n   A good reason\\n'\n\n    @pytest.mark.parametrize(\n        \"reason, version, expected\",\n        [\n            (\n                'A good reason',\n                '1.2.0',\n                textwrap.dedent(\n                    \"\"\"\\\n                    .. {directive}:: {version}\n                       {reason}\n                    \"\"\"\n                ),\n            ),\n            (\n                None,\n                '1.2.0',\n                textwrap.dedent(\n                    \"\"\"\\\n                    .. {directive}:: {version}\n                    \"\"\"\n                ),\n            ),\n        ],\n        ids=[\"reason&amp;version\", \"version\"],\n    )\n    def test_has_sphinx_docstring(docstring, directive, reason, version, expected):\n        # The function:\n        def foo(x, y):\n            return x + y\n\n        # with docstring:\n        foo.__doc__ = docstring\n\n        # is decorated with:\n        decorator_factory = getattr(deprecated.sphinx, directive)\n        decorator = decorator_factory(reason=reason, version=version)\n        foo = decorator(foo)\n\n        # The function must contains this Sphinx docstring:\n        expected = expected.format(directive=directive, version=version, reason=reason)\n\n        current = textwrap.dedent(foo.__doc__)\n        assert current.endswith(expected)\n\n        current = current.replace(expected, '')\n        if docstring:\n            # An empty line must separate the original docstring and the directive.\n            assert re.search(\"\\n[ ]*\\n$\", current, flags=re.DOTALL)\n        else:\n            # Avoid \"Explicit markup ends without a blank line\" when the decorated function has no docstring\n            assert current == \"\\n\"\n\n        with warnings.catch_warnings(record=True) as warns:\n            foo(1, 2)\n\n        if directive in {'versionadded', 'versionchanged'}:\n            # don't emit DeprecationWarning\n            assert len(warns) == 0\n        else:\n            # emit DeprecationWarning\n&gt;           assert len(warns) == 1\nE           assert 0 == 1\nE            +  where 0 = len([])\n\ntests/test_sphinx.py:105: AssertionError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_has_sphinx_docstringno_docstring-deprecated-version","title":"test_sphinx.py::test_has_sphinx_docstring[no_docstring-deprecated-version]","text":"<pre>test_sphinx.py::test_has_sphinx_docstring[no_docstring-deprecated-version]</pre><pre>\ndocstring = None, directive = 'deprecated', reason = None, version = '1.2.0'\nexpected = '.. deprecated:: 1.2.0\\n'\n\n    @pytest.mark.parametrize(\n        \"reason, version, expected\",\n        [\n            (\n                'A good reason',\n                '1.2.0',\n                textwrap.dedent(\n                    \"\"\"\\\n                    .. {directive}:: {version}\n                       {reason}\n                    \"\"\"\n                ),\n            ),\n            (\n                None,\n                '1.2.0',\n                textwrap.dedent(\n                    \"\"\"\\\n                    .. {directive}:: {version}\n                    \"\"\"\n                ),\n            ),\n        ],\n        ids=[\"reason&amp;version\", \"version\"],\n    )\n    def test_has_sphinx_docstring(docstring, directive, reason, version, expected):\n        # The function:\n        def foo(x, y):\n            return x + y\n\n        # with docstring:\n        foo.__doc__ = docstring\n\n        # is decorated with:\n        decorator_factory = getattr(deprecated.sphinx, directive)\n        decorator = decorator_factory(reason=reason, version=version)\n        foo = decorator(foo)\n\n        # The function must contains this Sphinx docstring:\n        expected = expected.format(directive=directive, version=version, reason=reason)\n\n        current = textwrap.dedent(foo.__doc__)\n        assert current.endswith(expected)\n\n        current = current.replace(expected, '')\n        if docstring:\n            # An empty line must separate the original docstring and the directive.\n            assert re.search(\"\\n[ ]*\\n$\", current, flags=re.DOTALL)\n        else:\n            # Avoid \"Explicit markup ends without a blank line\" when the decorated function has no docstring\n            assert current == \"\\n\"\n\n        with warnings.catch_warnings(record=True) as warns:\n            foo(1, 2)\n\n        if directive in {'versionadded', 'versionchanged'}:\n            # don't emit DeprecationWarning\n            assert len(warns) == 0\n        else:\n            # emit DeprecationWarning\n&gt;           assert len(warns) == 1\nE           assert 0 == 1\nE            +  where 0 = len([])\n\ntests/test_sphinx.py:105: AssertionError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_has_sphinx_docstringd213_long_docstring-deprecated-reasonversion","title":"test_sphinx.py::test_has_sphinx_docstring[D213_long_docstring-deprecated-reason&amp;version]","text":"<pre>test_sphinx.py::test_has_sphinx_docstring[D213_long_docstring-deprecated-reason&amp;version]</pre><pre>\ndocstring = '\\n        This function adds *x* and *y*.\\n\\n        :param x: number *x*\\n        :param y: number *y*\\n        :return: sum = *x* + *y*\\n        '\ndirective = 'deprecated', reason = 'A good reason', version = '1.2.0'\nexpected = '.. deprecated:: 1.2.0\\n   A good reason\\n'\n\n    @pytest.mark.parametrize(\n        \"reason, version, expected\",\n        [\n            (\n                'A good reason',\n                '1.2.0',\n                textwrap.dedent(\n                    \"\"\"\\\n                    .. {directive}:: {version}\n                       {reason}\n                    \"\"\"\n                ),\n            ),\n            (\n                None,\n                '1.2.0',\n                textwrap.dedent(\n                    \"\"\"\\\n                    .. {directive}:: {version}\n                    \"\"\"\n                ),\n            ),\n        ],\n        ids=[\"reason&amp;version\", \"version\"],\n    )\n    def test_has_sphinx_docstring(docstring, directive, reason, version, expected):\n        # The function:\n        def foo(x, y):\n            return x + y\n\n        # with docstring:\n        foo.__doc__ = docstring\n\n        # is decorated with:\n        decorator_factory = getattr(deprecated.sphinx, directive)\n        decorator = decorator_factory(reason=reason, version=version)\n        foo = decorator(foo)\n\n        # The function must contains this Sphinx docstring:\n        expected = expected.format(directive=directive, version=version, reason=reason)\n\n        current = textwrap.dedent(foo.__doc__)\n        assert current.endswith(expected)\n\n        current = current.replace(expected, '')\n        if docstring:\n            # An empty line must separate the original docstring and the directive.\n            assert re.search(\"\\n[ ]*\\n$\", current, flags=re.DOTALL)\n        else:\n            # Avoid \"Explicit markup ends without a blank line\" when the decorated function has no docstring\n            assert current == \"\\n\"\n\n        with warnings.catch_warnings(record=True) as warns:\n            foo(1, 2)\n\n        if directive in {'versionadded', 'versionchanged'}:\n            # don't emit DeprecationWarning\n            assert len(warns) == 0\n        else:\n            # emit DeprecationWarning\n&gt;           assert len(warns) == 1\nE           assert 0 == 1\nE            +  where 0 = len([])\n\ntests/test_sphinx.py:105: AssertionError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_has_sphinx_docstringd213_long_docstring-deprecated-version","title":"test_sphinx.py::test_has_sphinx_docstring[D213_long_docstring-deprecated-version]","text":"<pre>test_sphinx.py::test_has_sphinx_docstring[D213_long_docstring-deprecated-version]</pre><pre>\ndocstring = '\\n        This function adds *x* and *y*.\\n\\n        :param x: number *x*\\n        :param y: number *y*\\n        :return: sum = *x* + *y*\\n        '\ndirective = 'deprecated', reason = None, version = '1.2.0'\nexpected = '.. deprecated:: 1.2.0\\n'\n\n    @pytest.mark.parametrize(\n        \"reason, version, expected\",\n        [\n            (\n                'A good reason',\n                '1.2.0',\n                textwrap.dedent(\n                    \"\"\"\\\n                    .. {directive}:: {version}\n                       {reason}\n                    \"\"\"\n                ),\n            ),\n            (\n                None,\n                '1.2.0',\n                textwrap.dedent(\n                    \"\"\"\\\n                    .. {directive}:: {version}\n                    \"\"\"\n                ),\n            ),\n        ],\n        ids=[\"reason&amp;version\", \"version\"],\n    )\n    def test_has_sphinx_docstring(docstring, directive, reason, version, expected):\n        # The function:\n        def foo(x, y):\n            return x + y\n\n        # with docstring:\n        foo.__doc__ = docstring\n\n        # is decorated with:\n        decorator_factory = getattr(deprecated.sphinx, directive)\n        decorator = decorator_factory(reason=reason, version=version)\n        foo = decorator(foo)\n\n        # The function must contains this Sphinx docstring:\n        expected = expected.format(directive=directive, version=version, reason=reason)\n\n        current = textwrap.dedent(foo.__doc__)\n        assert current.endswith(expected)\n\n        current = current.replace(expected, '')\n        if docstring:\n            # An empty line must separate the original docstring and the directive.\n            assert re.search(\"\\n[ ]*\\n$\", current, flags=re.DOTALL)\n        else:\n            # Avoid \"Explicit markup ends without a blank line\" when the decorated function has no docstring\n            assert current == \"\\n\"\n\n        with warnings.catch_warnings(record=True) as warns:\n            foo(1, 2)\n\n        if directive in {'versionadded', 'versionchanged'}:\n            # don't emit DeprecationWarning\n            assert len(warns) == 0\n        else:\n            # emit DeprecationWarning\n&gt;           assert len(warns) == 1\nE           assert 0 == 1\nE            +  where 0 = len([])\n\ntests/test_sphinx.py:105: AssertionError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_has_sphinx_docstringd212_long_docstring-deprecated-reasonversion","title":"test_sphinx.py::test_has_sphinx_docstring[D212_long_docstring-deprecated-reason&amp;version]","text":"<pre>test_sphinx.py::test_has_sphinx_docstring[D212_long_docstring-deprecated-reason&amp;version]</pre><pre>\ndocstring = 'This function adds *x* and *y*.\\n\\n        :param x: number *x*\\n        :param y: number *y*\\n        :return: sum = *x* + *y*\\n        '\ndirective = 'deprecated', reason = 'A good reason', version = '1.2.0'\nexpected = '.. deprecated:: 1.2.0\\n   A good reason\\n'\n\n    @pytest.mark.parametrize(\n        \"reason, version, expected\",\n        [\n            (\n                'A good reason',\n                '1.2.0',\n                textwrap.dedent(\n                    \"\"\"\\\n                    .. {directive}:: {version}\n                       {reason}\n                    \"\"\"\n                ),\n            ),\n            (\n                None,\n                '1.2.0',\n                textwrap.dedent(\n                    \"\"\"\\\n                    .. {directive}:: {version}\n                    \"\"\"\n                ),\n            ),\n        ],\n        ids=[\"reason&amp;version\", \"version\"],\n    )\n    def test_has_sphinx_docstring(docstring, directive, reason, version, expected):\n        # The function:\n        def foo(x, y):\n            return x + y\n\n        # with docstring:\n        foo.__doc__ = docstring\n\n        # is decorated with:\n        decorator_factory = getattr(deprecated.sphinx, directive)\n        decorator = decorator_factory(reason=reason, version=version)\n        foo = decorator(foo)\n\n        # The function must contains this Sphinx docstring:\n        expected = expected.format(directive=directive, version=version, reason=reason)\n\n        current = textwrap.dedent(foo.__doc__)\n        assert current.endswith(expected)\n\n        current = current.replace(expected, '')\n        if docstring:\n            # An empty line must separate the original docstring and the directive.\n            assert re.search(\"\\n[ ]*\\n$\", current, flags=re.DOTALL)\n        else:\n            # Avoid \"Explicit markup ends without a blank line\" when the decorated function has no docstring\n            assert current == \"\\n\"\n\n        with warnings.catch_warnings(record=True) as warns:\n            foo(1, 2)\n\n        if directive in {'versionadded', 'versionchanged'}:\n            # don't emit DeprecationWarning\n            assert len(warns) == 0\n        else:\n            # emit DeprecationWarning\n&gt;           assert len(warns) == 1\nE           assert 0 == 1\nE            +  where 0 = len([])\n\ntests/test_sphinx.py:105: AssertionError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_has_sphinx_docstringd212_long_docstring-deprecated-version","title":"test_sphinx.py::test_has_sphinx_docstring[D212_long_docstring-deprecated-version]","text":"<pre>test_sphinx.py::test_has_sphinx_docstring[D212_long_docstring-deprecated-version]</pre><pre>\ndocstring = 'This function adds *x* and *y*.\\n\\n        :param x: number *x*\\n        :param y: number *y*\\n        :return: sum = *x* + *y*\\n        '\ndirective = 'deprecated', reason = None, version = '1.2.0'\nexpected = '.. deprecated:: 1.2.0\\n'\n\n    @pytest.mark.parametrize(\n        \"reason, version, expected\",\n        [\n            (\n                'A good reason',\n                '1.2.0',\n                textwrap.dedent(\n                    \"\"\"\\\n                    .. {directive}:: {version}\n                       {reason}\n                    \"\"\"\n                ),\n            ),\n            (\n                None,\n                '1.2.0',\n                textwrap.dedent(\n                    \"\"\"\\\n                    .. {directive}:: {version}\n                    \"\"\"\n                ),\n            ),\n        ],\n        ids=[\"reason&amp;version\", \"version\"],\n    )\n    def test_has_sphinx_docstring(docstring, directive, reason, version, expected):\n        # The function:\n        def foo(x, y):\n            return x + y\n\n        # with docstring:\n        foo.__doc__ = docstring\n\n        # is decorated with:\n        decorator_factory = getattr(deprecated.sphinx, directive)\n        decorator = decorator_factory(reason=reason, version=version)\n        foo = decorator(foo)\n\n        # The function must contains this Sphinx docstring:\n        expected = expected.format(directive=directive, version=version, reason=reason)\n\n        current = textwrap.dedent(foo.__doc__)\n        assert current.endswith(expected)\n\n        current = current.replace(expected, '')\n        if docstring:\n            # An empty line must separate the original docstring and the directive.\n            assert re.search(\"\\n[ ]*\\n$\", current, flags=re.DOTALL)\n        else:\n            # Avoid \"Explicit markup ends without a blank line\" when the decorated function has no docstring\n            assert current == \"\\n\"\n\n        with warnings.catch_warnings(record=True) as warns:\n            foo(1, 2)\n\n        if directive in {'versionadded', 'versionchanged'}:\n            # don't emit DeprecationWarning\n            assert len(warns) == 0\n        else:\n            # emit DeprecationWarning\n&gt;           assert len(warns) == 1\nE           assert 0 == 1\nE            +  where 0 = len([])\n\ntests/test_sphinx.py:105: AssertionError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_deprecated_function__warnssphinx_deprecated_function0","title":"test_sphinx.py::test_sphinx_deprecated_function__warns[sphinx_deprecated_function0]","text":"<pre>test_sphinx.py::test_sphinx_deprecated_function__warns[sphinx_deprecated_function0]</pre><pre>\nsphinx_deprecated_function = .foo1 at 0x7fc0882909d0&gt;\n\n    def test_sphinx_deprecated_function__warns(sphinx_deprecated_function):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            sphinx_deprecated_function()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_sphinx.py:252: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_deprecated_function__warnssphinx_deprecated_function1","title":"test_sphinx.py::test_sphinx_deprecated_function__warns[sphinx_deprecated_function1]","text":"<pre>test_sphinx.py::test_sphinx_deprecated_function__warns[sphinx_deprecated_function1]</pre><pre>\nsphinx_deprecated_function = .foo1 at 0x7fc088290310&gt;\n\n    def test_sphinx_deprecated_function__warns(sphinx_deprecated_function):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            sphinx_deprecated_function()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_sphinx.py:252: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_deprecated_function__warnssphinx_deprecated_function2","title":"test_sphinx.py::test_sphinx_deprecated_function__warns[sphinx_deprecated_function2]","text":"<pre>test_sphinx.py::test_sphinx_deprecated_function__warns[sphinx_deprecated_function2]</pre><pre>\nsphinx_deprecated_function = .foo1 at 0x7fc0882904c0&gt;\n\n    def test_sphinx_deprecated_function__warns(sphinx_deprecated_function):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            sphinx_deprecated_function()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_sphinx.py:252: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_deprecated_function__warnssphinx_deprecated_function3","title":"test_sphinx.py::test_sphinx_deprecated_function__warns[sphinx_deprecated_function3]","text":"<pre>test_sphinx.py::test_sphinx_deprecated_function__warns[sphinx_deprecated_function3]</pre><pre>\nsphinx_deprecated_function = .foo1 at 0x7fc088290940&gt;\n\n    def test_sphinx_deprecated_function__warns(sphinx_deprecated_function):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            sphinx_deprecated_function()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_sphinx.py:252: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_deprecated_method__warnssphinx_deprecated_method0","title":"test_sphinx.py::test_sphinx_deprecated_method__warns[sphinx_deprecated_method0]","text":"<pre>test_sphinx.py::test_sphinx_deprecated_method__warns[sphinx_deprecated_method0]</pre><pre>\nsphinx_deprecated_method = .Foo3'&gt;\n\n    def test_sphinx_deprecated_method__warns(sphinx_deprecated_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            obj = sphinx_deprecated_method()\n            obj.foo3()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_sphinx.py:278: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_deprecated_method__warnssphinx_deprecated_method1","title":"test_sphinx.py::test_sphinx_deprecated_method__warns[sphinx_deprecated_method1]","text":"<pre>test_sphinx.py::test_sphinx_deprecated_method__warns[sphinx_deprecated_method1]</pre><pre>\nsphinx_deprecated_method = .Foo3'&gt;\n\n    def test_sphinx_deprecated_method__warns(sphinx_deprecated_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            obj = sphinx_deprecated_method()\n            obj.foo3()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_sphinx.py:278: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_deprecated_method__warnssphinx_deprecated_method2","title":"test_sphinx.py::test_sphinx_deprecated_method__warns[sphinx_deprecated_method2]","text":"<pre>test_sphinx.py::test_sphinx_deprecated_method__warns[sphinx_deprecated_method2]</pre><pre>\nsphinx_deprecated_method = .Foo3'&gt;\n\n    def test_sphinx_deprecated_method__warns(sphinx_deprecated_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            obj = sphinx_deprecated_method()\n            obj.foo3()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_sphinx.py:278: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_deprecated_method__warnssphinx_deprecated_method3","title":"test_sphinx.py::test_sphinx_deprecated_method__warns[sphinx_deprecated_method3]","text":"<pre>test_sphinx.py::test_sphinx_deprecated_method__warns[sphinx_deprecated_method3]</pre><pre>\nsphinx_deprecated_method = .Foo3'&gt;\n\n    def test_sphinx_deprecated_method__warns(sphinx_deprecated_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            obj = sphinx_deprecated_method()\n            obj.foo3()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_sphinx.py:278: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_deprecated_static_method__warnssphinx_deprecated_static_method0","title":"test_sphinx.py::test_sphinx_deprecated_static_method__warns[sphinx_deprecated_static_method0]","text":"<pre>test_sphinx.py::test_sphinx_deprecated_static_method__warns[sphinx_deprecated_static_method0]</pre><pre>\nsphinx_deprecated_static_method = .Foo4.foo4 at 0x7fc088290d30&gt;\n\n    def test_sphinx_deprecated_static_method__warns(sphinx_deprecated_static_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            sphinx_deprecated_static_method()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_sphinx.py:289: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_deprecated_static_method__warnssphinx_deprecated_static_method1","title":"test_sphinx.py::test_sphinx_deprecated_static_method__warns[sphinx_deprecated_static_method1]","text":"<pre>test_sphinx.py::test_sphinx_deprecated_static_method__warns[sphinx_deprecated_static_method1]</pre><pre>\nsphinx_deprecated_static_method = .Foo4.foo4 at 0x7fc088291090&gt;\n\n    def test_sphinx_deprecated_static_method__warns(sphinx_deprecated_static_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            sphinx_deprecated_static_method()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_sphinx.py:289: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_deprecated_static_method__warnssphinx_deprecated_static_method2","title":"test_sphinx.py::test_sphinx_deprecated_static_method__warns[sphinx_deprecated_static_method2]","text":"<pre>test_sphinx.py::test_sphinx_deprecated_static_method__warns[sphinx_deprecated_static_method2]</pre><pre>\nsphinx_deprecated_static_method = .Foo4.foo4 at 0x7fc088291240&gt;\n\n    def test_sphinx_deprecated_static_method__warns(sphinx_deprecated_static_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            sphinx_deprecated_static_method()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_sphinx.py:289: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_deprecated_static_method__warnssphinx_deprecated_static_method3","title":"test_sphinx.py::test_sphinx_deprecated_static_method__warns[sphinx_deprecated_static_method3]","text":"<pre>test_sphinx.py::test_sphinx_deprecated_static_method__warns[sphinx_deprecated_static_method3]</pre><pre>\nsphinx_deprecated_static_method = .Foo4.foo4 at 0x7fc0882913f0&gt;\n\n    def test_sphinx_deprecated_static_method__warns(sphinx_deprecated_static_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            sphinx_deprecated_static_method()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_sphinx.py:289: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_deprecated_class_method__warnssphinx_deprecated_class_method0","title":"test_sphinx.py::test_sphinx_deprecated_class_method__warns[sphinx_deprecated_class_method0]","text":"<pre>test_sphinx.py::test_sphinx_deprecated_class_method__warns[sphinx_deprecated_class_method0]</pre><pre>\nsphinx_deprecated_class_method = .Foo5'&gt;\n\n    def test_sphinx_deprecated_class_method__warns(sphinx_deprecated_class_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            cls = sphinx_deprecated_class_method()\n            cls.foo5()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_sphinx.py:301: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_deprecated_class_method__warnssphinx_deprecated_class_method1","title":"test_sphinx.py::test_sphinx_deprecated_class_method__warns[sphinx_deprecated_class_method1]","text":"<pre>test_sphinx.py::test_sphinx_deprecated_class_method__warns[sphinx_deprecated_class_method1]</pre><pre>\nsphinx_deprecated_class_method = .Foo5'&gt;\n\n    def test_sphinx_deprecated_class_method__warns(sphinx_deprecated_class_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            cls = sphinx_deprecated_class_method()\n            cls.foo5()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_sphinx.py:301: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_deprecated_class_method__warnssphinx_deprecated_class_method2","title":"test_sphinx.py::test_sphinx_deprecated_class_method__warns[sphinx_deprecated_class_method2]","text":"<pre>test_sphinx.py::test_sphinx_deprecated_class_method__warns[sphinx_deprecated_class_method2]</pre><pre>\nsphinx_deprecated_class_method = .Foo5'&gt;\n\n    def test_sphinx_deprecated_class_method__warns(sphinx_deprecated_class_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            cls = sphinx_deprecated_class_method()\n            cls.foo5()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_sphinx.py:301: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_deprecated_class_method__warnssphinx_deprecated_class_method3","title":"test_sphinx.py::test_sphinx_deprecated_class_method__warns[sphinx_deprecated_class_method3]","text":"<pre>test_sphinx.py::test_sphinx_deprecated_class_method__warns[sphinx_deprecated_class_method3]</pre><pre>\nsphinx_deprecated_class_method = .Foo5'&gt;\n\n    def test_sphinx_deprecated_class_method__warns(sphinx_deprecated_class_method):\n        with warnings.catch_warnings(record=True) as warns:\n            warnings.simplefilter(\"always\")\n            cls = sphinx_deprecated_class_method()\n            cls.foo5()\n&gt;       assert len(warns) == 1\nE       assert 0 == 1\nE        +  where 0 = len([])\n\ntests/test_sphinx.py:301: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_warning_msg_has_reason","title":"test_sphinx.py::test_warning_msg_has_reason","text":"<pre>test_sphinx.py::test_warning_msg_has_reason</pre><pre>\ndef test_warning_msg_has_reason():\n        reason = \"Good reason\"\n\n        @deprecated.sphinx.deprecated(version=\"4.5.6\", reason=reason)\n        def foo():\n            pass\n\n        with warnings.catch_warnings(record=True) as warns:\n            foo()\n&gt;       warn = warns[0]\nE       IndexError: list index out of range\n\ntests/test_sphinx.py:330: IndexError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_warning_msg_has_version","title":"test_sphinx.py::test_warning_msg_has_version","text":"<pre>test_sphinx.py::test_warning_msg_has_version</pre><pre>\ndef test_warning_msg_has_version():\n        version = \"1.2.3\"\n\n        @deprecated.sphinx.deprecated(version=version)\n        def foo():\n            pass\n\n        with warnings.catch_warnings(record=True) as warns:\n            foo()\n&gt;       warn = warns[0]\nE       IndexError: list index out of range\n\ntests/test_sphinx.py:343: IndexError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_specific_warning_cls_is_used","title":"test_sphinx.py::test_specific_warning_cls_is_used","text":"<pre>test_sphinx.py::test_specific_warning_cls_is_used</pre><pre>\ndef test_specific_warning_cls_is_used():\n        @deprecated.sphinx.deprecated(version=\"4.5.6\", category=MyDeprecationWarning)\n        def foo():\n            pass\n\n        with warnings.catch_warnings(record=True) as warns:\n            foo()\n&gt;       warn = warns[0]\nE       IndexError: list index out of range\n\ntests/test_sphinx.py:364: IndexError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_syntax_trimminguse-functionbar-instead-use-bar-instead","title":"test_sphinx.py::test_sphinx_syntax_trimming[Use :function:<code>bar</code> instead-Use <code>bar</code> instead]","text":"<pre>test_sphinx.py::test_sphinx_syntax_trimming[Use :function:`bar` instead-Use `bar` instead]</pre><pre>\nreason = 'Use :function:`bar` instead', expected = 'Use `bar` instead'\n\n    @pytest.mark.parametrize(\n        [\"reason\", \"expected\"],\n        [\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n        ],\n    )\n    def test_sphinx_syntax_trimming(reason, expected):\n        @deprecated.sphinx.deprecated(version=\"4.5.6\", reason=reason)\n        def foo():\n            pass\n\n        with warnings.catch_warnings(record=True) as warns:\n            foo()\n&gt;       warn = warns[0]\nE       IndexError: list index out of range\n\ntests/test_sphinx.py:389: IndexError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_sphinx_syntax_trimminguse-pyfuncbar-instead-use-bar-instead","title":"test_sphinx.py::test_sphinx_syntax_trimming[Use :py:func:<code>bar</code> instead-Use <code>bar</code> instead]","text":"<pre>test_sphinx.py::test_sphinx_syntax_trimming[Use :py:func:`bar` instead-Use `bar` instead]</pre><pre>\nreason = 'Use :py:func:`bar` instead', expected = 'Use `bar` instead'\n\n    @pytest.mark.parametrize(\n        [\"reason\", \"expected\"],\n        [\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n        ],\n    )\n    def test_sphinx_syntax_trimming(reason, expected):\n        @deprecated.sphinx.deprecated(version=\"4.5.6\", reason=reason)\n        def foo():\n            pass\n\n        with warnings.catch_warnings(record=True) as warns:\n            foo()\n&gt;       warn = warns[0]\nE       IndexError: list index out of range\n\ntests/test_sphinx.py:389: IndexError\n</pre>"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_get_deprecated_msguse-funcbar-instead-use-bar-instead","title":"test_sphinx.py::test_get_deprecated_msg[Use :func:<code>bar</code> instead-Use <code>bar</code> instead]","text":"<pre>test_sphinx.py::test_get_deprecated_msg[Use :func:`bar` instead-Use `bar` instead]</pre><pre>\nreason = 'Use :func:`bar` instead', expected = 'Use `bar` instead'\n\n    @pytest.mark.parametrize(\n        \"reason, expected\",\n        [\n            # classic examples using the default domain (Python)\n            (\"Use :func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :class:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exc:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exception:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :meth:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            (\"Use :method:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            # other examples using a domain :\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :cpp:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :js:func:`bar` instead\", \"Use `bar` instead\"),\n            # the reference can have special characters:\n            (\"Use :func:`~pkg.mod.bar` instead\", \"Use `~pkg.mod.bar` instead\"),\n            # edge cases:\n            (\"Use :r:`` instead\", \"Use `` instead\"),\n            (\"Use :d:r:`` instead\", \"Use `` instead\"),\n            (\"Use :r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use :d:r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use r:`bad` instead\", \"Use r:`bad` instead\"),\n            (\"Use ::`bad` instead\", \"Use ::`bad` instead\"),\n            (\"Use :::`bad` instead\", \"Use :::`bad` instead\"),\n        ],\n    )\n    def test_get_deprecated_msg(reason, expected):\n        adapter = deprecated.sphinx.SphinxAdapter(\"deprecated\", reason=reason, version=\"1\")\n        actual = adapter.get_deprecated_msg(lambda: None, None)\n&gt;       assert expected in actual\nE       AssertionError: assert 'Use `bar` instead' in 'Call to deprecated function . (Use bar instead) -- Deprecated since version 1.'\n\ntests/test_sphinx.py:424: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_get_deprecated_msguse-functionbar-instead-use-bar-instead","title":"test_sphinx.py::test_get_deprecated_msg[Use :function:<code>bar</code> instead-Use <code>bar</code> instead]","text":"<pre>test_sphinx.py::test_get_deprecated_msg[Use :function:`bar` instead-Use `bar` instead]</pre><pre>\nreason = 'Use :function:`bar` instead', expected = 'Use `bar` instead'\n\n    @pytest.mark.parametrize(\n        \"reason, expected\",\n        [\n            # classic examples using the default domain (Python)\n            (\"Use :func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :class:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exc:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exception:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :meth:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            (\"Use :method:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            # other examples using a domain :\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :cpp:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :js:func:`bar` instead\", \"Use `bar` instead\"),\n            # the reference can have special characters:\n            (\"Use :func:`~pkg.mod.bar` instead\", \"Use `~pkg.mod.bar` instead\"),\n            # edge cases:\n            (\"Use :r:`` instead\", \"Use `` instead\"),\n            (\"Use :d:r:`` instead\", \"Use `` instead\"),\n            (\"Use :r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use :d:r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use r:`bad` instead\", \"Use r:`bad` instead\"),\n            (\"Use ::`bad` instead\", \"Use ::`bad` instead\"),\n            (\"Use :::`bad` instead\", \"Use :::`bad` instead\"),\n        ],\n    )\n    def test_get_deprecated_msg(reason, expected):\n        adapter = deprecated.sphinx.SphinxAdapter(\"deprecated\", reason=reason, version=\"1\")\n        actual = adapter.get_deprecated_msg(lambda: None, None)\n&gt;       assert expected in actual\nE       AssertionError: assert 'Use `bar` instead' in 'Call to deprecated function . (Use :function:`bar` instead) -- Deprecated since version 1.'\n\ntests/test_sphinx.py:424: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_get_deprecated_msguse-classbaz-instead-use-baz-instead","title":"test_sphinx.py::test_get_deprecated_msg[Use :class:<code>Baz</code> instead-Use <code>Baz</code> instead]","text":"<pre>test_sphinx.py::test_get_deprecated_msg[Use :class:`Baz` instead-Use `Baz` instead]</pre><pre>\nreason = 'Use :class:`Baz` instead', expected = 'Use `Baz` instead'\n\n    @pytest.mark.parametrize(\n        \"reason, expected\",\n        [\n            # classic examples using the default domain (Python)\n            (\"Use :func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :class:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exc:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exception:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :meth:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            (\"Use :method:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            # other examples using a domain :\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :cpp:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :js:func:`bar` instead\", \"Use `bar` instead\"),\n            # the reference can have special characters:\n            (\"Use :func:`~pkg.mod.bar` instead\", \"Use `~pkg.mod.bar` instead\"),\n            # edge cases:\n            (\"Use :r:`` instead\", \"Use `` instead\"),\n            (\"Use :d:r:`` instead\", \"Use `` instead\"),\n            (\"Use :r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use :d:r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use r:`bad` instead\", \"Use r:`bad` instead\"),\n            (\"Use ::`bad` instead\", \"Use ::`bad` instead\"),\n            (\"Use :::`bad` instead\", \"Use :::`bad` instead\"),\n        ],\n    )\n    def test_get_deprecated_msg(reason, expected):\n        adapter = deprecated.sphinx.SphinxAdapter(\"deprecated\", reason=reason, version=\"1\")\n        actual = adapter.get_deprecated_msg(lambda: None, None)\n&gt;       assert expected in actual\nE       AssertionError: assert 'Use `Baz` instead' in 'Call to deprecated function . (Use Baz instead) -- Deprecated since version 1.'\n\ntests/test_sphinx.py:424: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_get_deprecated_msguse-excbaz-instead-use-baz-instead","title":"test_sphinx.py::test_get_deprecated_msg[Use :exc:<code>Baz</code> instead-Use <code>Baz</code> instead]","text":"<pre>test_sphinx.py::test_get_deprecated_msg[Use :exc:`Baz` instead-Use `Baz` instead]</pre><pre>\nreason = 'Use :exc:`Baz` instead', expected = 'Use `Baz` instead'\n\n    @pytest.mark.parametrize(\n        \"reason, expected\",\n        [\n            # classic examples using the default domain (Python)\n            (\"Use :func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :class:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exc:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exception:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :meth:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            (\"Use :method:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            # other examples using a domain :\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :cpp:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :js:func:`bar` instead\", \"Use `bar` instead\"),\n            # the reference can have special characters:\n            (\"Use :func:`~pkg.mod.bar` instead\", \"Use `~pkg.mod.bar` instead\"),\n            # edge cases:\n            (\"Use :r:`` instead\", \"Use `` instead\"),\n            (\"Use :d:r:`` instead\", \"Use `` instead\"),\n            (\"Use :r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use :d:r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use r:`bad` instead\", \"Use r:`bad` instead\"),\n            (\"Use ::`bad` instead\", \"Use ::`bad` instead\"),\n            (\"Use :::`bad` instead\", \"Use :::`bad` instead\"),\n        ],\n    )\n    def test_get_deprecated_msg(reason, expected):\n        adapter = deprecated.sphinx.SphinxAdapter(\"deprecated\", reason=reason, version=\"1\")\n        actual = adapter.get_deprecated_msg(lambda: None, None)\n&gt;       assert expected in actual\nE       AssertionError: assert 'Use `Baz` instead' in 'Call to deprecated function . (Use Baz instead) -- Deprecated since version 1.'\n\ntests/test_sphinx.py:424: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_get_deprecated_msguse-exceptionbaz-instead-use-baz-instead","title":"test_sphinx.py::test_get_deprecated_msg[Use :exception:<code>Baz</code> instead-Use <code>Baz</code> instead]","text":"<pre>test_sphinx.py::test_get_deprecated_msg[Use :exception:`Baz` instead-Use `Baz` instead]</pre><pre>\nreason = 'Use :exception:`Baz` instead', expected = 'Use `Baz` instead'\n\n    @pytest.mark.parametrize(\n        \"reason, expected\",\n        [\n            # classic examples using the default domain (Python)\n            (\"Use :func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :class:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exc:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exception:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :meth:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            (\"Use :method:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            # other examples using a domain :\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :cpp:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :js:func:`bar` instead\", \"Use `bar` instead\"),\n            # the reference can have special characters:\n            (\"Use :func:`~pkg.mod.bar` instead\", \"Use `~pkg.mod.bar` instead\"),\n            # edge cases:\n            (\"Use :r:`` instead\", \"Use `` instead\"),\n            (\"Use :d:r:`` instead\", \"Use `` instead\"),\n            (\"Use :r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use :d:r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use r:`bad` instead\", \"Use r:`bad` instead\"),\n            (\"Use ::`bad` instead\", \"Use ::`bad` instead\"),\n            (\"Use :::`bad` instead\", \"Use :::`bad` instead\"),\n        ],\n    )\n    def test_get_deprecated_msg(reason, expected):\n        adapter = deprecated.sphinx.SphinxAdapter(\"deprecated\", reason=reason, version=\"1\")\n        actual = adapter.get_deprecated_msg(lambda: None, None)\n&gt;       assert expected in actual\nE       AssertionError: assert 'Use `Baz` instead' in 'Call to deprecated function . (Use :exception:`Baz` instead) -- Deprecated since version 1.'\n\ntests/test_sphinx.py:424: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_get_deprecated_msguse-methbazbar-instead-use-bazbar-instead","title":"test_sphinx.py::test_get_deprecated_msg[Use :meth:<code>Baz.bar</code> instead-Use <code>Baz.bar</code> instead]","text":"<pre>test_sphinx.py::test_get_deprecated_msg[Use :meth:`Baz.bar` instead-Use `Baz.bar` instead]</pre><pre>\nreason = 'Use :meth:`Baz.bar` instead', expected = 'Use `Baz.bar` instead'\n\n    @pytest.mark.parametrize(\n        \"reason, expected\",\n        [\n            # classic examples using the default domain (Python)\n            (\"Use :func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :class:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exc:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exception:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :meth:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            (\"Use :method:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            # other examples using a domain :\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :cpp:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :js:func:`bar` instead\", \"Use `bar` instead\"),\n            # the reference can have special characters:\n            (\"Use :func:`~pkg.mod.bar` instead\", \"Use `~pkg.mod.bar` instead\"),\n            # edge cases:\n            (\"Use :r:`` instead\", \"Use `` instead\"),\n            (\"Use :d:r:`` instead\", \"Use `` instead\"),\n            (\"Use :r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use :d:r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use r:`bad` instead\", \"Use r:`bad` instead\"),\n            (\"Use ::`bad` instead\", \"Use ::`bad` instead\"),\n            (\"Use :::`bad` instead\", \"Use :::`bad` instead\"),\n        ],\n    )\n    def test_get_deprecated_msg(reason, expected):\n        adapter = deprecated.sphinx.SphinxAdapter(\"deprecated\", reason=reason, version=\"1\")\n        actual = adapter.get_deprecated_msg(lambda: None, None)\n&gt;       assert expected in actual\nE       AssertionError: assert 'Use `Baz.bar` instead' in 'Call to deprecated function . (Use Baz.bar instead) -- Deprecated since version 1.'\n\ntests/test_sphinx.py:424: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_get_deprecated_msguse-methodbazbar-instead-use-bazbar-instead","title":"test_sphinx.py::test_get_deprecated_msg[Use :method:<code>Baz.bar</code> instead-Use <code>Baz.bar</code> instead]","text":"<pre>test_sphinx.py::test_get_deprecated_msg[Use :method:`Baz.bar` instead-Use `Baz.bar` instead]</pre><pre>\nreason = 'Use :method:`Baz.bar` instead', expected = 'Use `Baz.bar` instead'\n\n    @pytest.mark.parametrize(\n        \"reason, expected\",\n        [\n            # classic examples using the default domain (Python)\n            (\"Use :func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :class:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exc:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exception:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :meth:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            (\"Use :method:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            # other examples using a domain :\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :cpp:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :js:func:`bar` instead\", \"Use `bar` instead\"),\n            # the reference can have special characters:\n            (\"Use :func:`~pkg.mod.bar` instead\", \"Use `~pkg.mod.bar` instead\"),\n            # edge cases:\n            (\"Use :r:`` instead\", \"Use `` instead\"),\n            (\"Use :d:r:`` instead\", \"Use `` instead\"),\n            (\"Use :r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use :d:r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use r:`bad` instead\", \"Use r:`bad` instead\"),\n            (\"Use ::`bad` instead\", \"Use ::`bad` instead\"),\n            (\"Use :::`bad` instead\", \"Use :::`bad` instead\"),\n        ],\n    )\n    def test_get_deprecated_msg(reason, expected):\n        adapter = deprecated.sphinx.SphinxAdapter(\"deprecated\", reason=reason, version=\"1\")\n        actual = adapter.get_deprecated_msg(lambda: None, None)\n&gt;       assert expected in actual\nE       AssertionError: assert 'Use `Baz.bar` instead' in 'Call to deprecated function . (Use :method:`Baz.bar` instead) -- Deprecated since version 1.'\n\ntests/test_sphinx.py:424: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_get_deprecated_msguse-pyfuncbar-instead-use-bar-instead","title":"test_sphinx.py::test_get_deprecated_msg[Use :py:func:<code>bar</code> instead-Use <code>bar</code> instead]","text":"<pre>test_sphinx.py::test_get_deprecated_msg[Use :py:func:`bar` instead-Use `bar` instead]</pre><pre>\nreason = 'Use :py:func:`bar` instead', expected = 'Use `bar` instead'\n\n    @pytest.mark.parametrize(\n        \"reason, expected\",\n        [\n            # classic examples using the default domain (Python)\n            (\"Use :func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :class:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exc:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exception:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :meth:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            (\"Use :method:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            # other examples using a domain :\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :cpp:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :js:func:`bar` instead\", \"Use `bar` instead\"),\n            # the reference can have special characters:\n            (\"Use :func:`~pkg.mod.bar` instead\", \"Use `~pkg.mod.bar` instead\"),\n            # edge cases:\n            (\"Use :r:`` instead\", \"Use `` instead\"),\n            (\"Use :d:r:`` instead\", \"Use `` instead\"),\n            (\"Use :r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use :d:r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use r:`bad` instead\", \"Use r:`bad` instead\"),\n            (\"Use ::`bad` instead\", \"Use ::`bad` instead\"),\n            (\"Use :::`bad` instead\", \"Use :::`bad` instead\"),\n        ],\n    )\n    def test_get_deprecated_msg(reason, expected):\n        adapter = deprecated.sphinx.SphinxAdapter(\"deprecated\", reason=reason, version=\"1\")\n        actual = adapter.get_deprecated_msg(lambda: None, None)\n&gt;       assert expected in actual\nE       AssertionError: assert 'Use `bar` instead' in 'Call to deprecated function . (Use :pybar instead) -- Deprecated since version 1.'\n\ntests/test_sphinx.py:424: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_get_deprecated_msguse-cppfuncbar-instead-use-bar-instead","title":"test_sphinx.py::test_get_deprecated_msg[Use :cpp:func:<code>bar</code> instead-Use <code>bar</code> instead]","text":"<pre>test_sphinx.py::test_get_deprecated_msg[Use :cpp:func:`bar` instead-Use `bar` instead]</pre><pre>\nreason = 'Use :cpp:func:`bar` instead', expected = 'Use `bar` instead'\n\n    @pytest.mark.parametrize(\n        \"reason, expected\",\n        [\n            # classic examples using the default domain (Python)\n            (\"Use :func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :class:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exc:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exception:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :meth:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            (\"Use :method:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            # other examples using a domain :\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :cpp:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :js:func:`bar` instead\", \"Use `bar` instead\"),\n            # the reference can have special characters:\n            (\"Use :func:`~pkg.mod.bar` instead\", \"Use `~pkg.mod.bar` instead\"),\n            # edge cases:\n            (\"Use :r:`` instead\", \"Use `` instead\"),\n            (\"Use :d:r:`` instead\", \"Use `` instead\"),\n            (\"Use :r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use :d:r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use r:`bad` instead\", \"Use r:`bad` instead\"),\n            (\"Use ::`bad` instead\", \"Use ::`bad` instead\"),\n            (\"Use :::`bad` instead\", \"Use :::`bad` instead\"),\n        ],\n    )\n    def test_get_deprecated_msg(reason, expected):\n        adapter = deprecated.sphinx.SphinxAdapter(\"deprecated\", reason=reason, version=\"1\")\n        actual = adapter.get_deprecated_msg(lambda: None, None)\n&gt;       assert expected in actual\nE       AssertionError: assert 'Use `bar` instead' in 'Call to deprecated function . (Use :cppbar instead) -- Deprecated since version 1.'\n\ntests/test_sphinx.py:424: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_get_deprecated_msguse-jsfuncbar-instead-use-bar-instead","title":"test_sphinx.py::test_get_deprecated_msg[Use :js:func:<code>bar</code> instead-Use <code>bar</code> instead]","text":"<pre>test_sphinx.py::test_get_deprecated_msg[Use :js:func:`bar` instead-Use `bar` instead]</pre><pre>\nreason = 'Use :js:func:`bar` instead', expected = 'Use `bar` instead'\n\n    @pytest.mark.parametrize(\n        \"reason, expected\",\n        [\n            # classic examples using the default domain (Python)\n            (\"Use :func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :class:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exc:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exception:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :meth:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            (\"Use :method:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            # other examples using a domain :\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :cpp:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :js:func:`bar` instead\", \"Use `bar` instead\"),\n            # the reference can have special characters:\n            (\"Use :func:`~pkg.mod.bar` instead\", \"Use `~pkg.mod.bar` instead\"),\n            # edge cases:\n            (\"Use :r:`` instead\", \"Use `` instead\"),\n            (\"Use :d:r:`` instead\", \"Use `` instead\"),\n            (\"Use :r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use :d:r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use r:`bad` instead\", \"Use r:`bad` instead\"),\n            (\"Use ::`bad` instead\", \"Use ::`bad` instead\"),\n            (\"Use :::`bad` instead\", \"Use :::`bad` instead\"),\n        ],\n    )\n    def test_get_deprecated_msg(reason, expected):\n        adapter = deprecated.sphinx.SphinxAdapter(\"deprecated\", reason=reason, version=\"1\")\n        actual = adapter.get_deprecated_msg(lambda: None, None)\n&gt;       assert expected in actual\nE       AssertionError: assert 'Use `bar` instead' in 'Call to deprecated function . (Use :jsbar instead) -- Deprecated since version 1.'\n\ntests/test_sphinx.py:424: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_get_deprecated_msguse-funcpkgmodbar-instead-use-pkgmodbar-instead","title":"test_sphinx.py::test_get_deprecated_msg[Use :func:<code>~pkg.mod.bar</code> instead-Use <code>~pkg.mod.bar</code> instead]","text":"<pre>test_sphinx.py::test_get_deprecated_msg[Use :func:`~pkg.mod.bar` instead-Use `~pkg.mod.bar` instead]</pre><pre>\nreason = 'Use :func:`~pkg.mod.bar` instead'\nexpected = 'Use `~pkg.mod.bar` instead'\n\n    @pytest.mark.parametrize(\n        \"reason, expected\",\n        [\n            # classic examples using the default domain (Python)\n            (\"Use :func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :class:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exc:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exception:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :meth:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            (\"Use :method:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            # other examples using a domain :\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :cpp:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :js:func:`bar` instead\", \"Use `bar` instead\"),\n            # the reference can have special characters:\n            (\"Use :func:`~pkg.mod.bar` instead\", \"Use `~pkg.mod.bar` instead\"),\n            # edge cases:\n            (\"Use :r:`` instead\", \"Use `` instead\"),\n            (\"Use :d:r:`` instead\", \"Use `` instead\"),\n            (\"Use :r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use :d:r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use r:`bad` instead\", \"Use r:`bad` instead\"),\n            (\"Use ::`bad` instead\", \"Use ::`bad` instead\"),\n            (\"Use :::`bad` instead\", \"Use :::`bad` instead\"),\n        ],\n    )\n    def test_get_deprecated_msg(reason, expected):\n        adapter = deprecated.sphinx.SphinxAdapter(\"deprecated\", reason=reason, version=\"1\")\n        actual = adapter.get_deprecated_msg(lambda: None, None)\n&gt;       assert expected in actual\nE       AssertionError: assert 'Use `~pkg.mod.bar` instead' in 'Call to deprecated function . (Use pkg.mod.bar instead) -- Deprecated since version 1.'\n\ntests/test_sphinx.py:424: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_get_deprecated_msguse-rinstead-use-instead","title":"test_sphinx.py::test_get_deprecated_msg[Use :r:<code>instead-Use</code> instead]","text":"<pre>test_sphinx.py::test_get_deprecated_msg[Use :r:`` instead-Use `` instead]</pre><pre>\nreason = 'Use :r:`` instead', expected = 'Use `` instead'\n\n    @pytest.mark.parametrize(\n        \"reason, expected\",\n        [\n            # classic examples using the default domain (Python)\n            (\"Use :func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :class:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exc:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exception:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :meth:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            (\"Use :method:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            # other examples using a domain :\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :cpp:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :js:func:`bar` instead\", \"Use `bar` instead\"),\n            # the reference can have special characters:\n            (\"Use :func:`~pkg.mod.bar` instead\", \"Use `~pkg.mod.bar` instead\"),\n            # edge cases:\n            (\"Use :r:`` instead\", \"Use `` instead\"),\n            (\"Use :d:r:`` instead\", \"Use `` instead\"),\n            (\"Use :r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use :d:r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use r:`bad` instead\", \"Use r:`bad` instead\"),\n            (\"Use ::`bad` instead\", \"Use ::`bad` instead\"),\n            (\"Use :::`bad` instead\", \"Use :::`bad` instead\"),\n        ],\n    )\n    def test_get_deprecated_msg(reason, expected):\n        adapter = deprecated.sphinx.SphinxAdapter(\"deprecated\", reason=reason, version=\"1\")\n        actual = adapter.get_deprecated_msg(lambda: None, None)\n&gt;       assert expected in actual\nE       AssertionError: assert 'Use `` instead' in 'Call to deprecated function . (Use :r:`` instead) -- Deprecated since version 1.'\n\ntests/test_sphinx.py:424: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_get_deprecated_msguse-drinstead-use-instead","title":"test_sphinx.py::test_get_deprecated_msg[Use :d:r:<code>instead-Use</code> instead]","text":"<pre>test_sphinx.py::test_get_deprecated_msg[Use :d:r:`` instead-Use `` instead]</pre><pre>\nreason = 'Use :d:r:`` instead', expected = 'Use `` instead'\n\n    @pytest.mark.parametrize(\n        \"reason, expected\",\n        [\n            # classic examples using the default domain (Python)\n            (\"Use :func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :class:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exc:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exception:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :meth:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            (\"Use :method:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            # other examples using a domain :\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :cpp:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :js:func:`bar` instead\", \"Use `bar` instead\"),\n            # the reference can have special characters:\n            (\"Use :func:`~pkg.mod.bar` instead\", \"Use `~pkg.mod.bar` instead\"),\n            # edge cases:\n            (\"Use :r:`` instead\", \"Use `` instead\"),\n            (\"Use :d:r:`` instead\", \"Use `` instead\"),\n            (\"Use :r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use :d:r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use r:`bad` instead\", \"Use r:`bad` instead\"),\n            (\"Use ::`bad` instead\", \"Use ::`bad` instead\"),\n            (\"Use :::`bad` instead\", \"Use :::`bad` instead\"),\n        ],\n    )\n    def test_get_deprecated_msg(reason, expected):\n        adapter = deprecated.sphinx.SphinxAdapter(\"deprecated\", reason=reason, version=\"1\")\n        actual = adapter.get_deprecated_msg(lambda: None, None)\n&gt;       assert expected in actual\nE       AssertionError: assert 'Use `` instead' in 'Call to deprecated function . (Use :d:r:`` instead) -- Deprecated since version 1.'\n\ntests/test_sphinx.py:424: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_get_deprecated_msguse-rfoo-instead-use-foo-instead","title":"test_sphinx.py::test_get_deprecated_msg[Use :r:<code>foo</code> instead-Use <code>foo</code> instead]","text":"<pre>test_sphinx.py::test_get_deprecated_msg[Use :r:`foo` instead-Use `foo` instead]</pre><pre>\nreason = 'Use :r:`foo` instead', expected = 'Use `foo` instead'\n\n    @pytest.mark.parametrize(\n        \"reason, expected\",\n        [\n            # classic examples using the default domain (Python)\n            (\"Use :func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :class:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exc:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exception:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :meth:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            (\"Use :method:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            # other examples using a domain :\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :cpp:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :js:func:`bar` instead\", \"Use `bar` instead\"),\n            # the reference can have special characters:\n            (\"Use :func:`~pkg.mod.bar` instead\", \"Use `~pkg.mod.bar` instead\"),\n            # edge cases:\n            (\"Use :r:`` instead\", \"Use `` instead\"),\n            (\"Use :d:r:`` instead\", \"Use `` instead\"),\n            (\"Use :r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use :d:r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use r:`bad` instead\", \"Use r:`bad` instead\"),\n            (\"Use ::`bad` instead\", \"Use ::`bad` instead\"),\n            (\"Use :::`bad` instead\", \"Use :::`bad` instead\"),\n        ],\n    )\n    def test_get_deprecated_msg(reason, expected):\n        adapter = deprecated.sphinx.SphinxAdapter(\"deprecated\", reason=reason, version=\"1\")\n        actual = adapter.get_deprecated_msg(lambda: None, None)\n&gt;       assert expected in actual\nE       AssertionError: assert 'Use `foo` instead' in 'Call to deprecated function . (Use :r:`foo` instead) -- Deprecated since version 1.'\n\ntests/test_sphinx.py:424: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinxpytest_get_deprecated_msguse-drfoo-instead-use-foo-instead","title":"test_sphinx.py::test_get_deprecated_msg[Use :d:r:<code>foo</code> instead-Use <code>foo</code> instead]","text":"<pre>test_sphinx.py::test_get_deprecated_msg[Use :d:r:`foo` instead-Use `foo` instead]</pre><pre>\nreason = 'Use :d:r:`foo` instead', expected = 'Use `foo` instead'\n\n    @pytest.mark.parametrize(\n        \"reason, expected\",\n        [\n            # classic examples using the default domain (Python)\n            (\"Use :func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :function:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :class:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exc:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :exception:`Baz` instead\", \"Use `Baz` instead\"),\n            (\"Use :meth:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            (\"Use :method:`Baz.bar` instead\", \"Use `Baz.bar` instead\"),\n            # other examples using a domain :\n            (\"Use :py:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :cpp:func:`bar` instead\", \"Use `bar` instead\"),\n            (\"Use :js:func:`bar` instead\", \"Use `bar` instead\"),\n            # the reference can have special characters:\n            (\"Use :func:`~pkg.mod.bar` instead\", \"Use `~pkg.mod.bar` instead\"),\n            # edge cases:\n            (\"Use :r:`` instead\", \"Use `` instead\"),\n            (\"Use :d:r:`` instead\", \"Use `` instead\"),\n            (\"Use :r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use :d:r:`foo` instead\", \"Use `foo` instead\"),\n            (\"Use r:`bad` instead\", \"Use r:`bad` instead\"),\n            (\"Use ::`bad` instead\", \"Use ::`bad` instead\"),\n            (\"Use :::`bad` instead\", \"Use :::`bad` instead\"),\n        ],\n    )\n    def test_get_deprecated_msg(reason, expected):\n        adapter = deprecated.sphinx.SphinxAdapter(\"deprecated\", reason=reason, version=\"1\")\n        actual = adapter.get_deprecated_msg(lambda: None, None)\n&gt;       assert expected in actual\nE       AssertionError: assert 'Use `foo` instead' in 'Call to deprecated function . (Use :d:r:`foo` instead) -- Deprecated since version 1.'\n\ntests/test_sphinx.py:424: AssertionError"},{"location":"analysis_baseline_deprecated/#test_sphinx_metaclasspytest_with_init","title":"test_sphinx_metaclass.py::test_with_init","text":"<pre>test_sphinx_metaclass.py::test_with_init</pre><pre>\ndef test_with_init():\n        @deprecated.classic.deprecated\n&gt;       class MyClass(object):\n\ntests/test_sphinx_metaclass.py:26: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (.MyClass'&gt;,)\nkwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_sphinx_metaclasspytest_with_new","title":"test_sphinx_metaclass.py::test_with_new","text":"<pre>test_sphinx_metaclass.py::test_with_new</pre><pre>\ndef test_with_new():\n        @deprecated.classic.deprecated\n&gt;       class MyClass(object):\n\ntests/test_sphinx_metaclass.py:43: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (.MyClass'&gt;,)\nkwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_sphinx_metaclasspytest_with_metaclass","title":"test_sphinx_metaclass.py::test_with_metaclass","text":"<pre>test_sphinx_metaclass.py::test_with_metaclass</pre><pre>\ndef test_with_metaclass():\n        class Meta(type):\n            def __call__(cls, *args, **kwargs):\n                obj = super(Meta, cls).__call__(*args, **kwargs)\n                obj.c = 3.14\n                return obj\n\n        @deprecated.classic.deprecated\n&gt;       class MyClass(with_metaclass(Meta)):\n\ntests/test_sphinx_metaclass.py:72: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (.MyClass'&gt;,)\nkwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#test_sphinx_metaclasspytest_with_singleton_metaclass","title":"test_sphinx_metaclass.py::test_with_singleton_metaclass","text":"<pre>test_sphinx_metaclass.py::test_with_singleton_metaclass</pre><pre>\ndef test_with_singleton_metaclass():\n        class Singleton(type):\n            _instances = {}\n\n            def __call__(cls, *args, **kwargs):\n                if cls not in cls._instances:\n                    cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)\n                return cls._instances[cls]\n\n        @deprecated.classic.deprecated\n&gt;       class MyClass(with_metaclass(Singleton)):\n\ntests/test_sphinx_metaclass.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (.MyClass'&gt;,)\nkwargs = {}\n\n    def deprecated(*args, **kwargs):\n        \"\"\"\n        This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emitted\n        when the function is used.\n\n        **Classic usage:**\n\n        To use this, decorate your deprecated function with **@deprecated** decorator:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated\n           def some_old_function(x, y):\n               return x + y\n\n        You can also decorate a class or a method:\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           class SomeClass(object):\n               @deprecated\n               def some_old_method(self, x, y):\n                   return x + y\n\n\n           @deprecated\n           class SomeOldClass(object):\n               pass\n\n        You can give a *reason* message to help the developer to choose another function/class,\n        and a *version* number to specify the starting version number of the deprecation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(reason=\"use another function\", version='1.2.0')\n           def some_old_function(x, y):\n               return x + y\n\n        The *category* keyword argument allow you to specify the deprecation warning class of your choice.\n        By default, :exc:`DeprecationWarning` is used but you can choose :exc:`FutureWarning`,\n        :exc:`PendingDeprecationWarning` or a custom subclass.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(category=PendingDeprecationWarning)\n           def some_old_function(x, y):\n               return x + y\n\n        The *action* keyword argument allow you to locally change the warning filtering.\n        *action* can be one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\".\n        If ``None``, empty or missing, the the global filtering mechanism is used.\n        See: `The Warnings Filter`_ in the Python documentation.\n\n        .. code-block:: python\n\n           from deprecated import deprecated\n\n\n           @deprecated(action=\"error\")\n           def some_old_function(x, y):\n               return x + y\n\n        \"\"\"\n&gt;       if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\nE       NameError: name 'types' is not defined\n\ndeprecated/classic.py:248: NameError"},{"location":"analysis_baseline_deprecated/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/deprecated/classic.py b/deprecated/classic.py\nindex fc9af25..273dcec 100644\n--- a/deprecated/classic.py\n+++ b/deprecated/classic.py\n@@ -119,7 +119,21 @@ class ClassicAdapter(wrapt.AdapterFactory):\n\n         :return: The warning message.\n         \"\"\"\n-        pass\n+        if instance is None:\n+            if inspect.isclass(wrapped):\n+                fmt = \"Call to deprecated class {name}.\"\n+            else:\n+                fmt = \"Call to deprecated function {name}.\"\n+        else:\n+            if inspect.isclass(instance):\n+                fmt = \"Call to deprecated class method {name}.\"\n+            else:\n+                fmt = \"Call to deprecated method {name}.\"\n+        if self.reason:\n+            fmt += \" ({reason})\"\n+        if self.version:\n+            fmt += \" -- Deprecated since version {version}.\"\n+        return fmt.format(name=wrapped.__name__, reason=self.reason, version=self.version)\n\n     def __call__(self, wrapped):\n         \"\"\"\n@@ -231,4 +245,9 @@ def deprecated(*args, **kwargs):\n            return x + y\n\n     \"\"\"\n-    pass\n+    if args and isinstance(args[0], (type, types.FunctionType, types.MethodType)):\n+        return ClassicAdapter()(args[0])\n+    else:\n+        def wrapper(wrapped):\n+            return ClassicAdapter(**kwargs)(wrapped)\n+        return wrapper\ndiff --git a/deprecated/sphinx.py b/deprecated/sphinx.py\nindex 6daf81f..d91c375 100644\n--- a/deprecated/sphinx.py\n+++ b/deprecated/sphinx.py\n@@ -133,7 +133,13 @@ class SphinxAdapter(ClassicAdapter):\n            Strip Sphinx cross-referencing syntax from warning message.\n\n         \"\"\"\n-        pass\n+        # Get the original deprecation message\n+        message = super(SphinxAdapter, self).get_deprecated_msg(wrapped, instance)\n+        \n+        # Strip Sphinx cross-referencing syntax\n+        message = re.sub(r':(?:class|func|meth|attr|obj|exc|data|const|mod):`~?([^`]+)`', r'\\1', message)\n+        \n+        return message\n\n\n def versionadded(reason='', version='', line_length=70):\n@@ -157,7 +163,7 @@ def versionadded(reason='', version='', line_length=70):\n\n     :return: the decorated function.\n     \"\"\"\n-    pass\n+    return SphinxAdapter('versionadded', reason=reason, version=version, line_length=line_length)\n\n\n def versionchanged(reason='', version='', line_length=70):\n@@ -180,7 +186,7 @@ def versionchanged(reason='', version='', line_length=70):\n\n     :return: the decorated function.\n     \"\"\"\n-    pass\n+    return SphinxAdapter('versionchanged', reason=reason, version=version, line_length=line_length)\n\n\n def deprecated(reason='', version='', line_length=70, **kwargs):\n@@ -218,4 +224,4 @@ def deprecated(reason='', version='', line_length=70, **kwargs):\n     .. versionchanged:: 1.2.13\n        Change the signature of the decorator to reflect the valid use cases.\n     \"\"\"\n-    pass\n+    return SphinxAdapter('deprecated', reason=reason, version=version, line_length=line_length, **kwargs)\n</code></pre>"},{"location":"analysis_baseline_imapclient/","title":"Analysis baseline imapclient","text":"<p>back to baseline summary</p>"},{"location":"analysis_baseline_imapclient/#submission-name-baseline","title":"Submission Name: baseline","text":""},{"location":"analysis_baseline_imapclient/#repository-imapclient","title":"Repository: imapclient","text":""},{"location":"analysis_baseline_imapclient/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count total 0 collected 0 passed 0"},{"location":"analysis_baseline_imapclient/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_baseline_imapclient/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/imapclient/config.py b/imapclient/config.py\nindex f098591..43fc51c 100644\n--- a/imapclient/config.py\n+++ b/imapclient/config.py\n@@ -14,7 +14,25 @@ def parse_config_file(filename: str) -&gt;argparse.Namespace:\n\n     Used by livetest.py and interact.py\n     \"\"\"\n-    pass\n+    config = configparser.ConfigParser()\n+    config.read(filename)\n+\n+    if 'DEFAULT' not in config:\n+        raise ValueError(f\"Config file {filename} must have a DEFAULT section\")\n+\n+    ns = argparse.Namespace()\n+    for key, value in config['DEFAULT'].items():\n+        setattr(ns, key, value)\n+\n+    # Convert certain values to appropriate types\n+    if hasattr(ns, 'port'):\n+        ns.port = int(ns.port)\n+    if hasattr(ns, 'ssl'):\n+        ns.ssl = config['DEFAULT'].getboolean('ssl')\n+    if hasattr(ns, 'timeout'):\n+        ns.timeout = float(ns.timeout)\n+\n+    return ns\n\n\n T = TypeVar('T')\ndiff --git a/imapclient/datetime_util.py b/imapclient/datetime_util.py\nindex 57a44c4..6533952 100644\n--- a/imapclient/datetime_util.py\n+++ b/imapclient/datetime_util.py\n@@ -14,7 +14,19 @@ def parse_to_datetime(timestamp: bytes, normalise: bool=True) -&gt;datetime:\n     If normalise is False, then the returned datetime will be\n     unadjusted but will contain timezone information as per the input.\n     \"\"\"\n-    pass\n+    if isinstance(timestamp, bytes):\n+        timestamp = timestamp.decode('ascii')\n+    \n+    tt = parsedate_tz(timestamp)\n+    if tt is None:\n+        raise ValueError(\"Could not parse datetime string: %r\" % timestamp)\n+\n+    tz = tt[-1]\n+    dt = datetime(*tt[:6], tzinfo=FixedOffset(tz) if tz else None)\n+\n+    if normalise:\n+        return dt.astimezone().replace(tzinfo=None)\n+    return dt\n\n\n def datetime_to_INTERNALDATE(dt: datetime) -&gt;str:\n@@ -23,7 +35,10 @@ def datetime_to_INTERNALDATE(dt: datetime) -&gt;str:\n     If timezone information is missing the current system\n     timezone is used.\n     \"\"\"\n-    pass\n+    if dt.tzinfo is None:\n+        dt = dt.astimezone()\n+    \n+    return dt.strftime(\"%d-%b-%Y %H:%M:%S %z\")\n\n\n _rfc822_dotted_time = re.compile(\n@@ -32,4 +47,6 @@ _rfc822_dotted_time = re.compile(\n\n def format_criteria_date(dt: datetime) -&gt;bytes:\n     \"\"\"Format a date or datetime instance for use in IMAP search criteria.\"\"\"\n-    pass\n+    if isinstance(dt, datetime):\n+        dt = dt.date()\n+    return dt.strftime(\"%d-%b-%Y\").encode('ascii')\ndiff --git a/imapclient/fixed_offset.py b/imapclient/fixed_offset.py\nindex b9e7df9..33e7b01 100644\n--- a/imapclient/fixed_offset.py\n+++ b/imapclient/fixed_offset.py\n@@ -23,4 +23,8 @@ class FixedOffset(datetime.tzinfo):\n         \"\"\"Return a FixedOffset instance for the current working timezone and\n         DST conditions.\n         \"\"\"\n-        pass\n+        if time.daylight:\n+            offset = time.altzone\n+        else:\n+            offset = time.timezone\n+        return cls(-offset // 60)\ndiff --git a/imapclient/imap_utf7.py b/imapclient/imap_utf7.py\nindex 7a795b2..a2876fc 100644\n--- a/imapclient/imap_utf7.py\n+++ b/imapclient/imap_utf7.py\n@@ -1,4 +1,5 @@\n import binascii\n+import base64\n from typing import List, Union\n\n\n@@ -8,7 +9,27 @@ def encode(s: Union[str, bytes]) -&gt;bytes:\n     Input is unicode; output is bytes (Python 3) or str (Python 2). If\n     non-unicode input is provided, the input is returned unchanged.\n     \"\"\"\n-    pass\n+    if isinstance(s, bytes):\n+        return s\n+    if not isinstance(s, str):\n+        raise ValueError(\"Input must be str or bytes\")\n+    \n+    result = bytearray()\n+    utf7_buffer = bytearray()\n+    \n+    for char in s:\n+        if ord(char) in range(0x20, 0x7f) and char != '&amp;':\n+            if utf7_buffer:\n+                result.extend(b'&amp;' + base64.b64encode(utf7_buffer).rstrip(b'=').replace(b'/', b',') + b'-')\n+                utf7_buffer = bytearray()\n+            result.extend(char.encode('ascii'))\n+        else:\n+            utf7_buffer.extend(char.encode('utf-16be'))\n+    \n+    if utf7_buffer:\n+        result.extend(b'&amp;' + base64.b64encode(utf7_buffer).rstrip(b'=').replace(b'/', b',') + b'-')\n+    \n+    return bytes(result)\n\n\n AMPERSAND_ORD = ord('&amp;')\n@@ -22,4 +43,33 @@ def decode(s: Union[bytes, str]) -&gt;str:\n     unicode. If non-bytes/str input is provided, the input is returned\n     unchanged.\n     \"\"\"\n-    pass\n+    if isinstance(s, str):\n+        s = s.encode('ascii')\n+    if not isinstance(s, bytes):\n+        raise ValueError(\"Input must be str or bytes\")\n+    \n+    result = []\n+    utf7_buffer = bytearray()\n+    in_utf7 = False\n+    \n+    for byte in s:\n+        if in_utf7:\n+            if byte == DASH_ORD:\n+                if utf7_buffer:\n+                    utf16_bytes = base64.b64decode(utf7_buffer.replace(b',', b'/') + b'===')\n+                    result.append(utf16_bytes.decode('utf-16be'))\n+                in_utf7 = False\n+                utf7_buffer = bytearray()\n+            elif byte in (AMPERSAND_ORD, DASH_ORD):\n+                utf7_buffer.append(byte)\n+            else:\n+                utf7_buffer.append(byte)\n+        elif byte == AMPERSAND_ORD:\n+            in_utf7 = True\n+        else:\n+            result.append(chr(byte))\n+    \n+    if in_utf7:\n+        raise ValueError(\"Invalid IMAP UTF-7 encoding\")\n+    \n+    return ''.join(result)\ndiff --git a/imapclient/imapclient.py b/imapclient/imapclient.py\nindex 1b399f1..c2fd28c 100644\n--- a/imapclient/imapclient.py\n+++ b/imapclient/imapclient.py\n@@ -239,7 +239,7 @@ class IMAPClient:\n            This includes reading from and writing to the socket,\n            as they are likely to break internal bookkeeping of messages.\n         \"\"\"\n-        pass\n+        return self._imap.sock\n\n     @require_capability('STARTTLS')\n     def starttls(self, ssl_context=None):\n@@ -259,13 +259,34 @@ class IMAPClient:\n         Raises :py:exc:`AbortError` if the server does not support STARTTLS\n         or an SSL connection is already established.\n         \"\"\"\n-        pass\n+        if self._starttls_done:\n+            raise self.AbortError('STARTTLS has already been called')\n+        \n+        if ssl_context is None:\n+            ssl_context = ssl_lib.create_default_context()\n+        \n+        typ, data = self._imap._simple_command('STARTTLS')\n+        self._checkok('starttls', typ, data)\n+        \n+        self._imap.sock = ssl_context.wrap_socket(self._imap.sock,\n+                                                  server_hostname=self.host)\n+        self._imap.file = self._imap.sock.makefile('rb')\n+        self._starttls_done = True\n+        \n+        # Reissue CAPABILITY command after STARTTLS\n+        self._cached_capabilities = None\n+        self.capabilities()\n\n     def login(self, username: str, password: str):\n         \"\"\"Login using *username* and *password*, returning the\n         server response.\n         \"\"\"\n-        pass\n+        try:\n+            typ, data = self._imap.login(username, password)\n+            self._checkok('login', typ, data)\n+            return data[0].decode()\n+        except imaplib.IMAP4.error as e:\n+            raise self.Error(f'Login failed: {str(e)}')\n\n     def oauth2_login(self, user: str, access_token: str, mech: str=\n         'XOAUTH2', vendor: Optional[str]=None):\n@@ -274,7 +295,17 @@ class IMAPClient:\n         Gmail and Yahoo both support the 'XOAUTH2' mechanism, but Yahoo requires\n         the 'vendor' portion in the payload.\n         \"\"\"\n-        pass\n+        auth_string = f'user={user}\\1auth=Bearer {access_token}\\1'\n+        if vendor:\n+            auth_string += f'\\1vendor={vendor}'\n+        auth_string += '\\1\\1'\n+\n+        try:\n+            typ, data = self._imap.authenticate(mech, lambda x: auth_string)\n+            self._checkok('oauth2_login', typ, data)\n+            return data[0].decode()\n+        except imaplib.IMAP4.error as e:\n+            raise self.Error(f'OAuth2 login failed: {str(e)}')\n\n     def oauthbearer_login(self, identity, access_token):\n         \"\"\"Authenticate using the OAUTHBEARER method.\ndiff --git a/imapclient/response_parser.py b/imapclient/response_parser.py\nindex f632411..e8b489d 100644\n--- a/imapclient/response_parser.py\n+++ b/imapclient/response_parser.py\n@@ -22,7 +22,19 @@ def parse_response(data: List[bytes]) -&gt;Tuple[_Atom, ...]:\n\n     Returns nested tuples of appropriately typed objects.\n     \"\"\"\n-    pass\n+    lexer = TokenSource(data)\n+    return tuple(_parse_tokens(lexer))\n+\n+def _parse_tokens(lexer: TokenSource) -&gt;Iterator[_Atom]:\n+    for token in lexer:\n+        if token == b'(':\n+            yield tuple(_parse_tokens(lexer))\n+        elif token == b')':\n+            return\n+        elif isinstance(token, bytes):\n+            yield token.decode('ascii')\n+        else:\n+            yield token\n\n\n _msg_id_pattern = re.compile('(\\\\d+(?: +\\\\d+)*)')\n@@ -39,7 +51,17 @@ def parse_message_list(data: List[Union[bytes, str]]) -&gt;SearchIds:\n     attribute which contains the MODSEQ response (if returned by the\n     server).\n     \"\"\"\n-    pass\n+    data = [item.decode('ascii') if isinstance(item, bytes) else item for item in data]\n+    data = ' '.join(data)\n+    \n+    modseq = None\n+    if 'MODSEQ' in data:\n+        modseq_index = data.index('MODSEQ')\n+        modseq = int(data[modseq_index + 1])\n+        data = data[:modseq_index]\n+    \n+    ids = [int(num) for num in _msg_id_pattern.findall(data)]\n+    return SearchIds(ids, modseq)\n\n\n _ParseFetchResponseInnerDict = Dict[bytes, Optional[Union[datetime.datetime,\n@@ -53,4 +75,62 @@ def parse_fetch_response(text: List[bytes], normalise_times: bool=True,\n     Returns a dictionary, keyed by message ID. Each value a dictionary\n     keyed by FETCH field type (eg.\"RFC822\").\n     \"\"\"\n-    pass\n+    response = defaultdict(dict)\n+    lexer = TokenSource(text)\n+\n+    while True:\n+        try:\n+            msg_id = int(next(lexer))\n+        except StopIteration:\n+            break\n+\n+        if next(lexer) != b'(':\n+            raise ProtocolError('Expected \"(\" in FETCH response')\n+\n+        for key, value in _parse_fetch_pairs(lexer, normalise_times):\n+            if uid_is_key and key == b'UID':\n+                msg_id = value\n+            else:\n+                response[msg_id][key] = value\n+\n+        if next(lexer) != b')':\n+            raise ProtocolError('Expected \")\" in FETCH response')\n+\n+    return response\n+\n+def _parse_fetch_pairs(lexer: TokenSource, normalise_times: bool) -&gt;Iterator[Tuple[bytes, Union[datetime.datetime, int, BodyData, Envelope, _Atom]]]:\n+    while True:\n+        try:\n+            key = next(lexer)\n+        except StopIteration:\n+            return\n+\n+        if key == b')':\n+            lexer.push(key)\n+            return\n+\n+        value = _parse_fetch_value(lexer, key, normalise_times)\n+        yield key, value\n+\n+def _parse_fetch_value(lexer: TokenSource, key: bytes, normalise_times: bool) -&gt;Union[datetime.datetime, int, BodyData, Envelope, _Atom]:\n+    if key in (b'INTERNALDATE', b'ENVELOPE'):\n+        value = next(lexer)\n+        if key == b'INTERNALDATE' and normalise_times:\n+            return parse_to_datetime(value.decode('ascii'))\n+        elif key == b'ENVELOPE':\n+            return Envelope(*parse_response(value))\n+    elif key == b'BODY' and next(lexer) == b'[':\n+        section = b''\n+        while True:\n+            token = next(lexer)\n+            if token == b']':\n+                break\n+            section += token\n+        next(lexer)  # Consume the space\n+        value = next(lexer)\n+        return BodyData(section, value)\n+    else:\n+        value = next(lexer)\n+        if isinstance(value, int):\n+            return value\n+        return value.decode('ascii')\n</code></pre>"},{"location":"analysis_baseline_jinja/","title":"Analysis baseline jinja","text":"<p>back to baseline summary</p>"},{"location":"analysis_baseline_jinja/#submission-name-baseline","title":"Submission Name: baseline","text":""},{"location":"analysis_baseline_jinja/#repository-jinja","title":"Repository: jinja","text":""},{"location":"analysis_baseline_jinja/#failed-to-run-pytests","title":"Failed to run pytests","text":"<pre><code>ImportError while loading conftest '/testbed/tests/conftest.py'.\ntests/conftest.py:5: in &lt;module&gt;\n    from jinja2 import loaders\nsrc/jinja2/__init__.py:9: in &lt;module&gt;\n    from .environment import Environment as Environment\nsrc/jinja2/environment.py:14: in &lt;module&gt;\n    from . import nodes\nsrc/jinja2/nodes.py:808: in &lt;module&gt;\n    NodeType.__new__ = staticmethod(_failing_new)\nE   NameError: name '_failing_new' is not defined\n</code></pre>"},{"location":"analysis_baseline_jinja/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/src/jinja2/bccache.py b/src/jinja2/bccache.py\nindex ae575a3..7417030 100644\n--- a/src/jinja2/bccache.py\n+++ b/src/jinja2/bccache.py\n@@ -47,23 +47,31 @@ class Bucket:\n\n     def reset(self) -&gt;None:\n         \"\"\"Resets the bucket (unloads the bytecode).\"\"\"\n-        pass\n+        self.code = None\n\n     def load_bytecode(self, f: t.BinaryIO) -&gt;None:\n         \"\"\"Loads bytecode from a file or file like object.\"\"\"\n-        pass\n+        code = marshal.load(f)\n+        if isinstance(code, CodeType):\n+            self.code = code\n\n     def write_bytecode(self, f: t.IO[bytes]) -&gt;None:\n         \"\"\"Dump the bytecode into the file or file like object passed.\"\"\"\n-        pass\n+        if self.code is not None:\n+            marshal.dump(self.code, f)\n\n     def bytecode_from_string(self, string: bytes) -&gt;None:\n         \"\"\"Load bytecode from bytes.\"\"\"\n-        pass\n+        f = BytesIO(string)\n+        self.load_bytecode(f)\n\n     def bytecode_to_string(self) -&gt;bytes:\n         \"\"\"Return the bytecode as bytes.\"\"\"\n-        pass\n+        if self.code is None:\n+            return b\"\"\n+        f = BytesIO()\n+        self.write_bytecode(f)\n+        return f.getvalue()\n\n\n class BytecodeCache:\n@@ -100,41 +108,43 @@ class BytecodeCache:\n         bucket.  If they are not able to find code in the cache for the\n         bucket, it must not do anything.\n         \"\"\"\n-        pass\n+        raise NotImplementedError()\n\n     def dump_bytecode(self, bucket: Bucket) -&gt;None:\n         \"\"\"Subclasses have to override this method to write the bytecode\n         from a bucket back to the cache.  If it unable to do so it must not\n         fail silently but raise an exception.\n         \"\"\"\n-        pass\n+        raise NotImplementedError()\n\n     def clear(self) -&gt;None:\n         \"\"\"Clears the cache.  This method is not used by Jinja but should be\n         implemented to allow applications to clear the bytecode cache used\n         by a particular environment.\n         \"\"\"\n-        pass\n+        raise NotImplementedError()\n\n     def get_cache_key(self, name: str, filename: t.Optional[t.Union[str]]=None\n         ) -&gt;str:\n         \"\"\"Returns the unique hash key for this template name.\"\"\"\n-        pass\n+        return sha1(f\"{name}|{filename}\".encode(\"utf-8\")).hexdigest()\n\n     def get_source_checksum(self, source: str) -&gt;str:\n         \"\"\"Returns a checksum for the source.\"\"\"\n-        pass\n+        return sha1(source.encode(\"utf-8\")).hexdigest()\n\n     def get_bucket(self, environment: 'Environment', name: str, filename: t\n         .Optional[str], source: str) -&gt;Bucket:\n         \"\"\"Return a cache bucket for the given template.  All arguments are\n         mandatory but filename may be `None`.\n         \"\"\"\n-        pass\n+        key = self.get_cache_key(name, filename)\n+        checksum = self.get_source_checksum(source)\n+        return Bucket(environment, key, checksum)\n\n     def set_bucket(self, bucket: Bucket) -&gt;None:\n         \"\"\"Put the bucket into the cache.\"\"\"\n-        pass\n+        self.dump_bytecode(bucket)\n\n\n class FileSystemBytecodeCache(BytecodeCache):\n@@ -162,6 +172,38 @@ class FileSystemBytecodeCache(BytecodeCache):\n         self.directory = directory\n         self.pattern = pattern\n\n+    def _get_default_cache_dir(self) -&gt;str:\n+        if sys.platform == 'win32':\n+            return os.path.join(tempfile.gettempdir(), 'jinja2_cache')\n+        else:\n+            return os.path.join(tempfile.gettempdir(), f'jinja2_cache_{os.getuid()}')\n+\n+    def _get_cache_filename(self, bucket: Bucket) -&gt;str:\n+        return os.path.join(self.directory, self.pattern % bucket.key)\n+\n+    def load_bytecode(self, bucket: Bucket) -&gt;None:\n+        filename = self._get_cache_filename(bucket)\n+        if os.path.exists(filename):\n+            with open(filename, 'rb') as f:\n+                bucket.load_bytecode(f)\n+\n+    def dump_bytecode(self, bucket: Bucket) -&gt;None:\n+        filename = self._get_cache_filename(bucket)\n+        try:\n+            os.makedirs(os.path.dirname(filename), exist_ok=True)\n+            with open(filename, 'wb') as f:\n+                bucket.write_bytecode(f)\n+        except OSError as e:\n+            raise OSError(f'Unable to write bytecode cache file: {e}')\n+\n+    def clear(self) -&gt;None:\n+        for filename in os.listdir(self.directory):\n+            if fnmatch.fnmatch(filename, self.pattern % '*'):\n+                try:\n+                    os.remove(os.path.join(self.directory, filename))\n+                except OSError:\n+                    pass\n+\n\n class MemcachedBytecodeCache(BytecodeCache):\n     \"\"\"This class implements a bytecode cache that uses a memcache cache for\n@@ -215,3 +257,26 @@ class MemcachedBytecodeCache(BytecodeCache):\n         self.prefix = prefix\n         self.timeout = timeout\n         self.ignore_memcache_errors = ignore_memcache_errors\n+\n+    def load_bytecode(self, bucket: Bucket) -&gt;None:\n+        try:\n+            code = self.client.get(self.prefix + bucket.key)\n+            if code is not None:\n+                bucket.bytecode_from_string(code)\n+        except Exception:\n+            if not self.ignore_memcache_errors:\n+                raise\n+\n+    def dump_bytecode(self, bucket: Bucket) -&gt;None:\n+        try:\n+            args = [self.prefix + bucket.key, bucket.bytecode_to_string()]\n+            if self.timeout is not None:\n+                args.append(self.timeout)\n+            self.client.set(*args)\n+        except Exception:\n+            if not self.ignore_memcache_errors:\n+                raise\n+\n+    def clear(self) -&gt;None:\n+        # Memcached doesn't support clearing specific keys, so this is a no-op\n+        pass\ndiff --git a/src/jinja2/compiler.py b/src/jinja2/compiler.py\nindex 32df45a..307559e 100644\n--- a/src/jinja2/compiler.py\n+++ b/src/jinja2/compiler.py\n@@ -31,12 +31,16 @@ def generate(node: nodes.Template, environment: 'Environment', name: t.\n     Optional[str], filename: t.Optional[str], stream: t.Optional[t.TextIO]=\n     None, defer_init: bool=False, optimized: bool=True) -&gt;t.Optional[str]:\n     \"\"\"Generate the python source for a node tree.\"\"\"\n-    pass\n+    codegen = CodeGenerator(environment, name, filename, stream, defer_init, optimized)\n+    codegen.visit(node)\n+    if stream is None:\n+        return codegen.stream.getvalue()\n+    return None\n\n\n def has_safe_repr(value: t.Any) -&gt;bool:\n     \"\"\"Does the node have a safe representation?\"\"\"\n-    pass\n+    return isinstance(value, (bool, int, float, str, tuple, frozenset))\n\n\n def find_undeclared(nodes: t.Iterable[nodes.Node], names: t.Iterable[str]\n@@ -44,7 +48,13 @@ def find_undeclared(nodes: t.Iterable[nodes.Node], names: t.Iterable[str]\n     \"\"\"Check if the names passed are accessed undeclared.  The return value\n     is a set of all the undeclared names from the sequence of names found.\n     \"\"\"\n-    pass\n+    visitor = UndeclaredNameVisitor(names)\n+    try:\n+        for node in nodes:\n+            visitor.visit(node)\n+    except VisitorExit:\n+        pass\n+    return visitor.undeclared\n\n\n class MacroRef:\n@@ -81,11 +91,21 @@ class Frame:\n\n     def copy(self) -&gt;'Frame':\n         \"\"\"Create a copy of the current one.\"\"\"\n-        pass\n+        rv = object.__new__(self.__class__)\n+        rv.__dict__.update(self.__dict__)\n+        rv.symbols = self.symbols.copy()\n+        return rv\n\n     def inner(self, isolated: bool=False) -&gt;'Frame':\n         \"\"\"Return an inner frame.\"\"\"\n-        pass\n+        rv = self.copy()\n+        if isolated:\n+            rv.symbols = Symbols(parent=rv.symbols)\n+        rv.block_frame = False\n+        rv.loop_frame = False\n+        rv.toplevel = False\n+        rv.rootlevel = False\n+        return rv\n\n     def soft(self) -&gt;'Frame':\n         \"\"\"Return a soft frame.  A soft frame may not be modified as\n@@ -95,7 +115,13 @@ class Frame:\n         This is only used to implement if-statements and conditional\n         expressions.\n         \"\"\"\n-        pass\n+        rv = self.copy()\n+        rv.toplevel = False\n+        rv.rootlevel = False\n+        rv.loop_frame = False\n+        rv.block_frame = False\n+        rv.soft_frame = True\n+        return rv\n     __copy__ = copy\n\n\n@@ -112,8 +138,7 @@ class DependencyFinderVisitor(NodeVisitor):\n\n     def visit_Block(self, node: nodes.Block) -&gt;None:\n         \"\"\"Stop visiting at blocks.\"\"\"\n-        pass\n-\n+        return\n\n class UndeclaredNameVisitor(NodeVisitor):\n     \"\"\"A visitor that checks if a name is accessed without being\n@@ -125,9 +150,15 @@ class UndeclaredNameVisitor(NodeVisitor):\n         self.names = set(names)\n         self.undeclared: t.Set[str] = set()\n\n+    def visit_Name(self, node: nodes.Name) -&gt;None:\n+        if node.name in self.names:\n+            self.undeclared.add(node.name)\n+            if len(self.undeclared) == len(self.names):\n+                raise VisitorExit()\n+\n     def visit_Block(self, node: nodes.Block) -&gt;None:\n         \"\"\"Stop visiting a blocks.\"\"\"\n-        pass\n+        return\n\n\n class CompilerExit(Exception):\ndiff --git a/src/jinja2/debug.py b/src/jinja2/debug.py\nindex 412f2c2..6055a20 100644\n--- a/src/jinja2/debug.py\n+++ b/src/jinja2/debug.py\n@@ -20,7 +20,25 @@ def rewrite_traceback_stack(source: t.Optional[str]=None) -&gt;BaseException:\n         known.\n     :return: The original exception with the rewritten traceback.\n     \"\"\"\n-    pass\n+    exc_type, exc_value, tb = sys.exc_info()\n+    if isinstance(exc_value, TemplateSyntaxError) and source is not None:\n+        exc_value.source = source\n+    \n+    while tb is not None:\n+        if tb.tb_frame.f_code.co_filename == '&lt;template&gt;':\n+            filename = exc_value.filename\n+            lineno = exc_value.lineno\n+            \n+            # Create a fake traceback\n+            new_tb = fake_traceback(exc_value, tb, filename, lineno)\n+            \n+            # Replace the old traceback with the new one\n+            exc_value.__traceback__ = new_tb\n+            break\n+        \n+        tb = tb.tb_next\n+    \n+    return exc_value\n\n\n def fake_traceback(exc_value: BaseException, tb: t.Optional[TracebackType],\n@@ -37,7 +55,37 @@ def fake_traceback(exc_value: BaseException, tb: t.Optional[TracebackType],\n     :param filename: The template filename.\n     :param lineno: The line number in the template source.\n     \"\"\"\n-    pass\n+    if tb is None:\n+        raise exc_value\n+\n+    locals = get_template_locals(tb.tb_frame.f_locals)\n+    globals = tb.tb_frame.f_globals\n+\n+    # Create a fake code object\n+    code = CodeType(\n+        0,                      # argcount\n+        0,                      # kwonlyargcount\n+        0,                      # nlocals\n+        0,                      # stacksize\n+        0,                      # flags\n+        b'',                    # bytecode\n+        (),                     # constants\n+        (),                     # names\n+        (),                     # varnames\n+        filename,               # filename\n+        '&lt;template&gt;',           # name\n+        lineno,                 # firstlineno\n+        b'',                    # lnotab\n+        (),                     # freevars\n+        ()                      # cellvars\n+    )\n+\n+    # Create a fake frame\n+    fake_frame = tb.tb_frame.__class__(code, globals, locals)\n+    fake_frame.f_lineno = lineno\n+\n+    # Create a new traceback object\n+    return TracebackType(None, fake_frame, fake_frame.f_lasti, fake_frame.f_lineno)\n\n\n def get_template_locals(real_locals: t.Mapping[str, t.Any]) -&gt;t.Dict[str, t.Any\n@@ -45,4 +93,12 @@ def get_template_locals(real_locals: t.Mapping[str, t.Any]) -&gt;t.Dict[str, t.Any\n     \"\"\"Based on the runtime locals, get the context that would be\n     available at that point in the template.\n     \"\"\"\n-    pass\n+    context = real_locals.get('context')\n+    if isinstance(context, Context):\n+        return {\n+            'context': context,\n+            'environment': context.environment,\n+            'resolver': context.environment.resolver,\n+            **context.get_all()\n+        }\n+    return {}\ndiff --git a/src/jinja2/environment.py b/src/jinja2/environment.py\nindex aae9f98..f21e599 100644\n--- a/src/jinja2/environment.py\n+++ b/src/jinja2/environment.py\n@@ -68,19 +68,28 @@ def get_spontaneous_environment(cls: t.Type[_env_bound], *args: t.Any\n     :param cls: Environment class to create.\n     :param args: Positional arguments passed to environment.\n     \"\"\"\n-    pass\n+    return cls(*args)\n\n\n def create_cache(size: int) -&gt;t.Optional[t.MutableMapping[t.Tuple[\n     'weakref.ref[t.Any]', str], 'Template']]:\n     \"\"\"Return the cache class for the given size.\"\"\"\n-    pass\n+    if size == 0:\n+        return None\n+    if size &lt; 0:\n+        return {}\n+    return LRUCache(size)\n\n\n def copy_cache(cache: t.Optional[t.MutableMapping[t.Any, t.Any]]) -&gt;t.Optional[\n     t.MutableMapping[t.Tuple['weakref.ref[t.Any]', str], 'Template']]:\n     \"\"\"Create an empty copy of the given cache.\"\"\"\n-    pass\n+    if cache is None:\n+        return None\n+    elif isinstance(cache, LRUCache):\n+        return LRUCache(cache.capacity)\n+    else:\n+        return {}\n\n\n def load_extensions(environment: 'Environment', extensions: t.Sequence[t.\n@@ -88,12 +97,39 @@ def load_extensions(environment: 'Environment', extensions: t.Sequence[t.\n     \"\"\"Load the extensions from the list and bind it to the environment.\n     Returns a dict of instantiated extensions.\n     \"\"\"\n-    pass\n+    result = {}\n+    for extension in extensions:\n+        if isinstance(extension, str):\n+            extension = import_string(extension)\n+        if isinstance(extension, type):\n+            extension = extension(environment)\n+        result[extension.identifier] = extension\n+    return result\n\n\n def _environment_config_check(environment: 'Environment') -&gt;'Environment':\n     \"\"\"Perform a sanity check on the environment.\"\"\"\n-    pass\n+    if not isinstance(environment.block_start_string, str):\n+        raise TypeError('block_start_string must be a string')\n+    if not isinstance(environment.block_end_string, str):\n+        raise TypeError('block_end_string must be a string')\n+    if not isinstance(environment.variable_start_string, str):\n+        raise TypeError('variable_start_string must be a string')\n+    if not isinstance(environment.variable_end_string, str):\n+        raise TypeError('variable_end_string must be a string')\n+    if not isinstance(environment.comment_start_string, str):\n+        raise TypeError('comment_start_string must be a string')\n+    if not isinstance(environment.comment_end_string, str):\n+        raise TypeError('comment_end_string must be a string')\n+    if not isinstance(environment.line_statement_prefix, (str, type(None))):\n+        raise TypeError('line_statement_prefix must be a string or None')\n+    if not isinstance(environment.line_comment_prefix, (str, type(None))):\n+        raise TypeError('line_comment_prefix must be a string or None')\n+    if not isinstance(environment.trim_blocks, bool):\n+        raise TypeError('trim_blocks must be a boolean')\n+    if not isinstance(environment.lstrip_blocks, bool):\n+        raise TypeError('lstrip_blocks must be a boolean')\n+    return environment\n\n\n class Environment:\ndiff --git a/src/jinja2/ext.py b/src/jinja2/ext.py\nindex 337f30c..9d826ca 100644\n--- a/src/jinja2/ext.py\n+++ b/src/jinja2/ext.py\n@@ -62,7 +62,10 @@ class Extension:\n\n     def bind(self, environment: Environment) -&gt;'Extension':\n         \"\"\"Create a copy of this extension bound to another environment.\"\"\"\n-        pass\n+        rv = type(self)(environment)\n+        rv.__dict__.update(self.__dict__)\n+        rv.environment = environment\n+        return rv\n\n     def preprocess(self, source: str, name: t.Optional[str], filename: t.\n         Optional[str]=None) -&gt;str:\n@@ -70,7 +73,7 @@ class Extension:\n         preprocess the source.  The `filename` is optional.  The return value\n         must be the preprocessed source.\n         \"\"\"\n-        pass\n+        return source\n\n     def filter_stream(self, stream: 'TokenStream') -&gt;t.Union['TokenStream',\n         t.Iterable['Token']]:\n@@ -79,7 +82,7 @@ class Extension:\n         :class:`~jinja2.lexer.Token`\\\\s, but it doesn't have to return a\n         :class:`~jinja2.lexer.TokenStream`.\n         \"\"\"\n-        pass\n+        return stream\n\n     def parse(self, parser: 'Parser') -&gt;t.Union[nodes.Node, t.List[nodes.Node]\n         ]:\n@@ -88,7 +91,7 @@ class Extension:\n         is the name token that matched.  This method has to return one or a\n         list of multiple nodes.\n         \"\"\"\n-        pass\n+        raise NotImplementedError(f'{self.__class__.__name__}.parse() must be implemented')\n\n     def attr(self, name: str, lineno: t.Optional[int]=None\n         ) -&gt;nodes.ExtensionAttribute:\n@@ -99,7 +102,7 @@ class Extension:\n\n             self.attr('_my_attribute', lineno=lineno)\n         \"\"\"\n-        pass\n+        return nodes.ExtensionAttribute(self.identifier, name, lineno=lineno)\n\n     def call_method(self, name: str, args: t.Optional[t.List[nodes.Expr]]=\n         None, kwargs: t.Optional[t.List[nodes.Keyword]]=None, dyn_args: t.\n@@ -108,7 +111,12 @@ class Extension:\n         \"\"\"Call a method of the extension.  This is a shortcut for\n         :meth:`attr` + :class:`jinja2.nodes.Call`.\n         \"\"\"\n-        pass\n+        if args is None:\n+            args = []\n+        if kwargs is None:\n+            kwargs = []\n+        return nodes.Call(self.attr(name, lineno=lineno), args, kwargs,\n+                          dyn_args, dyn_kwargs, lineno=lineno)\n\n\n class InternationalizationExtension(Extension):\ndiff --git a/src/jinja2/filters.py b/src/jinja2/filters.py\nindex 9498dc3..ecd27f0 100644\n--- a/src/jinja2/filters.py\n+++ b/src/jinja2/filters.py\n@@ -43,7 +43,9 @@ V = t.TypeVar('V')\n def ignore_case(value: V) -&gt;V:\n     \"\"\"For use as a postprocessor for :func:`make_attrgetter`. Converts strings\n     to lowercase and returns other types as-is.\"\"\"\n-    pass\n+    if isinstance(value, str):\n+        return value.lower()\n+    return value\n\n\n def make_attrgetter(environment: 'Environment', attribute: t.Optional[t.\n@@ -54,7 +56,21 @@ def make_attrgetter(environment: 'Environment', attribute: t.Optional[t.\n     to access attributes of attributes.  Integer parts in paths are\n     looked up as integers.\n     \"\"\"\n-    pass\n+    if attribute is None:\n+        return lambda x: x\n+    if isinstance(attribute, int):\n+        return lambda x: environment.getitem(x, attribute)\n+    if '.' not in attribute:\n+        return lambda x: environment.getattr(x, attribute, default)\n+    \n+    def getter(x):\n+        for part in attribute.split('.'):\n+            if part.isdigit():\n+                x = environment.getitem(x, int(part))\n+            else:\n+                x = environment.getattr(x, part, default)\n+        return x if postprocess is None else postprocess(x)\n+    return getter\n\n\n def make_multi_attrgetter(environment: 'Environment', attribute: t.Optional\n@@ -70,12 +86,22 @@ def make_multi_attrgetter(environment: 'Environment', attribute: t.Optional\n\n     Examples of attribute: \"attr1,attr2\", \"attr1.inner1.0,attr2.inner2.0\", etc.\n     \"\"\"\n-    pass\n+    if attribute is None:\n+        return lambda x: [x]\n+    \n+    getters = [make_attrgetter(environment, attr.strip(), postprocess)\n+               for attr in attribute.split(',')]\n+    \n+    def getter(x):\n+        return [g(x) for g in getters]\n+    return getter\n\n\n def do_forceescape(value: 't.Union[str, HasHTML]') -&gt;Markup:\n     \"\"\"Enforce HTML escaping.  This will probably double escape variables.\"\"\"\n-    pass\n+    if hasattr(value, '__html__'):\n+        value = value.__html__()\n+    return Markup(escape(str(value)))\n\n\n def do_urlencode(value: t.Union[str, t.Mapping[str, t.Any], t.Iterable[t.\n@@ -95,7 +121,16 @@ def do_urlencode(value: t.Union[str, t.Mapping[str, t.Any], t.Iterable[t.\n\n     .. versionadded:: 2.7\n     \"\"\"\n-    pass\n+    from urllib.parse import quote, urlencode\n+\n+    if isinstance(value, str):\n+        return quote(value, safe='/')\n+    elif isinstance(value, t.Mapping):\n+        return urlencode(value)\n+    elif isinstance(value, t.Iterable):\n+        return urlencode(list(value))\n+    else:\n+        raise TypeError(\"Expected string, mapping, or iterable\")\n\n\n @pass_eval_context\ndiff --git a/src/jinja2/idtracking.py b/src/jinja2/idtracking.py\nindex a1d69ca..44d11c4 100644\n--- a/src/jinja2/idtracking.py\n+++ b/src/jinja2/idtracking.py\n@@ -45,32 +45,39 @@ class FrameSymbolVisitor(NodeVisitor):\n     def visit_Name(self, node: nodes.Name, store_as_param: bool=False, **\n         kwargs: t.Any) -&gt;None:\n         \"\"\"All assignments to names go through this function.\"\"\"\n-        pass\n+        if node.ctx == 'store':\n+            if store_as_param:\n+                self.symbols.loads[node.name] = VAR_LOAD_PARAMETER\n+            self.symbols.stores.add(node.name)\n+        elif node.ctx == 'param':\n+            self.symbols.loads[node.name] = VAR_LOAD_PARAMETER\n\n     def visit_Assign(self, node: nodes.Assign, **kwargs: t.Any) -&gt;None:\n         \"\"\"Visit assignments in the correct order.\"\"\"\n-        pass\n+        self.visit(node.node, **kwargs)\n+        self.visit(node.target, **kwargs)\n\n     def visit_For(self, node: nodes.For, **kwargs: t.Any) -&gt;None:\n         \"\"\"Visiting stops at for blocks.  However the block sequence\n         is visited as part of the outer scope.\n         \"\"\"\n-        pass\n+        self.visit(node.iter, **kwargs)\n+        self.visit(node.target, store_as_param=True, **kwargs)\n\n     def visit_AssignBlock(self, node: nodes.AssignBlock, **kwargs: t.Any\n         ) -&gt;None:\n         \"\"\"Stop visiting at block assigns.\"\"\"\n-        pass\n+        self.visit(node.target, **kwargs)\n\n     def visit_Scope(self, node: nodes.Scope, **kwargs: t.Any) -&gt;None:\n         \"\"\"Stop visiting at scopes.\"\"\"\n-        pass\n+        # We don't need to do anything here, as we're stopping at scopes\n\n     def visit_Block(self, node: nodes.Block, **kwargs: t.Any) -&gt;None:\n         \"\"\"Stop visiting at blocks.\"\"\"\n-        pass\n+        # We don't need to do anything here, as we're stopping at blocks\n\n     def visit_OverlayScope(self, node: nodes.OverlayScope, **kwargs: t.Any\n         ) -&gt;None:\n         \"\"\"Do not visit into overlay scopes.\"\"\"\n-        pass\n+        # We don't need to do anything here, as we're not visiting into overlay scopes\ndiff --git a/src/jinja2/lexer.py b/src/jinja2/lexer.py\nindex 2281b7e..e825327 100644\n--- a/src/jinja2/lexer.py\n+++ b/src/jinja2/lexer.py\n@@ -117,24 +117,39 @@ ignore_if_empty = frozenset([TOKEN_WHITESPACE, TOKEN_DATA, TOKEN_COMMENT,\n\n def describe_token(token: 'Token') -&gt;str:\n     \"\"\"Returns a description of the token.\"\"\"\n-    pass\n+    if token.type == 'name':\n+        return token.value\n+    return f'{token.type}'\n\n\n def describe_token_expr(expr: str) -&gt;str:\n     \"\"\"Like `describe_token` but for token expressions.\"\"\"\n-    pass\n+    if ':' in expr:\n+        type, value = expr.split(':', 1)\n+        if type == 'name':\n+            return value\n+        return f'{type}({value})'\n+    return expr\n\n\n def count_newlines(value: str) -&gt;int:\n     \"\"\"Count the number of newline characters in the string.  This is\n     useful for extensions that filter a stream.\n     \"\"\"\n-    pass\n+    return len(newline_re.findall(value))\n\n\n def compile_rules(environment: 'Environment') -&gt;t.List[t.Tuple[str, str]]:\n     \"\"\"Compiles all the rules from the environment into a list of rules.\"\"\"\n-    pass\n+    e = re.escape\n+    rules = [\n+        ('comment', e(environment.comment_start_string)),\n+        ('block', e(environment.block_start_string)),\n+        ('variable', e(environment.variable_start_string)),\n+        ('linestatement', e(environment.line_statement_prefix) if environment.line_statement_prefix else ''),\n+        ('linecomment', e(environment.line_comment_prefix) if environment.line_comment_prefix else ''),\n+    ]\n+    return [(k, v) for k, v in rules if v]\n\n\n class Failure:\n@@ -164,11 +179,14 @@ class Token(t.NamedTuple):\n         token type or ``'token_type:token_value'``.  This can only test\n         against string values and types.\n         \"\"\"\n-        pass\n+        if ':' in expr:\n+            type, value = expr.split(':', 1)\n+            return self.type == type and self.value == value\n+        return self.type == expr\n\n     def test_any(self, *iterable: str) -&gt;bool:\n         \"\"\"Test against multiple token expressions.\"\"\"\n-        pass\n+        return any(self.test(expr) for expr in iterable)\n\n\n class TokenStreamIterator:\n@@ -216,29 +234,35 @@ class TokenStream:\n     @property\n     def eos(self) -&gt;bool:\n         \"\"\"Are we at the end of the stream?\"\"\"\n-        pass\n+        return not bool(self)\n\n     def push(self, token: Token) -&gt;None:\n         \"\"\"Push a token back to the stream.\"\"\"\n-        pass\n+        self._pushed.append(token)\n\n     def look(self) -&gt;Token:\n         \"\"\"Look at the next token.\"\"\"\n-        pass\n+        old_token = next(self)\n+        result = self.current\n+        self.push(old_token)\n+        return result\n\n     def skip(self, n: int=1) -&gt;None:\n         \"\"\"Got n tokens ahead.\"\"\"\n-        pass\n+        for _ in range(n):\n+            next(self)\n\n     def next_if(self, expr: str) -&gt;t.Optional[Token]:\n         \"\"\"Perform the token test and return the token if it matched.\n         Otherwise the return value is `None`.\n         \"\"\"\n-        pass\n+        if self.current.test(expr):\n+            return next(self)\n+        return None\n\n     def skip_if(self, expr: str) -&gt;bool:\n         \"\"\"Like :meth:`next_if` but only returns `True` or `False`.\"\"\"\n-        pass\n+        return self.next_if(expr) is not None\n\n     def __next__(self) -&gt;Token:\n         \"\"\"Go one token ahead and return the old one.\n@@ -257,18 +281,46 @@ class TokenStream:\n\n     def close(self) -&gt;None:\n         \"\"\"Close the stream.\"\"\"\n-        pass\n+        self.closed = True\n\n     def expect(self, expr: str) -&gt;Token:\n         \"\"\"Expect a given token type and return it.  This accepts the same\n         argument as :meth:`jinja2.lexer.Token.test`.\n         \"\"\"\n-        pass\n+        if not self.current.test(expr):\n+            if ':' in expr:\n+                expr = f'{expr.split(\":\", 1)[0]} token'\n+            raise TemplateSyntaxError(\n+                f'expected {expr}', self.current.lineno,\n+                self.name, self.filename\n+            )\n+        try:\n+            return next(self)\n+        except StopIteration:\n+            raise TemplateSyntaxError('unexpected end of template',\n+                                      self.current.lineno, self.name, self.filename)\n\n\n def get_lexer(environment: 'Environment') -&gt;'Lexer':\n     \"\"\"Return a lexer which is probably cached.\"\"\"\n-    pass\n+    key = (environment.block_start_string,\n+           environment.block_end_string,\n+           environment.variable_start_string,\n+           environment.variable_end_string,\n+           environment.comment_start_string,\n+           environment.comment_end_string,\n+           environment.line_statement_prefix,\n+           environment.line_comment_prefix,\n+           environment.trim_blocks,\n+           environment.lstrip_blocks,\n+           environment.newline_sequence,\n+           environment.keep_trailing_newline)\n+\n+    if key in _lexer_cache:\n+        return _lexer_cache[key]\n+    lexer = Lexer(environment)\n+    _lexer_cache[key] = lexer\n+    return lexer\n\n\n class OptionalLStrip(tuple):\n@@ -344,12 +396,13 @@ class Lexer:\n         \"\"\"Replace all newlines with the configured sequence in strings\n         and template data.\n         \"\"\"\n-        pass\n+        return newline_re.sub(self.newline_sequence, value)\n\n     def tokenize(self, source: str, name: t.Optional[str]=None, filename: t\n         .Optional[str]=None, state: t.Optional[str]=None) -&gt;TokenStream:\n         \"\"\"Calls tokeniter + tokenize and wraps it in a token stream.\"\"\"\n-        pass\n+        stream = self.tokeniter(source, name, filename, state)\n+        return TokenStream(self.wrap(stream, name, filename), name, filename)\n\n     def wrap(self, stream: t.Iterable[t.Tuple[int, str, str]], name: t.\n         Optional[str]=None, filename: t.Optional[str]=None) -&gt;t.Iterator[Token\n@@ -357,7 +410,12 @@ class Lexer:\n         \"\"\"This is called with the stream as returned by `tokenize` and wraps\n         every token in a :class:`Token` and converts the value.\n         \"\"\"\n-        pass\n+        for lineno, token, value in stream:\n+            if token in ('linestatement_begin', 'linestatement_end'):\n+                token = 'block_begin' if token == 'linestatement_begin' else 'block_end'\n+            elif token in ('linecomment_begin', 'linecomment_end', 'linecomment'):\n+                token = 'comment'\n+            yield Token(lineno, token, value)\n\n     def tokeniter(self, source: str, name: t.Optional[str], filename: t.\n         Optional[str]=None, state: t.Optional[str]=None) -&gt;t.Iterator[t.\n@@ -369,4 +427,48 @@ class Lexer:\n             Only ``\\\\n``, ``\\\\r\\\\n`` and ``\\\\r`` are treated as line\n             breaks.\n         \"\"\"\n-        pass\n+        source = self._normalize_newlines(source)\n+        lines = source.splitlines(True)\n+        lineno = 1\n+        state = state or 'root'\n+        state_stack = [state]\n+        line = ''\n+        pos = 0\n+        len_lines = len(lines)\n+\n+        while 1:\n+            # tokenizer loop\n+            for rule in self.rules[state]:\n+                m = rule.pattern.match(line, pos)\n+                if m:\n+                    if isinstance(rule.tokens, tuple):\n+                        for idx, token in enumerate(rule.tokens):\n+                            yield lineno, token, m.group(idx + 1)\n+                    else:\n+                        yield lineno, rule.tokens, m.group()\n+                    pos = m.end()\n+                    if rule.command is not None:\n+                        cmd = rule.command\n+                        if cmd == '#pop':\n+                            state_stack.pop()\n+                            if not state_stack:\n+                                state_stack.append('root')\n+                        elif cmd == '#push':\n+                            state_stack.append(state)\n+                        else:\n+                            state_stack.append(cmd)\n+                        state = state_stack[-1]\n+                    break\n+            else:\n+                # if loop exhausted, move to next line\n+                pos = 0\n+                lineno += 1\n+                if lineno &gt; len_lines:\n+                    break\n+                line = lines[lineno - 1]\n+\n+        if state != 'root':\n+            raise TemplateSyntaxError('Unexpected end of template',\n+                                      lineno, name, filename)\n+\n+        yield lineno, 'eof', ''\ndiff --git a/src/jinja2/meta.py b/src/jinja2/meta.py\nindex 37016c7..2beb63e 100644\n--- a/src/jinja2/meta.py\n+++ b/src/jinja2/meta.py\n@@ -22,7 +22,7 @@ class TrackingCodeGenerator(CodeGenerator):\n\n     def enter_frame(self, frame: Frame) -&gt;None:\n         \"\"\"Remember all undeclared identifiers.\"\"\"\n-        pass\n+        self.undeclared_identifiers.update(frame.identifiers.undeclared)\n\n\n def find_undeclared_variables(ast: nodes.Template) -&gt;t.Set[str]:\n@@ -44,7 +44,9 @@ def find_undeclared_variables(ast: nodes.Template) -&gt;t.Set[str]:\n        :exc:`TemplateAssertionError` during compilation and as a matter of\n        fact this function can currently raise that exception as well.\n     \"\"\"\n-    pass\n+    codegen = TrackingCodeGenerator(ast.environment)\n+    codegen.visit(ast)\n+    return codegen.undeclared_identifiers\n\n\n _ref_types = nodes.Extends, nodes.FromImport, nodes.Import, nodes.Include\n@@ -68,4 +70,17 @@ def find_referenced_templates(ast: nodes.Template) -&gt;t.Iterator[t.Optional[str]\n     This function is useful for dependency tracking.  For example if you want\n     to rebuild parts of the website after a layout template has changed.\n     \"\"\"\n-    pass\n+    for node in ast.find_all(_ref_types):\n+        if isinstance(node, nodes.Extends):\n+            if isinstance(node.template, nodes.Const):\n+                yield node.template.value\n+            else:\n+                yield None\n+        elif isinstance(node, nodes.Include):\n+            if isinstance(node.template, nodes.Const):\n+                yield node.template.value\n+            else:\n+                yield None\n+        elif isinstance(node, (nodes.Import, nodes.FromImport)):\n+            if isinstance(node.template, nodes.Const):\n+                yield node.template.value\ndiff --git a/src/jinja2/nativetypes.py b/src/jinja2/nativetypes.py\nindex 9eae726..da64b12 100644\n--- a/src/jinja2/nativetypes.py\n+++ b/src/jinja2/nativetypes.py\n@@ -1,4 +1,5 @@\n import typing as t\n+import sys\n from ast import literal_eval\n from ast import parse\n from itertools import chain\n@@ -21,7 +22,16 @@ def native_concat(values: t.Iterable[t.Any]) -&gt;t.Optional[t.Any]:\n\n     :param values: Iterable of outputs to concatenate.\n     \"\"\"\n-    pass\n+    result = list(values)\n+    if not result:\n+        return None\n+    if len(result) == 1:\n+        return result[0]\n+    \n+    try:\n+        return literal_eval(\"\".join(str(v) for v in result))\n+    except (ValueError, SyntaxError):\n+        return \"\".join(str(v) for v in result)\n\n\n class NativeCodeGenerator(CodeGenerator):\n@@ -46,7 +56,12 @@ class NativeTemplate(Template):\n         with :func:`ast.literal_eval`, the parsed value is returned.\n         Otherwise, the string is returned.\n         \"\"\"\n-        pass\n+        ctx = self.new_context(dict(*args, **kwargs))\n+        try:\n+            return self.environment.concat(self.root_render_func(ctx))\n+        except Exception:\n+            exc_info = sys.exc_info()\n+            return self.environment.handle_exception(exc_info, True)\n\n\n NativeEnvironment.template_class = NativeTemplate\ndiff --git a/src/jinja2/nodes.py b/src/jinja2/nodes.py\nindex 4ec1d17..416aa80 100644\n--- a/src/jinja2/nodes.py\n+++ b/src/jinja2/nodes.py\n@@ -107,7 +107,9 @@ class Node(metaclass=NodeType):\n         parameter or to exclude some using the `exclude` parameter.  Both\n         should be sets or tuples of field names.\n         \"\"\"\n-        pass\n+        for name in self.fields:\n+            if (exclude is None or name not in exclude) and (only is None or name in only):\n+                yield name, getattr(self, name)\n\n     def iter_child_nodes(self, exclude: t.Optional[t.Container[str]]=None,\n         only: t.Optional[t.Container[str]]=None) -&gt;t.Iterator['Node']:\n@@ -115,20 +117,35 @@ class Node(metaclass=NodeType):\n         over all fields and yields the values of they are nodes.  If the value\n         of a field is a list all the nodes in that list are returned.\n         \"\"\"\n-        pass\n+        for _, field in self.iter_fields(exclude, only):\n+            if isinstance(field, Node):\n+                yield field\n+            elif isinstance(field, list):\n+                for item in field:\n+                    if isinstance(item, Node):\n+                        yield item\n\n     def find(self, node_type: t.Type[_NodeBound]) -&gt;t.Optional[_NodeBound]:\n         \"\"\"Find the first node of a given type.  If no such node exists the\n         return value is `None`.\n         \"\"\"\n-        pass\n+        for child in self.iter_child_nodes():\n+            if isinstance(child, node_type):\n+                return child\n+            result = child.find(node_type)\n+            if result is not None:\n+                return result\n+        return None\n\n     def find_all(self, node_type: t.Union[t.Type[_NodeBound], t.Tuple[t.\n         Type[_NodeBound], ...]]) -&gt;t.Iterator[_NodeBound]:\n         \"\"\"Find all the nodes of a given type.  If the type is a tuple,\n         the check is performed for any of the tuple items.\n         \"\"\"\n-        pass\n+        for child in self.iter_child_nodes():\n+            if isinstance(child, node_type):\n+                yield child\n+            yield from child.find_all(node_type)\n\n     def set_ctx(self, ctx: str) -&gt;'Node':\n         \"\"\"Reset the context of a node and all child nodes.  Per default the\n@@ -136,15 +153,26 @@ class Node(metaclass=NodeType):\n         most common one.  This method is used in the parser to set assignment\n         targets and other nodes to a store context.\n         \"\"\"\n-        pass\n+        if 'ctx' in self.fields:\n+            self.ctx = ctx\n+        for child in self.iter_child_nodes():\n+            child.set_ctx(ctx)\n+        return self\n\n     def set_lineno(self, lineno: int, override: bool=False) -&gt;'Node':\n         \"\"\"Set the line numbers of the node and children.\"\"\"\n-        pass\n+        if not hasattr(self, 'lineno') or override:\n+            self.lineno = lineno\n+        for child in self.iter_child_nodes():\n+            child.set_lineno(lineno, override)\n+        return self\n\n     def set_environment(self, environment: 'Environment') -&gt;'Node':\n         \"\"\"Set the environment for all nodes.\"\"\"\n-        pass\n+        self.environment = environment\n+        for child in self.iter_child_nodes():\n+            child.set_environment(environment)\n+        return self\n\n     def __eq__(self, other: t.Any) -&gt;bool:\n         if type(self) is not type(other):\n@@ -340,11 +368,11 @@ class Expr(Node):\n         .. versionchanged:: 2.4\n            the `eval_ctx` parameter was added.\n         \"\"\"\n-        pass\n+        raise Impossible()\n\n     def can_assign(self) -&gt;bool:\n         \"\"\"Check if it's possible to assign something to this node.\"\"\"\n-        pass\n+        return False\n\n\n class BinExpr(Expr):\n@@ -405,7 +433,17 @@ class Const(Literal):\n         constant value in the generated code, otherwise it will raise\n         an `Impossible` exception.\n         \"\"\"\n-        pass\n+        if isinstance(value, (bool, int, float, str, type(None))):\n+            return cls(value, lineno=lineno, environment=environment)\n+        elif isinstance(value, (list, tuple)):\n+            items = [cls.from_untrusted(item, lineno, environment) for item in value]\n+            return cls(type(value)(item.value for item in items), lineno=lineno, environment=environment)\n+        elif isinstance(value, dict):\n+            items = {cls.from_untrusted(k, lineno, environment).value: \n+                     cls.from_untrusted(v, lineno, environment).value \n+                     for k, v in value.items()}\n+            return cls(items, lineno=lineno, environment=environment)\n+        raise Impossible(f\"Cannot convert {type(value)} to Const\")\n\n\n class TemplateData(Literal):\ndiff --git a/src/jinja2/optimizer.py b/src/jinja2/optimizer.py\nindex 53d50e4..3136cb0 100644\n--- a/src/jinja2/optimizer.py\n+++ b/src/jinja2/optimizer.py\n@@ -17,10 +17,68 @@ if t.TYPE_CHECKING:\n def optimize(node: nodes.Node, environment: 'Environment') -&gt;nodes.Node:\n     \"\"\"The context hint can be used to perform an static optimization\n     based on the context given.\"\"\"\n-    pass\n+    optimizer = Optimizer(environment)\n+    return optimizer.visit(node)\n\n\n class Optimizer(NodeTransformer):\n\n     def __init__(self, environment: 't.Optional[Environment]') -&gt;None:\n         self.environment = environment\n+\n+    def visit_Const(self, node: nodes.Const) -&gt;nodes.Node:\n+        \"\"\"Optimize constant nodes.\"\"\"\n+        return node\n+\n+    def visit_List(self, node: nodes.List) -&gt;nodes.Node:\n+        \"\"\"Optimize list nodes.\"\"\"\n+        node.items = [self.visit(item) for item in node.items]\n+        return node\n+\n+    def visit_Dict(self, node: nodes.Dict) -&gt;nodes.Node:\n+        \"\"\"Optimize dict nodes.\"\"\"\n+        node.items = [(self.visit(key), self.visit(value)) for key, value in node.items]\n+        return node\n+\n+    def visit_Getitem(self, node: nodes.Getitem) -&gt;nodes.Node:\n+        \"\"\"Optimize getitem nodes.\"\"\"\n+        node.node = self.visit(node.node)\n+        node.arg = self.visit(node.arg)\n+        return node\n+\n+    def visit_Getattr(self, node: nodes.Getattr) -&gt;nodes.Node:\n+        \"\"\"Optimize getattr nodes.\"\"\"\n+        node.node = self.visit(node.node)\n+        return node\n+\n+    def visit_Call(self, node: nodes.Call) -&gt;nodes.Node:\n+        \"\"\"Optimize call nodes.\"\"\"\n+        node.node = self.visit(node.node)\n+        node.args = [self.visit(arg) for arg in node.args]\n+        node.kwargs = [(key, self.visit(value)) for key, value in node.kwargs]\n+        return node\n+\n+    def visit_Filter(self, node: nodes.Filter) -&gt;nodes.Node:\n+        \"\"\"Optimize filter nodes.\"\"\"\n+        node.node = self.visit(node.node)\n+        node.args = [self.visit(arg) for arg in node.args]\n+        node.kwargs = [(key, self.visit(value)) for key, value in node.kwargs]\n+        return node\n+\n+    def visit_Test(self, node: nodes.Test) -&gt;nodes.Node:\n+        \"\"\"Optimize test nodes.\"\"\"\n+        node.node = self.visit(node.node)\n+        node.args = [self.visit(arg) for arg in node.args]\n+        node.kwargs = [(key, self.visit(value)) for key, value in node.kwargs]\n+        return node\n+\n+    def visit_CondExpr(self, node: nodes.CondExpr) -&gt;nodes.Node:\n+        \"\"\"Optimize conditional expression nodes.\"\"\"\n+        node.test = self.visit(node.test)\n+        node.expr1 = self.visit(node.expr1)\n+        node.expr2 = self.visit(node.expr2)\n+        return node\n+\n+    def generic_visit(self, node: nodes.Node) -&gt;nodes.Node:\n+        \"\"\"Visit a node.\"\"\"\n+        return super().generic_visit(node)\ndiff --git a/src/jinja2/parser.py b/src/jinja2/parser.py\nindex 05ce33d..1a2147c 100644\n--- a/src/jinja2/parser.py\n+++ b/src/jinja2/parser.py\n@@ -47,7 +47,9 @@ class Parser:\n         line number or last line number as well as the current name and\n         filename.\n         \"\"\"\n-        pass\n+        if lineno is None:\n+            lineno = self.stream.current.lineno\n+        raise exc(msg, lineno, self.name, self.filename)\n\n     def fail_unknown_tag(self, name: str, lineno: t.Optional[int]=None\n         ) -&gt;'te.NoReturn':\n@@ -55,26 +57,54 @@ class Parser:\n         with a human readable error message that could help to identify\n         the problem.\n         \"\"\"\n-        pass\n+        if lineno is None:\n+            lineno = self.stream.current.lineno\n+        if name in ('endif', 'endfor', 'endblock', 'endmacro', 'endcall'):\n+            self.fail(f'Unexpected end of block tag {name!r}', lineno)\n+        elif name in _statement_keywords:\n+            self.fail(f'Block tag {name!r} expected', lineno)\n+        self.fail(f'Unknown tag {name!r}', lineno)\n\n     def fail_eof(self, end_tokens: t.Optional[t.Tuple[str, ...]]=None,\n         lineno: t.Optional[int]=None) -&gt;'te.NoReturn':\n         \"\"\"Like fail_unknown_tag but for end of template situations.\"\"\"\n-        pass\n+        if end_tokens is not None:\n+            expected = ' or '.join(repr(x) for x in end_tokens)\n+            msg = f'Unexpected end of template. Expected {expected}.'\n+        else:\n+            msg = 'Unexpected end of template.'\n+        self.fail(msg, lineno)\n\n     def is_tuple_end(self, extra_end_rules: t.Optional[t.Tuple[str, ...]]=None\n         ) -&gt;bool:\n         \"\"\"Are we at the end of a tuple?\"\"\"\n-        pass\n+        if self.stream.current.type in ('variable_end', 'block_end', 'rparen'):\n+            return True\n+        if extra_end_rules is not None:\n+            return self.stream.current.test_any(extra_end_rules)\n+        return False\n\n     def free_identifier(self, lineno: t.Optional[int]=None\n         ) -&gt;nodes.InternalName:\n         \"\"\"Return a new free identifier as :class:`~jinja2.nodes.InternalName`.\"\"\"\n-        pass\n+        self._last_identifier += 1\n+        rv = object.__new__(nodes.InternalName)\n+        rv.name = f'fi{self._last_identifier}'\n+        rv.lineno = lineno\n+        return rv\n\n     def parse_statement(self) -&gt;t.Union[nodes.Node, t.List[nodes.Node]]:\n         \"\"\"Parse a single statement.\"\"\"\n-        pass\n+        token = self.stream.current\n+        if token.type != 'name':\n+            return self.parse_expression()\n+        if token.value in _statement_keywords:\n+            return getattr(self, f'parse_{token.value}')()\n+        if token.value == 'call':\n+            return self.parse_call_block()\n+        if token.value == 'filter':\n+            return self.parse_filter_block()\n+        return self.parse_expression()\n\n     def parse_statements(self, end_tokens: t.Tuple[str, ...], drop_needle:\n         bool=False) -&gt;t.List[nodes.Node]:\n@@ -87,7 +117,20 @@ class Parser:\n         the call is the matched end token.  If this is not wanted `drop_needle`\n         can be set to `True` and the end token is removed.\n         \"\"\"\n-        pass\n+        result = []\n+        while 1:\n+            if self.stream.current.type == 'data':\n+                result.append(nodes.Output([self.parse_tuple(with_condexpr=True)]))\n+            elif self.stream.current.type == 'block_begin':\n+                self.stream.next()\n+                if self.stream.current.test_any(end_tokens):\n+                    if drop_needle:\n+                        self.stream.next()\n+                    return result\n+                result.append(self.parse_statement())\n+            else:\n+                break\n+        self.fail_eof(end_tokens)\n\n     def parse_set(self) -&gt;t.Union[nodes.Assign, nodes.AssignBlock]:\n         \"\"\"Parse an assign statement.\"\"\"\ndiff --git a/src/jinja2/runtime.py b/src/jinja2/runtime.py\nindex c88211d..1bceb54 100644\n--- a/src/jinja2/runtime.py\n+++ b/src/jinja2/runtime.py\n@@ -43,17 +43,17 @@ def identity(x: V) -&gt;V:\n     \"\"\"Returns its argument. Useful for certain things in the\n     environment.\n     \"\"\"\n-    pass\n+    return x\n\n\n def markup_join(seq: t.Iterable[t.Any]) -&gt;str:\n     \"\"\"Concatenation that escapes if necessary and converts to string.\"\"\"\n-    pass\n+    return Markup('').join(escape(soft_str(v)) for v in seq)\n\n\n def str_join(seq: t.Iterable[t.Any]) -&gt;str:\n     \"\"\"Simple args to string conversion and concatenation.\"\"\"\n-    pass\n+    return ''.join(map(str, seq))\n\n\n def new_context(environment: 'Environment', template_name: t.Optional[str],\n@@ -62,7 +62,14 @@ def new_context(environment: 'Environment', template_name: t.Optional[str],\n     Optional[t.MutableMapping[str, t.Any]]=None, locals: t.Optional[t.\n     Mapping[str, t.Any]]=None) -&gt;'Context':\n     \"\"\"Internal helper for context creation.\"\"\"\n-    pass\n+    parent = environment.make_globals(globals)\n+    if vars is not None:\n+        parent.update(vars)\n+    if shared:\n+        parent = vars or {}\n+    if locals:\n+        parent.update(locals)\n+    return Context(environment, parent, template_name, blocks)\n\n\n class TemplateReference:\n@@ -116,7 +123,14 @@ class Context:\n     def super(self, name: str, current: t.Callable[['Context'], t.Iterator[\n         str]]) -&gt;t.Union['BlockReference', 'Undefined']:\n         \"\"\"Render a parent block.\"\"\"\n-        pass\n+        try:\n+            blocks = self.blocks[name]\n+            index = blocks.index(current) + 1\n+            if index &lt; len(blocks):\n+                return BlockReference(name, self, blocks, index)\n+        except (LookupError, ValueError):\n+            pass\n+        return self.environment.undefined(f'there is no parent block called {name!r}.', name='super')\n\n     def get(self, key: str, default: t.Any=None) -&gt;t.Any:\n         \"\"\"Look up a variable by name, or return a default if the key is\n@@ -125,7 +139,10 @@ class Context:\n         :param key: The variable name to look up.\n         :param default: The value to return if the key is not found.\n         \"\"\"\n-        pass\n+        try:\n+            return self[key]\n+        except KeyError:\n+            return default\n\n     def resolve(self, key: str) -&gt;t.Union[t.Any, 'Undefined']:\n         \"\"\"Look up a variable by name, or return an :class:`Undefined`\n@@ -137,7 +154,10 @@ class Context:\n\n         :param key: The variable name to look up.\n         \"\"\"\n-        pass\n+        rv = self.resolve_or_missing(key)\n+        if rv is missing:\n+            return self.environment.undefined(name=key)\n+        return rv\n\n     def resolve_or_missing(self, key: str) -&gt;t.Any:\n         \"\"\"Look up a variable by name, or return a ``missing`` sentinel\n@@ -149,18 +169,22 @@ class Context:\n\n         :param key: The variable name to look up.\n         \"\"\"\n-        pass\n+        if key in self.vars:\n+            return self.vars[key]\n+        if key in self.parent:\n+            return self.parent[key]\n+        return missing\n\n     def get_exported(self) -&gt;t.Dict[str, t.Any]:\n         \"\"\"Get a new dict with the exported variables.\"\"\"\n-        pass\n+        return {k: self.vars[k] for k in self.exported_vars}\n\n     def get_all(self) -&gt;t.Dict[str, t.Any]:\n         \"\"\"Return the complete context as dict including the exported\n         variables.  For optimizations reasons this might not return an\n         actual copy so be careful with using it.\n         \"\"\"\n-        pass\n+        return {**self.parent, **self.vars}\n\n     @internalcode\n     def call(__self, __obj: t.Callable[..., t.Any], *args: t.Any, **kwargs:\n@@ -170,14 +194,23 @@ class Context:\n         argument if the callable has :func:`pass_context` or\n         :func:`pass_environment`.\n         \"\"\"\n-        pass\n+        if isinstance(__obj, _PassArg):\n+            if __obj._type == 'context':\n+                args = (__self,) + args\n+            elif __obj._type == 'environment':\n+                args = (__self.environment,) + args\n+            return __obj._func(*args, **kwargs)\n+        return __obj(*args, **kwargs)\n\n     def derived(self, locals: t.Optional[t.Dict[str, t.Any]]=None) -&gt;'Context':\n         \"\"\"Internal helper function to create a derived context.  This is\n         used in situations where the system needs a new context in the same\n         template that is independent.\n         \"\"\"\n-        pass\n+        context = new_context(self.environment, self.name, self.blocks,\n+                              self.get_all(), True, None, locals)\n+        context.globals_keys = self.globals_keys\n+        return context\n     keys = _dict_method_all(dict.keys)\n     values = _dict_method_all(dict.values)\n     items = _dict_method_all(dict.items)\ndiff --git a/src/jinja2/sandbox.py b/src/jinja2/sandbox.py\nindex b73a983..9ea91b9 100644\n--- a/src/jinja2/sandbox.py\n+++ b/src/jinja2/sandbox.py\n@@ -35,7 +35,22 @@ def safe_range(*args: int) -&gt;range:\n     \"\"\"A range that can't generate ranges with a length of more than\n     MAX_RANGE items.\n     \"\"\"\n-    pass\n+    if len(args) == 1:\n+        start, stop, step = 0, args[0], 1\n+    elif len(args) == 2:\n+        start, stop, step = args[0], args[1], 1\n+    elif len(args) == 3:\n+        start, stop, step = args\n+    else:\n+        raise TypeError('range() requires 1-3 integer arguments')\n+    \n+    # Calculate the length of the range\n+    length = (stop - start + step - 1) // step\n+    \n+    if length &gt; MAX_RANGE:\n+        raise OverflowError(f'range() result has too many items (maximum is {MAX_RANGE})')\n+    \n+    return range(start, stop, step)\n\n\n def unsafe(f: F) -&gt;F:\n@@ -47,7 +62,8 @@ def unsafe(f: F) -&gt;F:\n         def delete(self):\n             pass\n     \"\"\"\n-    pass\n+    f.unsafe_callable = True\n+    return f\n\n\n def is_internal_attribute(obj: t.Any, attr: str) -&gt;bool:\n@@ -62,7 +78,11 @@ def is_internal_attribute(obj: t.Any, attr: str) -&gt;bool:\n     &gt;&gt;&gt; is_internal_attribute(str, \"upper\")\n     False\n     \"\"\"\n-    pass\n+    return attr.startswith('__') and attr.endswith('__') or \\\n+           attr.startswith('func_') or \\\n+           attr.startswith('im_') or \\\n+           attr in UNSAFE_FUNCTION_ATTRIBUTES or \\\n+           attr in UNSAFE_METHOD_ATTRIBUTES\n\n\n def modifies_known_mutable(obj: t.Any, attr: str) -&gt;bool:\n@@ -84,7 +104,10 @@ def modifies_known_mutable(obj: t.Any, attr: str) -&gt;bool:\n     &gt;&gt;&gt; modifies_known_mutable(\"foo\", \"upper\")\n     False\n     \"\"\"\n-    pass\n+    for typ, mutable_attrs in _mutable_spec:\n+        if isinstance(obj, typ):\n+            return attr in mutable_attrs\n+    return False\n\n\n class SandboxedEnvironment(Environment):\n@@ -120,7 +143,7 @@ class SandboxedEnvironment(Environment):\n         special attributes of internal python objects as returned by the\n         :func:`is_internal_attribute` function.\n         \"\"\"\n-        pass\n+        return not (attr.startswith('_') or is_internal_attribute(obj, attr))\n\n     def is_safe_callable(self, obj: t.Any) -&gt;bool:\n         \"\"\"Check if an object is safely callable. By default callables\n@@ -129,7 +152,10 @@ class SandboxedEnvironment(Environment):\n         This also recognizes the Django convention of setting\n         ``func.alters_data = True``.\n         \"\"\"\n-        pass\n+        return callable(obj) and not (\n+            getattr(obj, 'unsafe_callable', False) or\n+            getattr(obj, 'alters_data', False)\n+        )\n\n     def call_binop(self, context: Context, operator: str, left: t.Any,\n         right: t.Any) -&gt;t.Any:\n@@ -139,7 +165,9 @@ class SandboxedEnvironment(Environment):\n\n         .. versionadded:: 2.6\n         \"\"\"\n-        pass\n+        if operator not in self.binop_table:\n+            raise SecurityError(f'unsupported binary operator: {operator}')\n+        return self.binop_table[operator](left, right)\n\n     def call_unop(self, context: Context, operator: str, arg: t.Any) -&gt;t.Any:\n         \"\"\"For intercepted unary operator calls (:meth:`intercepted_unops`)\n@@ -148,22 +176,47 @@ class SandboxedEnvironment(Environment):\n\n         .. versionadded:: 2.6\n         \"\"\"\n-        pass\n+        if operator not in self.unop_table:\n+            raise SecurityError(f'unsupported unary operator: {operator}')\n+        return self.unop_table[operator](arg)\n\n     def getitem(self, obj: t.Any, argument: t.Union[str, t.Any]) -&gt;t.Union[\n         t.Any, Undefined]:\n         \"\"\"Subscribe an object from sandboxed code.\"\"\"\n-        pass\n+        try:\n+            return obj[argument]\n+        except (TypeError, LookupError):\n+            if isinstance(argument, str):\n+                try:\n+                    attr = str(argument)\n+                except Exception:\n+                    pass\n+                else:\n+                    try:\n+                        return self.getattr(obj, attr)\n+                    except RuntimeError:\n+                        return self.undefined(obj=obj, name=argument)\n+            return self.undefined(obj=obj, name=argument)\n\n     def getattr(self, obj: t.Any, attribute: str) -&gt;t.Union[t.Any, Undefined]:\n         \"\"\"Subscribe an object from sandboxed code and prefer the\n         attribute.  The attribute passed *must* be a bytestring.\n         \"\"\"\n-        pass\n+        try:\n+            value = getattr(obj, attribute)\n+        except AttributeError:\n+            return self.undefined(obj=obj, name=attribute)\n+        else:\n+            if self.is_safe_attribute(obj, attribute, value):\n+                return value\n+            return self.unsafe_undefined(obj, attribute)\n\n     def unsafe_undefined(self, obj: t.Any, attribute: str) -&gt;Undefined:\n         \"\"\"Return an undefined object for unsafe attributes.\"\"\"\n-        pass\n+        return self.undefined('access to attribute %r of %r object is unsafe.' % (\n+            attribute,\n+            obj.__class__.__name__\n+        ), name=attribute, obj=obj, exc=SecurityError)\n\n     def format_string(self, s: str, args: t.Tuple[t.Any, ...], kwargs: t.\n         Dict[str, t.Any], format_func: t.Optional[t.Callable[..., t.Any]]=None\n@@ -171,12 +224,21 @@ class SandboxedEnvironment(Environment):\n         \"\"\"If a format call is detected, then this is routed through this\n         method so that our safety sandbox can be used for it.\n         \"\"\"\n-        pass\n+        if format_func is not None:\n+            formatter = SandboxedEscapeFormatter(self, format_func)\n+        elif isinstance(s, Markup):\n+            formatter = SandboxedEscapeFormatter(self, lambda x: x)\n+        else:\n+            formatter = SandboxedFormatter(self)\n+        \n+        return formatter.vformat(s, args, kwargs)\n\n     def call(__self, __context: Context, __obj: t.Any, *args: t.Any, **\n         kwargs: t.Any) -&gt;t.Any:\n         \"\"\"Call an object from sandboxed code.\"\"\"\n-        pass\n+        if not __self.is_safe_callable(__obj):\n+            raise SecurityError(f'{__obj!r} is not safely callable')\n+        return __obj(*args, **kwargs)\n\n\n class ImmutableSandboxedEnvironment(SandboxedEnvironment):\ndiff --git a/src/jinja2/tests.py b/src/jinja2/tests.py\nindex 2823a4b..0963a3e 100644\n--- a/src/jinja2/tests.py\n+++ b/src/jinja2/tests.py\n@@ -11,17 +11,17 @@ if t.TYPE_CHECKING:\n\n def test_odd(value: int) -&gt;bool:\n     \"\"\"Return true if the variable is odd.\"\"\"\n-    pass\n+    return value % 2 != 0\n\n\n def test_even(value: int) -&gt;bool:\n     \"\"\"Return true if the variable is even.\"\"\"\n-    pass\n+    return value % 2 == 0\n\n\n def test_divisibleby(value: int, num: int) -&gt;bool:\n     \"\"\"Check if a variable is divisible by a number.\"\"\"\n-    pass\n+    return value % num == 0\n\n\n def test_defined(value: t.Any) -&gt;bool:\n@@ -38,12 +38,12 @@ def test_defined(value: t.Any) -&gt;bool:\n     See the :func:`default` filter for a simple way to set undefined\n     variables.\n     \"\"\"\n-    pass\n+    return not isinstance(value, Undefined)\n\n\n def test_undefined(value: t.Any) -&gt;bool:\n     \"\"\"Like :func:`defined` but the other way round.\"\"\"\n-    pass\n+    return isinstance(value, Undefined)\n\n\n @pass_environment\n@@ -61,7 +61,7 @@ def test_filter(env: 'Environment', value: str) -&gt;bool:\n\n     .. versionadded:: 3.0\n     \"\"\"\n-    pass\n+    return value in env.filters\n\n\n @pass_environment\n@@ -83,12 +83,12 @@ def test_test(env: 'Environment', value: str) -&gt;bool:\n\n     .. versionadded:: 3.0\n     \"\"\"\n-    pass\n+    return value in env.tests\n\n\n def test_none(value: t.Any) -&gt;bool:\n     \"\"\"Return true if the variable is none.\"\"\"\n-    pass\n+    return value is None\n\n\n def test_boolean(value: t.Any) -&gt;bool:\n@@ -96,7 +96,7 @@ def test_boolean(value: t.Any) -&gt;bool:\n\n     .. versionadded:: 2.11\n     \"\"\"\n-    pass\n+    return isinstance(value, bool)\n\n\n def test_false(value: t.Any) -&gt;bool:\n@@ -104,7 +104,7 @@ def test_false(value: t.Any) -&gt;bool:\n\n     .. versionadded:: 2.11\n     \"\"\"\n-    pass\n+    return value is False\n\n\n def test_true(value: t.Any) -&gt;bool:\n@@ -112,7 +112,7 @@ def test_true(value: t.Any) -&gt;bool:\n\n     .. versionadded:: 2.11\n     \"\"\"\n-    pass\n+    return value is True\n\n\n def test_integer(value: t.Any) -&gt;bool:\n@@ -120,7 +120,7 @@ def test_integer(value: t.Any) -&gt;bool:\n\n     .. versionadded:: 2.11\n     \"\"\"\n-    pass\n+    return isinstance(value, int)\n\n\n def test_float(value: t.Any) -&gt;bool:\n@@ -128,22 +128,22 @@ def test_float(value: t.Any) -&gt;bool:\n\n     .. versionadded:: 2.11\n     \"\"\"\n-    pass\n+    return isinstance(value, float)\n\n\n def test_lower(value: str) -&gt;bool:\n     \"\"\"Return true if the variable is lowercased.\"\"\"\n-    pass\n+    return isinstance(value, str) and value.islower()\n\n\n def test_upper(value: str) -&gt;bool:\n     \"\"\"Return true if the variable is uppercased.\"\"\"\n-    pass\n+    return isinstance(value, str) and value.isupper()\n\n\n def test_string(value: t.Any) -&gt;bool:\n     \"\"\"Return true if the object is a string.\"\"\"\n-    pass\n+    return isinstance(value, str)\n\n\n def test_mapping(value: t.Any) -&gt;bool:\n@@ -151,19 +151,19 @@ def test_mapping(value: t.Any) -&gt;bool:\n\n     .. versionadded:: 2.6\n     \"\"\"\n-    pass\n+    return isinstance(value, abc.Mapping)\n\n\n def test_number(value: t.Any) -&gt;bool:\n     \"\"\"Return true if the variable is a number.\"\"\"\n-    pass\n+    return isinstance(value, Number)\n\n\n def test_sequence(value: t.Any) -&gt;bool:\n     \"\"\"Return true if the variable is a sequence. Sequences are variables\n     that are iterable.\n     \"\"\"\n-    pass\n+    return isinstance(value, (abc.Sequence, abc.Set)) and not isinstance(value, str)\n\n\n def test_sameas(value: t.Any, other: t.Any) -&gt;bool:\n@@ -176,17 +176,21 @@ def test_sameas(value: t.Any, other: t.Any) -&gt;bool:\n             the foo attribute really is the `False` singleton\n         {% endif %}\n     \"\"\"\n-    pass\n+    return value is other\n\n\n def test_iterable(value: t.Any) -&gt;bool:\n     \"\"\"Check if it's possible to iterate over an object.\"\"\"\n-    pass\n+    try:\n+        iter(value)\n+        return True\n+    except TypeError:\n+        return False\n\n\n def test_escaped(value: t.Any) -&gt;bool:\n     \"\"\"Check if the value is escaped.\"\"\"\n-    pass\n+    return hasattr(value, '__html__')\n\n\n def test_in(value: t.Any, seq: t.Container[t.Any]) -&gt;bool:\n@@ -194,7 +198,7 @@ def test_in(value: t.Any, seq: t.Container[t.Any]) -&gt;bool:\n\n     .. versionadded:: 2.10\n     \"\"\"\n-    pass\n+    return value in seq\n\n\n TESTS = {'odd': test_odd, 'even': test_even, 'divisibleby':\ndiff --git a/src/jinja2/utils.py b/src/jinja2/utils.py\nindex 7563812..9a4ac9c 100644\n--- a/src/jinja2/utils.py\n+++ b/src/jinja2/utils.py\n@@ -32,7 +32,8 @@ def pass_context(f: F) -&gt;F:\n     .. versionadded:: 3.0.0\n         Replaces ``contextfunction`` and ``contextfilter``.\n     \"\"\"\n-    pass\n+    f.jinja_pass_arg = _PassArg.context\n+    return f\n\n\n def pass_eval_context(f: F) -&gt;F:\n@@ -48,7 +49,8 @@ def pass_eval_context(f: F) -&gt;F:\n     .. versionadded:: 3.0.0\n         Replaces ``evalcontextfunction`` and ``evalcontextfilter``.\n     \"\"\"\n-    pass\n+    f.jinja_pass_arg = _PassArg.eval_context\n+    return f\n\n\n def pass_environment(f: F) -&gt;F:\n@@ -60,7 +62,8 @@ def pass_environment(f: F) -&gt;F:\n     .. versionadded:: 3.0.0\n         Replaces ``environmentfunction`` and ``environmentfilter``.\n     \"\"\"\n-    pass\n+    f.jinja_pass_arg = _PassArg.environment\n+    return f\n\n\n class _PassArg(enum.Enum):\n@@ -71,7 +74,8 @@ class _PassArg(enum.Enum):\n\n def internalcode(f: F) -&gt;F:\n     \"\"\"Marks the function as internally used\"\"\"\n-    pass\n+    internal_code.add(f.__code__)\n+    return f\n\n\n def is_undefined(obj: t.Any) -&gt;bool:\n@@ -86,7 +90,8 @@ def is_undefined(obj: t.Any) -&gt;bool:\n                 return default\n             return var\n     \"\"\"\n-    pass\n+    from .runtime import Undefined\n+    return isinstance(obj, Undefined)\n\n\n def consume(iterable: t.Iterable[t.Any]) -&gt;None:\ndiff --git a/src/jinja2/visitor.py b/src/jinja2/visitor.py\nindex ebb34c6..17dcc82 100644\n--- a/src/jinja2/visitor.py\n+++ b/src/jinja2/visitor.py\n@@ -30,15 +30,19 @@ class NodeVisitor:\n         exists for this node.  In that case the generic visit function is\n         used instead.\n         \"\"\"\n-        pass\n+        method = 'visit_' + node.__class__.__name__\n+        return getattr(self, method, None)\n\n     def visit(self, node: Node, *args: t.Any, **kwargs: t.Any) -&gt;t.Any:\n         \"\"\"Visit a node.\"\"\"\n-        pass\n+        f = self.get_visitor(node)\n+        if f is not None:\n+            return f(node, *args, **kwargs)\n+        return self.generic_visit(node, *args, **kwargs)\n\n     def generic_visit(self, node: Node, *args: t.Any, **kwargs: t.Any) -&gt;t.Any:\n         \"\"\"Called if no explicit visitor function exists for a node.\"\"\"\n-        pass\n+        return node\n\n\n class NodeTransformer(NodeVisitor):\n@@ -52,9 +56,16 @@ class NodeTransformer(NodeVisitor):\n     replacement takes place.\n     \"\"\"\n\n-    def visit_list(self, node: Node, *args: t.Any, **kwargs: t.Any) -&gt;t.List[\n-        Node]:\n+    def visit_list(self, node: Node, *args: t.Any, **kwargs: t.Any) -&gt;t.List[Node]:\n         \"\"\"As transformers may return lists in some places this method\n         can be used to enforce a list as return value.\n         \"\"\"\n-        pass\n+        result = []\n+        for child in node:\n+            new_node = self.visit(child, *args, **kwargs)\n+            if new_node is not None:\n+                if isinstance(new_node, list):\n+                    result.extend(new_node)\n+                else:\n+                    result.append(new_node)\n+        return result\n</code></pre>"},{"location":"analysis_baseline_marshmallow/","title":"Analysis baseline marshmallow","text":"<p>back to baseline summary</p>"},{"location":"analysis_baseline_marshmallow/#submission-name-baseline","title":"Submission Name: baseline","text":""},{"location":"analysis_baseline_marshmallow/#repository-marshmallow","title":"Repository: marshmallow","text":""},{"location":"analysis_baseline_marshmallow/#failed-to-run-pytests","title":"Failed to run pytests","text":"<pre><code>ImportError while loading conftest '/testbed/tests/conftest.py'.\ntests/conftest.py:5: in &lt;module&gt;\n    from tests.base import Blog, User, UserSchema\ntests/base.py:11: in &lt;module&gt;\n    from marshmallow import Schema, fields, missing, post_load, validate\nsrc/marshmallow/__init__.py:17: in &lt;module&gt;\n    from marshmallow.schema import Schema, SchemaOpts\nsrc/marshmallow/schema.py:15: in &lt;module&gt;\n    from marshmallow import fields as ma_fields\nsrc/marshmallow/fields.py:18: in &lt;module&gt;\n    from marshmallow.utils import is_aware, is_collection, resolve_field_instance\nE   ImportError: cannot import name 'is_aware' from 'marshmallow.utils' (/testbed/src/marshmallow/utils.py)\n</code></pre>"},{"location":"analysis_baseline_marshmallow/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/src/marshmallow/class_registry.py b/src/marshmallow/class_registry.py\nindex 249b898..a7b38e8 100644\n--- a/src/marshmallow/class_registry.py\n+++ b/src/marshmallow/class_registry.py\n@@ -35,14 +35,29 @@ def register(classname: str, cls: SchemaType) -&gt;None:\n         # }\n\n     \"\"\"\n-    pass\n+    global _registry\n+    _registry[classname] = [cls]\n+    _registry[f\"{cls.__module__}.{cls.__name__}\"] = [cls]\n\n\n-def get_class(classname: str, all: bool=False) -&gt;(list[SchemaType] | SchemaType\n-    ):\n+def get_class(classname: str, all: bool=False) -&gt;(list[SchemaType] | SchemaType):\n     \"\"\"Retrieve a class from the registry.\n\n     :raises: marshmallow.exceptions.RegistryError if the class cannot be found\n         or if there are multiple entries for the given class name.\n     \"\"\"\n-    pass\n+    try:\n+        classes = _registry[classname]\n+    except KeyError:\n+        raise RegistryError(f\"Class with name {classname!r} was not found.\")\n+    \n+    if all:\n+        return classes\n+    \n+    if len(classes) &gt; 1:\n+        raise RegistryError(\n+            f\"Multiple classes with name {classname!r} were found. \"\n+            \"Please use the full, module-qualified path.\"\n+        )\n+    \n+    return classes[0]\ndiff --git a/src/marshmallow/decorators.py b/src/marshmallow/decorators.py\nindex d78f5be..e2944df 100644\n--- a/src/marshmallow/decorators.py\n+++ b/src/marshmallow/decorators.py\n@@ -84,7 +84,13 @@ def validates(field_name: str) -&gt;Callable[..., Any]:\n\n     :param str field_name: Name of the field that the method validates.\n     \"\"\"\n-    pass\n+    def decorator(fn):\n+        @functools.wraps(fn)\n+        def wrapper(self, value, **kwargs):\n+            return fn(self, value, **kwargs)\n+        wrapper.__marshmallow_hook__ = {VALIDATES: field_name}\n+        return wrapper\n+    return decorator\n\n\n def validates_schema(fn: (Callable[..., Any] | None)=None, pass_many: bool=\n@@ -109,7 +115,25 @@ def validates_schema(fn: (Callable[..., Any] | None)=None, pass_many: bool=\n         ``partial`` and ``many`` are always passed as keyword arguments to\n         the decorated method.\n     \"\"\"\n-    pass\n+    if fn is None:\n+        return functools.partial(\n+            validates_schema,\n+            pass_many=pass_many,\n+            pass_original=pass_original,\n+            skip_on_field_errors=skip_on_field_errors,\n+        )\n+\n+    @functools.wraps(fn)\n+    def wrapper(*args, **kwargs):\n+        return fn(*args, **kwargs)\n+\n+    wrapper.__marshmallow_hook__ = {\n+        (VALIDATES_SCHEMA, pass_many): {\n+            'pass_original': pass_original,\n+            'skip_on_field_errors': skip_on_field_errors,\n+        }\n+    }\n+    return wrapper\n\n\n def pre_dump(fn: (Callable[..., Any] | None)=None, pass_many: bool=False\n@@ -124,7 +148,7 @@ def pre_dump(fn: (Callable[..., Any] | None)=None, pass_many: bool=False\n     .. versionchanged:: 3.0.0\n         ``many`` is always passed as a keyword arguments to the decorated method.\n     \"\"\"\n-    pass\n+    return set_hook(fn, (PRE_DUMP, pass_many))\n\n\n def post_dump(fn: (Callable[..., Any] | None)=None, pass_many: bool=False,\n@@ -142,7 +166,7 @@ def post_dump(fn: (Callable[..., Any] | None)=None, pass_many: bool=False,\n     .. versionchanged:: 3.0.0\n         ``many`` is always passed as a keyword arguments to the decorated method.\n     \"\"\"\n-    pass\n+    return set_hook(fn, (POST_DUMP, pass_many), pass_original=pass_original)\n\n\n def pre_load(fn: (Callable[..., Any] | None)=None, pass_many: bool=False\n@@ -158,7 +182,7 @@ def pre_load(fn: (Callable[..., Any] | None)=None, pass_many: bool=False\n         ``partial`` and ``many`` are always passed as keyword arguments to\n         the decorated method.\n     \"\"\"\n-    pass\n+    return set_hook(fn, (PRE_LOAD, pass_many))\n\n\n def post_load(fn: (Callable[..., Any] | None)=None, pass_many: bool=False,\n@@ -177,7 +201,7 @@ def post_load(fn: (Callable[..., Any] | None)=None, pass_many: bool=False,\n         ``partial`` and ``many`` are always passed as keyword arguments to\n         the decorated method.\n     \"\"\"\n-    pass\n+    return set_hook(fn, (POST_LOAD, pass_many), pass_original=pass_original)\n\n\n def set_hook(fn: (Callable[..., Any] | None), key: (tuple[str, bool] | str),\n@@ -192,4 +216,11 @@ def set_hook(fn: (Callable[..., Any] | None), key: (tuple[str, bool] | str),\n     :return: Decorated function if supplied, else this decorator with its args\n         bound.\n     \"\"\"\n-    pass\n+    def decorator(func):\n+        func.__marshmallow_hook__ = {key: kwargs or True}\n+        return func\n+\n+    if fn is None:\n+        return decorator\n+    else:\n+        return decorator(fn)\ndiff --git a/src/marshmallow/error_store.py b/src/marshmallow/error_store.py\nindex a659aaf..d5a60d5 100644\n--- a/src/marshmallow/error_store.py\n+++ b/src/marshmallow/error_store.py\n@@ -13,6 +13,16 @@ class ErrorStore:\n     def __init__(self):\n         self.errors = {}\n\n+    def store_error(self, field_name, error):\n+        \"\"\"Store an error message for a field.\"\"\"\n+        if field_name not in self.errors:\n+            self.errors[field_name] = []\n+        self.errors[field_name].append(error)\n+\n+    def get_errors(self):\n+        \"\"\"Return all stored errors.\"\"\"\n+        return self.errors\n+\n\n def merge_errors(errors1, errors2):\n     \"\"\"Deeply merge two error messages.\n@@ -20,4 +30,15 @@ def merge_errors(errors1, errors2):\n     The format of ``errors1`` and ``errors2`` matches the ``message``\n     parameter of :exc:`marshmallow.exceptions.ValidationError`.\n     \"\"\"\n-    pass\n+    merged = errors1.copy()\n+    for key, value in errors2.items():\n+        if key in merged:\n+            if isinstance(merged[key], dict) and isinstance(value, dict):\n+                merged[key] = merge_errors(merged[key], value)\n+            elif isinstance(merged[key], list) and isinstance(value, list):\n+                merged[key].extend(value)\n+            else:\n+                merged[key] = [merged[key], value]\n+        else:\n+            merged[key] = value\n+    return merged\ndiff --git a/src/marshmallow/fields.py b/src/marshmallow/fields.py\nindex 8656a56..c3a5d4a 100644\n--- a/src/marshmallow/fields.py\n+++ b/src/marshmallow/fields.py\n@@ -166,19 +166,37 @@ class Field(FieldABC):\n         :param callable accessor: A callable used to retrieve the value of `attr` from\n             the object `obj`. Defaults to `marshmallow.utils.get_value`.\n         \"\"\"\n-        pass\n+        accessor_func = accessor or utils.get_value\n+        return accessor_func(obj, attr, default)\n\n     def _validate(self, value):\n         \"\"\"Perform validation on ``value``. Raise a :exc:`ValidationError` if validation\n         does not succeed.\n         \"\"\"\n-        pass\n+        errors = []\n+        for validator in self.validators:\n+            try:\n+                if validator(value) is False:\n+                    self.fail('validator_failed')\n+            except ValidationError as error:\n+                errors.extend(error.messages)\n+        if errors:\n+            raise ValidationError(errors)\n\n     def make_error(self, key: str, **kwargs) -&gt;ValidationError:\n         \"\"\"Helper method to make a `ValidationError` with an error message\n         from ``self.error_messages``.\n         \"\"\"\n-        pass\n+        try:\n+            msg = self.error_messages[key]\n+        except KeyError as error:\n+            class_name = self.__class__.__name__\n+            message = (f'Error key \"{key}\" does not exist for field \"{class_name}\".'\n+                       f' Available keys are {\", \".join(self.error_messages.keys())}.')\n+            raise KeyError(message) from error\n+        if isinstance(msg, str):\n+            msg = msg.format(**kwargs)\n+        return ValidationError(msg)\n\n     def fail(self, key: str, **kwargs):\n         \"\"\"Helper method that raises a `ValidationError` with an error message\n@@ -187,13 +205,23 @@ class Field(FieldABC):\n         .. deprecated:: 3.0.0\n             Use `make_error &lt;marshmallow.fields.Field.make_error&gt;` instead.\n         \"\"\"\n-        pass\n+        warnings.warn(\n+            \"Field.fail is deprecated. Use Field.make_error instead.\",\n+            RemovedInMarshmallow4Warning,\n+            stacklevel=2\n+        )\n+        raise self.make_error(key, **kwargs)\n\n     def _validate_missing(self, value):\n         \"\"\"Validate missing values. Raise a :exc:`ValidationError` if\n         `value` should be considered missing.\n         \"\"\"\n-        pass\n+        if value is missing_:\n+            if self.required:\n+                raise self.make_error('required')\n+        elif value is None:\n+            if self.allow_none is False:\n+                raise self.make_error('null')\n\n     def serialize(self, attr: str, obj: typing.Any, accessor: (typing.\n         Callable[[typing.Any, str, typing.Any], typing.Any] | None)=None,\n@@ -206,7 +234,14 @@ class Field(FieldABC):\n         :param accessor: Function used to access values from ``obj``.\n         :param kwargs: Field-specific keyword arguments.\n         \"\"\"\n-        pass\n+        if self.dump_only:\n+            return self.dump_default\n+\n+        value = self.get_value(obj, attr, accessor=accessor)\n+        if value is missing_:\n+            return self.dump_default\n+\n+        return self._serialize(value, attr, obj, **kwargs)\n\n     def deserialize(self, value: typing.Any, attr: (str | None)=None, data:\n         (typing.Mapping[str, typing.Any] | None)=None, **kwargs):\n@@ -219,7 +254,17 @@ class Field(FieldABC):\n         :raise ValidationError: If an invalid value is passed or if a required value\n             is missing.\n         \"\"\"\n-        pass\n+        if self.load_only:\n+            return self.load_default\n+\n+        self._validate_missing(value)\n+        if value is missing_:\n+            return self.load_default\n+\n+        value = self._deserialize(value, attr, data, **kwargs)\n+        self._validate(value)\n+\n+        return value\n\n     def _bind_to_schema(self, field_name, schema):\n         \"\"\"Update field with values from its parent schema. Called by\n@@ -228,7 +273,13 @@ class Field(FieldABC):\n         :param str field_name: Field name set in schema.\n         :param Schema|Field schema: Parent object.\n         \"\"\"\n-        pass\n+        self.parent = self.schema = schema\n+        self.name = field_name\n+        self.root = schema.root\n+        # Allow fields to override their data key\n+        if self.data_key is None:\n+            self.data_key = field_name\n+        self.metadata.setdefault('name', field_name)\n\n     def _serialize(self, value: typing.Any, attr: (str | None), obj: typing\n         .Any, **kwargs):\n@@ -249,7 +300,7 @@ class Field(FieldABC):\n         :param dict kwargs: Field-specific keyword arguments.\n         :return: The serialized value\n         \"\"\"\n-        pass\n+        return value\n\n     def _deserialize(self, value: typing.Any, attr: (str | None), data: (\n         typing.Mapping[str, typing.Any] | None), **kwargs):\n@@ -268,12 +319,12 @@ class Field(FieldABC):\n         .. versionchanged:: 3.0.0\n             Added ``**kwargs`` to signature.\n         \"\"\"\n-        pass\n+        return value\n\n     @property\n     def context(self):\n         \"\"\"The context dictionary for the parent :class:`Schema`.\"\"\"\n-        pass\n+        return self.parent.context if self.parent else {}\n\n\n class Raw(Field):\ndiff --git a/src/marshmallow/schema.py b/src/marshmallow/schema.py\nindex 1e6eabf..38ad968 100644\n--- a/src/marshmallow/schema.py\n+++ b/src/marshmallow/schema.py\n@@ -311,7 +311,10 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n\n         .. versionadded:: 3.0.0\n         \"\"\"\n-        pass\n+        attrs = fields.copy()\n+        attrs['Meta'] = type('Meta', (), {'register': False})\n+        schema_cls = type(name, (Schema,), attrs)\n+        return schema_cls\n\n     def handle_error(self, error: ValidationError, data: typing.Any, *,\n         many: bool, **kwargs):\n@@ -327,7 +330,7 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n         .. versionchanged:: 3.0.0rc9\n             Receives `many` and `partial` (on deserialization) as keyword arguments.\n         \"\"\"\n-        pass\n+        pass  # Default implementation does nothing\n\n     def get_attribute(self, obj: typing.Any, attr: str, default: typing.Any):\n         \"\"\"Defines how to pull values from an object to serialize.\n@@ -337,7 +340,7 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n         .. versionchanged:: 3.0.0a1\n             Changed position of ``obj`` and ``attr``.\n         \"\"\"\n-        pass\n+        return get_value(obj, attr, default)\n\n     @staticmethod\n     def _call_and_store(getter_func, data, *, field_name, error_store,\n@@ -351,7 +354,12 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n         :param int index: Index of the item being validated, if validating a collection,\n             otherwise `None`.\n         \"\"\"\n-        pass\n+        try:\n+            value = getter_func(data)\n+        except ValidationError as error:\n+            error_store.store_error(error.messages, field_name, index=index)\n+            return missing\n+        return value\n\n     def _serialize(self, obj: (_T | typing.Iterable[_T]), *, many: bool=False):\n         \"\"\"Serialize ``obj``.\ndiff --git a/src/marshmallow/utils.py b/src/marshmallow/utils.py\nindex 1c71b57..e9ec424 100644\n--- a/src/marshmallow/utils.py\n+++ b/src/marshmallow/utils.py\n@@ -40,29 +40,35 @@ missing = _Missing()\n\n def is_generator(obj) -&gt;bool:\n     \"\"\"Return True if ``obj`` is a generator\"\"\"\n-    pass\n+    return inspect.isgenerator(obj)\n\n\n def is_iterable_but_not_string(obj) -&gt;bool:\n     \"\"\"Return True if ``obj`` is an iterable object that isn't a string.\"\"\"\n-    pass\n+    return (\n+        isinstance(obj, collections.abc.Iterable) and\n+        not isinstance(obj, (str, bytes))\n+    )\n\n\n def is_collection(obj) -&gt;bool:\n     \"\"\"Return True if ``obj`` is a collection type, e.g list, tuple, queryset.\"\"\"\n-    pass\n+    return is_iterable_but_not_string(obj) and not isinstance(obj, Mapping)\n\n\n def is_instance_or_subclass(val, class_) -&gt;bool:\n     \"\"\"Return True if ``val`` is either a subclass or instance of ``class_``.\"\"\"\n-    pass\n+    try:\n+        return issubclass(val, class_)\n+    except TypeError:\n+        return isinstance(val, class_)\n\n\n def is_keyed_tuple(obj) -&gt;bool:\n     \"\"\"Return True if ``obj`` has keyed tuple behavior, such as\n     namedtuples or SQLAlchemy's KeyedTuples.\n     \"\"\"\n-    pass\n+    return isinstance(obj, tuple) and hasattr(obj, '_fields')\n\n\n def pprint(obj, *args, **kwargs) -&gt;None:\n@@ -73,7 +79,15 @@ def pprint(obj, *args, **kwargs) -&gt;None:\n     .. deprecated:: 3.7.0\n         marshmallow.pprint will be removed in marshmallow 4.\n     \"\"\"\n-    pass\n+    warnings.warn(\n+        \"marshmallow.pprint is deprecated and will be removed in marshmallow 4.\",\n+        RemovedInMarshmallow4Warning,\n+        stacklevel=2,\n+    )\n+    if isinstance(obj, collections.OrderedDict):\n+        py_pprint(dict(obj), *args, **kwargs)\n+    else:\n+        py_pprint(obj, *args, **kwargs)\n\n\n def from_rfc(datestring: str) -&gt;dt.datetime:\n@@ -81,7 +95,7 @@ def from_rfc(datestring: str) -&gt;dt.datetime:\n\n     https://stackoverflow.com/questions/885015/how-to-parse-a-rfc-2822-date-time-into-a-python-datetime  # noqa: B950\n     \"\"\"\n-    pass\n+    return parsedate_to_datetime(datestring)\n\n\n def rfcformat(datetime: dt.datetime) -&gt;str:\n@@ -89,7 +103,7 @@ def rfcformat(datetime: dt.datetime) -&gt;str:\n\n     :param datetime datetime: The datetime.\n     \"\"\"\n-    pass\n+    return format_datetime(datetime)\n\n\n _iso8601_datetime_re = re.compile(\n@@ -104,7 +118,9 @@ _iso8601_time_re = re.compile(\n\n def get_fixed_timezone(offset: (int | float | dt.timedelta)) -&gt;dt.timezone:\n     \"\"\"Return a tzinfo instance with a fixed offset from UTC.\"\"\"\n-    pass\n+    if isinstance(offset, dt.timedelta):\n+        offset = offset.total_seconds()\n+    return dt.timezone(dt.timedelta(seconds=int(offset)))\n\n\n def from_iso_datetime(value):\n@@ -113,7 +129,32 @@ def from_iso_datetime(value):\n     This function supports time zone offsets. When the input contains one,\n     the output uses a timezone with a fixed offset from UTC.\n     \"\"\"\n-    pass\n+    match = _iso8601_datetime_re.match(value)\n+    if not match:\n+        raise ValueError('Not a valid ISO8601-formatted datetime string')\n+\n+    groups = match.groupdict()\n+\n+    groups['year'] = int(groups['year'])\n+    groups['month'] = int(groups['month'])\n+    groups['day'] = int(groups['day'])\n+    groups['hour'] = int(groups['hour'])\n+    groups['minute'] = int(groups['minute'])\n+    groups['second'] = int(groups['second'] or 0)\n+    groups['microsecond'] = int(groups['microsecond'] or 0)\n+\n+    if groups['tzinfo'] == 'Z':\n+        tzinfo = dt.timezone.utc\n+    elif groups['tzinfo']:\n+        offset_mins = int(groups['tzinfo'][-2:]) if len(groups['tzinfo']) &gt; 3 else 0\n+        offset = 60 * int(groups['tzinfo'][1:3]) + offset_mins\n+        if groups['tzinfo'][0] == '-':\n+            offset = -offset\n+        tzinfo = get_fixed_timezone(offset * 60)\n+    else:\n+        tzinfo = None\n+\n+    return dt.datetime(tzinfo=tzinfo, **groups)\n\n\n def from_iso_time(value):\n@@ -121,12 +162,33 @@ def from_iso_time(value):\n\n     This function doesn't support time zone offsets.\n     \"\"\"\n-    pass\n+    match = _iso8601_time_re.match(value)\n+    if not match:\n+        raise ValueError('Not a valid ISO8601-formatted time string')\n+\n+    groups = match.groupdict()\n+\n+    groups['hour'] = int(groups['hour'])\n+    groups['minute'] = int(groups['minute'])\n+    groups['second'] = int(groups['second'] or 0)\n+    groups['microsecond'] = int(groups['microsecond'] or 0)\n+\n+    return dt.time(**groups)\n\n\n def from_iso_date(value):\n     \"\"\"Parse a string and return a datetime.date.\"\"\"\n-    pass\n+    match = _iso8601_date_re.match(value)\n+    if not match:\n+        raise ValueError('Not a valid ISO8601-formatted date string')\n+\n+    groups = match.groupdict()\n+\n+    return dt.date(\n+        int(groups['year']),\n+        int(groups['month']),\n+        int(groups['day'])\n+    )\n\n\n def isoformat(datetime: dt.datetime) -&gt;str:\n@@ -134,7 +196,7 @@ def isoformat(datetime: dt.datetime) -&gt;str:\n\n     :param datetime datetime: The datetime.\n     \"\"\"\n-    pass\n+    return datetime.isoformat()\n\n\n def pluck(dictlist: list[dict[str, typing.Any]], key: str):\n@@ -145,7 +207,7 @@ def pluck(dictlist: list[dict[str, typing.Any]], key: str):\n         &gt;&gt;&gt; pluck(dlist, 'id')\n         [1, 2]\n     \"\"\"\n-    pass\n+    return [d.get(key) for d in dictlist]\n\n\n def get_value(obj, key: (int | str), default=missing):\n@@ -159,7 +221,19 @@ def get_value(obj, key: (int | str), default=missing):\n         `get_value` will never check the value `x.i`. Consider overriding\n         `marshmallow.fields.Field.get_value` in this case.\n     \"\"\"\n-    pass\n+    if isinstance(key, int):\n+        return obj[key] if isinstance(obj, collections.abc.Sequence) else default\n+\n+    try:\n+        return obj[key]\n+    except (KeyError, AttributeError, IndexError, TypeError):\n+        pass\n+\n+    # Fall back to getattr for dotted paths\n+    if '.' in key:\n+        return functools.reduce(lambda o, k: get_value(o, k, default), key.split('.'), obj)\n+\n+    return getattr(obj, key, default)\n\n\n def set_value(dct: dict[str, typing.Any], key: str, value: typing.Any):\n@@ -173,12 +247,26 @@ def set_value(dct: dict[str, typing.Any], key: str, value: typing.Any):\n         &gt;&gt;&gt; d\n         {'foo': {'bar': 42}}\n     \"\"\"\n-    pass\n+    if '.' in key:\n+        head, rest = key.split('.', 1)\n+        target = dct.setdefault(head, {})\n+        if not isinstance(target, dict):\n+            raise ValueError(\n+                \"Cannot set '{rest}' in '{head}' ({target}) \"\n+                \"which is not a dict\".format(\n+                    rest=rest, head=head, target=target\n+                )\n+            )\n+        set_value(target, rest, value)\n+    else:\n+        dct[key] = value\n\n\n def callable_or_raise(obj):\n     \"\"\"Check that an object is callable, else raise a :exc:`TypeError`.\"\"\"\n-    pass\n+    if not callable(obj):\n+        raise TypeError('Object {!r} is not callable.'.format(obj))\n+    return obj\n\n\n def get_func_args(func: typing.Callable) -&gt;list[str]:\n@@ -188,7 +276,12 @@ def get_func_args(func: typing.Callable) -&gt;list[str]:\n     .. versionchanged:: 3.0.0a1\n         Do not return bound arguments, eg. ``self``.\n     \"\"\"\n-    pass\n+    if isinstance(func, functools.partial):\n+        return get_func_args(func.func)\n+    if inspect.isfunction(func) or inspect.ismethod(func):\n+        return list(inspect.signature(func).parameters.keys())\n+    # Callable class\n+    return list(inspect.signature(func.__call__).parameters.keys())[1:]\n\n\n def resolve_field_instance(cls_or_instance):\n@@ -196,7 +289,19 @@ def resolve_field_instance(cls_or_instance):\n\n     :param type|Schema cls_or_instance: Marshmallow Schema class or instance.\n     \"\"\"\n-    pass\n+    if isinstance(cls_or_instance, type):\n+        if not issubclass(cls_or_instance, FieldABC):\n+            raise FieldInstanceResolutionError(\n+                'The class \"{}\" is not a subclass of '\n+                'marshmallow.base.FieldABC'.format(cls_or_instance.__name__)\n+            )\n+        return cls_or_instance()\n+    if not isinstance(cls_or_instance, FieldABC):\n+        raise FieldInstanceResolutionError(\n+            'The object \"{}\" is not an instance of '\n+            'marshmallow.base.FieldABC'.format(cls_or_instance)\n+        )\n+    return cls_or_instance\n\n\n def timedelta_to_microseconds(value: dt.timedelta) -&gt;int:\n@@ -204,4 +309,4 @@ def timedelta_to_microseconds(value: dt.timedelta) -&gt;int:\n\n     https://github.com/python/cpython/blob/bb3e0c240bc60fe08d332ff5955d54197f79751c/Lib/datetime.py#L665-L667  # noqa: B950\n     \"\"\"\n-    pass\n+    return (value.days * 86400 + value.seconds) * 1000000 + value.microseconds\ndiff --git a/src/marshmallow/validate.py b/src/marshmallow/validate.py\nindex 3cc3b97..928d96e 100644\n--- a/src/marshmallow/validate.py\n+++ b/src/marshmallow/validate.py\n@@ -105,6 +105,20 @@ class URL(Validator):\n                 self._memoized[key] = self._regex_generator(relative,\n                     absolute, require_tld)\n             return self._memoized[key]\n+\n+        def _regex_generator(self, relative: bool, absolute: bool, require_tld: bool\n+            ) -&gt;typing.Pattern:\n+            return re.compile(\n+                r\"\".join([\n+                    r\"^\",\n+                    r\"(\" if relative else r\"\",\n+                    r\"(?:[a-z0-9\\.\\-\\+]*)://\" if absolute else r\"\",\n+                    r\"(?:[^/:]+)\" if not require_tld else r\"(?:[^/:]+\\.)+[^/:]{2,}\",\n+                    r\"(?::\\d+)?(?:/?|[/?]\\S+)$\",\n+                    r\")?\" if relative else r\"\",\n+                ]),\n+                re.IGNORECASE\n+            )\n     _regex = RegexMemoizer()\n     default_message = 'Not a valid URL.'\n     default_schemes = {'http', 'https', 'ftp', 'ftps'}\n@@ -419,7 +433,15 @@ class OneOf(Validator):\n             of an attribute of the choice objects. Defaults to `str()`\n             or `str()`.\n         \"\"\"\n-        pass\n+        if callable(valuegetter):\n+            getter = valuegetter\n+        elif isinstance(valuegetter, str):\n+            getter = attrgetter(valuegetter)\n+        else:\n+            getter = str\n+\n+        for choice, label in zip_longest(self.choices, self.labels):\n+            yield getter(choice), label or str(choice)\n\n\n class ContainsOnly(OneOf):\n</code></pre>"},{"location":"analysis_baseline_simpy/","title":"Analysis baseline simpy","text":"<p>back to baseline summary</p>"},{"location":"analysis_baseline_simpy/#submission-name-baseline","title":"Submission Name: baseline","text":""},{"location":"analysis_baseline_simpy/#repository-simpy","title":"Repository: simpy","text":""},{"location":"analysis_baseline_simpy/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count failed 120 passed 20 total 140 collected 150 deselected 10"},{"location":"analysis_baseline_simpy/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_baseline_simpy/#test_conditionpytest_operator_and","title":"test_condition.py::test_operator_and","text":"<pre>test_condition.py::test_operator_and</pre><pre>\nenv = \n\n    def test_operator_and(env):\n        def process(env):\n            timeout = [env.timeout(delay, value=delay) for delay in range(3)]\n            results = yield timeout[0] &amp; timeout[1] &amp; timeout[2]\n\n            assert results == {\n                timeout[0]: 0,\n                timeout[1]: 1,\n                timeout[2]: 2,\n            }\n\n        env.process(process(env))\n&gt;       env.run()\n\ntests/test_condition.py:16: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_operator_and_blocked","title":"test_condition.py::test_operator_and_blocked","text":"<pre>test_condition.py::test_operator_and_blocked</pre><pre>\nenv = \n\n    def test_operator_and_blocked(env):\n        def process(env):\n            timeout = env.timeout(1)\n            event = env.event()\n            yield env.timeout(1)\n\n            condition = timeout &amp; event\n            assert not condition.triggered\n\n        env.process(process(env))\n&gt;       env.run()\n\ntests/test_condition.py:29: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_operator_or","title":"test_condition.py::test_operator_or","text":"<pre>test_condition.py::test_operator_or</pre><pre>\nenv = \n\n    def test_operator_or(env):\n        def process(env):\n            timeout = [env.timeout(delay, value=delay) for delay in range(3)]\n            results = yield timeout[0] | timeout[1] | timeout[2]\n\n            assert results == {\n                timeout[0]: 0,\n            }\n\n        env.process(process(env))\n&gt;       env.run()\n\ntests/test_condition.py:42: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_operator_nested_and","title":"test_condition.py::test_operator_nested_and","text":"<pre>test_condition.py::test_operator_nested_and</pre><pre>\nenv = \n\n    def test_operator_nested_and(env):\n        def process(env):\n            timeout = [env.timeout(delay, value=delay) for delay in range(3)]\n            results = yield (timeout[0] &amp; timeout[2]) | timeout[1]\n\n            assert results == {\n                timeout[0]: 0,\n                timeout[1]: 1,\n            }\n            assert env.now == 1\n\n        env.process(process(env))\n&gt;       env.run()\n\ntests/test_condition.py:57: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_operator_nested_or","title":"test_condition.py::test_operator_nested_or","text":"<pre>test_condition.py::test_operator_nested_or</pre><pre>\nenv = \n\n    def test_operator_nested_or(env):\n        def process(env):\n            timeout = [env.timeout(delay, value=delay) for delay in range(3)]\n            results = yield (timeout[0] | timeout[1]) &amp; timeout[2]\n\n            assert results == {\n                timeout[0]: 0,\n                timeout[1]: 1,\n                timeout[2]: 2,\n            }\n            assert env.now == 2\n\n        env.process(process(env))\n&gt;       env.run()\n\ntests/test_condition.py:73: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_nested_cond_with_error","title":"test_condition.py::test_nested_cond_with_error","text":"<pre>test_condition.py::test_nested_cond_with_error</pre><pre>\nenv = \n\n    def test_nested_cond_with_error(env):\n        def explode(env):\n            yield env.timeout(1)\n            raise ValueError('Onoes!')\n\n        def process(env):\n            with pytest.raises(ValueError, match='Onoes!'):\n                yield env.process(explode(env)) &amp; env.timeout(1)\n\n        env.process(process(env))\n&gt;       env.run()\n\ntests/test_condition.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_cond_with_error","title":"test_condition.py::test_cond_with_error","text":"<pre>test_condition.py::test_cond_with_error</pre><pre>\nenv = \n\n    def test_cond_with_error(env):\n        def explode(env, delay):\n            yield env.timeout(delay)\n            raise ValueError(f'Onoes, failed after {delay}!')\n\n        def process(env):\n            with pytest.raises(ValueError, match='Onoes, failed after 0!'):\n                yield env.process(explode(env, 0)) | env.timeout(1)\n\n        env.process(process(env))\n&gt;       env.run()\n\ntests/test_condition.py:99: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_cond_with_nested_error","title":"test_condition.py::test_cond_with_nested_error","text":"<pre>test_condition.py::test_cond_with_nested_error</pre><pre>\nenv = \n\n    def test_cond_with_nested_error(env):\n        def explode(env, delay):\n            yield env.timeout(delay)\n            raise ValueError(f'Onoes, failed after {delay}!')\n\n        def process(env):\n            with pytest.raises(ValueError, match='Onoes, failed after 0!'):\n                yield env.process(explode(env, 0)) &amp; env.timeout(1) | env.timeout(1)\n\n        env.process(process(env))\n&gt;       env.run()\n\ntests/test_condition.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_cond_with_uncaught_error","title":"test_condition.py::test_cond_with_uncaught_error","text":"<pre>test_condition.py::test_cond_with_uncaught_error</pre><pre>\nenv = \n\n    def test_cond_with_uncaught_error(env):\n        \"\"\"Errors that happen after the condition has been triggered will not be\n        handled by the condition and cause the simulation to crash.\"\"\"\n\n        def explode(env, delay):\n            yield env.timeout(delay)\n            raise ValueError(f'Onoes, failed after {delay}!')\n\n        def process(env):\n            yield env.timeout(1) | env.process(explode(env, 2))\n\n        env.process(process(env))\n        with pytest.raises(ValueError, match='Onoes, failed after'):\n&gt;           env.run()\n\ntests/test_condition.py:128: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_iand_with_and_cond","title":"test_condition.py::test_iand_with_and_cond","text":"<pre>test_condition.py::test_iand_with_and_cond</pre><pre>\nenv = \n\n    def test_iand_with_and_cond(env):\n        def process(env):\n            cond = env.timeout(1, value=1) &amp; env.timeout(2, value=2)\n            orig = cond\n\n            cond &amp;= env.timeout(0, value=0)\n            assert cond is not orig\n\n            results = yield cond\n            assert list(results.values()) == [1, 2, 0]\n\n        env.process(process(env))\n&gt;       env.run()\n\ntests/test_condition.py:144: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_iand_with_or_cond","title":"test_condition.py::test_iand_with_or_cond","text":"<pre>test_condition.py::test_iand_with_or_cond</pre><pre>\nenv = \n\n    def test_iand_with_or_cond(env):\n        def process(env):\n            cond = env.timeout(1, value=1) | env.timeout(2, value=2)\n            orig = cond\n\n            cond &amp;= env.timeout(0, value=0)\n            assert cond is not orig\n\n            results = yield cond\n            assert list(results.values()) == [1, 0]\n\n        env.process(process(env))\n&gt;       env.run()\n\ntests/test_condition.py:159: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_ior_with_or_cond","title":"test_condition.py::test_ior_with_or_cond","text":"<pre>test_condition.py::test_ior_with_or_cond</pre><pre>\nenv = \n\n    def test_ior_with_or_cond(env):\n        def process(env):\n            cond = env.timeout(1, value=1) | env.timeout(2, value=2)\n            orig = cond\n\n            cond |= env.timeout(0, value=0)\n            assert cond is not orig\n\n            results = yield cond\n            assert list(results.values()) == [0]\n\n        env.process(process(env))\n&gt;       env.run()\n\ntests/test_condition.py:174: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_ior_with_and_cond","title":"test_condition.py::test_ior_with_and_cond","text":"<pre>test_condition.py::test_ior_with_and_cond</pre><pre>\nenv = \n\n    def test_ior_with_and_cond(env):\n        def process(env):\n            cond = env.timeout(1, value=1) &amp; env.timeout(2, value=2)\n            orig = cond\n\n            cond |= env.timeout(0, value=0)\n            assert cond is not orig\n\n            results = yield cond\n            assert list(results.values()) == [0]\n\n        env.process(process(env))\n&gt;       env.run()\n\ntests/test_condition.py:189: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_immutable_results","title":"test_condition.py::test_immutable_results","text":"<pre>test_condition.py::test_immutable_results</pre><pre>\nenv = \n\n    def test_immutable_results(env):\n        \"\"\"Results of conditions should not change after they have been\n        triggered.\"\"\"\n\n        def process(env):\n            timeout = [env.timeout(delay, value=delay) for delay in range(3)]\n            # The or condition in this expression will trigger immediately. The and\n            # condition will trigger later on.\n            condition = timeout[0] | (timeout[1] &amp; timeout[2])\n\n            results = yield condition\n            assert results == {timeout[0]: 0}\n\n            # Make sure that the results of condition were frozen. The results of\n            # the nested and condition do not become visible afterwards.\n            yield env.timeout(2)\n            assert results == {timeout[0]: 0}\n\n        env.process(process(env))\n&gt;       env.run()\n\ntests/test_condition.py:211: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_shared_and_condition","title":"test_condition.py::test_shared_and_condition","text":"<pre>test_condition.py::test_shared_and_condition</pre><pre>\nenv = \n\n    def test_shared_and_condition(env):\n        timeout = [env.timeout(delay, value=delay) for delay in range(3)]\n        c1 = timeout[0] &amp; timeout[1]\n        c2 = c1 &amp; timeout[2]\n\n        def p1(_, condition):\n            results = yield condition\n            assert results == {timeout[0]: 0, timeout[1]: 1}\n\n        def p2(_, condition):\n            results = yield condition\n            assert results == {timeout[0]: 0, timeout[1]: 1, timeout[2]: 2}\n\n        env.process(p1(env, c1))\n        env.process(p2(env, c2))\n&gt;       env.run()\n\ntests/test_condition.py:229: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_shared_or_condition","title":"test_condition.py::test_shared_or_condition","text":"<pre>test_condition.py::test_shared_or_condition</pre><pre>\nenv = \n\n    def test_shared_or_condition(env):\n        timeout = [env.timeout(delay, value=delay) for delay in range(3)]\n        c1 = timeout[0] | timeout[1]\n        c2 = c1 | timeout[2]\n\n        def p1(_, condition):\n            results = yield condition\n            assert results == {timeout[0]: 0}\n\n        def p2(_, condition):\n            results = yield condition\n            assert results == {timeout[0]: 0}\n\n        env.process(p1(env, c1))\n        env.process(p2(env, c2))\n&gt;       env.run()\n\ntests/test_condition.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_condition_value","title":"test_condition.py::test_condition_value","text":"<pre>test_condition.py::test_condition_value</pre><pre>\nenv = \n\n    def test_condition_value(env):\n        \"\"\"The value of a condition behaves like a readonly dictionary.\"\"\"\n        timeouts = [env.timeout(delay, value=delay) for delay in range(3)]\n\n        def p(env, timeouts):\n            results = yield env.all_of(timeouts)\n            assert list(results) == timeouts\n            assert list(results.keys()) == timeouts\n            assert list(results.values()) == [0, 1, 2]\n            assert list(results.items()) == list(zip(timeouts, [0, 1, 2]))\n            assert timeouts[0] in results\n            assert results[timeouts[0]] == 0\n            assert results == results  # noqa: PLR0124\n            assert results == results.todict()\n\n        env.process(p(env, timeouts))\n&gt;       env.run()\n\ntests/test_condition.py:266: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_result_order","title":"test_condition.py::test_result_order","text":"<pre>test_condition.py::test_result_order</pre><pre>\nenv = \n\n    def test_result_order(env):\n        \"\"\"The order of a conditions result is based on the order in which the\n        events have been specified.\"\"\"\n        timeouts = list(reversed([env.timeout(delay) for delay in range(3)]))\n\n        def p(env, timeouts):\n            results = yield env.all_of(timeouts)\n            assert list(results.keys()) == timeouts\n\n        env.process(p(env, timeouts))\n&gt;       env.run()\n\ntests/test_condition.py:279: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_conditionpytest_nested_result_order","title":"test_condition.py::test_nested_result_order","text":"<pre>test_condition.py::test_nested_result_order</pre><pre>\nenv = \n\n    def test_nested_result_order(env):\n        \"\"\"The order of a conditions result is based on the order in which the\n        events have been specified (even if nested).\"\"\"\n        timeouts = [env.timeout(delay) for delay in range(3)]\n        condition = (timeouts[0] | timeouts[1]) &amp; timeouts[2]\n\n        def p(_, timeouts):\n            results = yield condition\n            assert list(results.keys()) == timeouts\n\n        env.process(p(env, timeouts))\n&gt;       env.run()\n\ntests/test_condition.py:293: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_environmentpytest_event_queue_empty","title":"test_environment.py::test_event_queue_empty","text":"<pre>test_environment.py::test_event_queue_empty</pre><pre>\nenv = , log = []\n\n    def test_event_queue_empty(env, log):\n        \"\"\"The simulation should stop if there are no more events, that means, no\n        more active process.\"\"\"\n\n        def pem(env, log):\n            while env.now &lt; 2:\n                log.append(env.now)\n                yield env.timeout(1)\n\n        env.process(pem(env, log))\n&gt;       env.run(10)\n\ntests/test_environment.py:19: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_environmentpytest_run_negative_until","title":"test_environment.py::test_run_negative_until","text":"<pre>test_environment.py::test_run_negative_until</pre><pre>\nenv = \n\n    def test_run_negative_until(env):\n        \"\"\"Test passing a negative time to run.\"\"\"\n&gt;       with pytest.raises(\n            ValueError, match='must be greater than the current simulation time'\n        ):\nE       Failed: DID NOT RAISE \n\ntests/test_environment.py:26: Failed"},{"location":"analysis_baseline_simpy/#test_environmentpytest_run_resume","title":"test_environment.py::test_run_resume","text":"<pre>test_environment.py::test_run_resume</pre><pre>\nenv = \n\n    def test_run_resume(env):\n        \"\"\"Stopped simulation can be resumed.\"\"\"\n        events = [env.timeout(t) for t in (5, 10, 15)]\n\n        assert env.now == 0\n        assert not any(event.processed for event in events)\n\n&gt;       env.run(until=10)\n\ntests/test_environment.py:39: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Timeout' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_environmentpytest_run_until_value","title":"test_environment.py::test_run_until_value","text":"<pre>test_environment.py::test_run_until_value</pre><pre>\nenv = \n\n    def test_run_until_value(env):\n        \"\"\"Anything that can be converted to a float is a valid until value.\"\"\"\n&gt;       env.run(until='3.141592')\n\ntests/test_environment.py:56: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = , until = '3.141592'\n\n    def run(self, until: Optional[Union[SimTime, Event]]=None) -&gt;Optional[Any]:\n        \"\"\"Executes :meth:`step()` until the given criterion *until* is met.\n\n        - If it is ``None`` (which is the default), this method will return\n          when there are no further events to be processed.\n\n        - If it is an :class:`~simpy.events.Event`, the method will continue\n          stepping until this event has been triggered and will return its\n          value.  Raises a :exc:`RuntimeError` if there are no further events\n          to be processed and the *until* event was not triggered.\n\n        - If it is a number, the method will continue stepping\n          until the environment's time reaches *until*.\n\n        \"\"\"\n        if until is None:\n            while True:\n                try:\n                    self.step()\n                except EmptySchedule:\n                    return None\n        elif isinstance(until, Event):\n            until.callbacks.append(StopSimulation.callback)\n            try:\n                while not until.triggered:\n                    self.step()\n            except StopSimulation:\n                return until.value\n            except EmptySchedule:\n                if not until.triggered:\n                    raise RuntimeError('No scheduled events left but \"until\" event was not triggered')\n        elif isinstance(until, (int, float)):\n            try:\n                while self._now &lt; until:\n                    self.step()\n            except EmptySchedule:\n                return None\n        else:\n&gt;           raise ValueError('Invalid until parameter type')\nE           ValueError: Invalid until parameter type\n\nsrc/simpy/core.py:196: ValueError"},{"location":"analysis_baseline_simpy/#test_environmentpytest_run_with_processed_event","title":"test_environment.py::test_run_with_processed_event","text":"<pre>test_environment.py::test_run_with_processed_event</pre><pre>\nenv = \n\n    def test_run_with_processed_event(env):\n        \"\"\"An already processed event may also be passed as until value.\"\"\"\n        timeout = env.timeout(1, value='spam')\n&gt;       assert env.run(until=timeout) == 'spam'\nE       AssertionError: assert None == 'spam'\nE        +  where None = run(until=)\nE        +    where run = .run\n\ntests/test_environment.py:63: AssertionError"},{"location":"analysis_baseline_simpy/#test_environmentpytest_run_with_untriggered_event","title":"test_environment.py::test_run_with_untriggered_event","text":"<pre>test_environment.py::test_run_with_untriggered_event</pre><pre>\nenv = \n\n    def test_run_with_untriggered_event(env):\n        excinfo = pytest.raises(RuntimeError, env.run, until=env.event())\n&gt;       assert str(excinfo.value).startswith(\n            'No scheduled events left but \"until\" event was not triggered:'\n        )\nE       assert False\nE        +  where False = ('No scheduled events left but \"until\" event was not triggered:')\nE        +    where  = 'No scheduled events left but \"until\" event was not triggered'.startswith\nE        +      where 'No scheduled events left but \"until\" event was not triggered' = str(RuntimeError('No scheduled events left but \"until\" event was not triggered'))\nE        +        where RuntimeError('No scheduled events left but \"until\" event was not triggered') = .value\n\ntests/test_environment.py:75: AssertionError"},{"location":"analysis_baseline_simpy/#test_eventpytest_succeed","title":"test_event.py::test_succeed","text":"<pre>test_event.py::test_succeed</pre><pre>\nenv = \n\n    def test_succeed(env):\n        \"\"\"Test for the Environment.event() helper function.\"\"\"\n\n        def child(env, event):\n            value = yield event\n            assert value == 'ohai'\n            assert env.now == 5\n\n        def parent(env):\n            event = env.event()\n            env.process(child(env, event))\n            yield env.timeout(5)\n            event.succeed('ohai')\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_event.py:26: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_eventpytest_fail","title":"test_event.py::test_fail","text":"<pre>test_event.py::test_fail</pre><pre>\nenv = \n\n    def test_fail(env):\n        \"\"\"Test for the Environment.event() helper function.\"\"\"\n\n        def child(env, event):\n            with pytest.raises(ValueError, match='ohai'):\n                yield event\n            assert env.now == 5\n\n        def parent(env):\n            event = env.event()\n            env.process(child(env, event))\n            yield env.timeout(5)\n            event.fail(ValueError('ohai'))\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_event.py:44: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_eventpytest_value","title":"test_event.py::test_value","text":"<pre>test_event.py::test_value</pre><pre>\nenv = \n\n    def test_value(env):\n        \"\"\"After an event has been triggered, its value becomes accessible.\"\"\"\n        event = env.timeout(0, 'I am the value')\n\n&gt;       env.run()\n\ntests/test_event.py:72: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Timeout' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_eventpytest_unavailable_value","title":"test_event.py::test_unavailable_value","text":"<pre>test_event.py::test_unavailable_value</pre><pre>\nenv = \n\n    def test_unavailable_value(env):\n        \"\"\"If an event has not yet been triggered, its value is not available and\n        trying to access it will result in a AttributeError.\"\"\"\n        event = env.event()\n\n        with pytest.raises(AttributeError, match='.* is not yet available$'):\n&gt;           _ = event.value\n\ntests/test_event.py:83: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    @property\n    def value(self) -&gt;Optional[Any]:\n        \"\"\"The value of the event if it is available.\n\n        The value is available when the event has been triggered.\n\n        Raises :exc:`AttributeError` if the value is not yet available.\n\n        \"\"\"\n        if self._value is PENDING:\n&gt;           raise AttributeError('Value not yet available')\nE           AttributeError: Value not yet available. Did you mean: '_value'?\n\nsrc/simpy/events.py:132: AttributeError\n\nDuring handling of the above exception, another exception occurred:\n\nenv = \n\n    def test_unavailable_value(env):\n        \"\"\"If an event has not yet been triggered, its value is not available and\n        trying to access it will result in a AttributeError.\"\"\"\n        event = env.event()\n\n&gt;       with pytest.raises(AttributeError, match='.* is not yet available$'):\nE       AssertionError: Regex pattern did not match.\nE        Regex: '.* is not yet available$'\nE        Input: 'Value not yet available'\n\ntests/test_event.py:82: AssertionError"},{"location":"analysis_baseline_simpy/#test_eventpytest_triggered","title":"test_event.py::test_triggered","text":"<pre>test_event.py::test_triggered</pre><pre>\nenv = \n\n    def test_triggered(env):\n        def pem(env, event):\n            value = yield event\n            return value\n\n        event = env.event()\n        event.succeed('i was already done')\n\n&gt;       result = env.run(env.process(pem(env, event)))\n\ntests/test_event.py:94: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:183: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_eventpytest_condition_callback_removal","title":"test_event.py::test_condition_callback_removal","text":"<pre>test_event.py::test_condition_callback_removal</pre><pre>\nenv = \n\n    def test_condition_callback_removal(env):\n        \"\"\"A condition will remove all outstanding callbacks from its events.\"\"\"\n        a, b = env.event(), env.event()\n        a.succeed()\n&gt;       env.run(until=a | b)\n\ntests/test_event.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:183: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Event' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_eventpytest_condition_nested_callback_removal","title":"test_event.py::test_condition_nested_callback_removal","text":"<pre>test_event.py::test_condition_nested_callback_removal</pre><pre>\nenv = \n\n    def test_condition_nested_callback_removal(env):\n        \"\"\"A condition will remove all outstanding callbacks from its events (even\n        if nested).\"\"\"\n        a, b, c = env.event(), env.event(), env.event()\n        b_and_c = b &amp; c\n        a_or_b_and_c = a | b_and_c\n        a.succeed()\n&gt;       env.run(until=a_or_b_and_c)\n\ntests/test_event.py:129: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:183: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Event' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_exceptionspytest_error_forwarding","title":"test_exceptions.py::test_error_forwarding","text":"<pre>test_exceptions.py::test_error_forwarding</pre><pre>\nenv = \n\n    def test_error_forwarding(env):\n        \"\"\"Exceptions are forwarded from child to parent processes if there\n        are any.\n\n        \"\"\"\n\n        def child(env):\n            raise ValueError('Onoes!')\n            yield env.timeout(1)\n\n        def parent(env):\n            with pytest.raises(ValueError, match='Onoes!'):\n                yield env.process(child(env))\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_exceptions.py:28: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_exceptionspytest_no_parent_process","title":"test_exceptions.py::test_no_parent_process","text":"<pre>test_exceptions.py::test_no_parent_process</pre><pre>\nenv = \n\n    def test_no_parent_process(env):\n        \"\"\"Exceptions should be normally raised if there are no processes waiting\n        for the one that raises something.\n\n        \"\"\"\n\n        def child(env):\n            raise ValueError('Onoes!')\n            yield env.timeout(1)\n\n        def parent(env):\n            try:\n                env.process(child(env))\n                yield env.timeout(1)\n            except Exception as err:\n                pytest.fail(f'There should be no error ({err}).')\n\n        env.process(parent(env))\n        with pytest.raises(ValueError, match='Onoes!'):\n&gt;           env.run()\n\ntests/test_exceptions.py:50: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_exceptionspytest_crashing_child_traceback","title":"test_exceptions.py::test_crashing_child_traceback","text":"<pre>test_exceptions.py::test_crashing_child_traceback</pre><pre>\nenv = \n\n    def test_crashing_child_traceback(env):\n        def panic(env):\n            yield env.timeout(1)\n            raise RuntimeError('Oh noes, roflcopter incoming... BOOM!')\n\n        def root(env):\n            try:\n                yield env.process(panic(env))\n                pytest.fail(\"Hey, where's the roflcopter?\")\n            except RuntimeError:\n                # The current frame must be visible in the stacktrace.\n                stacktrace = traceback.format_exc()\n                assert 'yield env.process(panic(env))' in stacktrace\n                assert \"raise RuntimeError('Oh noes,\" in stacktrace\n\n        env.process(root(env))\n&gt;       env.run()\n\ntests/test_exceptions.py:69: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_exceptionspytest_exception_chaining","title":"test_exceptions.py::test_exception_chaining","text":"<pre>test_exceptions.py::test_exception_chaining</pre><pre>\nenv = \n\n    def test_exception_chaining(env):\n        \"\"\"Unhandled exceptions pass through the entire event stack. This must be\n        visible in the stacktrace of the exception.\n\n        \"\"\"\n\n        def child(env):\n            yield env.timeout(1)\n            raise RuntimeError('foo')\n\n        def parent(env):\n            child_proc = env.process(child(env))\n            yield child_proc\n\n        def grandparent(env):\n            parent_proc = env.process(parent(env))\n            yield parent_proc\n\n        env.process(grandparent(env))\n        try:\n&gt;           env.run()\n\ntests/test_exceptions.py:92: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_exceptionspytest_invalid_event","title":"test_exceptions.py::test_invalid_event","text":"<pre>test_exceptions.py::test_invalid_event</pre><pre>\nenv = \n\n    def test_invalid_event(env):\n        \"\"\"Invalid yield values will cause the simulation to fail.\"\"\"\n\n        def root(_):\n            yield None\n\n        env.process(root(env))\n        with pytest.raises(RuntimeError, match='Invalid yield value \"None\"'):\n&gt;           env.run()\n\ntests/test_exceptions.py:151: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_exceptionspytest_exception_handling","title":"test_exceptions.py::test_exception_handling","text":"<pre>test_exceptions.py::test_exception_handling</pre><pre>\nenv = \n\n    def test_exception_handling(env):\n        \"\"\"If failed events are not defused (which is the default) the simulation\n        crashes.\"\"\"\n\n        event = env.event()\n        event.fail(RuntimeError())\n        with pytest.raises(RuntimeError):\n&gt;           env.run(until=1)\n\ntests/test_exceptions.py:161: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Event' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_exceptionspytest_callback_exception_handling","title":"test_exceptions.py::test_callback_exception_handling","text":"<pre>test_exceptions.py::test_callback_exception_handling</pre><pre>\nenv = \n\n    def test_callback_exception_handling(env):\n        \"\"\"Callbacks of events may handle exception by setting the ``defused``\n        attribute of ``event`` to ``True``.\"\"\"\n\n        def callback(event):\n            event.defused = True\n\n        event = env.event()\n        event.callbacks.append(callback)\n        event.fail(RuntimeError())\n        assert not event.defused, 'Event has been defused immediately'\n&gt;       env.run(until=1)\n\ntests/test_exceptions.py:175: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Event' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_exceptionspytest_process_exception_handling","title":"test_exceptions.py::test_process_exception_handling","text":"<pre>test_exceptions.py::test_process_exception_handling</pre><pre>\nenv = \n\n    def test_process_exception_handling(env):\n        \"\"\"Processes can't ignore failed events and auto-handle exceptions.\"\"\"\n\n        def pem(_, event):\n            try:\n                yield event\n                pytest.fail('Hey, the event should fail!')\n            except RuntimeError:\n                pass\n\n        event = env.event()\n        env.process(pem(env, event))\n        event.fail(RuntimeError())\n\n        assert not event.defused, 'Event has been defused immediately'\n&gt;       env.run(until=1)\n\ntests/test_exceptions.py:194: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_exceptionspytest_process_exception_chaining","title":"test_exceptions.py::test_process_exception_chaining","text":"<pre>test_exceptions.py::test_process_exception_chaining</pre><pre>\nenv = \n\n    def test_process_exception_chaining(env):\n        \"\"\"Because multiple processes can be waiting for an event, exceptions of\n        failed events are copied before being thrown into a process. Otherwise, the\n        traceback of the exception gets modified by a process.\n\n        See https://bitbucket.org/simpy/simpy/issue/60 for more details.\"\"\"\n        import traceback\n\n        def process_a(event):\n            try:\n                yield event\n            except RuntimeError:\n                stacktrace = traceback.format_exc()\n                assert 'process_b' not in stacktrace\n\n        def process_b(event):\n            try:\n                yield event\n            except RuntimeError:\n                stacktrace = traceback.format_exc()\n                assert 'process_a' not in stacktrace\n\n        event = env.event()\n        event.fail(RuntimeError('foo'))\n\n        env.process(process_a(event))\n        env.process(process_b(event))\n\n&gt;       env.run()\n\ntests/test_exceptions.py:226: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_exceptionspytest_sys_excepthook","title":"test_exceptions.py::test_sys_excepthook","text":"<pre>test_exceptions.py::test_sys_excepthook</pre><pre>\nenv = \n\n    def test_sys_excepthook(env):\n        \"\"\"Check that the default exception hook reports exception chains.\"\"\"\n\n        def process_a(event):\n            yield event\n\n        def process_b(event):\n            yield event\n\n        event = env.event()\n        event.fail(RuntimeError('foo'))\n\n        env.process(process_b(env.process(process_a(event))))\n\n        try:\n&gt;           env.run()\n\ntests/test_exceptions.py:244: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError\n\nDuring handling of the above exception, another exception occurred:\n\nenv = \n\n    def test_sys_excepthook(env):\n        \"\"\"Check that the default exception hook reports exception chains.\"\"\"\n\n        def process_a(event):\n            yield event\n\n        def process_b(event):\n            yield event\n\n        event = env.event()\n        event.fail(RuntimeError('foo'))\n\n        env.process(process_b(env.process(process_a(event))))\n\n        try:\n            env.run()\n        except BaseException:\n            # Let the default exception hook print the traceback to the redirected\n            # standard error channel.\n            import sys\n            from io import StringIO\n\n            stderr, sys.stderr = sys.stderr, StringIO()\n\n            typ, e, tb = sys.exc_info()\n            assert typ is not None\n            assert e is not None\n            sys.excepthook(typ, e, tb)\n\n            traceback = sys.stderr.getvalue()\n\n            sys.stderr = stderr\n\n            # Check if frames of process_a and process_b are visible in the\n            # traceback.\n&gt;           assert 'process_a' in traceback\nE           assert 'process_a' in 'Traceback (most recent call last):\\n  File \"/testbed/tests/test_exceptions.py\", line 244, in test_sys_excepthook\\n   ..._callback(event)\\nAttributeError: \\'Initialize\\' object has no attribute \\'_callback\\'. Did you mean: \\'callbacks\\'?\\n'\n\ntests/test_exceptions.py:264: AssertionError"},{"location":"analysis_baseline_simpy/#test_interruptspytest_interruption","title":"test_interrupts.py::test_interruption","text":"<pre>test_interrupts.py::test_interruption</pre><pre>\nenv = \n\n    def test_interruption(env):\n        \"\"\"Processes can be interrupted while waiting for other events.\"\"\"\n\n        def interruptee(env):\n            with pytest.raises(simpy.Interrupt, match='interrupt!'):\n                yield env.timeout(10)\n\n        def interruptor(env):\n            child_process = env.process(interruptee(env))\n            yield env.timeout(5)\n            child_process.interrupt('interrupt!')\n\n        env.process(interruptor(env))\n&gt;       env.run()\n\ntests/test_interrupts.py:25: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_interruptspytest_concurrent_interrupts","title":"test_interrupts.py::test_concurrent_interrupts","text":"<pre>test_interrupts.py::test_concurrent_interrupts</pre><pre>\nenv = , log = []\n\n    def test_concurrent_interrupts(env, log):\n        \"\"\"Concurrent interrupts are scheduled in the order in which they\n        occurred.\n\n        \"\"\"\n\n        def fox(env, log):\n            while True:\n                try:\n                    yield env.timeout(10)\n                except simpy.Interrupt as interrupt:\n                    log.append((env.now, interrupt.cause))\n\n        def farmer(env, name, fox):\n            fox.interrupt(name)\n            yield env.timeout(1)\n\n        fantastic_mr_fox = env.process(fox(env, log))\n        for name in ('boggis', 'bunce', 'beans'):\n            env.process(farmer(env, name, fantastic_mr_fox))\n\n&gt;       env.run(20)\n\ntests/test_interrupts.py:49: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_interruptspytest_concurrent_interrupts_and_events","title":"test_interrupts.py::test_concurrent_interrupts_and_events","text":"<pre>test_interrupts.py::test_concurrent_interrupts_and_events</pre><pre>\nenv = , log = []\n\n    def test_concurrent_interrupts_and_events(env, log):\n        \"\"\"Interrupts interrupt a process while waiting for an event. Even if the\n        event has happened concurrently with the interrupt.\"\"\"\n\n        def fox(env, coup, log):\n            while True:\n                try:\n                    yield coup\n                    log.append(f'coup completed at {env.now}')\n                except simpy.Interrupt:\n                    log.append(f'coup interrupted at {env.now}')\n                else:\n                    return\n\n        def master_plan(env, fox, coup):\n            yield env.timeout(1)\n            # Succeed and interrupt concurrently.\n            coup.succeed()\n            fox.interrupt()\n\n        coup = env.event()\n        fantastic_mr_fox = env.process(fox(env, coup, log))\n        env.process(master_plan(env, fantastic_mr_fox, coup))\n\n&gt;       env.run(5)\n\ntests/test_interrupts.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_interruptspytest_init_interrupt","title":"test_interrupts.py::test_init_interrupt","text":"<pre>test_interrupts.py::test_init_interrupt</pre><pre>\nenv = \n\n    def test_init_interrupt(env):\n        \"\"\"An interrupt should always be executed after the Initialize event at the\n        same time.\"\"\"\n\n        def child(env):\n            try:\n                yield env.timeout(10)\n                pytest.fail('Should have been interrupted.')\n            except simpy.Interrupt:\n                assert env.now == 0\n\n        def root(env):\n            child_proc = env.process(child(env))\n            child_proc.interrupt()\n\n            yield env.timeout(1)\n\n        env.process(root(env))\n&gt;       env.run()\n\ntests/test_interrupts.py:99: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_interruptspytest_interrupt_terminated_process","title":"test_interrupts.py::test_interrupt_terminated_process","text":"<pre>test_interrupts.py::test_interrupt_terminated_process</pre><pre>\nenv = \n\n    def test_interrupt_terminated_process(env):\n        \"\"\"Dead processes cannot be interrupted.\"\"\"\n\n        def child(env):\n            yield env.timeout(1)\n\n        def parent(env):\n            child_proc = env.process(child(env))\n\n            # Wait long enough so that child_proc terminates.\n            yield env.timeout(2)\n            ei = pytest.raises(RuntimeError, child_proc.interrupt)\n            assert re.match(\n                r' has terminated '\n                r'and cannot be interrupted.',\n                ei.value.args[0],\n            )\n\n            yield env.timeout(1)\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_interrupts.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_interruptspytest_multiple_interrupts","title":"test_interrupts.py::test_multiple_interrupts","text":"<pre>test_interrupts.py::test_multiple_interrupts</pre><pre>\nenv = \n\n    def test_multiple_interrupts(env):\n        \"\"\"Interrupts on dead processes are discarded. If there are multiple\n        concurrent interrupts on a process and the latter dies after\n        handling the first interrupt, the remaining ones are silently\n        ignored.\n\n        \"\"\"\n\n        def child(env):\n            try:\n                yield env.timeout(1)\n            except simpy.Interrupt as i:\n                return i.cause\n\n        def parent(env):\n            c = env.process(child(env))\n            yield env.timeout(0)\n            c.interrupt(1)\n            c.interrupt(2)\n            result = yield c\n            assert result == 1\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_interrupts.py:149: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_interruptspytest_interrupt_self","title":"test_interrupts.py::test_interrupt_self","text":"<pre>test_interrupts.py::test_interrupt_self</pre><pre>\nenv = \n\n    def test_interrupt_self(env):\n        \"\"\"A process should not be able to interrupt itself.\"\"\"\n\n        def pem(env):\n            pytest.raises(RuntimeError, env.active_process.interrupt)\n            yield env.timeout(0)\n\n        env.process(pem(env))\n&gt;       env.run()\n\ntests/test_interrupts.py:160: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_interruptspytest_immediate_interrupt","title":"test_interrupts.py::test_immediate_interrupt","text":"<pre>test_interrupts.py::test_immediate_interrupt</pre><pre>\nenv = , log = []\n\n    def test_immediate_interrupt(env, log):\n        \"\"\"Processes are immediately interruptable.\"\"\"\n\n        def child(env, log):\n            try:\n                yield env.event()\n            except simpy.Interrupt:\n                log.append(env.now)\n\n        def parent(env, log):\n            child_proc = env.process(child(env, log))\n            child_proc.interrupt()\n            return\n            yield\n\n        env.process(parent(env, log))\n&gt;       env.run()\n\ntests/test_interrupts.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_interruptspytest_interrupt_event","title":"test_interrupts.py::test_interrupt_event","text":"<pre>test_interrupts.py::test_interrupt_event</pre><pre>\nenv = \n\n    def test_interrupt_event(env):\n        \"\"\"A process should be interruptable while waiting for an Event.\"\"\"\n\n        def child(env):\n            try:\n                yield env.event()\n            except simpy.Interrupt:\n                assert env.now == 5\n\n        def parent(env):\n            child_proc = env.process(child(env))\n            yield env.timeout(5)\n            child_proc.interrupt()\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_interrupts.py:200: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_interruptspytest_concurrent_behaviour","title":"test_interrupts.py::test_concurrent_behaviour","text":"<pre>test_interrupts.py::test_concurrent_behaviour</pre><pre>\nenv = \n\n    def test_concurrent_behaviour(env):\n        def proc_a(env):\n            timeouts = [env.timeout(0) for i in range(2)]\n            while timeouts:\n                with pytest.raises(simpy.Interrupt):\n                    yield timeouts.pop(0)\n\n        def proc_b(_, proc_a):\n            for _ in range(2):\n                proc_a.interrupt()\n            return\n            yield\n\n        proc_a = env.process(proc_a(env))\n        env.process(proc_b(env, proc_a))\n\n&gt;       env.run()\n\ntests/test_interrupts.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_processpytest_get_state","title":"test_process.py::test_get_state","text":"<pre>test_process.py::test_get_state</pre><pre>\nenv = \n\n    def test_get_state(env):\n        \"\"\"A process is alive until it's generator has not terminated.\"\"\"\n\n        def pem_a(env):\n            yield env.timeout(3)\n\n        def pem_b(env, pem_a):\n            yield env.timeout(1)\n            assert pem_a.is_alive\n\n            yield env.timeout(3)\n            assert not pem_a.is_alive\n\n        proc_a = env.process(pem_a(env))\n        env.process(pem_b(env, proc_a))\n&gt;       env.run()\n\ntests/test_process.py:36: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_processpytest_target","title":"test_process.py::test_target","text":"<pre>test_process.py::test_target</pre><pre>\nenv = \n\n    def test_target(env):\n        def pem(env, event):\n            yield event\n\n        event = env.timeout(5)\n        proc = env.process(pem(env, event))\n\n        # Wait until \"proc\" is initialized and yielded the event\n        while env.peek() &lt; 5:\n&gt;           env.step()\n\ntests/test_process.py:48: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_processpytest_wait_for_proc","title":"test_process.py::test_wait_for_proc","text":"<pre>test_process.py::test_wait_for_proc</pre><pre>\nenv = \n\n    def test_wait_for_proc(env):\n        \"\"\"A process can wait until another process finishes.\"\"\"\n\n        def finisher(env):\n            yield env.timeout(5)\n\n        def waiter(env, finisher):\n            proc = env.process(finisher(env))\n            yield proc  # Waits until \"proc\" finishes\n\n            assert env.now == 5\n\n        env.process(waiter(env, finisher))\n&gt;       env.run()\n\ntests/test_process.py:66: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_processpytest_return_value","title":"test_process.py::test_return_value","text":"<pre>test_process.py::test_return_value</pre><pre>\nenv = \n\n    def test_return_value(env):\n        \"\"\"Processes can set a return value.\"\"\"\n\n        def child(env):\n            yield env.timeout(1)\n            return env.now\n\n        def parent(env):\n            result1 = yield env.process(child(env))\n            result2 = yield env.process(child(env))\n\n            assert [result1, result2] == [1, 2]\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_process.py:83: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_processpytest_child_exception","title":"test_process.py::test_child_exception","text":"<pre>test_process.py::test_child_exception</pre><pre>\nenv = \n\n    def test_child_exception(env):\n        \"\"\"A child catches an exception and sends it to its parent.\"\"\"\n\n        def child(env):\n            yield env.timeout(1)\n            return RuntimeError('Onoes!')\n\n        def parent(env):\n            result = yield env.process(child(env))\n            assert isinstance(result, Exception)\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_process.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_processpytest_interrupted_join","title":"test_process.py::test_interrupted_join","text":"<pre>test_process.py::test_interrupted_join</pre><pre>\nenv = \n\n    def test_interrupted_join(env):\n        \"\"\"Interrupts remove a process from the callbacks of its target.\"\"\"\n\n        def interruptor(env, process):\n            yield env.timeout(1)\n            process.interrupt()\n\n        def child(env):\n            yield env.timeout(2)\n\n        def parent(env):\n            child_proc = env.process(child(env))\n            try:\n                yield child_proc\n                pytest.fail('Did not receive an interrupt.')\n            except Interrupt:\n                assert env.now == 1\n                assert child_proc.is_alive\n\n                # We should not get resumed when child terminates.\n                yield env.timeout(5)\n                assert env.now == 6\n\n        parent_proc = env.process(parent(env))\n        env.process(interruptor(env, parent_proc))\n&gt;       env.run()\n\ntests/test_process.py:126: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_processpytest_interrupted_join_and_rejoin","title":"test_process.py::test_interrupted_join_and_rejoin","text":"<pre>test_process.py::test_interrupted_join_and_rejoin</pre><pre>\nenv = \n\n    def test_interrupted_join_and_rejoin(env):\n        \"\"\"Tests that interrupts are raised while the victim is waiting for\n        another process. The victim tries to join again.\n\n        \"\"\"\n\n        def interruptor(env, process):\n            yield env.timeout(1)\n            process.interrupt()\n\n        def child(env):\n            yield env.timeout(2)\n\n        def parent(env):\n            child_proc = env.process(child(env))\n            try:\n                yield child_proc\n                pytest.fail('Did not receive an interrupt.')\n            except Interrupt:\n                assert env.now == 1\n                assert child_proc.is_alive\n\n                yield child_proc\n                assert env.now == 2\n\n        parent_proc = env.process(parent(env))\n        env.process(interruptor(env, parent_proc))\n&gt;       env.run()\n\ntests/test_process.py:156: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_resource","title":"test_resources.py::test_resource","text":"<pre>test_resources.py::test_resource</pre><pre>\nenv = , log = []\n\n    def test_resource(env, log):\n        \"\"\"A *resource* is something with a limited numer of slots that need\n        to be requested before and released after the usage (e.g., gas pumps\n        at a gas station).\n\n        \"\"\"\n\n        def pem(env, name, resource, log):\n            req = resource.request()\n            yield req\n            assert resource.count == 1\n\n            yield env.timeout(1)\n            resource.release(req)\n\n            log.append((name, env.now))\n\n        resource = simpy.Resource(env, capacity=1)\n        assert resource.capacity == 1\n        assert resource.count == 0\n        env.process(pem(env, 'a', resource, log))\n        env.process(pem(env, 'b', resource, log))\n&gt;       env.run()\n\ntests/test_resources.py:38: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_resource_context_manager","title":"test_resources.py::test_resource_context_manager","text":"<pre>test_resources.py::test_resource_context_manager</pre><pre>\nenv = , log = []\n\n    def test_resource_context_manager(env, log):\n        \"\"\"The event that ``Resource.request()`` returns can be used as\n        Context Manager.\"\"\"\n\n        def pem(env, name, resource, log):\n            with resource.request() as request:\n                yield request\n                yield env.timeout(1)\n\n            log.append((name, env.now))\n\n        resource = simpy.Resource(env, capacity=1)\n        env.process(pem(env, 'a', resource, log))\n        env.process(pem(env, 'b', resource, log))\n&gt;       env.run()\n\ntests/test_resources.py:62: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_resource_slots","title":"test_resources.py::test_resource_slots","text":"<pre>test_resources.py::test_resource_slots</pre><pre>\nenv = , log = []\n\n    def test_resource_slots(env, log):\n        def pem(env, name, resource, log):\n            with resource.request() as req:\n                yield req\n                log.append((name, env.now))\n                yield env.timeout(1)\n\n        resource = simpy.Resource(env, capacity=3)\n        for i in range(9):\n            env.process(pem(env, str(i), resource, log))\n&gt;       env.run()\n\ntests/test_resources.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_resource_continue_after_interrupt","title":"test_resources.py::test_resource_continue_after_interrupt","text":"<pre>test_resources.py::test_resource_continue_after_interrupt</pre><pre>\nenv = \n\n    def test_resource_continue_after_interrupt(env):\n        \"\"\"A process may be interrupted while waiting for a resource but\n        should be able to continue waiting afterwards.\"\"\"\n\n        def pem(env, res):\n            with res.request() as req:\n                yield req\n                yield env.timeout(1)\n\n        def victim(env, res):\n            evt = res.request()\n            try:\n                yield evt\n                pytest.fail('Should not have gotten the resource.')\n            except simpy.Interrupt:\n                yield evt\n                res.release(evt)\n                assert env.now == 1\n\n        def interruptor(proc):\n            proc.interrupt()\n            return 0\n            yield\n\n        res = simpy.Resource(env, 1)\n        env.process(pem(env, res))\n        proc = env.process(victim(env, res))\n        env.process(interruptor(proc))\n&gt;       env.run()\n\ntests/test_resources.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_resource_release_after_interrupt","title":"test_resources.py::test_resource_release_after_interrupt","text":"<pre>test_resources.py::test_resource_release_after_interrupt</pre><pre>\nenv = \n\n    def test_resource_release_after_interrupt(env):\n        \"\"\"A process needs to release a resource, even if it was interrupted\n        and does not continue to wait for it.\"\"\"\n\n        def blocker(env, res):\n            with res.request() as req:\n                yield req\n                yield env.timeout(1)\n\n        def victim(env, res):\n            evt = res.request()\n            try:\n                yield evt\n                pytest.fail('Should not have gotten the resource.')\n            except simpy.Interrupt:\n                # Don't wait for the resource\n                res.release(evt)\n                assert env.now == 0\n\n        def interruptor(proc):\n            proc.interrupt()\n            return 0\n            yield\n\n        res = simpy.Resource(env, 1)\n        env.process(blocker(env, res))\n        victim_proc = env.process(victim(env, res))\n        env.process(interruptor(victim_proc))\n&gt;       env.run()\n\ntests/test_resources.py:151: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_resource_immediate_requests","title":"test_resources.py::test_resource_immediate_requests","text":"<pre>test_resources.py::test_resource_immediate_requests</pre><pre>\nenv = \n\n    def test_resource_immediate_requests(env):\n        \"\"\"A process must not acquire a resource if it releases it and immediately\n        requests it again while there are already other requesting processes.\"\"\"\n\n        def child(env, res):\n            result = []\n            for _ in range(3):\n                with res.request() as req:\n                    yield req\n                    result.append(env.now)\n                    yield env.timeout(1)\n            return result\n\n        def parent(env):\n            res = simpy.Resource(env, 1)\n            child_a = env.process(child(env, res))\n            child_b = env.process(child(env, res))\n\n            a_acquire_times = yield child_a\n            b_acquire_times = yield child_b\n\n            assert a_acquire_times == [0, 2, 4]\n            assert b_acquire_times == [1, 3, 5]\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_resources.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_resource_cm_exception","title":"test_resources.py::test_resource_cm_exception","text":"<pre>test_resources.py::test_resource_cm_exception</pre><pre>\nenv = , log = []\n\n    def test_resource_cm_exception(env, log):\n        \"\"\"Resource with context manager receives an exception.\"\"\"\n\n        def process(env, resource, log, raise_):\n            with resource.request() as req:\n                yield req\n                yield env.timeout(1)\n                log.append(env.now)\n                if raise_:\n                    with pytest.raises(ValueError, match='Foo'):\n                        raise ValueError('Foo')\n\n        resource = simpy.Resource(env, 1)\n        env.process(process(env, resource, log, True))\n        # The second process is used to check if it was able to access the\n        # resource:\n        env.process(process(env, resource, log, False))\n&gt;       env.run()\n\ntests/test_resources.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_resource_with_condition","title":"test_resources.py::test_resource_with_condition","text":"<pre>test_resources.py::test_resource_with_condition</pre><pre>\nenv = \n\n    def test_resource_with_condition(env):\n        def process(env, resource):\n            with resource.request() as res_event:\n                result = yield res_event | env.timeout(1)\n                assert res_event in result\n\n        resource = simpy.Resource(env, 1)\n        env.process(process(env, resource))\n&gt;       env.run()\n\ntests/test_resources.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_resource_with_priority_queue","title":"test_resources.py::test_resource_with_priority_queue","text":"<pre>test_resources.py::test_resource_with_priority_queue</pre><pre>\nenv = \n\n    def test_resource_with_priority_queue(env):\n        def process(env, delay, resource, priority, res_time):\n            yield env.timeout(delay)\n            req = resource.request(priority=priority)\n            yield req\n            assert env.now == res_time\n            yield env.timeout(5)\n            resource.release(req)\n\n        resource = simpy.PriorityResource(env, capacity=1)\n        env.process(process(env, 0, resource, 2, 0))\n        env.process(process(env, 2, resource, 3, 10))\n        env.process(process(env, 2, resource, 3, 15))  # Test equal priority\n        env.process(process(env, 4, resource, 1, 5))\n&gt;       env.run()\n\ntests/test_resources.py:229: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_sorted_queue_maxlen","title":"test_resources.py::test_sorted_queue_maxlen","text":"<pre>test_resources.py::test_sorted_queue_maxlen</pre><pre>\nenv = \n\n    def test_sorted_queue_maxlen(env):\n        \"\"\"Requests must fail if more than *maxlen* requests happen\n        concurrently.\"\"\"\n        resource = simpy.PriorityResource(env, capacity=1)\n        resource.put_queue.maxlen = 1  # pyright: ignore\n\n        def process(env, resource):\n            # The first request immediately triggered and does not enter the queue.\n            resource.request(priority=1)\n            # The second request is enqueued.\n            resource.request(priority=1)\n            with pytest.raises(RuntimeError, match='Cannot append event. Queue is full.'):\n                # The third request will now fail.\n                resource.request(priority=1)\n            yield env.timeout(0)\n\n        env.process(process(env, resource))\n&gt;       env.run()\n\ntests/test_resources.py:249: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_get_users","title":"test_resources.py::test_get_users","text":"<pre>test_resources.py::test_get_users</pre><pre>\nenv = \n\n    def test_get_users(env):\n        def process(env, resource):\n            with resource.request() as req:\n                yield req\n                yield env.timeout(1)\n\n        resource = simpy.Resource(env, 1)\n        procs = [env.process(process(env, resource)) for _ in range(3)]\n&gt;       env.run(until=1)\n\ntests/test_resources.py:260: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_preemptive_resource","title":"test_resources.py::test_preemptive_resource","text":"<pre>test_resources.py::test_preemptive_resource</pre><pre>\nenv = \n\n    def test_preemptive_resource(env):\n        \"\"\"Processes with a higher priority may preempt requests of lower priority\n        processes. Note that higher priorities are indicated by a lower number\n        value.\"\"\"\n\n        def proc_a(_, resource, prio):\n            try:\n                with resource.request(priority=prio) as req:\n                    yield req\n                    pytest.fail('Should have received an interrupt/preemption.')\n            except simpy.Interrupt:\n                pass\n\n        def proc_b(_, resource, prio):\n            with resource.request(priority=prio) as req:\n                yield req\n\n        resource = simpy.PreemptiveResource(env, 1)\n        env.process(proc_a(env, resource, 1))\n        env.process(proc_b(env, resource, 0))\n\n&gt;       env.run()\n\ntests/test_resources.py:293: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_preemptive_resource_timeout_0","title":"test_resources.py::test_preemptive_resource_timeout_0","text":"<pre>test_resources.py::test_preemptive_resource_timeout_0</pre><pre>\nenv = \n\n    def test_preemptive_resource_timeout_0(env):\n        def proc_a(env, resource, prio):\n            with resource.request(priority=prio) as req:\n                try:\n                    yield req\n                    yield env.timeout(1)\n                    pytest.fail('Should have received an interrupt/preemption.')\n                except simpy.Interrupt:\n                    pass\n            yield env.event()\n\n        def proc_b(_, resource, prio):\n            with resource.request(priority=prio) as req:\n                yield req\n\n        resource = simpy.PreemptiveResource(env, 1)\n        env.process(proc_a(env, resource, 1))\n        env.process(proc_b(env, resource, 0))\n\n&gt;       env.run()\n\ntests/test_resources.py:315: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_mixed_preemption","title":"test_resources.py::test_mixed_preemption","text":"<pre>test_resources.py::test_mixed_preemption</pre><pre>\nenv = , log = []\n\n    def test_mixed_preemption(env, log):\n        def p(id, env, res, delay, prio, preempt, log):\n            yield env.timeout(delay)\n            with res.request(priority=prio, preempt=preempt) as req:\n                try:\n                    yield req\n                    yield env.timeout(2)\n                    log.append((env.now, id))\n                except simpy.Interrupt as ir:\n                    assert ir is not None  # noqa: PT017\n                    assert isinstance(ir.cause, Preempted)  # noqa: PT017\n                    log.append((env.now, id, (ir.cause.by, ir.cause.usage_since)))\n\n        res = simpy.PreemptiveResource(env, 1)\n        # p0: First user:\n        env.process(p(0, env, res, delay=0, prio=2, preempt=True, log=log))\n        # p1: Waits (cannot preempt):\n        env.process(p(1, env, res, delay=0, prio=2, preempt=True, log=log))\n        # p2: Waits later, but has a higher prio:\n        env.process(p(2, env, res, delay=1, prio=1, preempt=False, log=log))\n        # p3: Preempt the above proc:\n        p3 = env.process(p(3, env, res, delay=3, prio=0, preempt=True, log=log))\n        # p4: Wait again:\n        env.process(p(4, env, res, delay=4, prio=3, preempt=True, log=log))\n\n&gt;       env.run()\n\ntests/test_resources.py:343: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_nested_preemption","title":"test_resources.py::test_nested_preemption","text":"<pre>test_resources.py::test_nested_preemption</pre><pre>\nenv = , log = []\n\n    def test_nested_preemption(env, log):\n        def process(id, env, res, delay, prio, preempt, log):\n            yield env.timeout(delay)\n            with res.request(priority=prio, preempt=preempt) as req:\n                try:\n                    yield req\n                    yield env.timeout(5)\n                    log.append((env.now, id))\n                except simpy.Interrupt as ir:\n                    assert isinstance(ir.cause, Preempted)  # noqa: PT017\n                    log.append((env.now, id, (ir.cause.by, ir.cause.usage_since)))\n\n        def process2(id, env, res0, res1, delay, prio, preempt, log):\n            yield env.timeout(delay)\n            with res0.request(priority=prio, preempt=preempt) as req0:\n                try:\n                    yield req0\n                    with res1.request(priority=prio, preempt=preempt) as req1:\n                        try:\n                            yield req1\n                            yield env.timeout(5)\n                            log.append((env.now, id))\n                        except simpy.Interrupt as ir:\n                            assert isinstance(ir.cause, Preempted)  # noqa: PT017\n                            log.append(\n                                (\n                                    env.now,\n                                    id,\n                                    (ir.cause.by, ir.cause.usage_since, ir.cause.resource),\n                                )\n                            )\n                except simpy.Interrupt as ir:\n                    assert isinstance(ir.cause, Preempted)  # noqa: PT017\n                    log.append(\n                        (\n                            env.now,\n                            id,\n                            (ir.cause.by, ir.cause.usage_since, ir.cause.resource),\n                        )\n                    )\n\n        res0 = simpy.PreemptiveResource(env, 1)\n        res1 = simpy.PreemptiveResource(env, 1)\n\n        env.process(process2(0, env, res0, res1, 0, -1, True, log))\n        p1 = env.process(process(1, env, res1, 1, -2, True, log))\n\n        env.process(process2(2, env, res0, res1, 20, -1, True, log))\n        p3 = env.process(process(3, env, res0, 21, -2, True, log))\n\n        env.process(process2(4, env, res0, res1, 21, -1, True, log))\n\n&gt;       env.run()\n\ntests/test_resources.py:406: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_container","title":"test_resources.py::test_container","text":"<pre>test_resources.py::test_container</pre><pre>\nenv = , log = []\n\n    def test_container(env, log):\n        \"\"\"A *container* is a resource (of optionally limited capacity) where\n        you can put in our take-out a discrete or continuous amount of\n        things (e.g., a box of lump sugar or a can of milk).  The *put* and\n        *get* operations block if the buffer is to full or to empty. If they\n        return, the process knows that the *put* or *get* operation was\n        successful.\n\n        \"\"\"\n\n        def putter(env, buf, log):\n            yield env.timeout(1)\n            while True:\n                yield buf.put(2)\n                log.append(('p', env.now))\n                yield env.timeout(1)\n\n        def getter(env, buf, log):\n            yield buf.get(1)\n            log.append(('g', env.now))\n\n            yield env.timeout(1)\n            yield buf.get(1)\n            log.append(('g', env.now))\n\n        buf = simpy.Container(env, init=0, capacity=2)\n        env.process(putter(env, buf, log))\n        env.process(getter(env, buf, log))\n&gt;       env.run(until=5)\n\ntests/test_resources.py:450: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_container_get_queued","title":"test_resources.py::test_container_get_queued","text":"<pre>test_resources.py::test_container_get_queued</pre><pre>\nenv = \n\n    def test_container_get_queued(env):\n        def proc(env, wait, container, what):\n            yield env.timeout(wait)\n            with getattr(container, what)(1) as req:\n                yield req\n\n        container = simpy.Container(env, 1)\n        p0 = env.process(proc(env, 0, container, 'get'))\n        env.process(proc(env, 1, container, 'put'))\n        env.process(proc(env, 1, container, 'put'))\n        p3 = env.process(proc(env, 1, container, 'put'))\n\n&gt;       env.run(until=1)\n\ntests/test_resources.py:467: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_store","title":"test_resources.py::test_store","text":"<pre>test_resources.py::test_store</pre><pre>\nenv = \n\n    def test_store(env):\n        \"\"\"A store models the production and consumption of concrete python\n        objects (in contrast to containers, where you only now if the *put*\n        or *get* operations were successful but don't get concrete\n        objects).\n\n        \"\"\"\n\n        def putter(_, store, item):\n            yield store.put(item)\n\n        def getter(_, store, orig_item):\n            item = yield store.get()\n            assert item is orig_item\n\n        store = simpy.Store(env, capacity=2)\n        item = object()\n\n        # NOTE: Does the start order matter? Need to test this.\n        env.process(putter(env, store, item))\n        env.process(getter(env, store, item))\n&gt;       env.run()\n\ntests/test_resources.py:535: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_store_capacity","title":"test_resources.py::test_store_capacity","text":"<pre>test_resources.py::test_store_capacity</pre><pre>\nenv = \n\n    def test_store_capacity(env):\n        with pytest.raises(ValueError, match='\"capacity\" must be &gt; 0'):\n            simpy.Store(env, 0)\n        with pytest.raises(ValueError, match='\"capacity\" must be &gt; 0'):\n            simpy.Store(env, -1)\n\n        capacity = 2\n        store = simpy.Store(env, capacity)\n        env.process(store.put(i) for i in range(capacity + 1))\n&gt;       env.run()\n\ntests/test_resources.py:559: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_store_cancel","title":"test_resources.py::test_store_cancel","text":"<pre>test_resources.py::test_store_cancel</pre><pre>\nenv = \n\n    def test_store_cancel(env):\n        store = simpy.Store(env, capacity=1)\n\n        def acquire_implicit_cancel():\n            with store.get():\n                yield env.timeout(1)\n                # implicit cancel() when exiting with-block\n\n        env.process(acquire_implicit_cancel())\n&gt;       env.run()\n\ntests/test_resources.py:574: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_priority_store_item_priority","title":"test_resources.py::test_priority_store_item_priority","text":"<pre>test_resources.py::test_priority_store_item_priority</pre><pre>\nenv = \n\n    def test_priority_store_item_priority(env):\n        pstore = simpy.PriorityStore(env, 3)\n        log = []\n\n        def getter(wait):\n            yield env.timeout(wait)\n            item = yield pstore.get()\n            log.append(item)\n\n        # Do not specify priority; the items themselves will be compared to\n        # determine priority.\n        env.process(pstore.put(s) for s in 'bcadefg')\n        env.process(getter(1))\n        env.process(getter(2))\n        env.process(getter(3))\n&gt;       env.run()\n\ntests/test_resources.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_priority_store_stable_order","title":"test_resources.py::test_priority_store_stable_order","text":"<pre>test_resources.py::test_priority_store_stable_order</pre><pre>\nenv = \n\n    def test_priority_store_stable_order(env):\n        pstore = simpy.PriorityStore(env, 3)\n        log = []\n\n        def getter(wait):\n            yield env.timeout(wait)\n            _, item = yield pstore.get()\n            log.append(item)\n\n        items = [object() for _ in range(3)]\n\n        # Unorderable items are inserted with same priority.\n        env.process(pstore.put(simpy.PriorityItem(0, item)) for item in items)\n        env.process(getter(1))\n        env.process(getter(2))\n        env.process(getter(3))\n&gt;       env.run()\n\ntests/test_resources.py:612: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_filter_store","title":"test_resources.py::test_filter_store","text":"<pre>test_resources.py::test_filter_store</pre><pre>\nenv = \n\n    def test_filter_store(env):\n        def pem(env):\n            store = simpy.FilterStore(env, capacity=2)\n\n            get_event = store.get(lambda item: item == 'b')\n            yield store.put('a')\n            assert not get_event.triggered\n            yield store.put('b')\n            assert get_event.triggered\n\n        env.process(pem(env))\n&gt;       env.run()\n\ntests/test_resources.py:630: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_filter_store_get_after_mismatch","title":"test_resources.py::test_filter_store_get_after_mismatch","text":"<pre>test_resources.py::test_filter_store_get_after_mismatch</pre><pre>\nenv = \n\n    def test_filter_store_get_after_mismatch(env):\n        \"\"\"Regression test for issue #49.\n\n        Triggering get-events after a put in FilterStore wrongly breaks after the\n        first mismatch.\n\n        \"\"\"\n\n        def putter(env, store):\n            # The order of putting 'spam' before 'eggs' is important here.\n            yield store.put('spam')\n            yield env.timeout(1)\n            yield store.put('eggs')\n\n        def getter(store):\n            # The order of requesting 'eggs' before 'spam' is important here.\n            eggs = store.get(lambda i: i == 'eggs')\n            spam = store.get(lambda i: i == 'spam')\n\n            ret = yield spam | eggs\n            assert spam in ret\n            assert eggs not in ret\n            assert env.now == 0\n\n            yield eggs\n            assert env.now == 1\n\n        store = simpy.FilterStore(env, capacity=2)\n        env.process(getter(store))\n        env.process(putter(env, store))\n&gt;       env.run()\n\ntests/test_resources.py:663: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_filter_calls_best_case","title":"test_resources.py::test_filter_calls_best_case","text":"<pre>test_resources.py::test_filter_calls_best_case</pre><pre>\nenv = \n\n    def test_filter_calls_best_case(env):\n        \"\"\"The filter function is called every item in the store until a match is\n        found. In the best case the first item already matches.\"\"\"\n        log = []\n\n        def log_filter(item):\n            log.append(f'check {item}')\n            return True\n\n        store = simpy.FilterStore(env)\n        store.items = [1, 2, 3]\n\n        def getter(store):\n            log.append(f'get {yield store.get(log_filter)}')\n            log.append(f'get {yield store.get(log_filter)}')\n            log.append(f'get {yield store.get(log_filter)}')\n\n        env.process(getter(store))\n&gt;       env.run()\n\ntests/test_resources.py:684: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_filter_calls_worst_case","title":"test_resources.py::test_filter_calls_worst_case","text":"<pre>test_resources.py::test_filter_calls_worst_case</pre><pre>\nenv = \n\n    def test_filter_calls_worst_case(env):\n        \"\"\"In the worst case the filter function is being called for items multiple\n        times.\"\"\"\n\n        log = []\n        store = simpy.FilterStore(env)\n\n        def putter(store):\n            for i in range(4):\n                log.append(f'put {i}')\n                yield store.put(i)\n\n        def log_filter(item):\n            log.append(f'check {item}')\n            return item &gt;= 3\n\n        def getter(store):\n            log.append(f'get {yield store.get(log_filter)}')\n\n        env.process(getter(store))\n        env.process(putter(store))\n&gt;       env.run()\n\ntests/test_resources.py:710: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_immediate_put_request","title":"test_resources.py::test_immediate_put_request","text":"<pre>test_resources.py::test_immediate_put_request</pre><pre>\nenv = \n\n    def test_immediate_put_request(env):\n        \"\"\"Put requests that can be fulfilled immediately do not enter the put\n        queue.\"\"\"\n        resource = simpy.Resource(env, capacity=1)\n        assert len(resource.users) == 0\n        assert len(resource.queue) == 0\n\n        # The resource is empty, the first request will succeed immediately without\n        # entering the queue.\n&gt;       request = resource.request()\n\ntests/test_resources.py:733: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/resources/resource.py:74: in __init__\n    super().__init__(resource)\nsrc/simpy/resources/base.py:39: in __init__\n    resource._trigger_put(None)\nsrc/simpy/resources/base.py:199: in _trigger_put\n    if not self._do_put(put_event):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nevent = \n\n    def _do_put(self, event: PutType) -&gt;Optional[bool]:\n        \"\"\"Perform the *put* operation.\n\n        This method needs to be implemented by subclasses. If the conditions\n        for the put *event* are met, the method must trigger the event (e.g.\n        call :meth:`Event.succeed()` with an appropriate value).\n\n        This method is called by :meth:`_trigger_put` for every event in the\n        :attr:`put_queue`, as long as the return value does not evaluate\n        ``False``.\n        \"\"\"\n&gt;       raise NotImplementedError(\"The _do_put() method has to be implemented by subclasses.\")\nE       NotImplementedError: The _do_put() method has to be implemented by subclasses.\n\nsrc/simpy/resources/base.py:186: NotImplementedError"},{"location":"analysis_baseline_simpy/#test_resourcespytest_immediate_get_request","title":"test_resources.py::test_immediate_get_request","text":"<pre>test_resources.py::test_immediate_get_request</pre><pre>\nenv = \n\n    def test_immediate_get_request(env):\n        \"\"\"Get requests that can be fulfilled immediately do not enter the get\n        queue.\"\"\"\n        container = simpy.Container(env)\n        # Put something in the container, this request is triggered immediately\n        # without entering the queue.\n&gt;       request = container.put(1)\n\ntests/test_resources.py:751: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/resources/container.py:30: in __init__\n    super().__init__(container)\nsrc/simpy/resources/base.py:39: in __init__\n    resource._trigger_put(None)\nsrc/simpy/resources/base.py:199: in _trigger_put\n    if not self._do_put(put_event):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nevent = \n\n    def _do_put(self, event: PutType) -&gt;Optional[bool]:\n        \"\"\"Perform the *put* operation.\n\n        This method needs to be implemented by subclasses. If the conditions\n        for the put *event* are met, the method must trigger the event (e.g.\n        call :meth:`Event.succeed()` with an appropriate value).\n\n        This method is called by :meth:`_trigger_put` for every event in the\n        :attr:`put_queue`, as long as the return value does not evaluate\n        ``False``.\n        \"\"\"\n&gt;       raise NotImplementedError(\"The _do_put() method has to be implemented by subclasses.\")\nE       NotImplementedError: The _do_put() method has to be implemented by subclasses.\n\nsrc/simpy/resources/base.py:186: NotImplementedError"},{"location":"analysis_baseline_simpy/#test_rtpytest_rt01","title":"test_rt.py::test_rt[0.1]","text":"<pre>test_rt.py::test_rt[0.1]</pre><pre>\nlog = [], factor = 0.1\n\n    @pytest.mark.parametrize('factor', [0.1, 0.05, 0.15])\n    def test_rt(log, factor):\n        \"\"\"Basic tests for run().\"\"\"\n        start = monotonic()\n        env = RealtimeEnvironment(factor=factor)\n        env.process(process(env, log, 0.01, 1))\n        env.process(process(env, log, 0.02, 1))\n\n&gt;       env.run(2)\n\ntests/test_rt.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event after enough real-time has passed for the\n        event to happen.\n\n        The delay is scaled according to the real-time :attr:`factor`. With\n        :attr:`strict` mode enabled, a :exc:`RuntimeError` will be raised, if\n        the event is processed too slowly.\n\n        \"\"\"\n        try:\n            evt_time = self.peek()\n        except EmptySchedule:\n            return\n\n        real_time = monotonic()\n        expected_real_time = self.real_start + (evt_time - self.env_start) / self._factor\n\n        if real_time &lt; expected_real_time:\n            sleep(expected_real_time - real_time)\n        elif self._strict and real_time &gt; expected_real_time:\n&gt;           raise RuntimeError(f'Simulation too slow: {real_time - expected_real_time:.3f} seconds late')\nE           RuntimeError: Simulation too slow: 0.000 seconds late\n\nsrc/simpy/rt.py:74: RuntimeError"},{"location":"analysis_baseline_simpy/#test_rtpytest_rt005","title":"test_rt.py::test_rt[0.05]","text":"<pre>test_rt.py::test_rt[0.05]</pre><pre>\nlog = [], factor = 0.05\n\n    @pytest.mark.parametrize('factor', [0.1, 0.05, 0.15])\n    def test_rt(log, factor):\n        \"\"\"Basic tests for run().\"\"\"\n        start = monotonic()\n        env = RealtimeEnvironment(factor=factor)\n        env.process(process(env, log, 0.01, 1))\n        env.process(process(env, log, 0.02, 1))\n\n&gt;       env.run(2)\n\ntests/test_rt.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event after enough real-time has passed for the\n        event to happen.\n\n        The delay is scaled according to the real-time :attr:`factor`. With\n        :attr:`strict` mode enabled, a :exc:`RuntimeError` will be raised, if\n        the event is processed too slowly.\n\n        \"\"\"\n        try:\n            evt_time = self.peek()\n        except EmptySchedule:\n            return\n\n        real_time = monotonic()\n        expected_real_time = self.real_start + (evt_time - self.env_start) / self._factor\n\n        if real_time &lt; expected_real_time:\n            sleep(expected_real_time - real_time)\n        elif self._strict and real_time &gt; expected_real_time:\n&gt;           raise RuntimeError(f'Simulation too slow: {real_time - expected_real_time:.3f} seconds late')\nE           RuntimeError: Simulation too slow: 0.000 seconds late\n\nsrc/simpy/rt.py:74: RuntimeError"},{"location":"analysis_baseline_simpy/#test_rtpytest_rt015","title":"test_rt.py::test_rt[0.15]","text":"<pre>test_rt.py::test_rt[0.15]</pre><pre>\nlog = [], factor = 0.15\n\n    @pytest.mark.parametrize('factor', [0.1, 0.05, 0.15])\n    def test_rt(log, factor):\n        \"\"\"Basic tests for run().\"\"\"\n        start = monotonic()\n        env = RealtimeEnvironment(factor=factor)\n        env.process(process(env, log, 0.01, 1))\n        env.process(process(env, log, 0.02, 1))\n\n&gt;       env.run(2)\n\ntests/test_rt.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event after enough real-time has passed for the\n        event to happen.\n\n        The delay is scaled according to the real-time :attr:`factor`. With\n        :attr:`strict` mode enabled, a :exc:`RuntimeError` will be raised, if\n        the event is processed too slowly.\n\n        \"\"\"\n        try:\n            evt_time = self.peek()\n        except EmptySchedule:\n            return\n\n        real_time = monotonic()\n        expected_real_time = self.real_start + (evt_time - self.env_start) / self._factor\n\n        if real_time &lt; expected_real_time:\n            sleep(expected_real_time - real_time)\n        elif self._strict and real_time &gt; expected_real_time:\n&gt;           raise RuntimeError(f'Simulation too slow: {real_time - expected_real_time:.3f} seconds late')\nE           RuntimeError: Simulation too slow: 0.000 seconds late\n\nsrc/simpy/rt.py:74: RuntimeError"},{"location":"analysis_baseline_simpy/#test_rtpytest_rt_multiple_call","title":"test_rt.py::test_rt_multiple_call","text":"<pre>test_rt.py::test_rt_multiple_call</pre><pre>\nlog = []\n\n    def test_rt_multiple_call(log):\n        \"\"\"Test multiple calls to run().\"\"\"\n        start = monotonic()\n        env = RealtimeEnvironment(factor=0.05)\n\n        env.process(process(env, log, 0.01, 2))\n        env.process(process(env, log, 0.01, 3))\n\n&gt;       env.run(5)\n\ntests/test_rt.py:47: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event after enough real-time has passed for the\n        event to happen.\n\n        The delay is scaled according to the real-time :attr:`factor`. With\n        :attr:`strict` mode enabled, a :exc:`RuntimeError` will be raised, if\n        the event is processed too slowly.\n\n        \"\"\"\n        try:\n            evt_time = self.peek()\n        except EmptySchedule:\n            return\n\n        real_time = monotonic()\n        expected_real_time = self.real_start + (evt_time - self.env_start) / self._factor\n\n        if real_time &lt; expected_real_time:\n            sleep(expected_real_time - real_time)\n        elif self._strict and real_time &gt; expected_real_time:\n&gt;           raise RuntimeError(f'Simulation too slow: {real_time - expected_real_time:.3f} seconds late')\nE           RuntimeError: Simulation too slow: 0.000 seconds late\n\nsrc/simpy/rt.py:74: RuntimeError"},{"location":"analysis_baseline_simpy/#test_rtpytest_rt_slow_sim_default_behavior","title":"test_rt.py::test_rt_slow_sim_default_behavior","text":"<pre>test_rt.py::test_rt_slow_sim_default_behavior</pre><pre>\nlog = []\n\n    def test_rt_slow_sim_default_behavior(log):\n        \"\"\"By default, SimPy should raise an error if a simulation is too\n        slow for the selected real-time factor.\"\"\"\n        env = RealtimeEnvironment(factor=0.05)\n        env.process(process(env, log, 0.1, 1))\n\n        err = pytest.raises(RuntimeError, env.run, 3)\n&gt;       assert 'Simulation too slow for real time' in str(err.value)\nE       AssertionError: assert 'Simulation too slow for real time' in 'Simulation too slow: 0.000 seconds late'\nE        +  where 'Simulation too slow: 0.000 seconds late' = str(RuntimeError('Simulation too slow: 0.000 seconds late'))\nE        +    where RuntimeError('Simulation too slow: 0.000 seconds late') = .value\n\ntests/test_rt.py:68: AssertionError"},{"location":"analysis_baseline_simpy/#test_rtpytest_rt_slow_sim_no_error","title":"test_rt.py::test_rt_slow_sim_no_error","text":"<pre>test_rt.py::test_rt_slow_sim_no_error</pre><pre>\nlog = []\n\n    def test_rt_slow_sim_no_error(log):\n        \"\"\"Test ignoring slow simulations.\"\"\"\n        start = monotonic()\n        env = RealtimeEnvironment(factor=0.05, strict=False)\n        env.process(process(env, log, 0.1, 1))\n\n&gt;       env.run(2)\n\ntests/test_rt.py:78: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\nsrc/simpy/rt.py:76: in step\n    super().step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_rtpytest_rt_illegal_until","title":"test_rt.py::test_rt_illegal_until","text":"<pre>test_rt.py::test_rt_illegal_until</pre><pre>\ndef test_rt_illegal_until():\n        \"\"\"Test illegal value for *until*.\"\"\"\n        env = RealtimeEnvironment()\n&gt;       with pytest.raises(\n            ValueError,\n            match=r'until \\(-1\\) must be greater than the current simulation time',\n        ):\nE       Failed: DID NOT RAISE \n\ntests/test_rt.py:88: Failed"},{"location":"analysis_baseline_simpy/#test_rtpytest_rt_sync","title":"test_rt.py::test_rt_sync","text":"<pre>test_rt.py::test_rt_sync</pre><pre>\nlog = []\n\n    def test_rt_sync(log):\n        \"\"\"Test resetting the internal wall-clock reference time.\"\"\"\n        env = RealtimeEnvironment(factor=0.05)\n        env.process(process(env, log, 0.01))\n        sleep(0.06)  # Simulate massive workload :-)\n        env.sync()\n&gt;       env.run(3)\n\ntests/test_rt.py:101: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event after enough real-time has passed for the\n        event to happen.\n\n        The delay is scaled according to the real-time :attr:`factor`. With\n        :attr:`strict` mode enabled, a :exc:`RuntimeError` will be raised, if\n        the event is processed too slowly.\n\n        \"\"\"\n        try:\n            evt_time = self.peek()\n        except EmptySchedule:\n            return\n\n        real_time = monotonic()\n        expected_real_time = self.real_start + (evt_time - self.env_start) / self._factor\n\n        if real_time &lt; expected_real_time:\n            sleep(expected_real_time - real_time)\n        elif self._strict and real_time &gt; expected_real_time:\n&gt;           raise RuntimeError(f'Simulation too slow: {real_time - expected_real_time:.3f} seconds late')\nE           RuntimeError: Simulation too slow: 0.000 seconds late\n\nsrc/simpy/rt.py:74: RuntimeError"},{"location":"analysis_baseline_simpy/#test_rtpytest_run_with_untriggered_event","title":"test_rt.py::test_run_with_untriggered_event","text":"<pre>test_rt.py::test_run_with_untriggered_event</pre><pre>\nenv = \n\n    def test_run_with_untriggered_event(env):\n        env = RealtimeEnvironment(factor=0.05)\n&gt;       excinfo = pytest.raises(RuntimeError, env.run, until=env.event())\n\ntests/test_rt.py:106: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:183: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event after enough real-time has passed for the\n        event to happen.\n\n        The delay is scaled according to the real-time :attr:`factor`. With\n        :attr:`strict` mode enabled, a :exc:`RuntimeError` will be raised, if\n        the event is processed too slowly.\n\n        \"\"\"\n        try:\n            evt_time = self.peek()\n        except EmptySchedule:\n            return\n\n        real_time = monotonic()\n        expected_real_time = self.real_start + (evt_time - self.env_start) / self._factor\n\n        if real_time &lt; expected_real_time:\n&gt;           sleep(expected_real_time - real_time)\nE           OverflowError: timestamp too large to convert to C _PyTime_t\n\nsrc/simpy/rt.py:72: OverflowError"},{"location":"analysis_baseline_simpy/#test_timeoutpytest_discrete_time_steps","title":"test_timeout.py::test_discrete_time_steps","text":"<pre>test_timeout.py::test_discrete_time_steps</pre><pre>\nenv = , log = []\n\n    def test_discrete_time_steps(env, log):\n        \"\"\"envple envulation with discrete time steps.\"\"\"\n\n        def pem(env, log):\n            while True:\n                log.append(env.now)\n                yield env.timeout(delay=1)\n\n        env.process(pem(env, log))\n&gt;       env.run(until=3)\n\ntests/test_timeout.py:18: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:192: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_timeoutpytest_negative_timeout","title":"test_timeout.py::test_negative_timeout","text":"<pre>test_timeout.py::test_negative_timeout</pre><pre>\nenv = \n\n    def test_negative_timeout(env):\n        \"\"\"Don't allow negative timeout times.\"\"\"\n\n        def pem(env):\n            yield env.timeout(-1)\n\n        env.process(pem(env))\n        with pytest.raises(ValueError, match='Negative delay'):\n&gt;           env.run()\n\ntests/test_timeout.py:31: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_timeoutpytest_timeout_value","title":"test_timeout.py::test_timeout_value","text":"<pre>test_timeout.py::test_timeout_value</pre><pre>\nenv = \n\n    def test_timeout_value(env):\n        \"\"\"You can pass an additional *value* to *timeout* which will be\n        directly yielded back into the PEM. This is useful to implement some\n        kinds of resources or other additions.\n\n        See :class:`envpy.resources.Store` for an example.\n\n        \"\"\"\n\n        def pem(env):\n            val = yield env.timeout(1, 'ohai')\n            assert val == 'ohai'\n\n        env.process(pem(env))\n&gt;       env.run()\n\ntests/test_timeout.py:48: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_timeoutpytest_shared_timeout","title":"test_timeout.py::test_shared_timeout","text":"<pre>test_timeout.py::test_shared_timeout</pre><pre>\nenv = , log = []\n\n    def test_shared_timeout(env, log):\n        def child(env, timeout, id, log):\n            yield timeout\n            log.append((id, env.now))\n\n        timeout = env.timeout(1)\n        for i in range(3):\n            env.process(child(env, timeout, i, log))\n\n&gt;       env.run()\n\ntests/test_timeout.py:60: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_timeoutpytest_triggered_timeout","title":"test_timeout.py::test_triggered_timeout","text":"<pre>test_timeout.py::test_triggered_timeout</pre><pre>\nenv = \n\n    def test_triggered_timeout(env):\n        def process(env):\n            def child(env, event):\n                value = yield event\n                return value\n\n            event = env.timeout(1, 'i was already done')\n            # Start the child after the timeout has already happened.\n            yield env.timeout(2)\n            value = yield env.process(child(env, event))\n            assert value == 'i was already done'\n\n&gt;       env.run(env.process(process(env)))\n\ntests/test_timeout.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:183: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_start_delayed","title":"test_util.py::test_start_delayed","text":"<pre>test_util.py::test_start_delayed</pre><pre>\nenv = \n\n    def test_start_delayed(env):\n        def pem(env):\n            assert env.now == 5\n            yield env.timeout(1)\n\n        start_delayed(env, pem(env), delay=5)\n&gt;       env.run()\n\ntests/test_util.py:18: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_subscribe","title":"test_util.py::test_subscribe","text":"<pre>test_util.py::test_subscribe</pre><pre>\nenv = \n\n    def test_subscribe(env):\n        \"\"\"Check async. interrupt if a process terminates.\"\"\"\n\n        def child(env):\n            yield env.timeout(3)\n            return 'ohai'\n\n        def parent(env):\n            child_proc = env.process(child(env))\n            subscribe_at(child_proc)\n\n            try:\n                yield env.event()\n            except Interrupt as interrupt:\n                assert interrupt.cause is not None  # noqa: PT017\n                assert interrupt.cause[0] is child_proc  # noqa: PT017\n                assert interrupt.cause[1] == 'ohai'  # noqa: PT017\n                assert env.now == 3\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_util.py:51: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_subscribe_terminated_proc","title":"test_util.py::test_subscribe_terminated_proc","text":"<pre>test_util.py::test_subscribe_terminated_proc</pre><pre>\nenv = \n\n    def test_subscribe_terminated_proc(env):\n        \"\"\"subscribe() proc should send a signal immediately if\n        \"other\" has already terminated.\n\n        \"\"\"\n\n        def child(env):\n            yield env.timeout(1)\n\n        def parent(env):\n            child_proc = env.process(child(env))\n            yield env.timeout(2)\n            pytest.raises(RuntimeError, subscribe_at, child_proc)\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_util.py:69: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_subscribe_with_join","title":"test_util.py::test_subscribe_with_join","text":"<pre>test_util.py::test_subscribe_with_join</pre><pre>\nenv = \n\n    def test_subscribe_with_join(env):\n        \"\"\"Test that subscribe() works if a process waits for another one.\"\"\"\n\n        def child(env, i):\n            yield env.timeout(i)\n\n        def parent(env):\n            child_proc1 = env.process(child(env, 1))\n            child_proc2 = env.process(child(env, 2))\n            try:\n                subscribe_at(child_proc1)\n                yield child_proc2\n            except Interrupt as interrupt:\n                assert env.now == 1\n                assert interrupt.cause is not None  # noqa: PT017\n                assert interrupt.cause[0] is child_proc1  # noqa: PT017\n                assert child_proc2.is_alive\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_util.py:91: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_subscribe_at_timeout","title":"test_util.py::test_subscribe_at_timeout","text":"<pre>test_util.py::test_subscribe_at_timeout</pre><pre>\nenv = \n\n    def test_subscribe_at_timeout(env):\n        \"\"\"You should be able to subscribe at arbitrary events.\"\"\"\n\n        def pem(env):\n            to = env.timeout(2)\n            subscribe_at(to)\n            try:\n                yield env.timeout(10)\n            except Interrupt as interrupt:\n                assert interrupt.cause == (to, None)  # noqa: PT017\n                assert env.now == 2\n\n        env.process(pem(env))\n&gt;       env.run()\n\ntests/test_util.py:107: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_subscribe_at_timeout_with_value","title":"test_util.py::test_subscribe_at_timeout_with_value","text":"<pre>test_util.py::test_subscribe_at_timeout_with_value</pre><pre>\nenv = \n\n    def test_subscribe_at_timeout_with_value(env):\n        \"\"\"An event's value should be accessible via the interrupt cause.\"\"\"\n\n        def pem(env):\n            val = 'ohai'\n            to = env.timeout(2, value=val)\n            subscribe_at(to)\n            try:\n                yield env.timeout(10)\n            except Interrupt as interrupt:\n                assert interrupt.cause == (to, val)  # noqa: PT017\n                assert env.now == 2\n\n        env.process(pem(env))\n&gt;       env.run()\n\ntests/test_util.py:124: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_all_of","title":"test_util.py::test_all_of","text":"<pre>test_util.py::test_all_of</pre><pre>\nenv = \n\n    def test_all_of(env):\n        \"\"\"Wait for all events to be triggered.\"\"\"\n\n        def parent(env):\n            # Start 10 events.\n            events = [env.timeout(i, value=i) for i in range(10)]\n            results = yield env.all_of(events)\n\n            assert results == {events[i]: i for i in range(10)}\n            assert env.now == 9\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_util.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_all_of_generator","title":"test_util.py::test_all_of_generator","text":"<pre>test_util.py::test_all_of_generator</pre><pre>\nenv = \n\n    def test_all_of_generator(env):\n        \"\"\"Conditions also work with generators.\"\"\"\n\n        def parent(env):\n            # Start 10 events.\n            events = (env.timeout(i, value=i) for i in range(10))\n            results = yield env.all_of(events)\n\n            assert list(results.values()) == list(range(10))\n            assert env.now == 9\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_util.py:154: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_wait_for_all_with_errors","title":"test_util.py::test_wait_for_all_with_errors","text":"<pre>test_util.py::test_wait_for_all_with_errors</pre><pre>\nenv = \n\n    def test_wait_for_all_with_errors(env):\n        \"\"\"On default AllOf should fail immediately if one of its events\n        fails.\"\"\"\n\n        def child_with_error(env, value):\n            yield env.timeout(value)\n            raise RuntimeError('crashing')\n\n        def parent(env):\n            events = [\n                env.timeout(1, value=1),\n                env.process(child_with_error(env, 2)),\n                env.timeout(3, value=3),\n            ]\n\n            condition = env.all_of(events)\n            with pytest.raises(RuntimeError, match='crashing'):\n                yield condition\n\n            # Although the condition has failed, interim values are available.\n            assert condition._events[0].value == 1\n            assert condition._events[1].value.args[0] == 'crashing'\n            # The last child has not terminated yet.\n            assert not events[2].processed\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_util.py:183: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_all_of_chaining","title":"test_util.py::test_all_of_chaining","text":"<pre>test_util.py::test_all_of_chaining</pre><pre>\nenv = \n\n    def test_all_of_chaining(env):\n        \"\"\"If a wait_for_all condition A is chained to a wait_for_all condition B,\n        B will be merged into A.\"\"\"\n\n        def parent(env):\n            condition_a = env.all_of([env.timeout(i, value=i) for i in range(2)])\n            condition_b = env.all_of([env.timeout(i, value=i) for i in range(2)])\n\n            condition_a &amp;= condition_b\n\n            results = yield condition_a\n            assert list(results.values()) == [0, 1, 0, 1]\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_util.py:200: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_all_of_chaining_intermediate_results","title":"test_util.py::test_all_of_chaining_intermediate_results","text":"<pre>test_util.py::test_all_of_chaining_intermediate_results</pre><pre>\nenv = \n\n    def test_all_of_chaining_intermediate_results(env):\n        \"\"\"If a wait_for_all condition A with intermediate results is merged into\n        another wait_for_all condition B, the results are copied into condition\n        A.\"\"\"\n\n        def parent(env):\n            condition_a = env.all_of([env.timeout(i, value=i) for i in range(2)])\n            condition_b = env.all_of([env.timeout(i, value=i) for i in range(2)])\n\n            yield env.timeout(0)\n\n            condition = condition_a &amp; condition_b\n            result = ConditionValue()\n            condition._populate_value(result)\n            assert list(result.values()) == [0, 0]\n\n            results = yield condition\n            assert list(results.values()) == [0, 1, 0, 1]\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_util.py:223: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_all_of_with_triggered_events","title":"test_util.py::test_all_of_with_triggered_events","text":"<pre>test_util.py::test_all_of_with_triggered_events</pre><pre>\nenv = \n\n    def test_all_of_with_triggered_events(env):\n        \"\"\"Processed events can be added to a condition. Confirm this with\n        all_of.\"\"\"\n\n        def parent(env):\n            events = [env.timeout(0, value='spam'), env.timeout(1, value='eggs')]\n            yield env.timeout(2)\n\n            values = list((yield env.all_of(events)).values())\n            assert values == ['spam', 'eggs']\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_util.py:238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_any_of","title":"test_util.py::test_any_of","text":"<pre>test_util.py::test_any_of</pre><pre>\nenv = \n\n    def test_any_of(env):\n        \"\"\"Wait for any event to be triggered.\"\"\"\n\n        def parent(env):\n            # Start 10 events.\n            events = [env.timeout(i, value=i) for i in range(10)]\n            results = yield env.any_of(events)\n\n            assert results == {events[0]: 0}\n            assert env.now == 0\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_util.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_any_of_with_errors","title":"test_util.py::test_any_of_with_errors","text":"<pre>test_util.py::test_any_of_with_errors</pre><pre>\nenv = \n\n    def test_any_of_with_errors(env):\n        \"\"\"On default any_of should fail if the event has failed too.\"\"\"\n\n        def child_with_error(env, value):\n            yield env.timeout(value)\n            raise RuntimeError('crashing')\n\n        def parent(env):\n            events = [env.process(child_with_error(env, 1)), env.timeout(2, value=2)]\n            condition = env.any_of(events)\n            with pytest.raises(RuntimeError, match='crashing'):\n                yield condition\n\n            assert condition._events[0].value.args[0] == 'crashing'\n            # The last event has not terminated yet.\n            assert not events[1].processed\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_util.py:274: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_any_of_chaining","title":"test_util.py::test_any_of_chaining","text":"<pre>test_util.py::test_any_of_chaining</pre><pre>\nenv = \n\n    def test_any_of_chaining(env):\n        \"\"\"If a any_of condition A is chained to a any_of condition B,\n        B will be merged into A.\"\"\"\n\n        def parent(env):\n            condition_a = env.any_of([env.timeout(2, value='a')])\n            condition_b = env.any_of([env.timeout(1, value='b')])\n\n            condition_a |= condition_b\n\n            results = yield condition_a\n            assert list(results.values()) == ['b']\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_util.py:291: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_any_of_with_triggered_events","title":"test_util.py::test_any_of_with_triggered_events","text":"<pre>test_util.py::test_any_of_with_triggered_events</pre><pre>\nenv = \n\n    def test_any_of_with_triggered_events(env):\n        \"\"\"Processed events can be added to a condition. Confirm this with\n        all_of.\"\"\"\n\n        def parent(env):\n            events = [env.timeout(0, value='spam'), env.timeout(1, value='eggs')]\n            yield env.timeout(2)\n\n            values = list((yield env.any_of(events)).values())\n            assert values == ['spam', 'eggs']\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_util.py:306: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_empty_any_of","title":"test_util.py::test_empty_any_of","text":"<pre>test_util.py::test_empty_any_of</pre><pre>\nenv = \n\n    def test_empty_any_of(env):\n        \"\"\"AnyOf will trigger immediately if there are no events.\"\"\"\n\n        def parent(env):\n            results = yield env.any_of([])\n            assert results == {}\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_util.py:317: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_empty_all_of","title":"test_util.py::test_empty_all_of","text":"<pre>test_util.py::test_empty_all_of</pre><pre>\nenv = \n\n    def test_empty_all_of(env):\n        \"\"\"AllOf will trigger immediately if there are no events.\"\"\"\n\n        def parent(env):\n            results = yield env.all_of([])\n            assert results == {}\n\n        env.process(parent(env))\n&gt;       env.run()\n\ntests/test_util.py:328: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#test_utilpytest_all_of_expansion","title":"test_util.py::test_all_of_expansion","text":"<pre>test_util.py::test_all_of_expansion</pre><pre>\nenv = \n\n    def test_all_of_expansion(env):\n        \"\"\"The result of AllOf is an OrderedDict, which allows to expand its values\n        directly into variables.\"\"\"\n\n        def p(env):\n            timeouts = [env.timeout(d, d) for d in [3, 2, 1]]\n            a, b, c = (yield env.all_of(timeouts)).values()\n            assert a == 3\n            assert b == 2\n            assert c == 1\n\n        env.process(p(env))\n&gt;       env.run()\n\ntests/test_util.py:343: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nsrc/simpy/core.py:176: in run\n    self.step()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def step(self) -&gt;None:\n        \"\"\"Process the next event.\n\n        Raise an :exc:`EmptySchedule` if no further events are available.\n\n        \"\"\"\n        try:\n            self._now, _, _, event = heappop(self._queue)\n        except IndexError:\n            raise EmptySchedule()\n\n        # Process the event\n        event._ok = True\n&gt;       event._value = event._callback(event)\nE       AttributeError: 'Initialize' object has no attribute '_callback'. Did you mean: 'callbacks'?\n\nsrc/simpy/core.py:150: AttributeError"},{"location":"analysis_baseline_simpy/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/src/simpy/core.py b/src/simpy/core.py\nindex 10c88fb..b39ddef 100644\n--- a/src/simpy/core.py\n+++ b/src/simpy/core.py\n@@ -34,7 +34,10 @@ class BoundClass(Generic[T]):\n     def bind_early(instance: object) -&gt;None:\n         \"\"\"Bind all :class:`BoundClass` attributes of the *instance's* class\n         to the instance itself to increase performance.\"\"\"\n-        pass\n+        cls = type(instance)\n+        for name, obj in cls.__dict__.items():\n+            if isinstance(obj, BoundClass):\n+                setattr(instance, name, obj.__get__(instance, cls))\n\n\n class EmptySchedule(Exception):\n@@ -49,7 +52,7 @@ class StopSimulation(Exception):\n     def callback(cls, event: Event) -&gt;None:\n         \"\"\"Used as callback in :meth:`Environment.run()` to stop the simulation\n         when the *until* event occurred.\"\"\"\n-        pass\n+        raise cls()\n\n\n SimTime = Union[int, float]\n@@ -77,12 +80,12 @@ class Environment:\n     @property\n     def now(self) -&gt;SimTime:\n         \"\"\"The current simulation time.\"\"\"\n-        pass\n+        return self._now\n\n     @property\n     def active_process(self) -&gt;Optional[Process]:\n         \"\"\"The currently active process of the environment.\"\"\"\n-        pass\n+        return self._active_proc\n     if TYPE_CHECKING:\n\n         def process(self, generator: ProcessGenerator) -&gt;Process:\n@@ -121,12 +124,15 @@ class Environment:\n     def schedule(self, event: Event, priority: EventPriority=NORMAL, delay:\n         SimTime=0) -&gt;None:\n         \"\"\"Schedule an *event* with a given *priority* and a *delay*.\"\"\"\n-        pass\n+        heappush(self._queue, (self._now + delay, priority, next(self._eid), event))\n\n     def peek(self) -&gt;SimTime:\n         \"\"\"Get the time of the next scheduled event. Return\n         :data:`~simpy.core.Infinity` if there is no further event.\"\"\"\n-        pass\n+        try:\n+            return self._queue[0][0]\n+        except IndexError:\n+            return Infinity\n\n     def step(self) -&gt;None:\n         \"\"\"Process the next event.\n@@ -134,7 +140,20 @@ class Environment:\n         Raise an :exc:`EmptySchedule` if no further events are available.\n\n         \"\"\"\n-        pass\n+        try:\n+            self._now, _, _, event = heappop(self._queue)\n+        except IndexError:\n+            raise EmptySchedule()\n+\n+        # Process the event\n+        event._ok = True\n+        event._value = event._callback(event)\n+        event._processed = True\n+\n+        if isinstance(event, Process):\n+            self._active_proc = event\n+        else:\n+            self._active_proc = None\n\n     def run(self, until: Optional[Union[SimTime, Event]]=None) -&gt;Optional[Any]:\n         \"\"\"Executes :meth:`step()` until the given criterion *until* is met.\n@@ -151,4 +170,27 @@ class Environment:\n           until the environment's time reaches *until*.\n\n         \"\"\"\n-        pass\n+        if until is None:\n+            while True:\n+                try:\n+                    self.step()\n+                except EmptySchedule:\n+                    return None\n+        elif isinstance(until, Event):\n+            until.callbacks.append(StopSimulation.callback)\n+            try:\n+                while not until.triggered:\n+                    self.step()\n+            except StopSimulation:\n+                return until.value\n+            except EmptySchedule:\n+                if not until.triggered:\n+                    raise RuntimeError('No scheduled events left but \"until\" event was not triggered')\n+        elif isinstance(until, (int, float)):\n+            try:\n+                while self._now &lt; until:\n+                    self.step()\n+            except EmptySchedule:\n+                return None\n+        else:\n+            raise ValueError('Invalid until parameter type')\ndiff --git a/src/simpy/events.py b/src/simpy/events.py\nindex 128ed75..2781b3f 100644\n--- a/src/simpy/events.py\n+++ b/src/simpy/events.py\n@@ -75,19 +75,19 @@ class Event:\n\n     def _desc(self) -&gt;str:\n         \"\"\"Return a string *Event()*.\"\"\"\n-        pass\n+        return 'Event()'\n\n     @property\n     def triggered(self) -&gt;bool:\n         \"\"\"Becomes ``True`` if the event has been triggered and its callbacks\n         are about to be invoked.\"\"\"\n-        pass\n+        return self._value is not PENDING\n\n     @property\n     def processed(self) -&gt;bool:\n         \"\"\"Becomes ``True`` if the event has been processed (e.g., its\n         callbacks have been invoked).\"\"\"\n-        pass\n+        return self.callbacks is None\n\n     @property\n     def ok(self) -&gt;bool:\n@@ -98,7 +98,9 @@ class Event:\n         :raises AttributeError: if accessed before the event is triggered.\n\n         \"\"\"\n-        pass\n+        if self._value is PENDING:\n+            raise AttributeError('Event has not yet been triggered')\n+        return self._ok\n\n     @property\n     def defused(self) -&gt;bool:\n@@ -115,7 +117,7 @@ class Event:\n         processed by the :class:`~simpy.core.Environment`.\n\n         \"\"\"\n-        pass\n+        return self._defused\n\n     @property\n     def value(self) -&gt;Optional[Any]:\n@@ -126,7 +128,9 @@ class Event:\n         Raises :exc:`AttributeError` if the value is not yet available.\n\n         \"\"\"\n-        pass\n+        if self._value is PENDING:\n+            raise AttributeError('Value not yet available')\n+        return self._value\n\n     def trigger(self, event: Event) -&gt;None:\n         \"\"\"Trigger the event with the state and value of the provided *event*.\n@@ -136,7 +140,10 @@ class Event:\n         chain reactions.\n\n         \"\"\"\n-        pass\n+        self._ok = event._ok\n+        self._value = event._value\n+        self._defused = event._defused\n+        self.env.schedule(self)\n\n     def succeed(self, value: Optional[Any]=None) -&gt;Event:\n         \"\"\"Set the event's value, mark it as successful and schedule it for\n@@ -145,7 +152,12 @@ class Event:\n         Raises :exc:`RuntimeError` if this event has already been triggerd.\n\n         \"\"\"\n-        pass\n+        if self._value is not PENDING:\n+            raise RuntimeError('Event has already been triggered')\n+        self._ok = True\n+        self._value = value\n+        self.env.schedule(self)\n+        return self\n\n     def fail(self, exception: Exception) -&gt;Event:\n         \"\"\"Set *exception* as the events value, mark it as failed and schedule\n@@ -156,7 +168,15 @@ class Event:\n         Raises :exc:`RuntimeError` if this event has already been triggered.\n\n         \"\"\"\n-        pass\n+        if not isinstance(exception, Exception):\n+            raise TypeError('exception must be an Exception instance')\n+        if self._value is not PENDING:\n+            raise RuntimeError('Event has already been triggered')\n+        self._ok = False\n+        self._value = exception\n+        self._defused = False\n+        self.env.schedule(self)\n+        return self\n\n     def __and__(self, other: Event) -&gt;Condition:\n         \"\"\"Return a :class:`~simpy.events.Condition` that will be triggered if\n@@ -197,7 +217,8 @@ class Timeout(Event):\n\n     def _desc(self) -&gt;str:\n         \"\"\"Return a string *Timeout(delay[, value=value])*.\"\"\"\n-        pass\n+        value_str = f', value={self._value!r}' if self._value is not None else ''\n+        return f'Timeout({self._delay}{value_str})'\n\n\n class Initialize(Event):\n@@ -267,7 +288,7 @@ class Process(Event):\n\n     def _desc(self) -&gt;str:\n         \"\"\"Return a string *Process(process_func_name)*.\"\"\"\n-        pass\n+        return f'Process({self._generator.__name__})'\n\n     @property\n     def target(self) -&gt;Event:\n@@ -277,17 +298,17 @@ class Process(Event):\n         interrupted.\n\n         \"\"\"\n-        pass\n+        return self._target\n\n     @property\n     def name(self) -&gt;str:\n         \"\"\"Name of the function used to start the process.\"\"\"\n-        pass\n+        return self._generator.__name__\n\n     @property\n     def is_alive(self) -&gt;bool:\n         \"\"\"``True`` until the process generator exits.\"\"\"\n-        pass\n+        return self._value is PENDING\n\n     def interrupt(self, cause: Optional[Any]=None) -&gt;None:\n         \"\"\"Interrupt this process optionally providing a *cause*.\n@@ -297,7 +318,12 @@ class Process(Event):\n         cases.\n\n         \"\"\"\n-        pass\n+        if not self.is_alive:\n+            raise RuntimeError(f'{self} has terminated and cannot be interrupted.')\n+        if self is self.env.active_process:\n+            raise RuntimeError('A process is not allowed to interrupt itself.')\n+        \n+        Interruption(self, cause)\n\n     def _resume(self, event: Event) -&gt;None:\n         \"\"\"Resumes the execution of the process with the value of *event*. If\n@@ -383,16 +409,24 @@ class Condition(Event):\n\n     def _desc(self) -&gt;str:\n         \"\"\"Return a string *Condition(evaluate, [events])*.\"\"\"\n-        pass\n+        return f'Condition({self._evaluate.__name__}, {self._events})'\n\n     def _populate_value(self, value: ConditionValue) -&gt;None:\n         \"\"\"Populate the *value* by recursively visiting all nested\n         conditions.\"\"\"\n-        pass\n+        for event in self._events:\n+            if isinstance(event, Condition):\n+                event._populate_value(value)\n+            elif event.callbacks is None:\n+                value.events.append(event)\n\n     def _build_value(self, event: Event) -&gt;None:\n         \"\"\"Build the value of this condition.\"\"\"\n-        pass\n+        if not self._ok:\n+            return\n+        value = ConditionValue()\n+        self._populate_value(value)\n+        self._value = value\n\n     def _remove_check_callbacks(self) -&gt;None:\n         \"\"\"Remove _check() callbacks from events recursively.\n@@ -403,24 +437,36 @@ class Condition(Event):\n         untriggered events.\n\n         \"\"\"\n-        pass\n+        for event in self._events:\n+            if event.callbacks and self._check in event.callbacks:\n+                event.callbacks.remove(self._check)\n+            if isinstance(event, Condition):\n+                event._remove_check_callbacks()\n\n     def _check(self, event: Event) -&gt;None:\n         \"\"\"Check if the condition was already met and schedule the *event* if\n         so.\"\"\"\n-        pass\n+        if self._value is not PENDING:\n+            return\n+\n+        self._count += 1\n+\n+        if self._evaluate(self._events, self._count):\n+            self._ok = True\n+            self.env.schedule(self)\n+            self._remove_check_callbacks()\n\n     @staticmethod\n     def all_events(events: Tuple[Event, ...], count: int) -&gt;bool:\n         \"\"\"An evaluation function that returns ``True`` if all *events* have\n         been triggered.\"\"\"\n-        pass\n+        return len(events) == count\n\n     @staticmethod\n     def any_events(events: Tuple[Event, ...], count: int) -&gt;bool:\n         \"\"\"An evaluation function that returns ``True`` if at least one of\n         *events* has been triggered.\"\"\"\n-        pass\n+        return count &gt; 0\n\n\n class AllOf(Condition):\n@@ -447,4 +493,7 @@ class AnyOf(Condition):\n\n def _describe_frame(frame: FrameType) -&gt;str:\n     \"\"\"Print filename, line number and function name of a stack frame.\"\"\"\n-    pass\n+    filename = frame.f_code.co_filename\n+    lineno = frame.f_lineno\n+    funcname = frame.f_code.co_name\n+    return f'{filename}:{lineno}, in {funcname}'\ndiff --git a/src/simpy/exceptions.py b/src/simpy/exceptions.py\nindex d45300e..beef1b2 100644\n--- a/src/simpy/exceptions.py\n+++ b/src/simpy/exceptions.py\n@@ -31,4 +31,4 @@ class Interrupt(SimPyException):\n     @property\n     def cause(self) -&gt;Optional[Any]:\n         \"\"\"The cause of the interrupt or ``None`` if no cause was provided.\"\"\"\n-        pass\n+        return self.args[0] if self.args else None\ndiff --git a/src/simpy/resources/base.py b/src/simpy/resources/base.py\nindex a7d0b96..ccedb56 100644\n--- a/src/simpy/resources/base.py\n+++ b/src/simpy/resources/base.py\n@@ -58,7 +58,8 @@ class Put(Event, ContextManager['Put'], Generic[ResourceType]):\n         method is called automatically.\n\n         \"\"\"\n-        pass\n+        if not self.triggered:\n+            self.resource.put_queue.remove(self)\n\n\n class Get(Event, ContextManager['Get'], Generic[ResourceType]):\n@@ -104,7 +105,8 @@ class Get(Event, ContextManager['Get'], Generic[ResourceType]):\n         method is called automatically.\n\n         \"\"\"\n-        pass\n+        if not self.triggered:\n+            self.resource.get_queue.remove(self)\n\n\n PutType = TypeVar('PutType', bound=Put)\n@@ -152,7 +154,7 @@ class BaseResource(Generic[PutType, GetType]):\n     @property\n     def capacity(self) -&gt;Union[float, int]:\n         \"\"\"Maximum capacity of the resource.\"\"\"\n-        pass\n+        return self._capacity\n     if TYPE_CHECKING:\n\n         def put(self) -&gt;Put:\n@@ -181,7 +183,7 @@ class BaseResource(Generic[PutType, GetType]):\n         :attr:`put_queue`, as long as the return value does not evaluate\n         ``False``.\n         \"\"\"\n-        pass\n+        raise NotImplementedError(\"The _do_put() method has to be implemented by subclasses.\")\n\n     def _trigger_put(self, get_event: Optional[GetType]) -&gt;None:\n         \"\"\"This method is called once a new put event has been created or a get\n@@ -191,7 +193,12 @@ class BaseResource(Generic[PutType, GetType]):\n         calls :meth:`_do_put` to check if the conditions for the event are met.\n         If :meth:`_do_put` returns ``False``, the iteration is stopped early.\n         \"\"\"\n-        pass\n+        idx = 0\n+        while idx &lt; len(self.put_queue):\n+            put_event = self.put_queue[idx]\n+            if not self._do_put(put_event):\n+                break\n+            idx += 1\n\n     def _do_get(self, event: GetType) -&gt;Optional[bool]:\n         \"\"\"Perform the *get* operation.\n@@ -204,7 +211,7 @@ class BaseResource(Generic[PutType, GetType]):\n         :attr:`get_queue`, as long as the return value does not evaluate\n         ``False``.\n         \"\"\"\n-        pass\n+        raise NotImplementedError(\"The _do_get() method has to be implemented by subclasses.\")\n\n     def _trigger_get(self, put_event: Optional[PutType]) -&gt;None:\n         \"\"\"Trigger get events.\n@@ -216,4 +223,9 @@ class BaseResource(Generic[PutType, GetType]):\n         calls :meth:`_do_get` to check if the conditions for the event are met.\n         If :meth:`_do_get` returns ``False``, the iteration is stopped early.\n         \"\"\"\n-        pass\n+        idx = 0\n+        while idx &lt; len(self.get_queue):\n+            get_event = self.get_queue[idx]\n+            if not self._do_get(get_event):\n+                break\n+            idx += 1\ndiff --git a/src/simpy/resources/container.py b/src/simpy/resources/container.py\nindex 00aa6de..fe7bce5 100644\n--- a/src/simpy/resources/container.py\n+++ b/src/simpy/resources/container.py\n@@ -77,16 +77,16 @@ class Container(base.BaseResource):\n     @property\n     def level(self) -&gt;ContainerAmount:\n         \"\"\"The current amount of the matter in the container.\"\"\"\n-        pass\n+        return self._level\n     if TYPE_CHECKING:\n\n         def put(self, amount: ContainerAmount) -&gt;ContainerPut:\n             \"\"\"Request to put *amount* of matter into the container.\"\"\"\n-            pass\n+            return ContainerPut(self, amount)\n\n         def get(self, amount: ContainerAmount) -&gt;ContainerGet:\n             \"\"\"Request to get *amount* of matter out of the container.\"\"\"\n-            pass\n+            return ContainerGet(self, amount)\n     else:\n         put = BoundClass(ContainerPut)\n         get = BoundClass(ContainerGet)\ndiff --git a/src/simpy/resources/resource.py b/src/simpy/resources/resource.py\nindex 2c4f6dd..fa35618 100644\n--- a/src/simpy/resources/resource.py\n+++ b/src/simpy/resources/resource.py\n@@ -70,6 +70,15 @@ class Request(base.Put):\n     resource: Resource\n     usage_since: Optional[SimTime] = None\n\n+    def __init__(self, resource: Resource):\n+        super().__init__(resource)\n+        self.resource = resource\n+        self.usage_since = None\n+\n+    def __enter__(self):\n+        self.usage_since = self.env.now\n+        return self\n+\n     def __exit__(self, exc_type: Optional[Type[BaseException]], exc_value:\n         Optional[BaseException], traceback: Optional[TracebackType]\n         ) -&gt;Optional[bool]:\n@@ -90,6 +99,13 @@ class Release(base.Get):\n         \"\"\"The request (:class:`Request`) that is to be released.\"\"\"\n         super().__init__(resource)\n\n+    def __call__(self):\n+        if self.request in self.resource.users:\n+            self.resource.users.remove(self.request)\n+            self.succeed()\n+        else:\n+            self.fail(ValueError(\"This request is not in the resource's users.\"))\n+\n\n class PriorityRequest(Request):\n     \"\"\"Request the usage of *resource* with a given *priority*. If the\n@@ -138,7 +154,10 @@ class SortedQueue(list):\n         Raise a :exc:`RuntimeError` if the queue is full.\n\n         \"\"\"\n-        pass\n+        if self.maxlen is not None and len(self) &gt;= self.maxlen:\n+            raise RuntimeError(\"Queue is full\")\n+        super().append(item)\n+        self.sort(key=lambda x: x.key)\n\n\n class Resource(base.BaseResource):\n@@ -168,7 +187,7 @@ class Resource(base.BaseResource):\n     @property\n     def count(self) -&gt;int:\n         \"\"\"Number of users currently using the resource.\"\"\"\n-        pass\n+        return len(self.users)\n     if TYPE_CHECKING:\n\n         def request(self) -&gt;Request:\ndiff --git a/src/simpy/resources/store.py b/src/simpy/resources/store.py\nindex 5875e6d..379e325 100644\n--- a/src/simpy/resources/store.py\n+++ b/src/simpy/resources/store.py\n@@ -73,11 +73,11 @@ class Store(base.BaseResource):\n\n         def put(self, item: Any) -&gt;StorePut:\n             \"\"\"Request to put *item* into the store.\"\"\"\n-            pass\n+            return StorePut(self, item)\n\n         def get(self) -&gt;StoreGet:\n             \"\"\"Request to get an *item* out of the store.\"\"\"\n-            pass\n+            return StoreGet(self)\n     else:\n         put = BoundClass(StorePut)\n         get = BoundClass(StoreGet)\n@@ -111,6 +111,31 @@ class PriorityStore(Store):\n\n     \"\"\"\n\n+    def __init__(self, env: Environment, capacity: Union[float, int]=float('inf')):\n+        super().__init__(env, capacity)\n+        self.items = []  # Use a list as a heap\n+\n+    if TYPE_CHECKING:\n+        def put(self, item: Any) -&gt; StorePut:\n+            \"\"\"Request to put *item* into the store.\"\"\"\n+            return StorePut(self, item)\n+\n+        def get(self) -&gt; StoreGet:\n+            \"\"\"Request to get the highest priority *item* from the store.\"\"\"\n+            return StoreGet(self)\n+    else:\n+        put = BoundClass(StorePut)\n+        get = BoundClass(StoreGet)\n+\n+    def _do_put(self, event: StorePut) -&gt; None:\n+        if len(self.items) &lt; self.capacity:\n+            heappush(self.items, event.item)\n+            event.succeed()\n+\n+    def _do_get(self, event: StoreGet) -&gt; None:\n+        if self.items:\n+            event.succeed(heappop(self.items))\n+\n\n class FilterStore(Store):\n     \"\"\"Resource with *capacity* slots for storing arbitrary objects supporting\n@@ -139,6 +164,13 @@ class FilterStore(Store):\n             ) -&gt;FilterStoreGet:\n             \"\"\"Request to get an *item*, for which *filter* returns ``True``,\n             out of the store.\"\"\"\n-            pass\n+            return FilterStoreGet(self, filter)\n     else:\n         get = BoundClass(FilterStoreGet)\n+\n+    def _do_get(self, event: FilterStoreGet) -&gt; None:\n+        for item in self.items:\n+            if event.filter(item):\n+                self.items.remove(item)\n+                event.succeed(item)\n+                break\ndiff --git a/src/simpy/rt.py b/src/simpy/rt.py\nindex 9d99392..e3c068c 100644\n--- a/src/simpy/rt.py\n+++ b/src/simpy/rt.py\n@@ -31,14 +31,14 @@ class RealtimeEnvironment(Environment):\n     @property\n     def factor(self) -&gt;float:\n         \"\"\"Scaling factor of the real-time.\"\"\"\n-        pass\n+        return self._factor\n\n     @property\n     def strict(self) -&gt;bool:\n         \"\"\"Running mode of the environment. :meth:`step()` will raise a\n         :exc:`RuntimeError` if this is set to ``True`` and the processing of\n         events takes too long.\"\"\"\n-        pass\n+        return self._strict\n\n     def sync(self) -&gt;None:\n         \"\"\"Synchronize the internal time with the current wall-clock time.\n@@ -48,7 +48,8 @@ class RealtimeEnvironment(Environment):\n         calling :meth:`run()` or :meth:`step()`.\n\n         \"\"\"\n-        pass\n+        self.real_start = monotonic()\n+        self.env_start = self._now\n\n     def step(self) -&gt;None:\n         \"\"\"Process the next event after enough real-time has passed for the\n@@ -59,4 +60,17 @@ class RealtimeEnvironment(Environment):\n         the event is processed too slowly.\n\n         \"\"\"\n-        pass\n+        try:\n+            evt_time = self.peek()\n+        except EmptySchedule:\n+            return\n+\n+        real_time = monotonic()\n+        expected_real_time = self.real_start + (evt_time - self.env_start) / self._factor\n+\n+        if real_time &lt; expected_real_time:\n+            sleep(expected_real_time - real_time)\n+        elif self._strict and real_time &gt; expected_real_time:\n+            raise RuntimeError(f'Simulation too slow: {real_time - expected_real_time:.3f} seconds late')\n+\n+        super().step()\ndiff --git a/src/simpy/util.py b/src/simpy/util.py\nindex 5e3a81a..bb287ec 100644\n--- a/src/simpy/util.py\n+++ b/src/simpy/util.py\n@@ -33,7 +33,14 @@ def start_delayed(env: Environment, generator: ProcessGenerator, delay: SimTime\n     Raise a :exc:`ValueError` if ``delay &lt;= 0``.\n\n     \"\"\"\n-    pass\n+    if delay &lt;= 0:\n+        raise ValueError(\"delay must be &gt; 0\")\n+    \n+    def delayed_process():\n+        yield env.timeout(delay)\n+        yield from generator\n+\n+    return env.process(delayed_process())\n\n\n def subscribe_at(event: Event) -&gt;None:\n@@ -45,4 +52,11 @@ def subscribe_at(event: Event) -&gt;None:\n     Raise a :exc:`RuntimeError` if ``event`` has already occurred.\n\n     \"\"\"\n-    pass\n+    if event.triggered:\n+        raise RuntimeError(\"Cannot subscribe to an event that has already occurred\")\n+    \n+    def interrupt_callback(event):\n+        import simpy\n+        simpy.exceptions.Interrupt(event.value)\n+\n+    event.callbacks.append(interrupt_callback)\n</code></pre>"},{"location":"analysis_baseline_tinydb/","title":"Analysis baseline tinydb","text":"<p>back to baseline summary</p>"},{"location":"analysis_baseline_tinydb/#submission-name-baseline","title":"Submission Name: baseline","text":""},{"location":"analysis_baseline_tinydb/#repository-tinydb","title":"Repository: tinydb","text":""},{"location":"analysis_baseline_tinydb/#failed-to-run-pytests","title":"Failed to run pytests","text":"<pre><code>ImportError while loading conftest '/testbed/tests/conftest.py'.\ntests/conftest.py:7: in &lt;module&gt;\n    from tinydb.middlewares import CachingMiddleware\ntinydb/__init__.py:27: in &lt;module&gt;\n    from .queries import Query, where\ntinydb/queries.py:21: in &lt;module&gt;\n    from .utils import freeze\ntinydb/utils.py:84: in &lt;module&gt;\n    class FrozenDict(dict):\ntinydb/utils.py:95: in FrozenDict\n    __setitem__ = _immutable\nE   NameError: name '_immutable' is not defined\n</code></pre>"},{"location":"analysis_baseline_tinydb/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/tinydb/database.py b/tinydb/database.py\nindex a4ce0e1..f05a307 100644\n--- a/tinydb/database.py\n+++ b/tinydb/database.py\n@@ -99,7 +99,9 @@ class TinyDB(TableBase):\n         :param name: The name of the table.\n         :param kwargs: Keyword arguments to pass to the table class constructor\n         \"\"\"\n-        pass\n+        if name not in self._tables:\n+            self._tables[name] = self.table_class(self._storage, name, **kwargs)\n+        return self._tables[name]\n\n     def tables(self) -&gt;Set[str]:\n         \"\"\"\n@@ -107,13 +109,14 @@ class TinyDB(TableBase):\n\n         :returns: a set of table names\n         \"\"\"\n-        pass\n+        return set(self._storage.read().keys())\n\n     def drop_tables(self) -&gt;None:\n         \"\"\"\n         Drop all tables from the database. **CANNOT BE REVERSED!**\n         \"\"\"\n-        pass\n+        self._storage.write({})\n+        self._tables.clear()\n\n     def drop_table(self, name: str) -&gt;None:\n         \"\"\"\n@@ -121,7 +124,13 @@ class TinyDB(TableBase):\n\n         :param name: The name of the table to drop.\n         \"\"\"\n-        pass\n+        if name in self._tables:\n+            del self._tables[name]\n+        \n+        data = self._storage.read()\n+        if name in data:\n+            del data[name]\n+            self._storage.write(data)\n\n     @property\n     def storage(self) -&gt;Storage:\n@@ -131,7 +140,7 @@ class TinyDB(TableBase):\n         :return: This instance's storage\n         :rtype: Storage\n         \"\"\"\n-        pass\n+        return self._storage\n\n     def close(self) -&gt;None:\n         \"\"\"\n@@ -148,7 +157,8 @@ class TinyDB(TableBase):\n\n         Upon leaving this context, the ``close`` method will be called.\n         \"\"\"\n-        pass\n+        self._storage.close()\n+        self._opened = False\n\n     def __enter__(self):\n         \"\"\"\ndiff --git a/tinydb/middlewares.py b/tinydb/middlewares.py\nindex 50c2af2..c978b1c 100644\n--- a/tinydb/middlewares.py\n+++ b/tinydb/middlewares.py\n@@ -84,8 +84,36 @@ class CachingMiddleware(Middleware):\n         self.cache = None\n         self._cache_modified_count = 0\n\n+    def read(self):\n+        \"\"\"\n+        Read data from cache if available, otherwise read from storage.\n+        \"\"\"\n+        if self.cache is None:\n+            self.cache = self.storage.read()\n+        return self.cache\n+\n+    def write(self, data):\n+        \"\"\"\n+        Write data to cache and increment the modified count.\n+        Flush to storage if the write cache size is reached.\n+        \"\"\"\n+        self.cache = data\n+        self._cache_modified_count += 1\n+        \n+        if self._cache_modified_count &gt;= self.WRITE_CACHE_SIZE:\n+            self.flush()\n+\n     def flush(self):\n         \"\"\"\n         Flush all unwritten data to disk.\n         \"\"\"\n-        pass\n+        if self.cache is not None:\n+            self.storage.write(self.cache)\n+            self._cache_modified_count = 0\n+\n+    def close(self):\n+        \"\"\"\n+        Flush the cache and close the storage.\n+        \"\"\"\n+        self.flush()\n+        self.storage.close()\ndiff --git a/tinydb/mypy_plugin.py b/tinydb/mypy_plugin.py\nindex 5a0191a..08b3f83 100644\n--- a/tinydb/mypy_plugin.py\n+++ b/tinydb/mypy_plugin.py\n@@ -12,3 +12,28 @@ class TinyDBPlugin(Plugin):\n     def __init__(self, options: Options):\n         super().__init__(options)\n         self.named_placeholders: Dict[str, str] = {}\n+\n+    def get_dynamic_class_hook(self, fullname: str) -&gt; CB[DynamicClassDef]:\n+        if fullname == 'tinydb.utils.with_typehint':\n+            return self.with_typehint_callback\n+        return None\n+\n+    def with_typehint_callback(self, ctx: DynamicClassDef) -&gt; None:\n+        if len(ctx.call.args) != 1:\n+            ctx.api.fail(\"with_typehint() requires exactly one argument\", ctx.call)\n+            return\n+\n+        arg = ctx.call.args[0]\n+        if not isinstance(arg, NameExpr):\n+            ctx.api.fail(\"with_typehint() argument must be a type\", ctx.call)\n+            return\n+\n+        base_type = ctx.api.lookup_qualified(arg.fullname)\n+        if base_type is None:\n+            ctx.api.fail(f\"Cannot find type '{arg.fullname}'\", ctx.call)\n+            return\n+\n+        ctx.cls.info.bases = [base_type]\n+\n+def plugin(version: str):\n+    return TinyDBPlugin\ndiff --git a/tinydb/operations.py b/tinydb/operations.py\nindex fdfa678..833860e 100644\n--- a/tinydb/operations.py\n+++ b/tinydb/operations.py\n@@ -13,39 +13,62 @@ def delete(field):\n     \"\"\"\n     Delete a given field from the document.\n     \"\"\"\n-    pass\n+    def transform(doc):\n+        if field in doc:\n+            del doc[field]\n+        return doc\n+    return transform\n\n\n def add(field, n):\n     \"\"\"\n     Add ``n`` to a given field in the document.\n     \"\"\"\n-    pass\n+    def transform(doc):\n+        if field in doc:\n+            doc[field] += n\n+        return doc\n+    return transform\n\n\n def subtract(field, n):\n     \"\"\"\n     Subtract ``n`` to a given field in the document.\n     \"\"\"\n-    pass\n+    def transform(doc):\n+        if field in doc:\n+            doc[field] -= n\n+        return doc\n+    return transform\n\n\n def set(field, val):\n     \"\"\"\n     Set a given field to ``val``.\n     \"\"\"\n-    pass\n+    def transform(doc):\n+        doc[field] = val\n+        return doc\n+    return transform\n\n\n def increment(field):\n     \"\"\"\n     Increment a given field in the document by 1.\n     \"\"\"\n-    pass\n+    def transform(doc):\n+        if field in doc:\n+            doc[field] += 1\n+        return doc\n+    return transform\n\n\n def decrement(field):\n     \"\"\"\n     Decrement a given field in the document by 1.\n     \"\"\"\n-    pass\n+    def transform(doc):\n+        if field in doc:\n+            doc[field] -= 1\n+        return doc\n+    return transform\ndiff --git a/tinydb/queries.py b/tinydb/queries.py\nindex 0ad5c7e..9ec0435 100644\n--- a/tinydb/queries.py\n+++ b/tinydb/queries.py\n@@ -181,7 +181,21 @@ class Query(QueryInstance):\n         :param hashval: The hash of the query.\n         :return: A :class:`~tinydb.queries.QueryInstance` object\n         \"\"\"\n-        pass\n+        if not self._path and not allow_empty_path:\n+            raise RuntimeError('Query has no path')\n+\n+        def runner(value):\n+            try:\n+                for part in self._path:\n+                    if isinstance(part, Callable):\n+                        value = part(value)\n+                    else:\n+                        value = value[part]\n+                return test(value)\n+            except (KeyError, TypeError, ValueError):\n+                return False\n+\n+        return QueryInstance(runner, hashval)\n\n     def __eq__(self, rhs: Any):\n         \"\"\"\n@@ -255,7 +269,7 @@ class Query(QueryInstance):\n\n         &gt;&gt;&gt; Query().f1.exists()\n         \"\"\"\n-        pass\n+        return self._generate_test(lambda _: True, ('exists', self._path))\n\n     def matches(self, regex: str, flags: int=0) -&gt;QueryInstance:\n         \"\"\"\n@@ -266,7 +280,10 @@ class Query(QueryInstance):\n         :param regex: The regular expression to use for matching\n         :param flags: regex flags to pass to ``re.match``\n         \"\"\"\n-        pass\n+        return self._generate_test(\n+            lambda value: re.match(regex, value, flags) is not None,\n+            ('matches', self._path, regex, flags)\n+        )\n\n     def search(self, regex: str, flags: int=0) -&gt;QueryInstance:\n         \"\"\"\n@@ -278,7 +295,10 @@ class Query(QueryInstance):\n         :param regex: The regular expression to use for matching\n         :param flags: regex flags to pass to ``re.match``\n         \"\"\"\n-        pass\n+        return self._generate_test(\n+            lambda value: re.search(regex, value, flags) is not None,\n+            ('search', self._path, regex, flags)\n+        )\n\n     def test(self, func: Callable[[Mapping], bool], *args) -&gt;QueryInstance:\n         \"\"\"\n@@ -300,7 +320,10 @@ class Query(QueryInstance):\n                      argument\n         :param args: Additional arguments to pass to the test function\n         \"\"\"\n-        pass\n+        return self._generate_test(\n+            lambda value: func(value, *args),\n+            ('test', self._path, func, args)\n+        )\n\n     def any(self, cond: Union[QueryInstance, List[Any]]) -&gt;QueryInstance:\n         \"\"\"\n@@ -324,7 +347,14 @@ class Query(QueryInstance):\n                      a list of which at least one document has to be contained\n                      in the tested document.\n         \"\"\"\n-        pass\n+        if isinstance(cond, QueryInstance):\n+            def test(value):\n+                return any(cond(item) for item in value)\n+        else:\n+            def test(value):\n+                return any(item in cond for item in value)\n+\n+        return self._generate_test(test, ('any', self._path, freeze(cond)))\n\n     def all(self, cond: Union['QueryInstance', List[Any]]) -&gt;QueryInstance:\n         \"\"\"\n@@ -346,7 +376,14 @@ class Query(QueryInstance):\n         :param cond: Either a query that all documents have to match or a list\n                      which has to be contained in the tested document.\n         \"\"\"\n-        pass\n+        if isinstance(cond, QueryInstance):\n+            def test(value):\n+                return all(cond(item) for item in value)\n+        else:\n+            def test(value):\n+                return all(item in value for item in cond)\n+\n+        return self._generate_test(test, ('all', self._path, freeze(cond)))\n\n     def one_of(self, items: List[Any]) -&gt;QueryInstance:\n         \"\"\"\n@@ -356,7 +393,8 @@ class Query(QueryInstance):\n\n         :param items: The list of items to check with\n         \"\"\"\n-        pass\n+        return self._generate_test(lambda value: value in items,\n+                                   ('one_of', self._path, freeze(items)))\n\n     def noop(self) -&gt;QueryInstance:\n         \"\"\"\n@@ -364,18 +402,21 @@ class Query(QueryInstance):\n\n         Useful for having a base value when composing queries dynamically.\n         \"\"\"\n-        pass\n+        return self._generate_test(lambda _: True, ('noop',), allow_empty_path=True)\n\n     def map(self, fn: Callable[[Any], Any]) -&gt;'Query':\n         \"\"\"\n         Add a function to the query path. Similar to __getattr__ but for\n         arbitrary functions.\n         \"\"\"\n-        pass\n+        query = type(self)()\n+        query._path = self._path + (fn,)\n+        query._hash = ('path', query._path) if self.is_cacheable() else None\n+        return query\n\n\n def where(key: str) -&gt;Query:\n     \"\"\"\n     A shorthand for ``Query()[key]``\n     \"\"\"\n-    pass\n+    return Query()[key]\ndiff --git a/tinydb/storages.py b/tinydb/storages.py\nindex 0ddc223..16bfa7a 100644\n--- a/tinydb/storages.py\n+++ b/tinydb/storages.py\n@@ -18,7 +18,12 @@ def touch(path: str, create_dirs: bool):\n     :param path: The file to create.\n     :param create_dirs: Whether to create all missing parent directories.\n     \"\"\"\n-    pass\n+    if create_dirs:\n+        os.makedirs(os.path.dirname(path), exist_ok=True)\n+    \n+    if not os.path.exists(path):\n+        with open(path, 'a'):\n+            os.utime(path, None)\n\n\n class Storage(ABC):\n@@ -38,7 +43,7 @@ class Storage(ABC):\n\n         Return ``None`` here to indicate that the storage is empty.\n         \"\"\"\n-        pass\n+        raise NotImplementedError\n\n     @abstractmethod\n     def write(self, data: Dict[str, Dict[str, Any]]) -&gt;None:\n@@ -49,7 +54,7 @@ class Storage(ABC):\n\n         :param data: The current state of the database.\n         \"\"\"\n-        pass\n+        raise NotImplementedError\n\n     def close(self) -&gt;None:\n         \"\"\"\n@@ -88,6 +93,40 @@ class JSONStorage(Storage):\n         if any([(character in self._mode) for character in ('+', 'w', 'a')]):\n             touch(path, create_dirs=create_dirs)\n         self._handle = open(path, mode=self._mode, encoding=encoding)\n+        self.path = path\n+        self.encoding = encoding\n+\n+    def read(self) -&gt;Optional[Dict[str, Dict[str, Any]]]:\n+        \"\"\"\n+        Read the current state.\n+\n+        Any kind of deserialization should go here.\n+\n+        Return ``None`` here to indicate that the storage is empty.\n+        \"\"\"\n+        self._handle.seek(0)\n+        try:\n+            return json.load(self._handle)\n+        except json.JSONDecodeError:\n+            return None\n+\n+    def write(self, data: Dict[str, Dict[str, Any]]) -&gt;None:\n+        \"\"\"\n+        Write the current state of the database to the storage.\n+\n+        Any kind of serialization should go here.\n+\n+        :param data: The current state of the database.\n+        \"\"\"\n+        self._handle.seek(0)\n+        json.dump(data, self._handle, **self.kwargs)\n+        self._handle.truncate()\n+\n+    def close(self) -&gt;None:\n+        \"\"\"\n+        Close open file handles.\n+        \"\"\"\n+        self._handle.close()\n\n\n class MemoryStorage(Storage):\n@@ -101,3 +140,25 @@ class MemoryStorage(Storage):\n         \"\"\"\n         super().__init__()\n         self.memory = None\n+\n+    def read(self) -&gt;Optional[Dict[str, Dict[str, Any]]]:\n+        \"\"\"\n+        Read the current state from memory.\n+\n+        Return ``None`` here to indicate that the storage is empty.\n+        \"\"\"\n+        return self.memory\n+\n+    def write(self, data: Dict[str, Dict[str, Any]]) -&gt;None:\n+        \"\"\"\n+        Write the current state of the database to memory.\n+\n+        :param data: The current state of the database.\n+        \"\"\"\n+        self.memory = data\n+\n+    def close(self) -&gt;None:\n+        \"\"\"\n+        Clear the memory.\n+        \"\"\"\n+        self.memory = None\ndiff --git a/tinydb/table.py b/tinydb/table.py\nindex 48eea63..1e85fff 100644\n--- a/tinydb/table.py\n+++ b/tinydb/table.py\n@@ -85,14 +85,14 @@ class Table:\n         \"\"\"\n         Get the table name.\n         \"\"\"\n-        pass\n+        return self._name\n\n     @property\n     def storage(self) -&gt;Storage:\n         \"\"\"\n         Get the table storage instance.\n         \"\"\"\n-        pass\n+        return self._storage\n\n     def insert(self, document: Mapping) -&gt;int:\n         \"\"\"\n@@ -101,7 +101,10 @@ class Table:\n         :param document: the document to insert\n         :returns: the inserted document's ID\n         \"\"\"\n-        pass\n+        doc_id = self._get_next_id()\n+        self._update_table(lambda table: table.update({doc_id: document}))\n+        self.clear_cache()\n+        return doc_id\n\n     def insert_multiple(self, documents: Iterable[Mapping]) -&gt;List[int]:\n         \"\"\"\n@@ -110,7 +113,15 @@ class Table:\n         :param documents: an Iterable of documents to insert\n         :returns: a list containing the inserted documents' IDs\n         \"\"\"\n-        pass\n+        doc_ids = []\n+        def updater(table):\n+            for document in documents:\n+                doc_id = self._get_next_id()\n+                table[doc_id] = document\n+                doc_ids.append(doc_id)\n+        self._update_table(updater)\n+        self.clear_cache()\n+        return doc_ids\n\n     def all(self) -&gt;List[Document]:\n         \"\"\"\n@@ -118,7 +129,8 @@ class Table:\n\n         :returns: a list with all documents.\n         \"\"\"\n-        pass\n+        return [self.document_class(doc, self.document_id_class(doc_id))\n+                for doc_id, doc in self._read_table().items()]\n\n     def search(self, cond: QueryLike) -&gt;List[Document]:\n         \"\"\"\n@@ -127,7 +139,12 @@ class Table:\n         :param cond: the condition to check against\n         :returns: list of matching documents\n         \"\"\"\n-        pass\n+        if cond in self._query_cache:\n+            return self._query_cache[cond]\n+\n+        docs = [doc for doc in self.all() if cond(doc)]\n+        self._query_cache[cond] = docs\n+        return docs\n\n     def get(self, cond: Optional[QueryLike]=None, doc_id: Optional[int]=\n         None, doc_ids: Optional[List]=None) -&gt;Optional[Union[Document, List\n@@ -145,7 +162,25 @@ class Table:\n\n         :returns: the document(s) or ``None``\n         \"\"\"\n-        pass\n+        if doc_id is not None:\n+            table = self._read_table()\n+            if doc_id in table:\n+                return self.document_class(table[doc_id], self.document_id_class(doc_id))\n+            return None\n+        \n+        if doc_ids is not None:\n+            docs = []\n+            table = self._read_table()\n+            for id in doc_ids:\n+                if id in table:\n+                    docs.append(self.document_class(table[id], self.document_id_class(id)))\n+            return docs if docs else None\n+        \n+        if cond is not None:\n+            docs = self.search(cond)\n+            return docs[0] if docs else None\n+        \n+        return None\n\n     def contains(self, cond: Optional[QueryLike]=None, doc_id: Optional[int\n         ]=None) -&gt;bool:\n@@ -158,7 +193,10 @@ class Table:\n         :param cond: the condition use\n         :param doc_id: the document ID to look for\n         \"\"\"\n-        pass\n+        if doc_id is not None:\n+            return doc_id in self._read_table()\n+        \n+        return bool(self.search(cond)) if cond is not None else False\n\n     def update(self, fields: Union[Mapping, Callable[[Mapping], None]],\n         cond: Optional[QueryLike]=None, doc_ids: Optional[Iterable[int]]=None\n@@ -172,7 +210,21 @@ class Table:\n         :param doc_ids: a list of document IDs\n         :returns: a list containing the updated document's ID\n         \"\"\"\n-        pass\n+        updated_ids = []\n+\n+        def updater(table):\n+            nonlocal updated_ids\n+            for doc_id, doc in table.items():\n+                if (doc_ids is None or doc_id in doc_ids) and (cond is None or cond(doc)):\n+                    if callable(fields):\n+                        fields(doc)\n+                    else:\n+                        doc.update(fields)\n+                    updated_ids.append(doc_id)\n+\n+        self._update_table(updater)\n+        self.clear_cache()\n+        return updated_ids\n\n     def update_multiple(self, updates: Iterable[Tuple[Union[Mapping,\n         Callable[[Mapping], None]], QueryLike]]) -&gt;List[int]:\n@@ -181,7 +233,10 @@ class Table:\n\n         :returns: a list containing the updated document's ID\n         \"\"\"\n-        pass\n+        updated_ids = []\n+        for fields, cond in updates:\n+            updated_ids.extend(self.update(fields, cond))\n+        return updated_ids\n\n     def upsert(self, document: Mapping, cond: Optional[QueryLike]=None) -&gt;List[\n         int]:\n@@ -197,7 +252,19 @@ class Table:\n         Document with a doc_id\n         :returns: a list containing the updated documents' IDs\n         \"\"\"\n-        pass\n+        if isinstance(document, Document):\n+            doc_id = document.doc_id\n+            document = dict(document)\n+            del document['doc_id']\n+            cond = Query().doc_id == doc_id\n+\n+        if cond is None:\n+            return [self.insert(document)]\n+        \n+        updated = self.update(document, cond)\n+        if not updated:\n+            return [self.insert(document)]\n+        return updated\n\n     def remove(self, cond: Optional[QueryLike]=None, doc_ids: Optional[\n         Iterable[int]]=None) -&gt;List[int]:\n@@ -208,13 +275,31 @@ class Table:\n         :param doc_ids: a list of document IDs\n         :returns: a list containing the removed documents' ID\n         \"\"\"\n-        pass\n+        removed = []\n+\n+        def remover(table):\n+            nonlocal removed\n+            if doc_ids is not None:\n+                for doc_id in doc_ids:\n+                    if doc_id in table:\n+                        del table[doc_id]\n+                        removed.append(doc_id)\n+            else:\n+                for doc_id, doc in list(table.items()):\n+                    if cond is None or cond(doc):\n+                        del table[doc_id]\n+                        removed.append(doc_id)\n+\n+        self._update_table(remover)\n+        self.clear_cache()\n+        return removed\n\n     def truncate(self) -&gt;None:\n         \"\"\"\n         Truncate the table by removing all documents.\n         \"\"\"\n-        pass\n+        self._update_table(lambda table: table.clear())\n+        self.clear_cache()\n\n     def count(self, cond: QueryLike) -&gt;int:\n         \"\"\"\n@@ -222,13 +307,13 @@ class Table:\n\n         :param cond: the condition use\n         \"\"\"\n-        pass\n+        return len(self.search(cond))\n\n     def clear_cache(self) -&gt;None:\n         \"\"\"\n         Clear the query cache.\n         \"\"\"\n-        pass\n+        self._query_cache.clear()\n\n     def __len__(self):\n         \"\"\"\n@@ -249,7 +334,11 @@ class Table:\n         \"\"\"\n         Return the ID for a newly inserted document.\n         \"\"\"\n-        pass\n+        if self._next_id is None:\n+            self._next_id = max(self._read_table().keys() or [0]) + 1\n+        else:\n+            self._next_id += 1\n+        return self._next_id\n\n     def _read_table(self) -&gt;Dict[str, Mapping]:\n         \"\"\"\n@@ -259,7 +348,7 @@ class Table:\n         we may not want to convert *all* documents when returning\n         only one document for example.\n         \"\"\"\n-        pass\n+        return self._storage.read() or {}\n\n     def _update_table(self, updater: Callable[[Dict[int, Mapping]], None]):\n         \"\"\"\n@@ -274,4 +363,6 @@ class Table:\n         As a further optimization, we don't convert the documents into the\n         document class, as the table data will *not* be returned to the user.\n         \"\"\"\n-        pass\n+        data = self._read_table()\n+        updater(data)\n+        self._storage.write(data)\ndiff --git a/tinydb/utils.py b/tinydb/utils.py\nindex 0721622..9957b9e 100644\n--- a/tinydb/utils.py\n+++ b/tinydb/utils.py\n@@ -23,7 +23,8 @@ def with_typehint(baseclass: Type[T]):\n     MyPy does not. For that reason TinyDB has a MyPy plugin in\n     ``mypy_plugin.py`` that adds support for this pattern.\n     \"\"\"\n-    pass\n+    # The actual implementation is handled by the MyPy plugin in mypy_plugin.py\n+    return baseclass\n\n\n class LRUCache(abc.MutableMapping, Generic[K, V]):\n@@ -45,26 +46,40 @@ class LRUCache(abc.MutableMapping, Generic[K, V]):\n         self.cache: OrderedDict[K, V] = OrderedDict()\n\n     def __len__(self) -&gt;int:\n-        return self.length\n+        return len(self.cache)\n\n     def __contains__(self, key: object) -&gt;bool:\n         return key in self.cache\n\n     def __setitem__(self, key: K, value: V) -&gt;None:\n-        self.set(key, value)\n+        if key in self.cache:\n+            del self.cache[key]\n+        elif len(self.cache) &gt;= self.capacity:\n+            self.cache.popitem(last=False)\n+        self.cache[key] = value\n\n     def __delitem__(self, key: K) -&gt;None:\n         del self.cache[key]\n\n-    def __getitem__(self, key) -&gt;V:\n-        value = self.get(key)\n-        if value is None:\n+    def __getitem__(self, key: K) -&gt;V:\n+        if key not in self.cache:\n             raise KeyError(key)\n+        value = self.cache.pop(key)\n+        self.cache[key] = value\n         return value\n\n     def __iter__(self) -&gt;Iterator[K]:\n         return iter(self.cache)\n\n+    def get(self, key: K, default: Optional[D] = None) -&gt; Union[V, D, None]:\n+        try:\n+            return self[key]\n+        except KeyError:\n+            return default\n+\n+    def set(self, key: K, value: V) -&gt; None:\n+        self[key] = value\n+\n\n class FrozenDict(dict):\n     \"\"\"\n@@ -88,4 +103,10 @@ def freeze(obj):\n     \"\"\"\n     Freeze an object by making it immutable and thus hashable.\n     \"\"\"\n-    pass\n+    if isinstance(obj, dict):\n+        return FrozenDict((k, freeze(v)) for k, v in obj.items())\n+    elif isinstance(obj, list):\n+        return tuple(freeze(i) for i in obj)\n+    elif isinstance(obj, set):\n+        return frozenset(freeze(i) for i in obj)\n+    return obj\n</code></pre>"},{"location":"analysis_baseline_voluptuous/","title":"Analysis baseline voluptuous","text":"<p>back to baseline summary</p>"},{"location":"analysis_baseline_voluptuous/#submission-name-baseline","title":"Submission Name: baseline","text":""},{"location":"analysis_baseline_voluptuous/#repository-voluptuous","title":"Repository: voluptuous","text":""},{"location":"analysis_baseline_voluptuous/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count error 1 total 1 collected 1 passed 0"},{"location":"analysis_baseline_voluptuous/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_baseline_voluptuous/#testsmdtestsmd","title":"tests.md::tests.md","text":"<pre>tests.md::tests.md</pre><pre>\npath = PosixPath('/testbed/voluptuous/__init__.py')\nconfig = &lt;_pytest.config.Config object at 0x7f47d55d8820&gt;\n\n    def importtestmodule(\n        path: Path,\n        config: Config,\n    ):\n        # We assume we are only called once per module.\n        importmode = config.getoption(\"--import-mode\")\n        try:\n&gt;           mod = import_path(\n                path,\n                mode=importmode,\n                root=config.rootpath,\n                consider_namespace_packages=config.getini(\"consider_namespace_packages\"),\n            )\n\n.venv/lib/python3.10/site-packages/_pytest/python.py:493: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\npath = PosixPath('/testbed/voluptuous/__init__.py')\n\n    def import_path(\n        path: str | os.PathLike[str],\n        *,\n        mode: str | ImportMode = ImportMode.prepend,\n        root: Path,\n        consider_namespace_packages: bool,\n    ) -&gt; ModuleType:\n        \"\"\"\n        Import and return a module from the given path, which can be a file (a module) or\n        a directory (a package).\n\n        :param path:\n            Path to the file to import.\n\n        :param mode:\n            Controls the underlying import mechanism that will be used:\n\n            * ImportMode.prepend: the directory containing the module (or package, taking\n              `__init__.py` files into account) will be put at the *start* of `sys.path` before\n              being imported with `importlib.import_module`.\n\n            * ImportMode.append: same as `prepend`, but the directory will be appended\n              to the end of `sys.path`, if not already in `sys.path`.\n\n            * ImportMode.importlib: uses more fine control mechanisms provided by `importlib`\n              to import the module, which avoids having to muck with `sys.path` at all. It effectively\n              allows having same-named test modules in different places.\n\n        :param root:\n            Used as an anchor when mode == ImportMode.importlib to obtain\n            a unique name for the module being imported so it can safely be stored\n            into ``sys.modules``.\n\n        :param consider_namespace_packages:\n            If True, consider namespace packages when resolving module names.\n\n        :raises ImportPathMismatchError:\n            If after importing the given `path` and the module `__file__`\n            are different. Only raised in `prepend` and `append` modes.\n        \"\"\"\n        path = Path(path)\n        mode = ImportMode(mode)\n\n        if not path.exists():\n            raise ImportError(path)\n\n        if mode is ImportMode.importlib:\n            # Try to import this module using the standard import mechanisms, but\n            # without touching sys.path.\n            try:\n                pkg_root, module_name = resolve_pkg_root_and_module_name(\n                    path, consider_namespace_packages=consider_namespace_packages\n                )\n            except CouldNotResolvePathError:\n                pass\n            else:\n                # If the given module name is already in sys.modules, do not import it again.\n                with contextlib.suppress(KeyError):\n                    return sys.modules[module_name]\n\n                mod = _import_module_using_spec(\n                    module_name, path, pkg_root, insert_modules=False\n                )\n                if mod is not None:\n                    return mod\n\n            # Could not import the module with the current sys.path, so we fall back\n            # to importing the file as a single module, not being a part of a package.\n            module_name = module_name_from_path(path, root)\n            with contextlib.suppress(KeyError):\n                return sys.modules[module_name]\n\n            mod = _import_module_using_spec(\n                module_name, path, path.parent, insert_modules=True\n            )\n            if mod is None:\n                raise ImportError(f\"Can't find module {module_name} at location {path}\")\n            return mod\n\n        try:\n            pkg_root, module_name = resolve_pkg_root_and_module_name(\n                path, consider_namespace_packages=consider_namespace_packages\n            )\n        except CouldNotResolvePathError:\n            pkg_root, module_name = path.parent, path.stem\n\n        # Change sys.path permanently: restoring it at the end of this function would cause surprising\n        # problems because of delayed imports: for example, a conftest.py file imported by this function\n        # might have local imports, which would fail at runtime if we restored sys.path.\n        if mode is ImportMode.append:\n            if str(pkg_root) not in sys.path:\n                sys.path.append(str(pkg_root))\n        elif mode is ImportMode.prepend:\n            if str(pkg_root) != sys.path[0]:\n                sys.path.insert(0, str(pkg_root))\n        else:\n            assert_never(mode)\n\n&gt;       importlib.import_module(module_name)\n\n.venv/lib/python3.10/site-packages/_pytest/pathlib.py:582: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = 'voluptuous', package = None\n\n    def import_module(name, package=None):\n        \"\"\"Import a module.\n\n        The 'package' argument is required when performing a relative import. It\n        specifies the package to use as the anchor point from which to resolve the\n        relative import to an absolute import.\n\n        \"\"\"\n        level = 0\n        if name.startswith('.'):\n            if not package:\n                msg = (\"the 'package' argument is required to perform a relative \"\n                       \"import for {!r}\")\n                raise TypeError(msg.format(name))\n            for character in name:\n                if character != '.':\n                    break\n                level += 1\n&gt;       return _bootstrap._gcd_import(name[level:], package, level)\n\n/usr/lib/python3.10/importlib/__init__.py:126: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = 'voluptuous', package = None, level = 0\n\n&gt;   ???\n\n:1050: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = 'voluptuous', import_ = \n\n&gt;   ???\n\n:1027: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = 'voluptuous', import_ = \n\n&gt;   ???\n\n:1006: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nspec = ModuleSpec(name='voluptuous', loader=&lt;_frozen_importlib_external.SourceFileLoader object at 0x7f47d5bf99c0&gt;, origin='/testbed/voluptuous/__init__.py', submodule_search_locations=['/testbed/voluptuous'])\n\n&gt;   ???\n\n:688: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &lt;_frozen_importlib_external.SourceFileLoader object at 0x7f47d5bf99c0&gt;\nmodule = \n\n&gt;   ???\n\n:883: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nf = \nargs = (<code> at 0x7f47d4912340, file \"/testbed/voluptuous/__init__.py\", line 1&gt;, {'ALLOW_EXTRA': 1, 'Default...ing.Any]], 'Error': , 'Exclusive': , ...})\nkwds = {}\n\n&gt;   ???\n\n:241: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    \"\"\"Schema validation for Python data structures.\n\n    Given eg. a nested data structure like this:\n\n        {\n            'exclude': ['Users', 'Uptime'],\n            'include': [],\n            'set': {\n                'snmp_community': 'public',\n                'snmp_timeout': 15,\n                'snmp_version': '2c',\n            },\n            'targets': {\n                'localhost': {\n                    'exclude': ['Uptime'],\n                    'features': {\n                        'Uptime': {\n                            'retries': 3,\n                        },\n                        'Users': {\n                            'snmp_community': 'monkey',\n                            'snmp_port': 15,\n                        },\n                    },\n                    'include': ['Users'],\n                    'set': {\n                        'snmp_community': 'monkeys',\n                    },\n                },\n            },\n        }\n\n    A schema like this:\n\n        &gt;&gt;&gt; settings = {\n        ...   'snmp_community': str,\n        ...   'retries': int,\n        ...   'snmp_version': All(Coerce(str), Any('3', '2c', '1')),\n        ... }\n        &gt;&gt;&gt; features = ['Ping', 'Uptime', 'Http']\n        &gt;&gt;&gt; schema = Schema({\n        ...    'exclude': features,\n        ...    'include': features,\n        ...    'set': settings,\n        ...    'targets': {\n        ...      'exclude': features,\n        ...      'include': features,\n        ...      'features': {\n        ...        str: settings,\n        ...      },\n        ...    },\n        ... })\n\n    Validate like so:\n\n        &gt;&gt;&gt; schema({\n        ...   'set': {\n        ...     'snmp_community': 'public',\n        ...     'snmp_version': '2c',\n        ...   },\n        ...   'targets': {\n        ...     'exclude': ['Ping'],\n        ...     'features': {\n        ...       'Uptime': {'retries': 3},\n        ...       'Users': {'snmp_community': 'monkey'},\n        ...     },\n        ...   },\n        ... }) == {\n        ...   'set': {'snmp_version': '2c', 'snmp_community': 'public'},\n        ...   'targets': {\n        ...     'exclude': ['Ping'],\n        ...     'features': {'Uptime': {'retries': 3},\n        ...                  'Users': {'snmp_community': 'monkey'}}}}\n        True\n    \"\"\"\n\n    # flake8: noqa\n    # fmt: off\n    from voluptuous.schema_builder import *\n&gt;   from voluptuous.util import *\n\nvoluptuous/__init__.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    import typing\n&gt;   from voluptuous import validators\n\nvoluptuous/util.py:2: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    from __future__ import annotations\n    import datetime\n    import os\n    import re\n    import sys\n    import typing\n    from decimal import Decimal, InvalidOperation\n    from functools import wraps\n    from voluptuous.error import AllInvalid, AnyInvalid, BooleanInvalid, CoerceInvalid, ContainsInvalid, DateInvalid, DatetimeInvalid, DirInvalid, EmailInvalid, ExactSequenceInvalid, FalseInvalid, FileInvalid, InInvalid, Invalid, LengthInvalid, MatchInvalid, MultipleInvalid, NotEnoughValid, NotInInvalid, PathInvalid, RangeInvalid, TooManyValid, TrueInvalid, TypeInvalid, UrlInvalid\n&gt;   from voluptuous.schema_builder import Schema, Schemable, message, raises\nE   ImportError: cannot import name 'raises' from 'voluptuous.schema_builder' (/testbed/voluptuous/schema_builder.py)\n\nvoluptuous/validators.py:10: ImportError\n\nThe above exception was the direct cause of the following exception:\n\ncls = \nfunc = . at 0x7f47d48f12d0&gt;\nwhen = 'setup'\nreraise = (, )\n\n    @classmethod\n    def from_call(\n        cls,\n        func: Callable[[], TResult],\n        when: Literal[\"collect\", \"setup\", \"call\", \"teardown\"],\n        reraise: type[BaseException] | tuple[type[BaseException], ...] | None = None,\n    ) -&gt; CallInfo[TResult]:\n        \"\"\"Call func, wrapping the result in a CallInfo.\n\n        :param func:\n            The function to call. Called without arguments.\n        :type func: Callable[[], _pytest.runner.TResult]\n        :param when:\n            The phase in which the function is called.\n        :param reraise:\n            Exception or exceptions that shall propagate if raised by the\n            function, instead of being wrapped in the CallInfo.\n        \"\"\"\n        excinfo = None\n        start = timing.time()\n        precise_start = timing.perf_counter()\n        try:\n&gt;           result: TResult | None = func()\n\n.venv/lib/python3.10/site-packages/_pytest/runner.py:341: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n&gt;       lambda: runtest_hook(item=item, **kwds), when=when, reraise=reraise\n    )\n\n.venv/lib/python3.10/site-packages/_pytest/runner.py:242: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \nkwargs = {'item': }, firstresult = False\n\n    def __call__(self, **kwargs: object) -&gt; Any:\n        \"\"\"Call the hook.\n\n        Only accepts keyword arguments, which should match the hook\n        specification.\n\n        Returns the result(s) of calling all registered plugins, see\n        :ref:`calling`.\n        \"\"\"\n        assert (\n            not self.is_historic()\n        ), \"Cannot directly call a historic hook - use call_historic instead.\"\n        self._verify_all_args_are_provided(kwargs)\n        firstresult = self.spec.opts.get(\"firstresult\", False) if self.spec else False\n        # Copy because plugins may register other plugins during iteration (#438).\n&gt;       return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n\n.venv/lib/python3.10/site-packages/pluggy/_hooks.py:513: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &lt;_pytest.config.PytestPluginManager object at 0x7f47d5b5ff40&gt;\nhook_name = 'pytest_runtest_setup'\nmethods = [&gt;, &gt;, ...]\nkwargs = {'item': }, firstresult = False\n\n    def _hookexec(\n        self,\n        hook_name: str,\n        methods: Sequence[HookImpl],\n        kwargs: Mapping[str, object],\n        firstresult: bool,\n    ) -&gt; object | list[object]:\n        # called from all hookcaller instances.\n        # enable_tracing will set its own wrapping function at self._inner_hookexec\n&gt;       return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n\n.venv/lib/python3.10/site-packages/pluggy/_manager.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhook_name = 'pytest_runtest_setup'\nhook_impls = [&gt;, &gt;, ...]\ncaller_kwargs = {'item': }, firstresult = False\n\n    def _multicall(\n        hook_name: str,\n        hook_impls: Sequence[HookImpl],\n        caller_kwargs: Mapping[str, object],\n        firstresult: bool,\n    ) -&gt; object | list[object]:\n        \"\"\"Execute a call into multiple python functions/methods and return the\n        result(s).\n\n        ``caller_kwargs`` comes from HookCaller.__call__().\n        \"\"\"\n        __tracebackhide__ = True\n        results: list[object] = []\n        exception = None\n        only_new_style_wrappers = True\n        try:  # run impl and wrapper setup functions in a loop\n            teardowns: list[Teardown] = []\n            try:\n                for hook_impl in reversed(hook_impls):\n                    try:\n                        args = [caller_kwargs[argname] for argname in hook_impl.argnames]\n                    except KeyError:\n                        for argname in hook_impl.argnames:\n                            if argname not in caller_kwargs:\n                                raise HookCallError(\n                                    f\"hook call must provide argument {argname!r}\"\n                                )\n\n                    if hook_impl.hookwrapper:\n                        only_new_style_wrappers = False\n                        try:\n                            # If this cast is not valid, a type error is raised below,\n                            # which is the desired response.\n                            res = hook_impl.function(*args)\n                            wrapper_gen = cast(Generator[None, Result[object], None], res)\n                            next(wrapper_gen)  # first yield\n                            teardowns.append((wrapper_gen, hook_impl))\n                        except StopIteration:\n                            _raise_wrapfail(wrapper_gen, \"did not yield\")\n                    elif hook_impl.wrapper:\n                        try:\n                            # If this cast is not valid, a type error is raised below,\n                            # which is the desired response.\n                            res = hook_impl.function(*args)\n                            function_gen = cast(Generator[None, object, object], res)\n                            next(function_gen)  # first yield\n                            teardowns.append(function_gen)\n                        except StopIteration:\n                            _raise_wrapfail(function_gen, \"did not yield\")\n                    else:\n                        res = hook_impl.function(*args)\n                        if res is not None:\n                            results.append(res)\n                            if firstresult:  # halt further impl calls\n                                break\n            except BaseException as exc:\n                exception = exc\n        finally:\n            # Fast path - only new-style wrappers, no Result.\n            if only_new_style_wrappers:\n                if firstresult:  # first result hooks return a single value\n                    result = results[0] if results else None\n                else:\n                    result = results\n\n                # run all wrapper post-yield blocks\n                for teardown in reversed(teardowns):\n                    try:\n                        if exception is not None:\n                            teardown.throw(exception)  # type: ignore[union-attr]\n                        else:\n                            teardown.send(result)  # type: ignore[union-attr]\n                        # Following is unreachable for a well behaved hook wrapper.\n                        # Try to force finalizers otherwise postponed till GC action.\n                        # Note: close() may raise if generator handles GeneratorExit.\n                        teardown.close()  # type: ignore[union-attr]\n                    except StopIteration as si:\n                        result = si.value\n                        exception = None\n                        continue\n                    except BaseException as e:\n                        exception = e\n                        continue\n                    _raise_wrapfail(teardown, \"has second yield\")  # type: ignore[arg-type]\n\n                if exception is not None:\n                    raise exception.with_traceback(exception.__traceback__)\n                else:\n                    return result\n\n            # Slow path - need to support old-style wrappers.\n            else:\n                if firstresult:  # first result hooks return a single value\n                    outcome: Result[object | list[object]] = Result(\n                        results[0] if results else None, exception\n                    )\n                else:\n                    outcome = Result(results, exception)\n\n                # run all wrapper post-yield blocks\n                for teardown in reversed(teardowns):\n                    if isinstance(teardown, tuple):\n                        try:\n                            teardown[0].send(outcome)\n                        except StopIteration:\n                            pass\n                        except BaseException as e:\n                            _warn_teardown_exception(hook_name, teardown[1], e)\n                            raise\n                        else:\n                            _raise_wrapfail(teardown[0], \"has second yield\")\n                    else:\n                        try:\n                            if outcome._exception is not None:\n                                teardown.throw(outcome._exception)\n                            else:\n                                teardown.send(outcome._result)\n                            # Following is unreachable for a well behaved hook wrapper.\n                            # Try to force finalizers otherwise postponed till GC action.\n                            # Note: close() may raise if generator handles GeneratorExit.\n                            teardown.close()\n                        except StopIteration as si:\n                            outcome.force_result(si.value)\n                            continue\n                        except BaseException as e:\n                            outcome.force_exception(e)\n                            continue\n                        _raise_wrapfail(teardown, \"has second yield\")\n\n&gt;               return outcome.get_result()\n\n.venv/lib/python3.10/site-packages/pluggy/_callers.py:182: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def get_result(self) -&gt; ResultType:\n        \"\"\"Get the result(s) for this hook call.\n\n        If the hook was marked as a ``firstresult`` only a single value\n        will be returned, otherwise a list of results.\n        \"\"\"\n        __tracebackhide__ = True\n        exc = self._exception\n        if exc is None:\n            return cast(ResultType, self._result)\n        else:\n&gt;           raise exc.with_traceback(exc.__traceback__)\n\n.venv/lib/python3.10/site-packages/pluggy/_result.py:100: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhook_name = 'pytest_runtest_setup'\nhook_impls = [&gt;, &gt;, ...]\ncaller_kwargs = {'item': }, firstresult = False\n\n    def _multicall(\n        hook_name: str,\n        hook_impls: Sequence[HookImpl],\n        caller_kwargs: Mapping[str, object],\n        firstresult: bool,\n    ) -&gt; object | list[object]:\n        \"\"\"Execute a call into multiple python functions/methods and return the\n        result(s).\n\n        ``caller_kwargs`` comes from HookCaller.__call__().\n        \"\"\"\n        __tracebackhide__ = True\n        results: list[object] = []\n        exception = None\n        only_new_style_wrappers = True\n        try:  # run impl and wrapper setup functions in a loop\n            teardowns: list[Teardown] = []\n            try:\n                for hook_impl in reversed(hook_impls):\n                    try:\n                        args = [caller_kwargs[argname] for argname in hook_impl.argnames]\n                    except KeyError:\n                        for argname in hook_impl.argnames:\n                            if argname not in caller_kwargs:\n                                raise HookCallError(\n                                    f\"hook call must provide argument {argname!r}\"\n                                )\n\n                    if hook_impl.hookwrapper:\n                        only_new_style_wrappers = False\n                        try:\n                            # If this cast is not valid, a type error is raised below,\n                            # which is the desired response.\n                            res = hook_impl.function(*args)\n                            wrapper_gen = cast(Generator[None, Result[object], None], res)\n                            next(wrapper_gen)  # first yield\n                            teardowns.append((wrapper_gen, hook_impl))\n                        except StopIteration:\n                            _raise_wrapfail(wrapper_gen, \"did not yield\")\n                    elif hook_impl.wrapper:\n                        try:\n                            # If this cast is not valid, a type error is raised below,\n                            # which is the desired response.\n                            res = hook_impl.function(*args)\n                            function_gen = cast(Generator[None, object, object], res)\n                            next(function_gen)  # first yield\n                            teardowns.append(function_gen)\n                        except StopIteration:\n                            _raise_wrapfail(function_gen, \"did not yield\")\n                    else:\n                        res = hook_impl.function(*args)\n                        if res is not None:\n                            results.append(res)\n                            if firstresult:  # halt further impl calls\n                                break\n            except BaseException as exc:\n                exception = exc\n        finally:\n            # Fast path - only new-style wrappers, no Result.\n            if only_new_style_wrappers:\n                if firstresult:  # first result hooks return a single value\n                    result = results[0] if results else None\n                else:\n                    result = results\n\n                # run all wrapper post-yield blocks\n                for teardown in reversed(teardowns):\n                    try:\n                        if exception is not None:\n                            teardown.throw(exception)  # type: ignore[union-attr]\n                        else:\n                            teardown.send(result)  # type: ignore[union-attr]\n                        # Following is unreachable for a well behaved hook wrapper.\n                        # Try to force finalizers otherwise postponed till GC action.\n                        # Note: close() may raise if generator handles GeneratorExit.\n                        teardown.close()  # type: ignore[union-attr]\n                    except StopIteration as si:\n                        result = si.value\n                        exception = None\n                        continue\n                    except BaseException as e:\n                        exception = e\n                        continue\n                    _raise_wrapfail(teardown, \"has second yield\")  # type: ignore[arg-type]\n\n                if exception is not None:\n                    raise exception.with_traceback(exception.__traceback__)\n                else:\n                    return result\n\n            # Slow path - need to support old-style wrappers.\n            else:\n                if firstresult:  # first result hooks return a single value\n                    outcome: Result[object | list[object]] = Result(\n                        results[0] if results else None, exception\n                    )\n                else:\n                    outcome = Result(results, exception)\n\n                # run all wrapper post-yield blocks\n                for teardown in reversed(teardowns):\n                    if isinstance(teardown, tuple):\n                        try:\n                            teardown[0].send(outcome)\n                        except StopIteration:\n                            pass\n                        except BaseException as e:\n                            _warn_teardown_exception(hook_name, teardown[1], e)\n                            raise\n                        else:\n                            _raise_wrapfail(teardown[0], \"has second yield\")\n                    else:\n                        try:\n                            if outcome._exception is not None:\n&gt;                               teardown.throw(outcome._exception)\n\n.venv/lib/python3.10/site-packages/pluggy/_callers.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    @pytest.hookimpl(wrapper=True, tryfirst=True)\n    def pytest_runtest_setup() -&gt; Generator[None]:\n&gt;       yield from unraisable_exception_runtest_hook()\n\n.venv/lib/python3.10/site-packages/_pytest/unraisableexception.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def unraisable_exception_runtest_hook() -&gt; Generator[None]:\n        with catch_unraisable_exception() as cm:\n            try:\n&gt;               yield\n\n.venv/lib/python3.10/site-packages/_pytest/unraisableexception.py:70: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhook_name = 'pytest_runtest_setup'\nhook_impls = [&gt;, &gt;, ...]\ncaller_kwargs = {'item': }, firstresult = False\n\n    def _multicall(\n        hook_name: str,\n        hook_impls: Sequence[HookImpl],\n        caller_kwargs: Mapping[str, object],\n        firstresult: bool,\n    ) -&gt; object | list[object]:\n        \"\"\"Execute a call into multiple python functions/methods and return the\n        result(s).\n\n        ``caller_kwargs`` comes from HookCaller.__call__().\n        \"\"\"\n        __tracebackhide__ = True\n        results: list[object] = []\n        exception = None\n        only_new_style_wrappers = True\n        try:  # run impl and wrapper setup functions in a loop\n            teardowns: list[Teardown] = []\n            try:\n                for hook_impl in reversed(hook_impls):\n                    try:\n                        args = [caller_kwargs[argname] for argname in hook_impl.argnames]\n                    except KeyError:\n                        for argname in hook_impl.argnames:\n                            if argname not in caller_kwargs:\n                                raise HookCallError(\n                                    f\"hook call must provide argument {argname!r}\"\n                                )\n\n                    if hook_impl.hookwrapper:\n                        only_new_style_wrappers = False\n                        try:\n                            # If this cast is not valid, a type error is raised below,\n                            # which is the desired response.\n                            res = hook_impl.function(*args)\n                            wrapper_gen = cast(Generator[None, Result[object], None], res)\n                            next(wrapper_gen)  # first yield\n                            teardowns.append((wrapper_gen, hook_impl))\n                        except StopIteration:\n                            _raise_wrapfail(wrapper_gen, \"did not yield\")\n                    elif hook_impl.wrapper:\n                        try:\n                            # If this cast is not valid, a type error is raised below,\n                            # which is the desired response.\n                            res = hook_impl.function(*args)\n                            function_gen = cast(Generator[None, object, object], res)\n                            next(function_gen)  # first yield\n                            teardowns.append(function_gen)\n                        except StopIteration:\n                            _raise_wrapfail(function_gen, \"did not yield\")\n                    else:\n                        res = hook_impl.function(*args)\n                        if res is not None:\n                            results.append(res)\n                            if firstresult:  # halt further impl calls\n                                break\n            except BaseException as exc:\n                exception = exc\n        finally:\n            # Fast path - only new-style wrappers, no Result.\n            if only_new_style_wrappers:\n                if firstresult:  # first result hooks return a single value\n                    result = results[0] if results else None\n                else:\n                    result = results\n\n                # run all wrapper post-yield blocks\n                for teardown in reversed(teardowns):\n                    try:\n                        if exception is not None:\n                            teardown.throw(exception)  # type: ignore[union-attr]\n                        else:\n                            teardown.send(result)  # type: ignore[union-attr]\n                        # Following is unreachable for a well behaved hook wrapper.\n                        # Try to force finalizers otherwise postponed till GC action.\n                        # Note: close() may raise if generator handles GeneratorExit.\n                        teardown.close()  # type: ignore[union-attr]\n                    except StopIteration as si:\n                        result = si.value\n                        exception = None\n                        continue\n                    except BaseException as e:\n                        exception = e\n                        continue\n                    _raise_wrapfail(teardown, \"has second yield\")  # type: ignore[arg-type]\n\n                if exception is not None:\n                    raise exception.with_traceback(exception.__traceback__)\n                else:\n                    return result\n\n            # Slow path - need to support old-style wrappers.\n            else:\n                if firstresult:  # first result hooks return a single value\n                    outcome: Result[object | list[object]] = Result(\n                        results[0] if results else None, exception\n                    )\n                else:\n                    outcome = Result(results, exception)\n\n                # run all wrapper post-yield blocks\n                for teardown in reversed(teardowns):\n                    if isinstance(teardown, tuple):\n                        try:\n                            teardown[0].send(outcome)\n                        except StopIteration:\n                            pass\n                        except BaseException as e:\n                            _warn_teardown_exception(hook_name, teardown[1], e)\n                            raise\n                        else:\n                            _raise_wrapfail(teardown[0], \"has second yield\")\n                    else:\n                        try:\n                            if outcome._exception is not None:\n&gt;                               teardown.throw(outcome._exception)\n\n.venv/lib/python3.10/site-packages/pluggy/_callers.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &lt;_pytest.logging.LoggingPlugin object at 0x7f47d5bc4a60&gt;\nitem = \n\n    @hookimpl(wrapper=True)\n    def pytest_runtest_setup(self, item: nodes.Item) -&gt; Generator[None]:\n        self.log_cli_handler.set_when(\"setup\")\n\n        empty: dict[str, list[logging.LogRecord]] = {}\n        item.stash[caplog_records_key] = empty\n&gt;       yield from self._runtest_for(item, \"setup\")\n\n.venv/lib/python3.10/site-packages/_pytest/logging.py:840: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &lt;_pytest.logging.LoggingPlugin object at 0x7f47d5bc4a60&gt;\nitem = , when = 'setup'\n\n    def _runtest_for(self, item: nodes.Item, when: str) -&gt; Generator[None]:\n        \"\"\"Implement the internals of the pytest_runtest_xxx() hooks.\"\"\"\n        with catching_logs(\n            self.caplog_handler,\n            level=self.log_level,\n        ) as caplog_handler, catching_logs(\n            self.report_handler,\n            level=self.log_level,\n        ) as report_handler:\n            caplog_handler.reset()\n            report_handler.reset()\n            item.stash[caplog_records_key][when] = caplog_handler.records\n            item.stash[caplog_handler_key] = caplog_handler\n\n            try:\n&gt;               yield\n\n.venv/lib/python3.10/site-packages/_pytest/logging.py:829: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhook_name = 'pytest_runtest_setup'\nhook_impls = [&gt;, &gt;, ...]\ncaller_kwargs = {'item': }, firstresult = False\n\n    def _multicall(\n        hook_name: str,\n        hook_impls: Sequence[HookImpl],\n        caller_kwargs: Mapping[str, object],\n        firstresult: bool,\n    ) -&gt; object | list[object]:\n        \"\"\"Execute a call into multiple python functions/methods and return the\n        result(s).\n\n        ``caller_kwargs`` comes from HookCaller.__call__().\n        \"\"\"\n        __tracebackhide__ = True\n        results: list[object] = []\n        exception = None\n        only_new_style_wrappers = True\n        try:  # run impl and wrapper setup functions in a loop\n            teardowns: list[Teardown] = []\n            try:\n                for hook_impl in reversed(hook_impls):\n                    try:\n                        args = [caller_kwargs[argname] for argname in hook_impl.argnames]\n                    except KeyError:\n                        for argname in hook_impl.argnames:\n                            if argname not in caller_kwargs:\n                                raise HookCallError(\n                                    f\"hook call must provide argument {argname!r}\"\n                                )\n\n                    if hook_impl.hookwrapper:\n                        only_new_style_wrappers = False\n                        try:\n                            # If this cast is not valid, a type error is raised below,\n                            # which is the desired response.\n                            res = hook_impl.function(*args)\n                            wrapper_gen = cast(Generator[None, Result[object], None], res)\n                            next(wrapper_gen)  # first yield\n                            teardowns.append((wrapper_gen, hook_impl))\n                        except StopIteration:\n                            _raise_wrapfail(wrapper_gen, \"did not yield\")\n                    elif hook_impl.wrapper:\n                        try:\n                            # If this cast is not valid, a type error is raised below,\n                            # which is the desired response.\n                            res = hook_impl.function(*args)\n                            function_gen = cast(Generator[None, object, object], res)\n                            next(function_gen)  # first yield\n                            teardowns.append(function_gen)\n                        except StopIteration:\n                            _raise_wrapfail(function_gen, \"did not yield\")\n                    else:\n                        res = hook_impl.function(*args)\n                        if res is not None:\n                            results.append(res)\n                            if firstresult:  # halt further impl calls\n                                break\n            except BaseException as exc:\n                exception = exc\n        finally:\n            # Fast path - only new-style wrappers, no Result.\n            if only_new_style_wrappers:\n                if firstresult:  # first result hooks return a single value\n                    result = results[0] if results else None\n                else:\n                    result = results\n\n                # run all wrapper post-yield blocks\n                for teardown in reversed(teardowns):\n                    try:\n                        if exception is not None:\n                            teardown.throw(exception)  # type: ignore[union-attr]\n                        else:\n                            teardown.send(result)  # type: ignore[union-attr]\n                        # Following is unreachable for a well behaved hook wrapper.\n                        # Try to force finalizers otherwise postponed till GC action.\n                        # Note: close() may raise if generator handles GeneratorExit.\n                        teardown.close()  # type: ignore[union-attr]\n                    except StopIteration as si:\n                        result = si.value\n                        exception = None\n                        continue\n                    except BaseException as e:\n                        exception = e\n                        continue\n                    _raise_wrapfail(teardown, \"has second yield\")  # type: ignore[arg-type]\n\n                if exception is not None:\n                    raise exception.with_traceback(exception.__traceback__)\n                else:\n                    return result\n\n            # Slow path - need to support old-style wrappers.\n            else:\n                if firstresult:  # first result hooks return a single value\n                    outcome: Result[object | list[object]] = Result(\n                        results[0] if results else None, exception\n                    )\n                else:\n                    outcome = Result(results, exception)\n\n                # run all wrapper post-yield blocks\n                for teardown in reversed(teardowns):\n                    if isinstance(teardown, tuple):\n                        try:\n                            teardown[0].send(outcome)\n                        except StopIteration:\n                            pass\n                        except BaseException as e:\n                            _warn_teardown_exception(hook_name, teardown[1], e)\n                            raise\n                        else:\n                            _raise_wrapfail(teardown[0], \"has second yield\")\n                    else:\n                        try:\n                            if outcome._exception is not None:\n&gt;                               teardown.throw(outcome._exception)\n\n.venv/lib/python3.10/site-packages/pluggy/_callers.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &gt; _state='suspended' _in_suspended=False&gt; _capture_fixture=None&gt;\nitem = \n\n    @hookimpl(wrapper=True)\n    def pytest_runtest_setup(self, item: Item) -&gt; Generator[None]:\n        with self.item_capture(\"setup\", item):\n&gt;           return (yield)\n\n.venv/lib/python3.10/site-packages/_pytest/capture.py:875: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhook_name = 'pytest_runtest_setup'\nhook_impls = [&gt;, &gt;, ...]\ncaller_kwargs = {'item': }, firstresult = False\n\n    def _multicall(\n        hook_name: str,\n        hook_impls: Sequence[HookImpl],\n        caller_kwargs: Mapping[str, object],\n        firstresult: bool,\n    ) -&gt; object | list[object]:\n        \"\"\"Execute a call into multiple python functions/methods and return the\n        result(s).\n\n        ``caller_kwargs`` comes from HookCaller.__call__().\n        \"\"\"\n        __tracebackhide__ = True\n        results: list[object] = []\n        exception = None\n        only_new_style_wrappers = True\n        try:  # run impl and wrapper setup functions in a loop\n            teardowns: list[Teardown] = []\n            try:\n                for hook_impl in reversed(hook_impls):\n                    try:\n                        args = [caller_kwargs[argname] for argname in hook_impl.argnames]\n                    except KeyError:\n                        for argname in hook_impl.argnames:\n                            if argname not in caller_kwargs:\n                                raise HookCallError(\n                                    f\"hook call must provide argument {argname!r}\"\n                                )\n\n                    if hook_impl.hookwrapper:\n                        only_new_style_wrappers = False\n                        try:\n                            # If this cast is not valid, a type error is raised below,\n                            # which is the desired response.\n                            res = hook_impl.function(*args)\n                            wrapper_gen = cast(Generator[None, Result[object], None], res)\n                            next(wrapper_gen)  # first yield\n                            teardowns.append((wrapper_gen, hook_impl))\n                        except StopIteration:\n                            _raise_wrapfail(wrapper_gen, \"did not yield\")\n                    elif hook_impl.wrapper:\n                        try:\n                            # If this cast is not valid, a type error is raised below,\n                            # which is the desired response.\n                            res = hook_impl.function(*args)\n                            function_gen = cast(Generator[None, object, object], res)\n                            next(function_gen)  # first yield\n                            teardowns.append(function_gen)\n                        except StopIteration:\n                            _raise_wrapfail(function_gen, \"did not yield\")\n                    else:\n                        res = hook_impl.function(*args)\n                        if res is not None:\n                            results.append(res)\n                            if firstresult:  # halt further impl calls\n                                break\n            except BaseException as exc:\n                exception = exc\n        finally:\n            # Fast path - only new-style wrappers, no Result.\n            if only_new_style_wrappers:\n                if firstresult:  # first result hooks return a single value\n                    result = results[0] if results else None\n                else:\n                    result = results\n\n                # run all wrapper post-yield blocks\n                for teardown in reversed(teardowns):\n                    try:\n                        if exception is not None:\n                            teardown.throw(exception)  # type: ignore[union-attr]\n                        else:\n                            teardown.send(result)  # type: ignore[union-attr]\n                        # Following is unreachable for a well behaved hook wrapper.\n                        # Try to force finalizers otherwise postponed till GC action.\n                        # Note: close() may raise if generator handles GeneratorExit.\n                        teardown.close()  # type: ignore[union-attr]\n                    except StopIteration as si:\n                        result = si.value\n                        exception = None\n                        continue\n                    except BaseException as e:\n                        exception = e\n                        continue\n                    _raise_wrapfail(teardown, \"has second yield\")  # type: ignore[arg-type]\n\n                if exception is not None:\n                    raise exception.with_traceback(exception.__traceback__)\n                else:\n                    return result\n\n            # Slow path - need to support old-style wrappers.\n            else:\n                if firstresult:  # first result hooks return a single value\n                    outcome: Result[object | list[object]] = Result(\n                        results[0] if results else None, exception\n                    )\n                else:\n                    outcome = Result(results, exception)\n\n                # run all wrapper post-yield blocks\n                for teardown in reversed(teardowns):\n                    if isinstance(teardown, tuple):\n                        try:\n                            teardown[0].send(outcome)\n                        except StopIteration:\n                            pass\n                        except BaseException as e:\n                            _warn_teardown_exception(hook_name, teardown[1], e)\n                            raise\n                        else:\n                            _raise_wrapfail(teardown[0], \"has second yield\")\n                    else:\n                        try:\n                            if outcome._exception is not None:\n&gt;                               teardown.throw(outcome._exception)\n\n.venv/lib/python3.10/site-packages/pluggy/_callers.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    @pytest.hookimpl(wrapper=True, trylast=True)\n    def pytest_runtest_setup() -&gt; Generator[None]:\n&gt;       yield from thread_exception_runtest_hook()\n\n.venv/lib/python3.10/site-packages/_pytest/threadexception.py:87: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def thread_exception_runtest_hook() -&gt; Generator[None]:\n        with catch_threading_exception() as cm:\n            try:\n&gt;               yield\n\n.venv/lib/python3.10/site-packages/_pytest/threadexception.py:68: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhook_name = 'pytest_runtest_setup'\nhook_impls = [&gt;, &gt;, ...]\ncaller_kwargs = {'item': }, firstresult = False\n\n    def _multicall(\n        hook_name: str,\n        hook_impls: Sequence[HookImpl],\n        caller_kwargs: Mapping[str, object],\n        firstresult: bool,\n    ) -&gt; object | list[object]:\n        \"\"\"Execute a call into multiple python functions/methods and return the\n        result(s).\n\n        ``caller_kwargs`` comes from HookCaller.__call__().\n        \"\"\"\n        __tracebackhide__ = True\n        results: list[object] = []\n        exception = None\n        only_new_style_wrappers = True\n        try:  # run impl and wrapper setup functions in a loop\n            teardowns: list[Teardown] = []\n            try:\n                for hook_impl in reversed(hook_impls):\n                    try:\n                        args = [caller_kwargs[argname] for argname in hook_impl.argnames]\n                    except KeyError:\n                        for argname in hook_impl.argnames:\n                            if argname not in caller_kwargs:\n                                raise HookCallError(\n                                    f\"hook call must provide argument {argname!r}\"\n                                )\n\n                    if hook_impl.hookwrapper:\n                        only_new_style_wrappers = False\n                        try:\n                            # If this cast is not valid, a type error is raised below,\n                            # which is the desired response.\n                            res = hook_impl.function(*args)\n                            wrapper_gen = cast(Generator[None, Result[object], None], res)\n                            next(wrapper_gen)  # first yield\n                            teardowns.append((wrapper_gen, hook_impl))\n                        except StopIteration:\n                            _raise_wrapfail(wrapper_gen, \"did not yield\")\n                    elif hook_impl.wrapper:\n                        try:\n                            # If this cast is not valid, a type error is raised below,\n                            # which is the desired response.\n                            res = hook_impl.function(*args)\n                            function_gen = cast(Generator[None, object, object], res)\n                            next(function_gen)  # first yield\n                            teardowns.append(function_gen)\n                        except StopIteration:\n                            _raise_wrapfail(function_gen, \"did not yield\")\n                    else:\n&gt;                       res = hook_impl.function(*args)\n\n.venv/lib/python3.10/site-packages/pluggy/_callers.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nitem = \n\n    def pytest_runtest_setup(item: Item) -&gt; None:\n        _update_current_test_var(item, \"setup\")\n&gt;       item.session._setupstate.setup(item)\n\n.venv/lib/python3.10/site-packages/_pytest/runner.py:160: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &lt;_pytest.runner.SetupState object at 0x7f47d51bdb70&gt;\nitem = \n\n    def setup(self, item: Item) -&gt; None:\n        \"\"\"Setup objects along the collector chain to the item.\"\"\"\n        needed_collectors = item.listchain()\n\n        # If a collector fails its setup, fail its entire subtree of items.\n        # The setup is not retried for each item - the same exception is used.\n        for col, (finalizers, exc) in self.stack.items():\n            assert col in needed_collectors, \"previous item was not torn down properly\"\n            if exc:\n                raise exc[0].with_traceback(exc[1])\n\n        for col in needed_collectors[len(self.stack) :]:\n            assert col not in self.stack\n            # Push onto the stack.\n            self.stack[col] = ([col.teardown], None)\n            try:\n&gt;               col.setup()\n\n.venv/lib/python3.10/site-packages/_pytest/runner.py:514: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = \n\n    def setup(self) -&gt; None:\n&gt;       init_mod = importtestmodule(self.path / \"__init__.py\", self.config)\n\n.venv/lib/python3.10/site-packages/_pytest/python.py:663: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\npath = PosixPath('/testbed/voluptuous/__init__.py')\nconfig = &lt;_pytest.config.Config object at 0x7f47d55d8820&gt;\n\n    def importtestmodule(\n        path: Path,\n        config: Config,\n    ):\n        # We assume we are only called once per module.\n        importmode = config.getoption(\"--import-mode\")\n        try:\n            mod = import_path(\n                path,\n                mode=importmode,\n                root=config.rootpath,\n                consider_namespace_packages=config.getini(\"consider_namespace_packages\"),\n            )\n        except SyntaxError as e:\n            raise nodes.Collector.CollectError(\n                ExceptionInfo.from_current().getrepr(style=\"short\")\n            ) from e\n        except ImportPathMismatchError as e:\n            raise nodes.Collector.CollectError(\n                \"import file mismatch:\\n\"\n                \"imported module {!r} has this __file__ attribute:\\n\"\n                \"  {}\\n\"\n                \"which is not the same as the test file we want to collect:\\n\"\n                \"  {}\\n\"\n                \"HINT: remove __pycache__ / .pyc files and/or use a \"\n                \"unique basename for your test file modules\".format(*e.args)\n            ) from e\n        except ImportError as e:\n            exc_info = ExceptionInfo.from_current()\n            if config.get_verbosity() &lt; 2:\n                exc_info.traceback = exc_info.traceback.filter(filter_traceback)\n            exc_repr = (\n                exc_info.getrepr(style=\"short\")\n                if exc_info.traceback\n                else exc_info.exconly()\n            )\n            formatted_tb = str(exc_repr)\n&gt;           raise nodes.Collector.CollectError(\n                f\"ImportError while importing test module '{path}'.\\n\"\n                \"Hint: make sure your test modules/packages have valid Python names.\\n\"\n                \"Traceback:\\n\"\n                f\"{formatted_tb}\"\n            ) from e\nE           _pytest.nodes.Collector.CollectError: ImportError while importing test module '/testbed/voluptuous/__init__.py'.\nE           Hint: make sure your test modules/packages have valid Python names.\nE           Traceback:\nE           /usr/lib/python3.10/importlib/__init__.py:126: in import_module\nE               return _bootstrap._gcd_import(name[level:], package, level)\nE           voluptuous/__init__.py:80: in \nE               from voluptuous.util import *\nE           voluptuous/util.py:2: in \nE               from voluptuous import validators\nE           voluptuous/validators.py:10: in \nE               from voluptuous.schema_builder import Schema, Schemable, message, raises\nE           E   ImportError: cannot import name 'raises' from 'voluptuous.schema_builder' (/testbed/voluptuous/schema_builder.py)\n\n.venv/lib/python3.10/site-packages/_pytest/python.py:523: CollectError"},{"location":"analysis_baseline_voluptuous/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/voluptuous/error.py b/voluptuous/error.py\nindex f72fbe7..7999b26 100644\n--- a/voluptuous/error.py\n+++ b/voluptuous/error.py\n@@ -146,7 +146,7 @@ class LiteralInvalid(Invalid):\n\n\n class LengthInvalid(Invalid):\n-    pass\n+    \"\"\"The value has an invalid length.\"\"\"\n\n\n class DatetimeInvalid(Invalid):\n@@ -158,22 +158,28 @@ class DateInvalid(Invalid):\n\n\n class InInvalid(Invalid):\n-    pass\n+    \"\"\"The value is not in the required collection.\"\"\"\n\n\n class NotInInvalid(Invalid):\n-    pass\n+    \"\"\"The value is in a collection it should not be in.\"\"\"\n\n\n class ExactSequenceInvalid(Invalid):\n-    pass\n+    \"\"\"The sequence does not match exactly.\"\"\"\n\n\n class NotEnoughValid(Invalid):\n     \"\"\"The value did not pass enough validations.\"\"\"\n-    pass\n+    def __init__(self, msg: str, min_valid: int, actual_valid: int, path: typing.Optional[typing.List[typing.Hashable]] = None):\n+        super().__init__(msg, path)\n+        self.min_valid = min_valid\n+        self.actual_valid = actual_valid\n\n\n class TooManyValid(Invalid):\n     \"\"\"The value passed more than expected validations.\"\"\"\n-    pass\n+    def __init__(self, msg: str, max_valid: int, actual_valid: int, path: typing.Optional[typing.List[typing.Hashable]] = None):\n+        super().__init__(msg, path)\n+        self.max_valid = max_valid\n+        self.actual_valid = actual_valid\ndiff --git a/voluptuous/humanize.py b/voluptuous/humanize.py\nindex 2902871..7776e89 100644\n--- a/voluptuous/humanize.py\n+++ b/voluptuous/humanize.py\n@@ -11,4 +11,32 @@ def humanize_error(data, validation_error: Invalid, max_sub_error_length:\n     Invalid and MultipleInvalid do not include the offending value in error messages,\n     and MultipleInvalid.__str__ only provides the first error.\n     \"\"\"\n-    pass\n+    if isinstance(validation_error, MultipleInvalid):\n+        errors = validation_error.errors\n+    else:\n+        errors = [validation_error]\n+\n+    error_messages = []\n+    for error in errors:\n+        path = _format_path(error.path)\n+        value = _get_value_from_path(data, error.path)\n+        error_message = f\"Error at {path}: {error}\"\n+        if value is not None:\n+            truncated_value = str(value)[:max_sub_error_length]\n+            if len(str(value)) &gt; max_sub_error_length:\n+                truncated_value += \"...\"\n+            error_message += f\" (got {truncated_value})\"\n+        error_messages.append(error_message)\n+\n+    return \"\\n\".join(error_messages)\n+\n+def _format_path(path):\n+    return \".\".join(str(p) for p in path) if path else \"root\"\n+\n+def _get_value_from_path(data, path):\n+    for key in path:\n+        if isinstance(data, (dict, list)) and key in data:\n+            data = data[key]\n+        else:\n+            return None\n+    return data\ndiff --git a/voluptuous/schema_builder.py b/voluptuous/schema_builder.py\nindex de2b53c..57ef356 100644\n--- a/voluptuous/schema_builder.py\n+++ b/voluptuous/schema_builder.py\n@@ -113,7 +113,27 @@ class Schema(object):\n\n         Note: only very basic inference is supported.\n         \"\"\"\n-        pass\n+        def infer_type(value):\n+            if isinstance(value, dict):\n+                return {k: infer_type(v) for k, v in value.items()}\n+            elif isinstance(value, list):\n+                if value:\n+                    return [infer_type(value[0])]\n+                else:\n+                    return list\n+            elif isinstance(value, str):\n+                return str\n+            elif isinstance(value, int):\n+                return int\n+            elif isinstance(value, float):\n+                return float\n+            elif isinstance(value, bool):\n+                return bool\n+            else:\n+                return type(value)\n+\n+        inferred_schema = infer_type(data)\n+        return cls(inferred_schema, **kwargs)\n\n     def __eq__(self, other):\n         if not isinstance(other, Schema):\n@@ -142,7 +162,58 @@ class Schema(object):\n\n     def _compile_mapping(self, schema, invalid_msg=None):\n         \"\"\"Create validator for given mapping.\"\"\"\n-        pass\n+        def validate_mapping(path, iterable, value):\n+            if not isinstance(value, dict):\n+                raise er.Invalid(invalid_msg or 'expected a dictionary', path)\n+\n+            out = {}\n+            required_keys = set()\n+            optional_keys = set()\n+            _compile = self._compile\n+            error = er.MultipleInvalid()\n+\n+            for key, subschema in _iterate_mapping_candidates(schema):\n+                if isinstance(key, Required):\n+                    required_keys.add(key.schema)\n+                elif isinstance(key, Optional):\n+                    optional_keys.add(key.schema)\n+                else:\n+                    optional_keys.add(key)\n+\n+            for key, val in value.items():\n+                key_path = path + [key]\n+                for skey, svalue in _iterate_mapping_candidates(schema):\n+                    if isinstance(skey, Optional):\n+                        skey = skey.schema\n+                    if isinstance(skey, Required):\n+                        skey = skey.schema\n+                    if skey == key:\n+                        try:\n+                            out[key] = _compile(svalue)(key_path, value, val)\n+                            break\n+                        except er.Invalid as e:\n+                            error.add(e)\n+                else:\n+                    if self.extra == PREVENT_EXTRA:\n+                        error.add(er.Invalid('extra keys not allowed', key_path))\n+                    elif self.extra == ALLOW_EXTRA:\n+                        out[key] = val\n+                    elif self.extra == REMOVE_EXTRA:\n+                        pass\n+                    else:\n+                        raise ValueError('Invalid value for extra')\n+\n+            missing_required_keys = required_keys - set(out.keys())\n+            if missing_required_keys:\n+                error.add(er.Invalid(f'required key(s) {\", \".join(repr(k) for k in missing_required_keys)} not provided',\n+                                     path))\n+\n+            if error.errors:\n+                raise error\n+\n+            return out\n+\n+        return validate_mapping\n\n     def _compile_object(self, schema):\n         \"\"\"Validate an object.\n@@ -162,7 +233,26 @@ class Schema(object):\n             ...   validate(Structure(one='three'))\n\n         \"\"\"\n-        pass\n+        base = self._compile_mapping(schema, invalid_msg='object value')\n+\n+        def validate_object(path, iterable, value):\n+            if schema.cls is not UNDEFINED and not isinstance(value, schema.cls):\n+                raise er.Invalid('expected {} but got {}'.format(schema.cls, type(value)), path)\n+            \n+            # Convert object attributes to a dictionary\n+            value_dict = {k: getattr(value, k) for k in dir(value) if not k.startswith('_')}\n+            \n+            # Validate the dictionary\n+            result_dict = base(path, iterable, value_dict)\n+            \n+            # Create a new object with validated attributes\n+            validated_obj = schema.cls() if schema.cls is not UNDEFINED else type(value)()\n+            for k, v in result_dict.items():\n+                setattr(validated_obj, k, v)\n+            \n+            return validated_obj\n+\n+        return validate_object\n\n     def _compile_dict(self, schema):\n         \"\"\"Validate a dictionary.\n@@ -240,7 +330,7 @@ class Schema(object):\n          \"expected str for dictionary value @ data['adict']['strfield']\"]\n\n         \"\"\"\n-        pass\n+        return self._compile_mapping(schema, invalid_msg='expected a dictionary')\n\n     def _compile_sequence(self, schema, seq_type):\n         \"\"\"Validate a sequence type.\n@@ -255,7 +345,27 @@ class Schema(object):\n         &gt;&gt;&gt; validator([1])\n         [1]\n         \"\"\"\n-        pass\n+        _compile = self._compile\n+        seq_schema = [_compile(s) for s in schema]\n+\n+        def validate_sequence(path, iterable, value):\n+            if not isinstance(value, seq_type):\n+                raise er.Invalid('expected a {}'.format(seq_type.__name__), path)\n+\n+            result = []\n+            for i, item in enumerate(value):\n+                item_path = path + [i]\n+                for validator in seq_schema:\n+                    try:\n+                        result.append(validator(item_path, iterable, item))\n+                        break\n+                    except er.Invalid:\n+                        pass\n+                else:\n+                    raise er.Invalid('invalid value', item_path)\n+            return seq_type(result)\n+\n+        return validate_sequence\n\n     def _compile_tuple(self, schema):\n         \"\"\"Validate a tuple.\n@@ -270,7 +380,7 @@ class Schema(object):\n         &gt;&gt;&gt; validator((1,))\n         (1,)\n         \"\"\"\n-        pass\n+        return self._compile_sequence(schema, tuple)\n\n     def _compile_list(self, schema):\n         \"\"\"Validate a list.\n@@ -285,7 +395,7 @@ class Schema(object):\n         &gt;&gt;&gt; validator([1])\n         [1]\n         \"\"\"\n-        pass\n+        return self._compile_sequence(schema, list)\n\n     def _compile_set(self, schema):\n         \"\"\"Validate a set.\n@@ -300,7 +410,26 @@ class Schema(object):\n         &gt;&gt;&gt; with raises(er.MultipleInvalid, 'invalid value in set'):\n         ...   validator(set(['a']))\n         \"\"\"\n-        pass\n+        _compile = self._compile\n+        set_schema = [_compile(s) for s in schema]\n+\n+        def validate_set(path, iterable, value):\n+            if not isinstance(value, set):\n+                raise er.Invalid('expected a set', path)\n+\n+            result = set()\n+            for item in value:\n+                for validator in set_schema:\n+                    try:\n+                        result.add(validator(path, iterable, item))\n+                        break\n+                    except er.Invalid:\n+                        pass\n+                else:\n+                    raise er.Invalid('invalid value in set', path)\n+            return result\n+\n+        return validate_set\n\n     def extend(self, schema: Schemable, required: typing.Optional[bool]=\n         None, extra: typing.Optional[int]=None) -&gt;Schema:\n@@ -316,7 +445,17 @@ class Schema(object):\n         :param required: if set, overrides `required` of this `Schema`\n         :param extra: if set, overrides `extra` of this `Schema`\n         \"\"\"\n-        pass\n+        if not isinstance(self.schema, dict) or not isinstance(schema, dict):\n+            raise ValueError(\"Both schemas must be dictionary-based\")\n+\n+        new_schema = self.schema.copy()\n+        new_schema.update(schema)\n+\n+        return Schema(\n+            new_schema,\n+            required=self.required if required is None else required,\n+            extra=self.extra if extra is None else extra\n+        )\n\n\n def _compile_scalar(schema):\n@@ -678,17 +817,31 @@ def message(default: typing.Optional[str]=None, cls: typing.Optional[typing\n         ... except er.MultipleInvalid as e:\n         ...   assert isinstance(e.errors[0], IntegerInvalid)\n     \"\"\"\n-    pass\n+    def decorator(func):\n+        @wraps(func)\n+        def wrapper(*args, **kwargs):\n+            msg = kwargs.pop('msg', None) or default\n+            clsoverride = kwargs.pop('clsoverride', None) or cls\n+            try:\n+                return func(*args, **kwargs)\n+            except ValueError as e:\n+                raise (clsoverride or er.Invalid)(msg or str(e))\n+        return wrapper\n+    return decorator\n\n\n def _args_to_dict(func, args):\n     \"\"\"Returns argument names as values as key-value pairs.\"\"\"\n-    pass\n+    arg_count = func.__code__.co_argcount\n+    arg_names = func.__code__.co_varnames[:arg_count]\n+    return dict(zip(arg_names, args))\n\n\n def _merge_args_with_kwargs(args_dict, kwargs_dict):\n     \"\"\"Merge args with kwargs.\"\"\"\n-    pass\n+    ret = args_dict.copy()\n+    ret.update(kwargs_dict)\n+    return ret\n\n\n def validate(*a, **kw) -&gt;typing.Callable:\n@@ -707,4 +860,20 @@ def validate(*a, **kw) -&gt;typing.Callable:\n         ...   return arg1 * 2\n\n     \"\"\"\n-    pass\n+    def validate_schema_decorator(func):\n+        schema = Schema(kw) if kw else Schema(a[0])\n+\n+        @wraps(func)\n+        def wrapper(*args, **kwargs):\n+            schema_dict = _merge_args_with_kwargs(_args_to_dict(func, args), kwargs)\n+            validated = schema(schema_dict)\n+            result = func(**validated)\n+            if '__return__' in schema.schema:\n+                return_validator = schema.schema['__return__']\n+                if isinstance(return_validator, Schema):\n+                    return return_validator(result)\n+                else:\n+                    return Schema(return_validator)(result)\n+            return result\n+        return wrapper\n+    return validate_schema_decorator\ndiff --git a/voluptuous/util.py b/voluptuous/util.py\nindex fe15b1a..a2c57d8 100644\n--- a/voluptuous/util.py\n+++ b/voluptuous/util.py\n@@ -13,7 +13,7 @@ def Lower(v: str) -&gt;str:\n     &gt;&gt;&gt; s('HI')\n     'hi'\n     \"\"\"\n-    pass\n+    return v.lower()\n\n\n def Upper(v: str) -&gt;str:\n@@ -23,7 +23,7 @@ def Upper(v: str) -&gt;str:\n     &gt;&gt;&gt; s('hi')\n     'HI'\n     \"\"\"\n-    pass\n+    return v.upper()\n\n\n def Capitalize(v: str) -&gt;str:\n@@ -33,7 +33,7 @@ def Capitalize(v: str) -&gt;str:\n     &gt;&gt;&gt; s('hello world')\n     'Hello world'\n     \"\"\"\n-    pass\n+    return v.capitalize()\n\n\n def Title(v: str) -&gt;str:\n@@ -43,7 +43,7 @@ def Title(v: str) -&gt;str:\n     &gt;&gt;&gt; s('hello world')\n     'Hello World'\n     \"\"\"\n-    pass\n+    return v.title()\n\n\n def Strip(v: str) -&gt;str:\n@@ -53,7 +53,7 @@ def Strip(v: str) -&gt;str:\n     &gt;&gt;&gt; s('  hello world  ')\n     'hello world'\n     \"\"\"\n-    pass\n+    return v.strip()\n\n\n class DefaultTo(object):\ndiff --git a/voluptuous/validators.py b/voluptuous/validators.py\nindex 88b50f6..10230e1 100644\n--- a/voluptuous/validators.py\n+++ b/voluptuous/validators.py\n@@ -41,7 +41,13 @@ def truth(f: typing.Callable) -&gt;typing.Callable:\n     &gt;&gt;&gt; with raises(MultipleInvalid, 'not a valid value'):\n     ...   validate('/notavaliddir')\n     \"\"\"\n-    pass\n+    @wraps(f)\n+    def wrapper(v):\n+        t = f(v)\n+        if not t:\n+            raise ValueError\n+        return v\n+    return wrapper\n\n\n class Coerce(object):\n@@ -109,7 +115,7 @@ def IsTrue(v):\n     ... except MultipleInvalid as e:\n     ...   assert isinstance(e.errors[0], TrueInvalid)\n     \"\"\"\n-    pass\n+    return bool(v)\n\n\n @message('value was not false', cls=FalseInvalid)\n@@ -129,7 +135,7 @@ def IsFalse(v):\n     ... except MultipleInvalid as e:\n     ...   assert isinstance(e.errors[0], FalseInvalid)\n     \"\"\"\n-    pass\n+    return not bool(v)\n\n\n @message('expected boolean', cls=BooleanInvalid)\n@@ -153,7 +159,18 @@ def Boolean(v):\n     ... except MultipleInvalid as e:\n     ...   assert isinstance(e.errors[0], BooleanInvalid)\n     \"\"\"\n-    pass\n+    if isinstance(v, bool):\n+        return v\n+    if isinstance(v, str):\n+        v = v.lower()\n+        if v in ('1', 'true', 'yes', 'on', 'enable'):\n+            return True\n+        if v in ('0', 'false', 'no', 'off', 'disable'):\n+            return False\n+    try:\n+        return bool(v)\n+    except ValueError:\n+        raise BooleanInvalid('expected boolean')\n\n\n class _WithSubValidators(object):\n@@ -894,7 +911,16 @@ class Number(object):\n         :param number:\n         :return: tuple(precision, scale, decimal_number)\n         \"\"\"\n-        pass\n+        try:\n+            decimal_num = Decimal(number)\n+        except InvalidOperation:\n+            raise Invalid(self.msg or f'{number} is not a valid Decimal')\n+\n+        sign, digits, exponent = decimal_num.as_tuple()\n+        scale = -exponent if exponent &lt; 0 else 0\n+        precision = len(digits)\n+\n+        return precision, scale, decimal_num\n\n\n class SomeOf(_WithSubValidators):\n</code></pre>"},{"location":"analysis_baseline_wcwidth/","title":"Analysis baseline wcwidth","text":"<p>back to baseline summary</p>"},{"location":"analysis_baseline_wcwidth/#submission-name-baseline","title":"Submission Name: baseline","text":""},{"location":"analysis_baseline_wcwidth/#repository-wcwidth","title":"Repository: wcwidth","text":""},{"location":"analysis_baseline_wcwidth/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count passed 6 failed 32 skipped 1 total 39 collected 39"},{"location":"analysis_baseline_wcwidth/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_baseline_wcwidth/#test_corepytest_empty_string","title":"test_core.py::test_empty_string","text":"<pre>test_core.py::test_empty_string</pre><pre>\ndef test_empty_string():\n        \"\"\"\n        Test empty string is OK.\n\n        https://github.com/jquast/wcwidth/issues/24\n        \"\"\"\n        phrase = \"\"\n        expect_length_each = 0\n        expect_length_phrase = 0\n\n        # exercise,\n&gt;       length_each = wcwidth.wcwidth(phrase)\n\ntests/test_core.py:44: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nwc = '', unicode_version = 'auto'\n\n    @lru_cache(maxsize=1000)\n    def wcwidth(wc, unicode_version='auto'):\n        \"\"\"\n        Given one Unicode character, return its printable length on a terminal.\n\n        :param str wc: A single Unicode character.\n        :param str unicode_version: A Unicode version number, such as\n            ``'6.0.0'``. A list of version levels suported by wcwidth\n            is returned by :func:`list_versions`.\n\n            Any version string may be specified without error -- the nearest\n            matching version is selected.  When ``latest`` (default), the\n            highest Unicode version level is used.\n        :return: The width, in cells, necessary to display the character of\n            Unicode string character, ``wc``.  Returns 0 if the ``wc`` argument has\n            no printable effect on a terminal (such as NUL '\\\\0'), -1 if ``wc`` is\n            not printable, or has an indeterminate effect on the terminal, such as\n            a control character.  Otherwise, the number of column positions the\n            character occupies on a graphic terminal (1 or 2) is returned.\n        :rtype: int\n\n        See :ref:`Specification` for details of cell measurement.\n        \"\"\"\n&gt;       ucs = ord(wc)\nE       TypeError: ord() expected a character, but string of length 0 found\n\nwcwidth/wcwidth.py:129: TypeError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_corepytest_hello_jp","title":"test_core.py::test_hello_jp","text":"<pre>test_core.py::test_hello_jp</pre><pre>\ndef test_hello_jp():\n        u\"\"\"\n        Width of Japanese phrase: \u30b3\u30f3\u30cb\u30c1\u30cf, \u30bb\u30ab\u30a4!\n\n        Given a phrase of 5 and 3 Katakana ideographs, joined with\n        3 English-ASCII punctuation characters, totaling 11, this\n        phrase consumes 19 cells of a terminal emulator.\n        \"\"\"\n        # given,\n        phrase = u'\u30b3\u30f3\u30cb\u30c1\u30cf, \u30bb\u30ab\u30a4!'\n        expect_length_each = (2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1)\n        expect_length_phrase = sum(expect_length_each)\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_core.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 12467\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_corepytest_wcswidth_substr","title":"test_core.py::test_wcswidth_substr","text":"<pre>test_core.py::test_wcswidth_substr</pre><pre>\ndef test_wcswidth_substr():\n        \"\"\"\n        Test wcswidth() optional 2nd parameter, ``n``.\n\n        ``n`` determines at which position of the string\n        to stop counting length.\n        \"\"\"\n        # given,\n        phrase = u'\u30b3\u30f3\u30cb\u30c1\u30cf, \u30bb\u30ab\u30a4!'\n        end = 7\n        expect_length_each = (2, 2, 2, 2, 2, 1, 1,)\n        expect_length_phrase = sum(expect_length_each)\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))[:end]\n\ntests/test_core.py:108: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 12467\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_corepytest_null_width_0","title":"test_core.py::test_null_width_0","text":"<pre>test_core.py::test_null_width_0</pre><pre>\ndef test_null_width_0():\n        \"\"\"NULL (0) reports width 0.\"\"\"\n        # given,\n        phrase = u'abc\\x00def'\n        expect_length_each = (1, 1, 1, 0, 1, 1, 1)\n        expect_length_phrase = sum(expect_length_each)\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_core.py:124: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 97\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_corepytest_control_c0_width_negative_1","title":"test_core.py::test_control_c0_width_negative_1","text":"<pre>test_core.py::test_control_c0_width_negative_1</pre><pre>\ndef test_control_c0_width_negative_1():\n        \"\"\"How the API reacts to CSI (Control sequence initiate).\n\n        An example of bad fortune, this terminal sequence is a width of 0\n        on all terminals, but wcwidth doesn't parse Control-Sequence-Inducer\n        (CSI) sequences.\n\n        Also the \"legacy\" posix functions wcwidth and wcswidth return -1 for\n        any string containing the C1 control character \\x1b (ESC).\n        \"\"\"\n        # given,\n        phrase = u'\\x1b[0m'\n        expect_length_each = (-1, 1, 1, 1)\n        expect_length_phrase = -1\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_core.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 91\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_corepytest_combining_width","title":"test_core.py::test_combining_width","text":"<pre>test_core.py::test_combining_width</pre><pre>\ndef test_combining_width():\n        \"\"\"Simple test combining reports total width of 4.\"\"\"\n        # given,\n        phrase = u'--\\u05bf--'\n        expect_length_each = (1, 1, 0, 1, 1)\n        expect_length_phrase = 4\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_core.py:164: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 45\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_corepytest_combining_cafe","title":"test_core.py::test_combining_cafe","text":"<pre>test_core.py::test_combining_cafe</pre><pre>\ndef test_combining_cafe():\n        u\"\"\"Phrase cafe + COMBINING ACUTE ACCENT is caf\u00e9 of length 4.\"\"\"\n        phrase = u\"cafe\\u0301\"\n        expect_length_each = (1, 1, 1, 1, 0)\n        expect_length_phrase = 4\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_core.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 99\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_corepytest_combining_enclosing","title":"test_core.py::test_combining_enclosing","text":"<pre>test_core.py::test_combining_enclosing</pre><pre>\ndef test_combining_enclosing():\n        u\"\"\"CYRILLIC CAPITAL LETTER A + COMBINING CYRILLIC HUNDRED THOUSANDS SIGN is of length 1.\"\"\"\n        phrase = u\"\\u0410\\u0488\"\n        expect_length_each = (1, 0)\n        expect_length_phrase = 1\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_core.py:194: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 1040\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_corepytest_balinese_script","title":"test_core.py::test_balinese_script","text":"<pre>test_core.py::test_balinese_script</pre><pre>\ndef test_balinese_script():\n        u\"\"\"\n        Balinese kapal (ship) is length 3.\n\n        This may be an example that is not yet correctly rendered by any terminal so\n        far, like devanagari.\n        \"\"\"\n        phrase = (u\"\\u1B13\"    # Category 'Lo', EAW 'N' -- BALINESE LETTER KA\n                  u\"\\u1B28\"    # Category 'Lo', EAW 'N' -- BALINESE LETTER PA KAPAL\n                  u\"\\u1B2E\"    # Category 'Lo', EAW 'N' -- BALINESE LETTER LA\n                  u\"\\u1B44\")   # Category 'Mc', EAW 'N' -- BALINESE ADEG ADEG\n        expect_length_each = (1, 1, 1, 0)\n        expect_length_phrase = 3\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_core.py:217: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 6931\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_corepytest_kr_jamo","title":"test_core.py::test_kr_jamo","text":"<pre>test_core.py::test_kr_jamo</pre><pre>\ndef test_kr_jamo():\n        \"\"\"\n        Test basic combining of HANGUL CHOSEONG and JUNGSEONG\n\n        Example and from Raymond Chen's blog post,\n        https://devblogs.microsoft.com/oldnewthing/20201009-00/?p=104351\n        \"\"\"\n        # This is an example where both characters are \"wide\" when displayed alone.\n        #\n        # But JUNGSEONG (vowel) is designed for combination with a CHOSEONG (consonant).\n        #\n        # This wcwidth library understands their width only when combination,\n        # and not by independent display, like other zero-width characters that may\n        # only combine with an appropriate preceding character.\n        phrase = (\n            u\"\\u1100\"  # \u1100 HANGUL CHOSEONG KIYEOK (consonant)\n            u\"\\u1161\"  # \u1161 HANGUL JUNGSEONG A (vowel)\n        )\n        expect_length_each = (2, 0)\n        expect_length_phrase = 2\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_core.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 4352\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_corepytest_kr_jamo_filler","title":"test_core.py::test_kr_jamo_filler","text":"<pre>test_core.py::test_kr_jamo_filler</pre><pre>\ndef test_kr_jamo_filler():\n        u\"\"\"\n        Jamo filler is 0 width.\n\n        Example from https://www.unicode.org/L2/L2006/06310-hangul-decompose9.pdf\n        \"\"\"\n        phrase = (\n            u\"\\u1100\"  # HANGUL CHOSEONG KIYEOK (consonant)\n            u\"\\u1160\"  # HANGUL JUNGSEONG FILLER (vowel)\n        )\n        expect_length_each = (2, 0)\n        expect_length_phrase = 2\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_core.py:269: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 4352\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_corepytest_devanagari_script","title":"test_core.py::test_devanagari_script","text":"<pre>test_core.py::test_devanagari_script</pre><pre>\ndef test_devanagari_script():\n        \"\"\"\n        Attempt to test the measurement width of Devanagari script.\n\n        I believe this 'phrase' should be length 3.\n\n        This is a difficult problem, and this library does not yet get it right,\n        because we interpret the unicode data files programmatically, but they do\n        not correctly describe how their terminal width is measured.\n\n        There are very few Terminals that do!\n\n        As of 2023,\n\n        - iTerm2: correct length but individual characters are out of order and\n                  horizaontally misplaced as to be unreadable in its language when\n                  using 'Noto Sans' font.\n        - mlterm: mixed results, it offers several options in the configuration\n                  dialog, \"Xft\", \"Cario\", and \"Variable Column Width\" have some\n                  effect, but with neither 'Noto Sans' or 'unifont', it is not\n                  recognizable as the Devanagari script it is meant to display.\n\n        Previous testing with Devanagari documented at address https://benizi.com/vim/devanagari/\n\n        See also, https://askubuntu.com/questions/8437/is-there-a-good-mono-spaced-font-for-devanagari-script-in-the-terminal\n        \"\"\"\n        # This test adapted from https://www.unicode.org/L2/L2023/23107-terminal-suppt.pdf\n        # please note that document correctly points out that the final width cannot be determined\n        # as a sum of each individual width, as this library currently performs with exception of\n        # ZWJ, but I think it incorrectly gestures what a stateless call to wcwidth.wcwidth of\n        # each codepoint *should* return.\n        phrase = (u\"\\u0915\"    # Akhand, Category 'Lo', East Asian Width property 'N' -- DEVANAGARI LETTER KA\n                  u\"\\u094D\"    # Joiner, Category 'Mn', East Asian Width property 'N' -- DEVANAGARI SIGN VIRAMA\n                  u\"\\u0937\"    # Fused, Category 'Lo', East Asian Width property 'N' -- DEVANAGARI LETTER SSA\n                  u\"\\u093F\")   # MatraL, Category 'Mc', East Asian Width property 'N' -- DEVANAGARI VOWEL SIGN I\n        # 23107-terminal-suppt.pdf suggests wcwidth.wcwidth should return (2, 0, 0, 1)\n        expect_length_each = (1, 0, 1, 0)\n        # I believe the final width *should* be 3.\n        expect_length_phrase = 2\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_core.py:318: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 2325\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_corepytest_tamil_script","title":"test_core.py::test_tamil_script","text":"<pre>test_core.py::test_tamil_script</pre><pre>\ndef test_tamil_script():\n        # This test adapted from https://www.unicode.org/L2/L2023/23107-terminal-suppt.pdf\n        phrase = (u\"\\u0b95\"    # Akhand, Category 'Lo', East Asian Width property 'N' -- TAMIL LETTER KA\n                  u\"\\u0bcd\"    # Joiner, Category 'Mn', East Asian Width property 'N' -- TAMIL SIGN VIRAMA\n                  u\"\\u0bb7\"    # Fused, Category 'Lo', East Asian Width property 'N' -- TAMIL LETTER SSA\n                  u\"\\u0bcc\")   # MatraLR, Category 'Mc', East Asian Width property 'N' -- TAMIL VOWEL SIGN AU\n        # 23107-terminal-suppt.pdf suggests wcwidth.wcwidth should return (3, 0, 0, 4)\n        expect_length_each = (1, 0, 1, 0)\n\n        # I believe the final width should be about 5 or 6.\n        expect_length_phrase = 2\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_core.py:339: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 2965\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_corepytest_kannada_script","title":"test_core.py::test_kannada_script","text":"<pre>test_core.py::test_kannada_script</pre><pre>\ndef test_kannada_script():\n        # This test adapted from https://www.unicode.org/L2/L2023/23107-terminal-suppt.pdf\n        # |\u0cb0\u0ccd\u0c9d\u0cc8|\n        # |123|\n        phrase = (u\"\\u0cb0\"    # Repha, Category 'Lo', East Asian Width property 'N' -- KANNADA LETTER RA\n                  u\"\\u0ccd\"    # Joiner, Category 'Mn', East Asian Width property 'N' -- KANNADA SIGN VIRAMA\n                  u\"\\u0c9d\"    # Base, Category 'Lo', East Asian Width property 'N' -- KANNADA LETTER JHA\n                  u\"\\u0cc8\")   # MatraUR, Category 'Mc', East Asian Width property 'N' -- KANNADA VOWEL SIGN AI\n        # 23107-terminal-suppt.pdf suggests should be (2, 0, 3, 1)\n        expect_length_each = (1, 0, 1, 0)\n        # I believe the correct final width *should* be 3 or 4.\n        expect_length_phrase = 2\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_core.py:361: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 3248\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_corepytest_kannada_script_2","title":"test_core.py::test_kannada_script_2","text":"<pre>test_core.py::test_kannada_script_2</pre><pre>\ndef test_kannada_script_2():\n        # This test adapted from https://www.unicode.org/L2/L2023/23107-terminal-suppt.pdf\n        # |\u0cb0\u0cbc\u0ccd\u0c9a|\n        # |12|\n        phrase = (u\"\\u0cb0\"    # Base, Category 'Lo', East Asian Width property 'N' -- KANNADA LETTER RA\n                  u\"\\u0cbc\"    # Nukta, Category 'Mn', East Asian Width property 'N' -- KANNADA SIGN NUKTA\n                  u\"\\u0ccd\"    # Joiner, Category 'Lo', East Asian Width property 'N' -- KANNADA SIGN VIRAMA\n                  u\"\\u0c9a\")   # Subjoin, Category 'Mc', East Asian Width property 'N' -- KANNADA LETTER CA\n        # 23107-terminal-suppt.pdf suggests wcwidth.wcwidth should return (2, 0, 0, 1)\n        expect_length_each = (1, 0, 0, 1)\n        # I believe the final width is correct, but maybe for the wrong reasons!\n        expect_length_phrase = 2\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_core.py:383: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 3248\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_corepytest_zero_wide_conflict","title":"test_core.py::test_zero_wide_conflict","text":"<pre>test_core.py::test_zero_wide_conflict</pre><pre>\ndef test_zero_wide_conflict():\n        # Test characters considered both \"wide\" and \"zero\" width\n        # -  (0x03000, 0x0303e,),  # Ideographic Space       ..Ideographic Variation In\n        # +  (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n&gt;       assert wcwidth.wcwidth(unichr(0x03029), unicode_version='4.1.0') == 2\n\ntests/test_core.py:395: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 12329\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_emojispytest_unfinished_zwj_sequence","title":"test_emojis.py::test_unfinished_zwj_sequence","text":"<pre>test_emojis.py::test_unfinished_zwj_sequence</pre><pre>\n@pytest.mark.skipif(NARROW_ONLY, reason=\"Test cannot verify on python 'narrow' builds\")\n    def test_unfinished_zwj_sequence():\n        u\"\"\"\n        Ensure index-out-of-bounds does not occur for zero-width joiner without any following character\n        \"\"\"\n        phrase = (u\"\\U0001f469\"   # Base, Category So, East Asian Width property 'W' -- WOMAN\n                  u\"\\U0001f3fb\"   # Modifier, Category Sk, East Asian Width property 'W' -- EMOJI MODIFIER FITZPATRICK TYPE-1-2\n                  u\"\\u200d\")      # Joiner, Category Cf, East Asian Width property 'N'  -- ZERO WIDTH JOINER\n        expect_length_each = (2, 0, 0)\n        expect_length_phrase = 2\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_emojis.py:67: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 128105\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_emojispytest_non_recommended_zwj_sequence","title":"test_emojis.py::test_non_recommended_zwj_sequence","text":"<pre>test_emojis.py::test_non_recommended_zwj_sequence</pre><pre>\n@pytest.mark.skipif(NARROW_ONLY, reason=\"Test cannot verify on python 'narrow' builds\")\n    def test_non_recommended_zwj_sequence():\n        \"\"\"\n        Verify ZWJ is measured as though successful with characters that cannot be joined, wcwidth does not verify\n        \"\"\"\n        phrase = (u\"\\U0001f469\"   # Base, Category So, East Asian Width property 'W' -- WOMAN\n                  u\"\\U0001f3fb\"   # Modifier, Category Sk, East Asian Width property 'W' -- EMOJI MODIFIER FITZPATRICK TYPE-1-2\n                  u\"\\u200d\")      # Joiner, Category Cf, East Asian Width property 'N'  -- ZERO WIDTH JOINER\n        expect_length_each = (2, 0, 0)\n        expect_length_phrase = 2\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_emojis.py:87: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 128105\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_emojispytest_another_emoji_zwj_sequence","title":"test_emojis.py::test_another_emoji_zwj_sequence","text":"<pre>test_emojis.py::test_another_emoji_zwj_sequence</pre><pre>\n@pytest.mark.skipif(NARROW_ONLY, reason=\"Test cannot verify on python 'narrow' builds\")\n    def test_another_emoji_zwj_sequence():\n        phrase = (\n            u\"\\u26F9\"        # PERSON WITH BALL\n            u\"\\U0001F3FB\"    # EMOJI MODIFIER FITZPATRICK TYPE-1-2\n            u\"\\u200D\"        # ZERO WIDTH JOINER\n            u\"\\u2640\"        # FEMALE SIGN\n            u\"\\uFE0F\")       # VARIATION SELECTOR-16\n        expect_length_each = (1, 0, 0, 1, 0)\n        expect_length_phrase = 2\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_emojis.py:107: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 9977\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_emojispytest_longer_emoji_zwj_sequence","title":"test_emojis.py::test_longer_emoji_zwj_sequence","text":"<pre>test_emojis.py::test_longer_emoji_zwj_sequence</pre><pre>\n@pytest.mark.skipif(NARROW_ONLY, reason=\"Test cannot verify on python 'narrow' builds\")\n    def test_longer_emoji_zwj_sequence():\n        \"\"\"\n        A much longer emoji ZWJ sequence of 10 total codepoints is just 2 cells!\n\n        Also test the same sequence in duplicate, verifying multiple VS-16 sequences\n        in a single function call.\n        \"\"\"\n        # 'Category Code', 'East Asian Width property' -- 'description'\n        phrase = (u\"\\U0001F9D1\"   # 'So', 'W' -- ADULT\n                  u\"\\U0001F3FB\"   # 'Sk', 'W' -- EMOJI MODIFIER FITZPATRICK TYPE-1-2\n                  u\"\\u200d\"       # 'Cf', 'N' -- ZERO WIDTH JOINER\n                  u\"\\u2764\"       # 'So', 'N' -- HEAVY BLACK HEART\n                  u\"\\uFE0F\"       # 'Mn', 'A' -- VARIATION SELECTOR-16\n                  u\"\\u200d\"       # 'Cf', 'N' -- ZERO WIDTH JOINER\n                  u\"\\U0001F48B\"   # 'So', 'W' -- KISS MARK\n                  u\"\\u200d\"       # 'Cf', 'N' -- ZERO WIDTH JOINER\n                  u\"\\U0001F9D1\"   # 'So', 'W' -- ADULT\n                  u\"\\U0001F3FD\"   # 'Sk', 'W' -- EMOJI MODIFIER FITZPATRICK TYPE-4\n        ) * 2\n        # This test adapted from https://www.unicode.org/L2/L2023/23107-terminal-suppt.pdf\n        expect_length_each = (2, 0, 0, 1, 0, 0, 2, 0, 2, 0) * 2\n        expect_length_phrase = 4\n\n        # exercise,\n&gt;       length_each = tuple(map(wcwidth.wcwidth, phrase))\n\ntests/test_emojis.py:140: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 129489\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_emojispytest_recommended_emoji_zwj_sequences","title":"test_emojis.py::test_recommended_emoji_zwj_sequences","text":"<pre>test_emojis.py::test_recommended_emoji_zwj_sequences</pre><pre>\n@pytest.mark.skipif(NARROW_ONLY, reason=\"Some sequences in text file are not compatible with 'narrow' builds\")\n    def test_recommended_emoji_zwj_sequences():\n        \"\"\"\n        Test wcswidth of all of the unicode.org-published emoji-zwj-sequences.txt\n        \"\"\"\n        # given,\n        lines, sequences = read_sequences_from_file('emoji-zwj-sequences.txt')\n\n        errors = []\n        # Exercise, track by zipping with original text file line, a debugging aide\n        num = 0\n        for sequence, line in zip(sequences, lines):\n            num += 1\n&gt;           measured_width = wcwidth.wcswidth(sequence)\n\ntests/test_emojis.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:177: in wcswidth\n    char_width = wcwidth(char, unicode_version)\nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 128104\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_emojispytest_recommended_variation_16_sequences","title":"test_emojis.py::test_recommended_variation_16_sequences","text":"<pre>test_emojis.py::test_recommended_variation_16_sequences</pre><pre>\ndef test_recommended_variation_16_sequences():\n        \"\"\"\n        Test wcswidth of all of the unicode.org-published emoji-variation-sequences.txt\n        \"\"\"\n        # given,\n        lines, sequences = read_sequences_from_file('emoji-variation-sequences.txt')\n\n        errors = []\n        num = 0\n        for sequence, line in zip(sequences, lines):\n            num += 1\n            if '\\ufe0f' not in sequence:\n                # filter for only \\uFE0F (VS-16)\n                continue\n&gt;           measured_width = wcwidth.wcswidth(sequence)\n\ntests/test_emojis.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:177: in wcswidth\n    char_width = wcwidth(char, unicode_version)\nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 35\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_emojispytest_unicode_9_vs16","title":"test_emojis.py::test_unicode_9_vs16","text":"<pre>test_emojis.py::test_unicode_9_vs16</pre><pre>\ndef test_unicode_9_vs16():\n        \"\"\"Verify effect of VS-16 on unicode_version 9.0 and later\"\"\"\n        phrase = (u\"\\u2640\"        # FEMALE SIGN\n                  u\"\\uFE0F\")       # VARIATION SELECTOR-16\n\n        expect_length_each = (1, 0)\n        expect_length_phrase = 2\n\n        # exercise,\n&gt;       length_each = tuple(wcwidth.wcwidth(w_char, unicode_version='9.0') for w_char in phrase)\n\ntests/test_emojis.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_emojis.py:222: in \n    length_each = tuple(wcwidth.wcwidth(w_char, unicode_version='9.0') for w_char in phrase)\nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 9792\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError"},{"location":"analysis_baseline_wcwidth/#test_emojispytest_unicode_8_vs16","title":"test_emojis.py::test_unicode_8_vs16","text":"<pre>test_emojis.py::test_unicode_8_vs16</pre><pre>\ndef test_unicode_8_vs16():\n        \"\"\"Verify that VS-16 has no effect on unicode_version 8.0 and earler\"\"\"\n        phrase = (u\"\\u2640\"        # FEMALE SIGN\n                  u\"\\uFE0F\")       # VARIATION SELECTOR-16\n\n        expect_length_each = (1, 0)\n        expect_length_phrase = 1\n\n        # exercise,\n&gt;       length_each = tuple(wcwidth.wcwidth(w_char, unicode_version='8.0') for w_char in phrase)\n\ntests/test_emojis.py:238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/test_emojis.py:238: in \n    length_each = tuple(wcwidth.wcwidth(w_char, unicode_version='8.0') for w_char in phrase)\nwcwidth/wcwidth.py:136: in wcwidth\n    if _bisearch(ucs, ZERO_WIDTH):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nucs = 9792\ntable = {'10.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), '11.0.0': ((0, 0), (173, 1...9), (1471, 1471), ...), '12.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), ...), ...}\n\n    def _bisearch(ucs, table):\n        \"\"\"\n        Auxiliary function for binary search in interval table.\n\n        :arg int ucs: Ordinal value of unicode character.\n        :arg list table: List of starting and ending ranges of ordinal values,\n            in form of ``[(start, end), ...]``.\n        :rtype: int\n        :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n        \"\"\"\n        lbound = 0\n        ubound = len(table) - 1\n\n&gt;       if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\nE       KeyError: 0\n\nwcwidth/wcwidth.py:91: KeyError"},{"location":"analysis_baseline_wcwidth/#test_table_integritypytest_verify_table_integrity","title":"test_table_integrity.py::test_verify_table_integrity","text":"<pre>test_table_integrity.py::test_verify_table_integrity</pre><pre>\n('/testbed/tests/test_table_integrity.py', 10, 'Skipped: Test only with a single version of python')\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_ucslevelpytest_nearest_505_str","title":"test_ucslevel.py::test_nearest_505_str","text":"<pre>test_ucslevel.py::test_nearest_505_str</pre><pre>\ndef test_nearest_505_str():\n        \"\"\"wcwidth._wcmatch_version('5.0.5') returns nearest '5.0.0'. (str)\"\"\"\n        # given\n        given, expected = '5.0.5', '5.0.0'\n\n        # exercise\n&gt;       result = wcwidth._wcmatch_version(given)\n\ntests/test_ucslevel.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ngiven_version = '5.0.5'\n\n    @lru_cache(maxsize=8)\n    def _wcmatch_version(given_version):\n        \"\"\"\n        Return nearest matching supported Unicode version level.\n\n        If an exact match is not determined, the nearest lowest version level is\n        returned after a warning is emitted.  For example, given supported levels\n        ``4.1.0`` and ``5.0.0``, and a version string of ``4.9.9``, then ``4.1.0``\n        is selected and returned:\n\n        &gt;&gt;&gt; _wcmatch_version('4.9.9')\n        '4.1.0'\n        &gt;&gt;&gt; _wcmatch_version('8.0')\n        '8.0.0'\n        &gt;&gt;&gt; _wcmatch_version('1')\n        '4.1.0'\n\n        :param str given_version: given version for compare, may be ``auto``\n            (default), to select Unicode Version from Environment Variable,\n            ``UNICODE_VERSION``. If the environment variable is not set, then the\n            latest is used.\n        :rtype: str\n        :returns: unicode string, or non-unicode ``str`` type for python 2\n            when given ``version`` is also type ``str``.\n        \"\"\"\n        if given_version == 'auto':\n            given_version = os.environ.get('UNICODE_VERSION', 'latest')\n\n        if given_version == 'latest':\n            return list_versions()[-1]\n\n        supported_versions = list_versions()\n        given_value = _wcversion_value(given_version)\n\n        for version in reversed(supported_versions):\n            if _wcversion_value(version) &lt;= given_value:\n                if version != given_version:\n&gt;                   warnings.warn(f\"Unicode version '{given_version}' not found, using '{version}'\")\nE                   UserWarning: Unicode version '5.0.5' not found, using '5.0.0'\n\nwcwidth/wcwidth.py:234: UserWarning\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_ucslevelpytest_nearest_505_unicode","title":"test_ucslevel.py::test_nearest_505_unicode","text":"<pre>test_ucslevel.py::test_nearest_505_unicode</pre><pre>\ndef test_nearest_505_unicode():\n        \"\"\"wcwidth._wcmatch_version(u'5.0.5') returns nearest u'5.0.0'. (unicode)\"\"\"\n        # given\n        given, expected = u'5.0.5', u'5.0.0'\n\n        # exercise\n&gt;       result = wcwidth._wcmatch_version(given)\n\ntests/test_ucslevel.py:67: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ngiven_version = '5.0.5'\n\n    @lru_cache(maxsize=8)\n    def _wcmatch_version(given_version):\n        \"\"\"\n        Return nearest matching supported Unicode version level.\n\n        If an exact match is not determined, the nearest lowest version level is\n        returned after a warning is emitted.  For example, given supported levels\n        ``4.1.0`` and ``5.0.0``, and a version string of ``4.9.9``, then ``4.1.0``\n        is selected and returned:\n\n        &gt;&gt;&gt; _wcmatch_version('4.9.9')\n        '4.1.0'\n        &gt;&gt;&gt; _wcmatch_version('8.0')\n        '8.0.0'\n        &gt;&gt;&gt; _wcmatch_version('1')\n        '4.1.0'\n\n        :param str given_version: given version for compare, may be ``auto``\n            (default), to select Unicode Version from Environment Variable,\n            ``UNICODE_VERSION``. If the environment variable is not set, then the\n            latest is used.\n        :rtype: str\n        :returns: unicode string, or non-unicode ``str`` type for python 2\n            when given ``version`` is also type ``str``.\n        \"\"\"\n        if given_version == 'auto':\n            given_version = os.environ.get('UNICODE_VERSION', 'latest')\n\n        if given_version == 'latest':\n            return list_versions()[-1]\n\n        supported_versions = list_versions()\n        given_value = _wcversion_value(given_version)\n\n        for version in reversed(supported_versions):\n            if _wcversion_value(version) &lt;= given_value:\n                if version != given_version:\n&gt;                   warnings.warn(f\"Unicode version '{given_version}' not found, using '{version}'\")\nE                   UserWarning: Unicode version '5.0.5' not found, using '5.0.0'\n\nwcwidth/wcwidth.py:234: UserWarning\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_ucslevelpytest_nearest_800_str","title":"test_ucslevel.py::test_nearest_800_str","text":"<pre>test_ucslevel.py::test_nearest_800_str</pre><pre>\ndef test_nearest_800_str():\n        \"\"\"wcwidth._wcmatch_version('8') returns nearest '8.0.0'.\"\"\"\n        # given\n        given, expected = '8', '8.0.0'\n\n        # exercise\n&gt;       result = wcwidth._wcmatch_version(given)\n\ntests/test_ucslevel.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ngiven_version = '8'\n\n    @lru_cache(maxsize=8)\n    def _wcmatch_version(given_version):\n        \"\"\"\n        Return nearest matching supported Unicode version level.\n\n        If an exact match is not determined, the nearest lowest version level is\n        returned after a warning is emitted.  For example, given supported levels\n        ``4.1.0`` and ``5.0.0``, and a version string of ``4.9.9``, then ``4.1.0``\n        is selected and returned:\n\n        &gt;&gt;&gt; _wcmatch_version('4.9.9')\n        '4.1.0'\n        &gt;&gt;&gt; _wcmatch_version('8.0')\n        '8.0.0'\n        &gt;&gt;&gt; _wcmatch_version('1')\n        '4.1.0'\n\n        :param str given_version: given version for compare, may be ``auto``\n            (default), to select Unicode Version from Environment Variable,\n            ``UNICODE_VERSION``. If the environment variable is not set, then the\n            latest is used.\n        :rtype: str\n        :returns: unicode string, or non-unicode ``str`` type for python 2\n            when given ``version`` is also type ``str``.\n        \"\"\"\n        if given_version == 'auto':\n            given_version = os.environ.get('UNICODE_VERSION', 'latest')\n\n        if given_version == 'latest':\n            return list_versions()[-1]\n\n        supported_versions = list_versions()\n        given_value = _wcversion_value(given_version)\n\n        for version in reversed(supported_versions):\n            if _wcversion_value(version) &lt;= given_value:\n                if version != given_version:\n&gt;                   warnings.warn(f\"Unicode version '{given_version}' not found, using '{version}'\")\nE                   UserWarning: Unicode version '8' not found, using '7.0.0'\n\nwcwidth/wcwidth.py:234: UserWarning\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_ucslevelpytest_nearest_800_unicode","title":"test_ucslevel.py::test_nearest_800_unicode","text":"<pre>test_ucslevel.py::test_nearest_800_unicode</pre><pre>\ndef test_nearest_800_unicode():\n        \"\"\"wcwidth._wcmatch_version(u'8') returns nearest u'8.0.0'.\"\"\"\n        # given\n        given, expected = u'8', u'8.0.0'\n\n        # exercise\n&gt;       result = wcwidth._wcmatch_version(given)\n\ntests/test_ucslevel.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ngiven_version = '8'\n\n    @lru_cache(maxsize=8)\n    def _wcmatch_version(given_version):\n        \"\"\"\n        Return nearest matching supported Unicode version level.\n\n        If an exact match is not determined, the nearest lowest version level is\n        returned after a warning is emitted.  For example, given supported levels\n        ``4.1.0`` and ``5.0.0``, and a version string of ``4.9.9``, then ``4.1.0``\n        is selected and returned:\n\n        &gt;&gt;&gt; _wcmatch_version('4.9.9')\n        '4.1.0'\n        &gt;&gt;&gt; _wcmatch_version('8.0')\n        '8.0.0'\n        &gt;&gt;&gt; _wcmatch_version('1')\n        '4.1.0'\n\n        :param str given_version: given version for compare, may be ``auto``\n            (default), to select Unicode Version from Environment Variable,\n            ``UNICODE_VERSION``. If the environment variable is not set, then the\n            latest is used.\n        :rtype: str\n        :returns: unicode string, or non-unicode ``str`` type for python 2\n            when given ``version`` is also type ``str``.\n        \"\"\"\n        if given_version == 'auto':\n            given_version = os.environ.get('UNICODE_VERSION', 'latest')\n\n        if given_version == 'latest':\n            return list_versions()[-1]\n\n        supported_versions = list_versions()\n        given_value = _wcversion_value(given_version)\n\n        for version in reversed(supported_versions):\n            if _wcversion_value(version) &lt;= given_value:\n                if version != given_version:\n&gt;                   warnings.warn(f\"Unicode version '{given_version}' not found, using '{version}'\")\nE                   UserWarning: Unicode version '8' not found, using '7.0.0'\n\nwcwidth/wcwidth.py:234: UserWarning\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_ucslevelpytest_nearest_999_str","title":"test_ucslevel.py::test_nearest_999_str","text":"<pre>test_ucslevel.py::test_nearest_999_str</pre><pre>\ndef test_nearest_999_str():\n        \"\"\"wcwidth._wcmatch_version('999.0') returns nearest (latest).\"\"\"\n        # given\n        given, expected = '999.0', wcwidth.list_versions()[-1]\n\n        # exercise\n&gt;       result = wcwidth._wcmatch_version(given)\n\ntests/test_ucslevel.py:135: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ngiven_version = '999.0'\n\n    @lru_cache(maxsize=8)\n    def _wcmatch_version(given_version):\n        \"\"\"\n        Return nearest matching supported Unicode version level.\n\n        If an exact match is not determined, the nearest lowest version level is\n        returned after a warning is emitted.  For example, given supported levels\n        ``4.1.0`` and ``5.0.0``, and a version string of ``4.9.9``, then ``4.1.0``\n        is selected and returned:\n\n        &gt;&gt;&gt; _wcmatch_version('4.9.9')\n        '4.1.0'\n        &gt;&gt;&gt; _wcmatch_version('8.0')\n        '8.0.0'\n        &gt;&gt;&gt; _wcmatch_version('1')\n        '4.1.0'\n\n        :param str given_version: given version for compare, may be ``auto``\n            (default), to select Unicode Version from Environment Variable,\n            ``UNICODE_VERSION``. If the environment variable is not set, then the\n            latest is used.\n        :rtype: str\n        :returns: unicode string, or non-unicode ``str`` type for python 2\n            when given ``version`` is also type ``str``.\n        \"\"\"\n        if given_version == 'auto':\n            given_version = os.environ.get('UNICODE_VERSION', 'latest')\n\n        if given_version == 'latest':\n            return list_versions()[-1]\n\n        supported_versions = list_versions()\n        given_value = _wcversion_value(given_version)\n\n        for version in reversed(supported_versions):\n            if _wcversion_value(version) &lt;= given_value:\n                if version != given_version:\n&gt;                   warnings.warn(f\"Unicode version '{given_version}' not found, using '{version}'\")\nE                   UserWarning: Unicode version '999.0' not found, using '15.1.0'\n\nwcwidth/wcwidth.py:234: UserWarning\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_ucslevelpytest_nearest_999_unicode","title":"test_ucslevel.py::test_nearest_999_unicode","text":"<pre>test_ucslevel.py::test_nearest_999_unicode</pre><pre>\ndef test_nearest_999_unicode():\n        \"\"\"wcwidth._wcmatch_version(u'999.0') returns nearest (latest).\"\"\"\n        # given\n        given, expected = u'999.0', wcwidth.list_versions()[-1]\n\n        # exercise\n&gt;       result = wcwidth._wcmatch_version(given)\n\ntests/test_ucslevel.py:147: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ngiven_version = '999.0'\n\n    @lru_cache(maxsize=8)\n    def _wcmatch_version(given_version):\n        \"\"\"\n        Return nearest matching supported Unicode version level.\n\n        If an exact match is not determined, the nearest lowest version level is\n        returned after a warning is emitted.  For example, given supported levels\n        ``4.1.0`` and ``5.0.0``, and a version string of ``4.9.9``, then ``4.1.0``\n        is selected and returned:\n\n        &gt;&gt;&gt; _wcmatch_version('4.9.9')\n        '4.1.0'\n        &gt;&gt;&gt; _wcmatch_version('8.0')\n        '8.0.0'\n        &gt;&gt;&gt; _wcmatch_version('1')\n        '4.1.0'\n\n        :param str given_version: given version for compare, may be ``auto``\n            (default), to select Unicode Version from Environment Variable,\n            ``UNICODE_VERSION``. If the environment variable is not set, then the\n            latest is used.\n        :rtype: str\n        :returns: unicode string, or non-unicode ``str`` type for python 2\n            when given ``version`` is also type ``str``.\n        \"\"\"\n        if given_version == 'auto':\n            given_version = os.environ.get('UNICODE_VERSION', 'latest')\n\n        if given_version == 'latest':\n            return list_versions()[-1]\n\n        supported_versions = list_versions()\n        given_value = _wcversion_value(given_version)\n\n        for version in reversed(supported_versions):\n            if _wcversion_value(version) &lt;= given_value:\n                if version != given_version:\n&gt;                   warnings.warn(f\"Unicode version '{given_version}' not found, using '{version}'\")\nE                   UserWarning: Unicode version '999.0' not found, using '15.1.0'\n\nwcwidth/wcwidth.py:234: UserWarning\n</pre>"},{"location":"analysis_baseline_wcwidth/#test_ucslevelpytest_nonint_unicode","title":"test_ucslevel.py::test_nonint_unicode","text":"<pre>test_ucslevel.py::test_nonint_unicode</pre><pre>\ndef test_nonint_unicode():\n        \"\"\"wcwidth._wcmatch_version(u'x.y.z') returns latest (unicode).\"\"\"\n        # given\n        given, expected = u'x.y.z', wcwidth.list_versions()[-1]\n        warnings.resetwarnings()\n        wcwidth._wcmatch_version.cache_clear()\n\n        # exercise\n        with pytest.warns(UserWarning):\n            # warns that given version is not valid\n&gt;           result = wcwidth._wcmatch_version(given)\n\ntests/test_ucslevel.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:229: in _wcmatch_version\n    given_value = _wcversion_value(given_version)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nver_string = 'x.y.z'\n\n    @lru_cache(maxsize=128)\n    def _wcversion_value(ver_string):\n        \"\"\"\n        Integer-mapped value of given dotted version string.\n\n        :param str ver_string: Unicode version string, of form ``n.n.n``.\n        :rtype: tuple(int)\n        :returns: tuple of digit tuples, ``tuple(int, [...])``.\n        \"\"\"\n&gt;       return tuple(map(int, ver_string.split('.')))\nE       ValueError: invalid literal for int() with base 10: 'x'\n\nwcwidth/wcwidth.py:194: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\n    def test_nonint_unicode():\n        \"\"\"wcwidth._wcmatch_version(u'x.y.z') returns latest (unicode).\"\"\"\n        # given\n        given, expected = u'x.y.z', wcwidth.list_versions()[-1]\n        warnings.resetwarnings()\n        wcwidth._wcmatch_version.cache_clear()\n\n        # exercise\n&gt;       with pytest.warns(UserWarning):\nE       Failed: DID NOT WARN. No warnings of type (,) were emitted.\nE        Emitted warnings: [].\n\ntests/test_ucslevel.py:161: Failed"},{"location":"analysis_baseline_wcwidth/#test_ucslevelpytest_nonint_str","title":"test_ucslevel.py::test_nonint_str","text":"<pre>test_ucslevel.py::test_nonint_str</pre><pre>\ndef test_nonint_str():\n        \"\"\"wcwidth._wcmatch_version(u'x.y.z') returns latest (str).\"\"\"\n        # given\n        given, expected = 'x.y.z', wcwidth.list_versions()[-1]\n        warnings.resetwarnings()\n        wcwidth._wcmatch_version.cache_clear()\n\n        # exercise\n        with pytest.warns(UserWarning):\n            # warns that given version is not valid\n&gt;           result = wcwidth._wcmatch_version(given)\n\ntests/test_ucslevel.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nwcwidth/wcwidth.py:229: in _wcmatch_version\n    given_value = _wcversion_value(given_version)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nver_string = 'x.y.z'\n\n    @lru_cache(maxsize=128)\n    def _wcversion_value(ver_string):\n        \"\"\"\n        Integer-mapped value of given dotted version string.\n\n        :param str ver_string: Unicode version string, of form ``n.n.n``.\n        :rtype: tuple(int)\n        :returns: tuple of digit tuples, ``tuple(int, [...])``.\n        \"\"\"\n&gt;       return tuple(map(int, ver_string.split('.')))\nE       ValueError: invalid literal for int() with base 10: 'x'\n\nwcwidth/wcwidth.py:194: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\n    def test_nonint_str():\n        \"\"\"wcwidth._wcmatch_version(u'x.y.z') returns latest (str).\"\"\"\n        # given\n        given, expected = 'x.y.z', wcwidth.list_versions()[-1]\n        warnings.resetwarnings()\n        wcwidth._wcmatch_version.cache_clear()\n\n        # exercise\n&gt;       with pytest.warns(UserWarning):\nE       Failed: DID NOT WARN. No warnings of type (,) were emitted.\nE        Emitted warnings: [].\n\ntests/test_ucslevel.py:177: Failed"},{"location":"analysis_baseline_wcwidth/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/wcwidth/unicode_versions.py b/wcwidth/unicode_versions.py\nindex cc437d7..5c07028 100644\n--- a/wcwidth/unicode_versions.py\n+++ b/wcwidth/unicode_versions.py\n@@ -15,4 +15,8 @@ def list_versions():\n     :returns: Supported Unicode version numbers in ascending sorted order.\n     :rtype: list[str]\n     \"\"\"\n-    pass\n+    return [\n+        '4.1.0', '5.0.0', '5.1.0', '5.2.0', '6.0.0', '6.1.0', '6.2.0', '6.3.0',\n+        '7.0.0', '8.0.0', '9.0.0', '10.0.0', '11.0.0', '12.0.0', '12.1.0',\n+        '13.0.0', '14.0.0', '15.0.0', '15.1.0'\n+    ]\ndiff --git a/wcwidth/wcwidth.py b/wcwidth/wcwidth.py\nindex 6d93a59..8daf7de 100644\n--- a/wcwidth/wcwidth.py\n+++ b/wcwidth/wcwidth.py\n@@ -85,7 +85,22 @@ def _bisearch(ucs, table):\n     :rtype: int\n     :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n     \"\"\"\n-    pass\n+    lbound = 0\n+    ubound = len(table) - 1\n+\n+    if ucs &lt; table[0][0] or ucs &gt; table[-1][1]:\n+        return 0\n+\n+    while ubound &gt;= lbound:\n+        mid = (lbound + ubound) // 2\n+        if ucs &gt; table[mid][1]:\n+            lbound = mid + 1\n+        elif ucs &lt; table[mid][0]:\n+            ubound = mid - 1\n+        else:\n+            return 1\n+\n+    return 0\n\n\n @lru_cache(maxsize=1000)\n@@ -111,7 +126,26 @@ def wcwidth(wc, unicode_version='auto'):\n\n     See :ref:`Specification` for details of cell measurement.\n     \"\"\"\n-    pass\n+    ucs = ord(wc)\n+    \n+    # C0/C1 control characters\n+    if ucs &lt; 32 or 0x07F &lt;= ucs &lt; 0x0A0:\n+        return -1\n+\n+    # Check if the character is in the zero width table\n+    if _bisearch(ucs, ZERO_WIDTH):\n+        return 0\n+\n+    # Check if the character is in the wide East Asian table\n+    if _bisearch(ucs, WIDE_EASTASIAN):\n+        return 2\n+\n+    # Check if it's a combining character\n+    if ucs in VS16_NARROW_TO_WIDE:\n+        return 2\n+\n+    # All other characters are considered to have a width of 1\n+    return 1\n\n\n def wcswidth(pwcs, n=None, unicode_version='auto'):\n@@ -135,7 +169,17 @@ def wcswidth(pwcs, n=None, unicode_version='auto'):\n\n     See :ref:`Specification` for details of cell measurement.\n     \"\"\"\n-    pass\n+    if n is None:\n+        n = len(pwcs)\n+    \n+    width = 0\n+    for char in pwcs[:n]:\n+        char_width = wcwidth(char, unicode_version)\n+        if char_width == -1:\n+            return -1\n+        width += char_width\n+    \n+    return width\n\n\n @lru_cache(maxsize=128)\n@@ -147,7 +191,7 @@ def _wcversion_value(ver_string):\n     :rtype: tuple(int)\n     :returns: tuple of digit tuples, ``tuple(int, [...])``.\n     \"\"\"\n-    pass\n+    return tuple(map(int, ver_string.split('.')))\n\n\n @lru_cache(maxsize=8)\n@@ -175,4 +219,21 @@ def _wcmatch_version(given_version):\n     :returns: unicode string, or non-unicode ``str`` type for python 2\n         when given ``version`` is also type ``str``.\n     \"\"\"\n-    pass\n+    if given_version == 'auto':\n+        given_version = os.environ.get('UNICODE_VERSION', 'latest')\n+    \n+    if given_version == 'latest':\n+        return list_versions()[-1]\n+    \n+    supported_versions = list_versions()\n+    given_value = _wcversion_value(given_version)\n+    \n+    for version in reversed(supported_versions):\n+        if _wcversion_value(version) &lt;= given_value:\n+            if version != given_version:\n+                warnings.warn(f\"Unicode version '{given_version}' not found, using '{version}'\")\n+            return version\n+    \n+    # If no suitable version found, return the earliest supported version\n+    warnings.warn(f\"Unicode version '{given_version}' not found, using '{supported_versions[0]}'\")\n+    return supported_versions[0]\n</code></pre>"},{"location":"analysis_reference/","title":"Analysis reference","text":"<p>back to all submissions</p>"},{"location":"analysis_reference/#submission-name-reference-gold-split-lite","title":"Submission Name: Reference (Gold) (split: lite)","text":"Repository Resolved Pass Rate Test Duration (s) Analysis simpy Yes 140 / 150 2.51 Analysis tinydb Yes 201 / 201 1.36 Analysis marshmallow Yes 1229 / 1229 2.82 Analysis wcwidth Yes 38 / 39 1.11 Analysis imapclient Yes 267 / 267 0.58 Analysis voluptuous Yes 149 / 149 0.42 Analysis jinja Yes 851 / 851 2.85 Analysis deprecated Yes 171 / 171 0.99 Analysis cookiecutter Yes 367 / 371 7.29 Analysis cachetools Yes 215 / 215 1.21 Analysis"},{"location":"analysis_reference_cachetools/","title":"Analysis reference cachetools","text":"<p>back to reference summary</p>"},{"location":"analysis_reference_cachetools/#submission-name-reference","title":"Submission Name: reference","text":""},{"location":"analysis_reference_cachetools/#repository-cachetools","title":"Repository: cachetools","text":""},{"location":"analysis_reference_cachetools/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count passed 215 total 215 collected 215"},{"location":"analysis_reference_cachetools/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_reference_cachetools/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/src/cachetools/func.py b/src/cachetools/func.py\nindex 338ef94..3eafddf 100644\n--- a/src/cachetools/func.py\n+++ b/src/cachetools/func.py\n@@ -1,23 +1,39 @@\n \"\"\"`functools.lru_cache` compatible memoizing function decorators.\"\"\"\n-__all__ = ('fifo_cache', 'lfu_cache', 'lru_cache', 'mru_cache', 'rr_cache',\n-    'ttl_cache')\n+\n+__all__ = (\"fifo_cache\", \"lfu_cache\", \"lru_cache\", \"mru_cache\", \"rr_cache\", \"ttl_cache\")\n+\n import math\n import random\n import time\n+\n try:\n     from threading import RLock\n-except ImportError:\n+except ImportError:  # pragma: no cover\n     from dummy_threading import RLock\n+\n from . import FIFOCache, LFUCache, LRUCache, MRUCache, RRCache, TTLCache\n from . import cached\n from . import keys\n\n\n class _UnboundTTLCache(TTLCache):\n-\n     def __init__(self, ttl, timer):\n         TTLCache.__init__(self, math.inf, ttl, timer)\n\n+    @property\n+    def maxsize(self):\n+        return None\n+\n+\n+def _cache(cache, maxsize, typed):\n+    def decorator(func):\n+        key = keys.typedkey if typed else keys.hashkey\n+        wrapper = cached(cache=cache, key=key, lock=RLock(), info=True)(func)\n+        wrapper.cache_parameters = lambda: {\"maxsize\": maxsize, \"typed\": typed}\n+        return wrapper\n+\n+    return decorator\n+\n\n def fifo_cache(maxsize=128, typed=False):\n     \"\"\"Decorator to wrap a function with a memoizing callable that saves\n@@ -25,7 +41,12 @@ def fifo_cache(maxsize=128, typed=False):\n     algorithm.\n\n     \"\"\"\n-    pass\n+    if maxsize is None:\n+        return _cache({}, None, typed)\n+    elif callable(maxsize):\n+        return _cache(FIFOCache(128), 128, typed)(maxsize)\n+    else:\n+        return _cache(FIFOCache(maxsize), maxsize, typed)\n\n\n def lfu_cache(maxsize=128, typed=False):\n@@ -34,7 +55,12 @@ def lfu_cache(maxsize=128, typed=False):\n     algorithm.\n\n     \"\"\"\n-    pass\n+    if maxsize is None:\n+        return _cache({}, None, typed)\n+    elif callable(maxsize):\n+        return _cache(LFUCache(128), 128, typed)(maxsize)\n+    else:\n+        return _cache(LFUCache(maxsize), maxsize, typed)\n\n\n def lru_cache(maxsize=128, typed=False):\n@@ -43,7 +69,12 @@ def lru_cache(maxsize=128, typed=False):\n     algorithm.\n\n     \"\"\"\n-    pass\n+    if maxsize is None:\n+        return _cache({}, None, typed)\n+    elif callable(maxsize):\n+        return _cache(LRUCache(128), 128, typed)(maxsize)\n+    else:\n+        return _cache(LRUCache(maxsize), maxsize, typed)\n\n\n def mru_cache(maxsize=128, typed=False):\n@@ -51,7 +82,16 @@ def mru_cache(maxsize=128, typed=False):\n     up to `maxsize` results based on a Most Recently Used (MRU)\n     algorithm.\n     \"\"\"\n-    pass\n+    from warnings import warn\n+\n+    warn(\"@mru_cache is deprecated\", DeprecationWarning, stacklevel=2)\n+\n+    if maxsize is None:\n+        return _cache({}, None, typed)\n+    elif callable(maxsize):\n+        return _cache(MRUCache(128), 128, typed)(maxsize)\n+    else:\n+        return _cache(MRUCache(maxsize), maxsize, typed)\n\n\n def rr_cache(maxsize=128, choice=random.choice, typed=False):\n@@ -60,7 +100,12 @@ def rr_cache(maxsize=128, choice=random.choice, typed=False):\n     algorithm.\n\n     \"\"\"\n-    pass\n+    if maxsize is None:\n+        return _cache({}, None, typed)\n+    elif callable(maxsize):\n+        return _cache(RRCache(128, choice), 128, typed)(maxsize)\n+    else:\n+        return _cache(RRCache(maxsize, choice), maxsize, typed)\n\n\n def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n@@ -68,4 +113,9 @@ def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n     up to `maxsize` results based on a Least Recently Used (LRU)\n     algorithm with a per-item time-to-live (TTL) value.\n     \"\"\"\n-    pass\n+    if maxsize is None:\n+        return _cache(_UnboundTTLCache(ttl, timer), None, typed)\n+    elif callable(maxsize):\n+        return _cache(TTLCache(128, ttl, timer), 128, typed)(maxsize)\n+    else:\n+        return _cache(TTLCache(maxsize, ttl, timer), maxsize, typed)\ndiff --git a/src/cachetools/keys.py b/src/cachetools/keys.py\nindex ed97ffd..8689b17 100644\n--- a/src/cachetools/keys.py\n+++ b/src/cachetools/keys.py\n@@ -1,5 +1,6 @@\n \"\"\"Key functions for memoizing decorators.\"\"\"\n-__all__ = 'hashkey', 'methodkey', 'typedkey', 'typedmethodkey'\n+\n+__all__ = (\"hashkey\", \"methodkey\", \"typedkey\", \"typedmethodkey\")\n\n\n class _HashedTuple(tuple):\n@@ -9,6 +10,7 @@ class _HashedTuple(tuple):\n     library functools implementation.\n\n     \"\"\"\n+\n     __hashvalue = None\n\n     def __hash__(self, hash=tuple.__hash__):\n@@ -27,24 +29,34 @@ class _HashedTuple(tuple):\n         return {}\n\n\n-_kwmark = _HashedTuple,\n+# used for separating keyword arguments; we do not use an object\n+# instance here so identity is preserved when pickling/unpickling\n+_kwmark = (_HashedTuple,)\n\n\n def hashkey(*args, **kwargs):\n     \"\"\"Return a cache key for the specified hashable arguments.\"\"\"\n-    pass\n+\n+    if kwargs:\n+        return _HashedTuple(args + sum(sorted(kwargs.items()), _kwmark))\n+    else:\n+        return _HashedTuple(args)\n\n\n def methodkey(self, *args, **kwargs):\n     \"\"\"Return a cache key for use with cached methods.\"\"\"\n-    pass\n+    return hashkey(*args, **kwargs)\n\n\n def typedkey(*args, **kwargs):\n     \"\"\"Return a typed cache key for the specified hashable arguments.\"\"\"\n-    pass\n+\n+    key = hashkey(*args, **kwargs)\n+    key += tuple(type(v) for v in args)\n+    key += tuple(type(v) for _, v in sorted(kwargs.items()))\n+    return key\n\n\n def typedmethodkey(self, *args, **kwargs):\n     \"\"\"Return a typed cache key for use with cached methods.\"\"\"\n-    pass\n+    return typedkey(*args, **kwargs)\n</code></pre>"},{"location":"analysis_reference_cookiecutter/","title":"Analysis reference cookiecutter","text":"<p>back to reference summary</p>"},{"location":"analysis_reference_cookiecutter/#submission-name-reference","title":"Submission Name: reference","text":""},{"location":"analysis_reference_cookiecutter/#repository-cookiecutter","title":"Repository: cookiecutter","text":""},{"location":"analysis_reference_cookiecutter/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count passed 367 skipped 4 total 371 collected 371"},{"location":"analysis_reference_cookiecutter/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_reference_cookiecutter/#test_generate_hookspytest_run_shell_hooks_win","title":"test_generate_hooks.py::test_run_shell_hooks_win","text":"<pre>test_generate_hooks.py::test_run_shell_hooks_win</pre><pre>\n('/testbed/tests/test_generate_hooks.py', 195, 'Skipped: Win only test')\n</pre>"},{"location":"analysis_reference_cookiecutter/#test_promptpytest_cookiecutter_nested_templates_invalid_win_paths","title":"test_prompt.py::test_cookiecutter_nested_templates_invalid_win_paths[]","text":"<pre>test_prompt.py::test_cookiecutter_nested_templates_invalid_win_paths[]</pre><pre>\n('/testbed/tests/test_prompt.py', 623, 'Skipped: Win only test')\n</pre>"},{"location":"analysis_reference_cookiecutter/#tmp","title":"tmp]","text":"<pre>tmp]</pre><pre>\n('/testbed/tests/test_prompt.py', 623, 'Skipped: Win only test')\n</pre>"},{"location":"analysis_reference_cookiecutter/#tmp_1","title":"tmp]","text":"<pre>tmp]</pre><pre>\n('/testbed/tests/test_prompt.py', 623, 'Skipped: Win only test')\n</pre>"},{"location":"analysis_reference_cookiecutter/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/cookiecutter/cli.py b/cookiecutter/cli.py\nindex b050655..8b67863 100644\n--- a/cookiecutter/cli.py\n+++ b/cookiecutter/cli.py\n@@ -1,81 +1,241 @@\n \"\"\"Main `cookiecutter` CLI.\"\"\"\n+\n import collections\n import json\n import os\n import sys\n+\n import click\n+\n from cookiecutter import __version__\n from cookiecutter.config import get_user_config\n-from cookiecutter.exceptions import ContextDecodingException, FailedHookException, InvalidModeException, InvalidZipRepository, OutputDirExistsException, RepositoryCloneFailed, RepositoryNotFound, UndefinedVariableInTemplate, UnknownExtension\n+from cookiecutter.exceptions import (\n+    ContextDecodingException,\n+    FailedHookException,\n+    InvalidModeException,\n+    InvalidZipRepository,\n+    OutputDirExistsException,\n+    RepositoryCloneFailed,\n+    RepositoryNotFound,\n+    UndefinedVariableInTemplate,\n+    UnknownExtension,\n+)\n from cookiecutter.log import configure_logger\n from cookiecutter.main import cookiecutter\n\n\n def version_msg():\n     \"\"\"Return the Cookiecutter version, location and Python powering it.\"\"\"\n-    pass\n+    python_version = sys.version\n+    location = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n+    return f\"Cookiecutter {__version__} from {location} (Python {python_version})\"\n\n\n def validate_extra_context(ctx, param, value):\n     \"\"\"Validate extra context.\"\"\"\n-    pass\n+    for string in value:\n+        if '=' not in string:\n+            raise click.BadParameter(\n+                f\"EXTRA_CONTEXT should contain items of the form key=value; \"\n+                f\"'{string}' doesn't match that form\"\n+            )\n+\n+    # Convert tuple -- e.g.: ('program_name=foobar', 'startsecs=66')\n+    # to dict -- e.g.: {'program_name': 'foobar', 'startsecs': '66'}\n+    return collections.OrderedDict(s.split('=', 1) for s in value) or None\n\n\n def list_installed_templates(default_config, passed_config_file):\n     \"\"\"List installed (locally cloned) templates. Use cookiecutter --list-installed.\"\"\"\n-    pass\n+    config = get_user_config(passed_config_file, default_config)\n+    cookiecutter_folder = config.get('cookiecutters_dir')\n+    if not os.path.exists(cookiecutter_folder):\n+        click.echo(\n+            f\"Error: Cannot list installed templates. \"\n+            f\"Folder does not exist: {cookiecutter_folder}\"\n+        )\n+        sys.exit(-1)\n+\n+    template_names = [\n+        folder\n+        for folder in os.listdir(cookiecutter_folder)\n+        if os.path.exists(\n+            os.path.join(cookiecutter_folder, folder, 'cookiecutter.json')\n+        )\n+    ]\n+    click.echo(f'{len(template_names)} installed templates: ')\n+    for name in template_names:\n+        click.echo(f' * {name}')\n\n\n @click.command(context_settings=dict(help_option_names=['-h', '--help']))\n @click.version_option(__version__, '-V', '--version', message=version_msg())\n @click.argument('template', required=False)\n @click.argument('extra_context', nargs=-1, callback=validate_extra_context)\n-@click.option('--no-input', is_flag=True, help=\n-    'Do not prompt for parameters and only use cookiecutter.json file content. Defaults to deleting any cached resources and redownloading them. Cannot be combined with the --replay flag.'\n-    )\n-@click.option('-c', '--checkout', help=\n-    'branch, tag or commit to checkout after git clone')\n-@click.option('--directory', help=\n-    'Directory within repo that holds cookiecutter.json file for advanced repositories with multi templates in it'\n-    )\n-@click.option('-v', '--verbose', is_flag=True, help=\n-    'Print debug information', default=False)\n-@click.option('--replay', is_flag=True, help=\n-    'Do not prompt for parameters and only use information entered previously. Cannot be combined with the --no-input flag or with extra configuration passed.'\n-    )\n-@click.option('--replay-file', type=click.Path(), default=None, help=\n-    'Use this file for replay instead of the default.')\n-@click.option('-f', '--overwrite-if-exists', is_flag=True, help=\n-    'Overwrite the contents of the output directory if it already exists')\n-@click.option('-s', '--skip-if-file-exists', is_flag=True, help=\n-    'Skip the files in the corresponding directories if they already exist',\n-    default=False)\n-@click.option('-o', '--output-dir', default='.', type=click.Path(), help=\n-    'Where to output the generated project dir into')\n-@click.option('--config-file', type=click.Path(), default=None, help=\n-    'User configuration file')\n-@click.option('--default-config', is_flag=True, help=\n-    'Do not load a config file. Use the defaults instead')\n-@click.option('--debug-file', type=click.Path(), default=None, help=\n-    'File to be used as a stream for DEBUG logging')\n-@click.option('--accept-hooks', type=click.Choice(['yes', 'ask', 'no']),\n-    default='yes', help='Accept pre/post hooks')\n-@click.option('-l', '--list-installed', is_flag=True, help=\n-    'List currently installed templates.')\n-@click.option('--keep-project-on-failure', is_flag=True, help=\n-    'Do not delete project folder on failure')\n-def main(template, extra_context, no_input, checkout, verbose, replay,\n-    overwrite_if_exists, output_dir, config_file, default_config,\n-    debug_file, directory, skip_if_file_exists, accept_hooks, replay_file,\n-    list_installed, keep_project_on_failure):\n+@click.option(\n+    '--no-input',\n+    is_flag=True,\n+    help='Do not prompt for parameters and only use cookiecutter.json file content. '\n+    'Defaults to deleting any cached resources and redownloading them. '\n+    'Cannot be combined with the --replay flag.',\n+)\n+@click.option(\n+    '-c',\n+    '--checkout',\n+    help='branch, tag or commit to checkout after git clone',\n+)\n+@click.option(\n+    '--directory',\n+    help='Directory within repo that holds cookiecutter.json file '\n+    'for advanced repositories with multi templates in it',\n+)\n+@click.option(\n+    '-v', '--verbose', is_flag=True, help='Print debug information', default=False\n+)\n+@click.option(\n+    '--replay',\n+    is_flag=True,\n+    help='Do not prompt for parameters and only use information entered previously. '\n+    'Cannot be combined with the --no-input flag or with extra configuration passed.',\n+)\n+@click.option(\n+    '--replay-file',\n+    type=click.Path(),\n+    default=None,\n+    help='Use this file for replay instead of the default.',\n+)\n+@click.option(\n+    '-f',\n+    '--overwrite-if-exists',\n+    is_flag=True,\n+    help='Overwrite the contents of the output directory if it already exists',\n+)\n+@click.option(\n+    '-s',\n+    '--skip-if-file-exists',\n+    is_flag=True,\n+    help='Skip the files in the corresponding directories if they already exist',\n+    default=False,\n+)\n+@click.option(\n+    '-o',\n+    '--output-dir',\n+    default='.',\n+    type=click.Path(),\n+    help='Where to output the generated project dir into',\n+)\n+@click.option(\n+    '--config-file', type=click.Path(), default=None, help='User configuration file'\n+)\n+@click.option(\n+    '--default-config',\n+    is_flag=True,\n+    help='Do not load a config file. Use the defaults instead',\n+)\n+@click.option(\n+    '--debug-file',\n+    type=click.Path(),\n+    default=None,\n+    help='File to be used as a stream for DEBUG logging',\n+)\n+@click.option(\n+    '--accept-hooks',\n+    type=click.Choice(['yes', 'ask', 'no']),\n+    default='yes',\n+    help='Accept pre/post hooks',\n+)\n+@click.option(\n+    '-l', '--list-installed', is_flag=True, help='List currently installed templates.'\n+)\n+@click.option(\n+    '--keep-project-on-failure',\n+    is_flag=True,\n+    help='Do not delete project folder on failure',\n+)\n+def main(\n+    template,\n+    extra_context,\n+    no_input,\n+    checkout,\n+    verbose,\n+    replay,\n+    overwrite_if_exists,\n+    output_dir,\n+    config_file,\n+    default_config,\n+    debug_file,\n+    directory,\n+    skip_if_file_exists,\n+    accept_hooks,\n+    replay_file,\n+    list_installed,\n+    keep_project_on_failure,\n+):\n     \"\"\"Create a project from a Cookiecutter project template (TEMPLATE).\n\n     Cookiecutter is free and open source software, developed and managed by\n     volunteers. If you would like to help out or fund the project, please get\n     in touch at https://github.com/cookiecutter/cookiecutter.\n     \"\"\"\n-    pass\n+    # Commands that should work without arguments\n+    if list_installed:\n+        list_installed_templates(default_config, config_file)\n+        sys.exit(0)\n+\n+    # Raising usage, after all commands that should work without args.\n+    if not template or template.lower() == 'help':\n+        click.echo(click.get_current_context().get_help())\n+        sys.exit(0)\n+\n+    configure_logger(stream_level='DEBUG' if verbose else 'INFO', debug_file=debug_file)\n+\n+    # If needed, prompt the user to ask whether or not they want to execute\n+    # the pre/post hooks.\n+    if accept_hooks == \"ask\":\n+        _accept_hooks = click.confirm(\"Do you want to execute hooks?\")\n+    else:\n+        _accept_hooks = accept_hooks == \"yes\"\n+\n+    if replay_file:\n+        replay = replay_file\n+\n+    try:\n+        cookiecutter(\n+            template,\n+            checkout,\n+            no_input,\n+            extra_context=extra_context,\n+            replay=replay,\n+            overwrite_if_exists=overwrite_if_exists,\n+            output_dir=output_dir,\n+            config_file=config_file,\n+            default_config=default_config,\n+            password=os.environ.get('COOKIECUTTER_REPO_PASSWORD'),\n+            directory=directory,\n+            skip_if_file_exists=skip_if_file_exists,\n+            accept_hooks=_accept_hooks,\n+            keep_project_on_failure=keep_project_on_failure,\n+        )\n+    except (\n+        ContextDecodingException,\n+        OutputDirExistsException,\n+        InvalidModeException,\n+        FailedHookException,\n+        UnknownExtension,\n+        InvalidZipRepository,\n+        RepositoryNotFound,\n+        RepositoryCloneFailed,\n+    ) as e:\n+        click.echo(e)\n+        sys.exit(1)\n+    except UndefinedVariableInTemplate as undefined_err:\n+        click.echo(f'{undefined_err.message}')\n+        click.echo(f'Error message: {undefined_err.error.message}')\n+\n+        context_str = json.dumps(undefined_err.context, indent=4, sort_keys=True)\n+        click.echo(f'Context: {context_str}')\n+        sys.exit(1)\n\n\n-if __name__ == '__main__':\n+if __name__ == \"__main__\":\n     main()\ndiff --git a/cookiecutter/config.py b/cookiecutter/config.py\nindex 6356215..04d59b7 100644\n--- a/cookiecutter/config.py\n+++ b/cookiecutter/config.py\n@@ -1,23 +1,37 @@\n \"\"\"Global configuration handling.\"\"\"\n+\n import collections\n import copy\n import logging\n import os\n+\n import yaml\n+\n from cookiecutter.exceptions import ConfigDoesNotExistException, InvalidConfiguration\n+\n logger = logging.getLogger(__name__)\n+\n USER_CONFIG_PATH = os.path.expanduser('~/.cookiecutterrc')\n-BUILTIN_ABBREVIATIONS = {'gh': 'https://github.com/{0}.git', 'gl':\n-    'https://gitlab.com/{0}.git', 'bb': 'https://bitbucket.org/{0}'}\n-DEFAULT_CONFIG = {'cookiecutters_dir': os.path.expanduser(\n-    '~/.cookiecutters/'), 'replay_dir': os.path.expanduser(\n-    '~/.cookiecutter_replay/'), 'default_context': collections.OrderedDict(\n-    []), 'abbreviations': BUILTIN_ABBREVIATIONS}\n+\n+BUILTIN_ABBREVIATIONS = {\n+    'gh': 'https://github.com/{0}.git',\n+    'gl': 'https://gitlab.com/{0}.git',\n+    'bb': 'https://bitbucket.org/{0}',\n+}\n+\n+DEFAULT_CONFIG = {\n+    'cookiecutters_dir': os.path.expanduser('~/.cookiecutters/'),\n+    'replay_dir': os.path.expanduser('~/.cookiecutter_replay/'),\n+    'default_context': collections.OrderedDict([]),\n+    'abbreviations': BUILTIN_ABBREVIATIONS,\n+}\n\n\n def _expand_path(path):\n     \"\"\"Expand both environment variables and user home in the given path.\"\"\"\n-    pass\n+    path = os.path.expandvars(path)\n+    path = os.path.expanduser(path)\n+    return path\n\n\n def merge_configs(default, overwrite):\n@@ -26,12 +40,46 @@ def merge_configs(default, overwrite):\n     Dict values that are dictionaries themselves will be updated, whilst\n     preserving existing keys.\n     \"\"\"\n-    pass\n+    new_config = copy.deepcopy(default)\n+\n+    for k, v in overwrite.items():\n+        # Make sure to preserve existing items in\n+        # nested dicts, for example `abbreviations`\n+        if isinstance(v, dict):\n+            new_config[k] = merge_configs(default.get(k, {}), v)\n+        else:\n+            new_config[k] = v\n+\n+    return new_config\n\n\n def get_config(config_path):\n     \"\"\"Retrieve the config from the specified path, returning a config dict.\"\"\"\n-    pass\n+    if not os.path.exists(config_path):\n+        raise ConfigDoesNotExistException(f'Config file {config_path} does not exist.')\n+\n+    logger.debug('config_path is %s', config_path)\n+    with open(config_path, encoding='utf-8') as file_handle:\n+        try:\n+            yaml_dict = yaml.safe_load(file_handle) or {}\n+        except yaml.YAMLError as e:\n+            raise InvalidConfiguration(\n+                f'Unable to parse YAML file {config_path}.'\n+            ) from e\n+        if not isinstance(yaml_dict, dict):\n+            raise InvalidConfiguration(\n+                f'Top-level element of YAML file {config_path} should be an object.'\n+            )\n+\n+    config_dict = merge_configs(DEFAULT_CONFIG, yaml_dict)\n+\n+    raw_replay_dir = config_dict['replay_dir']\n+    config_dict['replay_dir'] = _expand_path(raw_replay_dir)\n+\n+    raw_cookies_dir = config_dict['cookiecutters_dir']\n+    config_dict['cookiecutters_dir'] = _expand_path(raw_cookies_dir)\n+\n+    return config_dict\n\n\n def get_user_config(config_file=None, default_config=False):\n@@ -53,4 +101,34 @@ def get_user_config(config_file=None, default_config=False):\n     If the environment variable is not set, try the default config file path\n     before falling back to the default config values.\n     \"\"\"\n-    pass\n+    # Do NOT load a config. Merge provided values with defaults and return them instead\n+    if default_config and isinstance(default_config, dict):\n+        return merge_configs(DEFAULT_CONFIG, default_config)\n+\n+    # Do NOT load a config. Return defaults instead.\n+    if default_config:\n+        logger.debug(\"Force ignoring user config with default_config switch.\")\n+        return copy.copy(DEFAULT_CONFIG)\n+\n+    # Load the given config file\n+    if config_file and config_file is not USER_CONFIG_PATH:\n+        logger.debug(\"Loading custom config from %s.\", config_file)\n+        return get_config(config_file)\n+\n+    try:\n+        # Does the user set up a config environment variable?\n+        env_config_file = os.environ['COOKIECUTTER_CONFIG']\n+    except KeyError:\n+        # Load an optional user config if it exists\n+        # otherwise return the defaults\n+        if os.path.exists(USER_CONFIG_PATH):\n+            logger.debug(\"Loading config from %s.\", USER_CONFIG_PATH)\n+            return get_config(USER_CONFIG_PATH)\n+        else:\n+            logger.debug(\"User config not found. Loading default config.\")\n+            return copy.copy(DEFAULT_CONFIG)\n+    else:\n+        # There is a config environment variable. Try to load it.\n+        # Do not check for existence, so invalid file paths raise an error.\n+        logger.debug(\"User config not found or not specified. Loading default config.\")\n+        return get_config(env_config_file)\ndiff --git a/cookiecutter/environment.py b/cookiecutter/environment.py\nindex 8a7bb61..235f74b 100644\n--- a/cookiecutter/environment.py\n+++ b/cookiecutter/environment.py\n@@ -1,5 +1,7 @@\n \"\"\"Jinja2 environment and extensions loading.\"\"\"\n+\n from jinja2 import Environment, StrictUndefined\n+\n from cookiecutter.exceptions import UnknownExtension\n\n\n@@ -20,12 +22,16 @@ class ExtensionLoaderMixin:\n         3. Attempts to load the extensions. Provides useful error if fails.\n         \"\"\"\n         context = kwargs.pop('context', {})\n-        default_extensions = ['cookiecutter.extensions.JsonifyExtension',\n+\n+        default_extensions = [\n+            'cookiecutter.extensions.JsonifyExtension',\n             'cookiecutter.extensions.RandomStringExtension',\n             'cookiecutter.extensions.SlugifyExtension',\n             'cookiecutter.extensions.TimeExtension',\n-            'cookiecutter.extensions.UUIDExtension']\n+            'cookiecutter.extensions.UUIDExtension',\n+        ]\n         extensions = default_extensions + self._read_extensions(context)\n+\n         try:\n             super().__init__(extensions=extensions, **kwargs)\n         except ImportError as err:\n@@ -37,7 +43,12 @@ class ExtensionLoaderMixin:\n         If context does not contain the relevant info, return an empty\n         list instead.\n         \"\"\"\n-        pass\n+        try:\n+            extensions = context['cookiecutter']['_extensions']\n+        except KeyError:\n+            return []\n+        else:\n+            return [str(ext) for ext in extensions]\n\n\n class StrictEnvironment(ExtensionLoaderMixin, Environment):\ndiff --git a/cookiecutter/exceptions.py b/cookiecutter/exceptions.py\nindex 8de08a2..622e7c6 100644\n--- a/cookiecutter/exceptions.py\n+++ b/cookiecutter/exceptions.py\n@@ -26,6 +26,8 @@ class UnknownTemplateDirException(CookiecutterException):\n     template, e.g. more than one dir appears to be a template dir.\n     \"\"\"\n\n+    # unused locally\n+\n\n class MissingProjectDir(CookiecutterException):\n     \"\"\"\n@@ -35,6 +37,8 @@ class MissingProjectDir(CookiecutterException):\n     directory inside of a repo.\n     \"\"\"\n\n+    # unused locally\n+\n\n class ConfigDoesNotExistException(CookiecutterException):\n     \"\"\"\n@@ -120,8 +124,10 @@ class UndefinedVariableInTemplate(CookiecutterException):\n     def __str__(self):\n         \"\"\"Text representation of UndefinedVariableInTemplate.\"\"\"\n         return (\n-            f'{self.message}. Error message: {self.error.message}. Context: {self.context}'\n-            )\n+            f\"{self.message}. \"\n+            f\"Error message: {self.error.message}. \"\n+            f\"Context: {self.context}\"\n+        )\n\n\n class UnknownExtension(CookiecutterException):\ndiff --git a/cookiecutter/extensions.py b/cookiecutter/extensions.py\nindex 8ce014a..666497c 100644\n--- a/cookiecutter/extensions.py\n+++ b/cookiecutter/extensions.py\n@@ -1,8 +1,10 @@\n \"\"\"Jinja2 extensions.\"\"\"\n+\n import json\n import string\n import uuid\n from secrets import choice\n+\n import arrow\n from jinja2 import nodes\n from jinja2.ext import Extension\n@@ -18,6 +20,7 @@ class JsonifyExtension(Extension):\n\n         def jsonify(obj):\n             return json.dumps(obj, sort_keys=True, indent=4)\n+\n         environment.filters['jsonify'] = jsonify\n\n\n@@ -30,10 +33,11 @@ class RandomStringExtension(Extension):\n\n         def random_ascii_string(length, punctuation=False):\n             if punctuation:\n-                corpus = ''.join((string.ascii_letters, string.punctuation))\n+                corpus = \"\".join((string.ascii_letters, string.punctuation))\n             else:\n                 corpus = string.ascii_letters\n-            return ''.join(choice(corpus) for _ in range(length))\n+            return \"\".join(choice(corpus) for _ in range(length))\n+\n         environment.globals.update(random_ascii_string=random_ascii_string)\n\n\n@@ -47,6 +51,7 @@ class SlugifyExtension(Extension):\n         def slugify(value, **kwargs):\n             \"\"\"Slugifies the value.\"\"\"\n             return pyslugify(value, **kwargs)\n+\n         environment.filters['slugify'] = slugify\n\n\n@@ -60,18 +65,67 @@ class UUIDExtension(Extension):\n         def uuid4():\n             \"\"\"Generate UUID4.\"\"\"\n             return str(uuid.uuid4())\n+\n         environment.globals.update(uuid4=uuid4)\n\n\n class TimeExtension(Extension):\n     \"\"\"Jinja2 Extension for dates and times.\"\"\"\n+\n     tags = {'now'}\n\n     def __init__(self, environment):\n         \"\"\"Jinja2 Extension constructor.\"\"\"\n         super().__init__(environment)\n+\n         environment.extend(datetime_format='%Y-%m-%d')\n\n+    def _datetime(self, timezone, operator, offset, datetime_format):\n+        d = arrow.now(timezone)\n+\n+        # parse shift params from offset and include operator\n+        shift_params = {}\n+        for param in offset.split(','):\n+            interval, value = param.split('=')\n+            shift_params[interval.strip()] = float(operator + value.strip())\n+        d = d.shift(**shift_params)\n+\n+        if datetime_format is None:\n+            datetime_format = self.environment.datetime_format\n+        return d.strftime(datetime_format)\n+\n+    def _now(self, timezone, datetime_format):\n+        if datetime_format is None:\n+            datetime_format = self.environment.datetime_format\n+        return arrow.now(timezone).strftime(datetime_format)\n+\n     def parse(self, parser):\n         \"\"\"Parse datetime template and add datetime value.\"\"\"\n-        pass\n+        lineno = next(parser.stream).lineno\n+\n+        node = parser.parse_expression()\n+\n+        if parser.stream.skip_if('comma'):\n+            datetime_format = parser.parse_expression()\n+        else:\n+            datetime_format = nodes.Const(None)\n+\n+        if isinstance(node, nodes.Add):\n+            call_method = self.call_method(\n+                '_datetime',\n+                [node.left, nodes.Const('+'), node.right, datetime_format],\n+                lineno=lineno,\n+            )\n+        elif isinstance(node, nodes.Sub):\n+            call_method = self.call_method(\n+                '_datetime',\n+                [node.left, nodes.Const('-'), node.right, datetime_format],\n+                lineno=lineno,\n+            )\n+        else:\n+            call_method = self.call_method(\n+                '_now',\n+                [node, datetime_format],\n+                lineno=lineno,\n+            )\n+        return nodes.Output([call_method], lineno=lineno)\ndiff --git a/cookiecutter/find.py b/cookiecutter/find.py\nindex 667e50d..486735f 100644\n--- a/cookiecutter/find.py\n+++ b/cookiecutter/find.py\n@@ -1,16 +1,34 @@\n \"\"\"Functions for finding Cookiecutter templates and other components.\"\"\"\n+\n import logging\n import os\n from pathlib import Path\n+\n from jinja2 import Environment\n+\n from cookiecutter.exceptions import NonTemplatedInputDirException\n+\n logger = logging.getLogger(__name__)\n\n\n-def find_template(repo_dir: 'os.PathLike[str]', env: Environment) -&gt;Path:\n+def find_template(repo_dir: \"os.PathLike[str]\", env: Environment) -&gt; Path:\n     \"\"\"Determine which child directory of ``repo_dir`` is the project template.\n\n     :param repo_dir: Local directory of newly cloned repo.\n     :return: Relative path to project template.\n     \"\"\"\n-    pass\n+    logger.debug('Searching %s for the project template.', repo_dir)\n+\n+    for str_path in os.listdir(repo_dir):\n+        if (\n+            'cookiecutter' in str_path\n+            and env.variable_start_string in str_path\n+            and env.variable_end_string in str_path\n+        ):\n+            project_template = Path(repo_dir, str_path)\n+            break\n+    else:\n+        raise NonTemplatedInputDirException\n+\n+    logger.debug('The project template appears to be %s', project_template)\n+    return project_template\ndiff --git a/cookiecutter/generate.py b/cookiecutter/generate.py\nindex 715232e..eb3b200 100644\n--- a/cookiecutter/generate.py\n+++ b/cookiecutter/generate.py\n@@ -1,4 +1,5 @@\n \"\"\"Functions for generating a project from a project template.\"\"\"\n+\n import fnmatch\n import json\n import logging\n@@ -7,13 +8,25 @@ import shutil\n import warnings\n from collections import OrderedDict\n from pathlib import Path\n+\n from binaryornot.check import is_binary\n from jinja2 import Environment, FileSystemLoader\n from jinja2.exceptions import TemplateSyntaxError, UndefinedError\n-from cookiecutter.exceptions import ContextDecodingException, OutputDirExistsException, UndefinedVariableInTemplate\n+\n+from cookiecutter.exceptions import (\n+    ContextDecodingException,\n+    OutputDirExistsException,\n+    UndefinedVariableInTemplate,\n+)\n from cookiecutter.find import find_template\n from cookiecutter.hooks import run_hook_from_repo_dir\n-from cookiecutter.utils import create_env_with_context, make_sure_path_exists, rmtree, work_in\n+from cookiecutter.utils import (\n+    create_env_with_context,\n+    make_sure_path_exists,\n+    rmtree,\n+    work_in,\n+)\n+\n logger = logging.getLogger(__name__)\n\n\n@@ -27,17 +40,70 @@ def is_copy_only_path(path, context):\n         should be rendered or just copied.\n     :param context: cookiecutter context.\n     \"\"\"\n-    pass\n+    try:\n+        for dont_render in context['cookiecutter']['_copy_without_render']:\n+            if fnmatch.fnmatch(path, dont_render):\n+                return True\n+    except KeyError:\n+        return False\n+\n+    return False\n\n\n-def apply_overwrites_to_context(context, overwrite_context, *,\n-    in_dictionary_variable=False):\n+def apply_overwrites_to_context(\n+    context, overwrite_context, *, in_dictionary_variable=False\n+):\n     \"\"\"Modify the given context in place based on the overwrite_context.\"\"\"\n-    pass\n+    for variable, overwrite in overwrite_context.items():\n+        if variable not in context:\n+            if not in_dictionary_variable:\n+                # We are dealing with a new variable on first level, ignore\n+                continue\n+            # We are dealing with a new dictionary variable in a deeper level\n+            context[variable] = overwrite\n+\n+        context_value = context[variable]\n+        if isinstance(context_value, list):\n+            if in_dictionary_variable:\n+                context[variable] = overwrite\n+                continue\n+            if isinstance(overwrite, list):\n+                # We are dealing with a multichoice variable\n+                # Let's confirm all choices are valid for the given context\n+                if set(overwrite).issubset(set(context_value)):\n+                    context[variable] = overwrite\n+                else:\n+                    raise ValueError(\n+                        f\"{overwrite} provided for multi-choice variable \"\n+                        f\"{variable}, but valid choices are {context_value}\"\n+                    )\n+            else:\n+                # We are dealing with a choice variable\n+                if overwrite in context_value:\n+                    # This overwrite is actually valid for the given context\n+                    # Let's set it as default (by definition first item in list)\n+                    # see ``cookiecutter.prompt.prompt_choice_for_config``\n+                    context_value.remove(overwrite)\n+                    context_value.insert(0, overwrite)\n+                else:\n+                    raise ValueError(\n+                        f\"{overwrite} provided for choice variable \"\n+                        f\"{variable}, but the choices are {context_value}.\"\n+                    )\n+        elif isinstance(context_value, dict) and isinstance(overwrite, dict):\n+            # Partially overwrite some keys in original dict\n+            apply_overwrites_to_context(\n+                context_value, overwrite, in_dictionary_variable=True\n+            )\n+            context[variable] = context_value\n+        else:\n+            # Simply overwrite the value for this variable\n+            context[variable] = overwrite\n\n\n-def generate_context(context_file='cookiecutter.json', default_context=None,\n-    extra_context=None):\n+def generate_context(\n+    context_file='cookiecutter.json', default_context=None, extra_context=None\n+):\n     \"\"\"Generate the context for a Cookiecutter project template.\n\n     Loads the JSON file as a Python object, with key being the JSON filename.\n@@ -47,11 +113,42 @@ def generate_context(context_file='cookiecutter.json', default_context=None,\n     :param default_context: Dictionary containing config to take into account.\n     :param extra_context: Dictionary containing configuration overrides\n     \"\"\"\n-    pass\n+    context = OrderedDict([])\n\n+    try:\n+        with open(context_file, encoding='utf-8') as file_handle:\n+            obj = json.load(file_handle, object_pairs_hook=OrderedDict)\n+    except ValueError as e:\n+        # JSON decoding error.  Let's throw a new exception that is more\n+        # friendly for the developer or user.\n+        full_fpath = os.path.abspath(context_file)\n+        json_exc_message = str(e)\n+        our_exc_message = (\n+            f\"JSON decoding error while loading '{full_fpath}'. \"\n+            f\"Decoding error details: '{json_exc_message}'\"\n+        )\n+        raise ContextDecodingException(our_exc_message) from e\n\n-def generate_file(project_dir, infile, context, env, skip_if_file_exists=False\n-    ):\n+    # Add the Python object to the context dictionary\n+    file_name = os.path.split(context_file)[1]\n+    file_stem = file_name.split('.')[0]\n+    context[file_stem] = obj\n+\n+    # Overwrite context variable defaults with the default context from the\n+    # user's global config, if available\n+    if default_context:\n+        try:\n+            apply_overwrites_to_context(obj, default_context)\n+        except ValueError as error:\n+            warnings.warn(f\"Invalid default received: {error}\")\n+    if extra_context:\n+        apply_overwrites_to_context(obj, extra_context)\n+\n+    logger.debug('Context generated is %s', context)\n+    return context\n+\n+\n+def generate_file(project_dir, infile, context, env, skip_if_file_exists=False):\n     \"\"\"Render filename of infile as name of outfile, handle infile correctly.\n\n     Dealing with infile appropriately:\n@@ -72,18 +169,103 @@ def generate_file(project_dir, infile, context, env, skip_if_file_exists=False\n     :param context: Dict for populating the cookiecutter's variables.\n     :param env: Jinja2 template execution environment.\n     \"\"\"\n-    pass\n+    logger.debug('Processing file %s', infile)\n+\n+    # Render the path to the output file (not including the root project dir)\n+    outfile_tmpl = env.from_string(infile)\n+\n+    outfile = os.path.join(project_dir, outfile_tmpl.render(**context))\n+    file_name_is_empty = os.path.isdir(outfile)\n+    if file_name_is_empty:\n+        logger.debug('The resulting file name is empty: %s', outfile)\n+        return\n+\n+    if skip_if_file_exists and os.path.exists(outfile):\n+        logger.debug('The resulting file already exists: %s', outfile)\n+        return\n+\n+    logger.debug('Created file at %s', outfile)\n+\n+    # Just copy over binary files. Don't render.\n+    logger.debug(\"Check %s to see if it's a binary\", infile)\n+    if is_binary(infile):\n+        logger.debug('Copying binary %s to %s without rendering', infile, outfile)\n+        shutil.copyfile(infile, outfile)\n+        shutil.copymode(infile, outfile)\n+        return\n+\n+    # Force fwd slashes on Windows for get_template\n+    # This is a by-design Jinja issue\n+    infile_fwd_slashes = infile.replace(os.path.sep, '/')\n+\n+    # Render the file\n+    try:\n+        tmpl = env.get_template(infile_fwd_slashes)\n+    except TemplateSyntaxError as exception:\n+        # Disable translated so that printed exception contains verbose\n+        # information about syntax error location\n+        exception.translated = False\n+        raise\n+    rendered_file = tmpl.render(**context)\n+\n+    if context['cookiecutter'].get('_new_lines', False):\n+        # Use `_new_lines` from context, if configured.\n+        newline = context['cookiecutter']['_new_lines']\n+        logger.debug('Using configured newline character %s', repr(newline))\n+    else:\n+        # Detect original file newline to output the rendered file.\n+        # Note that newlines can be a tuple if file contains mixed line endings.\n+        # In this case, we pick the first line ending we detected.\n+        with open(infile, encoding='utf-8') as rd:\n+            rd.readline()  # Read only the first line to load a 'newlines' value.\n+        newline = rd.newlines[0] if isinstance(rd.newlines, tuple) else rd.newlines\n+        logger.debug('Using detected newline character %s', repr(newline))\n+\n+    logger.debug('Writing contents to file %s', outfile)\n+\n+    with open(outfile, 'w', encoding='utf-8', newline=newline) as fh:\n+        fh.write(rendered_file)\n+\n+    # Apply file permissions to output file\n+    shutil.copymode(infile, outfile)\n\n\n-def render_and_create_dir(dirname: str, context: dict, output_dir:\n-    'os.PathLike[str]', environment: Environment, overwrite_if_exists: bool\n-    =False):\n+def render_and_create_dir(\n+    dirname: str,\n+    context: dict,\n+    output_dir: \"os.PathLike[str]\",\n+    environment: Environment,\n+    overwrite_if_exists: bool = False,\n+):\n     \"\"\"Render name of a directory, create the directory, return its path.\"\"\"\n-    pass\n+    name_tmpl = environment.from_string(dirname)\n+    rendered_dirname = name_tmpl.render(**context)\n\n+    dir_to_create = Path(output_dir, rendered_dirname)\n\n-def _run_hook_from_repo_dir(repo_dir, hook_name, project_dir, context,\n-    delete_project_on_failure):\n+    logger.debug(\n+        'Rendered dir %s must exist in output_dir %s', dir_to_create, output_dir\n+    )\n+\n+    output_dir_exists = dir_to_create.exists()\n+\n+    if output_dir_exists:\n+        if overwrite_if_exists:\n+            logger.debug(\n+                'Output directory %s already exists, overwriting it', dir_to_create\n+            )\n+        else:\n+            msg = f'Error: \"{dir_to_create}\" directory already exists'\n+            raise OutputDirExistsException(msg)\n+    else:\n+        make_sure_path_exists(dir_to_create)\n+\n+    return dir_to_create, not output_dir_exists\n+\n+\n+def _run_hook_from_repo_dir(\n+    repo_dir, hook_name, project_dir, context, delete_project_on_failure\n+):\n     \"\"\"Run hook from repo directory, clean project directory if hook fails.\n\n     :param repo_dir: Project template input directory.\n@@ -93,12 +275,26 @@ def _run_hook_from_repo_dir(repo_dir, hook_name, project_dir, context,\n     :param delete_project_on_failure: Delete the project directory on hook\n         failure?\n     \"\"\"\n-    pass\n+    warnings.warn(\n+        \"The '_run_hook_from_repo_dir' function is deprecated, \"\n+        \"use 'cookiecutter.hooks.run_hook_from_repo_dir' instead\",\n+        DeprecationWarning,\n+        2,\n+    )\n+    run_hook_from_repo_dir(\n+        repo_dir, hook_name, project_dir, context, delete_project_on_failure\n+    )\n\n\n-def generate_files(repo_dir, context=None, output_dir='.',\n-    overwrite_if_exists=False, skip_if_file_exists=False, accept_hooks=True,\n-    keep_project_on_failure=False):\n+def generate_files(\n+    repo_dir,\n+    context=None,\n+    output_dir='.',\n+    overwrite_if_exists=False,\n+    skip_if_file_exists=False,\n+    accept_hooks=True,\n+    keep_project_on_failure=False,\n+):\n     \"\"\"Render the templates and saves them to files.\n\n     :param repo_dir: Project template input directory.\n@@ -112,4 +308,120 @@ def generate_files(repo_dir, context=None, output_dir='.',\n     :param keep_project_on_failure: If `True` keep generated project directory even when\n         generation fails\n     \"\"\"\n-    pass\n+    context = context or OrderedDict([])\n+\n+    env = create_env_with_context(context)\n+\n+    template_dir = find_template(repo_dir, env)\n+    logger.debug('Generating project from %s...', template_dir)\n+\n+    unrendered_dir = os.path.split(template_dir)[1]\n+    try:\n+        project_dir, output_directory_created = render_and_create_dir(\n+            unrendered_dir, context, output_dir, env, overwrite_if_exists\n+        )\n+    except UndefinedError as err:\n+        msg = f\"Unable to create project directory '{unrendered_dir}'\"\n+        raise UndefinedVariableInTemplate(msg, err, context) from err\n+\n+    # We want the Jinja path and the OS paths to match. Consequently, we'll:\n+    #   + CD to the template folder\n+    #   + Set Jinja's path to '.'\n+    #\n+    #  In order to build our files to the correct folder(s), we'll use an\n+    # absolute path for the target folder (project_dir)\n+\n+    project_dir = os.path.abspath(project_dir)\n+    logger.debug('Project directory is %s', project_dir)\n+\n+    # if we created the output directory, then it's ok to remove it\n+    # if rendering fails\n+    delete_project_on_failure = output_directory_created and not keep_project_on_failure\n+\n+    if accept_hooks:\n+        run_hook_from_repo_dir(\n+            repo_dir, 'pre_gen_project', project_dir, context, delete_project_on_failure\n+        )\n+\n+    with work_in(template_dir):\n+        env.loader = FileSystemLoader(['.', '../templates'])\n+\n+        for root, dirs, files in os.walk('.'):\n+            # We must separate the two types of dirs into different lists.\n+            # The reason is that we don't want ``os.walk`` to go through the\n+            # unrendered directories, since they will just be copied.\n+            copy_dirs = []\n+            render_dirs = []\n+\n+            for d in dirs:\n+                d_ = os.path.normpath(os.path.join(root, d))\n+                # We check the full path, because that's how it can be\n+                # specified in the ``_copy_without_render`` setting, but\n+                # we store just the dir name\n+                if is_copy_only_path(d_, context):\n+                    logger.debug('Found copy only path %s', d)\n+                    copy_dirs.append(d)\n+                else:\n+                    render_dirs.append(d)\n+\n+            for copy_dir in copy_dirs:\n+                indir = os.path.normpath(os.path.join(root, copy_dir))\n+                outdir = os.path.normpath(os.path.join(project_dir, indir))\n+                outdir = env.from_string(outdir).render(**context)\n+                logger.debug('Copying dir %s to %s without rendering', indir, outdir)\n+\n+                # The outdir is not the root dir, it is the dir which marked as copy\n+                # only in the config file. If the program hits this line, which means\n+                # the overwrite_if_exists = True, and root dir exists\n+                if os.path.isdir(outdir):\n+                    shutil.rmtree(outdir)\n+                shutil.copytree(indir, outdir)\n+\n+            # We mutate ``dirs``, because we only want to go through these dirs\n+            # recursively\n+            dirs[:] = render_dirs\n+            for d in dirs:\n+                unrendered_dir = os.path.join(project_dir, root, d)\n+                try:\n+                    render_and_create_dir(\n+                        unrendered_dir, context, output_dir, env, overwrite_if_exists\n+                    )\n+                except UndefinedError as err:\n+                    if delete_project_on_failure:\n+                        rmtree(project_dir)\n+                    _dir = os.path.relpath(unrendered_dir, output_dir)\n+                    msg = f\"Unable to create directory '{_dir}'\"\n+                    raise UndefinedVariableInTemplate(msg, err, context) from err\n+\n+            for f in files:\n+                infile = os.path.normpath(os.path.join(root, f))\n+                if is_copy_only_path(infile, context):\n+                    outfile_tmpl = env.from_string(infile)\n+                    outfile_rendered = outfile_tmpl.render(**context)\n+                    outfile = os.path.join(project_dir, outfile_rendered)\n+                    logger.debug(\n+                        'Copying file %s to %s without rendering', infile, outfile\n+                    )\n+                    shutil.copyfile(infile, outfile)\n+                    shutil.copymode(infile, outfile)\n+                    continue\n+                try:\n+                    generate_file(\n+                        project_dir, infile, context, env, skip_if_file_exists\n+                    )\n+                except UndefinedError as err:\n+                    if delete_project_on_failure:\n+                        rmtree(project_dir)\n+                    msg = f\"Unable to create file '{infile}'\"\n+                    raise UndefinedVariableInTemplate(msg, err, context) from err\n+\n+    if accept_hooks:\n+        run_hook_from_repo_dir(\n+            repo_dir,\n+            'post_gen_project',\n+            project_dir,\n+            context,\n+            delete_project_on_failure,\n+        )\n+\n+    return project_dir\ndiff --git a/cookiecutter/hooks.py b/cookiecutter/hooks.py\nindex 0aa9c52..16b0647 100644\n--- a/cookiecutter/hooks.py\n+++ b/cookiecutter/hooks.py\n@@ -1,17 +1,31 @@\n \"\"\"Functions for discovering and executing various cookiecutter hooks.\"\"\"\n+\n import errno\n import logging\n import os\n-import subprocess\n+import subprocess  # nosec\n import sys\n import tempfile\n from pathlib import Path\n+\n from jinja2.exceptions import UndefinedError\n+\n from cookiecutter import utils\n from cookiecutter.exceptions import FailedHookException\n-from cookiecutter.utils import create_env_with_context, create_tmp_repo_dir, rmtree, work_in\n+from cookiecutter.utils import (\n+    create_env_with_context,\n+    create_tmp_repo_dir,\n+    rmtree,\n+    work_in,\n+)\n+\n logger = logging.getLogger(__name__)\n-_HOOKS = ['pre_prompt', 'pre_gen_project', 'post_gen_project']\n+\n+_HOOKS = [\n+    'pre_prompt',\n+    'pre_gen_project',\n+    'post_gen_project',\n+]\n EXIT_SUCCESS = 0\n\n\n@@ -22,7 +36,13 @@ def valid_hook(hook_file, hook_name):\n     :param hook_name: The hook to find\n     :return: The hook file validity\n     \"\"\"\n-    pass\n+    filename = os.path.basename(hook_file)\n+    basename = os.path.splitext(filename)[0]\n+    matching_hook = basename == hook_name\n+    supported_hook = basename in _HOOKS\n+    backup_file = filename.endswith('~')\n+\n+    return matching_hook and supported_hook and not backup_file\n\n\n def find_hook(hook_name, hooks_dir='hooks'):\n@@ -37,7 +57,20 @@ def find_hook(hook_name, hooks_dir='hooks'):\n     :param hooks_dir: The hook directory in the template\n     :return: The absolute path to the hook script or None\n     \"\"\"\n-    pass\n+    logger.debug('hooks_dir is %s', os.path.abspath(hooks_dir))\n+\n+    if not os.path.isdir(hooks_dir):\n+        logger.debug('No hooks/dir in template_dir')\n+        return None\n+\n+    scripts = []\n+    for hook_file in os.listdir(hooks_dir):\n+        if valid_hook(hook_file, hook_name):\n+            scripts.append(os.path.abspath(os.path.join(hooks_dir, hook_file)))\n+\n+    if len(scripts) == 0:\n+        return None\n+    return scripts\n\n\n def run_script(script_path, cwd='.'):\n@@ -46,7 +79,27 @@ def run_script(script_path, cwd='.'):\n     :param script_path: Absolute path to the script to run.\n     :param cwd: The directory to run the script from.\n     \"\"\"\n-    pass\n+    run_thru_shell = sys.platform.startswith('win')\n+    if script_path.endswith('.py'):\n+        script_command = [sys.executable, script_path]\n+    else:\n+        script_command = [script_path]\n+\n+    utils.make_executable(script_path)\n+\n+    try:\n+        proc = subprocess.Popen(script_command, shell=run_thru_shell, cwd=cwd)  # nosec\n+        exit_status = proc.wait()\n+        if exit_status != EXIT_SUCCESS:\n+            raise FailedHookException(\n+                f'Hook script failed (exit status: {exit_status})'\n+            )\n+    except OSError as err:\n+        if err.errno == errno.ENOEXEC:\n+            raise FailedHookException(\n+                'Hook script failed, might be an empty file or missing a shebang'\n+            ) from err\n+        raise FailedHookException(f'Hook script failed (error: {err})') from err\n\n\n def run_script_with_context(script_path, cwd, context):\n@@ -56,7 +109,18 @@ def run_script_with_context(script_path, cwd, context):\n     :param cwd: The directory to run the script from.\n     :param context: Cookiecutter project template context.\n     \"\"\"\n-    pass\n+    _, extension = os.path.splitext(script_path)\n+\n+    with open(script_path, encoding='utf-8') as file:\n+        contents = file.read()\n+\n+    with tempfile.NamedTemporaryFile(delete=False, mode='wb', suffix=extension) as temp:\n+        env = create_env_with_context(context)\n+        template = env.from_string(contents)\n+        output = template.render(**context)\n+        temp.write(output.encode('utf-8'))\n+\n+    run_script(temp.name, cwd)\n\n\n def run_hook(hook_name, project_dir, context):\n@@ -67,11 +131,18 @@ def run_hook(hook_name, project_dir, context):\n     :param project_dir: The directory to execute the script from.\n     :param context: Cookiecutter project context.\n     \"\"\"\n-    pass\n-\n-\n-def run_hook_from_repo_dir(repo_dir, hook_name, project_dir, context,\n-    delete_project_on_failure):\n+    scripts = find_hook(hook_name)\n+    if not scripts:\n+        logger.debug('No %s hook found', hook_name)\n+        return\n+    logger.debug('Running hook %s', hook_name)\n+    for script in scripts:\n+        run_script_with_context(script, project_dir, context)\n+\n+\n+def run_hook_from_repo_dir(\n+    repo_dir, hook_name, project_dir, context, delete_project_on_failure\n+):\n     \"\"\"Run hook from repo directory, clean project directory if hook fails.\n\n     :param repo_dir: Project template input directory.\n@@ -81,12 +152,41 @@ def run_hook_from_repo_dir(repo_dir, hook_name, project_dir, context,\n     :param delete_project_on_failure: Delete the project directory on hook\n         failure?\n     \"\"\"\n-    pass\n-\n-\n-def run_pre_prompt_hook(repo_dir: 'os.PathLike[str]') -&gt;Path:\n+    with work_in(repo_dir):\n+        try:\n+            run_hook(hook_name, project_dir, context)\n+        except (\n+            FailedHookException,\n+            UndefinedError,\n+        ):\n+            if delete_project_on_failure:\n+                rmtree(project_dir)\n+            logger.error(\n+                \"Stopping generation because %s hook \"\n+                \"script didn't exit successfully\",\n+                hook_name,\n+            )\n+            raise\n+\n+\n+def run_pre_prompt_hook(repo_dir: \"os.PathLike[str]\") -&gt; Path:\n     \"\"\"Run pre_prompt hook from repo directory.\n\n     :param repo_dir: Project template input directory.\n     \"\"\"\n-    pass\n+    # Check if we have a valid pre_prompt script\n+    with work_in(repo_dir):\n+        scripts = find_hook('pre_prompt')\n+        if not scripts:\n+            return repo_dir\n+\n+    # Create a temporary directory\n+    repo_dir = create_tmp_repo_dir(repo_dir)\n+    with work_in(repo_dir):\n+        scripts = find_hook('pre_prompt')\n+        for script in scripts:\n+            try:\n+                run_script(script, repo_dir)\n+            except FailedHookException:\n+                raise FailedHookException('Pre-Prompt Hook script failed')\n+    return repo_dir\ndiff --git a/cookiecutter/log.py b/cookiecutter/log.py\nindex 894c633..c2ac283 100644\n--- a/cookiecutter/log.py\n+++ b/cookiecutter/log.py\n@@ -1,10 +1,20 @@\n \"\"\"Module for setting up logging.\"\"\"\n+\n import logging\n import sys\n-LOG_LEVELS = {'DEBUG': logging.DEBUG, 'INFO': logging.INFO, 'WARNING':\n-    logging.WARNING, 'ERROR': logging.ERROR, 'CRITICAL': logging.CRITICAL}\n-LOG_FORMATS = {'DEBUG': '%(levelname)s %(name)s: %(message)s', 'INFO':\n-    '%(levelname)s: %(message)s'}\n+\n+LOG_LEVELS = {\n+    'DEBUG': logging.DEBUG,\n+    'INFO': logging.INFO,\n+    'WARNING': logging.WARNING,\n+    'ERROR': logging.ERROR,\n+    'CRITICAL': logging.CRITICAL,\n+}\n+\n+LOG_FORMATS = {\n+    'DEBUG': '%(levelname)s %(name)s: %(message)s',\n+    'INFO': '%(levelname)s: %(message)s',\n+}\n\n\n def configure_logger(stream_level='DEBUG', debug_file=None):\n@@ -13,4 +23,30 @@ def configure_logger(stream_level='DEBUG', debug_file=None):\n     Set up logging to stdout with given level. If ``debug_file`` is given set\n     up logging to file with DEBUG level.\n     \"\"\"\n-    pass\n+    # Set up 'cookiecutter' logger\n+    logger = logging.getLogger('cookiecutter')\n+    logger.setLevel(logging.DEBUG)\n+\n+    # Remove all attached handlers, in case there was\n+    # a logger with using the name 'cookiecutter'\n+    del logger.handlers[:]\n+\n+    # Create a file handler if a log file is provided\n+    if debug_file is not None:\n+        debug_formatter = logging.Formatter(LOG_FORMATS['DEBUG'])\n+        file_handler = logging.FileHandler(debug_file)\n+        file_handler.setLevel(LOG_LEVELS['DEBUG'])\n+        file_handler.setFormatter(debug_formatter)\n+        logger.addHandler(file_handler)\n+\n+    # Get settings based on the given stream_level\n+    log_formatter = logging.Formatter(LOG_FORMATS[stream_level])\n+    log_level = LOG_LEVELS[stream_level]\n+\n+    # Create a stream handler\n+    stream_handler = logging.StreamHandler(stream=sys.stdout)\n+    stream_handler.setLevel(log_level)\n+    stream_handler.setFormatter(log_formatter)\n+    logger.addHandler(stream_handler)\n+\n+    return logger\ndiff --git a/cookiecutter/main.py b/cookiecutter/main.py\nindex 4b1087d..2146c1b 100644\n--- a/cookiecutter/main.py\n+++ b/cookiecutter/main.py\n@@ -4,11 +4,13 @@ Main entry point for the `cookiecutter` command.\n The code in this module is also a good example of how to use Cookiecutter as a\n library rather than a script.\n \"\"\"\n+\n import logging\n import os\n import sys\n from copy import copy\n from pathlib import Path\n+\n from cookiecutter.config import get_user_config\n from cookiecutter.exceptions import InvalidModeException\n from cookiecutter.generate import generate_context, generate_files\n@@ -17,14 +19,26 @@ from cookiecutter.prompt import choose_nested_template, prompt_for_config\n from cookiecutter.replay import dump, load\n from cookiecutter.repository import determine_repo_dir\n from cookiecutter.utils import rmtree\n+\n logger = logging.getLogger(__name__)\n\n\n-def cookiecutter(template, checkout=None, no_input=False, extra_context=\n-    None, replay=None, overwrite_if_exists=False, output_dir='.',\n-    config_file=None, default_config=False, password=None, directory=None,\n-    skip_if_file_exists=False, accept_hooks=True, keep_project_on_failure=False\n-    ):\n+def cookiecutter(\n+    template,\n+    checkout=None,\n+    no_input=False,\n+    extra_context=None,\n+    replay=None,\n+    overwrite_if_exists=False,\n+    output_dir='.',\n+    config_file=None,\n+    default_config=False,\n+    password=None,\n+    directory=None,\n+    skip_if_file_exists=False,\n+    accept_hooks=True,\n+    keep_project_on_failure=False,\n+):\n     \"\"\"\n     Run Cookiecutter just as if using it from the command line.\n\n@@ -52,14 +66,140 @@ def cookiecutter(template, checkout=None, no_input=False, extra_context=\n     :param keep_project_on_failure: If `True` keep generated project directory even when\n         generation fails\n     \"\"\"\n-    pass\n+    if replay and ((no_input is not False) or (extra_context is not None)):\n+        err_msg = (\n+            \"You can not use both replay and no_input or extra_context \"\n+            \"at the same time.\"\n+        )\n+        raise InvalidModeException(err_msg)\n\n+    config_dict = get_user_config(\n+        config_file=config_file,\n+        default_config=default_config,\n+    )\n+    base_repo_dir, cleanup_base_repo_dir = determine_repo_dir(\n+        template=template,\n+        abbreviations=config_dict['abbreviations'],\n+        clone_to_dir=config_dict['cookiecutters_dir'],\n+        checkout=checkout,\n+        no_input=no_input,\n+        password=password,\n+        directory=directory,\n+    )\n+    repo_dir, cleanup = base_repo_dir, cleanup_base_repo_dir\n+    # Run pre_prompt hook\n+    repo_dir = run_pre_prompt_hook(base_repo_dir) if accept_hooks else repo_dir\n+    # Always remove temporary dir if it was created\n+    cleanup = True if repo_dir != base_repo_dir else False\n\n-class _patch_import_path_for_repo:\n+    import_patch = _patch_import_path_for_repo(repo_dir)\n+    template_name = os.path.basename(os.path.abspath(repo_dir))\n+    if replay:\n+        with import_patch:\n+            if isinstance(replay, bool):\n+                context_from_replayfile = load(config_dict['replay_dir'], template_name)\n+            else:\n+                path, template_name = os.path.split(os.path.splitext(replay)[0])\n+                context_from_replayfile = load(path, template_name)\n+\n+    context_file = os.path.join(repo_dir, 'cookiecutter.json')\n+    logger.debug('context_file is %s', context_file)\n+\n+    if replay:\n+        context = generate_context(\n+            context_file=context_file,\n+            default_context=config_dict['default_context'],\n+            extra_context=None,\n+        )\n+        logger.debug('replayfile context: %s', context_from_replayfile)\n+        items_for_prompting = {\n+            k: v\n+            for k, v in context['cookiecutter'].items()\n+            if k not in context_from_replayfile['cookiecutter'].keys()\n+        }\n+        context_for_prompting = {}\n+        context_for_prompting['cookiecutter'] = items_for_prompting\n+        context = context_from_replayfile\n+        logger.debug('prompting context: %s', context_for_prompting)\n+    else:\n+        context = generate_context(\n+            context_file=context_file,\n+            default_context=config_dict['default_context'],\n+            extra_context=extra_context,\n+        )\n+        context_for_prompting = context\n+    # preserve the original cookiecutter options\n+    # print(context['cookiecutter'])\n+    context['_cookiecutter'] = {\n+        k: v for k, v in context['cookiecutter'].items() if not k.startswith(\"_\")\n+    }\n+\n+    # prompt the user to manually configure at the command line.\n+    # except when 'no-input' flag is set\n+\n+    with import_patch:\n+        if {\"template\", \"templates\"} &amp; set(context[\"cookiecutter\"].keys()):\n+            nested_template = choose_nested_template(context, repo_dir, no_input)\n+            return cookiecutter(\n+                template=nested_template,\n+                checkout=checkout,\n+                no_input=no_input,\n+                extra_context=extra_context,\n+                replay=replay,\n+                overwrite_if_exists=overwrite_if_exists,\n+                output_dir=output_dir,\n+                config_file=config_file,\n+                default_config=default_config,\n+                password=password,\n+                directory=directory,\n+                skip_if_file_exists=skip_if_file_exists,\n+                accept_hooks=accept_hooks,\n+                keep_project_on_failure=keep_project_on_failure,\n+            )\n+        if context_for_prompting['cookiecutter']:\n+            context['cookiecutter'].update(\n+                prompt_for_config(context_for_prompting, no_input)\n+            )\n+\n+    logger.debug('context is %s', context)\n\n-    def __init__(self, repo_dir: 'os.PathLike[str]'):\n-        self._repo_dir = f'{repo_dir}' if isinstance(repo_dir, Path\n-            ) else repo_dir\n+    # include template dir or url in the context dict\n+    context['cookiecutter']['_template'] = template\n+\n+    # include output+dir in the context dict\n+    context['cookiecutter']['_output_dir'] = os.path.abspath(output_dir)\n+\n+    # include repo dir or url in the context dict\n+    context['cookiecutter']['_repo_dir'] = f\"{repo_dir}\"\n+\n+    # include checkout details in the context dict\n+    context['cookiecutter']['_checkout'] = checkout\n+\n+    dump(config_dict['replay_dir'], template_name, context)\n+\n+    # Create project from local context and project template.\n+    with import_patch:\n+        result = generate_files(\n+            repo_dir=repo_dir,\n+            context=context,\n+            overwrite_if_exists=overwrite_if_exists,\n+            skip_if_file_exists=skip_if_file_exists,\n+            output_dir=output_dir,\n+            accept_hooks=accept_hooks,\n+            keep_project_on_failure=keep_project_on_failure,\n+        )\n+\n+    # Cleanup (if required)\n+    if cleanup:\n+        rmtree(repo_dir)\n+    if cleanup_base_repo_dir:\n+        rmtree(base_repo_dir)\n+    return result\n+\n+\n+class _patch_import_path_for_repo:\n+    def __init__(self, repo_dir: \"os.PathLike[str]\"):\n+        self._repo_dir = f\"{repo_dir}\" if isinstance(repo_dir, Path) else repo_dir\n         self._path = None\n\n     def __enter__(self):\ndiff --git a/cookiecutter/prompt.py b/cookiecutter/prompt.py\nindex 2bcc55f..761ac99 100644\n--- a/cookiecutter/prompt.py\n+++ b/cookiecutter/prompt.py\n@@ -1,36 +1,57 @@\n \"\"\"Functions for prompting the user for project info.\"\"\"\n+\n import json\n import os\n import re\n import sys\n from collections import OrderedDict\n from pathlib import Path\n+\n from jinja2.exceptions import UndefinedError\n from rich.prompt import Confirm, InvalidResponse, Prompt, PromptBase\n+\n from cookiecutter.exceptions import UndefinedVariableInTemplate\n from cookiecutter.utils import create_env_with_context, rmtree\n\n\n-def read_user_variable(var_name, default_value, prompts=None, prefix=''):\n+def read_user_variable(var_name, default_value, prompts=None, prefix=\"\"):\n     \"\"\"Prompt user for variable and return the entered value or given default.\n\n     :param str var_name: Variable of the context to query the user\n     :param default_value: Value that will be returned if no input happens\n     \"\"\"\n-    pass\n+    question = (\n+        prompts[var_name]\n+        if prompts and var_name in prompts.keys() and prompts[var_name]\n+        else var_name\n+    )\n+\n+    while True:\n+        variable = Prompt.ask(f\"{prefix}{question}\", default=default_value)\n+        if variable is not None:\n+            break\n+\n+    return variable\n\n\n class YesNoPrompt(Confirm):\n     \"\"\"A prompt that returns a boolean for yes/no questions.\"\"\"\n-    yes_choices = ['1', 'true', 't', 'yes', 'y', 'on']\n-    no_choices = ['0', 'false', 'f', 'no', 'n', 'off']\n\n-    def process_response(self, value: str) -&gt;bool:\n+    yes_choices = [\"1\", \"true\", \"t\", \"yes\", \"y\", \"on\"]\n+    no_choices = [\"0\", \"false\", \"f\", \"no\", \"n\", \"off\"]\n+\n+    def process_response(self, value: str) -&gt; bool:\n         \"\"\"Convert choices to a bool.\"\"\"\n-        pass\n+        value = value.strip().lower()\n+        if value in self.yes_choices:\n+            return True\n+        elif value in self.no_choices:\n+            return False\n+        else:\n+            raise InvalidResponse(self.validate_error_message)\n\n\n-def read_user_yes_no(var_name, default_value, prompts=None, prefix=''):\n+def read_user_yes_no(var_name, default_value, prompts=None, prefix=\"\"):\n     \"\"\"Prompt the user to reply with 'yes' or 'no' (or equivalent values).\n\n     - These input values will be converted to ``True``:\n@@ -44,7 +65,12 @@ def read_user_yes_no(var_name, default_value, prompts=None, prefix=''):\n     :param str question: Question to the user\n     :param default_value: Value that will be returned if no input happens\n     \"\"\"\n-    pass\n+    question = (\n+        prompts[var_name]\n+        if prompts and var_name in prompts.keys() and prompts[var_name]\n+        else var_name\n+    )\n+    return YesNoPrompt.ask(f\"{prefix}{question}\", default=default_value)\n\n\n def read_repo_password(question):\n@@ -52,10 +78,10 @@ def read_repo_password(question):\n\n     :param str question: Question to the user\n     \"\"\"\n-    pass\n+    return Prompt.ask(question, password=True)\n\n\n-def read_user_choice(var_name, options, prompts=None, prefix=''):\n+def read_user_choice(var_name, options, prompts=None, prefix=\"\"):\n     \"\"\"Prompt the user to choose from several options for the given variable.\n\n     The first item will be returned if no input happens.\n@@ -64,7 +90,46 @@ def read_user_choice(var_name, options, prompts=None, prefix=''):\n     :param list options: Sequence of options that are available to select from\n     :return: Exactly one item of ``options`` that has been chosen by the user\n     \"\"\"\n-    pass\n+    if not isinstance(options, list):\n+        raise TypeError\n+\n+    if not options:\n+        raise ValueError\n+\n+    choice_map = OrderedDict((f'{i}', value) for i, value in enumerate(options, 1))\n+    choices = choice_map.keys()\n+\n+    question = f\"Select {var_name}\"\n+    choice_lines = [\n+        '    [bold magenta]{}[/] - [bold]{}[/]'.format(*c) for c in choice_map.items()\n+    ]\n+\n+    # Handle if human-readable prompt is provided\n+    if prompts and var_name in prompts.keys():\n+        if isinstance(prompts[var_name], str):\n+            question = prompts[var_name]\n+        else:\n+            if \"__prompt__\" in prompts[var_name]:\n+                question = prompts[var_name][\"__prompt__\"]\n+            choice_lines = [\n+                (\n+                    f\"    [bold magenta]{i}[/] - [bold]{prompts[var_name][p]}[/]\"\n+                    if p in prompts[var_name]\n+                    else f\"    [bold magenta]{i}[/] - [bold]{p}[/]\"\n+                )\n+                for i, p in choice_map.items()\n+            ]\n+\n+    prompt = '\\n'.join(\n+        (\n+            f\"{prefix}{question}\",\n+            \"\\n\".join(choice_lines),\n+            \"    Choose from\",\n+        )\n+    )\n+\n+    user_choice = Prompt.ask(prompt, choices=list(choices), default=list(choices)[0])\n+    return choice_map[user_choice]\n\n\n DEFAULT_DISPLAY = 'default'\n@@ -75,29 +140,52 @@ def process_json(user_value, default_value=None):\n\n     :param str user_value: User-supplied value to load as a JSON dict\n     \"\"\"\n-    pass\n+    try:\n+        user_dict = json.loads(user_value, object_pairs_hook=OrderedDict)\n+    except Exception as error:\n+        # Leave it up to click to ask the user again\n+        raise InvalidResponse('Unable to decode to JSON.') from error\n+\n+    if not isinstance(user_dict, dict):\n+        # Leave it up to click to ask the user again\n+        raise InvalidResponse('Requires JSON dict.')\n+\n+    return user_dict\n\n\n class JsonPrompt(PromptBase[dict]):\n     \"\"\"A prompt that returns a dict from JSON string.\"\"\"\n+\n     default = None\n     response_type = dict\n-    validate_error_message = (\n-        '[prompt.invalid]  Please enter a valid JSON string')\n+    validate_error_message = \"[prompt.invalid]  Please enter a valid JSON string\"\n\n-    def process_response(self, value: str) -&gt;dict:\n+    def process_response(self, value: str) -&gt; dict:\n         \"\"\"Convert choices to a dict.\"\"\"\n-        pass\n+        return process_json(value, self.default)\n\n\n-def read_user_dict(var_name, default_value, prompts=None, prefix=''):\n+def read_user_dict(var_name, default_value, prompts=None, prefix=\"\"):\n     \"\"\"Prompt the user to provide a dictionary of data.\n\n     :param str var_name: Variable as specified in the context\n     :param default_value: Value that will be returned if no input is provided\n     :return: A Python dictionary to use in the context.\n     \"\"\"\n-    pass\n+    if not isinstance(default_value, dict):\n+        raise TypeError\n+\n+    question = (\n+        prompts[var_name]\n+        if prompts and var_name in prompts.keys() and prompts[var_name]\n+        else var_name\n+    )\n+    user_value = JsonPrompt.ask(\n+        f\"{prefix}{question} [cyan bold]({DEFAULT_DISPLAY})[/]\",\n+        default=default_value,\n+        show_default=False,\n+    )\n+    return user_value\n\n\n def render_variable(env, raw, cookiecutter_dict):\n@@ -117,12 +205,34 @@ def render_variable(env, raw, cookiecutter_dict):\n         being populated with variables.\n     :return: The rendered value for the default variable.\n     \"\"\"\n-    pass\n-\n-\n-def _prompts_from_options(options: dict) -&gt;dict:\n+    if raw is None or isinstance(raw, bool):\n+        return raw\n+    elif isinstance(raw, dict):\n+        return {\n+            render_variable(env, k, cookiecutter_dict): render_variable(\n+                env, v, cookiecutter_dict\n+            )\n+            for k, v in raw.items()\n+        }\n+    elif isinstance(raw, list):\n+        return [render_variable(env, v, cookiecutter_dict) for v in raw]\n+    elif not isinstance(raw, str):\n+        raw = str(raw)\n+\n+    template = env.from_string(raw)\n+\n+    return template.render(cookiecutter=cookiecutter_dict)\n+\n+\n+def _prompts_from_options(options: dict) -&gt; dict:\n     \"\"\"Process template options and return friendly prompt information.\"\"\"\n-    pass\n+    prompts = {\"__prompt__\": \"Select a template\"}\n+    for option_key, option_value in options.items():\n+        title = str(option_value.get(\"title\", option_key))\n+        description = option_value.get(\"description\", option_key)\n+        label = title if title == description else f\"{title} ({description})\"\n+        prompts[option_key] = label\n+    return prompts\n\n\n def prompt_choice_for_template(key, options, no_input):\n@@ -130,16 +240,22 @@ def prompt_choice_for_template(key, options, no_input):\n\n     :param no_input: Do not prompt for user input and return the first available option.\n     \"\"\"\n-    pass\n+    opts = list(options.keys())\n+    prompts = {\"templates\": _prompts_from_options(options)}\n+    return opts[0] if no_input else read_user_choice(key, opts, prompts, \"\")\n\n\n-def prompt_choice_for_config(cookiecutter_dict, env, key, options, no_input,\n-    prompts=None, prefix=''):\n+def prompt_choice_for_config(\n+    cookiecutter_dict, env, key, options, no_input, prompts=None, prefix=\"\"\n+):\n     \"\"\"Prompt user with a set of options to choose from.\n\n     :param no_input: Do not prompt for user input and return the first available option.\n     \"\"\"\n-    pass\n+    rendered_options = [render_variable(env, raw, cookiecutter_dict) for raw in options]\n+    if no_input:\n+        return rendered_options[0]\n+    return read_user_choice(key, rendered_options, prompts, prefix)\n\n\n def prompt_for_config(context, no_input=False):\n@@ -148,11 +264,81 @@ def prompt_for_config(context, no_input=False):\n     :param dict context: Source for field names and sample values.\n     :param no_input: Do not prompt for user input and use only values from context.\n     \"\"\"\n-    pass\n-\n-\n-def choose_nested_template(context: dict, repo_dir: str, no_input: bool=False\n-    ) -&gt;str:\n+    cookiecutter_dict = OrderedDict([])\n+    env = create_env_with_context(context)\n+    prompts = context['cookiecutter'].pop('__prompts__', {})\n+\n+    # First pass: Handle simple and raw variables, plus choices.\n+    # These must be done first because the dictionaries keys and\n+    # values might refer to them.\n+    count = 0\n+    all_prompts = context['cookiecutter'].items()\n+    visible_prompts = [k for k, _ in all_prompts if not k.startswith(\"_\")]\n+    size = len(visible_prompts)\n+    for key, raw in all_prompts:\n+        if key.startswith('_') and not key.startswith('__'):\n+            cookiecutter_dict[key] = raw\n+            continue\n+        elif key.startswith('__'):\n+            cookiecutter_dict[key] = render_variable(env, raw, cookiecutter_dict)\n+            continue\n+\n+        if not isinstance(raw, dict):\n+            count += 1\n+            prefix = f\"  [dim][{count}/{size}][/] \"\n+\n+        try:\n+            if isinstance(raw, list):\n+                # We are dealing with a choice variable\n+                val = prompt_choice_for_config(\n+                    cookiecutter_dict, env, key, raw, no_input, prompts, prefix\n+                )\n+                cookiecutter_dict[key] = val\n+            elif isinstance(raw, bool):\n+                # We are dealing with a boolean variable\n+                if no_input:\n+                    cookiecutter_dict[key] = render_variable(\n+                        env, raw, cookiecutter_dict\n+                    )\n+                else:\n+                    cookiecutter_dict[key] = read_user_yes_no(key, raw, prompts, prefix)\n+            elif not isinstance(raw, dict):\n+                # We are dealing with a regular variable\n+                val = render_variable(env, raw, cookiecutter_dict)\n+\n+                if not no_input:\n+                    val = read_user_variable(key, val, prompts, prefix)\n+\n+                cookiecutter_dict[key] = val\n+        except UndefinedError as err:\n+            msg = f\"Unable to render variable '{key}'\"\n+            raise UndefinedVariableInTemplate(msg, err, context) from err\n+\n+    # Second pass; handle the dictionaries.\n+    for key, raw in context['cookiecutter'].items():\n+        # Skip private type dicts not to be rendered.\n+        if key.startswith('_') and not key.startswith('__'):\n+            continue\n+\n+        try:\n+            if isinstance(raw, dict):\n+                # We are dealing with a dict variable\n+                count += 1\n+                prefix = f\"  [dim][{count}/{size}][/] \"\n+                val = render_variable(env, raw, cookiecutter_dict)\n+\n+                if not no_input and not key.startswith('__'):\n+                    val = read_user_dict(key, val, prompts, prefix)\n+\n+                cookiecutter_dict[key] = val\n+        except UndefinedError as err:\n+            msg = f\"Unable to render variable '{key}'\"\n+            raise UndefinedVariableInTemplate(msg, err, context) from err\n+\n+    return cookiecutter_dict\n+\n+\n+def choose_nested_template(context: dict, repo_dir: str, no_input: bool = False) -&gt; str:\n     \"\"\"Prompt user to select the nested template to use.\n\n     :param context: Source for field names and sample values.\n@@ -160,7 +346,33 @@ def choose_nested_template(context: dict, repo_dir: str, no_input: bool=False\n     :param no_input: Do not prompt for user input and use only values from context.\n     :returns: Path to the selected template.\n     \"\"\"\n-    pass\n+    cookiecutter_dict = OrderedDict([])\n+    env = create_env_with_context(context)\n+    prefix = \"\"\n+    prompts = context['cookiecutter'].pop('__prompts__', {})\n+    key = \"templates\"\n+    config = context['cookiecutter'].get(key, {})\n+    if config:\n+        # Pass\n+        val = prompt_choice_for_template(key, config, no_input)\n+        template = config[val][\"path\"]\n+    else:\n+        # Old style\n+        key = \"template\"\n+        config = context['cookiecutter'].get(key, [])\n+        val = prompt_choice_for_config(\n+            cookiecutter_dict, env, key, config, no_input, prompts, prefix\n+        )\n+        template = re.search(r'\\((.+)\\)', val).group(1)\n+\n+    template = Path(template) if template else None\n+    if not (template and not template.is_absolute()):\n+        raise ValueError(\"Illegal template path\")\n+\n+    repo_dir = Path(repo_dir).resolve()\n+    template_path = (repo_dir / template).resolve()\n+    # Return path as string\n+    return f\"{template_path}\"\n\n\n def prompt_and_delete(path, no_input=False):\n@@ -174,4 +386,28 @@ def prompt_and_delete(path, no_input=False):\n     :param no_input: Suppress prompt to delete repo and just delete it.\n     :return: True if the content was deleted\n     \"\"\"\n-    pass\n+    # Suppress prompt if called via API\n+    if no_input:\n+        ok_to_delete = True\n+    else:\n+        question = (\n+            f\"You've downloaded {path} before. Is it okay to delete and re-download it?\"\n+        )\n+\n+        ok_to_delete = read_user_yes_no(question, 'yes')\n+\n+    if ok_to_delete:\n+        if os.path.isdir(path):\n+            rmtree(path)\n+        else:\n+            os.remove(path)\n+        return True\n+    else:\n+        ok_to_reuse = read_user_yes_no(\n+            \"Do you want to re-use the existing version?\", 'yes'\n+        )\n+\n+        if ok_to_reuse:\n+            return False\n+\n+        sys.exit()\ndiff --git a/cookiecutter/replay.py b/cookiecutter/replay.py\nindex 340be41..196f2b1 100644\n--- a/cookiecutter/replay.py\n+++ b/cookiecutter/replay.py\n@@ -3,21 +3,50 @@ cookiecutter.replay.\n\n -------------------\n \"\"\"\n+\n import json\n import os\n+\n from cookiecutter.utils import make_sure_path_exists\n\n\n def get_file_name(replay_dir, template_name):\n     \"\"\"Get the name of file.\"\"\"\n-    pass\n+    suffix = '.json' if not template_name.endswith('.json') else ''\n+    file_name = f'{template_name}{suffix}'\n+    return os.path.join(replay_dir, file_name)\n\n\n-def dump(replay_dir: 'os.PathLike[str]', template_name: str, context: dict):\n+def dump(replay_dir: \"os.PathLike[str]\", template_name: str, context: dict):\n     \"\"\"Write json data to file.\"\"\"\n-    pass\n+    make_sure_path_exists(replay_dir)\n+\n+    if not isinstance(template_name, str):\n+        raise TypeError('Template name is required to be of type str')\n+\n+    if not isinstance(context, dict):\n+        raise TypeError('Context is required to be of type dict')\n+\n+    if 'cookiecutter' not in context:\n+        raise ValueError('Context is required to contain a cookiecutter key')\n+\n+    replay_file = get_file_name(replay_dir, template_name)\n+\n+    with open(replay_file, 'w', encoding=\"utf-8\") as outfile:\n+        json.dump(context, outfile, indent=2)\n\n\n def load(replay_dir, template_name):\n     \"\"\"Read json data from file.\"\"\"\n-    pass\n+    if not isinstance(template_name, str):\n+        raise TypeError('Template name is required to be of type str')\n+\n+    replay_file = get_file_name(replay_dir, template_name)\n+\n+    with open(replay_file, encoding=\"utf-8\") as infile:\n+        context = json.load(infile)\n+\n+    if 'cookiecutter' not in context:\n+        raise ValueError('Context is required to contain a cookiecutter key')\n+\n+    return context\ndiff --git a/cookiecutter/repository.py b/cookiecutter/repository.py\nindex e350c56..cc5576a 100644\n--- a/cookiecutter/repository.py\n+++ b/cookiecutter/repository.py\n@@ -1,28 +1,32 @@\n \"\"\"Cookiecutter repository functions.\"\"\"\n+\n import os\n import re\n+\n from cookiecutter.exceptions import RepositoryNotFound\n from cookiecutter.vcs import clone\n from cookiecutter.zipfile import unzip\n+\n REPO_REGEX = re.compile(\n-    \"\"\"\n+    r\"\"\"\n # something like git:// ssh:// file:// etc.\n-((((git|hg)\\\\+)?(git|ssh|file|https?):(//)?)\n+((((git|hg)\\+)?(git|ssh|file|https?):(//)?)\n  |                                      # or\n- (\\\\w+@[\\\\w\\\\.]+)                          # something like user@...\n+ (\\w+@[\\w\\.]+)                          # something like user@...\n+)\n+\"\"\",\n+    re.VERBOSE,\n )\n-\"\"\"\n-    , re.VERBOSE)\n\n\n def is_repo_url(value):\n     \"\"\"Return True if value is a repository URL.\"\"\"\n-    pass\n+    return bool(REPO_REGEX.match(value))\n\n\n def is_zip_file(value):\n     \"\"\"Return True if value is a zip file.\"\"\"\n-    pass\n+    return value.lower().endswith('.zip')\n\n\n def expand_abbreviations(template, abbreviations):\n@@ -31,7 +35,16 @@ def expand_abbreviations(template, abbreviations):\n     :param template: The project template name.\n     :param abbreviations: Abbreviation definitions.\n     \"\"\"\n-    pass\n+    if template in abbreviations:\n+        return abbreviations[template]\n+\n+    # Split on colon. If there is no colon, rest will be empty\n+    # and prefix will be the whole template\n+    prefix, sep, rest = template.partition(':')\n+    if prefix in abbreviations:\n+        return abbreviations[prefix].format(rest)\n+\n+    return template\n\n\n def repository_has_cookiecutter_json(repo_directory):\n@@ -40,11 +53,23 @@ def repository_has_cookiecutter_json(repo_directory):\n     :param repo_directory: The candidate repository directory.\n     :return: True if the `repo_directory` is valid, else False.\n     \"\"\"\n-    pass\n+    repo_directory_exists = os.path.isdir(repo_directory)\n+\n+    repo_config_exists = os.path.isfile(\n+        os.path.join(repo_directory, 'cookiecutter.json')\n+    )\n+    return repo_directory_exists and repo_config_exists\n\n\n-def determine_repo_dir(template, abbreviations, clone_to_dir, checkout,\n-    no_input, password=None, directory=None):\n+def determine_repo_dir(\n+    template,\n+    abbreviations,\n+    clone_to_dir,\n+    checkout,\n+    no_input,\n+    password=None,\n+    directory=None,\n+):\n     \"\"\"\n     Locate the repository directory from a template reference.\n\n@@ -67,4 +92,41 @@ def determine_repo_dir(template, abbreviations, clone_to_dir, checkout,\n         after the template has been instantiated.\n     :raises: `RepositoryNotFound` if a repository directory could not be found.\n     \"\"\"\n-    pass\n+    template = expand_abbreviations(template, abbreviations)\n+\n+    if is_zip_file(template):\n+        unzipped_dir = unzip(\n+            zip_uri=template,\n+            is_url=is_repo_url(template),\n+            clone_to_dir=clone_to_dir,\n+            no_input=no_input,\n+            password=password,\n+        )\n+        repository_candidates = [unzipped_dir]\n+        cleanup = True\n+    elif is_repo_url(template):\n+        cloned_repo = clone(\n+            repo_url=template,\n+            checkout=checkout,\n+            clone_to_dir=clone_to_dir,\n+            no_input=no_input,\n+        )\n+        repository_candidates = [cloned_repo]\n+        cleanup = False\n+    else:\n+        repository_candidates = [template, os.path.join(clone_to_dir, template)]\n+        cleanup = False\n+\n+    if directory:\n+        repository_candidates = [\n+            os.path.join(s, directory) for s in repository_candidates\n+        ]\n+\n+    for repo_candidate in repository_candidates:\n+        if repository_has_cookiecutter_json(repo_candidate):\n+            return repo_candidate, cleanup\n+\n+    raise RepositoryNotFound(\n+        'A valid repository for \"{}\" could not be found in the following '\n+        'locations:\\n{}'.format(template, '\\n'.join(repository_candidates))\n+    )\ndiff --git a/cookiecutter/utils.py b/cookiecutter/utils.py\nindex 6aa68ba..b21252c 100644\n--- a/cookiecutter/utils.py\n+++ b/cookiecutter/utils.py\n@@ -1,4 +1,5 @@\n \"\"\"Helper functions used throughout Cookiecutter.\"\"\"\n+\n import contextlib\n import logging\n import os\n@@ -7,8 +8,11 @@ import stat\n import tempfile\n from pathlib import Path\n from typing import Dict\n+\n from jinja2.ext import Extension\n+\n from cookiecutter.environment import StrictEnvironment\n+\n logger = logging.getLogger(__name__)\n\n\n@@ -18,7 +22,8 @@ def force_delete(func, path, exc_info):\n     Usage: `shutil.rmtree(path, onerror=force_delete)`\n     From https://docs.python.org/3/library/shutil.html#rmtree-example\n     \"\"\"\n-    pass\n+    os.chmod(path, stat.S_IWRITE)\n+    func(path)\n\n\n def rmtree(path):\n@@ -26,15 +31,19 @@ def rmtree(path):\n\n     :param path: A directory path.\n     \"\"\"\n-    pass\n+    shutil.rmtree(path, onerror=force_delete)\n\n\n-def make_sure_path_exists(path: 'os.PathLike[str]') -&gt;None:\n+def make_sure_path_exists(path: \"os.PathLike[str]\") -&gt; None:\n     \"\"\"Ensure that a directory exists.\n\n     :param path: A directory tree path for creation.\n     \"\"\"\n-    pass\n+    logger.debug('Making sure path exists (creates tree if not exist): %s', path)\n+    try:\n+        Path(path).mkdir(parents=True, exist_ok=True)\n+    except OSError as error:\n+        raise OSError(f'Unable to create directory at {path}') from error\n\n\n @contextlib.contextmanager\n@@ -43,7 +52,13 @@ def work_in(dirname=None):\n\n     When exited, returns to the working directory prior to entering.\n     \"\"\"\n-    pass\n+    curdir = os.getcwd()\n+    try:\n+        if dirname is not None:\n+            os.chdir(dirname)\n+        yield\n+    finally:\n+        os.chdir(curdir)\n\n\n def make_executable(script_path):\n@@ -51,19 +66,34 @@ def make_executable(script_path):\n\n     :param script_path: The file to change\n     \"\"\"\n-    pass\n+    status = os.stat(script_path)\n+    os.chmod(script_path, status.st_mode | stat.S_IEXEC)\n\n\n def simple_filter(filter_function):\n     \"\"\"Decorate a function to wrap it in a simplified jinja2 extension.\"\"\"\n-    pass\n\n+    class SimpleFilterExtension(Extension):\n+        def __init__(self, environment):\n+            super().__init__(environment)\n+            environment.filters[filter_function.__name__] = filter_function\n\n-def create_tmp_repo_dir(repo_dir: 'os.PathLike[str]') -&gt;Path:\n+    SimpleFilterExtension.__name__ = filter_function.__name__\n+    return SimpleFilterExtension\n+\n+\n+def create_tmp_repo_dir(repo_dir: \"os.PathLike[str]\") -&gt; Path:\n     \"\"\"Create a temporary dir with a copy of the contents of repo_dir.\"\"\"\n-    pass\n+    repo_dir = Path(repo_dir).resolve()\n+    base_dir = tempfile.mkdtemp(prefix='cookiecutter')\n+    new_dir = f\"{base_dir}/{repo_dir.name}\"\n+    logger.debug(f'Copying repo_dir from {repo_dir} to {new_dir}')\n+    shutil.copytree(repo_dir, new_dir)\n+    return Path(new_dir)\n\n\n def create_env_with_context(context: Dict):\n     \"\"\"Create a jinja environment using the provided context.\"\"\"\n-    pass\n+    envvars = context.get('cookiecutter', {}).get('_jinja2_env_vars', {})\n+\n+    return StrictEnvironment(context=context, keep_trailing_newline=True, **envvars)\ndiff --git a/cookiecutter/vcs.py b/cookiecutter/vcs.py\nindex 94d6c05..db57ae9 100644\n--- a/cookiecutter/vcs.py\n+++ b/cookiecutter/vcs.py\n@@ -1,15 +1,28 @@\n \"\"\"Helper functions for working with version control systems.\"\"\"\n+\n import logging\n import os\n-import subprocess\n+import subprocess  # nosec\n from pathlib import Path\n from shutil import which\n from typing import Optional\n-from cookiecutter.exceptions import RepositoryCloneFailed, RepositoryNotFound, UnknownRepoType, VCSNotInstalled\n+\n+from cookiecutter.exceptions import (\n+    RepositoryCloneFailed,\n+    RepositoryNotFound,\n+    UnknownRepoType,\n+    VCSNotInstalled,\n+)\n from cookiecutter.prompt import prompt_and_delete\n from cookiecutter.utils import make_sure_path_exists\n+\n logger = logging.getLogger(__name__)\n-BRANCH_ERRORS = ['error: pathspec', 'unknown revision']\n+\n+\n+BRANCH_ERRORS = [\n+    'error: pathspec',\n+    'unknown revision',\n+]\n\n\n def identify_repo(repo_url):\n@@ -20,7 +33,20 @@ def identify_repo(repo_url):\n     :param repo_url: Repo URL of unknown type.\n     :returns: ('git', repo_url), ('hg', repo_url), or None.\n     \"\"\"\n-    pass\n+    repo_url_values = repo_url.split('+')\n+    if len(repo_url_values) == 2:\n+        repo_type = repo_url_values[0]\n+        if repo_type in [\"git\", \"hg\"]:\n+            return repo_type, repo_url_values[1]\n+        else:\n+            raise UnknownRepoType\n+    else:\n+        if 'git' in repo_url:\n+            return 'git', repo_url\n+        elif 'bitbucket' in repo_url:\n+            return 'hg', repo_url\n+        else:\n+            raise UnknownRepoType\n\n\n def is_vcs_installed(repo_type):\n@@ -29,11 +55,15 @@ def is_vcs_installed(repo_type):\n\n     :param repo_type:\n     \"\"\"\n-    pass\n+    return bool(which(repo_type))\n\n\n-def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n-    'os.PathLike[str]'='.', no_input: bool=False):\n+def clone(\n+    repo_url: str,\n+    checkout: Optional[str] = None,\n+    clone_to_dir: \"os.PathLike[str]\" = \".\",\n+    no_input: bool = False,\n+):\n     \"\"\"Clone a repo to the current directory.\n\n     :param repo_url: Repo URL of unknown type.\n@@ -44,4 +74,62 @@ def clone(repo_url: str, checkout: Optional[str]=None, clone_to_dir:\n         cached resources.\n     :returns: str with path to the new directory of the repository.\n     \"\"\"\n-    pass\n+    # Ensure that clone_to_dir exists\n+    clone_to_dir = Path(clone_to_dir).expanduser()\n+    make_sure_path_exists(clone_to_dir)\n+\n+    # identify the repo_type\n+    repo_type, repo_url = identify_repo(repo_url)\n+\n+    # check that the appropriate VCS for the repo_type is installed\n+    if not is_vcs_installed(repo_type):\n+        msg = f\"'{repo_type}' is not installed.\"\n+        raise VCSNotInstalled(msg)\n+\n+    repo_url = repo_url.rstrip('/')\n+    repo_name = os.path.split(repo_url)[1]\n+    if repo_type == 'git':\n+        repo_name = repo_name.split(':')[-1].rsplit('.git')[0]\n+        repo_dir = os.path.normpath(os.path.join(clone_to_dir, repo_name))\n+    if repo_type == 'hg':\n+        repo_dir = os.path.normpath(os.path.join(clone_to_dir, repo_name))\n+    logger.debug(f'repo_dir is {repo_dir}')\n+\n+    if os.path.isdir(repo_dir):\n+        clone = prompt_and_delete(repo_dir, no_input=no_input)\n+    else:\n+        clone = True\n+\n+    if clone:\n+        try:\n+            subprocess.check_output(  # nosec\n+                [repo_type, 'clone', repo_url],\n+                cwd=clone_to_dir,\n+                stderr=subprocess.STDOUT,\n+            )\n+            if checkout is not None:\n+                checkout_params = [checkout]\n+                # Avoid Mercurial \"--config\" and \"--debugger\" injection vulnerability\n+                if repo_type == \"hg\":\n+                    checkout_params.insert(0, \"--\")\n+                subprocess.check_output(  # nosec\n+                    [repo_type, 'checkout', *checkout_params],\n+                    cwd=repo_dir,\n+                    stderr=subprocess.STDOUT,\n+                )\n+        except subprocess.CalledProcessError as clone_error:\n+            output = clone_error.output.decode('utf-8')\n+            if 'not found' in output.lower():\n+                raise RepositoryNotFound(\n+                    f'The repository {repo_url} could not be found, '\n+                    'have you made a typo?'\n+                ) from clone_error\n+            if any(error in output for error in BRANCH_ERRORS):\n+                raise RepositoryCloneFailed(\n+                    f'The {checkout} branch of repository '\n+                    f'{repo_url} could not found, have you made a typo?'\n+                ) from clone_error\n+            logger.error('git clone failed with error: %s', output)\n+            raise\n+\n+    return repo_dir\ndiff --git a/cookiecutter/zipfile.py b/cookiecutter/zipfile.py\nindex c4d398a..e3cfb3e 100644\n--- a/cookiecutter/zipfile.py\n+++ b/cookiecutter/zipfile.py\n@@ -1,17 +1,25 @@\n \"\"\"Utility functions for handling and fetching repo archives in zip format.\"\"\"\n+\n import os\n import tempfile\n from pathlib import Path\n from typing import Optional\n from zipfile import BadZipFile, ZipFile\n+\n import requests\n+\n from cookiecutter.exceptions import InvalidZipRepository\n from cookiecutter.prompt import prompt_and_delete, read_repo_password\n from cookiecutter.utils import make_sure_path_exists\n\n\n-def unzip(zip_uri: str, is_url: bool, clone_to_dir: 'os.PathLike[str]'='.',\n-    no_input: bool=False, password: Optional[str]=None):\n+def unzip(\n+    zip_uri: str,\n+    is_url: bool,\n+    clone_to_dir: \"os.PathLike[str]\" = \".\",\n+    no_input: bool = False,\n+    password: Optional[str] = None,\n+):\n     \"\"\"Download and unpack a zipfile at a given URI.\n\n     This will download the zipfile to the cookiecutter repository,\n@@ -25,4 +33,89 @@ def unzip(zip_uri: str, is_url: bool, clone_to_dir: 'os.PathLike[str]'='.',\n         cached resources.\n     :param password: The password to use when unpacking the repository.\n     \"\"\"\n-    pass\n+    # Ensure that clone_to_dir exists\n+    clone_to_dir = Path(clone_to_dir).expanduser()\n+    make_sure_path_exists(clone_to_dir)\n+\n+    if is_url:\n+        # Build the name of the cached zipfile,\n+        # and prompt to delete if it already exists.\n+        identifier = zip_uri.rsplit('/', 1)[1]\n+        zip_path = os.path.join(clone_to_dir, identifier)\n+\n+        if os.path.exists(zip_path):\n+            download = prompt_and_delete(zip_path, no_input=no_input)\n+        else:\n+            download = True\n+\n+        if download:\n+            # (Re) download the zipfile\n+            r = requests.get(zip_uri, stream=True, timeout=100)\n+            with open(zip_path, 'wb') as f:\n+                for chunk in r.iter_content(chunk_size=1024):\n+                    if chunk:  # filter out keep-alive new chunks\n+                        f.write(chunk)\n+    else:\n+        # Just use the local zipfile as-is.\n+        zip_path = os.path.abspath(zip_uri)\n+\n+    # Now unpack the repository. The zipfile will be unpacked\n+    # into a temporary directory\n+    try:\n+        zip_file = ZipFile(zip_path)\n+\n+        if len(zip_file.namelist()) == 0:\n+            raise InvalidZipRepository(f'Zip repository {zip_uri} is empty')\n+\n+        # The first record in the zipfile should be the directory entry for\n+        # the archive. If it isn't a directory, there's a problem.\n+        first_filename = zip_file.namelist()[0]\n+        if not first_filename.endswith('/'):\n+            raise InvalidZipRepository(\n+                f\"Zip repository {zip_uri} does not include a top-level directory\"\n+            )\n+\n+        # Construct the final target directory\n+        project_name = first_filename[:-1]\n+        unzip_base = tempfile.mkdtemp()\n+        unzip_path = os.path.join(unzip_base, project_name)\n+\n+        # Extract the zip file into the temporary directory\n+        try:\n+            zip_file.extractall(path=unzip_base)\n+        except RuntimeError:\n+            # File is password protected; try to get a password from the\n+            # environment; if that doesn't work, ask the user.\n+            if password is not None:\n+                try:\n+                    zip_file.extractall(path=unzip_base, pwd=password.encode('utf-8'))\n+                except RuntimeError:\n+                    raise InvalidZipRepository(\n+                        'Invalid password provided for protected repository'\n+                    )\n+            elif no_input:\n+                raise InvalidZipRepository(\n+                    'Unable to unlock password protected repository'\n+                )\n+            else:\n+                retry = 0\n+                while retry is not None:\n+                    try:\n+                        password = read_repo_password('Repo password')\n+                        zip_file.extractall(\n+                            path=unzip_base, pwd=password.encode('utf-8')\n+                        )\n+                        retry = None\n+                    except RuntimeError:\n+                        retry += 1\n+                        if retry == 3:\n+                            raise InvalidZipRepository(\n+                                'Invalid password provided for protected repository'\n+                            )\n+\n+    except BadZipFile:\n+        raise InvalidZipRepository(\n+            f'Zip repository {zip_uri} is not a valid zip archive:'\n+        )\n+\n+    return unzip_path\n</code></pre>"},{"location":"analysis_reference_deprecated/","title":"Analysis reference deprecated","text":"<p>back to reference summary</p>"},{"location":"analysis_reference_deprecated/#submission-name-reference","title":"Submission Name: reference","text":""},{"location":"analysis_reference_deprecated/#repository-deprecated","title":"Repository: deprecated","text":""},{"location":"analysis_reference_deprecated/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count passed 171 total 171 collected 171"},{"location":"analysis_reference_deprecated/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_reference_deprecated/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/deprecated/classic.py b/deprecated/classic.py\nindex fc9af25..6ca3f27 100644\n--- a/deprecated/classic.py\n+++ b/deprecated/classic.py\n@@ -1,3 +1,4 @@\n+# -*- coding: utf-8 -*-\n \"\"\"\n Classic deprecation warning\n ===========================\n@@ -10,18 +11,25 @@ import functools\n import inspect\n import platform\n import warnings\n+\n import wrapt\n+\n try:\n+    # If the C extension for wrapt was compiled and wrapt/_wrappers.pyd exists, then the\n+    # stack level that should be passed to warnings.warn should be 2. However, if using\n+    # a pure python wrapt, a extra stacklevel is required.\n     import wrapt._wrappers\n+\n     _routine_stacklevel = 2\n     _class_stacklevel = 2\n except ImportError:\n     _routine_stacklevel = 3\n-    if platform.python_implementation() == 'PyPy':\n+    if platform.python_implementation() == \"PyPy\":\n         _class_stacklevel = 2\n     else:\n         _class_stacklevel = 3\n-string_types = type(b''), type(u'')\n+\n+string_types = (type(b''), type(u''))\n\n\n class ClassicAdapter(wrapt.AdapterFactory):\n@@ -75,8 +83,7 @@ class ClassicAdapter(wrapt.AdapterFactory):\n            return x + y\n     \"\"\"\n\n-    def __init__(self, reason='', version='', action=None, category=\n-        DeprecationWarning):\n+    def __init__(self, reason=\"\", version=\"\", action=None, category=DeprecationWarning):\n         \"\"\"\n         Construct a wrapper adapter.\n\n@@ -103,8 +110,8 @@ class ClassicAdapter(wrapt.AdapterFactory):\n             By default, the category class is :class:`~DeprecationWarning`,\n             you can inherit this class to define your own deprecation warning category.\n         \"\"\"\n-        self.reason = reason or ''\n-        self.version = version or ''\n+        self.reason = reason or \"\"\n+        self.version = version or \"\"\n         self.action = action\n         self.category = category\n         super(ClassicAdapter, self).__init__()\n@@ -119,7 +126,21 @@ class ClassicAdapter(wrapt.AdapterFactory):\n\n         :return: The warning message.\n         \"\"\"\n-        pass\n+        if instance is None:\n+            if inspect.isclass(wrapped):\n+                fmt = \"Call to deprecated class {name}.\"\n+            else:\n+                fmt = \"Call to deprecated function (or staticmethod) {name}.\"\n+        else:\n+            if inspect.isclass(instance):\n+                fmt = \"Call to deprecated class method {name}.\"\n+            else:\n+                fmt = \"Call to deprecated method {name}.\"\n+        if self.reason:\n+            fmt += \" ({reason})\"\n+        if self.version:\n+            fmt += \" -- Deprecated since version {version}.\"\n+        return fmt.format(name=wrapped.__name__, reason=self.reason or \"\", version=self.version or \"\")\n\n     def __call__(self, wrapped):\n         \"\"\"\n@@ -143,15 +164,16 @@ class ClassicAdapter(wrapt.AdapterFactory):\n                 if self.action:\n                     with warnings.catch_warnings():\n                         warnings.simplefilter(self.action, self.category)\n-                        warnings.warn(msg, category=self.category,\n-                            stacklevel=_class_stacklevel)\n+                        warnings.warn(msg, category=self.category, stacklevel=_class_stacklevel)\n                 else:\n-                    warnings.warn(msg, category=self.category, stacklevel=\n-                        _class_stacklevel)\n+                    warnings.warn(msg, category=self.category, stacklevel=_class_stacklevel)\n                 if old_new1 is object.__new__:\n                     return old_new1(cls)\n+                # actually, we don't know the real signature of *old_new1*\n                 return old_new1(cls, *args, **kwargs)\n+\n             wrapped.__new__ = staticmethod(wrapped_cls)\n+\n         return wrapped\n\n\n@@ -231,4 +253,40 @@ def deprecated(*args, **kwargs):\n            return x + y\n\n     \"\"\"\n-    pass\n+    if args and isinstance(args[0], string_types):\n+        kwargs['reason'] = args[0]\n+        args = args[1:]\n+\n+    if args and not callable(args[0]):\n+        raise TypeError(repr(type(args[0])))\n+\n+    if args:\n+        action = kwargs.get('action')\n+        category = kwargs.get('category', DeprecationWarning)\n+        adapter_cls = kwargs.pop('adapter_cls', ClassicAdapter)\n+        adapter = adapter_cls(**kwargs)\n+\n+        wrapped = args[0]\n+        if inspect.isclass(wrapped):\n+            wrapped = adapter(wrapped)\n+            return wrapped\n+\n+        elif inspect.isroutine(wrapped):\n+\n+            @wrapt.decorator(adapter=adapter)\n+            def wrapper_function(wrapped_, instance_, args_, kwargs_):\n+                msg = adapter.get_deprecated_msg(wrapped_, instance_)\n+                if action:\n+                    with warnings.catch_warnings():\n+                        warnings.simplefilter(action, category)\n+                        warnings.warn(msg, category=category, stacklevel=_routine_stacklevel)\n+                else:\n+                    warnings.warn(msg, category=category, stacklevel=_routine_stacklevel)\n+                return wrapped_(*args_, **kwargs_)\n+\n+            return wrapper_function(wrapped)\n+\n+        else:\n+            raise TypeError(repr(type(wrapped)))\n+\n+    return functools.partial(deprecated, **kwargs)\ndiff --git a/deprecated/sphinx.py b/deprecated/sphinx.py\nindex 6daf81f..7e717fb 100644\n--- a/deprecated/sphinx.py\n+++ b/deprecated/sphinx.py\n@@ -1,3 +1,4 @@\n+# coding: utf-8\n \"\"\"\n Sphinx directive integration\n ============================\n@@ -20,7 +21,9 @@ when the function/method is called or the class is constructed.\n \"\"\"\n import re\n import textwrap\n+\n import wrapt\n+\n from deprecated.classic import ClassicAdapter\n from deprecated.classic import deprecated as _classic_deprecated\n\n@@ -38,8 +41,15 @@ class SphinxAdapter(ClassicAdapter):\n     - The reason message is obviously added in the directive block if not empty.\n     \"\"\"\n\n-    def __init__(self, directive, reason='', version='', action=None,\n-        category=DeprecationWarning, line_length=70):\n+    def __init__(\n+        self,\n+        directive,\n+        reason=\"\",\n+        version=\"\",\n+        action=None,\n+        category=DeprecationWarning,\n+        line_length=70,\n+    ):\n         \"\"\"\n         Construct a wrapper adapter.\n\n@@ -75,12 +85,11 @@ class SphinxAdapter(ClassicAdapter):\n             Max line length of the directive text. If non nul, a long text is wrapped in several lines.\n         \"\"\"\n         if not version:\n-            raise ValueError(\n-                \"'version' argument is required in Sphinx directives\")\n+            # https://github.com/tantale/deprecated/issues/40\n+            raise ValueError(\"'version' argument is required in Sphinx directives\")\n         self.directive = directive\n         self.line_length = line_length\n-        super(SphinxAdapter, self).__init__(reason=reason, version=version,\n-            action=action, category=category)\n+        super(SphinxAdapter, self).__init__(reason=reason, version=version, action=action, category=category)\n\n     def __call__(self, wrapped):\n         \"\"\"\n@@ -90,32 +99,42 @@ class SphinxAdapter(ClassicAdapter):\n\n         :return: the decorated class or function.\n         \"\"\"\n-        fmt = ('.. {directive}:: {version}' if self.version else\n-            '.. {directive}::')\n-        div_lines = [fmt.format(directive=self.directive, version=self.version)\n-            ]\n+        # -- build the directive division\n+        fmt = \".. {directive}:: {version}\" if self.version else \".. {directive}::\"\n+        div_lines = [fmt.format(directive=self.directive, version=self.version)]\n         width = self.line_length - 3 if self.line_length &gt; 3 else 2 ** 16\n         reason = textwrap.dedent(self.reason).strip()\n         for paragraph in reason.splitlines():\n             if paragraph:\n-                div_lines.extend(textwrap.fill(paragraph, width=width,\n-                    initial_indent='   ', subsequent_indent='   ').splitlines()\n-                    )\n+                div_lines.extend(\n+                    textwrap.fill(\n+                        paragraph,\n+                        width=width,\n+                        initial_indent=\"   \",\n+                        subsequent_indent=\"   \",\n+                    ).splitlines()\n+                )\n             else:\n-                div_lines.append('')\n-        docstring = wrapped.__doc__ or ''\n-        lines = docstring.splitlines(keepends=True) or ['']\n-        docstring = textwrap.dedent(''.join(lines[1:])) if len(lines\n-            ) &gt; 1 else ''\n+                div_lines.append(\"\")\n+\n+        # -- get the docstring, normalize the trailing newlines\n+        # keep a consistent behaviour if the docstring starts with newline or directly on the first one\n+        docstring = wrapped.__doc__ or \"\"\n+        lines = docstring.splitlines(keepends=True) or [\"\"]\n+        docstring = textwrap.dedent(\"\".join(lines[1:])) if len(lines) &gt; 1 else \"\"\n         docstring = lines[0] + docstring\n         if docstring:\n-            docstring = re.sub('\\\\n+$', '', docstring, flags=re.DOTALL\n-                ) + '\\n\\n'\n+            # An empty line must separate the original docstring and the directive.\n+            docstring = re.sub(r\"\\n+$\", \"\", docstring, flags=re.DOTALL) + \"\\n\\n\"\n         else:\n-            docstring = '\\n'\n-        docstring += ''.join('{}\\n'.format(line) for line in div_lines)\n+            # Avoid \"Explicit markup ends without a blank line\" when the decorated function has no docstring\n+            docstring = \"\\n\"\n+\n+        # -- append the directive division to the docstring\n+        docstring += \"\".join(\"{}\\n\".format(line) for line in div_lines)\n+\n         wrapped.__doc__ = docstring\n-        if self.directive in {'versionadded', 'versionchanged'}:\n+        if self.directive in {\"versionadded\", \"versionchanged\"}:\n             return wrapped\n         return super(SphinxAdapter, self).__call__(wrapped)\n\n@@ -133,10 +152,15 @@ class SphinxAdapter(ClassicAdapter):\n            Strip Sphinx cross-referencing syntax from warning message.\n\n         \"\"\"\n-        pass\n+        msg = super(SphinxAdapter, self).get_deprecated_msg(wrapped, instance)\n+        # Strip Sphinx cross reference syntax (like \":function:\", \":py:func:\" and \":py:meth:\")\n+        # Possible values are \":role:`foo`\", \":domain:role:`foo`\"\n+        # where ``role`` and ``domain`` should match \"[a-zA-Z]+\"\n+        msg = re.sub(r\"(?: : [a-zA-Z]+ )? : [a-zA-Z]+ : (`[^`]*`)\", r\"\\1\", msg, flags=re.X)\n+        return msg\n\n\n-def versionadded(reason='', version='', line_length=70):\n+def versionadded(reason=\"\", version=\"\", line_length=70):\n     \"\"\"\n     This decorator can be used to insert a \"versionadded\" directive\n     in your function/class docstring in order to documents the\n@@ -157,10 +181,16 @@ def versionadded(reason='', version='', line_length=70):\n\n     :return: the decorated function.\n     \"\"\"\n-    pass\n+    adapter = SphinxAdapter(\n+        'versionadded',\n+        reason=reason,\n+        version=version,\n+        line_length=line_length,\n+    )\n+    return adapter\n\n\n-def versionchanged(reason='', version='', line_length=70):\n+def versionchanged(reason=\"\", version=\"\", line_length=70):\n     \"\"\"\n     This decorator can be used to insert a \"versionchanged\" directive\n     in your function/class docstring in order to documents the\n@@ -180,10 +210,16 @@ def versionchanged(reason='', version='', line_length=70):\n\n     :return: the decorated function.\n     \"\"\"\n-    pass\n+    adapter = SphinxAdapter(\n+        'versionchanged',\n+        reason=reason,\n+        version=version,\n+        line_length=line_length,\n+    )\n+    return adapter\n\n\n-def deprecated(reason='', version='', line_length=70, **kwargs):\n+def deprecated(reason=\"\", version=\"\", line_length=70, **kwargs):\n     \"\"\"\n     This decorator can be used to insert a \"deprecated\" directive\n     in your function/class docstring in order to documents the\n@@ -218,4 +254,9 @@ def deprecated(reason='', version='', line_length=70, **kwargs):\n     .. versionchanged:: 1.2.13\n        Change the signature of the decorator to reflect the valid use cases.\n     \"\"\"\n-    pass\n+    directive = kwargs.pop('directive', 'deprecated')\n+    adapter_cls = kwargs.pop('adapter_cls', SphinxAdapter)\n+    kwargs[\"reason\"] = reason\n+    kwargs[\"version\"] = version\n+    kwargs[\"line_length\"] = line_length\n+    return _classic_deprecated(directive=directive, adapter_cls=adapter_cls, **kwargs)\n</code></pre>"},{"location":"analysis_reference_imapclient/","title":"Analysis reference imapclient","text":"<p>back to reference summary</p>"},{"location":"analysis_reference_imapclient/#submission-name-reference","title":"Submission Name: reference","text":""},{"location":"analysis_reference_imapclient/#repository-imapclient","title":"Repository: imapclient","text":""},{"location":"analysis_reference_imapclient/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count passed 267 total 267 collected 267"},{"location":"analysis_reference_imapclient/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_reference_imapclient/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/imapclient/config.py b/imapclient/config.py\nindex f098591..76e8dc8 100644\n--- a/imapclient/config.py\n+++ b/imapclient/config.py\n@@ -1,3 +1,7 @@\n+# Copyright (c) 2015, Menno Smits\n+# Released subject to the New BSD License\n+# Please see http://en.wikipedia.org/wiki/BSD_licenses\n+\n import argparse\n import configparser\n import json\n@@ -6,19 +10,210 @@ import ssl\n import urllib.parse\n import urllib.request\n from typing import Any, Callable, Dict, Optional, Tuple, TYPE_CHECKING, TypeVar\n+\n import imapclient\n\n\n-def parse_config_file(filename: str) -&gt;argparse.Namespace:\n+def getenv(name: str, default: Optional[str]) -&gt; Optional[str]:\n+    return os.environ.get(\"imapclient_\" + name, default)\n+\n+\n+def get_config_defaults() -&gt; Dict[str, Any]:\n+    return {\n+        \"username\": getenv(\"username\", None),\n+        \"password\": getenv(\"password\", None),\n+        \"ssl\": True,\n+        \"ssl_check_hostname\": True,\n+        \"ssl_verify_cert\": True,\n+        \"ssl_ca_file\": None,\n+        \"timeout\": None,\n+        \"starttls\": False,\n+        \"stream\": False,\n+        \"oauth2\": False,\n+        \"oauth2_client_id\": getenv(\"oauth2_client_id\", None),\n+        \"oauth2_client_secret\": getenv(\"oauth2_client_secret\", None),\n+        \"oauth2_refresh_token\": getenv(\"oauth2_refresh_token\", None),\n+        \"expect_failure\": None,\n+    }\n+\n+\n+def parse_config_file(filename: str) -&gt; argparse.Namespace:\n     \"\"\"Parse INI files containing IMAP connection details.\n\n     Used by livetest.py and interact.py\n     \"\"\"\n-    pass\n\n+    parser = configparser.ConfigParser(get_string_config_defaults())\n+    parser.read(filename)\n+\n+    conf = _read_config_section(parser, \"DEFAULT\")\n+    if conf.expect_failure:\n+        raise ValueError(\"expect_failure should not be set for the DEFAULT section\")\n+\n+    conf.alternates = {}\n+    for section in parser.sections():\n+        # pylint: disable=no-member\n+        conf.alternates[section] = _read_config_section(parser, section)\n+\n+    return conf\n+\n+\n+def get_string_config_defaults() -&gt; Dict[str, str]:\n+    out = {}\n+    for k, v in get_config_defaults().items():\n+        if v is True:\n+            v = \"true\"\n+        elif v is False:\n+            v = \"false\"\n+        elif not v:\n+            v = \"\"\n+        out[k] = v\n+    return out\n+\n+\n+T = TypeVar(\"T\")\n+\n+\n+def _read_config_section(\n+    parser: configparser.ConfigParser, section: str\n+) -&gt; argparse.Namespace:\n+    def get(name: str) -&gt; str:\n+        return parser.get(section, name)\n+\n+    def getboolean(name: str) -&gt; bool:\n+        return parser.getboolean(section, name)\n+\n+    def get_allowing_none(name: str, typefunc: Callable[[str], T]) -&gt; Optional[T]:\n+        try:\n+            v = parser.get(section, name)\n+        except configparser.NoOptionError:\n+            return None\n+        if not v:\n+            return None\n+        return typefunc(v)\n+\n+    def getint(name: str) -&gt; Optional[int]:\n+        return get_allowing_none(name, int)\n+\n+    def getfloat(name: str) -&gt; Optional[float]:\n+        return get_allowing_none(name, float)\n\n-T = TypeVar('T')\n-OAUTH2_REFRESH_URLS = {'imap.gmail.com':\n-    'https://accounts.google.com/o/oauth2/token', 'imap.mail.yahoo.com':\n-    'https://api.login.yahoo.com/oauth2/get_token'}\n+    ssl_ca_file = get(\"ssl_ca_file\")\n+    if ssl_ca_file:\n+        ssl_ca_file = os.path.expanduser(ssl_ca_file)\n+\n+    return argparse.Namespace(\n+        host=get(\"host\"),\n+        port=getint(\"port\"),\n+        ssl=getboolean(\"ssl\"),\n+        starttls=getboolean(\"starttls\"),\n+        ssl_check_hostname=getboolean(\"ssl_check_hostname\"),\n+        ssl_verify_cert=getboolean(\"ssl_verify_cert\"),\n+        ssl_ca_file=ssl_ca_file,\n+        timeout=getfloat(\"timeout\"),\n+        stream=getboolean(\"stream\"),\n+        username=get(\"username\"),\n+        password=get(\"password\"),\n+        oauth2=getboolean(\"oauth2\"),\n+        oauth2_client_id=get(\"oauth2_client_id\"),\n+        oauth2_client_secret=get(\"oauth2_client_secret\"),\n+        oauth2_refresh_token=get(\"oauth2_refresh_token\"),\n+        expect_failure=get(\"expect_failure\"),\n+    )\n+\n+\n+OAUTH2_REFRESH_URLS = {\n+    \"imap.gmail.com\": \"https://accounts.google.com/o/oauth2/token\",\n+    \"imap.mail.yahoo.com\": \"https://api.login.yahoo.com/oauth2/get_token\",\n+}\n+\n+\n+def refresh_oauth2_token(\n+    hostname: str, client_id: str, client_secret: str, refresh_token: str\n+) -&gt; str:\n+    url = OAUTH2_REFRESH_URLS.get(hostname)\n+    if not url:\n+        raise ValueError(\"don't know where to refresh OAUTH2 token for %r\" % hostname)\n+\n+    post = {\n+        \"client_id\": client_id.encode(\"ascii\"),\n+        \"client_secret\": client_secret.encode(\"ascii\"),\n+        \"refresh_token\": refresh_token.encode(\"ascii\"),\n+        \"grant_type\": b\"refresh_token\",\n+    }\n+    with urllib.request.urlopen(\n+        url, urllib.parse.urlencode(post).encode(\"ascii\")\n+    ) as request:\n+        response = request.read()\n+    result = json.loads(response.decode(\"ascii\"))[\"access_token\"]\n+    if TYPE_CHECKING:\n+        assert isinstance(result, str)\n+    return result\n+\n+\n+# Tokens are expensive to refresh so use the same one for the duration of the process.\n _oauth2_cache: Dict[Tuple[str, str, str, str], str] = {}\n+\n+\n+def get_oauth2_token(\n+    hostname: str, client_id: str, client_secret: str, refresh_token: str\n+) -&gt; str:\n+    cache_key = (hostname, client_id, client_secret, refresh_token)\n+    token = _oauth2_cache.get(cache_key)\n+    if token:\n+        return token\n+\n+    token = refresh_oauth2_token(hostname, client_id, client_secret, refresh_token)\n+    _oauth2_cache[cache_key] = token\n+    return token\n+\n+\n+def create_client_from_config(\n+    conf: argparse.Namespace, login: bool = True\n+) -&gt; imapclient.IMAPClient:\n+    assert conf.host, \"missing host\"\n+\n+    ssl_context = None\n+    if conf.ssl:\n+        ssl_context = ssl.create_default_context()\n+        ssl_context.check_hostname = conf.ssl_check_hostname\n+        if not conf.ssl_verify_cert:\n+            ssl_context.verify_mode = ssl.CERT_NONE\n+        if conf.ssl_ca_file:\n+            ssl_context.load_verify_locations(cafile=conf.ssl_ca_file)\n+\n+    client = imapclient.IMAPClient(\n+        conf.host,\n+        port=conf.port,\n+        ssl=conf.ssl,\n+        ssl_context=ssl_context,\n+        stream=conf.stream,\n+        timeout=conf.timeout,\n+    )\n+    if not login:\n+        return client\n+\n+    try:\n+        if conf.starttls:\n+            client.starttls()\n+\n+        if conf.oauth2:\n+            assert conf.oauth2_client_id, \"missing oauth2 id\"\n+            assert conf.oauth2_client_secret, \"missing oauth2 secret\"\n+            assert conf.oauth2_refresh_token, \"missing oauth2 refresh token\"\n+            access_token = get_oauth2_token(\n+                conf.host,\n+                conf.oauth2_client_id,\n+                conf.oauth2_client_secret,\n+                conf.oauth2_refresh_token,\n+            )\n+            client.oauth2_login(conf.username, access_token)\n+\n+        elif not conf.stream:\n+            assert conf.username, \"missing username\"\n+            assert conf.password, \"missing password\"\n+            client.login(conf.username, conf.password)\n+        return client\n+    except:  # noqa: E722\n+        client.shutdown()\n+        raise\ndiff --git a/imapclient/datetime_util.py b/imapclient/datetime_util.py\nindex 57a44c4..060f889 100644\n--- a/imapclient/datetime_util.py\n+++ b/imapclient/datetime_util.py\n@@ -1,11 +1,17 @@\n+# Copyright (c) 2014, Menno Smits\n+# Released subject to the New BSD License\n+# Please see http://en.wikipedia.org/wiki/BSD_licenses\n+\n import re\n from datetime import datetime\n from email.utils import parsedate_tz\n+\n from .fixed_offset import FixedOffset\n-_SHORT_MONTHS = ' Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec'.split(' ')\n+\n+_SHORT_MONTHS = \" Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\".split(\" \")\n\n\n-def parse_to_datetime(timestamp: bytes, normalise: bool=True) -&gt;datetime:\n+def parse_to_datetime(timestamp: bytes, normalise: bool = True) -&gt; datetime:\n     \"\"\"Convert an IMAP datetime string to a datetime.\n\n     If normalise is True (the default), then the returned datetime\n@@ -14,22 +20,51 @@ def parse_to_datetime(timestamp: bytes, normalise: bool=True) -&gt;datetime:\n     If normalise is False, then the returned datetime will be\n     unadjusted but will contain timezone information as per the input.\n     \"\"\"\n-    pass\n+    time_tuple = parsedate_tz(_munge(timestamp))\n+    if time_tuple is None:\n+        raise ValueError(\"couldn't parse datetime %r\" % timestamp)\n+\n+    tz_offset_seconds = time_tuple[-1]\n+    tz = None\n+    if tz_offset_seconds is not None:\n+        tz = FixedOffset(tz_offset_seconds / 60)\n+\n+    dt = datetime(*time_tuple[:6], tzinfo=tz)\n+    if normalise and tz:\n+        dt = datetime_to_native(dt)\n\n+    return dt\n\n-def datetime_to_INTERNALDATE(dt: datetime) -&gt;str:\n+\n+def datetime_to_native(dt: datetime) -&gt; datetime:\n+    return dt.astimezone(FixedOffset.for_system()).replace(tzinfo=None)\n+\n+\n+def datetime_to_INTERNALDATE(dt: datetime) -&gt; str:\n     \"\"\"Convert a datetime instance to a IMAP INTERNALDATE string.\n\n     If timezone information is missing the current system\n     timezone is used.\n     \"\"\"\n-    pass\n+    if not dt.tzinfo:\n+        dt = dt.replace(tzinfo=FixedOffset.for_system())\n+    fmt = \"%d-\" + _SHORT_MONTHS[dt.month] + \"-%Y %H:%M:%S %z\"\n+    return dt.strftime(fmt)\n+\n+\n+# Matches timestamp strings where the time separator is a dot (see\n+# issue #154). For example: 'Sat, 8 May 2010 16.03.09 +0200'\n+_rfc822_dotted_time = re.compile(r\"\\w+, ?\\d{1,2} \\w+ \\d\\d(\\d\\d)? \\d\\d?\\.\\d\\d?\\.\\d\\d?.*\")\n\n\n-_rfc822_dotted_time = re.compile(\n-    '\\\\w+, ?\\\\d{1,2} \\\\w+ \\\\d\\\\d(\\\\d\\\\d)? \\\\d\\\\d?\\\\.\\\\d\\\\d?\\\\.\\\\d\\\\d?.*')\n+def _munge(timestamp: bytes) -&gt; str:\n+    s = timestamp.decode(\"latin-1\")  # parsedate_tz only works with strings\n+    if _rfc822_dotted_time.match(s):\n+        return s.replace(\".\", \":\")\n+    return s\n\n\n-def format_criteria_date(dt: datetime) -&gt;bytes:\n+def format_criteria_date(dt: datetime) -&gt; bytes:\n     \"\"\"Format a date or datetime instance for use in IMAP search criteria.\"\"\"\n-    pass\n+    out = \"%02d-%s-%d\" % (dt.day, _SHORT_MONTHS[dt.month], dt.year)\n+    return out.encode(\"ascii\")\ndiff --git a/imapclient/exceptions.py b/imapclient/exceptions.py\nindex a29d919..725af2f 100644\n--- a/imapclient/exceptions.py\n+++ b/imapclient/exceptions.py\n@@ -1,4 +1,10 @@\n import imaplib\n+\n+# Base class allowing to catch any IMAPClient related exceptions\n+# To ensure backward compatibility, we \"rename\" the imaplib general\n+# exception class, so we can catch its exceptions without having to\n+# deal with it in IMAPClient codebase\n+\n IMAPClientError = imaplib.IMAP4.error\n IMAPClientAbortError = imaplib.IMAP4.abort\n IMAPClientReadOnlyError = imaplib.IMAP4.readonly\ndiff --git a/imapclient/fixed_offset.py b/imapclient/fixed_offset.py\nindex b9e7df9..344df46 100644\n--- a/imapclient/fixed_offset.py\n+++ b/imapclient/fixed_offset.py\n@@ -1,6 +1,11 @@\n+# Copyright (c) 2014, Menno Smits\n+# Released subject to the New BSD License\n+# Please see http://en.wikipedia.org/wiki/BSD_licenses\n+\n import datetime\n import time\n from typing import Optional\n+\n ZERO = datetime.timedelta(0)\n\n\n@@ -10,17 +15,31 @@ class FixedOffset(datetime.tzinfo):\n     east from UTC\n     \"\"\"\n\n-    def __init__(self, minutes: float) -&gt;None:\n+    def __init__(self, minutes: float) -&gt; None:\n         self.__offset = datetime.timedelta(minutes=minutes)\n-        sign = '+'\n+\n+        sign = \"+\"\n         if minutes &lt; 0:\n-            sign = '-'\n+            sign = \"-\"\n         hours, remaining_mins = divmod(abs(minutes), 60)\n-        self.__name = '%s%02d%02d' % (sign, hours, remaining_mins)\n+        self.__name = \"%s%02d%02d\" % (sign, hours, remaining_mins)\n+\n+    def utcoffset(self, _: Optional[datetime.datetime]) -&gt; datetime.timedelta:\n+        return self.__offset\n+\n+    def tzname(self, _: Optional[datetime.datetime]) -&gt; str:\n+        return self.__name\n+\n+    def dst(self, _: Optional[datetime.datetime]) -&gt; datetime.timedelta:\n+        return ZERO\n\n     @classmethod\n-    def for_system(cls) -&gt;'FixedOffset':\n+    def for_system(cls) -&gt; \"FixedOffset\":\n         \"\"\"Return a FixedOffset instance for the current working timezone and\n         DST conditions.\n         \"\"\"\n-        pass\n+        if time.localtime().tm_isdst and time.daylight:\n+            offset = time.altzone\n+        else:\n+            offset = time.timezone\n+        return cls(-offset // 60)\ndiff --git a/imapclient/imap4.py b/imapclient/imap4.py\nindex 2a45702..d07515e 100644\n--- a/imapclient/imap4.py\n+++ b/imapclient/imap4.py\n@@ -1,11 +1,27 @@\n+# Copyright (c) 2015, Menno Smits\n+# Released subject to the New BSD License\n+# Please see http://en.wikipedia.org/wiki/BSD_licenses\n+\n import imaplib\n import socket\n from typing import Optional\n\n\n class IMAP4WithTimeout(imaplib.IMAP4):\n-\n-    def __init__(self, address: str, port: int, timeout: Optional[float]\n-        ) -&gt;None:\n+    def __init__(self, address: str, port: int, timeout: Optional[float]) -&gt; None:\n         self._timeout = timeout\n         imaplib.IMAP4.__init__(self, address, port)\n+\n+    def open(\n+        self, host: str = \"\", port: int = 143, timeout: Optional[float] = None\n+    ) -&gt; None:\n+        # This is overridden to make it consistent across Python versions.\n+        self.host = host\n+        self.port = port\n+        self.sock = self._create_socket(timeout)\n+        self.file = self.sock.makefile(\"rb\")\n+\n+    def _create_socket(self, timeout: Optional[float] = None) -&gt; socket.socket:\n+        return socket.create_connection(\n+            (self.host, self.port), timeout if timeout is not None else self._timeout\n+        )\ndiff --git a/imapclient/imap_utf7.py b/imapclient/imap_utf7.py\nindex 7a795b2..021c564 100644\n--- a/imapclient/imap_utf7.py\n+++ b/imapclient/imap_utf7.py\n@@ -1,25 +1,108 @@\n+# This file contains two main methods used to encode and decode UTF-7\n+# string, described in the RFC 3501. There are some variations specific\n+# to IMAP4rev1, so the built-in Python UTF-7 codec can't be used instead.\n+#\n+# The main difference is the shift character (used to switch from ASCII to\n+# base64 encoding context), which is &amp; in this modified UTF-7 convention,\n+# since + is considered as mainly used in mailbox names.\n+# Other variations and examples can be found in the RFC 3501, section 5.1.3.\n+\n import binascii\n from typing import List, Union\n\n\n-def encode(s: Union[str, bytes]) -&gt;bytes:\n+def encode(s: Union[str, bytes]) -&gt; bytes:\n     \"\"\"Encode a folder name using IMAP modified UTF-7 encoding.\n\n     Input is unicode; output is bytes (Python 3) or str (Python 2). If\n     non-unicode input is provided, the input is returned unchanged.\n     \"\"\"\n-    pass\n+    if not isinstance(s, str):\n+        return s\n+\n+    res = bytearray()\n+\n+    b64_buffer: List[str] = []\n+\n+    def consume_b64_buffer(buf: List[str]) -&gt; None:\n+        \"\"\"\n+        Consume the buffer by encoding it into a modified base 64 representation\n+        and surround it with shift characters &amp; and -\n+        \"\"\"\n+        if buf:\n+            res.extend(b\"&amp;\" + base64_utf7_encode(buf) + b\"-\")\n+            del buf[:]\n+\n+    for c in s:\n+        # printable ascii case should not be modified\n+        o = ord(c)\n+        if 0x20 &lt;= o &lt;= 0x7E:\n+            consume_b64_buffer(b64_buffer)\n+            # Special case: &amp; is used as shift character so we need to escape it in ASCII\n+            if o == 0x26:  # &amp; = 0x26\n+                res.extend(b\"&amp;-\")\n+            else:\n+                res.append(o)\n+\n+        # Bufferize characters that will be encoded in base64 and append them later\n+        # in the result, when iterating over ASCII character or the end of string\n+        else:\n+            b64_buffer.append(c)\n+\n+    # Consume the remaining buffer if the string finish with non-ASCII characters\n+    consume_b64_buffer(b64_buffer)\n+\n+    return bytes(res)\n\n\n-AMPERSAND_ORD = ord('&amp;')\n-DASH_ORD = ord('-')\n+AMPERSAND_ORD = ord(\"&amp;\")\n+DASH_ORD = ord(\"-\")\n\n\n-def decode(s: Union[bytes, str]) -&gt;str:\n+def decode(s: Union[bytes, str]) -&gt; str:\n     \"\"\"Decode a folder name from IMAP modified UTF-7 encoding to unicode.\n\n     Input is bytes (Python 3) or str (Python 2); output is always\n     unicode. If non-bytes/str input is provided, the input is returned\n     unchanged.\n     \"\"\"\n-    pass\n+    if not isinstance(s, bytes):\n+        return s\n+\n+    res = []\n+    # Store base64 substring that will be decoded once stepping on end shift character\n+    b64_buffer = bytearray()\n+    for c in s:\n+        # Shift character without anything in buffer -&gt; starts storing base64 substring\n+        if c == AMPERSAND_ORD and not b64_buffer:\n+            b64_buffer.append(c)\n+        # End shift char. -&gt; append the decoded buffer to the result and reset it\n+        elif c == DASH_ORD and b64_buffer:\n+            # Special case &amp;-, representing \"&amp;\" escaped\n+            if len(b64_buffer) == 1:\n+                res.append(\"&amp;\")\n+            else:\n+                res.append(base64_utf7_decode(b64_buffer[1:]))\n+            b64_buffer = bytearray()\n+        # Still buffering between the shift character and the shift back to ASCII\n+        elif b64_buffer:\n+            b64_buffer.append(c)\n+        # No buffer initialized yet, should be an ASCII printable char\n+        else:\n+            res.append(chr(c))\n+\n+    # Decode the remaining buffer if any\n+    if b64_buffer:\n+        res.append(base64_utf7_decode(b64_buffer[1:]))\n+\n+    return \"\".join(res)\n+\n+\n+def base64_utf7_encode(buffer: List[str]) -&gt; bytes:\n+    s = \"\".join(buffer).encode(\"utf-16be\")\n+    return binascii.b2a_base64(s).rstrip(b\"\\n=\").replace(b\"/\", b\",\")\n+\n+\n+def base64_utf7_decode(s: bytearray) -&gt; str:\n+    s_utf7 = b\"+\" + s.replace(b\",\", b\"/\") + b\"-\"\n+    return s_utf7.decode(\"utf-7\")\ndiff --git a/imapclient/imapclient.py b/imapclient/imapclient.py\nindex 1b399f1..eea281a 100644\n--- a/imapclient/imapclient.py\n+++ b/imapclient/imapclient.py\n@@ -1,3 +1,7 @@\n+# Copyright (c) 2015, Menno Smits\n+# Released subject to the New BSD License\n+# Please see http://en.wikipedia.org/wiki/BSD_licenses\n+\n import dataclasses\n import functools\n import imaplib\n@@ -12,57 +16,103 @@ from datetime import date, datetime\n from logging import getLogger, LoggerAdapter\n from operator import itemgetter\n from typing import List, Optional\n+\n from . import exceptions, imap4, response_lexer, tls\n from .datetime_util import datetime_to_INTERNALDATE, format_criteria_date\n from .imap_utf7 import decode as decode_utf7\n from .imap_utf7 import encode as encode_utf7\n from .response_parser import parse_fetch_response, parse_message_list, parse_response\n from .util import assert_imap_protocol, chunk, to_bytes, to_unicode\n-if hasattr(select, 'poll'):\n+\n+if hasattr(select, \"poll\"):\n     POLL_SUPPORT = True\n else:\n+    # Fallback to select() on systems that don't support poll()\n     POLL_SUPPORT = False\n+\n+\n logger = getLogger(__name__)\n-__all__ = ['IMAPClient', 'SocketTimeout', 'DELETED', 'SEEN', 'ANSWERED',\n-    'FLAGGED', 'DRAFT', 'RECENT']\n-if 'XLIST' not in imaplib.Commands:\n-    imaplib.Commands['XLIST'] = 'NONAUTH', 'AUTH', 'SELECTED'\n-if 'IDLE' not in imaplib.Commands:\n-    imaplib.Commands['IDLE'] = 'NONAUTH', 'AUTH', 'SELECTED'\n-if 'STARTTLS' not in imaplib.Commands:\n-    imaplib.Commands['STARTTLS'] = 'NONAUTH',\n-if 'ID' not in imaplib.Commands:\n-    imaplib.Commands['ID'] = 'NONAUTH', 'AUTH', 'SELECTED'\n-if 'UNSELECT' not in imaplib.Commands:\n-    imaplib.Commands['UNSELECT'] = 'AUTH', 'SELECTED'\n-if 'ENABLE' not in imaplib.Commands:\n-    imaplib.Commands['ENABLE'] = 'AUTH',\n-if 'MOVE' not in imaplib.Commands:\n-    imaplib.Commands['MOVE'] = 'AUTH', 'SELECTED'\n-DELETED = b'\\\\Deleted'\n-SEEN = b'\\\\Seen'\n-ANSWERED = b'\\\\Answered'\n-FLAGGED = b'\\\\Flagged'\n-DRAFT = b'\\\\Draft'\n-RECENT = b'\\\\Recent'\n-ALL = b'\\\\All'\n-ARCHIVE = b'\\\\Archive'\n-DRAFTS = b'\\\\Drafts'\n-JUNK = b'\\\\Junk'\n-SENT = b'\\\\Sent'\n-TRASH = b'\\\\Trash'\n-_POPULAR_PERSONAL_NAMESPACES = ('', ''), ('INBOX.', '.')\n-_POPULAR_SPECIAL_FOLDERS = {SENT: ('Sent', 'Sent Items', 'Sent items'),\n-    DRAFTS: ('Drafts',), ARCHIVE: ('Archive',), TRASH: ('Trash',\n-    'Deleted Items', 'Deleted Messages', 'Deleted'), JUNK: ('Junk', 'Spam')}\n-_RE_SELECT_RESPONSE = re.compile(\n-    b'\\\\[(?P&lt;key&gt;[A-Z-]+)( \\\\((?P&lt;data&gt;.*)\\\\))?\\\\]')\n\n+__all__ = [\n+    \"IMAPClient\",\n+    \"SocketTimeout\",\n+    \"DELETED\",\n+    \"SEEN\",\n+    \"ANSWERED\",\n+    \"FLAGGED\",\n+    \"DRAFT\",\n+    \"RECENT\",\n+]\n+\n+\n+# We also offer the gmail-specific XLIST command...\n+if \"XLIST\" not in imaplib.Commands:\n+    imaplib.Commands[\"XLIST\"] = (\"NONAUTH\", \"AUTH\", \"SELECTED\")\n+\n+# ...and IDLE\n+if \"IDLE\" not in imaplib.Commands:\n+    imaplib.Commands[\"IDLE\"] = (\"NONAUTH\", \"AUTH\", \"SELECTED\")\n+\n+# ..and STARTTLS\n+if \"STARTTLS\" not in imaplib.Commands:\n+    imaplib.Commands[\"STARTTLS\"] = (\"NONAUTH\",)\n+\n+# ...and ID. RFC2971 says that this command is valid in all states,\n+# but not that some servers (*cough* FastMail *cough*) don't seem to\n+# accept it in state NONAUTH.\n+if \"ID\" not in imaplib.Commands:\n+    imaplib.Commands[\"ID\"] = (\"NONAUTH\", \"AUTH\", \"SELECTED\")\n+\n+# ... and UNSELECT. RFC3691 does not specify the state but there is no\n+# reason to use the command without AUTH state and a mailbox selected.\n+if \"UNSELECT\" not in imaplib.Commands:\n+    imaplib.Commands[\"UNSELECT\"] = (\"AUTH\", \"SELECTED\")\n+\n+# .. and ENABLE.\n+if \"ENABLE\" not in imaplib.Commands:\n+    imaplib.Commands[\"ENABLE\"] = (\"AUTH\",)\n+\n+# .. and MOVE for RFC6851.\n+if \"MOVE\" not in imaplib.Commands:\n+    imaplib.Commands[\"MOVE\"] = (\"AUTH\", \"SELECTED\")\n+\n+# System flags\n+DELETED = rb\"\\Deleted\"\n+SEEN = rb\"\\Seen\"\n+ANSWERED = rb\"\\Answered\"\n+FLAGGED = rb\"\\Flagged\"\n+DRAFT = rb\"\\Draft\"\n+RECENT = rb\"\\Recent\"  # This flag is read-only\n+\n+# Special folders, see RFC6154\n+# \\Flagged is omitted because it is the same as the flag defined above\n+ALL = rb\"\\All\"\n+ARCHIVE = rb\"\\Archive\"\n+DRAFTS = rb\"\\Drafts\"\n+JUNK = rb\"\\Junk\"\n+SENT = rb\"\\Sent\"\n+TRASH = rb\"\\Trash\"\n+\n+# Personal namespaces that are common among providers\n+# used as a fallback when the server does not support the NAMESPACE capability\n+_POPULAR_PERSONAL_NAMESPACES = ((\"\", \"\"), (\"INBOX.\", \".\"))\n+\n+# Names of special folders that are common among providers\n+_POPULAR_SPECIAL_FOLDERS = {\n+    SENT: (\"Sent\", \"Sent Items\", \"Sent items\"),\n+    DRAFTS: (\"Drafts\",),\n+    ARCHIVE: (\"Archive\",),\n+    TRASH: (\"Trash\", \"Deleted Items\", \"Deleted Messages\", \"Deleted\"),\n+    JUNK: (\"Junk\", \"Spam\"),\n+}\n+\n+_RE_SELECT_RESPONSE = re.compile(rb\"\\[(?P&lt;key&gt;[A-Z-]+)( \\((?P&lt;data&gt;.*)\\))?\\]\")\n\n-class Namespace(tuple):\n\n+class Namespace(tuple):\n     def __new__(cls, personal, other, shared):\n         return tuple.__new__(cls, (personal, other, shared))\n+\n     personal = property(itemgetter(0))\n     other = property(itemgetter(1))\n     shared = property(itemgetter(2))\n@@ -79,6 +129,7 @@ class SocketTimeout:\n     timeout if the connection takes more than 15 seconds to establish but\n     read/write operations can take up to 60 seconds once the connection is done.\n     \"\"\"\n+\n     connect: float\n     read: float\n\n@@ -92,6 +143,7 @@ class MailboxQuotaRoots:\n     :ivar mailbox: the mailbox\n     :ivar quota_roots: list of quota roots associated with the mailbox\n     \"\"\"\n+\n     mailbox: str\n     quota_roots: List[str]\n\n@@ -107,6 +159,7 @@ class Quota:\n     :ivar usage: the current usage of the resource\n     :ivar limit: the maximum allowed usage of the resource\n     \"\"\"\n+\n     quota_root: str\n     resource: str\n     usage: bytes\n@@ -115,7 +168,19 @@ class Quota:\n\n def require_capability(capability):\n     \"\"\"Decorator raising CapabilityError when a capability is not available.\"\"\"\n-    pass\n+\n+    def actual_decorator(func):\n+        @functools.wraps(func)\n+        def wrapper(client, *args, **kwargs):\n+            if not client.has_capability(capability):\n+                raise exceptions.CapabilityError(\n+                    \"Server does not support {} capability\".format(capability)\n+                )\n+            return func(client, *args, **kwargs)\n+\n+        return wrapper\n+\n+    return actual_decorator\n\n\n class IMAPClient:\n@@ -168,13 +233,24 @@ class IMAPClient:\n     ...     client.login(\"bar@foo.org\", \"passwd\")\n\n     \"\"\"\n+\n+    # Those exceptions are kept for backward-compatibility, since\n+    # previous versions included these attributes as references to\n+    # imaplib original exceptions\n     Error = exceptions.IMAPClientError\n     AbortError = exceptions.IMAPClientAbortError\n     ReadOnlyError = exceptions.IMAPClientReadOnlyError\n\n-    def __init__(self, host: str, port: int=None, use_uid: bool=True, ssl:\n-        bool=True, stream: bool=False, ssl_context: Optional[ssl_lib.\n-        SSLContext]=None, timeout: Optional[float]=None):\n+    def __init__(\n+        self,\n+        host: str,\n+        port: int = None,\n+        use_uid: bool = True,\n+        ssl: bool = True,\n+        stream: bool = False,\n+        ssl_context: Optional[ssl_lib.SSLContext] = None,\n+        timeout: Optional[float] = None,\n+    ):\n         if stream:\n             if port is not None:\n                 raise ValueError(\"can't set 'port' when 'stream' True\")\n@@ -182,10 +258,14 @@ class IMAPClient:\n                 raise ValueError(\"can't use 'ssl' when 'stream' is True\")\n         elif port is None:\n             port = ssl and 993 or 143\n+\n         if ssl and port == 143:\n             logger.warning(\n-                'Attempting to establish an encrypted connection to a port (143) often used for unencrypted connections'\n-                )\n+                \"Attempting to establish an encrypted connection \"\n+                \"to a port (143) often used for unencrypted \"\n+                \"connections\"\n+            )\n+\n         self.host = host\n         self.port = port\n         self.ssl = ssl\n@@ -194,18 +274,27 @@ class IMAPClient:\n         self.use_uid = use_uid\n         self.folder_encode = True\n         self.normalise_times = True\n+\n+        # If the user gives a single timeout value, assume it is the same for\n+        # connection and read/write operations\n         if not isinstance(timeout, SocketTimeout):\n             timeout = SocketTimeout(timeout, timeout)\n+\n         self._timeout = timeout\n         self._starttls_done = False\n         self._cached_capabilities = None\n         self._idle_tag = None\n+\n         self._imap = self._create_IMAP4()\n-        logger.debug('Connected to host %s over %s', self.host, 'SSL/TLS' if\n-            ssl else 'plain text')\n+        logger.debug(\n+            \"Connected to host %s over %s\",\n+            self.host,\n+            \"SSL/TLS\" if ssl else \"plain text\",\n+        )\n+\n         self._set_read_timeout()\n-        imaplib_logger = IMAPlibLoggerAdapter(getLogger(\n-            'imapclient.imaplib'), {})\n+        # Small hack to make imaplib log everything to its own logger\n+        imaplib_logger = IMAPlibLoggerAdapter(getLogger(\"imapclient.imaplib\"), {})\n         self._imap.debug = 5\n         self._imap._mesg = imaplib_logger.debug\n\n@@ -224,7 +313,32 @@ class IMAPClient:\n             try:\n                 self.shutdown()\n             except Exception as e:\n-                logger.info('Could not close the connection cleanly: %s', e)\n+                logger.info(\"Could not close the connection cleanly: %s\", e)\n+\n+    def _create_IMAP4(self):\n+        if self.stream:\n+            return imaplib.IMAP4_stream(self.host)\n+\n+        connect_timeout = getattr(self._timeout, \"connect\", None)\n+\n+        if self.ssl:\n+            return tls.IMAP4_TLS(\n+                self.host,\n+                self.port,\n+                self.ssl_context,\n+                connect_timeout,\n+            )\n+\n+        return imap4.IMAP4WithTimeout(self.host, self.port, connect_timeout)\n+\n+    def _set_read_timeout(self):\n+        if self._timeout is not None:\n+            self.socket().settimeout(self._timeout.read)\n+\n+    @property\n+    def _sock(self):\n+        warnings.warn(\"_sock is deprecated. Use socket().\", DeprecationWarning)\n+        return self.socket()\n\n     def socket(self):\n         \"\"\"Returns socket used to connect to server.\n@@ -239,9 +353,11 @@ class IMAPClient:\n            This includes reading from and writing to the socket,\n            as they are likely to break internal bookkeeping of messages.\n         \"\"\"\n-        pass\n+        # In py2, imaplib has sslobj (for SSL connections), and sock for non-SSL.\n+        # In the py3 version it's just sock.\n+        return getattr(self._imap, \"sslobj\", self._imap.sock)\n\n-    @require_capability('STARTTLS')\n+    @require_capability(\"STARTTLS\")\n     def starttls(self, ssl_context=None):\n         \"\"\"Switch to an SSL encrypted connection by sending a STARTTLS command.\n\n@@ -259,22 +375,55 @@ class IMAPClient:\n         Raises :py:exc:`AbortError` if the server does not support STARTTLS\n         or an SSL connection is already established.\n         \"\"\"\n-        pass\n+        if self.ssl or self._starttls_done:\n+            raise exceptions.IMAPClientAbortError(\"TLS session already established\")\n+\n+        typ, data = self._imap._simple_command(\"STARTTLS\")\n+        self._checkok(\"starttls\", typ, data)\n+\n+        self._starttls_done = True\n+\n+        self._imap.sock = tls.wrap_socket(self._imap.sock, ssl_context, self.host)\n+        self._imap.file = self._imap.sock.makefile(\"rb\")\n+        return data[0]\n\n     def login(self, username: str, password: str):\n         \"\"\"Login using *username* and *password*, returning the\n         server response.\n         \"\"\"\n-        pass\n-\n-    def oauth2_login(self, user: str, access_token: str, mech: str=\n-        'XOAUTH2', vendor: Optional[str]=None):\n+        try:\n+            rv = self._command_and_check(\n+                \"login\",\n+                to_unicode(username),\n+                to_unicode(password),\n+                unpack=True,\n+            )\n+        except exceptions.IMAPClientError as e:\n+            raise exceptions.LoginError(str(e))\n+\n+        logger.debug(\"Logged in as %s\", username)\n+        return rv\n+\n+    def oauth2_login(\n+        self,\n+        user: str,\n+        access_token: str,\n+        mech: str = \"XOAUTH2\",\n+        vendor: Optional[str] = None,\n+    ):\n         \"\"\"Authenticate using the OAUTH2 or XOAUTH2 methods.\n\n         Gmail and Yahoo both support the 'XOAUTH2' mechanism, but Yahoo requires\n         the 'vendor' portion in the payload.\n         \"\"\"\n-        pass\n+        auth_string = \"user=%s\\1auth=Bearer %s\\1\" % (user, access_token)\n+        if vendor:\n+            auth_string += \"vendor=%s\\1\" % vendor\n+        auth_string += \"\\1\"\n+        try:\n+            return self._command_and_check(\"authenticate\", mech, lambda x: auth_string)\n+        except exceptions.IMAPClientError as e:\n+            raise exceptions.LoginError(str(e))\n\n     def oauthbearer_login(self, identity, access_token):\n         \"\"\"Authenticate using the OAUTHBEARER method.\n@@ -282,11 +431,35 @@ class IMAPClient:\n         This is supported by Gmail and is meant to supersede the non-standard\n         'OAUTH2' and 'XOAUTH2' mechanisms.\n         \"\"\"\n-        pass\n+        # https://tools.ietf.org/html/rfc5801#section-4\n+        # Technically this is the authorization_identity, but at least for Gmail it's\n+        # mandatory and practically behaves like the regular username/identity.\n+        if identity:\n+            gs2_header = \"n,a=%s,\" % identity.replace(\"=\", \"=3D\").replace(\",\", \"=2C\")\n+        else:\n+            gs2_header = \"n,,\"\n+        # https://tools.ietf.org/html/rfc6750#section-2.1\n+        http_authz = \"Bearer %s\" % access_token\n+        # https://tools.ietf.org/html/rfc7628#section-3.1\n+        auth_string = \"%s\\1auth=%s\\1\\1\" % (gs2_header, http_authz)\n+        try:\n+            return self._command_and_check(\n+                \"authenticate\", \"OAUTHBEARER\", lambda x: auth_string\n+            )\n+        except exceptions.IMAPClientError as e:\n+            raise exceptions.LoginError(str(e))\n\n     def plain_login(self, identity, password, authorization_identity=None):\n         \"\"\"Authenticate using the PLAIN method (requires server support).\"\"\"\n-        pass\n+        if not authorization_identity:\n+            authorization_identity = \"\"\n+        auth_string = \"%s\\0%s\\0%s\" % (authorization_identity, identity, password)\n+        try:\n+            return self._command_and_check(\n+                \"authenticate\", \"PLAIN\", lambda _: auth_string, unpack=True\n+            )\n+        except exceptions.IMAPClientError as e:\n+            raise exceptions.LoginError(str(e))\n\n     def sasl_login(self, mech_name, mech_callable):\n         \"\"\"Authenticate using a provided SASL mechanism (requires server support).\n@@ -337,21 +510,30 @@ class IMAPClient:\n\n             imap.sasl_login(\"SCRAM-SHA-256\", scram_mech)\n         \"\"\"\n-        pass\n+        try:\n+            return self._command_and_check(\n+                \"authenticate\", mech_name, mech_callable, unpack=True\n+            )\n+        except exceptions.IMAPClientError as e:\n+            raise exceptions.LoginError(str(e))\n\n     def logout(self):\n         \"\"\"Logout, returning the server response.\"\"\"\n-        pass\n+        typ, data = self._imap.logout()\n+        self._check_resp(\"BYE\", \"logout\", typ, data)\n+        logger.debug(\"Logged out, connection closed\")\n+        return data[0]\n\n-    def shutdown(self) -&gt;None:\n+    def shutdown(self) -&gt; None:\n         \"\"\"Close the connection to the IMAP server (without logging out)\n\n         In most cases, :py:meth:`.logout` should be used instead of\n         this. The logout method also shutdown down the connection.\n         \"\"\"\n-        pass\n+        self._imap.shutdown()\n+        logger.info(\"Connection closed\")\n\n-    @require_capability('ENABLE')\n+    @require_capability(\"ENABLE\")\n     def enable(self, *capabilities):\n         \"\"\"Activate one or more server side capability extensions.\n\n@@ -368,9 +550,23 @@ class IMAPClient:\n\n         See :rfc:`5161` for more details.\n         \"\"\"\n-        pass\n-\n-    @require_capability('ID')\n+        if self._imap.state != \"AUTH\":\n+            raise exceptions.IllegalStateError(\n+                \"ENABLE command illegal in state %s\" % self._imap.state\n+            )\n+\n+        resp = self._raw_command_untagged(\n+            b\"ENABLE\",\n+            [to_bytes(c) for c in capabilities],\n+            uid=False,\n+            response_name=\"ENABLED\",\n+            unpack=True,\n+        )\n+        if not resp:\n+            return []\n+        return resp.split()\n+\n+    @require_capability(\"ID\")\n     def id_(self, parameters=None):\n         \"\"\"Issue the ID command, returning a dict of server implementation\n         fields.\n@@ -378,7 +574,19 @@ class IMAPClient:\n         *parameters* should be specified as a dictionary of field/value pairs,\n         for example: ``{\"name\": \"IMAPClient\", \"version\": \"0.12\"}``\n         \"\"\"\n-        pass\n+        if parameters is None:\n+            args = \"NIL\"\n+        else:\n+            if not isinstance(parameters, dict):\n+                raise TypeError(\"'parameters' should be a dictionary\")\n+            args = seq_to_parenstr(\n+                _quote(v) for v in itertools.chain.from_iterable(parameters.items())\n+            )\n+\n+        typ, data = self._imap._simple_command(\"ID\", args)\n+        self._checkok(\"id\", typ, data)\n+        typ, data = self._imap._untagged_response(typ, data, \"ID\")\n+        return parse_response(data)\n\n     def capabilities(self):\n         \"\"\"Returns the server capability list.\n@@ -392,13 +600,51 @@ class IMAPClient:\n         If the session is not yet authenticated, the capabilities\n         requested at connection time will be returned.\n         \"\"\"\n-        pass\n+        # Ensure cached capabilities aren't used post-STARTTLS. As per\n+        # https://tools.ietf.org/html/rfc2595#section-3.1\n+        if self._starttls_done and self._imap.state == \"NONAUTH\":\n+            self._cached_capabilities = None\n+            return self._do_capabilites()\n+\n+        # If a capability response has been cached, use that.\n+        if self._cached_capabilities:\n+            return self._cached_capabilities\n+\n+        # If the server returned an untagged CAPABILITY response\n+        # (during authentication), cache it and return that.\n+        untagged = _dict_bytes_normaliser(self._imap.untagged_responses)\n+        response = untagged.pop(\"CAPABILITY\", None)\n+        if response:\n+            self._cached_capabilities = self._normalise_capabilites(response[0])\n+            return self._cached_capabilities\n+\n+        # If authenticated, but don't have a capability response, ask for one\n+        if self._imap.state in (\"SELECTED\", \"AUTH\"):\n+            self._cached_capabilities = self._do_capabilites()\n+            return self._cached_capabilities\n+\n+        # Return capabilities that imaplib requested at connection\n+        # time (pre-auth)\n+        return tuple(to_bytes(c) for c in self._imap.capabilities)\n+\n+    def _do_capabilites(self):\n+        raw_response = self._command_and_check(\"capability\", unpack=True)\n+        return self._normalise_capabilites(raw_response)\n+\n+    def _normalise_capabilites(self, raw_response):\n+        raw_response = to_bytes(raw_response)\n+        return tuple(raw_response.upper().split())\n\n     def has_capability(self, capability):\n         \"\"\"Return ``True`` if the IMAP server has the given *capability*.\"\"\"\n-        pass\n-\n-    @require_capability('NAMESPACE')\n+        # FIXME: this will not detect capabilities that are backwards\n+        # compatible with the current level. For instance the SORT\n+        # capabilities may in the future be named SORT2 which is\n+        # still compatible with the current standard and will not\n+        # be detected by this method.\n+        return to_bytes(capability).upper() in self.capabilities()\n+\n+    @require_capability(\"NAMESPACE\")\n     def namespace(self):\n         \"\"\"Return the namespace for the account as a (personal, other,\n         shared) tuple.\n@@ -412,9 +658,21 @@ class IMAPClient:\n\n         See :rfc:`2342` for more details.\n         \"\"\"\n-        pass\n-\n-    def list_folders(self, directory='', pattern='*'):\n+        data = self._command_and_check(\"namespace\")\n+        parts = []\n+        for item in parse_response(data):\n+            if item is None:\n+                parts.append(item)\n+            else:\n+                converted = []\n+                for prefix, separator in item:\n+                    if self.folder_encode:\n+                        prefix = decode_utf7(prefix)\n+                    converted.append((prefix, to_unicode(separator)))\n+                parts.append(tuple(converted))\n+        return Namespace(*parts)\n+\n+    def list_folders(self, directory=\"\", pattern=\"*\"):\n         \"\"\"Get a listing of folders on the server as a list of\n         ``(flags, delimiter, name)`` tuples.\n\n@@ -435,10 +693,10 @@ class IMAPClient:\n         decoded from modified UTF-7, except if folder_decode is not\n         set.\n         \"\"\"\n-        pass\n+        return self._do_list(\"LIST\", directory, pattern)\n\n-    @require_capability('XLIST')\n-    def xlist_folders(self, directory='', pattern='*'):\n+    @require_capability(\"XLIST\")\n+    def xlist_folders(self, directory=\"\", pattern=\"*\"):\n         \"\"\"Execute the XLIST command, returning ``(flags, delimiter,\n         name)`` tuples.\n\n@@ -467,16 +725,44 @@ class IMAPClient:\n         The *directory* and *pattern* arguments are as per\n         list_folders().\n         \"\"\"\n-        pass\n+        return self._do_list(\"XLIST\", directory, pattern)\n\n-    def list_sub_folders(self, directory='', pattern='*'):\n+    def list_sub_folders(self, directory=\"\", pattern=\"*\"):\n         \"\"\"Return a list of subscribed folders on the server as\n         ``(flags, delimiter, name)`` tuples.\n\n         The default behaviour will list all subscribed folders. The\n         *directory* and *pattern* arguments are as per list_folders().\n         \"\"\"\n-        pass\n+        return self._do_list(\"LSUB\", directory, pattern)\n+\n+    def _do_list(self, cmd, directory, pattern):\n+        directory = self._normalise_folder(directory)\n+        pattern = self._normalise_folder(pattern)\n+        typ, dat = self._imap._simple_command(cmd, directory, pattern)\n+        self._checkok(cmd, typ, dat)\n+        typ, dat = self._imap._untagged_response(typ, dat, cmd)\n+        return self._proc_folder_list(dat)\n+\n+    def _proc_folder_list(self, folder_data):\n+        # Filter out empty strings and None's.\n+        # This also deals with the special case of - no 'untagged'\n+        # responses (ie, no folders). This comes back as [None].\n+        folder_data = [item for item in folder_data if item not in (b\"\", None)]\n+\n+        ret = []\n+        parsed = parse_response(folder_data)\n+        for flags, delim, name in chunk(parsed, size=3):\n+            if isinstance(name, int):\n+                # Some IMAP implementations return integer folder names\n+                # with quotes. These get parsed to ints so convert them\n+                # back to strings.\n+                name = str(name)\n+            elif self.folder_encode:\n+                name = decode_utf7(name)\n+\n+            ret.append((flags, delim, name))\n+        return ret\n\n     def find_special_folder(self, folder_flag):\n         \"\"\"Try to locate a special folder, like the Sent or Trash folder.\n@@ -490,7 +776,27 @@ class IMAPClient:\n\n         Returns the name of the folder if found, or None otherwise.\n         \"\"\"\n-        pass\n+        # Detect folder by looking for known attributes\n+        # TODO: avoid listing all folders by using extended LIST (RFC6154)\n+        for folder in self.list_folders():\n+            if folder and len(folder[0]) &gt; 0 and folder_flag in folder[0]:\n+                return folder[2]\n+\n+        # Detect folder by looking for common names\n+        # We only look for folders in the \"personal\" namespace of the user\n+        if self.has_capability(\"NAMESPACE\"):\n+            personal_namespaces = self.namespace().personal\n+        else:\n+            personal_namespaces = _POPULAR_PERSONAL_NAMESPACES\n+\n+        for personal_namespace in personal_namespaces:\n+            for pattern in _POPULAR_SPECIAL_FOLDERS.get(folder_flag, tuple()):\n+                pattern = personal_namespace[0] + pattern\n+                sent_folders = self.list_folders(pattern=pattern)\n+                if sent_folders:\n+                    return sent_folders[0][2]\n+\n+        return None\n\n     def select_folder(self, folder, readonly=False):\n         \"\"\"Set the current folder on the server.\n@@ -510,18 +816,54 @@ class IMAPClient:\n              b'UIDNEXT': 11,\n              b'UIDVALIDITY': 1239278212}\n         \"\"\"\n-        pass\n+        self._command_and_check(\"select\", self._normalise_folder(folder), readonly)\n+        return self._process_select_response(self._imap.untagged_responses)\n\n-    @require_capability('UNSELECT')\n+    @require_capability(\"UNSELECT\")\n     def unselect_folder(self):\n-        \"\"\"Unselect the current folder and release associated resources.\n+        r\"\"\"Unselect the current folder and release associated resources.\n\n         Unlike ``close_folder``, the ``UNSELECT`` command does not expunge\n-        the mailbox, keeping messages with \\\\Deleted flag set for example.\n+        the mailbox, keeping messages with \\Deleted flag set for example.\n\n         Returns the UNSELECT response string returned by the server.\n         \"\"\"\n-        pass\n+        logger.debug(\"&lt; UNSELECT\")\n+        # IMAP4 class has no `unselect` method so we can't use `_command_and_check` there\n+        _typ, data = self._imap._simple_command(\"UNSELECT\")\n+        return data[0]\n+\n+    def _process_select_response(self, resp):\n+        untagged = _dict_bytes_normaliser(resp)\n+        out = {}\n+\n+        # imaplib doesn't parse these correctly (broken regex) so replace\n+        # with the raw values out of the OK section\n+        for line in untagged.get(\"OK\", []):\n+            match = _RE_SELECT_RESPONSE.match(line)\n+            if match:\n+                key = match.group(\"key\")\n+                if key == b\"PERMANENTFLAGS\":\n+                    out[key] = tuple(match.group(\"data\").split())\n+\n+        for key, value in untagged.items():\n+            key = key.upper()\n+            if key in (b\"OK\", b\"PERMANENTFLAGS\"):\n+                continue  # already handled above\n+            if key in (\n+                b\"EXISTS\",\n+                b\"RECENT\",\n+                b\"UIDNEXT\",\n+                b\"UIDVALIDITY\",\n+                b\"HIGHESTMODSEQ\",\n+            ):\n+                value = int(value[0])\n+            elif key == b\"READ-WRITE\":\n+                value = True\n+            elif key == b\"FLAGS\":\n+                value = tuple(value[0][1:-1].split())\n+            out[key] = value\n+        return out\n\n     def noop(self):\n         \"\"\"Execute the NOOP command.\n@@ -539,9 +881,10 @@ class IMAPClient:\n               (6, b'FETCH', (b'FLAGS', (b'sne',)))])\n\n         \"\"\"\n-        pass\n+        tag = self._imap._command(\"NOOP\")\n+        return self._consume_until_tagged_response(tag, \"NOOP\")\n\n-    @require_capability('IDLE')\n+    @require_capability(\"IDLE\")\n     def idle(self):\n         \"\"\"Put the server into IDLE mode.\n\n@@ -557,7 +900,10 @@ class IMAPClient:\n\n         See :rfc:`2177` for more information about the IDLE extension.\n         \"\"\"\n-        pass\n+        self._idle_tag = self._imap._command(\"IDLE\")\n+        resp = self._imap._get_response()\n+        if resp is not None:\n+            raise exceptions.IMAPClientError(\"Unexpected IDLE response: %s\" % resp)\n\n     def _poll_socket(self, sock, timeout=None):\n         \"\"\"\n@@ -565,7 +911,10 @@ class IMAPClient:\n         This implementation is more scalable because it ALLOWS your process\n         to have more than 1024 file descriptors.\n         \"\"\"\n-        pass\n+        poller = select.poll()\n+        poller.register(sock.fileno(), select.POLLIN)\n+        timeout = timeout * 1000 if timeout is not None else None\n+        return poller.poll(timeout)\n\n     def _select_poll_socket(self, sock, timeout=None):\n         \"\"\"\n@@ -574,9 +923,9 @@ class IMAPClient:\n         has more than 1024 file descriptors.\n         We still need this for Windows and some other niche systems.\n         \"\"\"\n-        pass\n+        return select.select([sock], [], [], timeout)[0]\n\n-    @require_capability('IDLE')\n+    @require_capability(\"IDLE\")\n     def idle_check(self, timeout=None):\n         \"\"\"Check for any IDLE responses sent by the server.\n\n@@ -595,9 +944,42 @@ class IMAPClient:\n              (1, b'EXISTS'),\n              (1, b'FETCH', (b'FLAGS', (b'\\\\NotJunk',)))]\n         \"\"\"\n-        pass\n+        sock = self.socket()\n+\n+        # make the socket non-blocking so the timeout can be\n+        # implemented for this call\n+        sock.settimeout(None)\n+        sock.setblocking(0)\n+\n+        if POLL_SUPPORT:\n+            poll_func = self._poll_socket\n+        else:\n+            poll_func = self._select_poll_socket\n\n-    @require_capability('IDLE')\n+        try:\n+            resps = []\n+            events = poll_func(sock, timeout)\n+            if events:\n+                while True:\n+                    try:\n+                        line = self._imap._get_line()\n+                    except (socket.timeout, socket.error):\n+                        break\n+                    except IMAPClient.AbortError:\n+                        # An imaplib.IMAP4.abort with \"EOF\" is raised\n+                        # under Python 3\n+                        err = sys.exc_info()[1]\n+                        if \"EOF\" in err.args[0]:\n+                            break\n+                        raise\n+                    else:\n+                        resps.append(_parse_untagged_response(line))\n+            return resps\n+        finally:\n+            sock.setblocking(1)\n+            self._set_read_timeout()\n+\n+    @require_capability(\"IDLE\")\n     def idle_done(self):\n         \"\"\"Take the server out of IDLE mode.\n\n@@ -612,7 +994,9 @@ class IMAPClient:\n         any). These are returned in parsed form as per\n         ``idle_check()``.\n         \"\"\"\n-        pass\n+        logger.debug(\"&lt; DONE\")\n+        self._imap.send(b\"DONE\\r\\n\")\n+        return self._consume_until_tagged_response(self._idle_tag, \"IDLE\")\n\n     def folder_status(self, folder, what=None):\n         \"\"\"Return the status of *folder*.\n@@ -624,39 +1008,58 @@ class IMAPClient:\n         Returns a dictionary of the status items for the folder with\n         keys matching *what*.\n         \"\"\"\n-        pass\n+        if what is None:\n+            what = (\"MESSAGES\", \"RECENT\", \"UIDNEXT\", \"UIDVALIDITY\", \"UNSEEN\")\n+        else:\n+            what = normalise_text_list(what)\n+        what_ = \"(%s)\" % (\" \".join(what))\n+\n+        fname = self._normalise_folder(folder)\n+        data = self._command_and_check(\"status\", fname, what_)\n+        response = parse_response(data)\n+        status_items = response[-1]\n+        return dict(as_pairs(status_items))\n\n     def close_folder(self):\n         \"\"\"Close the currently selected folder, returning the server\n         response string.\n         \"\"\"\n-        pass\n+        return self._command_and_check(\"close\", unpack=True)\n\n     def create_folder(self, folder):\n         \"\"\"Create *folder* on the server returning the server response string.\"\"\"\n-        pass\n+        return self._command_and_check(\n+            \"create\", self._normalise_folder(folder), unpack=True\n+        )\n\n     def rename_folder(self, old_name, new_name):\n         \"\"\"Change the name of a folder on the server.\"\"\"\n-        pass\n+        return self._command_and_check(\n+            \"rename\",\n+            self._normalise_folder(old_name),\n+            self._normalise_folder(new_name),\n+            unpack=True,\n+        )\n\n     def delete_folder(self, folder):\n         \"\"\"Delete *folder* on the server returning the server response string.\"\"\"\n-        pass\n+        return self._command_and_check(\n+            \"delete\", self._normalise_folder(folder), unpack=True\n+        )\n\n     def folder_exists(self, folder):\n         \"\"\"Return ``True`` if *folder* exists on the server.\"\"\"\n-        pass\n+        return len(self.list_folders(\"\", folder)) &gt; 0\n\n     def subscribe_folder(self, folder):\n         \"\"\"Subscribe to *folder*, returning the server response string.\"\"\"\n-        pass\n+        return self._command_and_check(\"subscribe\", self._normalise_folder(folder))\n\n     def unsubscribe_folder(self, folder):\n         \"\"\"Unsubscribe to *folder*, returning the server response string.\"\"\"\n-        pass\n+        return self._command_and_check(\"unsubscribe\", self._normalise_folder(folder))\n\n-    def search(self, criteria='ALL', charset=None):\n+    def search(self, criteria=\"ALL\", charset=None):\n         \"\"\"Return a list of messages ids from the currently selected\n         folder matching *criteria*.\n\n@@ -716,10 +1119,10 @@ class IMAPClient:\n         in the search).\n\n         \"\"\"\n-        pass\n+        return self._search(criteria, charset)\n\n-    @require_capability('X-GM-EXT-1')\n-    def gmail_search(self, query, charset='UTF-8'):\n+    @require_capability(\"X-GM-EXT-1\")\n+    def gmail_search(self, query, charset=\"UTF-8\"):\n         \"\"\"Search using Gmail's X-GM-RAW attribute.\n\n         *query* should be a valid Gmail search query string. For\n@@ -733,10 +1136,40 @@ class IMAPClient:\n         See https://developers.google.com/gmail/imap_extensions#extension_of_the_search_command_x-gm-raw\n         for more info.\n         \"\"\"\n-        pass\n+        return self._search([b\"X-GM-RAW\", query], charset)\n+\n+    def _search(self, criteria, charset):\n+        args = []\n+        if charset:\n+            args.extend([b\"CHARSET\", to_bytes(charset)])\n+        args.extend(_normalise_search_criteria(criteria, charset))\n+\n+        try:\n+            data = self._raw_command_untagged(b\"SEARCH\", args)\n+        except imaplib.IMAP4.error as e:\n+            # Make BAD IMAP responses easier to understand to the user, with a link to the docs\n+            m = re.match(r\"SEARCH command error: BAD \\[(.+)\\]\", str(e))\n+            if m:\n+                raise exceptions.InvalidCriteriaError(\n+                    \"{original_msg}\\n\\n\"\n+                    \"This error may have been caused by a syntax error in the criteria: \"\n+                    \"{criteria}\\nPlease refer to the documentation for more information \"\n+                    \"about search criteria syntax..\\n\"\n+                    \"https://imapclient.readthedocs.io/en/master/#imapclient.IMAPClient.search\".format(\n+                        original_msg=m.group(1),\n+                        criteria='\"%s\"' % criteria\n+                        if not isinstance(criteria, list)\n+                        else criteria,\n+                    )\n+                )\n+\n+            # If the exception is not from a BAD IMAP response, re-raise as-is\n+            raise\n\n-    @require_capability('SORT')\n-    def sort(self, sort_criteria, criteria='ALL', charset='UTF-8'):\n+        return parse_message_list(data)\n+\n+    @require_capability(\"SORT\")\n+    def sort(self, sort_criteria, criteria=\"ALL\", charset=\"UTF-8\"):\n         \"\"\"Return a list of message ids from the currently selected\n         folder, sorted by *sort_criteria* and optionally filtered by\n         *criteria*.\n@@ -758,9 +1191,15 @@ class IMAPClient:\n         Note that SORT is an extension to the IMAP4 standard so it may\n         not be supported by all IMAP servers.\n         \"\"\"\n-        pass\n-\n-    def thread(self, algorithm='REFERENCES', criteria='ALL', charset='UTF-8'):\n+        args = [\n+            _normalise_sort_criteria(sort_criteria),\n+            to_bytes(charset),\n+        ]\n+        args.extend(_normalise_search_criteria(criteria, charset))\n+        ids = self._raw_command_untagged(b\"SORT\", args, unpack=True)\n+        return [int(i) for i in ids.split()]\n+\n+    def thread(self, algorithm=\"REFERENCES\", criteria=\"ALL\", charset=\"UTF-8\"):\n         \"\"\"Return a list of messages threads from the currently\n         selected folder which match *criteria*.\n\n@@ -777,7 +1216,17 @@ class IMAPClient:\n\n         See :rfc:`5256` for more details.\n         \"\"\"\n-        pass\n+        algorithm = to_bytes(algorithm)\n+        if not self.has_capability(b\"THREAD=\" + algorithm):\n+            raise exceptions.CapabilityError(\n+                \"The server does not support %s threading algorithm\" % algorithm\n+            )\n+\n+        args = [algorithm, to_bytes(charset)] + _normalise_search_criteria(\n+            criteria, charset\n+        )\n+        data = self._raw_command_untagged(b\"THREAD\", args)\n+        return parse_response(data)\n\n     def get_flags(self, messages):\n         \"\"\"Return the flags set for each message in *messages* from\n@@ -786,7 +1235,8 @@ class IMAPClient:\n         The return value is a dictionary structured like this: ``{\n         msgid1: (flag1, flag2, ... ), }``.\n         \"\"\"\n-        pass\n+        response = self.fetch(messages, [\"FLAGS\"])\n+        return self._filter_fetch_dict(response, b\"FLAGS\")\n\n     def add_flags(self, messages, flags, silent=False):\n         \"\"\"Add *flags* to *messages* in the currently selected folder.\n@@ -796,7 +1246,7 @@ class IMAPClient:\n         Returns the flags set for each modified message (see\n         *get_flags*), or None if *silent* is true.\n         \"\"\"\n-        pass\n+        return self._store(b\"+FLAGS\", messages, flags, b\"FLAGS\", silent=silent)\n\n     def remove_flags(self, messages, flags, silent=False):\n         \"\"\"Remove one or more *flags* from *messages* in the currently\n@@ -807,7 +1257,7 @@ class IMAPClient:\n         Returns the flags set for each modified message (see\n         *get_flags*), or None if *silent* is true.\n         \"\"\"\n-        pass\n+        return self._store(b\"-FLAGS\", messages, flags, b\"FLAGS\", silent=silent)\n\n     def set_flags(self, messages, flags, silent=False):\n         \"\"\"Set the *flags* for *messages* in the currently selected\n@@ -818,7 +1268,7 @@ class IMAPClient:\n         Returns the flags set for each modified message (see\n         *get_flags*), or None if *silent* is true.\n         \"\"\"\n-        pass\n+        return self._store(b\"FLAGS\", messages, flags, b\"FLAGS\", silent=silent)\n\n     def get_gmail_labels(self, messages):\n         \"\"\"Return the label set for each message in *messages* in the\n@@ -830,7 +1280,9 @@ class IMAPClient:\n         This only works with IMAP servers that support the X-GM-LABELS\n         attribute (eg. Gmail).\n         \"\"\"\n-        pass\n+        response = self.fetch(messages, [b\"X-GM-LABELS\"])\n+        response = self._filter_fetch_dict(response, b\"X-GM-LABELS\")\n+        return {msg: utf7_decode_sequence(labels) for msg, labels in response.items()}\n\n     def add_gmail_labels(self, messages, labels, silent=False):\n         \"\"\"Add *labels* to *messages* in the currently selected folder.\n@@ -843,7 +1295,7 @@ class IMAPClient:\n         This only works with IMAP servers that support the X-GM-LABELS\n         attribute (eg. Gmail).\n         \"\"\"\n-        pass\n+        return self._gm_label_store(b\"+X-GM-LABELS\", messages, labels, silent=silent)\n\n     def remove_gmail_labels(self, messages, labels, silent=False):\n         \"\"\"Remove one or more *labels* from *messages* in the\n@@ -857,7 +1309,7 @@ class IMAPClient:\n         This only works with IMAP servers that support the X-GM-LABELS\n         attribute (eg. Gmail).\n         \"\"\"\n-        pass\n+        return self._gm_label_store(b\"-X-GM-LABELS\", messages, labels, silent=silent)\n\n     def set_gmail_labels(self, messages, labels, silent=False):\n         \"\"\"Set the *labels* for *messages* in the currently selected\n@@ -871,7 +1323,7 @@ class IMAPClient:\n         This only works with IMAP servers that support the X-GM-LABELS\n         attribute (eg. Gmail).\n         \"\"\"\n-        pass\n+        return self._gm_label_store(b\"X-GM-LABELS\", messages, labels, silent=silent)\n\n     def delete_messages(self, messages, silent=False):\n         \"\"\"Delete one or more *messages* from the currently selected\n@@ -880,7 +1332,7 @@ class IMAPClient:\n         Returns the flags set for each modified message (see\n         *get_flags*).\n         \"\"\"\n-        pass\n+        return self.add_flags(messages, DELETED, silent=silent)\n\n     def fetch(self, messages, data, modifiers=None):\n         \"\"\"Retrieve selected *data* associated with one or more\n@@ -922,7 +1374,22 @@ class IMAPClient:\n                     b'SEQ': 110}}\n\n         \"\"\"\n-        pass\n+        if not messages:\n+            return {}\n+\n+        args = [\n+            \"FETCH\",\n+            join_message_ids(messages),\n+            seq_to_parenstr_upper(data),\n+            seq_to_parenstr_upper(modifiers) if modifiers else None,\n+        ]\n+        if self.use_uid:\n+            args.insert(0, \"UID\")\n+        tag = self._imap._command(*args)\n+        typ, data = self._imap._command_complete(\"FETCH\", tag)\n+        self._checkok(\"fetch\", typ, data)\n+        typ, data = self._imap._untagged_response(typ, data, \"FETCH\")\n+        return parse_fetch_response(data, self.normalise_times, self.use_uid)\n\n     def append(self, folder, msg, flags=(), msg_time=None):\n         \"\"\"Append a message to *folder*.\n@@ -941,9 +1408,21 @@ class IMAPClient:\n\n         Returns the APPEND response as returned by the server.\n         \"\"\"\n-        pass\n-\n-    @require_capability('MULTIAPPEND')\n+        if msg_time:\n+            time_val = '\"%s\"' % datetime_to_INTERNALDATE(msg_time)\n+            time_val = to_unicode(time_val)\n+        else:\n+            time_val = None\n+        return self._command_and_check(\n+            \"append\",\n+            self._normalise_folder(folder),\n+            seq_to_parenstr(flags),\n+            time_val,\n+            to_bytes(msg),\n+            unpack=True,\n+        )\n+\n+    @require_capability(\"MULTIAPPEND\")\n     def multiappend(self, folder, msgs):\n         \"\"\"Append messages to *folder* using the MULTIAPPEND feature from :rfc:`3502`.\n\n@@ -955,16 +1434,40 @@ class IMAPClient:\n\n         Returns the APPEND response from the server.\n         \"\"\"\n-        pass\n+\n+        def chunks():\n+            for m in msgs:\n+                if isinstance(m, dict):\n+                    if \"flags\" in m:\n+                        yield to_bytes(seq_to_parenstr(m[\"flags\"]))\n+                    if \"date\" in m:\n+                        yield to_bytes('\"%s\"' % datetime_to_INTERNALDATE(m[\"date\"]))\n+                    yield _literal(to_bytes(m[\"msg\"]))\n+                else:\n+                    yield _literal(to_bytes(m))\n+\n+        msgs = list(chunks())\n+\n+        return self._raw_command(\n+            b\"APPEND\",\n+            [self._normalise_folder(folder)] + msgs,\n+            uid=False,\n+        )\n\n     def copy(self, messages, folder):\n         \"\"\"Copy one or more messages from the current folder to\n         *folder*. Returns the COPY response string returned by the\n         server.\n         \"\"\"\n-        pass\n-\n-    @require_capability('MOVE')\n+        return self._command_and_check(\n+            \"copy\",\n+            join_message_ids(messages),\n+            self._normalise_folder(folder),\n+            uid=True,\n+            unpack=True,\n+        )\n+\n+    @require_capability(\"MOVE\")\n     def move(self, messages, folder):\n         \"\"\"Atomically move messages to another folder.\n\n@@ -973,7 +1476,13 @@ class IMAPClient:\n         :param messages: List of message UIDs to move.\n         :param folder: The destination folder name.\n         \"\"\"\n-        pass\n+        return self._command_and_check(\n+            \"move\",\n+            join_message_ids(messages),\n+            self._normalise_folder(folder),\n+            uid=True,\n+            unpack=True,\n+        )\n\n     def expunge(self, messages=None):\n         \"\"\"Use of the *messages* argument is discouraged.\n@@ -1008,9 +1517,16 @@ class IMAPClient:\n\n         See :rfc:`4315#section-2.1` section 2.1 for more details.\n         \"\"\"\n-        pass\n-\n-    @require_capability('UIDPLUS')\n+        if messages:\n+            if not self.use_uid:\n+                raise ValueError(\"cannot EXPUNGE by ID when not using uids\")\n+            return self._command_and_check(\n+                \"EXPUNGE\", join_message_ids(messages), uid=True\n+            )\n+        tag = self._imap._command(\"EXPUNGE\")\n+        return self._consume_until_tagged_response(tag, \"EXPUNGE\")\n+\n+    @require_capability(\"UIDPLUS\")\n     def uid_expunge(self, messages):\n         \"\"\"Expunge deleted messages with the specified message ids from the\n         folder.\n@@ -1019,34 +1535,39 @@ class IMAPClient:\n\n         See :rfc:`4315#section-2.1` section 2.1 for more details.\n         \"\"\"\n-        pass\n+        return self._command_and_check(\"EXPUNGE\", join_message_ids(messages), uid=True)\n\n-    @require_capability('ACL')\n+    @require_capability(\"ACL\")\n     def getacl(self, folder):\n         \"\"\"Returns a list of ``(who, acl)`` tuples describing the\n         access controls for *folder*.\n         \"\"\"\n-        pass\n+        data = self._command_and_check(\"getacl\", self._normalise_folder(folder))\n+        parts = list(response_lexer.TokenSource(data))\n+        parts = parts[1:]  # First item is folder name\n+        return [(parts[i], parts[i + 1]) for i in range(0, len(parts), 2)]\n\n-    @require_capability('ACL')\n+    @require_capability(\"ACL\")\n     def setacl(self, folder, who, what):\n         \"\"\"Set an ACL (*what*) for user (*who*) for a folder.\n\n         Set *what* to an empty string to remove an ACL. Returns the\n         server response string.\n         \"\"\"\n-        pass\n+        return self._command_and_check(\n+            \"setacl\", self._normalise_folder(folder), who, what, unpack=True\n+        )\n\n-    @require_capability('QUOTA')\n-    def get_quota(self, mailbox='INBOX'):\n+    @require_capability(\"QUOTA\")\n+    def get_quota(self, mailbox=\"INBOX\"):\n         \"\"\"Get the quotas associated with a mailbox.\n\n         Returns a list of Quota objects.\n         \"\"\"\n-        pass\n+        return self.get_quota_root(mailbox)[1]\n\n-    @require_capability('QUOTA')\n-    def _get_quota(self, quota_root=''):\n+    @require_capability(\"QUOTA\")\n+    def _get_quota(self, quota_root=\"\"):\n         \"\"\"Get the quotas associated with a quota root.\n\n         This method is not private but put behind an underscore to show that\n@@ -1055,9 +1576,9 @@ class IMAPClient:\n\n         Returns a list of Quota objects.\n         \"\"\"\n-        pass\n+        return _parse_quota(self._command_and_check(\"getquota\", _quote(quota_root)))\n\n-    @require_capability('QUOTA')\n+    @require_capability(\"QUOTA\")\n     def get_quota_root(self, mailbox):\n         \"\"\"Get the quota roots for a mailbox.\n\n@@ -1068,22 +1589,78 @@ class IMAPClient:\n\n         Return a tuple of MailboxQuotaRoots and list of Quota associated\n         \"\"\"\n-        pass\n-\n-    @require_capability('QUOTA')\n+        quota_root_rep = self._raw_command_untagged(\n+            b\"GETQUOTAROOT\", to_bytes(mailbox), uid=False, response_name=\"QUOTAROOT\"\n+        )\n+        quota_rep = self._imap.untagged_responses.pop(\"QUOTA\", [])\n+        quota_root_rep = parse_response(quota_root_rep)\n+        quota_root = MailboxQuotaRoots(\n+            to_unicode(quota_root_rep[0]), [to_unicode(q) for q in quota_root_rep[1:]]\n+        )\n+        return quota_root, _parse_quota(quota_rep)\n+\n+    @require_capability(\"QUOTA\")\n     def set_quota(self, quotas):\n         \"\"\"Set one or more quotas on resources.\n\n         :param quotas: list of Quota objects\n         \"\"\"\n-        pass\n+        if not quotas:\n+            return\n+\n+        quota_root = None\n+        set_quota_args = []\n+\n+        for quota in quotas:\n+            if quota_root is None:\n+                quota_root = quota.quota_root\n+            elif quota_root != quota.quota_root:\n+                raise ValueError(\"set_quota only accepts a single quota root\")\n+\n+            set_quota_args.append(\"{} {}\".format(quota.resource, quota.limit))\n+\n+        set_quota_args = \" \".join(set_quota_args)\n+        args = [to_bytes(_quote(quota_root)), to_bytes(\"({})\".format(set_quota_args))]\n+\n+        response = self._raw_command_untagged(\n+            b\"SETQUOTA\", args, uid=False, response_name=\"QUOTA\"\n+        )\n+        return _parse_quota(response)\n\n     def _check_resp(self, expected, command, typ, data):\n         \"\"\"Check command responses for errors.\n\n         Raises IMAPClient.Error if the command fails.\n         \"\"\"\n-        pass\n+        if typ != expected:\n+            raise exceptions.IMAPClientError(\n+                \"%s failed: %s\" % (command, to_unicode(data[0]))\n+            )\n+\n+    def _consume_until_tagged_response(self, tag, command):\n+        tagged_commands = self._imap.tagged_commands\n+        resps = []\n+        while True:\n+            line = self._imap._get_response()\n+            if tagged_commands[tag]:\n+                break\n+            resps.append(_parse_untagged_response(line))\n+        typ, data = tagged_commands.pop(tag)\n+        self._checkok(command, typ, data)\n+        return data[0], resps\n+\n+    def _raw_command_untagged(\n+        self, command, args, response_name=None, unpack=False, uid=True\n+    ):\n+        # TODO: eventually this should replace _command_and_check (call it _command)\n+        typ, data = self._raw_command(command, args, uid=uid)\n+        if response_name is None:\n+            response_name = command\n+        typ, data = self._imap._untagged_response(typ, data, to_unicode(response_name))\n+        self._checkok(to_unicode(command), typ, data)\n+        if unpack:\n+            return data[0]\n+        return data\n\n     def _raw_command(self, command, args, uid=True):\n         \"\"\"Run the specific command with the arguments given. 8-bit arguments\n@@ -1096,23 +1673,184 @@ class IMAPClient:\n         *command* should be specified as bytes.\n         *args* should be specified as a list of bytes.\n         \"\"\"\n-        pass\n+        command = command.upper()\n+\n+        if isinstance(args, tuple):\n+            args = list(args)\n+        if not isinstance(args, list):\n+            args = [args]\n+\n+        tag = self._imap._new_tag()\n+        prefix = [to_bytes(tag)]\n+        if uid and self.use_uid:\n+            prefix.append(b\"UID\")\n+        prefix.append(command)\n+\n+        line = []\n+        for item, is_last in _iter_with_last(prefix + args):\n+            if not isinstance(item, bytes):\n+                raise ValueError(\"command args must be passed as bytes\")\n+\n+            if _is8bit(item):\n+                # If a line was already started send it\n+                if line:\n+                    out = b\" \".join(line)\n+                    logger.debug(\"&gt; %s\", out)\n+                    self._imap.send(out)\n+                    line = []\n+\n+                # Now send the (unquoted) literal\n+                if isinstance(item, _quoted):\n+                    item = item.original\n+                self._send_literal(tag, item)\n+                if not is_last:\n+                    self._imap.send(b\" \")\n+            else:\n+                line.append(item)\n+\n+        if line:\n+            out = b\" \".join(line)\n+            logger.debug(\"&gt; %s\", out)\n+            self._imap.send(out)\n+\n+        self._imap.send(b\"\\r\\n\")\n+\n+        return self._imap._command_complete(to_unicode(command), tag)\n\n     def _send_literal(self, tag, item):\n         \"\"\"Send a single literal for the command with *tag*.\"\"\"\n-        pass\n+        if b\"LITERAL+\" in self._cached_capabilities:\n+            out = b\" {\" + str(len(item)).encode(\"ascii\") + b\"+}\\r\\n\" + item\n+            logger.debug(\"&gt; %s\", debug_trunc(out, 64))\n+            self._imap.send(out)\n+            return\n+\n+        out = b\" {\" + str(len(item)).encode(\"ascii\") + b\"}\\r\\n\"\n+        logger.debug(\"&gt; %s\", out)\n+        self._imap.send(out)\n+\n+        # Wait for continuation response\n+        while self._imap._get_response():\n+            tagged_resp = self._imap.tagged_commands.get(tag)\n+            if tagged_resp:\n+                raise exceptions.IMAPClientAbortError(\n+                    \"unexpected response while waiting for continuation response: \"\n+                    + repr(tagged_resp)\n+                )\n+\n+        logger.debug(\"   (literal) &gt; %s\", debug_trunc(item, 256))\n+        self._imap.send(item)\n+\n+    def _command_and_check(\n+        self, command, *args, unpack: bool = False, uid: bool = False\n+    ):\n+        if uid and self.use_uid:\n+            command = to_unicode(command)  # imaplib must die\n+            typ, data = self._imap.uid(command, *args)\n+        else:\n+            meth = getattr(self._imap, to_unicode(command))\n+            typ, data = meth(*args)\n+        self._checkok(command, typ, data)\n+        if unpack:\n+            return data[0]\n+        return data\n+\n+    def _checkok(self, command, typ, data):\n+        self._check_resp(\"OK\", command, typ, data)\n+\n+    def _gm_label_store(self, cmd, messages, labels, silent):\n+        response = self._store(\n+            cmd, messages, self._normalise_labels(labels), b\"X-GM-LABELS\", silent=silent\n+        )\n+        return (\n+            {msg: utf7_decode_sequence(labels) for msg, labels in response.items()}\n+            if response\n+            else None\n+        )\n\n     def _store(self, cmd, messages, flags, fetch_key, silent):\n         \"\"\"Worker function for the various flag manipulation methods.\n\n         *cmd* is the STORE command to use (eg. '+FLAGS').\n         \"\"\"\n-        pass\n+        if not messages:\n+            return {}\n+        if silent:\n+            cmd += b\".SILENT\"\n+\n+        data = self._command_and_check(\n+            \"store\", join_message_ids(messages), cmd, seq_to_parenstr(flags), uid=True\n+        )\n+        if silent:\n+            return None\n+        return self._filter_fetch_dict(parse_fetch_response(data), fetch_key)\n+\n+    def _filter_fetch_dict(self, fetch_dict, key):\n+        return dict((msgid, data[key]) for msgid, data in fetch_dict.items())\n+\n+    def _normalise_folder(self, folder_name):\n+        if isinstance(folder_name, bytes):\n+            folder_name = folder_name.decode(\"ascii\")\n+        if self.folder_encode:\n+            folder_name = encode_utf7(folder_name)\n+        return _quote(folder_name)\n+\n+    def _normalise_labels(self, labels):\n+        if isinstance(labels, (str, bytes)):\n+            labels = (labels,)\n+        return [_quote(encode_utf7(label)) for label in labels]\n\n     @property\n     def welcome(self):\n         \"\"\"access the server greeting message\"\"\"\n-        pass\n+        try:\n+            return self._imap.welcome\n+        except AttributeError:\n+            pass\n+\n+\n+def _quote(arg):\n+    if isinstance(arg, str):\n+        arg = arg.replace(\"\\\\\", \"\\\\\\\\\")\n+        arg = arg.replace('\"', '\\\\\"')\n+        q = '\"'\n+    else:\n+        arg = arg.replace(b\"\\\\\", b\"\\\\\\\\\")\n+        arg = arg.replace(b'\"', b'\\\\\"')\n+        q = b'\"'\n+    return q + arg + q\n+\n+\n+def _normalise_search_criteria(criteria, charset=None):\n+    if not criteria:\n+        raise exceptions.InvalidCriteriaError(\"no criteria specified\")\n+    if not charset:\n+        charset = \"us-ascii\"\n+\n+    if isinstance(criteria, (str, bytes)):\n+        return [to_bytes(criteria, charset)]\n+\n+    out = []\n+    for item in criteria:\n+        if isinstance(item, int):\n+            out.append(str(item).encode(\"ascii\"))\n+        elif isinstance(item, (datetime, date)):\n+            out.append(format_criteria_date(item))\n+        elif isinstance(item, (list, tuple)):\n+            # Process nested criteria list and wrap in parens.\n+            inner = _normalise_search_criteria(item)\n+            inner[0] = b\"(\" + inner[0]\n+            inner[-1] = inner[-1] + b\")\"\n+            out.extend(inner)  # flatten\n+        else:\n+            out.append(_quoted.maybe(to_bytes(item, charset)))\n+    return out\n+\n+\n+def _normalise_sort_criteria(criteria, charset=None):\n+    if isinstance(criteria, (str, bytes)):\n+        criteria = [criteria]\n+    return b\"(\" + b\" \".join(to_bytes(item).upper() for item in criteria) + b\")\"\n\n\n class _literal(bytes):\n@@ -1137,14 +1875,87 @@ class _quoted(bytes):\n         holds the quoted version of the input while also providing\n         access to the original unquoted source.\n         \"\"\"\n-        pass\n+        quoted = original.replace(b\"\\\\\", b\"\\\\\\\\\")\n+        quoted = quoted.replace(b'\"', b'\\\\\"')\n+        if quoted != original or b\" \" in quoted or not quoted:\n+            out = cls(b'\"' + quoted + b'\"')\n+            out.original = original\n+            return out\n+        return original\n+\n+\n+# normalise_text_list, seq_to_parentstr etc have to return unicode\n+# because imaplib handles flags and sort criteria assuming these are\n+# passed as unicode\n+def normalise_text_list(items):\n+    return list(_normalise_text_list(items))\n+\n+\n+def seq_to_parenstr(items):\n+    return _join_and_paren(_normalise_text_list(items))\n+\n+\n+def seq_to_parenstr_upper(items):\n+    return _join_and_paren(item.upper() for item in _normalise_text_list(items))\n+\n+\n+def _join_and_paren(items):\n+    return \"(\" + \" \".join(items) + \")\"\n+\n+\n+def _normalise_text_list(items):\n+    if isinstance(items, (str, bytes)):\n+        items = (items,)\n+    return (to_unicode(c) for c in items)\n\n\n def join_message_ids(messages):\n     \"\"\"Convert a sequence of messages ids or a single integer message id\n     into an id byte string for use with IMAP commands\n     \"\"\"\n-    pass\n+    if isinstance(messages, (str, bytes, int)):\n+        messages = (to_bytes(messages),)\n+    return b\",\".join(_maybe_int_to_bytes(m) for m in messages)\n+\n+\n+def _maybe_int_to_bytes(val):\n+    if isinstance(val, int):\n+        return str(val).encode(\"us-ascii\")\n+    return to_bytes(val)\n+\n+\n+def _parse_untagged_response(text):\n+    assert_imap_protocol(text.startswith(b\"* \"))\n+    text = text[2:]\n+    if text.startswith((b\"OK \", b\"NO \")):\n+        return tuple(text.split(b\" \", 1))\n+    return parse_response([text])\n+\n+\n+def as_pairs(items):\n+    i = 0\n+    last_item = None\n+    for item in items:\n+        if i % 2:\n+            yield last_item, item\n+        else:\n+            last_item = item\n+        i += 1\n+\n+\n+def as_triplets(items):\n+    a = iter(items)\n+    return zip(a, a, a)\n+\n+\n+def _is8bit(data):\n+    return isinstance(data, _literal) or any(b &gt; 127 for b in data)\n+\n+\n+def _iter_with_last(items):\n+    last_i = len(items) - 1\n+    for i, item in enumerate(items):\n+        yield item, i == last_i\n\n\n _not_present = object()\n@@ -1157,6 +1968,12 @@ class _dict_bytes_normaliser:\n\n     def __init__(self, d):\n         self._d = d\n+\n+    def iteritems(self):\n+        for key, value in self._d.items():\n+            yield to_bytes(key), value\n+\n+    # For Python 3 compatibility.\n     items = iteritems\n\n     def __contains__(self, ink):\n@@ -1165,6 +1982,73 @@ class _dict_bytes_normaliser:\n                 return True\n         return False\n\n+    def get(self, ink, default=_not_present):\n+        for k in self._gen_keys(ink):\n+            try:\n+                return self._d[k]\n+            except KeyError:\n+                pass\n+        if default == _not_present:\n+            raise KeyError(ink)\n+        return default\n+\n+    def pop(self, ink, default=_not_present):\n+        for k in self._gen_keys(ink):\n+            try:\n+                return self._d.pop(k)\n+            except KeyError:\n+                pass\n+        if default == _not_present:\n+            raise KeyError(ink)\n+        return default\n+\n+    def _gen_keys(self, k):\n+        yield k\n+        if isinstance(k, bytes):\n+            yield to_unicode(k)\n+        else:\n+            yield to_bytes(k)\n+\n+\n+def debug_trunc(v, maxlen):\n+    if len(v) &lt; maxlen:\n+        return repr(v)\n+    hl = maxlen // 2\n+    return repr(v[:hl]) + \"...\" + repr(v[-hl:])\n+\n+\n+def utf7_decode_sequence(seq):\n+    return [decode_utf7(s) for s in seq]\n+\n+\n+def _parse_quota(quota_rep):\n+    quota_rep = parse_response(quota_rep)\n+    rv = []\n+    for quota_root, quota_resource_infos in as_pairs(quota_rep):\n+        for quota_resource_info in as_triplets(quota_resource_infos):\n+            rv.append(\n+                Quota(\n+                    quota_root=to_unicode(quota_root),\n+                    resource=to_unicode(quota_resource_info[0]),\n+                    usage=quota_resource_info[1],\n+                    limit=quota_resource_info[2],\n+                )\n+            )\n+    return rv\n+\n\n class IMAPlibLoggerAdapter(LoggerAdapter):\n     \"\"\"Adapter preventing IMAP secrets from going to the logging facility.\"\"\"\n+\n+    def process(self, msg, kwargs):\n+        # msg is usually unicode but see #367. Convert bytes to\n+        # unicode if required.\n+        if isinstance(msg, bytes):\n+            msg = msg.decode(\"ascii\", \"ignore\")\n+\n+        for command in (\"LOGIN\", \"AUTHENTICATE\"):\n+            if msg.startswith(\"&gt;\") and command in msg:\n+                msg_start = msg.split(command)[0]\n+                msg = \"{}{} **REDACTED**\".format(msg_start, command)\n+                break\n+        return super().process(msg, kwargs)\ndiff --git a/imapclient/interact.py b/imapclient/interact.py\nindex a57a825..7abdbaa 100644\n--- a/imapclient/interact.py\n+++ b/imapclient/interact.py\n@@ -1,6 +1,155 @@\n+#!/usr/bin/python\n+\n+# Copyright (c) 2020, Menno Smits\n+# Released subject to the New BSD License\n+# Please see http://en.wikipedia.org/wiki/BSD_licenses\n+\n import argparse\n from getpass import getpass\n+\n from . import imapclient\n from .config import create_client_from_config, get_config_defaults, parse_config_file\n-if __name__ == '__main__':\n+\n+\n+def command_line() -&gt; argparse.Namespace:\n+    parser = argparse.ArgumentParser()\n+    parser.add_argument(\n+        \"-H\", \"--host\", dest=\"host\", action=\"store\", help=\"IMAP host connect to\"\n+    )\n+    parser.add_argument(\n+        \"-u\",\n+        \"--username\",\n+        dest=\"username\",\n+        action=\"store\",\n+        help=\"Username to login with\",\n+    )\n+    parser.add_argument(\n+        \"-p\",\n+        \"--password\",\n+        dest=\"password\",\n+        action=\"store\",\n+        help=\"Password to login with\",\n+    )\n+    parser.add_argument(\n+        \"-P\",\n+        \"--port\",\n+        dest=\"port\",\n+        action=\"store\",\n+        type=int,\n+        default=None,\n+        help=\"IMAP port to use (default is 993 for TLS, or 143 otherwise)\",\n+    )\n+\n+    ssl_group = parser.add_mutually_exclusive_group()\n+    ssl_group.add_argument(\n+        \"-s\",\n+        \"--ssl\",\n+        dest=\"ssl\",\n+        action=\"store_true\",\n+        default=None,\n+        help=\"Use SSL/TLS connection (default)\",\n+    )\n+    ssl_group.add_argument(\n+        \"--insecure\",\n+        dest=\"insecure\",\n+        action=\"store_true\",\n+        default=False,\n+        help=\"Use insecure connection (i.e. without SSL/TLS)\",\n+    )\n+\n+    parser.add_argument(\n+        \"-f\",\n+        \"--file\",\n+        dest=\"file\",\n+        action=\"store\",\n+        default=None,\n+        help=\"Config file (same as livetest)\",\n+    )\n+\n+    args = parser.parse_args()\n+\n+    if args.file:\n+        if (\n+            args.host\n+            or args.username\n+            or args.password\n+            or args.port\n+            or args.ssl\n+            or args.insecure\n+        ):\n+            parser.error(\"If -f/--file is given no other options can be used\")\n+        # Use the options in the config file\n+        args = parse_config_file(args.file)\n+        return args\n+\n+    args.ssl = not args.insecure\n+\n+    # Scan through arguments, filling in defaults and prompting when\n+    # a compulsory argument wasn't provided.\n+    compulsory_args = (\"host\", \"username\", \"password\")\n+    for name, default_value in get_config_defaults().items():\n+        value = getattr(args, name, default_value)\n+        if name in compulsory_args and value is None:\n+            value = getpass(name + \": \")\n+        setattr(args, name, value)\n+\n+    return args\n+\n+\n+def main() -&gt; int:\n+    args = command_line()\n+    print(\"Connecting...\")\n+    client = create_client_from_config(args)\n+    print(\"Connected.\")\n+    banner = '\\nIMAPClient instance is \"c\"'\n+\n+    def ptpython(c: imapclient.IMAPClient) -&gt; None:\n+        from ptpython.repl import embed  # type: ignore[import-not-found]\n+\n+        embed(globals(), locals())\n+\n+    def ipython_400(c: imapclient.IMAPClient) -&gt; None:\n+        from IPython.terminal.embed import (  # type: ignore[import-not-found]\n+            InteractiveShellEmbed,\n+        )\n+\n+        ipshell = InteractiveShellEmbed(banner1=banner)\n+        ipshell(\"\")\n+\n+    def ipython_011(c: imapclient.IMAPClient) -&gt; None:\n+        from IPython.frontend.terminal.embed import (  # type: ignore[import-not-found]\n+            InteractiveShellEmbed,\n+        )\n+\n+        ipshell = InteractiveShellEmbed(banner1=banner)\n+        ipshell(\"\")\n+\n+    def ipython_010(c: imapclient.IMAPClient) -&gt; None:\n+        from IPython.Shell import IPShellEmbed  # type: ignore[import-not-found]\n+\n+        IPShellEmbed(\"\", banner=banner)()\n+\n+    def builtin(c: imapclient.IMAPClient) -&gt; None:\n+        import code\n+\n+        code.interact(banner, local={\"c\": c})\n+\n+    shell_attempts = (\n+        ptpython,\n+        ipython_400,\n+        ipython_011,\n+        ipython_010,\n+        builtin,\n+    )\n+    for shell in shell_attempts:\n+        try:\n+            shell(client)\n+        except ImportError:\n+            pass\n+        else:\n+            break\n+    return 0\n+\n+\n+if __name__ == \"__main__\":\n     main()\ndiff --git a/imapclient/response_lexer.py b/imapclient/response_lexer.py\nindex cd54a2b..1b7d8da 100644\n--- a/imapclient/response_lexer.py\n+++ b/imapclient/response_lexer.py\n@@ -1,20 +1,29 @@\n+# Copyright (c) 2014, Menno Smits\n+# Released subject to the New BSD License\n+# Please see http://en.wikipedia.org/wiki/BSD_licenses\n+\n \"\"\"\n A lexical analyzer class for IMAP responses.\n\n Although Lexer does all the work, TokenSource is the class to use for\n external callers.\n \"\"\"\n+\n from typing import Iterator, List, Optional, Tuple, TYPE_CHECKING, Union\n+\n from .util import assert_imap_protocol\n-__all__ = ['TokenSource']\n+\n+__all__ = [\"TokenSource\"]\n+\n CTRL_CHARS = frozenset(c for c in range(32))\n ALL_CHARS = frozenset(c for c in range(256))\n SPECIALS = frozenset(c for c in b' ()%\"[')\n NON_SPECIALS = ALL_CHARS - SPECIALS - CTRL_CHARS\n-WHITESPACE = frozenset(c for c in b' \\t\\r\\n')\n-BACKSLASH = ord('\\\\')\n-OPEN_SQUARE = ord('[')\n-CLOSE_SQUARE = ord(']')\n+WHITESPACE = frozenset(c for c in b\" \\t\\r\\n\")\n+\n+BACKSLASH = ord(\"\\\\\")\n+OPEN_SQUARE = ord(\"[\")\n+CLOSE_SQUARE = ord(\"]\")\n DOUBLE_QUOTE = ord('\"')\n\n\n@@ -28,7 +37,13 @@ class TokenSource:\n         self.lex = Lexer(text)\n         self.src = iter(self.lex)\n\n-    def __iter__(self) -&gt;Iterator[bytes]:\n+    @property\n+    def current_literal(self) -&gt; Optional[bytes]:\n+        if TYPE_CHECKING:\n+            assert self.lex.current_source is not None\n+        return self.lex.current_source.literal\n+\n+    def __iter__(self) -&gt; Iterator[bytes]:\n         return self.src\n\n\n@@ -41,26 +56,99 @@ class Lexer:\n         self.sources = (LiteralHandlingIter(chunk) for chunk in text)\n         self.current_source: Optional[LiteralHandlingIter] = None\n\n-    def __iter__(self) -&gt;Iterator[bytes]:\n+    def read_until(\n+        self, stream_i: \"PushableIterator\", end_char: int, escape: bool = True\n+    ) -&gt; bytearray:\n+        token = bytearray()\n+        try:\n+            for nextchar in stream_i:\n+                if escape and nextchar == BACKSLASH:\n+                    escaper = nextchar\n+                    nextchar = next(stream_i)\n+                    if nextchar not in (escaper, end_char):\n+                        token.append(escaper)  # Don't touch invalid escaping\n+                elif nextchar == end_char:\n+                    break\n+                token.append(nextchar)\n+            else:\n+                raise ValueError(\"No closing '%s'\" % chr(end_char))\n+        except StopIteration:\n+            raise ValueError(\"No closing '%s'\" % chr(end_char))\n+        token.append(end_char)\n+        return token\n+\n+    def read_token_stream(self, stream_i: \"PushableIterator\") -&gt; Iterator[bytearray]:\n+        whitespace = WHITESPACE\n+        wordchars = NON_SPECIALS\n+        read_until = self.read_until\n+\n+        while True:\n+            # Whitespace\n+            for nextchar in stream_i:\n+                if nextchar not in whitespace:\n+                    stream_i.push(nextchar)\n+                    break  # done skipping over the whitespace\n+\n+            # Non-whitespace\n+            token = bytearray()\n+            for nextchar in stream_i:\n+                if nextchar in wordchars:\n+                    token.append(nextchar)\n+                elif nextchar == OPEN_SQUARE:\n+                    token.append(nextchar)\n+                    token.extend(read_until(stream_i, CLOSE_SQUARE, escape=False))\n+                else:\n+                    if nextchar in whitespace:\n+                        yield token\n+                    elif nextchar == DOUBLE_QUOTE:\n+                        assert_imap_protocol(not token)\n+                        token.append(nextchar)\n+                        token.extend(read_until(stream_i, nextchar))\n+                        yield token\n+                    else:\n+                        # Other punctuation, eg. \"(\". This ends the current token.\n+                        if token:\n+                            yield token\n+                        yield bytearray([nextchar])\n+                    break\n+            else:\n+                if token:\n+                    yield token\n+                break\n+\n+    def __iter__(self) -&gt; Iterator[bytes]:\n         for source in self.sources:\n             self.current_source = source\n             for tok in self.read_token_stream(iter(source)):\n                 yield bytes(tok)\n\n\n+# imaplib has poor handling of 'literals' - it both fails to remove the\n+# {size} marker, and fails to keep responses grouped into the same logical\n+# 'line'.  What we end up with is a list of response 'records', where each\n+# record is either a simple string, or tuple of (str_with_lit, literal) -\n+# where str_with_lit is a string with the {xxx} marker at its end.  Note\n+# that each element of this list does *not* correspond 1:1 with the\n+# untagged responses.\n+# (http://bugs.python.org/issue5045 also has comments about this)\n+# So: we have a special object for each of these records.  When a\n+# string literal is processed, we peek into this object to grab the\n+# literal.\n class LiteralHandlingIter:\n-\n     def __init__(self, resp_record: Union[Tuple[bytes, bytes], bytes]):\n         self.literal: Optional[bytes]\n         if isinstance(resp_record, tuple):\n+            # A 'record' with a string which includes a literal marker, and\n+            # the literal itself.\n             self.src_text = resp_record[0]\n-            assert_imap_protocol(self.src_text.endswith(b'}'), self.src_text)\n+            assert_imap_protocol(self.src_text.endswith(b\"}\"), self.src_text)\n             self.literal = resp_record[1]\n         else:\n+            # just a line with no literals.\n             self.src_text = resp_record\n             self.literal = None\n\n-    def __iter__(self) -&gt;'PushableIterator':\n+    def __iter__(self) -&gt; \"PushableIterator\":\n         return PushableIterator(self.src_text)\n\n\n@@ -71,11 +159,16 @@ class PushableIterator:\n         self.it = iter(it)\n         self.pushed: List[int] = []\n\n-    def __iter__(self) -&gt;'PushableIterator':\n+    def __iter__(self) -&gt; \"PushableIterator\":\n         return self\n\n-    def __next__(self) -&gt;int:\n+    def __next__(self) -&gt; int:\n         if self.pushed:\n             return self.pushed.pop()\n         return next(self.it)\n+\n+    # For Python 2 compatibility\n     next = __next__\n+\n+    def push(self, item: int) -&gt; None:\n+        self.pushed.append(item)\ndiff --git a/imapclient/response_parser.py b/imapclient/response_parser.py\nindex f632411..9f29e4c 100644\n--- a/imapclient/response_parser.py\n+++ b/imapclient/response_parser.py\n@@ -1,34 +1,45 @@\n+# Copyright (c) 2014, Menno Smits\n+# Released subject to the New BSD License\n+# Please see http://en.wikipedia.org/wiki/BSD_licenses\n+\n \"\"\"\n Parsing for IMAP command responses with focus on FETCH responses as\n returned by imaplib.\n\n Initially inspired by http://effbot.org/zone/simple-iterator-parser.htm\n \"\"\"\n+\n+# TODO more exact error reporting\n+\n import datetime\n import re\n import sys\n from collections import defaultdict\n from typing import cast, Dict, Iterator, List, Optional, Tuple, TYPE_CHECKING, Union\n+\n from .datetime_util import parse_to_datetime\n from .exceptions import ProtocolError\n from .response_lexer import TokenSource\n from .response_types import Address, BodyData, Envelope, SearchIds\n from .typing_imapclient import _Atom\n-__all__ = ['parse_response', 'parse_message_list']\n+\n+__all__ = [\"parse_response\", \"parse_message_list\"]\n\n\n-def parse_response(data: List[bytes]) -&gt;Tuple[_Atom, ...]:\n+def parse_response(data: List[bytes]) -&gt; Tuple[_Atom, ...]:\n     \"\"\"Pull apart IMAP command responses.\n\n     Returns nested tuples of appropriately typed objects.\n     \"\"\"\n-    pass\n+    if data == [None]:\n+        return tuple()\n+    return tuple(gen_parsed_response(data))\n\n\n-_msg_id_pattern = re.compile('(\\\\d+(?: +\\\\d+)*)')\n+_msg_id_pattern = re.compile(r\"(\\d+(?: +\\d+)*)\")\n\n\n-def parse_message_list(data: List[Union[bytes, str]]) -&gt;SearchIds:\n+def parse_message_list(data: List[Union[bytes, str]]) -&gt; SearchIds:\n     \"\"\"Parse a list of message ids and return them as a list.\n\n     parse_response is also capable of doing this but this is\n@@ -39,18 +50,238 @@ def parse_message_list(data: List[Union[bytes, str]]) -&gt;SearchIds:\n     attribute which contains the MODSEQ response (if returned by the\n     server).\n     \"\"\"\n-    pass\n+    if len(data) != 1:\n+        raise ValueError(\"unexpected message list data\")\n+\n+    message_data = data[0]\n+    if not message_data:\n+        return SearchIds()\n+\n+    if isinstance(message_data, bytes):\n+        message_data = message_data.decode(\"ascii\")\n+\n+    m = _msg_id_pattern.match(message_data)\n+    if not m:\n+        raise ValueError(\"unexpected message list format\")\n+\n+    ids = SearchIds(int(n) for n in m.group(1).split())\n\n+    # Parse any non-numeric part on the end using parse_response (this\n+    # is likely to be the MODSEQ section).\n+    extra = message_data[m.end(1) :]\n+    if extra:\n+        for item in parse_response([extra.encode(\"ascii\")]):\n+            if (\n+                isinstance(item, tuple)\n+                and len(item) == 2\n+                and cast(bytes, item[0]).lower() == b\"modseq\"\n+            ):\n+                if TYPE_CHECKING:\n+                    assert isinstance(item[1], int)\n+                ids.modseq = item[1]\n+            elif isinstance(item, int):\n+                ids.append(item)\n+    return ids\n\n-_ParseFetchResponseInnerDict = Dict[bytes, Optional[Union[datetime.datetime,\n-    int, BodyData, Envelope, _Atom]]]\n\n+def gen_parsed_response(text: List[bytes]) -&gt; Iterator[_Atom]:\n+    if not text:\n+        return\n+    src = TokenSource(text)\n\n-def parse_fetch_response(text: List[bytes], normalise_times: bool=True,\n-    uid_is_key: bool=True) -&gt;'defaultdict[int, _ParseFetchResponseInnerDict]':\n+    token = None\n+    try:\n+        for token in src:\n+            yield atom(src, token)\n+    except ProtocolError:\n+        raise\n+    except ValueError:\n+        _, err, _ = sys.exc_info()\n+        raise ProtocolError(\"%s: %r\" % (str(err), token))\n+\n+\n+_ParseFetchResponseInnerDict = Dict[\n+    bytes, Optional[Union[datetime.datetime, int, BodyData, Envelope, _Atom]]\n+]\n+\n+\n+def parse_fetch_response(\n+    text: List[bytes], normalise_times: bool = True, uid_is_key: bool = True\n+) -&gt; \"defaultdict[int, _ParseFetchResponseInnerDict]\":\n     \"\"\"Pull apart IMAP FETCH responses as returned by imaplib.\n\n     Returns a dictionary, keyed by message ID. Each value a dictionary\n     keyed by FETCH field type (eg.\"RFC822\").\n     \"\"\"\n-    pass\n+    if text == [None]:\n+        return defaultdict()\n+    response = gen_parsed_response(text)\n+\n+    parsed_response: \"defaultdict[int, _ParseFetchResponseInnerDict]\" = defaultdict(\n+        dict\n+    )\n+    while True:\n+        try:\n+            msg_id = seq = _int_or_error(next(response), \"invalid message ID\")\n+        except StopIteration:\n+            break\n+\n+        try:\n+            msg_response = next(response)\n+        except StopIteration:\n+            raise ProtocolError(\"unexpected EOF\")\n+\n+        if not isinstance(msg_response, tuple):\n+            raise ProtocolError(\"bad response type: %s\" % repr(msg_response))\n+        if len(msg_response) % 2:\n+            raise ProtocolError(\n+                \"uneven number of response items: %s\" % repr(msg_response)\n+            )\n+\n+        # always return the sequence of the message, so it is available\n+        # even if we return keyed by UID.\n+        msg_data: _ParseFetchResponseInnerDict = {b\"SEQ\": seq}\n+        for i in range(0, len(msg_response), 2):\n+            msg_attribute = msg_response[i]\n+            if TYPE_CHECKING:\n+                assert isinstance(msg_attribute, bytes)\n+            word = msg_attribute.upper()\n+            value = msg_response[i + 1]\n+\n+            if word == b\"UID\":\n+                uid = _int_or_error(value, \"invalid UID\")\n+                if uid_is_key:\n+                    msg_id = uid\n+                else:\n+                    msg_data[word] = uid\n+            elif word == b\"INTERNALDATE\":\n+                msg_data[word] = _convert_INTERNALDATE(value, normalise_times)\n+            elif word == b\"ENVELOPE\":\n+                msg_data[word] = _convert_ENVELOPE(value, normalise_times)\n+            elif word in (b\"BODY\", b\"BODYSTRUCTURE\"):\n+                if TYPE_CHECKING:\n+                    assert isinstance(value, tuple)\n+                msg_data[word] = BodyData.create(value)\n+            else:\n+                msg_data[word] = value\n+\n+        parsed_response[msg_id].update(msg_data)\n+\n+    return parsed_response\n+\n+\n+def _int_or_error(value: _Atom, error_text: str) -&gt; int:\n+    try:\n+        return int(value)  # type: ignore[arg-type]\n+    except (TypeError, ValueError):\n+        raise ProtocolError(\"%s: %s\" % (error_text, repr(value)))\n+\n+\n+def _convert_INTERNALDATE(\n+    date_string: _Atom, normalise_times: bool = True\n+) -&gt; Optional[datetime.datetime]:\n+    if date_string is None:\n+        return None\n+\n+    try:\n+        if TYPE_CHECKING:\n+            assert isinstance(date_string, bytes)\n+        return parse_to_datetime(date_string, normalise=normalise_times)\n+    except ValueError:\n+        return None\n+\n+\n+def _convert_ENVELOPE(\n+    envelope_response: _Atom, normalise_times: bool = True\n+) -&gt; Envelope:\n+    if TYPE_CHECKING:\n+        assert isinstance(envelope_response, tuple)\n+    dt = None\n+    if envelope_response[0]:\n+        try:\n+            if TYPE_CHECKING:\n+                assert isinstance(envelope_response[0], bytes)\n+            dt = parse_to_datetime(\n+                envelope_response[0],\n+                normalise=normalise_times,\n+            )\n+        except ValueError:\n+            pass\n+\n+    subject = envelope_response[1]\n+    in_reply_to = envelope_response[8]\n+    message_id = envelope_response[9]\n+    if TYPE_CHECKING:\n+        assert isinstance(subject, bytes)\n+        assert isinstance(in_reply_to, bytes)\n+        assert isinstance(message_id, bytes)\n+\n+    # addresses contains a tuple of addresses\n+    # from, sender, reply_to, to, cc, bcc headers\n+    addresses: List[Optional[Tuple[Address, ...]]] = []\n+    for addr_list in envelope_response[2:8]:\n+        addrs = []\n+        if addr_list:\n+            if TYPE_CHECKING:\n+                assert isinstance(addr_list, tuple)\n+            for addr_tuple in addr_list:\n+                if TYPE_CHECKING:\n+                    assert isinstance(addr_tuple, tuple)\n+                if addr_tuple:\n+                    if TYPE_CHECKING:\n+                        addr_tuple = cast(Tuple[bytes, bytes, bytes, bytes], addr_tuple)\n+                    addrs.append(Address(*addr_tuple))\n+            addresses.append(tuple(addrs))\n+        else:\n+            addresses.append(None)\n+\n+    return Envelope(\n+        date=dt,\n+        subject=subject,\n+        from_=addresses[0],\n+        sender=addresses[1],\n+        reply_to=addresses[2],\n+        to=addresses[3],\n+        cc=addresses[4],\n+        bcc=addresses[5],\n+        in_reply_to=in_reply_to,\n+        message_id=message_id,\n+    )\n+\n+\n+def atom(src: TokenSource, token: bytes) -&gt; _Atom:\n+    if token == b\"(\":\n+        return parse_tuple(src)\n+    if token == b\"NIL\":\n+        return None\n+    if token[:1] == b\"{\":\n+        literal_len = int(token[1:-1])\n+        literal_text = src.current_literal\n+        if literal_text is None:\n+            raise ProtocolError(\"No literal corresponds to %r\" % token)\n+        if len(literal_text) != literal_len:\n+            raise ProtocolError(\n+                \"Expecting literal of size %d, got %d\"\n+                % (literal_len, len(literal_text))\n+            )\n+        return literal_text\n+    if len(token) &gt;= 2 and (token[:1] == token[-1:] == b'\"'):\n+        return token[1:-1]\n+    if token.isdigit() and (token[:1] != b\"0\" or len(token) == 1):\n+        # this prevents converting items like 0123 to 123\n+        return int(token)\n+    return token\n+\n+\n+def parse_tuple(src: TokenSource) -&gt; _Atom:\n+    out: List[_Atom] = []\n+    for token in src:\n+        if token == b\")\":\n+            return tuple(out)\n+        out.append(atom(src, token))\n+    # no terminator\n+    raise ProtocolError('Tuple incomplete before \"(%s\"' % _fmt_tuple(out))\n+\n+\n+def _fmt_tuple(t: List[_Atom]) -&gt; str:\n+    return \" \".join(str(item) for item in t)\ndiff --git a/imapclient/response_types.py b/imapclient/response_types.py\nindex 7d95b73..cd4631d 100644\n--- a/imapclient/response_types.py\n+++ b/imapclient/response_types.py\n@@ -1,25 +1,30 @@\n+# Copyright (c) 2014, Menno Smits\n+# Released subject to the New BSD License\n+# Please see http://en.wikipedia.org/wiki/BSD_licenses\n+\n import dataclasses\n import datetime\n from email.utils import formataddr\n from typing import Any, List, Optional, Tuple, TYPE_CHECKING, Union\n+\n from .typing_imapclient import _Atom\n from .util import to_unicode\n\n\n @dataclasses.dataclass\n class Envelope:\n-    \"\"\"Represents envelope structures of messages. Returned when parsing\n+    r\"\"\"Represents envelope structures of messages. Returned when parsing\n     ENVELOPE responses.\n\n     :ivar date: A datetime instance that represents the \"Date\" header.\n     :ivar subject: A string that contains the \"Subject\" header.\n-    :ivar from\\\\_: A tuple of Address objects that represent one or more\n+    :ivar from\\_: A tuple of Address objects that represent one or more\n       addresses from the \"From\" header, or None if header does not exist.\n-    :ivar sender: As for from\\\\_ but represents the \"Sender\" header.\n-    :ivar reply_to: As for from\\\\_ but represents the \"Reply-To\" header.\n-    :ivar to: As for from\\\\_ but represents the \"To\" header.\n-    :ivar cc: As for from\\\\_ but represents the \"Cc\" header.\n-    :ivar bcc: As for from\\\\_ but represents the \"Bcc\" recipients.\n+    :ivar sender: As for from\\_ but represents the \"Sender\" header.\n+    :ivar reply_to: As for from\\_ but represents the \"Reply-To\" header.\n+    :ivar to: As for from\\_ but represents the \"To\" header.\n+    :ivar cc: As for from\\_ but represents the \"Cc\" header.\n+    :ivar bcc: As for from\\_ but represents the \"Bcc\" recipients.\n     :ivar in_reply_to: A string that contains the \"In-Reply-To\" header.\n     :ivar message_id: A string that contains the \"Message-Id\" header.\n\n@@ -50,12 +55,12 @@ class Envelope:\n     \"\"\"\n     date: Optional[datetime.datetime]\n     subject: bytes\n-    from_: Optional[Tuple['Address', ...]]\n-    sender: Optional[Tuple['Address', ...]]\n-    reply_to: Optional[Tuple['Address', ...]]\n-    to: Optional[Tuple['Address', ...]]\n-    cc: Optional[Tuple['Address', ...]]\n-    bcc: Optional[Tuple['Address', ...]]\n+    from_: Optional[Tuple[\"Address\", ...]]\n+    sender: Optional[Tuple[\"Address\", ...]]\n+    reply_to: Optional[Tuple[\"Address\", ...]]\n+    to: Optional[Tuple[\"Address\", ...]]\n+    cc: Optional[Tuple[\"Address\", ...]]\n+    bcc: Optional[Tuple[\"Address\", ...]]\n     in_reply_to: bytes\n     message_id: bytes\n\n@@ -83,16 +88,18 @@ class Address:\n     See also :py:class:`Envelope` for information about handling of\n     \"group syntax\".\n     \"\"\"\n+\n     name: bytes\n     route: bytes\n     mailbox: bytes\n     host: bytes\n\n-    def __str__(self) -&gt;str:\n+    def __str__(self) -&gt; str:\n         if self.mailbox and self.host:\n-            address = to_unicode(self.mailbox) + '@' + to_unicode(self.host)\n+            address = to_unicode(self.mailbox) + \"@\" + to_unicode(self.host)\n         else:\n             address = to_unicode(self.mailbox or self.host)\n+\n         return formataddr((to_unicode(self.name), address))\n\n\n@@ -110,10 +117,32 @@ class SearchIds(List[int]):\n         self.modseq: Optional[int] = None\n\n\n-_BodyDataType = Tuple[Union[bytes, int, 'BodyData'], '_BodyDataType']\n+_BodyDataType = Tuple[Union[bytes, int, \"BodyData\"], \"_BodyDataType\"]\n\n\n class BodyData(_BodyDataType):\n     \"\"\"\n     Returned when parsing BODY and BODYSTRUCTURE responses.\n     \"\"\"\n+\n+    @classmethod\n+    def create(cls, response: Tuple[_Atom, ...]) -&gt; \"BodyData\":\n+        # In case of multipart messages we will see at least 2 tuples\n+        # at the start. Nest these in to a list so that the returned\n+        # response tuple always has a consistent number of elements\n+        # regardless of whether the message is multipart or not.\n+        if isinstance(response[0], tuple):\n+            # Multipart, find where the message part tuples stop\n+            parts = []\n+            for i, part in enumerate(response):\n+                if isinstance(part, bytes):\n+                    break\n+                if TYPE_CHECKING:\n+                    assert isinstance(part, tuple)\n+                parts.append(part)\n+            return cls(([cls.create(part) for part in parts],) + response[i:])\n+        return cls(response)\n+\n+    @property\n+    def is_multipart(self) -&gt; bool:\n+        return isinstance(self[0], list)\ndiff --git a/imapclient/testable_imapclient.py b/imapclient/testable_imapclient.py\nindex c605b90..c583274 100644\n--- a/imapclient/testable_imapclient.py\n+++ b/imapclient/testable_imapclient.py\n@@ -1,5 +1,10 @@\n+# Copyright (c) 2014, Menno Smits\n+# Released subject to the New BSD License\n+# Please see http://en.wikipedia.org/wiki/BSD_licenses\n+\n from typing import Any, Dict\n from unittest.mock import Mock\n+\n from .imapclient import IMAPClient\n\n\n@@ -12,15 +17,23 @@ class TestableIMAPClient(IMAPClient):\n     IMAP account.\n     \"\"\"\n\n-    def __init__(self) -&gt;None:\n-        super().__init__('somehost')\n+    def __init__(self) -&gt; None:\n+        super().__init__(\"somehost\")\n\n+    def _create_IMAP4(self) -&gt; \"MockIMAP4\":\n+        return MockIMAP4()\n\n-class MockIMAP4(Mock):\n\n+class MockIMAP4(Mock):\n     def __init__(self, *args: Any, **kwargs: Any):\n         super().__init__(*args, **kwargs)\n         self.use_uid = True\n-        self.sent = b''\n+        self.sent = b\"\"  # Accumulates what was given to send()\n         self.tagged_commands: Dict[Any, Any] = {}\n         self._starttls_done = False\n+\n+    def send(self, data: bytes) -&gt; None:\n+        self.sent += data\n+\n+    def _new_tag(self) -&gt; str:\n+        return \"tag\"\ndiff --git a/imapclient/tls.py b/imapclient/tls.py\nindex a700b1a..fe9671e 100644\n--- a/imapclient/tls.py\n+++ b/imapclient/tls.py\n@@ -1,25 +1,68 @@\n+# Copyright (c) 2023, Menno Smits\n+# Released subject to the New BSD License\n+# Please see http://en.wikipedia.org/wiki/BSD_licenses\n+\n \"\"\"\n This module contains IMAPClient's functionality related to Transport\n Layer Security (TLS a.k.a. SSL).\n \"\"\"\n+\n import imaplib\n import io\n import socket\n import ssl\n from typing import Optional, TYPE_CHECKING\n+\n if TYPE_CHECKING:\n     from typing_extensions import Buffer\n\n\n+def wrap_socket(\n+    sock: socket.socket, ssl_context: Optional[ssl.SSLContext], host: str\n+) -&gt; socket.socket:\n+    if ssl_context is None:\n+        ssl_context = ssl.create_default_context(purpose=ssl.Purpose.SERVER_AUTH)\n+\n+    return ssl_context.wrap_socket(sock, server_hostname=host)\n+\n+\n class IMAP4_TLS(imaplib.IMAP4):\n     \"\"\"IMAP4 client class for TLS/SSL connections.\n\n     Adapted from imaplib.IMAP4_SSL.\n     \"\"\"\n\n-    def __init__(self, host: str, port: int, ssl_context: Optional[ssl.\n-        SSLContext], timeout: Optional[float]=None):\n+    def __init__(\n+        self,\n+        host: str,\n+        port: int,\n+        ssl_context: Optional[ssl.SSLContext],\n+        timeout: Optional[float] = None,\n+    ):\n         self.ssl_context = ssl_context\n         self._timeout = timeout\n         imaplib.IMAP4.__init__(self, host, port)\n         self.file: io.BufferedReader\n+\n+    def open(\n+        self, host: str = \"\", port: int = 993, timeout: Optional[float] = None\n+    ) -&gt; None:\n+        self.host = host\n+        self.port = port\n+        sock = socket.create_connection(\n+            (host, port), timeout if timeout is not None else self._timeout\n+        )\n+        self.sock = wrap_socket(sock, self.ssl_context, host)\n+        self.file = self.sock.makefile(\"rb\")\n+\n+    def read(self, size: int) -&gt; bytes:\n+        return self.file.read(size)\n+\n+    def readline(self) -&gt; bytes:\n+        return self.file.readline()\n+\n+    def send(self, data: \"Buffer\") -&gt; None:\n+        self.sock.sendall(data)\n+\n+    def shutdown(self) -&gt; None:\n+        imaplib.IMAP4.shutdown(self)\ndiff --git a/imapclient/typing_imapclient.py b/imapclient/typing_imapclient.py\nindex 2fcbe01..a9fc1af 100644\n--- a/imapclient/typing_imapclient.py\n+++ b/imapclient/typing_imapclient.py\n@@ -1,3 +1,4 @@\n from typing import Tuple, Union\n+\n _AtomPart = Union[None, int, bytes]\n-_Atom = Union[_AtomPart, Tuple['_Atom', ...]]\n+_Atom = Union[_AtomPart, Tuple[\"_Atom\", ...]]\ndiff --git a/imapclient/util.py b/imapclient/util.py\nindex 5e3fab3..8f9aa35 100644\n--- a/imapclient/util.py\n+++ b/imapclient/util.py\n@@ -1,6 +1,50 @@\n+# Copyright (c) 2015, Menno Smits\n+# Released subject to the New BSD License\n+# Please see http://en.wikipedia.org/wiki/BSD_licenses\n+\n import logging\n from typing import Iterator, Optional, Tuple, Union\n+\n from . import exceptions\n+\n logger = logging.getLogger(__name__)\n+\n+\n+def to_unicode(s: Union[bytes, str]) -&gt; str:\n+    if isinstance(s, bytes):\n+        try:\n+            return s.decode(\"ascii\")\n+        except UnicodeDecodeError:\n+            logger.warning(\n+                \"An error occurred while decoding %s in ASCII 'strict' mode. Fallback to \"\n+                \"'ignore' errors handling, some characters might have been stripped\",\n+                s,\n+            )\n+            return s.decode(\"ascii\", \"ignore\")\n+    return s\n+\n+\n+def to_bytes(s: Union[bytes, str], charset: str = \"ascii\") -&gt; bytes:\n+    if isinstance(s, str):\n+        return s.encode(charset)\n+    return s\n+\n+\n+def assert_imap_protocol(condition: bool, message: Optional[bytes] = None) -&gt; None:\n+    if not condition:\n+        msg = \"Server replied with a response that violates the IMAP protocol\"\n+        if message:\n+            # FIXME(jlvillal): This looks wrong as it repeats `msg` twice\n+            msg += \"{}: {}\".format(\n+                msg, message.decode(encoding=\"ascii\", errors=\"ignore\")\n+            )\n+        raise exceptions.ProtocolError(msg)\n+\n+\n _TupleAtomPart = Union[None, int, bytes]\n-_TupleAtom = Tuple[Union[_TupleAtomPart, '_TupleAtom'], ...]\n+_TupleAtom = Tuple[Union[_TupleAtomPart, \"_TupleAtom\"], ...]\n+\n+\n+def chunk(lst: _TupleAtom, size: int) -&gt; Iterator[_TupleAtom]:\n+    for i in range(0, len(lst), size):\n+        yield lst[i : i + size]\ndiff --git a/imapclient/version.py b/imapclient/version.py\nindex 9e7d8dc..c97dfb6 100644\n--- a/imapclient/version.py\n+++ b/imapclient/version.py\n@@ -1,7 +1,24 @@\n+# Copyright (c) 2022, Menno Smits\n+# Released subject to the New BSD License\n+# Please see http://en.wikipedia.org/wiki/BSD_licenses\n+\n from typing import Tuple\n-version_info = 3, 0, 1, 'final'\n+\n+version_info = (3, 0, 1, \"final\")\n+\n+\n+def _imapclient_version_string(vinfo: Tuple[int, int, int, str]) -&gt; str:\n+    major, minor, micro, releaselevel = vinfo\n+    v = \"%d.%d.%d\" % (major, minor, micro)\n+    if releaselevel != \"final\":\n+        v += \"-\" + releaselevel\n+    return v\n+\n+\n version = _imapclient_version_string(version_info)\n-maintainer = 'IMAPClient Maintainers'\n-maintainer_email = 'imapclient@groups.io'\n-author = 'Menno Finlay-Smits'\n-author_email = 'inbox@menno.io'\n+\n+maintainer = \"IMAPClient Maintainers\"\n+maintainer_email = \"imapclient@groups.io\"\n+\n+author = \"Menno Finlay-Smits\"\n+author_email = \"inbox@menno.io\"\n</code></pre>"},{"location":"analysis_reference_jinja/","title":"Analysis reference jinja","text":"<p>back to reference summary</p>"},{"location":"analysis_reference_jinja/#submission-name-reference","title":"Submission Name: reference","text":""},{"location":"analysis_reference_jinja/#repository-jinja","title":"Repository: jinja","text":""},{"location":"analysis_reference_jinja/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count passed 851 total 851 collected 851"},{"location":"analysis_reference_jinja/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_reference_jinja/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/src/jinja2/_identifier.py b/src/jinja2/_identifier.py\nindex 503c0e8..928c150 100644\n--- a/src/jinja2/_identifier.py\n+++ b/src/jinja2/_identifier.py\n@@ -1,4 +1,6 @@\n import re\n+\n+# generated by scripts/generate_identifier_pattern.py\n pattern = re.compile(\n-    '[\\\\w\u00b7\u0300-\u036f\u0387\u0483-\u0487\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065f\u0670\u06d6-\u06dc\u06df-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u07fd\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0859-\u085b\u08d3-\u08e1\u08e3-\u0903\u093a-\u093c\u093e-\u094f\u0951-\u0957\u0962\u0963\u0981-\u0983\u09bc\u09be-\u09c4\u09c7\u09c8\u09cb-\u09cd\u09d7\u09e2\u09e3\u09fe\u0a01-\u0a03\u0a3c\u0a3e-\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81-\u0a83\u0abc\u0abe-\u0ac5\u0ac7-\u0ac9\u0acb-\u0acd\u0ae2\u0ae3\u0afa-\u0aff\u0b01-\u0b03\u0b3c\u0b3e-\u0b44\u0b47\u0b48\u0b4b-\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe-\u0bc2\u0bc6-\u0bc8\u0bca-\u0bcd\u0bd7\u0c00-\u0c04\u0c3e-\u0c44\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0c81-\u0c83\u0cbc\u0cbe-\u0cc4\u0cc6-\u0cc8\u0cca-\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d00-\u0d03\u0d3b\u0d3c\u0d3e-\u0d44\u0d46-\u0d48\u0d4a-\u0d4d\u0d57\u0d62\u0d63\u0d82\u0d83\u0dca\u0dcf-\u0dd4\u0dd6\u0dd8-\u0ddf\u0df2\u0df3\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f3e\u0f3f\u0f71-\u0f84\u0f86\u0f87\u0f8d-\u0f97\u0f99-\u0fbc\u0fc6\u102b-\u103e\u1056-\u1059\u105e-\u1060\u1062-\u1064\u1067-\u106d\u1071-\u1074\u1082-\u108d\u108f\u109a-\u109d\u135d-\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b4-\u17d3\u17dd\u180b-\u180d\u1885\u1886\u18a9\u1920-\u192b\u1930-\u193b\u1a17-\u1a1b\u1a55-\u1a5e\u1a60-\u1a7c\u1a7f\u1ab0-\u1abd\u1b00-\u1b04\u1b34-\u1b44\u1b6b-\u1b73\u1b80-\u1b82\u1ba1-\u1bad\u1be6-\u1bf3\u1c24-\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce8\u1ced\u1cf2-\u1cf4\u1cf7-\u1cf9\u1dc0-\u1df9\u1dfb-\u1dff\u203f\u2040\u2054\u20d0-\u20dc\u20e1\u20e5-\u20f0\u2118\u212e\u2cef-\u2cf1\u2d7f\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f\ua674-\ua67d\ua69e\ua69f\ua6f0\ua6f1\ua802\ua806\ua80b\ua823-\ua827\ua880\ua881\ua8b4-\ua8c5\ua8e0-\ua8f1\ua8ff\ua926-\ua92d\ua947-\ua953\ua980-\ua983\ua9b3-\ua9c0\ua9e5\uaa29-\uaa36\uaa43\uaa4c\uaa4d\uaa7b-\uaa7d\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uaaeb-\uaaef\uaaf5\uaaf6\uabe3-\uabea\uabec\uabed\ufb1e\ufe00-\ufe0f\ufe20-\ufe2f\ufe33\ufe34\ufe4d-\ufe4f\uff3f\ud800\uddfd\ud800\udee0\ud800\udf76-\ud800\udf7a\ud802\ude01-\ud802\ude03\ud802\ude05\ud802\ude06\ud802\ude0c-\ud802\ude0f\ud802\ude38-\ud802\ude3a\ud802\ude3f\ud802\udee5\ud802\udee6\ud803\udd24-\ud803\udd27\ud803\udf46-\ud803\udf50\ud804\udc00-\ud804\udc02\ud804\udc38-\ud804\udc46\ud804\udc7f-\ud804\udc82\ud804\udcb0-\ud804\udcba\ud804\udd00-\ud804\udd02\ud804\udd27-\ud804\udd34\ud804\udd45\ud804\udd46\ud804\udd73\ud804\udd80-\ud804\udd82\ud804\uddb3-\ud804\uddc0\ud804\uddc9-\ud804\uddcc\ud804\ude2c-\ud804\ude37\ud804\ude3e\ud804\udedf-\ud804\udeea\ud804\udf00-\ud804\udf03\ud804\udf3b\ud804\udf3c\ud804\udf3e-\ud804\udf44\ud804\udf47\ud804\udf48\ud804\udf4b-\ud804\udf4d\ud804\udf57\ud804\udf62\ud804\udf63\ud804\udf66-\ud804\udf6c\ud804\udf70-\ud804\udf74\ud805\udc35-\ud805\udc46\ud805\udc5e\ud805\udcb0-\ud805\udcc3\ud805\uddaf-\ud805\uddb5\ud805\uddb8-\ud805\uddc0\ud805\udddc\ud805\udddd\ud805\ude30-\ud805\ude40\ud805\udeab-\ud805\udeb7\ud805\udf1d-\ud805\udf2b\ud806\udc2c-\ud806\udc3a\ud806\ude01-\ud806\ude0a\ud806\ude33-\ud806\ude39\ud806\ude3b-\ud806\ude3e\ud806\ude47\ud806\ude51-\ud806\ude5b\ud806\ude8a-\ud806\ude99\ud807\udc2f-\ud807\udc36\ud807\udc38-\ud807\udc3f\ud807\udc92-\ud807\udca7\ud807\udca9-\ud807\udcb6\ud807\udd31-\ud807\udd36\ud807\udd3a\ud807\udd3c\ud807\udd3d\ud807\udd3f-\ud807\udd45\ud807\udd47\ud807\udd8a-\ud807\udd8e\ud807\udd90\ud807\udd91\ud807\udd93-\ud807\udd97\ud807\udef3-\ud807\udef6\ud81a\udef0-\ud81a\udef4\ud81a\udf30-\ud81a\udf36\ud81b\udf51-\ud81b\udf7e\ud81b\udf8f-\ud81b\udf92\ud82f\udc9d\ud82f\udc9e\ud834\udd65-\ud834\udd69\ud834\udd6d-\ud834\udd72\ud834\udd7b-\ud834\udd82\ud834\udd85-\ud834\udd8b\ud834\uddaa-\ud834\uddad\ud834\ude42-\ud834\ude44\ud836\ude00-\ud836\ude36\ud836\ude3b-\ud836\ude6c\ud836\ude75\ud836\ude84\ud836\ude9b-\ud836\ude9f\ud836\udea1-\ud836\udeaf\ud838\udc00-\ud838\udc06\ud838\udc08-\ud838\udc18\ud838\udc1b-\ud838\udc21\ud838\udc23\ud838\udc24\ud838\udc26-\ud838\udc2a\ud83a\udcd0-\ud83a\udcd6\ud83a\udd44-\ud83a\udd4a\udb40\udd00-\udb40\uddef]+'\n-    )\n+    r\"[\\w\u00b7\u0300-\u036f\u0387\u0483-\u0487\u0591-\u05bd\u05bf\u05c1\u05c2\u05c4\u05c5\u05c7\u0610-\u061a\u064b-\u065f\u0670\u06d6-\u06dc\u06df-\u06e4\u06e7\u06e8\u06ea-\u06ed\u0711\u0730-\u074a\u07a6-\u07b0\u07eb-\u07f3\u07fd\u0816-\u0819\u081b-\u0823\u0825-\u0827\u0829-\u082d\u0859-\u085b\u08d3-\u08e1\u08e3-\u0903\u093a-\u093c\u093e-\u094f\u0951-\u0957\u0962\u0963\u0981-\u0983\u09bc\u09be-\u09c4\u09c7\u09c8\u09cb-\u09cd\u09d7\u09e2\u09e3\u09fe\u0a01-\u0a03\u0a3c\u0a3e-\u0a42\u0a47\u0a48\u0a4b-\u0a4d\u0a51\u0a70\u0a71\u0a75\u0a81-\u0a83\u0abc\u0abe-\u0ac5\u0ac7-\u0ac9\u0acb-\u0acd\u0ae2\u0ae3\u0afa-\u0aff\u0b01-\u0b03\u0b3c\u0b3e-\u0b44\u0b47\u0b48\u0b4b-\u0b4d\u0b56\u0b57\u0b62\u0b63\u0b82\u0bbe-\u0bc2\u0bc6-\u0bc8\u0bca-\u0bcd\u0bd7\u0c00-\u0c04\u0c3e-\u0c44\u0c46-\u0c48\u0c4a-\u0c4d\u0c55\u0c56\u0c62\u0c63\u0c81-\u0c83\u0cbc\u0cbe-\u0cc4\u0cc6-\u0cc8\u0cca-\u0ccd\u0cd5\u0cd6\u0ce2\u0ce3\u0d00-\u0d03\u0d3b\u0d3c\u0d3e-\u0d44\u0d46-\u0d48\u0d4a-\u0d4d\u0d57\u0d62\u0d63\u0d82\u0d83\u0dca\u0dcf-\u0dd4\u0dd6\u0dd8-\u0ddf\u0df2\u0df3\u0e31\u0e34-\u0e3a\u0e47-\u0e4e\u0eb1\u0eb4-\u0eb9\u0ebb\u0ebc\u0ec8-\u0ecd\u0f18\u0f19\u0f35\u0f37\u0f39\u0f3e\u0f3f\u0f71-\u0f84\u0f86\u0f87\u0f8d-\u0f97\u0f99-\u0fbc\u0fc6\u102b-\u103e\u1056-\u1059\u105e-\u1060\u1062-\u1064\u1067-\u106d\u1071-\u1074\u1082-\u108d\u108f\u109a-\u109d\u135d-\u135f\u1712-\u1714\u1732-\u1734\u1752\u1753\u1772\u1773\u17b4-\u17d3\u17dd\u180b-\u180d\u1885\u1886\u18a9\u1920-\u192b\u1930-\u193b\u1a17-\u1a1b\u1a55-\u1a5e\u1a60-\u1a7c\u1a7f\u1ab0-\u1abd\u1b00-\u1b04\u1b34-\u1b44\u1b6b-\u1b73\u1b80-\u1b82\u1ba1-\u1bad\u1be6-\u1bf3\u1c24-\u1c37\u1cd0-\u1cd2\u1cd4-\u1ce8\u1ced\u1cf2-\u1cf4\u1cf7-\u1cf9\u1dc0-\u1df9\u1dfb-\u1dff\u203f\u2040\u2054\u20d0-\u20dc\u20e1\u20e5-\u20f0\u2118\u212e\u2cef-\u2cf1\u2d7f\u2de0-\u2dff\u302a-\u302f\u3099\u309a\ua66f\ua674-\ua67d\ua69e\ua69f\ua6f0\ua6f1\ua802\ua806\ua80b\ua823-\ua827\ua880\ua881\ua8b4-\ua8c5\ua8e0-\ua8f1\ua8ff\ua926-\ua92d\ua947-\ua953\ua980-\ua983\ua9b3-\ua9c0\ua9e5\uaa29-\uaa36\uaa43\uaa4c\uaa4d\uaa7b-\uaa7d\uaab0\uaab2-\uaab4\uaab7\uaab8\uaabe\uaabf\uaac1\uaaeb-\uaaef\uaaf5\uaaf6\uabe3-\uabea\uabec\uabed\ufb1e\ufe00-\ufe0f\ufe20-\ufe2f\ufe33\ufe34\ufe4d-\ufe4f\uff3f\ud800\uddfd\ud800\udee0\ud800\udf76-\ud800\udf7a\ud802\ude01-\ud802\ude03\ud802\ude05\ud802\ude06\ud802\ude0c-\ud802\ude0f\ud802\ude38-\ud802\ude3a\ud802\ude3f\ud802\udee5\ud802\udee6\ud803\udd24-\ud803\udd27\ud803\udf46-\ud803\udf50\ud804\udc00-\ud804\udc02\ud804\udc38-\ud804\udc46\ud804\udc7f-\ud804\udc82\ud804\udcb0-\ud804\udcba\ud804\udd00-\ud804\udd02\ud804\udd27-\ud804\udd34\ud804\udd45\ud804\udd46\ud804\udd73\ud804\udd80-\ud804\udd82\ud804\uddb3-\ud804\uddc0\ud804\uddc9-\ud804\uddcc\ud804\ude2c-\ud804\ude37\ud804\ude3e\ud804\udedf-\ud804\udeea\ud804\udf00-\ud804\udf03\ud804\udf3b\ud804\udf3c\ud804\udf3e-\ud804\udf44\ud804\udf47\ud804\udf48\ud804\udf4b-\ud804\udf4d\ud804\udf57\ud804\udf62\ud804\udf63\ud804\udf66-\ud804\udf6c\ud804\udf70-\ud804\udf74\ud805\udc35-\ud805\udc46\ud805\udc5e\ud805\udcb0-\ud805\udcc3\ud805\uddaf-\ud805\uddb5\ud805\uddb8-\ud805\uddc0\ud805\udddc\ud805\udddd\ud805\ude30-\ud805\ude40\ud805\udeab-\ud805\udeb7\ud805\udf1d-\ud805\udf2b\ud806\udc2c-\ud806\udc3a\ud806\ude01-\ud806\ude0a\ud806\ude33-\ud806\ude39\ud806\ude3b-\ud806\ude3e\ud806\ude47\ud806\ude51-\ud806\ude5b\ud806\ude8a-\ud806\ude99\ud807\udc2f-\ud807\udc36\ud807\udc38-\ud807\udc3f\ud807\udc92-\ud807\udca7\ud807\udca9-\ud807\udcb6\ud807\udd31-\ud807\udd36\ud807\udd3a\ud807\udd3c\ud807\udd3d\ud807\udd3f-\ud807\udd45\ud807\udd47\ud807\udd8a-\ud807\udd8e\ud807\udd90\ud807\udd91\ud807\udd93-\ud807\udd97\ud807\udef3-\ud807\udef6\ud81a\udef0-\ud81a\udef4\ud81a\udf30-\ud81a\udf36\ud81b\udf51-\ud81b\udf7e\ud81b\udf8f-\ud81b\udf92\ud82f\udc9d\ud82f\udc9e\ud834\udd65-\ud834\udd69\ud834\udd6d-\ud834\udd72\ud834\udd7b-\ud834\udd82\ud834\udd85-\ud834\udd8b\ud834\uddaa-\ud834\uddad\ud834\ude42-\ud834\ude44\ud836\ude00-\ud836\ude36\ud836\ude3b-\ud836\ude6c\ud836\ude75\ud836\ude84\ud836\ude9b-\ud836\ude9f\ud836\udea1-\ud836\udeaf\ud838\udc00-\ud838\udc06\ud838\udc08-\ud838\udc18\ud838\udc1b-\ud838\udc21\ud838\udc23\ud838\udc24\ud838\udc26-\ud838\udc2a\ud83a\udcd0-\ud83a\udcd6\ud83a\udd44-\ud83a\udd4a\udb40\udd00-\udb40\uddef]+\"  # noqa: B950\n+)\ndiff --git a/src/jinja2/async_utils.py b/src/jinja2/async_utils.py\nindex f60e3f3..e65219e 100644\n--- a/src/jinja2/async_utils.py\n+++ b/src/jinja2/async_utils.py\n@@ -2,7 +2,83 @@ import inspect\n import typing as t\n from functools import WRAPPER_ASSIGNMENTS\n from functools import wraps\n+\n from .utils import _PassArg\n from .utils import pass_eval_context\n-V = t.TypeVar('V')\n+\n+V = t.TypeVar(\"V\")\n+\n+\n+def async_variant(normal_func):  # type: ignore\n+    def decorator(async_func):  # type: ignore\n+        pass_arg = _PassArg.from_obj(normal_func)\n+        need_eval_context = pass_arg is None\n+\n+        if pass_arg is _PassArg.environment:\n+\n+            def is_async(args: t.Any) -&gt; bool:\n+                return t.cast(bool, args[0].is_async)\n+\n+        else:\n+\n+            def is_async(args: t.Any) -&gt; bool:\n+                return t.cast(bool, args[0].environment.is_async)\n+\n+        # Take the doc and annotations from the sync function, but the\n+        # name from the async function. Pallets-Sphinx-Themes\n+        # build_function_directive expects __wrapped__ to point to the\n+        # sync function.\n+        async_func_attrs = (\"__module__\", \"__name__\", \"__qualname__\")\n+        normal_func_attrs = tuple(set(WRAPPER_ASSIGNMENTS).difference(async_func_attrs))\n+\n+        @wraps(normal_func, assigned=normal_func_attrs)\n+        @wraps(async_func, assigned=async_func_attrs, updated=())\n+        def wrapper(*args, **kwargs):  # type: ignore\n+            b = is_async(args)\n+\n+            if need_eval_context:\n+                args = args[1:]\n+\n+            if b:\n+                return async_func(*args, **kwargs)\n+\n+            return normal_func(*args, **kwargs)\n+\n+        if need_eval_context:\n+            wrapper = pass_eval_context(wrapper)\n+\n+        wrapper.jinja_async_variant = True  # type: ignore[attr-defined]\n+        return wrapper\n+\n+    return decorator\n+\n+\n _common_primitives = {int, float, bool, str, list, dict, tuple, type(None)}\n+\n+\n+async def auto_await(value: t.Union[t.Awaitable[\"V\"], \"V\"]) -&gt; \"V\":\n+    # Avoid a costly call to isawaitable\n+    if type(value) in _common_primitives:\n+        return t.cast(\"V\", value)\n+\n+    if inspect.isawaitable(value):\n+        return await t.cast(\"t.Awaitable[V]\", value)\n+\n+    return t.cast(\"V\", value)\n+\n+\n+async def auto_aiter(\n+    iterable: \"t.Union[t.AsyncIterable[V], t.Iterable[V]]\",\n+) -&gt; \"t.AsyncIterator[V]\":\n+    if hasattr(iterable, \"__aiter__\"):\n+        async for item in t.cast(\"t.AsyncIterable[V]\", iterable):\n+            yield item\n+    else:\n+        for item in iterable:\n+            yield item\n+\n+\n+async def auto_to_list(\n+    value: \"t.Union[t.AsyncIterable[V], t.Iterable[V]]\",\n+) -&gt; t.List[\"V\"]:\n+    return [x async for x in auto_aiter(value)]\ndiff --git a/src/jinja2/bccache.py b/src/jinja2/bccache.py\nindex ae575a3..ada8b09 100644\n--- a/src/jinja2/bccache.py\n+++ b/src/jinja2/bccache.py\n@@ -5,6 +5,7 @@ slows down your application too much.\n Situations where this is useful are often forking web applications that\n are initialized on the first request.\n \"\"\"\n+\n import errno\n import fnmatch\n import marshal\n@@ -17,16 +18,29 @@ import typing as t\n from hashlib import sha1\n from io import BytesIO\n from types import CodeType\n+\n if t.TYPE_CHECKING:\n     import typing_extensions as te\n-    from .environment import Environment\n\n+    from .environment import Environment\n\n     class _MemcachedClient(te.Protocol):\n-        pass\n+        def get(self, key: str) -&gt; bytes: ...\n+\n+        def set(\n+            self, key: str, value: bytes, timeout: t.Optional[int] = None\n+        ) -&gt; None: ...\n+\n+\n bc_version = 5\n-bc_magic = b'j2' + pickle.dumps(bc_version, 2) + pickle.dumps(sys.\n-    version_info[0] &lt;&lt; 24 | sys.version_info[1], 2)\n+# Magic bytes to identify Jinja bytecode cache files. Contains the\n+# Python major and minor version to avoid loading incompatible bytecode\n+# if a project upgrades its Python version.\n+bc_magic = (\n+    b\"j2\"\n+    + pickle.dumps(bc_version, 2)\n+    + pickle.dumps((sys.version_info[0] &lt;&lt; 24) | sys.version_info[1], 2)\n+)\n\n\n class Bucket:\n@@ -38,32 +52,52 @@ class Bucket:\n     cache subclasses don't have to care about cache invalidation.\n     \"\"\"\n\n-    def __init__(self, environment: 'Environment', key: str, checksum: str\n-        ) -&gt;None:\n+    def __init__(self, environment: \"Environment\", key: str, checksum: str) -&gt; None:\n         self.environment = environment\n         self.key = key\n         self.checksum = checksum\n         self.reset()\n\n-    def reset(self) -&gt;None:\n+    def reset(self) -&gt; None:\n         \"\"\"Resets the bucket (unloads the bytecode).\"\"\"\n-        pass\n+        self.code: t.Optional[CodeType] = None\n\n-    def load_bytecode(self, f: t.BinaryIO) -&gt;None:\n+    def load_bytecode(self, f: t.BinaryIO) -&gt; None:\n         \"\"\"Loads bytecode from a file or file like object.\"\"\"\n-        pass\n-\n-    def write_bytecode(self, f: t.IO[bytes]) -&gt;None:\n+        # make sure the magic header is correct\n+        magic = f.read(len(bc_magic))\n+        if magic != bc_magic:\n+            self.reset()\n+            return\n+        # the source code of the file changed, we need to reload\n+        checksum = pickle.load(f)\n+        if self.checksum != checksum:\n+            self.reset()\n+            return\n+        # if marshal_load fails then we need to reload\n+        try:\n+            self.code = marshal.load(f)\n+        except (EOFError, ValueError, TypeError):\n+            self.reset()\n+            return\n+\n+    def write_bytecode(self, f: t.IO[bytes]) -&gt; None:\n         \"\"\"Dump the bytecode into the file or file like object passed.\"\"\"\n-        pass\n+        if self.code is None:\n+            raise TypeError(\"can't write empty bucket\")\n+        f.write(bc_magic)\n+        pickle.dump(self.checksum, f, 2)\n+        marshal.dump(self.code, f)\n\n-    def bytecode_from_string(self, string: bytes) -&gt;None:\n+    def bytecode_from_string(self, string: bytes) -&gt; None:\n         \"\"\"Load bytecode from bytes.\"\"\"\n-        pass\n+        self.load_bytecode(BytesIO(string))\n\n-    def bytecode_to_string(self) -&gt;bytes:\n+    def bytecode_to_string(self) -&gt; bytes:\n         \"\"\"Return the bytecode as bytes.\"\"\"\n-        pass\n+        out = BytesIO()\n+        self.write_bytecode(out)\n+        return out.getvalue()\n\n\n class BytecodeCache:\n@@ -95,46 +129,60 @@ class BytecodeCache:\n     Jinja.\n     \"\"\"\n\n-    def load_bytecode(self, bucket: Bucket) -&gt;None:\n+    def load_bytecode(self, bucket: Bucket) -&gt; None:\n         \"\"\"Subclasses have to override this method to load bytecode into a\n         bucket.  If they are not able to find code in the cache for the\n         bucket, it must not do anything.\n         \"\"\"\n-        pass\n+        raise NotImplementedError()\n\n-    def dump_bytecode(self, bucket: Bucket) -&gt;None:\n+    def dump_bytecode(self, bucket: Bucket) -&gt; None:\n         \"\"\"Subclasses have to override this method to write the bytecode\n         from a bucket back to the cache.  If it unable to do so it must not\n         fail silently but raise an exception.\n         \"\"\"\n-        pass\n+        raise NotImplementedError()\n\n-    def clear(self) -&gt;None:\n+    def clear(self) -&gt; None:\n         \"\"\"Clears the cache.  This method is not used by Jinja but should be\n         implemented to allow applications to clear the bytecode cache used\n         by a particular environment.\n         \"\"\"\n-        pass\n\n-    def get_cache_key(self, name: str, filename: t.Optional[t.Union[str]]=None\n-        ) -&gt;str:\n+    def get_cache_key(\n+        self, name: str, filename: t.Optional[t.Union[str]] = None\n+    ) -&gt; str:\n         \"\"\"Returns the unique hash key for this template name.\"\"\"\n-        pass\n+        hash = sha1(name.encode(\"utf-8\"))\n\n-    def get_source_checksum(self, source: str) -&gt;str:\n-        \"\"\"Returns a checksum for the source.\"\"\"\n-        pass\n+        if filename is not None:\n+            hash.update(f\"|{filename}\".encode())\n+\n+        return hash.hexdigest()\n\n-    def get_bucket(self, environment: 'Environment', name: str, filename: t\n-        .Optional[str], source: str) -&gt;Bucket:\n+    def get_source_checksum(self, source: str) -&gt; str:\n+        \"\"\"Returns a checksum for the source.\"\"\"\n+        return sha1(source.encode(\"utf-8\")).hexdigest()\n+\n+    def get_bucket(\n+        self,\n+        environment: \"Environment\",\n+        name: str,\n+        filename: t.Optional[str],\n+        source: str,\n+    ) -&gt; Bucket:\n         \"\"\"Return a cache bucket for the given template.  All arguments are\n         mandatory but filename may be `None`.\n         \"\"\"\n-        pass\n+        key = self.get_cache_key(name, filename)\n+        checksum = self.get_source_checksum(source)\n+        bucket = Bucket(environment, key, checksum)\n+        self.load_bytecode(bucket)\n+        return bucket\n\n-    def set_bucket(self, bucket: Bucket) -&gt;None:\n+    def set_bucket(self, bucket: Bucket) -&gt; None:\n         \"\"\"Put the bucket into the cache.\"\"\"\n-        pass\n+        self.dump_bytecode(bucket)\n\n\n class FileSystemBytecodeCache(BytecodeCache):\n@@ -155,13 +203,130 @@ class FileSystemBytecodeCache(BytecodeCache):\n     This bytecode cache supports clearing of the cache using the clear method.\n     \"\"\"\n\n-    def __init__(self, directory: t.Optional[str]=None, pattern: str=\n-        '__jinja2_%s.cache') -&gt;None:\n+    def __init__(\n+        self, directory: t.Optional[str] = None, pattern: str = \"__jinja2_%s.cache\"\n+    ) -&gt; None:\n         if directory is None:\n             directory = self._get_default_cache_dir()\n         self.directory = directory\n         self.pattern = pattern\n\n+    def _get_default_cache_dir(self) -&gt; str:\n+        def _unsafe_dir() -&gt; \"te.NoReturn\":\n+            raise RuntimeError(\n+                \"Cannot determine safe temp directory.  You \"\n+                \"need to explicitly provide one.\"\n+            )\n+\n+        tmpdir = tempfile.gettempdir()\n+\n+        # On windows the temporary directory is used specific unless\n+        # explicitly forced otherwise.  We can just use that.\n+        if os.name == \"nt\":\n+            return tmpdir\n+        if not hasattr(os, \"getuid\"):\n+            _unsafe_dir()\n+\n+        dirname = f\"_jinja2-cache-{os.getuid()}\"\n+        actual_dir = os.path.join(tmpdir, dirname)\n+\n+        try:\n+            os.mkdir(actual_dir, stat.S_IRWXU)\n+        except OSError as e:\n+            if e.errno != errno.EEXIST:\n+                raise\n+        try:\n+            os.chmod(actual_dir, stat.S_IRWXU)\n+            actual_dir_stat = os.lstat(actual_dir)\n+            if (\n+                actual_dir_stat.st_uid != os.getuid()\n+                or not stat.S_ISDIR(actual_dir_stat.st_mode)\n+                or stat.S_IMODE(actual_dir_stat.st_mode) != stat.S_IRWXU\n+            ):\n+                _unsafe_dir()\n+        except OSError as e:\n+            if e.errno != errno.EEXIST:\n+                raise\n+\n+        actual_dir_stat = os.lstat(actual_dir)\n+        if (\n+            actual_dir_stat.st_uid != os.getuid()\n+            or not stat.S_ISDIR(actual_dir_stat.st_mode)\n+            or stat.S_IMODE(actual_dir_stat.st_mode) != stat.S_IRWXU\n+        ):\n+            _unsafe_dir()\n+\n+        return actual_dir\n+\n+    def _get_cache_filename(self, bucket: Bucket) -&gt; str:\n+        return os.path.join(self.directory, self.pattern % (bucket.key,))\n+\n+    def load_bytecode(self, bucket: Bucket) -&gt; None:\n+        filename = self._get_cache_filename(bucket)\n+\n+        # Don't test for existence before opening the file, since the\n+        # file could disappear after the test before the open.\n+        try:\n+            f = open(filename, \"rb\")\n+        except (FileNotFoundError, IsADirectoryError, PermissionError):\n+            # PermissionError can occur on Windows when an operation is\n+            # in progress, such as calling clear().\n+            return\n+\n+        with f:\n+            bucket.load_bytecode(f)\n+\n+    def dump_bytecode(self, bucket: Bucket) -&gt; None:\n+        # Write to a temporary file, then rename to the real name after\n+        # writing. This avoids another process reading the file before\n+        # it is fully written.\n+        name = self._get_cache_filename(bucket)\n+        f = tempfile.NamedTemporaryFile(\n+            mode=\"wb\",\n+            dir=os.path.dirname(name),\n+            prefix=os.path.basename(name),\n+            suffix=\".tmp\",\n+            delete=False,\n+        )\n+\n+        def remove_silent() -&gt; None:\n+            try:\n+                os.remove(f.name)\n+            except OSError:\n+                # Another process may have called clear(). On Windows,\n+                # another program may be holding the file open.\n+                pass\n+\n+        try:\n+            with f:\n+                bucket.write_bytecode(f)\n+        except BaseException:\n+            remove_silent()\n+            raise\n+\n+        try:\n+            os.replace(f.name, name)\n+        except OSError:\n+            # Another process may have called clear(). On Windows,\n+            # another program may be holding the file open.\n+            remove_silent()\n+        except BaseException:\n+            remove_silent()\n+            raise\n+\n+    def clear(self) -&gt; None:\n+        # imported lazily here because google app-engine doesn't support\n+        # write access on the file system and the function does not exist\n+        # normally.\n+        from os import remove\n+\n+        files = fnmatch.filter(os.listdir(self.directory), self.pattern % (\"*\",))\n+        for filename in files:\n+            try:\n+                remove(os.path.join(self.directory, filename))\n+            except OSError:\n+                pass\n+\n\n class MemcachedBytecodeCache(BytecodeCache):\n     \"\"\"This class implements a bytecode cache that uses a memcache cache for\n@@ -208,10 +373,36 @@ class MemcachedBytecodeCache(BytecodeCache):\n        `ignore_memcache_errors` parameter.\n     \"\"\"\n\n-    def __init__(self, client: '_MemcachedClient', prefix: str=\n-        'jinja2/bytecode/', timeout: t.Optional[int]=None,\n-        ignore_memcache_errors: bool=True):\n+    def __init__(\n+        self,\n+        client: \"_MemcachedClient\",\n+        prefix: str = \"jinja2/bytecode/\",\n+        timeout: t.Optional[int] = None,\n+        ignore_memcache_errors: bool = True,\n+    ):\n         self.client = client\n         self.prefix = prefix\n         self.timeout = timeout\n         self.ignore_memcache_errors = ignore_memcache_errors\n+\n+    def load_bytecode(self, bucket: Bucket) -&gt; None:\n+        try:\n+            code = self.client.get(self.prefix + bucket.key)\n+        except Exception:\n+            if not self.ignore_memcache_errors:\n+                raise\n+        else:\n+            bucket.bytecode_from_string(code)\n+\n+    def dump_bytecode(self, bucket: Bucket) -&gt; None:\n+        key = self.prefix + bucket.key\n+        value = bucket.bytecode_to_string()\n+\n+        try:\n+            if self.timeout is not None:\n+                self.client.set(key, value, self.timeout)\n+            else:\n+                self.client.set(key, value)\n+        except Exception:\n+            if not self.ignore_memcache_errors:\n+                raise\ndiff --git a/src/jinja2/compiler.py b/src/jinja2/compiler.py\nindex 32df45a..2740717 100644\n--- a/src/jinja2/compiler.py\n+++ b/src/jinja2/compiler.py\n@@ -1,12 +1,15 @@\n \"\"\"Compiles nodes from the parser into Python code.\"\"\"\n+\n import typing as t\n from contextlib import contextmanager\n from functools import update_wrapper\n from io import StringIO\n from itertools import chain\n from keyword import iskeyword as is_python_keyword\n+\n from markupsafe import escape\n from markupsafe import Markup\n+\n from . import nodes\n from .exceptions import TemplateAssertionError\n from .idtracking import Symbols\n@@ -19,37 +22,140 @@ from .optimizer import Optimizer\n from .utils import _PassArg\n from .utils import concat\n from .visitor import NodeVisitor\n+\n if t.TYPE_CHECKING:\n     import typing_extensions as te\n+\n     from .environment import Environment\n-F = t.TypeVar('F', bound=t.Callable[..., t.Any])\n-operators = {'eq': '==', 'ne': '!=', 'gt': '&gt;', 'gteq': '&gt;=', 'lt': '&lt;',\n-    'lteq': '&lt;=', 'in': 'in', 'notin': 'not in'}\n\n+F = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n+\n+operators = {\n+    \"eq\": \"==\",\n+    \"ne\": \"!=\",\n+    \"gt\": \"&gt;\",\n+    \"gteq\": \"&gt;=\",\n+    \"lt\": \"&lt;\",\n+    \"lteq\": \"&lt;=\",\n+    \"in\": \"in\",\n+    \"notin\": \"not in\",\n+}\n+\n+\n+def optimizeconst(f: F) -&gt; F:\n+    def new_func(\n+        self: \"CodeGenerator\", node: nodes.Expr, frame: \"Frame\", **kwargs: t.Any\n+    ) -&gt; t.Any:\n+        # Only optimize if the frame is not volatile\n+        if self.optimizer is not None and not frame.eval_ctx.volatile:\n+            new_node = self.optimizer.visit(node, frame.eval_ctx)\n+\n+            if new_node != node:\n+                return self.visit(new_node, frame)\n+\n+        return f(self, node, frame, **kwargs)\n+\n+    return update_wrapper(t.cast(F, new_func), f)\n+\n+\n+def _make_binop(op: str) -&gt; t.Callable[[\"CodeGenerator\", nodes.BinExpr, \"Frame\"], None]:\n+    @optimizeconst\n+    def visitor(self: \"CodeGenerator\", node: nodes.BinExpr, frame: Frame) -&gt; None:\n+        if (\n+            self.environment.sandboxed and op in self.environment.intercepted_binops  # type: ignore\n+        ):\n+            self.write(f\"environment.call_binop(context, {op!r}, \")\n+            self.visit(node.left, frame)\n+            self.write(\", \")\n+            self.visit(node.right, frame)\n+        else:\n+            self.write(\"(\")\n+            self.visit(node.left, frame)\n+            self.write(f\" {op} \")\n+            self.visit(node.right, frame)\n+\n+        self.write(\")\")\n+\n+    return visitor\n+\n+\n+def _make_unop(\n+    op: str,\n+) -&gt; t.Callable[[\"CodeGenerator\", nodes.UnaryExpr, \"Frame\"], None]:\n+    @optimizeconst\n+    def visitor(self: \"CodeGenerator\", node: nodes.UnaryExpr, frame: Frame) -&gt; None:\n+        if (\n+            self.environment.sandboxed and op in self.environment.intercepted_unops  # type: ignore\n+        ):\n+            self.write(f\"environment.call_unop(context, {op!r}, \")\n+            self.visit(node.node, frame)\n+        else:\n+            self.write(\"(\" + op)\n+            self.visit(node.node, frame)\n+\n+        self.write(\")\")\n+\n+    return visitor\n\n-def generate(node: nodes.Template, environment: 'Environment', name: t.\n-    Optional[str], filename: t.Optional[str], stream: t.Optional[t.TextIO]=\n-    None, defer_init: bool=False, optimized: bool=True) -&gt;t.Optional[str]:\n+\n+def generate(\n+    node: nodes.Template,\n+    environment: \"Environment\",\n+    name: t.Optional[str],\n+    filename: t.Optional[str],\n+    stream: t.Optional[t.TextIO] = None,\n+    defer_init: bool = False,\n+    optimized: bool = True,\n+) -&gt; t.Optional[str]:\n     \"\"\"Generate the python source for a node tree.\"\"\"\n-    pass\n+    if not isinstance(node, nodes.Template):\n+        raise TypeError(\"Can't compile non template nodes\")\n+\n+    generator = environment.code_generator_class(\n+        environment, name, filename, stream, defer_init, optimized\n+    )\n+    generator.visit(node)\n+\n+    if stream is None:\n+        return generator.stream.getvalue()  # type: ignore\n\n+    return None\n\n-def has_safe_repr(value: t.Any) -&gt;bool:\n+\n+def has_safe_repr(value: t.Any) -&gt; bool:\n     \"\"\"Does the node have a safe representation?\"\"\"\n-    pass\n+    if value is None or value is NotImplemented or value is Ellipsis:\n+        return True\n+\n+    if type(value) in {bool, int, float, complex, range, str, Markup}:\n+        return True\n\n+    if type(value) in {tuple, list, set, frozenset}:\n+        return all(has_safe_repr(v) for v in value)\n\n-def find_undeclared(nodes: t.Iterable[nodes.Node], names: t.Iterable[str]\n-    ) -&gt;t.Set[str]:\n+    if type(value) is dict:  # noqa E721\n+        return all(has_safe_repr(k) and has_safe_repr(v) for k, v in value.items())\n+\n+    return False\n+\n+\n+def find_undeclared(\n+    nodes: t.Iterable[nodes.Node], names: t.Iterable[str]\n+) -&gt; t.Set[str]:\n     \"\"\"Check if the names passed are accessed undeclared.  The return value\n     is a set of all the undeclared names from the sequence of names found.\n     \"\"\"\n-    pass\n+    visitor = UndeclaredNameVisitor(names)\n+    try:\n+        for node in nodes:\n+            visitor.visit(node)\n+    except VisitorExit:\n+        pass\n+    return visitor.undeclared\n\n\n class MacroRef:\n-\n-    def __init__(self, node: t.Union[nodes.Macro, nodes.CallBlock]) -&gt;None:\n+    def __init__(self, node: t.Union[nodes.Macro, nodes.CallBlock]) -&gt; None:\n         self.node = node\n         self.accesses_caller = False\n         self.accesses_kwargs = False\n@@ -59,35 +165,71 @@ class MacroRef:\n class Frame:\n     \"\"\"Holds compile time information for us.\"\"\"\n\n-    def __init__(self, eval_ctx: EvalContext, parent: t.Optional['Frame']=\n-        None, level: t.Optional[int]=None) -&gt;None:\n+    def __init__(\n+        self,\n+        eval_ctx: EvalContext,\n+        parent: t.Optional[\"Frame\"] = None,\n+        level: t.Optional[int] = None,\n+    ) -&gt; None:\n         self.eval_ctx = eval_ctx\n+\n+        # the parent of this frame\n         self.parent = parent\n+\n         if parent is None:\n             self.symbols = Symbols(level=level)\n+\n+            # in some dynamic inheritance situations the compiler needs to add\n+            # write tests around output statements.\n             self.require_output_check = False\n+\n+            # inside some tags we are using a buffer rather than yield statements.\n+            # this for example affects {% filter %} or {% macro %}.  If a frame\n+            # is buffered this variable points to the name of the list used as\n+            # buffer.\n             self.buffer: t.Optional[str] = None\n+\n+            # the name of the block we're in, otherwise None.\n             self.block: t.Optional[str] = None\n+\n         else:\n             self.symbols = Symbols(parent.symbols, level=level)\n             self.require_output_check = parent.require_output_check\n             self.buffer = parent.buffer\n             self.block = parent.block\n+\n+        # a toplevel frame is the root + soft frames such as if conditions.\n         self.toplevel = False\n+\n+        # the root frame is basically just the outermost frame, so no if\n+        # conditions.  This information is used to optimize inheritance\n+        # situations.\n         self.rootlevel = False\n+\n+        # variables set inside of loops and blocks should not affect outer frames,\n+        # but they still needs to be kept track of as part of the active context.\n         self.loop_frame = False\n         self.block_frame = False\n+\n+        # track whether the frame is being used in an if-statement or conditional\n+        # expression as it determines which errors should be raised during runtime\n+        # or compile time.\n         self.soft_frame = False\n\n-    def copy(self) -&gt;'Frame':\n+    def copy(self) -&gt; \"Frame\":\n         \"\"\"Create a copy of the current one.\"\"\"\n-        pass\n+        rv = object.__new__(self.__class__)\n+        rv.__dict__.update(self.__dict__)\n+        rv.symbols = self.symbols.copy()\n+        return rv\n\n-    def inner(self, isolated: bool=False) -&gt;'Frame':\n+    def inner(self, isolated: bool = False) -&gt; \"Frame\":\n         \"\"\"Return an inner frame.\"\"\"\n-        pass\n+        if isolated:\n+            return Frame(self.eval_ctx, level=self.symbols.level + 1)\n+        return Frame(self.eval_ctx, self)\n\n-    def soft(self) -&gt;'Frame':\n+    def soft(self) -&gt; \"Frame\":\n         \"\"\"Return a soft frame.  A soft frame may not be modified as\n         standalone thing as it shares the resources with the frame it\n         was created of, but it's not a rootlevel frame any longer.\n@@ -95,7 +237,11 @@ class Frame:\n         This is only used to implement if-statements and conditional\n         expressions.\n         \"\"\"\n-        pass\n+        rv = self.copy()\n+        rv.rootlevel = False\n+        rv.soft_frame = True\n+        return rv\n+\n     __copy__ = copy\n\n\n@@ -106,13 +252,20 @@ class VisitorExit(RuntimeError):\n class DependencyFinderVisitor(NodeVisitor):\n     \"\"\"A visitor that collects filter and test calls.\"\"\"\n\n-    def __init__(self) -&gt;None:\n+    def __init__(self) -&gt; None:\n         self.filters: t.Set[str] = set()\n         self.tests: t.Set[str] = set()\n\n-    def visit_Block(self, node: nodes.Block) -&gt;None:\n+    def visit_Filter(self, node: nodes.Filter) -&gt; None:\n+        self.generic_visit(node)\n+        self.filters.add(node.name)\n+\n+    def visit_Test(self, node: nodes.Test) -&gt; None:\n+        self.generic_visit(node)\n+        self.tests.add(node.name)\n+\n+    def visit_Block(self, node: nodes.Block) -&gt; None:\n         \"\"\"Stop visiting at blocks.\"\"\"\n-        pass\n\n\n class UndeclaredNameVisitor(NodeVisitor):\n@@ -121,13 +274,20 @@ class UndeclaredNameVisitor(NodeVisitor):\n     not stop at closure frames.\n     \"\"\"\n\n-    def __init__(self, names: t.Iterable[str]) -&gt;None:\n+    def __init__(self, names: t.Iterable[str]) -&gt; None:\n         self.names = set(names)\n         self.undeclared: t.Set[str] = set()\n\n-    def visit_Block(self, node: nodes.Block) -&gt;None:\n+    def visit_Name(self, node: nodes.Name) -&gt; None:\n+        if node.ctx == \"load\" and node.name in self.names:\n+            self.undeclared.add(node.name)\n+            if self.undeclared == self.names:\n+                raise VisitorExit()\n+        else:\n+            self.names.discard(node.name)\n+\n+    def visit_Block(self, node: nodes.Block) -&gt; None:\n         \"\"\"Stop visiting a blocks.\"\"\"\n-        pass\n\n\n class CompilerExit(Exception):\n@@ -138,10 +298,15 @@ class CompilerExit(Exception):\n\n\n class CodeGenerator(NodeVisitor):\n-\n-    def __init__(self, environment: 'Environment', name: t.Optional[str],\n-        filename: t.Optional[str], stream: t.Optional[t.TextIO]=None,\n-        defer_init: bool=False, optimized: bool=True) -&gt;None:\n+    def __init__(\n+        self,\n+        environment: \"Environment\",\n+        name: t.Optional[str],\n+        filename: t.Optional[str],\n+        stream: t.Optional[t.TextIO] = None,\n+        defer_init: bool = False,\n+        optimized: bool = True,\n+    ) -&gt; None:\n         if stream is None:\n             stream = StringIO()\n         self.environment = environment\n@@ -151,96 +316,226 @@ class CodeGenerator(NodeVisitor):\n         self.created_block_context = False\n         self.defer_init = defer_init\n         self.optimizer: t.Optional[Optimizer] = None\n+\n         if optimized:\n             self.optimizer = Optimizer(environment)\n+\n+        # aliases for imports\n         self.import_aliases: t.Dict[str, str] = {}\n+\n+        # a registry for all blocks.  Because blocks are moved out\n+        # into the global python scope they are registered here\n         self.blocks: t.Dict[str, nodes.Block] = {}\n+\n+        # the number of extends statements so far\n         self.extends_so_far = 0\n+\n+        # some templates have a rootlevel extends.  In this case we\n+        # can safely assume that we're a child template and do some\n+        # more optimizations.\n         self.has_known_extends = False\n+\n+        # the current line number\n         self.code_lineno = 1\n+\n+        # registry of all filters and tests (global, not block local)\n         self.tests: t.Dict[str, str] = {}\n         self.filters: t.Dict[str, str] = {}\n+\n+        # the debug information\n         self.debug_info: t.List[t.Tuple[int, int]] = []\n         self._write_debug_info: t.Optional[int] = None\n+\n+        # the number of new lines before the next write()\n         self._new_lines = 0\n+\n+        # the line number of the last written statement\n         self._last_line = 0\n+\n+        # true if nothing was written so far.\n         self._first_write = True\n+\n+        # used by the `temporary_identifier` method to get new\n+        # unique, temporary identifier\n         self._last_identifier = 0\n+\n+        # the current indentation\n         self._indentation = 0\n+\n+        # Tracks toplevel assignments\n         self._assign_stack: t.List[t.Set[str]] = []\n+\n+        # Tracks parameter definition blocks\n         self._param_def_block: t.List[t.Set[str]] = []\n-        self._context_reference_stack = ['context']\n\n-    def fail(self, msg: str, lineno: int) -&gt;'te.NoReturn':\n+        # Tracks the current context.\n+        self._context_reference_stack = [\"context\"]\n+\n+    @property\n+    def optimized(self) -&gt; bool:\n+        return self.optimizer is not None\n+\n+    # -- Various compilation helpers\n+\n+    def fail(self, msg: str, lineno: int) -&gt; \"te.NoReturn\":\n         \"\"\"Fail with a :exc:`TemplateAssertionError`.\"\"\"\n-        pass\n+        raise TemplateAssertionError(msg, lineno, self.name, self.filename)\n\n-    def temporary_identifier(self) -&gt;str:\n+    def temporary_identifier(self) -&gt; str:\n         \"\"\"Get a new unique identifier.\"\"\"\n-        pass\n+        self._last_identifier += 1\n+        return f\"t_{self._last_identifier}\"\n\n-    def buffer(self, frame: Frame) -&gt;None:\n+    def buffer(self, frame: Frame) -&gt; None:\n         \"\"\"Enable buffering for the frame from that point onwards.\"\"\"\n-        pass\n+        frame.buffer = self.temporary_identifier()\n+        self.writeline(f\"{frame.buffer} = []\")\n\n-    def return_buffer_contents(self, frame: Frame, force_unescaped: bool=False\n-        ) -&gt;None:\n+    def return_buffer_contents(\n+        self, frame: Frame, force_unescaped: bool = False\n+    ) -&gt; None:\n         \"\"\"Return the buffer contents of the frame.\"\"\"\n-        pass\n-\n-    def indent(self) -&gt;None:\n+        if not force_unescaped:\n+            if frame.eval_ctx.volatile:\n+                self.writeline(\"if context.eval_ctx.autoescape:\")\n+                self.indent()\n+                self.writeline(f\"return Markup(concat({frame.buffer}))\")\n+                self.outdent()\n+                self.writeline(\"else:\")\n+                self.indent()\n+                self.writeline(f\"return concat({frame.buffer})\")\n+                self.outdent()\n+                return\n+            elif frame.eval_ctx.autoescape:\n+                self.writeline(f\"return Markup(concat({frame.buffer}))\")\n+                return\n+        self.writeline(f\"return concat({frame.buffer})\")\n+\n+    def indent(self) -&gt; None:\n         \"\"\"Indent by one.\"\"\"\n-        pass\n+        self._indentation += 1\n\n-    def outdent(self, step: int=1) -&gt;None:\n+    def outdent(self, step: int = 1) -&gt; None:\n         \"\"\"Outdent by step.\"\"\"\n-        pass\n+        self._indentation -= step\n\n-    def start_write(self, frame: Frame, node: t.Optional[nodes.Node]=None\n-        ) -&gt;None:\n+    def start_write(self, frame: Frame, node: t.Optional[nodes.Node] = None) -&gt; None:\n         \"\"\"Yield or write into the frame buffer.\"\"\"\n-        pass\n+        if frame.buffer is None:\n+            self.writeline(\"yield \", node)\n+        else:\n+            self.writeline(f\"{frame.buffer}.append(\", node)\n\n-    def end_write(self, frame: Frame) -&gt;None:\n+    def end_write(self, frame: Frame) -&gt; None:\n         \"\"\"End the writing process started by `start_write`.\"\"\"\n-        pass\n+        if frame.buffer is not None:\n+            self.write(\")\")\n\n-    def simple_write(self, s: str, frame: Frame, node: t.Optional[nodes.\n-        Node]=None) -&gt;None:\n+    def simple_write(\n+        self, s: str, frame: Frame, node: t.Optional[nodes.Node] = None\n+    ) -&gt; None:\n         \"\"\"Simple shortcut for start_write + write + end_write.\"\"\"\n-        pass\n+        self.start_write(frame, node)\n+        self.write(s)\n+        self.end_write(frame)\n\n-    def blockvisit(self, nodes: t.Iterable[nodes.Node], frame: Frame) -&gt;None:\n+    def blockvisit(self, nodes: t.Iterable[nodes.Node], frame: Frame) -&gt; None:\n         \"\"\"Visit a list of nodes as block in a frame.  If the current frame\n         is no buffer a dummy ``if 0: yield None`` is written automatically.\n         \"\"\"\n-        pass\n-\n-    def write(self, x: str) -&gt;None:\n+        try:\n+            self.writeline(\"pass\")\n+            for node in nodes:\n+                self.visit(node, frame)\n+        except CompilerExit:\n+            pass\n+\n+    def write(self, x: str) -&gt; None:\n         \"\"\"Write a string into the output stream.\"\"\"\n-        pass\n-\n-    def writeline(self, x: str, node: t.Optional[nodes.Node]=None, extra: int=0\n-        ) -&gt;None:\n+        if self._new_lines:\n+            if not self._first_write:\n+                self.stream.write(\"\\n\" * self._new_lines)\n+                self.code_lineno += self._new_lines\n+                if self._write_debug_info is not None:\n+                    self.debug_info.append((self._write_debug_info, self.code_lineno))\n+                    self._write_debug_info = None\n+            self._first_write = False\n+            self.stream.write(\"    \" * self._indentation)\n+            self._new_lines = 0\n+        self.stream.write(x)\n+\n+    def writeline(\n+        self, x: str, node: t.Optional[nodes.Node] = None, extra: int = 0\n+    ) -&gt; None:\n         \"\"\"Combination of newline and write.\"\"\"\n-        pass\n+        self.newline(node, extra)\n+        self.write(x)\n\n-    def newline(self, node: t.Optional[nodes.Node]=None, extra: int=0) -&gt;None:\n+    def newline(self, node: t.Optional[nodes.Node] = None, extra: int = 0) -&gt; None:\n         \"\"\"Add one or more newlines before the next write.\"\"\"\n-        pass\n-\n-    def signature(self, node: t.Union[nodes.Call, nodes.Filter, nodes.Test],\n-        frame: Frame, extra_kwargs: t.Optional[t.Mapping[str, t.Any]]=None\n-        ) -&gt;None:\n+        self._new_lines = max(self._new_lines, 1 + extra)\n+        if node is not None and node.lineno != self._last_line:\n+            self._write_debug_info = node.lineno\n+            self._last_line = node.lineno\n+\n+    def signature(\n+        self,\n+        node: t.Union[nodes.Call, nodes.Filter, nodes.Test],\n+        frame: Frame,\n+        extra_kwargs: t.Optional[t.Mapping[str, t.Any]] = None,\n+    ) -&gt; None:\n         \"\"\"Writes a function call to the stream for the current node.\n         A leading comma is added automatically.  The extra keyword\n         arguments may not include python keywords otherwise a syntax\n         error could occur.  The extra keyword arguments should be given\n         as python dict.\n         \"\"\"\n-        pass\n-\n-    def pull_dependencies(self, nodes: t.Iterable[nodes.Node]) -&gt;None:\n+        # if any of the given keyword arguments is a python keyword\n+        # we have to make sure that no invalid call is created.\n+        kwarg_workaround = any(\n+            is_python_keyword(t.cast(str, k))\n+            for k in chain((x.key for x in node.kwargs), extra_kwargs or ())\n+        )\n+\n+        for arg in node.args:\n+            self.write(\", \")\n+            self.visit(arg, frame)\n+\n+        if not kwarg_workaround:\n+            for kwarg in node.kwargs:\n+                self.write(\", \")\n+                self.visit(kwarg, frame)\n+            if extra_kwargs is not None:\n+                for key, value in extra_kwargs.items():\n+                    self.write(f\", {key}={value}\")\n+        if node.dyn_args:\n+            self.write(\", *\")\n+            self.visit(node.dyn_args, frame)\n+\n+        if kwarg_workaround:\n+            if node.dyn_kwargs is not None:\n+                self.write(\", **dict({\")\n+            else:\n+                self.write(\", **{\")\n+            for kwarg in node.kwargs:\n+                self.write(f\"{kwarg.key!r}: \")\n+                self.visit(kwarg.value, frame)\n+                self.write(\", \")\n+            if extra_kwargs is not None:\n+                for key, value in extra_kwargs.items():\n+                    self.write(f\"{key!r}: {value}, \")\n+            if node.dyn_kwargs is not None:\n+                self.write(\"}, **\")\n+                self.visit(node.dyn_kwargs, frame)\n+                self.write(\")\")\n+            else:\n+                self.write(\"}\")\n+\n+        elif node.dyn_kwargs is not None:\n+            self.write(\", **\")\n+            self.visit(node.dyn_kwargs, frame)\n+\n+    def pull_dependencies(self, nodes: t.Iterable[nodes.Node]) -&gt; None:\n         \"\"\"Find all filter and test names used in the template and\n         assign them to variables in the compiled namespace. Checking\n         that the names are registered with the environment is done when\n@@ -251,96 +546,837 @@ class CodeGenerator(NodeVisitor):\n             Filters and tests in If and CondExpr nodes are checked at\n             runtime instead of compile time.\n         \"\"\"\n-        pass\n-\n-    def macro_body(self, node: t.Union[nodes.Macro, nodes.CallBlock], frame:\n-        Frame) -&gt;t.Tuple[Frame, MacroRef]:\n+        visitor = DependencyFinderVisitor()\n+\n+        for node in nodes:\n+            visitor.visit(node)\n+\n+        for id_map, names, dependency in (\n+            (self.filters, visitor.filters, \"filters\"),\n+            (\n+                self.tests,\n+                visitor.tests,\n+                \"tests\",\n+            ),\n+        ):\n+            for name in sorted(names):\n+                if name not in id_map:\n+                    id_map[name] = self.temporary_identifier()\n+\n+                # add check during runtime that dependencies used inside of executed\n+                # blocks are defined, as this step may be skipped during compile time\n+                self.writeline(\"try:\")\n+                self.indent()\n+                self.writeline(f\"{id_map[name]} = environment.{dependency}[{name!r}]\")\n+                self.outdent()\n+                self.writeline(\"except KeyError:\")\n+                self.indent()\n+                self.writeline(\"@internalcode\")\n+                self.writeline(f\"def {id_map[name]}(*unused):\")\n+                self.indent()\n+                self.writeline(\n+                    f'raise TemplateRuntimeError(\"No {dependency[:-1]}'\n+                    f' named {name!r} found.\")'\n+                )\n+                self.outdent()\n+                self.outdent()\n+\n+    def enter_frame(self, frame: Frame) -&gt; None:\n+        undefs = []\n+        for target, (action, param) in frame.symbols.loads.items():\n+            if action == VAR_LOAD_PARAMETER:\n+                pass\n+            elif action == VAR_LOAD_RESOLVE:\n+                self.writeline(f\"{target} = {self.get_resolve_func()}({param!r})\")\n+            elif action == VAR_LOAD_ALIAS:\n+                self.writeline(f\"{target} = {param}\")\n+            elif action == VAR_LOAD_UNDEFINED:\n+                undefs.append(target)\n+            else:\n+                raise NotImplementedError(\"unknown load instruction\")\n+        if undefs:\n+            self.writeline(f\"{' = '.join(undefs)} = missing\")\n+\n+    def leave_frame(self, frame: Frame, with_python_scope: bool = False) -&gt; None:\n+        if not with_python_scope:\n+            undefs = []\n+            for target in frame.symbols.loads:\n+                undefs.append(target)\n+            if undefs:\n+                self.writeline(f\"{' = '.join(undefs)} = missing\")\n+\n+    def choose_async(self, async_value: str = \"async \", sync_value: str = \"\") -&gt; str:\n+        return async_value if self.environment.is_async else sync_value\n+\n+    def func(self, name: str) -&gt; str:\n+        return f\"{self.choose_async()}def {name}\"\n+\n+    def macro_body(\n+        self, node: t.Union[nodes.Macro, nodes.CallBlock], frame: Frame\n+    ) -&gt; t.Tuple[Frame, MacroRef]:\n         \"\"\"Dump the function def of a macro or call block.\"\"\"\n-        pass\n-\n-    def macro_def(self, macro_ref: MacroRef, frame: Frame) -&gt;None:\n+        frame = frame.inner()\n+        frame.symbols.analyze_node(node)\n+        macro_ref = MacroRef(node)\n+\n+        explicit_caller = None\n+        skip_special_params = set()\n+        args = []\n+\n+        for idx, arg in enumerate(node.args):\n+            if arg.name == \"caller\":\n+                explicit_caller = idx\n+            if arg.name in (\"kwargs\", \"varargs\"):\n+                skip_special_params.add(arg.name)\n+            args.append(frame.symbols.ref(arg.name))\n+\n+        undeclared = find_undeclared(node.body, (\"caller\", \"kwargs\", \"varargs\"))\n+\n+        if \"caller\" in undeclared:\n+            # In older Jinja versions there was a bug that allowed caller\n+            # to retain the special behavior even if it was mentioned in\n+            # the argument list.  However thankfully this was only really\n+            # working if it was the last argument.  So we are explicitly\n+            # checking this now and error out if it is anywhere else in\n+            # the argument list.\n+            if explicit_caller is not None:\n+                try:\n+                    node.defaults[explicit_caller - len(node.args)]\n+                except IndexError:\n+                    self.fail(\n+                        \"When defining macros or call blocks the \"\n+                        'special \"caller\" argument must be omitted '\n+                        \"or be given a default.\",\n+                        node.lineno,\n+                    )\n+            else:\n+                args.append(frame.symbols.declare_parameter(\"caller\"))\n+            macro_ref.accesses_caller = True\n+        if \"kwargs\" in undeclared and \"kwargs\" not in skip_special_params:\n+            args.append(frame.symbols.declare_parameter(\"kwargs\"))\n+            macro_ref.accesses_kwargs = True\n+        if \"varargs\" in undeclared and \"varargs\" not in skip_special_params:\n+            args.append(frame.symbols.declare_parameter(\"varargs\"))\n+            macro_ref.accesses_varargs = True\n+\n+        # macros are delayed, they never require output checks\n+        frame.require_output_check = False\n+        frame.symbols.analyze_node(node)\n+        self.writeline(f\"{self.func('macro')}({', '.join(args)}):\", node)\n+        self.indent()\n+\n+        self.buffer(frame)\n+        self.enter_frame(frame)\n+\n+        self.push_parameter_definitions(frame)\n+        for idx, arg in enumerate(node.args):\n+            ref = frame.symbols.ref(arg.name)\n+            self.writeline(f\"if {ref} is missing:\")\n+            self.indent()\n+            try:\n+                default = node.defaults[idx - len(node.args)]\n+            except IndexError:\n+                self.writeline(\n+                    f'{ref} = undefined(\"parameter {arg.name!r} was not provided\",'\n+                    f\" name={arg.name!r})\"\n+                )\n+            else:\n+                self.writeline(f\"{ref} = \")\n+                self.visit(default, frame)\n+            self.mark_parameter_stored(ref)\n+            self.outdent()\n+        self.pop_parameter_definitions()\n+\n+        self.blockvisit(node.body, frame)\n+        self.return_buffer_contents(frame, force_unescaped=True)\n+        self.leave_frame(frame, with_python_scope=True)\n+        self.outdent()\n+\n+        return frame, macro_ref\n+\n+    def macro_def(self, macro_ref: MacroRef, frame: Frame) -&gt; None:\n         \"\"\"Dump the macro definition for the def created by macro_body.\"\"\"\n-        pass\n-\n-    def position(self, node: nodes.Node) -&gt;str:\n+        arg_tuple = \", \".join(repr(x.name) for x in macro_ref.node.args)\n+        name = getattr(macro_ref.node, \"name\", None)\n+        if len(macro_ref.node.args) == 1:\n+            arg_tuple += \",\"\n+        self.write(\n+            f\"Macro(environment, macro, {name!r}, ({arg_tuple}),\"\n+            f\" {macro_ref.accesses_kwargs!r}, {macro_ref.accesses_varargs!r},\"\n+            f\" {macro_ref.accesses_caller!r}, context.eval_ctx.autoescape)\"\n+        )\n+\n+    def position(self, node: nodes.Node) -&gt; str:\n         \"\"\"Return a human readable position for the node.\"\"\"\n-        pass\n-\n-    def write_commons(self) -&gt;None:\n+        rv = f\"line {node.lineno}\"\n+        if self.name is not None:\n+            rv = f\"{rv} in {self.name!r}\"\n+        return rv\n+\n+    def dump_local_context(self, frame: Frame) -&gt; str:\n+        items_kv = \", \".join(\n+            f\"{name!r}: {target}\"\n+            for name, target in frame.symbols.dump_stores().items()\n+        )\n+        return f\"{{{items_kv}}}\"\n+\n+    def write_commons(self) -&gt; None:\n         \"\"\"Writes a common preamble that is used by root and block functions.\n         Primarily this sets up common local helpers and enforces a generator\n         through a dead branch.\n         \"\"\"\n-        pass\n-\n-    def push_parameter_definitions(self, frame: Frame) -&gt;None:\n+        self.writeline(\"resolve = context.resolve_or_missing\")\n+        self.writeline(\"undefined = environment.undefined\")\n+        self.writeline(\"concat = environment.concat\")\n+        # always use the standard Undefined class for the implicit else of\n+        # conditional expressions\n+        self.writeline(\"cond_expr_undefined = Undefined\")\n+        self.writeline(\"if 0: yield None\")\n+\n+    def push_parameter_definitions(self, frame: Frame) -&gt; None:\n         \"\"\"Pushes all parameter targets from the given frame into a local\n         stack that permits tracking of yet to be assigned parameters.  In\n         particular this enables the optimization from `visit_Name` to skip\n         undefined expressions for parameters in macros as macros can reference\n         otherwise unbound parameters.\n         \"\"\"\n-        pass\n+        self._param_def_block.append(frame.symbols.dump_param_targets())\n\n-    def pop_parameter_definitions(self) -&gt;None:\n+    def pop_parameter_definitions(self) -&gt; None:\n         \"\"\"Pops the current parameter definitions set.\"\"\"\n-        pass\n+        self._param_def_block.pop()\n\n-    def mark_parameter_stored(self, target: str) -&gt;None:\n+    def mark_parameter_stored(self, target: str) -&gt; None:\n         \"\"\"Marks a parameter in the current parameter definitions as stored.\n         This will skip the enforced undefined checks.\n         \"\"\"\n-        pass\n+        if self._param_def_block:\n+            self._param_def_block[-1].discard(target)\n+\n+    def push_context_reference(self, target: str) -&gt; None:\n+        self._context_reference_stack.append(target)\n+\n+    def pop_context_reference(self) -&gt; None:\n+        self._context_reference_stack.pop()\n+\n+    def get_context_ref(self) -&gt; str:\n+        return self._context_reference_stack[-1]\n+\n+    def get_resolve_func(self) -&gt; str:\n+        target = self._context_reference_stack[-1]\n+        if target == \"context\":\n+            return \"resolve\"\n+        return f\"{target}.resolve\"\n\n-    def parameter_is_undeclared(self, target: str) -&gt;bool:\n+    def derive_context(self, frame: Frame) -&gt; str:\n+        return f\"{self.get_context_ref()}.derived({self.dump_local_context(frame)})\"\n+\n+    def parameter_is_undeclared(self, target: str) -&gt; bool:\n         \"\"\"Checks if a given target is an undeclared parameter.\"\"\"\n-        pass\n+        if not self._param_def_block:\n+            return False\n+        return target in self._param_def_block[-1]\n\n-    def push_assign_tracking(self) -&gt;None:\n+    def push_assign_tracking(self) -&gt; None:\n         \"\"\"Pushes a new layer for assignment tracking.\"\"\"\n-        pass\n+        self._assign_stack.append(set())\n\n-    def pop_assign_tracking(self, frame: Frame) -&gt;None:\n+    def pop_assign_tracking(self, frame: Frame) -&gt; None:\n         \"\"\"Pops the topmost level for assignment tracking and updates the\n         context variables if necessary.\n         \"\"\"\n-        pass\n-\n-    def visit_Block(self, node: nodes.Block, frame: Frame) -&gt;None:\n+        vars = self._assign_stack.pop()\n+        if (\n+            not frame.block_frame\n+            and not frame.loop_frame\n+            and not frame.toplevel\n+            or not vars\n+        ):\n+            return\n+        public_names = [x for x in vars if x[:1] != \"_\"]\n+        if len(vars) == 1:\n+            name = next(iter(vars))\n+            ref = frame.symbols.ref(name)\n+            if frame.loop_frame:\n+                self.writeline(f\"_loop_vars[{name!r}] = {ref}\")\n+                return\n+            if frame.block_frame:\n+                self.writeline(f\"_block_vars[{name!r}] = {ref}\")\n+                return\n+            self.writeline(f\"context.vars[{name!r}] = {ref}\")\n+        else:\n+            if frame.loop_frame:\n+                self.writeline(\"_loop_vars.update({\")\n+            elif frame.block_frame:\n+                self.writeline(\"_block_vars.update({\")\n+            else:\n+                self.writeline(\"context.vars.update({\")\n+            for idx, name in enumerate(vars):\n+                if idx:\n+                    self.write(\", \")\n+                ref = frame.symbols.ref(name)\n+                self.write(f\"{name!r}: {ref}\")\n+            self.write(\"})\")\n+        if not frame.block_frame and not frame.loop_frame and public_names:\n+            if len(public_names) == 1:\n+                self.writeline(f\"context.exported_vars.add({public_names[0]!r})\")\n+            else:\n+                names_str = \", \".join(map(repr, public_names))\n+                self.writeline(f\"context.exported_vars.update(({names_str}))\")\n+\n+    # -- Statement Visitors\n+\n+    def visit_Template(\n+        self, node: nodes.Template, frame: t.Optional[Frame] = None\n+    ) -&gt; None:\n+        assert frame is None, \"no root frame allowed\"\n+        eval_ctx = EvalContext(self.environment, self.name)\n+\n+        from .runtime import async_exported\n+        from .runtime import exported\n+\n+        if self.environment.is_async:\n+            exported_names = sorted(exported + async_exported)\n+        else:\n+            exported_names = sorted(exported)\n+\n+        self.writeline(\"from jinja2.runtime import \" + \", \".join(exported_names))\n+\n+        # if we want a deferred initialization we cannot move the\n+        # environment into a local name\n+        envenv = \"\" if self.defer_init else \", environment=environment\"\n+\n+        # do we have an extends tag at all?  If not, we can save some\n+        # overhead by just not processing any inheritance code.\n+        have_extends = node.find(nodes.Extends) is not None\n+\n+        # find all blocks\n+        for block in node.find_all(nodes.Block):\n+            if block.name in self.blocks:\n+                self.fail(f\"block {block.name!r} defined twice\", block.lineno)\n+            self.blocks[block.name] = block\n+\n+        # find all imports and import them\n+        for import_ in node.find_all(nodes.ImportedName):\n+            if import_.importname not in self.import_aliases:\n+                imp = import_.importname\n+                self.import_aliases[imp] = alias = self.temporary_identifier()\n+                if \".\" in imp:\n+                    module, obj = imp.rsplit(\".\", 1)\n+                    self.writeline(f\"from {module} import {obj} as {alias}\")\n+                else:\n+                    self.writeline(f\"import {imp} as {alias}\")\n+\n+        # add the load name\n+        self.writeline(f\"name = {self.name!r}\")\n+\n+        # generate the root render function.\n+        self.writeline(\n+            f\"{self.func('root')}(context, missing=missing{envenv}):\", extra=1\n+        )\n+        self.indent()\n+        self.write_commons()\n+\n+        # process the root\n+        frame = Frame(eval_ctx)\n+        if \"self\" in find_undeclared(node.body, (\"self\",)):\n+            ref = frame.symbols.declare_parameter(\"self\")\n+            self.writeline(f\"{ref} = TemplateReference(context)\")\n+        frame.symbols.analyze_node(node)\n+        frame.toplevel = frame.rootlevel = True\n+        frame.require_output_check = have_extends and not self.has_known_extends\n+        if have_extends:\n+            self.writeline(\"parent_template = None\")\n+        self.enter_frame(frame)\n+        self.pull_dependencies(node.body)\n+        self.blockvisit(node.body, frame)\n+        self.leave_frame(frame, with_python_scope=True)\n+        self.outdent()\n+\n+        # make sure that the parent root is called.\n+        if have_extends:\n+            if not self.has_known_extends:\n+                self.indent()\n+                self.writeline(\"if parent_template is not None:\")\n+            self.indent()\n+            if not self.environment.is_async:\n+                self.writeline(\"yield from parent_template.root_render_func(context)\")\n+            else:\n+                self.writeline(\n+                    \"async for event in parent_template.root_render_func(context):\"\n+                )\n+                self.indent()\n+                self.writeline(\"yield event\")\n+                self.outdent()\n+            self.outdent(1 + (not self.has_known_extends))\n+\n+        # at this point we now have the blocks collected and can visit them too.\n+        for name, block in self.blocks.items():\n+            self.writeline(\n+                f\"{self.func('block_' + name)}(context, missing=missing{envenv}):\",\n+                block,\n+                1,\n+            )\n+            self.indent()\n+            self.write_commons()\n+            # It's important that we do not make this frame a child of the\n+            # toplevel template.  This would cause a variety of\n+            # interesting issues with identifier tracking.\n+            block_frame = Frame(eval_ctx)\n+            block_frame.block_frame = True\n+            undeclared = find_undeclared(block.body, (\"self\", \"super\"))\n+            if \"self\" in undeclared:\n+                ref = block_frame.symbols.declare_parameter(\"self\")\n+                self.writeline(f\"{ref} = TemplateReference(context)\")\n+            if \"super\" in undeclared:\n+                ref = block_frame.symbols.declare_parameter(\"super\")\n+                self.writeline(f\"{ref} = context.super({name!r}, block_{name})\")\n+            block_frame.symbols.analyze_node(block)\n+            block_frame.block = name\n+            self.writeline(\"_block_vars = {}\")\n+            self.enter_frame(block_frame)\n+            self.pull_dependencies(block.body)\n+            self.blockvisit(block.body, block_frame)\n+            self.leave_frame(block_frame, with_python_scope=True)\n+            self.outdent()\n+\n+        blocks_kv_str = \", \".join(f\"{x!r}: block_{x}\" for x in self.blocks)\n+        self.writeline(f\"blocks = {{{blocks_kv_str}}}\", extra=1)\n+        debug_kv_str = \"&amp;\".join(f\"{k}={v}\" for k, v in self.debug_info)\n+        self.writeline(f\"debug_info = {debug_kv_str!r}\")\n+\n+    def visit_Block(self, node: nodes.Block, frame: Frame) -&gt; None:\n         \"\"\"Call a block and register it for the template.\"\"\"\n-        pass\n-\n-    def visit_Extends(self, node: nodes.Extends, frame: Frame) -&gt;None:\n+        level = 0\n+        if frame.toplevel:\n+            # if we know that we are a child template, there is no need to\n+            # check if we are one\n+            if self.has_known_extends:\n+                return\n+            if self.extends_so_far &gt; 0:\n+                self.writeline(\"if parent_template is None:\")\n+                self.indent()\n+                level += 1\n+\n+        if node.scoped:\n+            context = self.derive_context(frame)\n+        else:\n+            context = self.get_context_ref()\n+\n+        if node.required:\n+            self.writeline(f\"if len(context.blocks[{node.name!r}]) &lt;= 1:\", node)\n+            self.indent()\n+            self.writeline(\n+                f'raise TemplateRuntimeError(\"Required block {node.name!r} not found\")',\n+                node,\n+            )\n+            self.outdent()\n+\n+        if not self.environment.is_async and frame.buffer is None:\n+            self.writeline(\n+                f\"yield from context.blocks[{node.name!r}][0]({context})\", node\n+            )\n+        else:\n+            self.writeline(\n+                f\"{self.choose_async()}for event in\"\n+                f\" context.blocks[{node.name!r}][0]({context}):\",\n+                node,\n+            )\n+            self.indent()\n+            self.simple_write(\"event\", frame)\n+            self.outdent()\n+\n+        self.outdent(level)\n+\n+    def visit_Extends(self, node: nodes.Extends, frame: Frame) -&gt; None:\n         \"\"\"Calls the extender.\"\"\"\n-        pass\n-\n-    def visit_Include(self, node: nodes.Include, frame: Frame) -&gt;None:\n+        if not frame.toplevel:\n+            self.fail(\"cannot use extend from a non top-level scope\", node.lineno)\n+\n+        # if the number of extends statements in general is zero so\n+        # far, we don't have to add a check if something extended\n+        # the template before this one.\n+        if self.extends_so_far &gt; 0:\n+            # if we have a known extends we just add a template runtime\n+            # error into the generated code.  We could catch that at compile\n+            # time too, but i welcome it not to confuse users by throwing the\n+            # same error at different times just \"because we can\".\n+            if not self.has_known_extends:\n+                self.writeline(\"if parent_template is not None:\")\n+                self.indent()\n+            self.writeline('raise TemplateRuntimeError(\"extended multiple times\")')\n+\n+            # if we have a known extends already we don't need that code here\n+            # as we know that the template execution will end here.\n+            if self.has_known_extends:\n+                raise CompilerExit()\n+            else:\n+                self.outdent()\n+\n+        self.writeline(\"parent_template = environment.get_template(\", node)\n+        self.visit(node.template, frame)\n+        self.write(f\", {self.name!r})\")\n+        self.writeline(\"for name, parent_block in parent_template.blocks.items():\")\n+        self.indent()\n+        self.writeline(\"context.blocks.setdefault(name, []).append(parent_block)\")\n+        self.outdent()\n+\n+        # if this extends statement was in the root level we can take\n+        # advantage of that information and simplify the generated code\n+        # in the top level from this point onwards\n+        if frame.rootlevel:\n+            self.has_known_extends = True\n+\n+        # and now we have one more\n+        self.extends_so_far += 1\n+\n+    def visit_Include(self, node: nodes.Include, frame: Frame) -&gt; None:\n         \"\"\"Handles includes.\"\"\"\n-        pass\n+        if node.ignore_missing:\n+            self.writeline(\"try:\")\n+            self.indent()\n+\n+        func_name = \"get_or_select_template\"\n+        if isinstance(node.template, nodes.Const):\n+            if isinstance(node.template.value, str):\n+                func_name = \"get_template\"\n+            elif isinstance(node.template.value, (tuple, list)):\n+                func_name = \"select_template\"\n+        elif isinstance(node.template, (nodes.Tuple, nodes.List)):\n+            func_name = \"select_template\"\n+\n+        self.writeline(f\"template = environment.{func_name}(\", node)\n+        self.visit(node.template, frame)\n+        self.write(f\", {self.name!r})\")\n+        if node.ignore_missing:\n+            self.outdent()\n+            self.writeline(\"except TemplateNotFound:\")\n+            self.indent()\n+            self.writeline(\"pass\")\n+            self.outdent()\n+            self.writeline(\"else:\")\n+            self.indent()\n+\n+        skip_event_yield = False\n+        if node.with_context:\n+            self.writeline(\n+                f\"{self.choose_async()}for event in template.root_render_func(\"\n+                \"template.new_context(context.get_all(), True,\"\n+                f\" {self.dump_local_context(frame)})):\"\n+            )\n+        elif self.environment.is_async:\n+            self.writeline(\n+                \"for event in (await template._get_default_module_async())\"\n+                \"._body_stream:\"\n+            )\n+        else:\n+            self.writeline(\"yield from template._get_default_module()._body_stream\")\n+            skip_event_yield = True\n+\n+        if not skip_event_yield:\n+            self.indent()\n+            self.simple_write(\"event\", frame)\n+            self.outdent()\n+\n+        if node.ignore_missing:\n+            self.outdent()\n+\n+    def _import_common(\n+        self, node: t.Union[nodes.Import, nodes.FromImport], frame: Frame\n+    ) -&gt; None:\n+        self.write(f\"{self.choose_async('await ')}environment.get_template(\")\n+        self.visit(node.template, frame)\n+        self.write(f\", {self.name!r}).\")\n+\n+        if node.with_context:\n+            f_name = f\"make_module{self.choose_async('_async')}\"\n+            self.write(\n+                f\"{f_name}(context.get_all(), True, {self.dump_local_context(frame)})\"\n+            )\n+        else:\n+            self.write(f\"_get_default_module{self.choose_async('_async')}(context)\")\n\n-    def visit_Import(self, node: nodes.Import, frame: Frame) -&gt;None:\n+    def visit_Import(self, node: nodes.Import, frame: Frame) -&gt; None:\n         \"\"\"Visit regular imports.\"\"\"\n-        pass\n+        self.writeline(f\"{frame.symbols.ref(node.target)} = \", node)\n+        if frame.toplevel:\n+            self.write(f\"context.vars[{node.target!r}] = \")\n+\n+        self._import_common(node, frame)\n\n-    def visit_FromImport(self, node: nodes.FromImport, frame: Frame) -&gt;None:\n+        if frame.toplevel and not node.target.startswith(\"_\"):\n+            self.writeline(f\"context.exported_vars.discard({node.target!r})\")\n+\n+    def visit_FromImport(self, node: nodes.FromImport, frame: Frame) -&gt; None:\n         \"\"\"Visit named imports.\"\"\"\n-        pass\n+        self.newline(node)\n+        self.write(\"included_template = \")\n+        self._import_common(node, frame)\n+        var_names = []\n+        discarded_names = []\n+        for name in node.names:\n+            if isinstance(name, tuple):\n+                name, alias = name\n+            else:\n+                alias = name\n+            self.writeline(\n+                f\"{frame.symbols.ref(alias)} =\"\n+                f\" getattr(included_template, {name!r}, missing)\"\n+            )\n+            self.writeline(f\"if {frame.symbols.ref(alias)} is missing:\")\n+            self.indent()\n+            message = (\n+                \"the template {included_template.__name__!r}\"\n+                f\" (imported on {self.position(node)})\"\n+                f\" does not export the requested name {name!r}\"\n+            )\n+            self.writeline(\n+                f\"{frame.symbols.ref(alias)} = undefined(f{message!r}, name={name!r})\"\n+            )\n+            self.outdent()\n+            if frame.toplevel:\n+                var_names.append(alias)\n+                if not alias.startswith(\"_\"):\n+                    discarded_names.append(alias)\n+\n+        if var_names:\n+            if len(var_names) == 1:\n+                name = var_names[0]\n+                self.writeline(f\"context.vars[{name!r}] = {frame.symbols.ref(name)}\")\n+            else:\n+                names_kv = \", \".join(\n+                    f\"{name!r}: {frame.symbols.ref(name)}\" for name in var_names\n+                )\n+                self.writeline(f\"context.vars.update({{{names_kv}}})\")\n+        if discarded_names:\n+            if len(discarded_names) == 1:\n+                self.writeline(f\"context.exported_vars.discard({discarded_names[0]!r})\")\n+            else:\n+                names_str = \", \".join(map(repr, discarded_names))\n+                self.writeline(\n+                    f\"context.exported_vars.difference_update(({names_str}))\"\n+                )\n+\n+    def visit_For(self, node: nodes.For, frame: Frame) -&gt; None:\n+        loop_frame = frame.inner()\n+        loop_frame.loop_frame = True\n+        test_frame = frame.inner()\n+        else_frame = frame.inner()\n+\n+        # try to figure out if we have an extended loop.  An extended loop\n+        # is necessary if the loop is in recursive mode if the special loop\n+        # variable is accessed in the body if the body is a scoped block.\n+        extended_loop = (\n+            node.recursive\n+            or \"loop\"\n+            in find_undeclared(node.iter_child_nodes(only=(\"body\",)), (\"loop\",))\n+            or any(block.scoped for block in node.find_all(nodes.Block))\n+        )\n+\n+        loop_ref = None\n+        if extended_loop:\n+            loop_ref = loop_frame.symbols.declare_parameter(\"loop\")\n+\n+        loop_frame.symbols.analyze_node(node, for_branch=\"body\")\n+        if node.else_:\n+            else_frame.symbols.analyze_node(node, for_branch=\"else\")\n+\n+        if node.test:\n+            loop_filter_func = self.temporary_identifier()\n+            test_frame.symbols.analyze_node(node, for_branch=\"test\")\n+            self.writeline(f\"{self.func(loop_filter_func)}(fiter):\", node.test)\n+            self.indent()\n+            self.enter_frame(test_frame)\n+            self.writeline(self.choose_async(\"async for \", \"for \"))\n+            self.visit(node.target, loop_frame)\n+            self.write(\" in \")\n+            self.write(self.choose_async(\"auto_aiter(fiter)\", \"fiter\"))\n+            self.write(\":\")\n+            self.indent()\n+            self.writeline(\"if \", node.test)\n+            self.visit(node.test, test_frame)\n+            self.write(\":\")\n+            self.indent()\n+            self.writeline(\"yield \")\n+            self.visit(node.target, loop_frame)\n+            self.outdent(3)\n+            self.leave_frame(test_frame, with_python_scope=True)\n+\n+        # if we don't have an recursive loop we have to find the shadowed\n+        # variables at that point.  Because loops can be nested but the loop\n+        # variable is a special one we have to enforce aliasing for it.\n+        if node.recursive:\n+            self.writeline(\n+                f\"{self.func('loop')}(reciter, loop_render_func, depth=0):\", node\n+            )\n+            self.indent()\n+            self.buffer(loop_frame)\n+\n+            # Use the same buffer for the else frame\n+            else_frame.buffer = loop_frame.buffer\n+\n+        # make sure the loop variable is a special one and raise a template\n+        # assertion error if a loop tries to write to loop\n+        if extended_loop:\n+            self.writeline(f\"{loop_ref} = missing\")\n+\n+        for name in node.find_all(nodes.Name):\n+            if name.ctx == \"store\" and name.name == \"loop\":\n+                self.fail(\n+                    \"Can't assign to special loop variable in for-loop target\",\n+                    name.lineno,\n+                )\n+\n+        if node.else_:\n+            iteration_indicator = self.temporary_identifier()\n+            self.writeline(f\"{iteration_indicator} = 1\")\n+\n+        self.writeline(self.choose_async(\"async for \", \"for \"), node)\n+        self.visit(node.target, loop_frame)\n+        if extended_loop:\n+            self.write(f\", {loop_ref} in {self.choose_async('Async')}LoopContext(\")\n+        else:\n+            self.write(\" in \")\n\n+        if node.test:\n+            self.write(f\"{loop_filter_func}(\")\n+        if node.recursive:\n+            self.write(\"reciter\")\n+        else:\n+            if self.environment.is_async and not extended_loop:\n+                self.write(\"auto_aiter(\")\n+            self.visit(node.iter, frame)\n+            if self.environment.is_async and not extended_loop:\n+                self.write(\")\")\n+        if node.test:\n+            self.write(\")\")\n+\n+        if node.recursive:\n+            self.write(\", undefined, loop_render_func, depth):\")\n+        else:\n+            self.write(\", undefined):\" if extended_loop else \":\")\n+\n+        self.indent()\n+        self.enter_frame(loop_frame)\n+\n+        self.writeline(\"_loop_vars = {}\")\n+        self.blockvisit(node.body, loop_frame)\n+        if node.else_:\n+            self.writeline(f\"{iteration_indicator} = 0\")\n+        self.outdent()\n+        self.leave_frame(\n+            loop_frame, with_python_scope=node.recursive and not node.else_\n+        )\n+\n+        if node.else_:\n+            self.writeline(f\"if {iteration_indicator}:\")\n+            self.indent()\n+            self.enter_frame(else_frame)\n+            self.blockvisit(node.else_, else_frame)\n+            self.leave_frame(else_frame)\n+            self.outdent()\n+\n+        # if the node was recursive we have to return the buffer contents\n+        # and start the iteration code\n+        if node.recursive:\n+            self.return_buffer_contents(loop_frame)\n+            self.outdent()\n+            self.start_write(frame, node)\n+            self.write(f\"{self.choose_async('await ')}loop(\")\n+            if self.environment.is_async:\n+                self.write(\"auto_aiter(\")\n+            self.visit(node.iter, frame)\n+            if self.environment.is_async:\n+                self.write(\")\")\n+            self.write(\", loop)\")\n+            self.end_write(frame)\n+\n+        # at the end of the iteration, clear any assignments made in the\n+        # loop from the top level\n+        if self._assign_stack:\n+            self._assign_stack[-1].difference_update(loop_frame.symbols.stores)\n+\n+    def visit_If(self, node: nodes.If, frame: Frame) -&gt; None:\n+        if_frame = frame.soft()\n+        self.writeline(\"if \", node)\n+        self.visit(node.test, if_frame)\n+        self.write(\":\")\n+        self.indent()\n+        self.blockvisit(node.body, if_frame)\n+        self.outdent()\n+        for elif_ in node.elif_:\n+            self.writeline(\"elif \", elif_)\n+            self.visit(elif_.test, if_frame)\n+            self.write(\":\")\n+            self.indent()\n+            self.blockvisit(elif_.body, if_frame)\n+            self.outdent()\n+        if node.else_:\n+            self.writeline(\"else:\")\n+            self.indent()\n+            self.blockvisit(node.else_, if_frame)\n+            self.outdent()\n+\n+    def visit_Macro(self, node: nodes.Macro, frame: Frame) -&gt; None:\n+        macro_frame, macro_ref = self.macro_body(node, frame)\n+        self.newline()\n+        if frame.toplevel:\n+            if not node.name.startswith(\"_\"):\n+                self.write(f\"context.exported_vars.add({node.name!r})\")\n+            self.writeline(f\"context.vars[{node.name!r}] = \")\n+        self.write(f\"{frame.symbols.ref(node.name)} = \")\n+        self.macro_def(macro_ref, macro_frame)\n+\n+    def visit_CallBlock(self, node: nodes.CallBlock, frame: Frame) -&gt; None:\n+        call_frame, macro_ref = self.macro_body(node, frame)\n+        self.writeline(\"caller = \")\n+        self.macro_def(macro_ref, call_frame)\n+        self.start_write(frame, node)\n+        self.visit_Call(node.call, frame, forward_caller=True)\n+        self.end_write(frame)\n+\n+    def visit_FilterBlock(self, node: nodes.FilterBlock, frame: Frame) -&gt; None:\n+        filter_frame = frame.inner()\n+        filter_frame.symbols.analyze_node(node)\n+        self.enter_frame(filter_frame)\n+        self.buffer(filter_frame)\n+        self.blockvisit(node.body, filter_frame)\n+        self.start_write(frame, node)\n+        self.visit_Filter(node.filter, filter_frame)\n+        self.end_write(frame)\n+        self.leave_frame(filter_frame)\n+\n+    def visit_With(self, node: nodes.With, frame: Frame) -&gt; None:\n+        with_frame = frame.inner()\n+        with_frame.symbols.analyze_node(node)\n+        self.enter_frame(with_frame)\n+        for target, expr in zip(node.targets, node.values):\n+            self.newline()\n+            self.visit(target, with_frame)\n+            self.write(\" = \")\n+            self.visit(expr, frame)\n+        self.blockvisit(node.body, with_frame)\n+        self.leave_frame(with_frame)\n+\n+    def visit_ExprStmt(self, node: nodes.ExprStmt, frame: Frame) -&gt; None:\n+        self.newline(node)\n+        self.visit(node.node, frame)\n\n     class _FinalizeInfo(t.NamedTuple):\n         const: t.Optional[t.Callable[..., str]]\n         src: t.Optional[str]\n\n     @staticmethod\n-    def _default_finalize(value: t.Any) -&gt;t.Any:\n+    def _default_finalize(value: t.Any) -&gt; t.Any:\n         \"\"\"The default finalize function if the environment isn't\n         configured with one. Or, if the environment has one, this is\n         called on that function's output for constants.\n         \"\"\"\n-        pass\n+        return str(value)\n+\n     _finalize: t.Optional[_FinalizeInfo] = None\n\n-    def _make_finalize(self) -&gt;_FinalizeInfo:\n+    def _make_finalize(self) -&gt; _FinalizeInfo:\n         \"\"\"Build the finalize function to be used on constants and at\n         runtime. Cached so it's only created once for all output nodes.\n\n@@ -353,17 +1389,51 @@ class CodeGenerator(NodeVisitor):\n             Source code to output around nodes to be evaluated at\n             runtime.\n         \"\"\"\n-        pass\n+        if self._finalize is not None:\n+            return self._finalize\n+\n+        finalize: t.Optional[t.Callable[..., t.Any]]\n+        finalize = default = self._default_finalize\n+        src = None\n+\n+        if self.environment.finalize:\n+            src = \"environment.finalize(\"\n+            env_finalize = self.environment.finalize\n+            pass_arg = {\n+                _PassArg.context: \"context\",\n+                _PassArg.eval_context: \"context.eval_ctx\",\n+                _PassArg.environment: \"environment\",\n+            }.get(\n+                _PassArg.from_obj(env_finalize)  # type: ignore\n+            )\n+            finalize = None\n+\n+            if pass_arg is None:\n+\n+                def finalize(value: t.Any) -&gt; t.Any:  # noqa: F811\n+                    return default(env_finalize(value))\n+\n+            else:\n+                src = f\"{src}{pass_arg}, \"\n\n-    def _output_const_repr(self, group: t.Iterable[t.Any]) -&gt;str:\n+                if pass_arg == \"environment\":\n+\n+                    def finalize(value: t.Any) -&gt; t.Any:  # noqa: F811\n+                        return default(env_finalize(self.environment, value))\n+\n+        self._finalize = self._FinalizeInfo(finalize, src)\n+        return self._finalize\n+\n+    def _output_const_repr(self, group: t.Iterable[t.Any]) -&gt; str:\n         \"\"\"Given a group of constant values converted from ``Output``\n         child nodes, produce a string to write to the template module\n         source.\n         \"\"\"\n-        pass\n+        return repr(concat(group))\n\n-    def _output_child_to_const(self, node: nodes.Expr, frame: Frame,\n-        finalize: _FinalizeInfo) -&gt;str:\n+    def _output_child_to_const(\n+        self, node: nodes.Expr, frame: Frame, finalize: _FinalizeInfo\n+    ) -&gt; str:\n         \"\"\"Try to optimize a child of an ``Output`` node by trying to\n         convert it to constant, finalized data at compile time.\n\n@@ -371,30 +1441,520 @@ class CodeGenerator(NodeVisitor):\n         will be evaluated at runtime. Any other exception will also be\n         evaluated at runtime for easier debugging.\n         \"\"\"\n-        pass\n+        const = node.as_const(frame.eval_ctx)\n\n-    def _output_child_pre(self, node: nodes.Expr, frame: Frame, finalize:\n-        _FinalizeInfo) -&gt;None:\n+        if frame.eval_ctx.autoescape:\n+            const = escape(const)\n+\n+        # Template data doesn't go through finalize.\n+        if isinstance(node, nodes.TemplateData):\n+            return str(const)\n+\n+        return finalize.const(const)  # type: ignore\n+\n+    def _output_child_pre(\n+        self, node: nodes.Expr, frame: Frame, finalize: _FinalizeInfo\n+    ) -&gt; None:\n         \"\"\"Output extra source code before visiting a child of an\n         ``Output`` node.\n         \"\"\"\n-        pass\n+        if frame.eval_ctx.volatile:\n+            self.write(\"(escape if context.eval_ctx.autoescape else str)(\")\n+        elif frame.eval_ctx.autoescape:\n+            self.write(\"escape(\")\n+        else:\n+            self.write(\"str(\")\n+\n+        if finalize.src is not None:\n+            self.write(finalize.src)\n\n-    def _output_child_post(self, node: nodes.Expr, frame: Frame, finalize:\n-        _FinalizeInfo) -&gt;None:\n+    def _output_child_post(\n+        self, node: nodes.Expr, frame: Frame, finalize: _FinalizeInfo\n+    ) -&gt; None:\n         \"\"\"Output extra source code after visiting a child of an\n         ``Output`` node.\n         \"\"\"\n-        pass\n-    visit_Add = _make_binop('+')\n-    visit_Sub = _make_binop('-')\n-    visit_Mul = _make_binop('*')\n-    visit_Div = _make_binop('/')\n-    visit_FloorDiv = _make_binop('//')\n-    visit_Pow = _make_binop('**')\n-    visit_Mod = _make_binop('%')\n-    visit_And = _make_binop('and')\n-    visit_Or = _make_binop('or')\n-    visit_Pos = _make_unop('+')\n-    visit_Neg = _make_unop('-')\n-    visit_Not = _make_unop('not ')\n+        self.write(\")\")\n+\n+        if finalize.src is not None:\n+            self.write(\")\")\n+\n+    def visit_Output(self, node: nodes.Output, frame: Frame) -&gt; None:\n+        # If an extends is active, don't render outside a block.\n+        if frame.require_output_check:\n+            # A top-level extends is known to exist at compile time.\n+            if self.has_known_extends:\n+                return\n+\n+            self.writeline(\"if parent_template is None:\")\n+            self.indent()\n+\n+        finalize = self._make_finalize()\n+        body: t.List[t.Union[t.List[t.Any], nodes.Expr]] = []\n+\n+        # Evaluate constants at compile time if possible. Each item in\n+        # body will be either a list of static data or a node to be\n+        # evaluated at runtime.\n+        for child in node.nodes:\n+            try:\n+                if not (\n+                    # If the finalize function requires runtime context,\n+                    # constants can't be evaluated at compile time.\n+                    finalize.const\n+                    # Unless it's basic template data that won't be\n+                    # finalized anyway.\n+                    or isinstance(child, nodes.TemplateData)\n+                ):\n+                    raise nodes.Impossible()\n+\n+                const = self._output_child_to_const(child, frame, finalize)\n+            except (nodes.Impossible, Exception):\n+                # The node was not constant and needs to be evaluated at\n+                # runtime. Or another error was raised, which is easier\n+                # to debug at runtime.\n+                body.append(child)\n+                continue\n+\n+            if body and isinstance(body[-1], list):\n+                body[-1].append(const)\n+            else:\n+                body.append([const])\n+\n+        if frame.buffer is not None:\n+            if len(body) == 1:\n+                self.writeline(f\"{frame.buffer}.append(\")\n+            else:\n+                self.writeline(f\"{frame.buffer}.extend((\")\n+\n+            self.indent()\n+\n+        for item in body:\n+            if isinstance(item, list):\n+                # A group of constant data to join and output.\n+                val = self._output_const_repr(item)\n+\n+                if frame.buffer is None:\n+                    self.writeline(\"yield \" + val)\n+                else:\n+                    self.writeline(val + \",\")\n+            else:\n+                if frame.buffer is None:\n+                    self.writeline(\"yield \", item)\n+                else:\n+                    self.newline(item)\n+\n+                # A node to be evaluated at runtime.\n+                self._output_child_pre(item, frame, finalize)\n+                self.visit(item, frame)\n+                self._output_child_post(item, frame, finalize)\n+\n+                if frame.buffer is not None:\n+                    self.write(\",\")\n+\n+        if frame.buffer is not None:\n+            self.outdent()\n+            self.writeline(\")\" if len(body) == 1 else \"))\")\n+\n+        if frame.require_output_check:\n+            self.outdent()\n+\n+    def visit_Assign(self, node: nodes.Assign, frame: Frame) -&gt; None:\n+        self.push_assign_tracking()\n+        self.newline(node)\n+        self.visit(node.target, frame)\n+        self.write(\" = \")\n+        self.visit(node.node, frame)\n+        self.pop_assign_tracking(frame)\n+\n+    def visit_AssignBlock(self, node: nodes.AssignBlock, frame: Frame) -&gt; None:\n+        self.push_assign_tracking()\n+        block_frame = frame.inner()\n+        # This is a special case.  Since a set block always captures we\n+        # will disable output checks.  This way one can use set blocks\n+        # toplevel even in extended templates.\n+        block_frame.require_output_check = False\n+        block_frame.symbols.analyze_node(node)\n+        self.enter_frame(block_frame)\n+        self.buffer(block_frame)\n+        self.blockvisit(node.body, block_frame)\n+        self.newline(node)\n+        self.visit(node.target, frame)\n+        self.write(\" = (Markup if context.eval_ctx.autoescape else identity)(\")\n+        if node.filter is not None:\n+            self.visit_Filter(node.filter, block_frame)\n+        else:\n+            self.write(f\"concat({block_frame.buffer})\")\n+        self.write(\")\")\n+        self.pop_assign_tracking(frame)\n+        self.leave_frame(block_frame)\n+\n+    # -- Expression Visitors\n+\n+    def visit_Name(self, node: nodes.Name, frame: Frame) -&gt; None:\n+        if node.ctx == \"store\" and (\n+            frame.toplevel or frame.loop_frame or frame.block_frame\n+        ):\n+            if self._assign_stack:\n+                self._assign_stack[-1].add(node.name)\n+        ref = frame.symbols.ref(node.name)\n+\n+        # If we are looking up a variable we might have to deal with the\n+        # case where it's undefined.  We can skip that case if the load\n+        # instruction indicates a parameter which are always defined.\n+        if node.ctx == \"load\":\n+            load = frame.symbols.find_load(ref)\n+            if not (\n+                load is not None\n+                and load[0] == VAR_LOAD_PARAMETER\n+                and not self.parameter_is_undeclared(ref)\n+            ):\n+                self.write(\n+                    f\"(undefined(name={node.name!r}) if {ref} is missing else {ref})\"\n+                )\n+                return\n+\n+        self.write(ref)\n+\n+    def visit_NSRef(self, node: nodes.NSRef, frame: Frame) -&gt; None:\n+        # NSRefs can only be used to store values; since they use the normal\n+        # `foo.bar` notation they will be parsed as a normal attribute access\n+        # when used anywhere but in a `set` context\n+        ref = frame.symbols.ref(node.name)\n+        self.writeline(f\"if not isinstance({ref}, Namespace):\")\n+        self.indent()\n+        self.writeline(\n+            \"raise TemplateRuntimeError\"\n+            '(\"cannot assign attribute on non-namespace object\")'\n+        )\n+        self.outdent()\n+        self.writeline(f\"{ref}[{node.attr!r}]\")\n+\n+    def visit_Const(self, node: nodes.Const, frame: Frame) -&gt; None:\n+        val = node.as_const(frame.eval_ctx)\n+        if isinstance(val, float):\n+            self.write(str(val))\n+        else:\n+            self.write(repr(val))\n+\n+    def visit_TemplateData(self, node: nodes.TemplateData, frame: Frame) -&gt; None:\n+        try:\n+            self.write(repr(node.as_const(frame.eval_ctx)))\n+        except nodes.Impossible:\n+            self.write(\n+                f\"(Markup if context.eval_ctx.autoescape else identity)({node.data!r})\"\n+            )\n+\n+    def visit_Tuple(self, node: nodes.Tuple, frame: Frame) -&gt; None:\n+        self.write(\"(\")\n+        idx = -1\n+        for idx, item in enumerate(node.items):\n+            if idx:\n+                self.write(\", \")\n+            self.visit(item, frame)\n+        self.write(\",)\" if idx == 0 else \")\")\n+\n+    def visit_List(self, node: nodes.List, frame: Frame) -&gt; None:\n+        self.write(\"[\")\n+        for idx, item in enumerate(node.items):\n+            if idx:\n+                self.write(\", \")\n+            self.visit(item, frame)\n+        self.write(\"]\")\n+\n+    def visit_Dict(self, node: nodes.Dict, frame: Frame) -&gt; None:\n+        self.write(\"{\")\n+        for idx, item in enumerate(node.items):\n+            if idx:\n+                self.write(\", \")\n+            self.visit(item.key, frame)\n+            self.write(\": \")\n+            self.visit(item.value, frame)\n+        self.write(\"}\")\n+\n+    visit_Add = _make_binop(\"+\")\n+    visit_Sub = _make_binop(\"-\")\n+    visit_Mul = _make_binop(\"*\")\n+    visit_Div = _make_binop(\"/\")\n+    visit_FloorDiv = _make_binop(\"//\")\n+    visit_Pow = _make_binop(\"**\")\n+    visit_Mod = _make_binop(\"%\")\n+    visit_And = _make_binop(\"and\")\n+    visit_Or = _make_binop(\"or\")\n+    visit_Pos = _make_unop(\"+\")\n+    visit_Neg = _make_unop(\"-\")\n+    visit_Not = _make_unop(\"not \")\n+\n+    @optimizeconst\n+    def visit_Concat(self, node: nodes.Concat, frame: Frame) -&gt; None:\n+        if frame.eval_ctx.volatile:\n+            func_name = \"(markup_join if context.eval_ctx.volatile else str_join)\"\n+        elif frame.eval_ctx.autoescape:\n+            func_name = \"markup_join\"\n+        else:\n+            func_name = \"str_join\"\n+        self.write(f\"{func_name}((\")\n+        for arg in node.nodes:\n+            self.visit(arg, frame)\n+            self.write(\", \")\n+        self.write(\"))\")\n+\n+    @optimizeconst\n+    def visit_Compare(self, node: nodes.Compare, frame: Frame) -&gt; None:\n+        self.write(\"(\")\n+        self.visit(node.expr, frame)\n+        for op in node.ops:\n+            self.visit(op, frame)\n+        self.write(\")\")\n+\n+    def visit_Operand(self, node: nodes.Operand, frame: Frame) -&gt; None:\n+        self.write(f\" {operators[node.op]} \")\n+        self.visit(node.expr, frame)\n+\n+    @optimizeconst\n+    def visit_Getattr(self, node: nodes.Getattr, frame: Frame) -&gt; None:\n+        if self.environment.is_async:\n+            self.write(\"(await auto_await(\")\n+\n+        self.write(\"environment.getattr(\")\n+        self.visit(node.node, frame)\n+        self.write(f\", {node.attr!r})\")\n+\n+        if self.environment.is_async:\n+            self.write(\"))\")\n+\n+    @optimizeconst\n+    def visit_Getitem(self, node: nodes.Getitem, frame: Frame) -&gt; None:\n+        # slices bypass the environment getitem method.\n+        if isinstance(node.arg, nodes.Slice):\n+            self.visit(node.node, frame)\n+            self.write(\"[\")\n+            self.visit(node.arg, frame)\n+            self.write(\"]\")\n+        else:\n+            if self.environment.is_async:\n+                self.write(\"(await auto_await(\")\n+\n+            self.write(\"environment.getitem(\")\n+            self.visit(node.node, frame)\n+            self.write(\", \")\n+            self.visit(node.arg, frame)\n+            self.write(\")\")\n+\n+            if self.environment.is_async:\n+                self.write(\"))\")\n+\n+    def visit_Slice(self, node: nodes.Slice, frame: Frame) -&gt; None:\n+        if node.start is not None:\n+            self.visit(node.start, frame)\n+        self.write(\":\")\n+        if node.stop is not None:\n+            self.visit(node.stop, frame)\n+        if node.step is not None:\n+            self.write(\":\")\n+            self.visit(node.step, frame)\n+\n+    @contextmanager\n+    def _filter_test_common(\n+        self, node: t.Union[nodes.Filter, nodes.Test], frame: Frame, is_filter: bool\n+    ) -&gt; t.Iterator[None]:\n+        if self.environment.is_async:\n+            self.write(\"(await auto_await(\")\n+\n+        if is_filter:\n+            self.write(f\"{self.filters[node.name]}(\")\n+            func = self.environment.filters.get(node.name)\n+        else:\n+            self.write(f\"{self.tests[node.name]}(\")\n+            func = self.environment.tests.get(node.name)\n+\n+        # When inside an If or CondExpr frame, allow the filter to be\n+        # undefined at compile time and only raise an error if it's\n+        # actually called at runtime. See pull_dependencies.\n+        if func is None and not frame.soft_frame:\n+            type_name = \"filter\" if is_filter else \"test\"\n+            self.fail(f\"No {type_name} named {node.name!r}.\", node.lineno)\n+\n+        pass_arg = {\n+            _PassArg.context: \"context\",\n+            _PassArg.eval_context: \"context.eval_ctx\",\n+            _PassArg.environment: \"environment\",\n+        }.get(\n+            _PassArg.from_obj(func)  # type: ignore\n+        )\n+\n+        if pass_arg is not None:\n+            self.write(f\"{pass_arg}, \")\n+\n+        # Back to the visitor function to handle visiting the target of\n+        # the filter or test.\n+        yield\n+\n+        self.signature(node, frame)\n+        self.write(\")\")\n+\n+        if self.environment.is_async:\n+            self.write(\"))\")\n+\n+    @optimizeconst\n+    def visit_Filter(self, node: nodes.Filter, frame: Frame) -&gt; None:\n+        with self._filter_test_common(node, frame, True):\n+            # if the filter node is None we are inside a filter block\n+            # and want to write to the current buffer\n+            if node.node is not None:\n+                self.visit(node.node, frame)\n+            elif frame.eval_ctx.volatile:\n+                self.write(\n+                    f\"(Markup(concat({frame.buffer}))\"\n+                    f\" if context.eval_ctx.autoescape else concat({frame.buffer}))\"\n+                )\n+            elif frame.eval_ctx.autoescape:\n+                self.write(f\"Markup(concat({frame.buffer}))\")\n+            else:\n+                self.write(f\"concat({frame.buffer})\")\n+\n+    @optimizeconst\n+    def visit_Test(self, node: nodes.Test, frame: Frame) -&gt; None:\n+        with self._filter_test_common(node, frame, False):\n+            self.visit(node.node, frame)\n+\n+    @optimizeconst\n+    def visit_CondExpr(self, node: nodes.CondExpr, frame: Frame) -&gt; None:\n+        frame = frame.soft()\n+\n+        def write_expr2() -&gt; None:\n+            if node.expr2 is not None:\n+                self.visit(node.expr2, frame)\n+                return\n+\n+            self.write(\n+                f'cond_expr_undefined(\"the inline if-expression on'\n+                f\" {self.position(node)} evaluated to false and no else\"\n+                f' section was defined.\")'\n+            )\n+\n+        self.write(\"(\")\n+        self.visit(node.expr1, frame)\n+        self.write(\" if \")\n+        self.visit(node.test, frame)\n+        self.write(\" else \")\n+        write_expr2()\n+        self.write(\")\")\n+\n+    @optimizeconst\n+    def visit_Call(\n+        self, node: nodes.Call, frame: Frame, forward_caller: bool = False\n+    ) -&gt; None:\n+        if self.environment.is_async:\n+            self.write(\"(await auto_await(\")\n+        if self.environment.sandboxed:\n+            self.write(\"environment.call(context, \")\n+        else:\n+            self.write(\"context.call(\")\n+        self.visit(node.node, frame)\n+        extra_kwargs = {\"caller\": \"caller\"} if forward_caller else None\n+        loop_kwargs = {\"_loop_vars\": \"_loop_vars\"} if frame.loop_frame else {}\n+        block_kwargs = {\"_block_vars\": \"_block_vars\"} if frame.block_frame else {}\n+        if extra_kwargs:\n+            extra_kwargs.update(loop_kwargs, **block_kwargs)\n+        elif loop_kwargs or block_kwargs:\n+            extra_kwargs = dict(loop_kwargs, **block_kwargs)\n+        self.signature(node, frame, extra_kwargs)\n+        self.write(\")\")\n+        if self.environment.is_async:\n+            self.write(\"))\")\n+\n+    def visit_Keyword(self, node: nodes.Keyword, frame: Frame) -&gt; None:\n+        self.write(node.key + \"=\")\n+        self.visit(node.value, frame)\n+\n+    # -- Unused nodes for extensions\n+\n+    def visit_MarkSafe(self, node: nodes.MarkSafe, frame: Frame) -&gt; None:\n+        self.write(\"Markup(\")\n+        self.visit(node.expr, frame)\n+        self.write(\")\")\n+\n+    def visit_MarkSafeIfAutoescape(\n+        self, node: nodes.MarkSafeIfAutoescape, frame: Frame\n+    ) -&gt; None:\n+        self.write(\"(Markup if context.eval_ctx.autoescape else identity)(\")\n+        self.visit(node.expr, frame)\n+        self.write(\")\")\n+\n+    def visit_EnvironmentAttribute(\n+        self, node: nodes.EnvironmentAttribute, frame: Frame\n+    ) -&gt; None:\n+        self.write(\"environment.\" + node.name)\n+\n+    def visit_ExtensionAttribute(\n+        self, node: nodes.ExtensionAttribute, frame: Frame\n+    ) -&gt; None:\n+        self.write(f\"environment.extensions[{node.identifier!r}].{node.name}\")\n+\n+    def visit_ImportedName(self, node: nodes.ImportedName, frame: Frame) -&gt; None:\n+        self.write(self.import_aliases[node.importname])\n+\n+    def visit_InternalName(self, node: nodes.InternalName, frame: Frame) -&gt; None:\n+        self.write(node.name)\n+\n+    def visit_ContextReference(\n+        self, node: nodes.ContextReference, frame: Frame\n+    ) -&gt; None:\n+        self.write(\"context\")\n+\n+    def visit_DerivedContextReference(\n+        self, node: nodes.DerivedContextReference, frame: Frame\n+    ) -&gt; None:\n+        self.write(self.derive_context(frame))\n+\n+    def visit_Continue(self, node: nodes.Continue, frame: Frame) -&gt; None:\n+        self.writeline(\"continue\", node)\n+\n+    def visit_Break(self, node: nodes.Break, frame: Frame) -&gt; None:\n+        self.writeline(\"break\", node)\n+\n+    def visit_Scope(self, node: nodes.Scope, frame: Frame) -&gt; None:\n+        scope_frame = frame.inner()\n+        scope_frame.symbols.analyze_node(node)\n+        self.enter_frame(scope_frame)\n+        self.blockvisit(node.body, scope_frame)\n+        self.leave_frame(scope_frame)\n+\n+    def visit_OverlayScope(self, node: nodes.OverlayScope, frame: Frame) -&gt; None:\n+        ctx = self.temporary_identifier()\n+        self.writeline(f\"{ctx} = {self.derive_context(frame)}\")\n+        self.writeline(f\"{ctx}.vars = \")\n+        self.visit(node.context, frame)\n+        self.push_context_reference(ctx)\n+\n+        scope_frame = frame.inner(isolated=True)\n+        scope_frame.symbols.analyze_node(node)\n+        self.enter_frame(scope_frame)\n+        self.blockvisit(node.body, scope_frame)\n+        self.leave_frame(scope_frame)\n+        self.pop_context_reference()\n+\n+    def visit_EvalContextModifier(\n+        self, node: nodes.EvalContextModifier, frame: Frame\n+    ) -&gt; None:\n+        for keyword in node.options:\n+            self.writeline(f\"context.eval_ctx.{keyword.key} = \")\n+            self.visit(keyword.value, frame)\n+            try:\n+                val = keyword.value.as_const(frame.eval_ctx)\n+            except nodes.Impossible:\n+                frame.eval_ctx.volatile = True\n+            else:\n+                setattr(frame.eval_ctx, keyword.key, val)\n+\n+    def visit_ScopedEvalContextModifier(\n+        self, node: nodes.ScopedEvalContextModifier, frame: Frame\n+    ) -&gt; None:\n+        old_ctx_name = self.temporary_identifier()\n+        saved_ctx = frame.eval_ctx.save()\n+        self.writeline(f\"{old_ctx_name} = context.eval_ctx.save()\")\n+        self.visit_EvalContextModifier(node, frame)\n+        for child in node.body:\n+            self.visit(child, frame)\n+        frame.eval_ctx.revert(saved_ctx)\n+        self.writeline(f\"context.eval_ctx.revert({old_ctx_name})\")\ndiff --git a/src/jinja2/constants.py b/src/jinja2/constants.py\nindex e3262f1..41a1c23 100644\n--- a/src/jinja2/constants.py\n+++ b/src/jinja2/constants.py\n@@ -1,4 +1,6 @@\n-LOREM_IPSUM_WORDS = \"\"\"a ac accumsan ad adipiscing aenean aliquam aliquet amet ante aptent arcu at\n+#: list of lorem ipsum words used by the lipsum() helper function\n+LOREM_IPSUM_WORDS = \"\"\"\\\n+a ac accumsan ad adipiscing aenean aliquam aliquet amet ante aptent arcu at\n auctor augue bibendum blandit class commodo condimentum congue consectetuer\n consequat conubia convallis cras cubilia cum curabitur curae cursus dapibus\n diam dictum dictumst dignissim dis dolor donec dui duis egestas eget eleifend\ndiff --git a/src/jinja2/debug.py b/src/jinja2/debug.py\nindex 412f2c2..7ed7e92 100644\n--- a/src/jinja2/debug.py\n+++ b/src/jinja2/debug.py\n@@ -2,14 +2,16 @@ import sys\n import typing as t\n from types import CodeType\n from types import TracebackType\n+\n from .exceptions import TemplateSyntaxError\n from .utils import internal_code\n from .utils import missing\n+\n if t.TYPE_CHECKING:\n     from .runtime import Context\n\n\n-def rewrite_traceback_stack(source: t.Optional[str]=None) -&gt;BaseException:\n+def rewrite_traceback_stack(source: t.Optional[str] = None) -&gt; BaseException:\n     \"\"\"Rewrite the current exception to replace any tracebacks from\n     within compiled template code with tracebacks that look like they\n     came from the template source.\n@@ -20,11 +22,60 @@ def rewrite_traceback_stack(source: t.Optional[str]=None) -&gt;BaseException:\n         known.\n     :return: The original exception with the rewritten traceback.\n     \"\"\"\n-    pass\n+    _, exc_value, tb = sys.exc_info()\n+    exc_value = t.cast(BaseException, exc_value)\n+    tb = t.cast(TracebackType, tb)\n+\n+    if isinstance(exc_value, TemplateSyntaxError) and not exc_value.translated:\n+        exc_value.translated = True\n+        exc_value.source = source\n+        # Remove the old traceback, otherwise the frames from the\n+        # compiler still show up.\n+        exc_value.with_traceback(None)\n+        # Outside of runtime, so the frame isn't executing template\n+        # code, but it still needs to point at the template.\n+        tb = fake_traceback(\n+            exc_value, None, exc_value.filename or \"&lt;unknown&gt;\", exc_value.lineno\n+        )\n+    else:\n+        # Skip the frame for the render function.\n+        tb = tb.tb_next\n+\n+    stack = []\n+\n+    # Build the stack of traceback object, replacing any in template\n+    # code with the source file and line information.\n+    while tb is not None:\n+        # Skip frames decorated with @internalcode. These are internal\n+        # calls that aren't useful in template debugging output.\n+        if tb.tb_frame.f_code in internal_code:\n+            tb = tb.tb_next\n+            continue\n+\n+        template = tb.tb_frame.f_globals.get(\"__jinja_template__\")\n+\n+        if template is not None:\n+            lineno = template.get_corresponding_lineno(tb.tb_lineno)\n+            fake_tb = fake_traceback(exc_value, tb, template.filename, lineno)\n+            stack.append(fake_tb)\n+        else:\n+            stack.append(tb)\n\n+        tb = tb.tb_next\n\n-def fake_traceback(exc_value: BaseException, tb: t.Optional[TracebackType],\n-    filename: str, lineno: int) -&gt;TracebackType:\n+    tb_next = None\n+\n+    # Assign tb_next in reverse to avoid circular references.\n+    for tb in reversed(stack):\n+        tb.tb_next = tb_next\n+        tb_next = tb\n+\n+    return exc_value.with_traceback(tb_next)\n+\n+\n+def fake_traceback(  # type: ignore\n+    exc_value: BaseException, tb: t.Optional[TracebackType], filename: str, lineno: int\n+) -&gt; TracebackType:\n     \"\"\"Produce a new traceback object that looks like it came from the\n     template source instead of the compiled code. The filename, line\n     number, and location name will point to the template, and the local\n@@ -37,12 +88,104 @@ def fake_traceback(exc_value: BaseException, tb: t.Optional[TracebackType],\n     :param filename: The template filename.\n     :param lineno: The line number in the template source.\n     \"\"\"\n-    pass\n+    if tb is not None:\n+        # Replace the real locals with the context that would be\n+        # available at that point in the template.\n+        locals = get_template_locals(tb.tb_frame.f_locals)\n+        locals.pop(\"__jinja_exception__\", None)\n+    else:\n+        locals = {}\n+\n+    globals = {\n+        \"__name__\": filename,\n+        \"__file__\": filename,\n+        \"__jinja_exception__\": exc_value,\n+    }\n+    # Raise an exception at the correct line number.\n+    code: CodeType = compile(\n+        \"\\n\" * (lineno - 1) + \"raise __jinja_exception__\", filename, \"exec\"\n+    )\n+\n+    # Build a new code object that points to the template file and\n+    # replaces the location with a block name.\n+    location = \"template\"\n\n+    if tb is not None:\n+        function = tb.tb_frame.f_code.co_name\n\n-def get_template_locals(real_locals: t.Mapping[str, t.Any]) -&gt;t.Dict[str, t.Any\n-    ]:\n+        if function == \"root\":\n+            location = \"top-level template code\"\n+        elif function.startswith(\"block_\"):\n+            location = f\"block {function[6:]!r}\"\n+\n+    if sys.version_info &gt;= (3, 8):\n+        code = code.replace(co_name=location)\n+    else:\n+        code = CodeType(\n+            code.co_argcount,\n+            code.co_kwonlyargcount,\n+            code.co_nlocals,\n+            code.co_stacksize,\n+            code.co_flags,\n+            code.co_code,\n+            code.co_consts,\n+            code.co_names,\n+            code.co_varnames,\n+            code.co_filename,\n+            location,\n+            code.co_firstlineno,\n+            code.co_lnotab,\n+            code.co_freevars,\n+            code.co_cellvars,\n+        )\n+\n+    # Execute the new code, which is guaranteed to raise, and return\n+    # the new traceback without this frame.\n+    try:\n+        exec(code, globals, locals)\n+    except BaseException:\n+        return sys.exc_info()[2].tb_next  # type: ignore\n+\n+\n+def get_template_locals(real_locals: t.Mapping[str, t.Any]) -&gt; t.Dict[str, t.Any]:\n     \"\"\"Based on the runtime locals, get the context that would be\n     available at that point in the template.\n     \"\"\"\n-    pass\n+    # Start with the current template context.\n+    ctx: \"t.Optional[Context]\" = real_locals.get(\"context\")\n+\n+    if ctx is not None:\n+        data: t.Dict[str, t.Any] = ctx.get_all().copy()\n+    else:\n+        data = {}\n+\n+    # Might be in a derived context that only sets local variables\n+    # rather than pushing a context. Local variables follow the scheme\n+    # l_depth_name. Find the highest-depth local that has a value for\n+    # each name.\n+    local_overrides: t.Dict[str, t.Tuple[int, t.Any]] = {}\n+\n+    for name, value in real_locals.items():\n+        if not name.startswith(\"l_\") or value is missing:\n+            # Not a template variable, or no longer relevant.\n+            continue\n+\n+        try:\n+            _, depth_str, name = name.split(\"_\", 2)\n+            depth = int(depth_str)\n+        except ValueError:\n+            continue\n+\n+        cur_depth = local_overrides.get(name, (-1,))[0]\n+\n+        if cur_depth &lt; depth:\n+            local_overrides[name] = (depth, value)\n+\n+    # Modify the context with any derived context.\n+    for name, (_, value) in local_overrides.items():\n+        if value is missing:\n+            data.pop(name, None)\n+        else:\n+            data[name] = value\n+\n+    return data\ndiff --git a/src/jinja2/defaults.py b/src/jinja2/defaults.py\nindex 07ecd67..638cad3 100644\n--- a/src/jinja2/defaults.py\n+++ b/src/jinja2/defaults.py\n@@ -1,28 +1,48 @@\n import typing as t\n-from .filters import FILTERS as DEFAULT_FILTERS\n-from .tests import TESTS as DEFAULT_TESTS\n+\n+from .filters import FILTERS as DEFAULT_FILTERS  # noqa: F401\n+from .tests import TESTS as DEFAULT_TESTS  # noqa: F401\n from .utils import Cycler\n from .utils import generate_lorem_ipsum\n from .utils import Joiner\n from .utils import Namespace\n+\n if t.TYPE_CHECKING:\n     import typing_extensions as te\n-BLOCK_START_STRING = '{%'\n-BLOCK_END_STRING = '%}'\n-VARIABLE_START_STRING = '{{'\n-VARIABLE_END_STRING = '}}'\n-COMMENT_START_STRING = '{#'\n-COMMENT_END_STRING = '#}'\n+\n+# defaults for the parser / lexer\n+BLOCK_START_STRING = \"{%\"\n+BLOCK_END_STRING = \"%}\"\n+VARIABLE_START_STRING = \"{{\"\n+VARIABLE_END_STRING = \"}}\"\n+COMMENT_START_STRING = \"{#\"\n+COMMENT_END_STRING = \"#}\"\n LINE_STATEMENT_PREFIX: t.Optional[str] = None\n LINE_COMMENT_PREFIX: t.Optional[str] = None\n TRIM_BLOCKS = False\n LSTRIP_BLOCKS = False\n-NEWLINE_SEQUENCE: \"te.Literal['\\\\n', '\\\\r\\\\n', '\\\\r']\" = '\\n'\n+NEWLINE_SEQUENCE: \"te.Literal['\\\\n', '\\\\r\\\\n', '\\\\r']\" = \"\\n\"\n KEEP_TRAILING_NEWLINE = False\n-DEFAULT_NAMESPACE = {'range': range, 'dict': dict, 'lipsum':\n-    generate_lorem_ipsum, 'cycler': Cycler, 'joiner': Joiner, 'namespace':\n-    Namespace}\n-DEFAULT_POLICIES: t.Dict[str, t.Any] = {'compiler.ascii_str': True,\n-    'urlize.rel': 'noopener', 'urlize.target': None, 'urlize.extra_schemes':\n-    None, 'truncate.leeway': 5, 'json.dumps_function': None,\n-    'json.dumps_kwargs': {'sort_keys': True}, 'ext.i18n.trimmed': False}\n+\n+# default filters, tests and namespace\n+\n+DEFAULT_NAMESPACE = {\n+    \"range\": range,\n+    \"dict\": dict,\n+    \"lipsum\": generate_lorem_ipsum,\n+    \"cycler\": Cycler,\n+    \"joiner\": Joiner,\n+    \"namespace\": Namespace,\n+}\n+\n+# default policies\n+DEFAULT_POLICIES: t.Dict[str, t.Any] = {\n+    \"compiler.ascii_str\": True,\n+    \"urlize.rel\": \"noopener\",\n+    \"urlize.target\": None,\n+    \"urlize.extra_schemes\": None,\n+    \"truncate.leeway\": 5,\n+    \"json.dumps_function\": None,\n+    \"json.dumps_kwargs\": {\"sort_keys\": True},\n+    \"ext.i18n.trimmed\": False,\n+}\ndiff --git a/src/jinja2/environment.py b/src/jinja2/environment.py\nindex aae9f98..1d3be0b 100644\n--- a/src/jinja2/environment.py\n+++ b/src/jinja2/environment.py\n@@ -1,6 +1,7 @@\n \"\"\"Classes for managing templates and their runtime and compile time\n options.\n \"\"\"\n+\n import os\n import typing\n import typing as t\n@@ -10,7 +11,9 @@ from functools import lru_cache\n from functools import partial\n from functools import reduce\n from types import CodeType\n+\n from markupsafe import Markup\n+\n from . import nodes\n from .compiler import CodeGenerator\n from .compiler import generate\n@@ -18,10 +21,10 @@ from .defaults import BLOCK_END_STRING\n from .defaults import BLOCK_START_STRING\n from .defaults import COMMENT_END_STRING\n from .defaults import COMMENT_START_STRING\n-from .defaults import DEFAULT_FILTERS\n+from .defaults import DEFAULT_FILTERS  # type: ignore[attr-defined]\n from .defaults import DEFAULT_NAMESPACE\n from .defaults import DEFAULT_POLICIES\n-from .defaults import DEFAULT_TESTS\n+from .defaults import DEFAULT_TESTS  # type: ignore[attr-defined]\n from .defaults import KEEP_TRAILING_NEWLINE\n from .defaults import LINE_COMMENT_PREFIX\n from .defaults import LINE_STATEMENT_PREFIX\n@@ -50,17 +53,20 @@ from .utils import import_string\n from .utils import internalcode\n from .utils import LRUCache\n from .utils import missing\n+\n if t.TYPE_CHECKING:\n     import typing_extensions as te\n+\n     from .bccache import BytecodeCache\n     from .ext import Extension\n     from .loaders import BaseLoader\n-_env_bound = t.TypeVar('_env_bound', bound='Environment')\n+\n+_env_bound = t.TypeVar(\"_env_bound\", bound=\"Environment\")\n\n\n+# for direct template usage we have up to ten living environments\n @lru_cache(maxsize=10)\n-def get_spontaneous_environment(cls: t.Type[_env_bound], *args: t.Any\n-    ) -&gt;_env_bound:\n+def get_spontaneous_environment(cls: t.Type[_env_bound], *args: t.Any) -&gt; _env_bound:\n     \"\"\"Return a new spontaneous environment. A spontaneous environment\n     is used for templates created directly rather than through an\n     existing environment.\n@@ -68,36 +74,75 @@ def get_spontaneous_environment(cls: t.Type[_env_bound], *args: t.Any\n     :param cls: Environment class to create.\n     :param args: Positional arguments passed to environment.\n     \"\"\"\n-    pass\n+    env = cls(*args)\n+    env.shared = True\n+    return env\n\n\n-def create_cache(size: int) -&gt;t.Optional[t.MutableMapping[t.Tuple[\n-    'weakref.ref[t.Any]', str], 'Template']]:\n+def create_cache(\n+    size: int,\n+) -&gt; t.Optional[t.MutableMapping[t.Tuple[\"weakref.ref[t.Any]\", str], \"Template\"]]:\n     \"\"\"Return the cache class for the given size.\"\"\"\n-    pass\n+    if size == 0:\n+        return None\n\n+    if size &lt; 0:\n+        return {}\n\n-def copy_cache(cache: t.Optional[t.MutableMapping[t.Any, t.Any]]) -&gt;t.Optional[\n-    t.MutableMapping[t.Tuple['weakref.ref[t.Any]', str], 'Template']]:\n+    return LRUCache(size)  # type: ignore\n+\n+\n+def copy_cache(\n+    cache: t.Optional[t.MutableMapping[t.Any, t.Any]],\n+) -&gt; t.Optional[t.MutableMapping[t.Tuple[\"weakref.ref[t.Any]\", str], \"Template\"]]:\n     \"\"\"Create an empty copy of the given cache.\"\"\"\n-    pass\n+    if cache is None:\n+        return None\n+\n+    if type(cache) is dict:  # noqa E721\n+        return {}\n\n+    return LRUCache(cache.capacity)  # type: ignore\n\n-def load_extensions(environment: 'Environment', extensions: t.Sequence[t.\n-    Union[str, t.Type['Extension']]]) -&gt;t.Dict[str, 'Extension']:\n+\n+def load_extensions(\n+    environment: \"Environment\",\n+    extensions: t.Sequence[t.Union[str, t.Type[\"Extension\"]]],\n+) -&gt; t.Dict[str, \"Extension\"]:\n     \"\"\"Load the extensions from the list and bind it to the environment.\n     Returns a dict of instantiated extensions.\n     \"\"\"\n-    pass\n+    result = {}\n+\n+    for extension in extensions:\n+        if isinstance(extension, str):\n+            extension = t.cast(t.Type[\"Extension\"], import_string(extension))\n+\n+        result[extension.identifier] = extension(environment)\n\n+    return result\n\n-def _environment_config_check(environment: 'Environment') -&gt;'Environment':\n+\n+def _environment_config_check(environment: \"Environment\") -&gt; \"Environment\":\n     \"\"\"Perform a sanity check on the environment.\"\"\"\n-    pass\n+    assert issubclass(\n+        environment.undefined, Undefined\n+    ), \"'undefined' must be a subclass of 'jinja2.Undefined'.\"\n+    assert (\n+        environment.block_start_string\n+        != environment.variable_start_string\n+        != environment.comment_start_string\n+    ), \"block, variable and comment start strings must be different.\"\n+    assert environment.newline_sequence in {\n+        \"\\r\",\n+        \"\\r\\n\",\n+        \"\\n\",\n+    }, \"'newline_sequence' must be one of '\\\\n', '\\\\r\\\\n', or '\\\\r'.\"\n+    return environment\n\n\n class Environment:\n-    \"\"\"The core component of Jinja is the `Environment`.  It contains\n+    r\"\"\"The core component of Jinja is the `Environment`.  It contains\n     important shared variables like configuration, filters, tests,\n     globals and others.  Instances of this class may be modified if\n     they are not shared and if no template was loaded so far.\n@@ -145,8 +190,8 @@ class Environment:\n             from the start of a line to a block.  Defaults to `False`.\n\n         `newline_sequence`\n-            The sequence that starts a newline.  Must be one of ``'\\\\r'``,\n-            ``'\\\\n'`` or ``'\\\\r\\\\n'``.  The default is ``'\\\\n'`` which is a\n+            The sequence that starts a newline.  Must be one of ``'\\r'``,\n+            ``'\\n'`` or ``'\\r\\n'``.  The default is ``'\\n'`` which is a\n             useful default for Linux and OS X systems as well as web\n             applications.\n\n@@ -217,31 +262,72 @@ class Environment:\n             If set to true this enables async template execution which\n             allows using async functions and generators.\n     \"\"\"\n+\n+    #: if this environment is sandboxed.  Modifying this variable won't make\n+    #: the environment sandboxed though.  For a real sandboxed environment\n+    #: have a look at jinja2.sandbox.  This flag alone controls the code\n+    #: generation by the compiler.\n     sandboxed = False\n+\n+    #: True if the environment is just an overlay\n     overlayed = False\n-    linked_to: t.Optional['Environment'] = None\n+\n+    #: the environment this environment is linked to if it is an overlay\n+    linked_to: t.Optional[\"Environment\"] = None\n+\n+    #: shared environments have this set to `True`.  A shared environment\n+    #: must not be modified\n     shared = False\n-    code_generator_class: t.Type['CodeGenerator'] = CodeGenerator\n-    concat = ''.join\n+\n+    #: the class that is used for code generation.  See\n+    #: :class:`~jinja2.compiler.CodeGenerator` for more information.\n+    code_generator_class: t.Type[\"CodeGenerator\"] = CodeGenerator\n+\n+    concat = \"\".join\n+\n+    #: the context class that is used for templates.  See\n+    #: :class:`~jinja2.runtime.Context` for more information.\n     context_class: t.Type[Context] = Context\n-    template_class: t.Type['Template']\n-\n-    def __init__(self, block_start_string: str=BLOCK_START_STRING,\n-        block_end_string: str=BLOCK_END_STRING, variable_start_string: str=\n-        VARIABLE_START_STRING, variable_end_string: str=VARIABLE_END_STRING,\n-        comment_start_string: str=COMMENT_START_STRING, comment_end_string:\n-        str=COMMENT_END_STRING, line_statement_prefix: t.Optional[str]=\n-        LINE_STATEMENT_PREFIX, line_comment_prefix: t.Optional[str]=\n-        LINE_COMMENT_PREFIX, trim_blocks: bool=TRIM_BLOCKS, lstrip_blocks:\n-        bool=LSTRIP_BLOCKS, newline_sequence:\n-        \"te.Literal['\\\\n', '\\\\r\\\\n', '\\\\r']\"=NEWLINE_SEQUENCE,\n-        keep_trailing_newline: bool=KEEP_TRAILING_NEWLINE, extensions: t.\n-        Sequence[t.Union[str, t.Type['Extension']]]=(), optimized: bool=\n-        True, undefined: t.Type[Undefined]=Undefined, finalize: t.Optional[\n-        t.Callable[..., t.Any]]=None, autoescape: t.Union[bool, t.Callable[\n-        [t.Optional[str]], bool]]=False, loader: t.Optional['BaseLoader']=\n-        None, cache_size: int=400, auto_reload: bool=True, bytecode_cache:\n-        t.Optional['BytecodeCache']=None, enable_async: bool=False):\n+\n+    template_class: t.Type[\"Template\"]\n+\n+    def __init__(\n+        self,\n+        block_start_string: str = BLOCK_START_STRING,\n+        block_end_string: str = BLOCK_END_STRING,\n+        variable_start_string: str = VARIABLE_START_STRING,\n+        variable_end_string: str = VARIABLE_END_STRING,\n+        comment_start_string: str = COMMENT_START_STRING,\n+        comment_end_string: str = COMMENT_END_STRING,\n+        line_statement_prefix: t.Optional[str] = LINE_STATEMENT_PREFIX,\n+        line_comment_prefix: t.Optional[str] = LINE_COMMENT_PREFIX,\n+        trim_blocks: bool = TRIM_BLOCKS,\n+        lstrip_blocks: bool = LSTRIP_BLOCKS,\n+        newline_sequence: \"te.Literal['\\\\n', '\\\\r\\\\n', '\\\\r']\" = NEWLINE_SEQUENCE,\n+        keep_trailing_newline: bool = KEEP_TRAILING_NEWLINE,\n+        extensions: t.Sequence[t.Union[str, t.Type[\"Extension\"]]] = (),\n+        optimized: bool = True,\n+        undefined: t.Type[Undefined] = Undefined,\n+        finalize: t.Optional[t.Callable[..., t.Any]] = None,\n+        autoescape: t.Union[bool, t.Callable[[t.Optional[str]], bool]] = False,\n+        loader: t.Optional[\"BaseLoader\"] = None,\n+        cache_size: int = 400,\n+        auto_reload: bool = True,\n+        bytecode_cache: t.Optional[\"BytecodeCache\"] = None,\n+        enable_async: bool = False,\n+    ):\n+        # !!Important notice!!\n+        #   The constructor accepts quite a few arguments that should be\n+        #   passed by keyword rather than position.  However it's important to\n+        #   not change the order of arguments because it's used at least\n+        #   internally in those cases:\n+        #       -   spontaneous environments (i18n extension and Template)\n+        #       -   unittests\n+        #   If parameter changes are required only add parameters at the end\n+        #   and don't change the arguments (or the defaults!) of the arguments\n+        #   existing already.\n+\n+        # lexer / parser information\n         self.block_start_string = block_start_string\n         self.block_end_string = block_end_string\n         self.variable_start_string = variable_start_string\n@@ -254,52 +340,74 @@ class Environment:\n         self.lstrip_blocks = lstrip_blocks\n         self.newline_sequence = newline_sequence\n         self.keep_trailing_newline = keep_trailing_newline\n+\n+        # runtime information\n         self.undefined: t.Type[Undefined] = undefined\n         self.optimized = optimized\n         self.finalize = finalize\n         self.autoescape = autoescape\n+\n+        # defaults\n         self.filters = DEFAULT_FILTERS.copy()\n         self.tests = DEFAULT_TESTS.copy()\n         self.globals = DEFAULT_NAMESPACE.copy()\n+\n+        # set the loader provided\n         self.loader = loader\n         self.cache = create_cache(cache_size)\n         self.bytecode_cache = bytecode_cache\n         self.auto_reload = auto_reload\n+\n+        # configurable policies\n         self.policies = DEFAULT_POLICIES.copy()\n+\n+        # load extensions\n         self.extensions = load_extensions(self, extensions)\n+\n         self.is_async = enable_async\n         _environment_config_check(self)\n\n-    def add_extension(self, extension: t.Union[str, t.Type['Extension']]\n-        ) -&gt;None:\n+    def add_extension(self, extension: t.Union[str, t.Type[\"Extension\"]]) -&gt; None:\n         \"\"\"Adds an extension after the environment was created.\n\n         .. versionadded:: 2.5\n         \"\"\"\n-        pass\n+        self.extensions.update(load_extensions(self, [extension]))\n\n-    def extend(self, **attributes: t.Any) -&gt;None:\n+    def extend(self, **attributes: t.Any) -&gt; None:\n         \"\"\"Add the items to the instance of the environment if they do not exist\n         yet.  This is used by :ref:`extensions &lt;writing-extensions&gt;` to register\n         callbacks and configuration values without breaking inheritance.\n         \"\"\"\n-        pass\n-\n-    def overlay(self, block_start_string: str=missing, block_end_string:\n-        str=missing, variable_start_string: str=missing,\n-        variable_end_string: str=missing, comment_start_string: str=missing,\n-        comment_end_string: str=missing, line_statement_prefix: t.Optional[\n-        str]=missing, line_comment_prefix: t.Optional[str]=missing,\n-        trim_blocks: bool=missing, lstrip_blocks: bool=missing,\n-        newline_sequence: \"te.Literal['\\\\n', '\\\\r\\\\n', '\\\\r']\"=missing,\n-        keep_trailing_newline: bool=missing, extensions: t.Sequence[t.Union\n-        [str, t.Type['Extension']]]=missing, optimized: bool=missing,\n-        undefined: t.Type[Undefined]=missing, finalize: t.Optional[t.\n-        Callable[..., t.Any]]=missing, autoescape: t.Union[bool, t.Callable\n-        [[t.Optional[str]], bool]]=missing, loader: t.Optional['BaseLoader'\n-        ]=missing, cache_size: int=missing, auto_reload: bool=missing,\n-        bytecode_cache: t.Optional['BytecodeCache']=missing, enable_async:\n-        bool=False) -&gt;'Environment':\n+        for key, value in attributes.items():\n+            if not hasattr(self, key):\n+                setattr(self, key, value)\n+\n+    def overlay(\n+        self,\n+        block_start_string: str = missing,\n+        block_end_string: str = missing,\n+        variable_start_string: str = missing,\n+        variable_end_string: str = missing,\n+        comment_start_string: str = missing,\n+        comment_end_string: str = missing,\n+        line_statement_prefix: t.Optional[str] = missing,\n+        line_comment_prefix: t.Optional[str] = missing,\n+        trim_blocks: bool = missing,\n+        lstrip_blocks: bool = missing,\n+        newline_sequence: \"te.Literal['\\\\n', '\\\\r\\\\n', '\\\\r']\" = missing,\n+        keep_trailing_newline: bool = missing,\n+        extensions: t.Sequence[t.Union[str, t.Type[\"Extension\"]]] = missing,\n+        optimized: bool = missing,\n+        undefined: t.Type[Undefined] = missing,\n+        finalize: t.Optional[t.Callable[..., t.Any]] = missing,\n+        autoescape: t.Union[bool, t.Callable[[t.Optional[str]], bool]] = missing,\n+        loader: t.Optional[\"BaseLoader\"] = missing,\n+        cache_size: int = missing,\n+        auto_reload: bool = missing,\n+        bytecode_cache: t.Optional[\"BytecodeCache\"] = missing,\n+        enable_async: bool = False,\n+    ) -&gt; \"Environment\":\n         \"\"\"Create a new overlay environment that shares all the data with the\n         current environment except for cache and the overridden attributes.\n         Extensions cannot be removed for an overlayed environment.  An overlayed\n@@ -315,32 +423,138 @@ class Environment:\n             Added the ``newline_sequence``,, ``keep_trailing_newline``,\n             and ``enable_async`` parameters to match ``__init__``.\n         \"\"\"\n-        pass\n+        args = dict(locals())\n+        del args[\"self\"], args[\"cache_size\"], args[\"extensions\"], args[\"enable_async\"]\n+\n+        rv = object.__new__(self.__class__)\n+        rv.__dict__.update(self.__dict__)\n+        rv.overlayed = True\n+        rv.linked_to = self\n+\n+        for key, value in args.items():\n+            if value is not missing:\n+                setattr(rv, key, value)\n+\n+        if cache_size is not missing:\n+            rv.cache = create_cache(cache_size)\n+        else:\n+            rv.cache = copy_cache(self.cache)\n+\n+        rv.extensions = {}\n+        for key, value in self.extensions.items():\n+            rv.extensions[key] = value.bind(rv)\n+        if extensions is not missing:\n+            rv.extensions.update(load_extensions(rv, extensions))\n+\n+        if enable_async is not missing:\n+            rv.is_async = enable_async\n+\n+        return _environment_config_check(rv)\n\n     @property\n-    def lexer(self) -&gt;Lexer:\n+    def lexer(self) -&gt; Lexer:\n         \"\"\"The lexer for this environment.\"\"\"\n-        pass\n+        return get_lexer(self)\n\n-    def iter_extensions(self) -&gt;t.Iterator['Extension']:\n+    def iter_extensions(self) -&gt; t.Iterator[\"Extension\"]:\n         \"\"\"Iterates over the extensions by priority.\"\"\"\n-        pass\n+        return iter(sorted(self.extensions.values(), key=lambda x: x.priority))\n\n-    def getitem(self, obj: t.Any, argument: t.Union[str, t.Any]) -&gt;t.Union[\n-        t.Any, Undefined]:\n+    def getitem(\n+        self, obj: t.Any, argument: t.Union[str, t.Any]\n+    ) -&gt; t.Union[t.Any, Undefined]:\n         \"\"\"Get an item or attribute of an object but prefer the item.\"\"\"\n-        pass\n-\n-    def getattr(self, obj: t.Any, attribute: str) -&gt;t.Any:\n+        try:\n+            return obj[argument]\n+        except (AttributeError, TypeError, LookupError):\n+            if isinstance(argument, str):\n+                try:\n+                    attr = str(argument)\n+                except Exception:\n+                    pass\n+                else:\n+                    try:\n+                        return getattr(obj, attr)\n+                    except AttributeError:\n+                        pass\n+            return self.undefined(obj=obj, name=argument)\n+\n+    def getattr(self, obj: t.Any, attribute: str) -&gt; t.Any:\n         \"\"\"Get an item or attribute of an object but prefer the attribute.\n         Unlike :meth:`getitem` the attribute *must* be a string.\n         \"\"\"\n-        pass\n-\n-    def call_filter(self, name: str, value: t.Any, args: t.Optional[t.\n-        Sequence[t.Any]]=None, kwargs: t.Optional[t.Mapping[str, t.Any]]=\n-        None, context: t.Optional[Context]=None, eval_ctx: t.Optional[\n-        EvalContext]=None) -&gt;t.Any:\n+        try:\n+            return getattr(obj, attribute)\n+        except AttributeError:\n+            pass\n+        try:\n+            return obj[attribute]\n+        except (TypeError, LookupError, AttributeError):\n+            return self.undefined(obj=obj, name=attribute)\n+\n+    def _filter_test_common(\n+        self,\n+        name: t.Union[str, Undefined],\n+        value: t.Any,\n+        args: t.Optional[t.Sequence[t.Any]],\n+        kwargs: t.Optional[t.Mapping[str, t.Any]],\n+        context: t.Optional[Context],\n+        eval_ctx: t.Optional[EvalContext],\n+        is_filter: bool,\n+    ) -&gt; t.Any:\n+        if is_filter:\n+            env_map = self.filters\n+            type_name = \"filter\"\n+        else:\n+            env_map = self.tests\n+            type_name = \"test\"\n+\n+        func = env_map.get(name)  # type: ignore\n+\n+        if func is None:\n+            msg = f\"No {type_name} named {name!r}.\"\n+\n+            if isinstance(name, Undefined):\n+                try:\n+                    name._fail_with_undefined_error()\n+                except Exception as e:\n+                    msg = f\"{msg} ({e}; did you forget to quote the callable name?)\"\n+\n+            raise TemplateRuntimeError(msg)\n+\n+        args = [value, *(args if args is not None else ())]\n+        kwargs = kwargs if kwargs is not None else {}\n+        pass_arg = _PassArg.from_obj(func)\n+\n+        if pass_arg is _PassArg.context:\n+            if context is None:\n+                raise TemplateRuntimeError(\n+                    f\"Attempted to invoke a context {type_name} without context.\"\n+                )\n+\n+            args.insert(0, context)\n+        elif pass_arg is _PassArg.eval_context:\n+            if eval_ctx is None:\n+                if context is not None:\n+                    eval_ctx = context.eval_ctx\n+                else:\n+                    eval_ctx = EvalContext(self)\n+\n+            args.insert(0, eval_ctx)\n+        elif pass_arg is _PassArg.environment:\n+            args.insert(0, self)\n+\n+        return func(*args, **kwargs)\n+\n+    def call_filter(\n+        self,\n+        name: str,\n+        value: t.Any,\n+        args: t.Optional[t.Sequence[t.Any]] = None,\n+        kwargs: t.Optional[t.Mapping[str, t.Any]] = None,\n+        context: t.Optional[Context] = None,\n+        eval_ctx: t.Optional[EvalContext] = None,\n+    ) -&gt; t.Any:\n         \"\"\"Invoke a filter on a value the same way the compiler does.\n\n         This might return a coroutine if the filter is running from an\n@@ -349,12 +563,19 @@ class Environment:\n\n         .. versionadded:: 2.7\n         \"\"\"\n-        pass\n-\n-    def call_test(self, name: str, value: t.Any, args: t.Optional[t.\n-        Sequence[t.Any]]=None, kwargs: t.Optional[t.Mapping[str, t.Any]]=\n-        None, context: t.Optional[Context]=None, eval_ctx: t.Optional[\n-        EvalContext]=None) -&gt;t.Any:\n+        return self._filter_test_common(\n+            name, value, args, kwargs, context, eval_ctx, True\n+        )\n+\n+    def call_test(\n+        self,\n+        name: str,\n+        value: t.Any,\n+        args: t.Optional[t.Sequence[t.Any]] = None,\n+        kwargs: t.Optional[t.Mapping[str, t.Any]] = None,\n+        context: t.Optional[Context] = None,\n+        eval_ctx: t.Optional[EvalContext] = None,\n+    ) -&gt; t.Any:\n         \"\"\"Invoke a test on a value the same way the compiler does.\n\n         This might return a coroutine if the test is running from an\n@@ -367,11 +588,17 @@ class Environment:\n\n         .. versionadded:: 2.7\n         \"\"\"\n-        pass\n+        return self._filter_test_common(\n+            name, value, args, kwargs, context, eval_ctx, False\n+        )\n\n     @internalcode\n-    def parse(self, source: str, name: t.Optional[str]=None, filename: t.\n-        Optional[str]=None) -&gt;nodes.Template:\n+    def parse(\n+        self,\n+        source: str,\n+        name: t.Optional[str] = None,\n+        filename: t.Optional[str] = None,\n+    ) -&gt; nodes.Template:\n         \"\"\"Parse the sourcecode and return the abstract syntax tree.  This\n         tree of nodes is used by the compiler to convert the template into\n         executable source- or bytecode.  This is useful for debugging or to\n@@ -380,15 +607,23 @@ class Environment:\n         If you are :ref:`developing Jinja extensions &lt;writing-extensions&gt;`\n         this gives you a good overview of the node tree generated.\n         \"\"\"\n-        pass\n-\n-    def _parse(self, source: str, name: t.Optional[str], filename: t.\n-        Optional[str]) -&gt;nodes.Template:\n+        try:\n+            return self._parse(source, name, filename)\n+        except TemplateSyntaxError:\n+            self.handle_exception(source=source)\n+\n+    def _parse(\n+        self, source: str, name: t.Optional[str], filename: t.Optional[str]\n+    ) -&gt; nodes.Template:\n         \"\"\"Internal parsing function used by `parse` and `compile`.\"\"\"\n-        pass\n-\n-    def lex(self, source: str, name: t.Optional[str]=None, filename: t.\n-        Optional[str]=None) -&gt;t.Iterator[t.Tuple[int, str, str]]:\n+        return Parser(self, source, name, filename).parse()\n+\n+    def lex(\n+        self,\n+        source: str,\n+        name: t.Optional[str] = None,\n+        filename: t.Optional[str] = None,\n+    ) -&gt; t.Iterator[t.Tuple[int, str, str]]:\n         \"\"\"Lex the given sourcecode and return a generator that yields\n         tokens as tuples in the form ``(lineno, token_type, value)``.\n         This can be useful for :ref:`extension development &lt;writing-extensions&gt;`\n@@ -398,44 +633,107 @@ class Environment:\n         of the extensions to be applied you have to filter source through\n         the :meth:`preprocess` method.\n         \"\"\"\n-        pass\n-\n-    def preprocess(self, source: str, name: t.Optional[str]=None, filename:\n-        t.Optional[str]=None) -&gt;str:\n+        source = str(source)\n+        try:\n+            return self.lexer.tokeniter(source, name, filename)\n+        except TemplateSyntaxError:\n+            self.handle_exception(source=source)\n+\n+    def preprocess(\n+        self,\n+        source: str,\n+        name: t.Optional[str] = None,\n+        filename: t.Optional[str] = None,\n+    ) -&gt; str:\n         \"\"\"Preprocesses the source with all extensions.  This is automatically\n         called for all parsing and compiling methods but *not* for :meth:`lex`\n         because there you usually only want the actual source tokenized.\n         \"\"\"\n-        pass\n-\n-    def _tokenize(self, source: str, name: t.Optional[str], filename: t.\n-        Optional[str]=None, state: t.Optional[str]=None) -&gt;TokenStream:\n+        return reduce(\n+            lambda s, e: e.preprocess(s, name, filename),\n+            self.iter_extensions(),\n+            str(source),\n+        )\n+\n+    def _tokenize(\n+        self,\n+        source: str,\n+        name: t.Optional[str],\n+        filename: t.Optional[str] = None,\n+        state: t.Optional[str] = None,\n+    ) -&gt; TokenStream:\n         \"\"\"Called by the parser to do the preprocessing and filtering\n         for all the extensions.  Returns a :class:`~jinja2.lexer.TokenStream`.\n         \"\"\"\n-        pass\n+        source = self.preprocess(source, name, filename)\n+        stream = self.lexer.tokenize(source, name, filename, state)\n\n-    def _generate(self, source: nodes.Template, name: t.Optional[str],\n-        filename: t.Optional[str], defer_init: bool=False) -&gt;str:\n+        for ext in self.iter_extensions():\n+            stream = ext.filter_stream(stream)  # type: ignore\n+\n+            if not isinstance(stream, TokenStream):\n+                stream = TokenStream(stream, name, filename)\n+\n+        return stream\n+\n+    def _generate(\n+        self,\n+        source: nodes.Template,\n+        name: t.Optional[str],\n+        filename: t.Optional[str],\n+        defer_init: bool = False,\n+    ) -&gt; str:\n         \"\"\"Internal hook that can be overridden to hook a different generate\n         method in.\n\n         .. versionadded:: 2.5\n         \"\"\"\n-        pass\n-\n-    def _compile(self, source: str, filename: str) -&gt;CodeType:\n+        return generate(  # type: ignore\n+            source,\n+            self,\n+            name,\n+            filename,\n+            defer_init=defer_init,\n+            optimized=self.optimized,\n+        )\n+\n+    def _compile(self, source: str, filename: str) -&gt; CodeType:\n         \"\"\"Internal hook that can be overridden to hook a different compile\n         method in.\n\n         .. versionadded:: 2.5\n         \"\"\"\n-        pass\n+        return compile(source, filename, \"exec\")\n+\n+    @typing.overload\n+    def compile(  # type: ignore\n+        self,\n+        source: t.Union[str, nodes.Template],\n+        name: t.Optional[str] = None,\n+        filename: t.Optional[str] = None,\n+        raw: \"te.Literal[False]\" = False,\n+        defer_init: bool = False,\n+    ) -&gt; CodeType: ...\n+\n+    @typing.overload\n+    def compile(\n+        self,\n+        source: t.Union[str, nodes.Template],\n+        name: t.Optional[str] = None,\n+        filename: t.Optional[str] = None,\n+        raw: \"te.Literal[True]\" = ...,\n+        defer_init: bool = False,\n+    ) -&gt; str: ...\n\n     @internalcode\n-    def compile(self, source: t.Union[str, nodes.Template], name: t.\n-        Optional[str]=None, filename: t.Optional[str]=None, raw: bool=False,\n-        defer_init: bool=False) -&gt;t.Union[str, CodeType]:\n+    def compile(\n+        self,\n+        source: t.Union[str, nodes.Template],\n+        name: t.Optional[str] = None,\n+        filename: t.Optional[str] = None,\n+        raw: bool = False,\n+        defer_init: bool = False,\n+    ) -&gt; t.Union[str, CodeType]:\n         \"\"\"Compile a node or template source code.  The `name` parameter is\n         the load name of the template after it was joined using\n         :meth:`join_path` if necessary, not the filename on the file system.\n@@ -455,10 +753,23 @@ class Environment:\n         .. versionadded:: 2.4\n            `defer_init` parameter added.\n         \"\"\"\n-        pass\n-\n-    def compile_expression(self, source: str, undefined_to_none: bool=True\n-        ) -&gt;'TemplateExpression':\n+        source_hint = None\n+        try:\n+            if isinstance(source, str):\n+                source_hint = source\n+                source = self._parse(source, name, filename)\n+            source = self._generate(source, name, filename, defer_init=defer_init)\n+            if raw:\n+                return source\n+            if filename is None:\n+                filename = \"&lt;template&gt;\"\n+            return self._compile(source, filename)\n+        except TemplateSyntaxError:\n+            self.handle_exception(source=source_hint)\n+\n+    def compile_expression(\n+        self, source: str, undefined_to_none: bool = True\n+    ) -&gt; \"TemplateExpression\":\n         \"\"\"A handy helper method that returns a callable that accepts keyword\n         arguments that appear as variables in the expression.  If called it\n         returns the result of the expression.\n@@ -486,13 +797,30 @@ class Environment:\n\n         .. versionadded:: 2.1\n         \"\"\"\n-        pass\n-\n-    def compile_templates(self, target: t.Union[str, 'os.PathLike[str]'],\n-        extensions: t.Optional[t.Collection[str]]=None, filter_func: t.\n-        Optional[t.Callable[[str], bool]]=None, zip: t.Optional[str]=\n-        'deflated', log_function: t.Optional[t.Callable[[str], None]]=None,\n-        ignore_errors: bool=True) -&gt;None:\n+        parser = Parser(self, source, state=\"variable\")\n+        try:\n+            expr = parser.parse_expression()\n+            if not parser.stream.eos:\n+                raise TemplateSyntaxError(\n+                    \"chunk after expression\", parser.stream.current.lineno, None, None\n+                )\n+            expr.set_environment(self)\n+        except TemplateSyntaxError:\n+            self.handle_exception(source=source)\n+\n+        body = [nodes.Assign(nodes.Name(\"result\", \"store\"), expr, lineno=1)]\n+        template = self.from_string(nodes.Template(body, lineno=1))\n+        return TemplateExpression(template, undefined_to_none)\n+\n+    def compile_templates(\n+        self,\n+        target: t.Union[str, \"os.PathLike[str]\"],\n+        extensions: t.Optional[t.Collection[str]] = None,\n+        filter_func: t.Optional[t.Callable[[str], bool]] = None,\n+        zip: t.Optional[str] = \"deflated\",\n+        log_function: t.Optional[t.Callable[[str], None]] = None,\n+        ignore_errors: bool = True,\n+    ) -&gt; None:\n         \"\"\"Finds all the templates the loader can find, compiles them\n         and stores them in `target`.  If `zip` is `None`, instead of in a\n         zipfile, the templates will be stored in a directory.\n@@ -510,10 +838,66 @@ class Environment:\n\n         .. versionadded:: 2.4\n         \"\"\"\n-        pass\n-\n-    def list_templates(self, extensions: t.Optional[t.Collection[str]]=None,\n-        filter_func: t.Optional[t.Callable[[str], bool]]=None) -&gt;t.List[str]:\n+        from .loaders import ModuleLoader\n+\n+        if log_function is None:\n+\n+            def log_function(x: str) -&gt; None:\n+                pass\n+\n+        assert log_function is not None\n+        assert self.loader is not None, \"No loader configured.\"\n+\n+        def write_file(filename: str, data: str) -&gt; None:\n+            if zip:\n+                info = ZipInfo(filename)\n+                info.external_attr = 0o755 &lt;&lt; 16\n+                zip_file.writestr(info, data)\n+            else:\n+                with open(os.path.join(target, filename), \"wb\") as f:\n+                    f.write(data.encode(\"utf8\"))\n+\n+        if zip is not None:\n+            from zipfile import ZIP_DEFLATED\n+            from zipfile import ZIP_STORED\n+            from zipfile import ZipFile\n+            from zipfile import ZipInfo\n+\n+            zip_file = ZipFile(\n+                target, \"w\", dict(deflated=ZIP_DEFLATED, stored=ZIP_STORED)[zip]\n+            )\n+            log_function(f\"Compiling into Zip archive {target!r}\")\n+        else:\n+            if not os.path.isdir(target):\n+                os.makedirs(target)\n+            log_function(f\"Compiling into folder {target!r}\")\n+\n+        try:\n+            for name in self.list_templates(extensions, filter_func):\n+                source, filename, _ = self.loader.get_source(self, name)\n+                try:\n+                    code = self.compile(source, name, filename, True, True)\n+                except TemplateSyntaxError as e:\n+                    if not ignore_errors:\n+                        raise\n+                    log_function(f'Could not compile \"{name}\": {e}')\n+                    continue\n+\n+                filename = ModuleLoader.get_module_filename(name)\n+\n+                write_file(filename, code)\n+                log_function(f'Compiled \"{name}\" as {filename}')\n+        finally:\n+            if zip:\n+                zip_file.close()\n+\n+        log_function(\"Finished compiling templates\")\n+\n+    def list_templates(\n+        self,\n+        extensions: t.Optional[t.Collection[str]] = None,\n+        filter_func: t.Optional[t.Callable[[str], bool]] = None,\n+    ) -&gt; t.List[str]:\n         \"\"\"Returns a list of templates for this environment.  This requires\n         that the loader supports the loader's\n         :meth:`~BaseLoader.list_templates` method.\n@@ -529,15 +913,32 @@ class Environment:\n\n         .. versionadded:: 2.4\n         \"\"\"\n-        pass\n+        assert self.loader is not None, \"No loader configured.\"\n+        names = self.loader.list_templates()\n+\n+        if extensions is not None:\n+            if filter_func is not None:\n+                raise TypeError(\n+                    \"either extensions or filter_func can be passed, but not both\"\n+                )\n+\n+            def filter_func(x: str) -&gt; bool:\n+                return \".\" in x and x.rsplit(\".\", 1)[1] in extensions\n+\n+        if filter_func is not None:\n+            names = [name for name in names if filter_func(name)]\n\n-    def handle_exception(self, source: t.Optional[str]=None) -&gt;'te.NoReturn':\n+        return names\n+\n+    def handle_exception(self, source: t.Optional[str] = None) -&gt; \"te.NoReturn\":\n         \"\"\"Exception handling helper.  This is used internally to either raise\n         rewritten exceptions or return a rendered traceback for the template.\n         \"\"\"\n-        pass\n+        from .debug import rewrite_traceback_stack\n+\n+        raise rewrite_traceback_stack(source=source)\n\n-    def join_path(self, template: str, parent: str) -&gt;str:\n+    def join_path(self, template: str, parent: str) -&gt; str:\n         \"\"\"Join a template with the parent.  By default all the lookups are\n         relative to the loader root so this method returns the `template`\n         parameter unchanged, but if the paths should be relative to the\n@@ -547,12 +948,40 @@ class Environment:\n         Subclasses may override this method and implement template path\n         joining here.\n         \"\"\"\n-        pass\n+        return template\n+\n+    @internalcode\n+    def _load_template(\n+        self, name: str, globals: t.Optional[t.MutableMapping[str, t.Any]]\n+    ) -&gt; \"Template\":\n+        if self.loader is None:\n+            raise TypeError(\"no loader for this environment specified\")\n+        cache_key = (weakref.ref(self.loader), name)\n+        if self.cache is not None:\n+            template = self.cache.get(cache_key)\n+            if template is not None and (\n+                not self.auto_reload or template.is_up_to_date\n+            ):\n+                # template.globals is a ChainMap, modifying it will only\n+                # affect the template, not the environment globals.\n+                if globals:\n+                    template.globals.update(globals)\n+\n+                return template\n+\n+        template = self.loader.load(self, name, self.make_globals(globals))\n+\n+        if self.cache is not None:\n+            self.cache[cache_key] = template\n+        return template\n\n     @internalcode\n-    def get_template(self, name: t.Union[str, 'Template'], parent: t.\n-        Optional[str]=None, globals: t.Optional[t.MutableMapping[str, t.Any\n-        ]]=None) -&gt;'Template':\n+    def get_template(\n+        self,\n+        name: t.Union[str, \"Template\"],\n+        parent: t.Optional[str] = None,\n+        globals: t.Optional[t.MutableMapping[str, t.Any]] = None,\n+    ) -&gt; \"Template\":\n         \"\"\"Load a template by name with :attr:`loader` and return a\n         :class:`Template`. If the template does not exist a\n         :exc:`TemplateNotFound` exception is raised.\n@@ -576,12 +1005,20 @@ class Environment:\n             If ``name`` is a :class:`Template` object it is returned\n             unchanged.\n         \"\"\"\n-        pass\n+        if isinstance(name, Template):\n+            return name\n+        if parent is not None:\n+            name = self.join_path(name, parent)\n+\n+        return self._load_template(name, globals)\n\n     @internalcode\n-    def select_template(self, names: t.Iterable[t.Union[str, 'Template']],\n-        parent: t.Optional[str]=None, globals: t.Optional[t.MutableMapping[\n-        str, t.Any]]=None) -&gt;'Template':\n+    def select_template(\n+        self,\n+        names: t.Iterable[t.Union[str, \"Template\"]],\n+        parent: t.Optional[str] = None,\n+        globals: t.Optional[t.MutableMapping[str, t.Any]] = None,\n+    ) -&gt; \"Template\":\n         \"\"\"Like :meth:`get_template`, but tries loading multiple names.\n         If none of the names can be loaded a :exc:`TemplatesNotFound`\n         exception is raised.\n@@ -610,23 +1047,51 @@ class Environment:\n\n         .. versionadded:: 2.3\n         \"\"\"\n-        pass\n+        if isinstance(names, Undefined):\n+            names._fail_with_undefined_error()\n+\n+        if not names:\n+            raise TemplatesNotFound(\n+                message=\"Tried to select from an empty list of templates.\"\n+            )\n+\n+        for name in names:\n+            if isinstance(name, Template):\n+                return name\n+            if parent is not None:\n+                name = self.join_path(name, parent)\n+            try:\n+                return self._load_template(name, globals)\n+            except (TemplateNotFound, UndefinedError):\n+                pass\n+        raise TemplatesNotFound(names)  # type: ignore\n\n     @internalcode\n-    def get_or_select_template(self, template_name_or_list: t.Union[str,\n-        'Template', t.List[t.Union[str, 'Template']]], parent: t.Optional[\n-        str]=None, globals: t.Optional[t.MutableMapping[str, t.Any]]=None\n-        ) -&gt;'Template':\n+    def get_or_select_template(\n+        self,\n+        template_name_or_list: t.Union[\n+            str, \"Template\", t.List[t.Union[str, \"Template\"]]\n+        ],\n+        parent: t.Optional[str] = None,\n+        globals: t.Optional[t.MutableMapping[str, t.Any]] = None,\n+    ) -&gt; \"Template\":\n         \"\"\"Use :meth:`select_template` if an iterable of template names\n         is given, or :meth:`get_template` if one name is given.\n\n         .. versionadded:: 2.3\n         \"\"\"\n-        pass\n-\n-    def from_string(self, source: t.Union[str, nodes.Template], globals: t.\n-        Optional[t.MutableMapping[str, t.Any]]=None, template_class: t.\n-        Optional[t.Type['Template']]=None) -&gt;'Template':\n+        if isinstance(template_name_or_list, (str, Undefined)):\n+            return self.get_template(template_name_or_list, parent, globals)\n+        elif isinstance(template_name_or_list, Template):\n+            return template_name_or_list\n+        return self.select_template(template_name_or_list, parent, globals)\n+\n+    def from_string(\n+        self,\n+        source: t.Union[str, nodes.Template],\n+        globals: t.Optional[t.MutableMapping[str, t.Any]] = None,\n+        template_class: t.Optional[t.Type[\"Template\"]] = None,\n+    ) -&gt; \"Template\":\n         \"\"\"Load a template from a source string without using\n         :attr:`loader`.\n\n@@ -638,10 +1103,13 @@ class Environment:\n         :param template_class: Return an instance of this\n             :class:`Template` class.\n         \"\"\"\n-        pass\n+        gs = self.make_globals(globals)\n+        cls = template_class or self.template_class\n+        return cls.from_code(self, self.compile(source), gs, None)\n\n-    def make_globals(self, d: t.Optional[t.MutableMapping[str, t.Any]]\n-        ) -&gt;t.MutableMapping[str, t.Any]:\n+    def make_globals(\n+        self, d: t.Optional[t.MutableMapping[str, t.Any]]\n+    ) -&gt; t.MutableMapping[str, t.Any]:\n         \"\"\"Make the globals map for a template. Any given template\n         globals overlay the environment :attr:`globals`.\n\n@@ -656,7 +1124,10 @@ class Environment:\n             Use :class:`collections.ChainMap` to always prevent mutating\n             environment globals.\n         \"\"\"\n-        pass\n+        if d is None:\n+            d = {}\n+\n+        return ChainMap(d, self.globals)\n\n\n class Template:\n@@ -675,62 +1146,130 @@ class Template:\n     A template object should be considered immutable. Modifications on\n     the object are not supported.\n     \"\"\"\n+\n+    #: Type of environment to create when creating a template directly\n+    #: rather than through an existing environment.\n     environment_class: t.Type[Environment] = Environment\n+\n     environment: Environment\n     globals: t.MutableMapping[str, t.Any]\n     name: t.Optional[str]\n     filename: t.Optional[str]\n     blocks: t.Dict[str, t.Callable[[Context], t.Iterator[str]]]\n     root_render_func: t.Callable[[Context], t.Iterator[str]]\n-    _module: t.Optional['TemplateModule']\n+    _module: t.Optional[\"TemplateModule\"]\n     _debug_info: str\n     _uptodate: t.Optional[t.Callable[[], bool]]\n\n-    def __new__(cls, source: t.Union[str, nodes.Template],\n-        block_start_string: str=BLOCK_START_STRING, block_end_string: str=\n-        BLOCK_END_STRING, variable_start_string: str=VARIABLE_START_STRING,\n-        variable_end_string: str=VARIABLE_END_STRING, comment_start_string:\n-        str=COMMENT_START_STRING, comment_end_string: str=\n-        COMMENT_END_STRING, line_statement_prefix: t.Optional[str]=\n-        LINE_STATEMENT_PREFIX, line_comment_prefix: t.Optional[str]=\n-        LINE_COMMENT_PREFIX, trim_blocks: bool=TRIM_BLOCKS, lstrip_blocks:\n-        bool=LSTRIP_BLOCKS, newline_sequence:\n-        \"te.Literal['\\\\n', '\\\\r\\\\n', '\\\\r']\"=NEWLINE_SEQUENCE,\n-        keep_trailing_newline: bool=KEEP_TRAILING_NEWLINE, extensions: t.\n-        Sequence[t.Union[str, t.Type['Extension']]]=(), optimized: bool=\n-        True, undefined: t.Type[Undefined]=Undefined, finalize: t.Optional[\n-        t.Callable[..., t.Any]]=None, autoescape: t.Union[bool, t.Callable[\n-        [t.Optional[str]], bool]]=False, enable_async: bool=False) -&gt;t.Any:\n-        env = get_spontaneous_environment(cls.environment_class,\n-            block_start_string, block_end_string, variable_start_string,\n-            variable_end_string, comment_start_string, comment_end_string,\n-            line_statement_prefix, line_comment_prefix, trim_blocks,\n-            lstrip_blocks, newline_sequence, keep_trailing_newline,\n-            frozenset(extensions), optimized, undefined, finalize,\n-            autoescape, None, 0, False, None, enable_async)\n+    def __new__(\n+        cls,\n+        source: t.Union[str, nodes.Template],\n+        block_start_string: str = BLOCK_START_STRING,\n+        block_end_string: str = BLOCK_END_STRING,\n+        variable_start_string: str = VARIABLE_START_STRING,\n+        variable_end_string: str = VARIABLE_END_STRING,\n+        comment_start_string: str = COMMENT_START_STRING,\n+        comment_end_string: str = COMMENT_END_STRING,\n+        line_statement_prefix: t.Optional[str] = LINE_STATEMENT_PREFIX,\n+        line_comment_prefix: t.Optional[str] = LINE_COMMENT_PREFIX,\n+        trim_blocks: bool = TRIM_BLOCKS,\n+        lstrip_blocks: bool = LSTRIP_BLOCKS,\n+        newline_sequence: \"te.Literal['\\\\n', '\\\\r\\\\n', '\\\\r']\" = NEWLINE_SEQUENCE,\n+        keep_trailing_newline: bool = KEEP_TRAILING_NEWLINE,\n+        extensions: t.Sequence[t.Union[str, t.Type[\"Extension\"]]] = (),\n+        optimized: bool = True,\n+        undefined: t.Type[Undefined] = Undefined,\n+        finalize: t.Optional[t.Callable[..., t.Any]] = None,\n+        autoescape: t.Union[bool, t.Callable[[t.Optional[str]], bool]] = False,\n+        enable_async: bool = False,\n+    ) -&gt; t.Any:  # it returns a `Template`, but this breaks the sphinx build...\n+        env = get_spontaneous_environment(\n+            cls.environment_class,  # type: ignore\n+            block_start_string,\n+            block_end_string,\n+            variable_start_string,\n+            variable_end_string,\n+            comment_start_string,\n+            comment_end_string,\n+            line_statement_prefix,\n+            line_comment_prefix,\n+            trim_blocks,\n+            lstrip_blocks,\n+            newline_sequence,\n+            keep_trailing_newline,\n+            frozenset(extensions),\n+            optimized,\n+            undefined,  # type: ignore\n+            finalize,\n+            autoescape,\n+            None,\n+            0,\n+            False,\n+            None,\n+            enable_async,\n+        )\n         return env.from_string(source, template_class=cls)\n\n     @classmethod\n-    def from_code(cls, environment: Environment, code: CodeType, globals: t\n-        .MutableMapping[str, t.Any], uptodate: t.Optional[t.Callable[[],\n-        bool]]=None) -&gt;'Template':\n+    def from_code(\n+        cls,\n+        environment: Environment,\n+        code: CodeType,\n+        globals: t.MutableMapping[str, t.Any],\n+        uptodate: t.Optional[t.Callable[[], bool]] = None,\n+    ) -&gt; \"Template\":\n         \"\"\"Creates a template object from compiled code and the globals.  This\n         is used by the loaders and environment to create a template object.\n         \"\"\"\n-        pass\n+        namespace = {\"environment\": environment, \"__file__\": code.co_filename}\n+        exec(code, namespace)\n+        rv = cls._from_namespace(environment, namespace, globals)\n+        rv._uptodate = uptodate\n+        return rv\n\n     @classmethod\n-    def from_module_dict(cls, environment: Environment, module_dict: t.\n-        MutableMapping[str, t.Any], globals: t.MutableMapping[str, t.Any]\n-        ) -&gt;'Template':\n+    def from_module_dict(\n+        cls,\n+        environment: Environment,\n+        module_dict: t.MutableMapping[str, t.Any],\n+        globals: t.MutableMapping[str, t.Any],\n+    ) -&gt; \"Template\":\n         \"\"\"Creates a template object from a module.  This is used by the\n         module loader to create a template object.\n\n         .. versionadded:: 2.4\n         \"\"\"\n-        pass\n+        return cls._from_namespace(environment, module_dict, globals)\n\n-    def render(self, *args: t.Any, **kwargs: t.Any) -&gt;str:\n+    @classmethod\n+    def _from_namespace(\n+        cls,\n+        environment: Environment,\n+        namespace: t.MutableMapping[str, t.Any],\n+        globals: t.MutableMapping[str, t.Any],\n+    ) -&gt; \"Template\":\n+        t: \"Template\" = object.__new__(cls)\n+        t.environment = environment\n+        t.globals = globals\n+        t.name = namespace[\"name\"]\n+        t.filename = namespace[\"__file__\"]\n+        t.blocks = namespace[\"blocks\"]\n+\n+        # render function and module\n+        t.root_render_func = namespace[\"root\"]\n+        t._module = None\n+\n+        # debug and loader helpers\n+        t._debug_info = namespace[\"debug_info\"]\n+        t._uptodate = None\n+\n+        # store the reference\n+        namespace[\"environment\"] = environment\n+        namespace[\"__jinja_template__\"] = t\n+\n+        return t\n+\n+    def render(self, *args: t.Any, **kwargs: t.Any) -&gt; str:\n         \"\"\"This method accepts the same arguments as the `dict` constructor:\n         A dict, a dict subclass or some keyword arguments.  If no arguments\n         are given the context will be empty.  These two calls do the same::\n@@ -740,9 +1279,31 @@ class Template:\n\n         This will return the rendered template as a string.\n         \"\"\"\n-        pass\n+        if self.environment.is_async:\n+            import asyncio\n+\n+            close = False\n\n-    async def render_async(self, *args: t.Any, **kwargs: t.Any) -&gt;str:\n+            try:\n+                loop = asyncio.get_running_loop()\n+            except RuntimeError:\n+                loop = asyncio.new_event_loop()\n+                close = True\n+\n+            try:\n+                return loop.run_until_complete(self.render_async(*args, **kwargs))\n+            finally:\n+                if close:\n+                    loop.close()\n+\n+        ctx = self.new_context(dict(*args, **kwargs))\n+\n+        try:\n+            return self.environment.concat(self.root_render_func(ctx))  # type: ignore\n+        except Exception:\n+            self.environment.handle_exception()\n+\n+    async def render_async(self, *args: t.Any, **kwargs: t.Any) -&gt; str:\n         \"\"\"This works similar to :meth:`render` but returns a coroutine\n         that when awaited returns the entire rendered template string.  This\n         requires the async feature to be enabled.\n@@ -751,15 +1312,27 @@ class Template:\n\n             await template.render_async(knights='that say nih; asynchronously')\n         \"\"\"\n-        pass\n+        if not self.environment.is_async:\n+            raise RuntimeError(\n+                \"The environment was not created with async mode enabled.\"\n+            )\n+\n+        ctx = self.new_context(dict(*args, **kwargs))\n\n-    def stream(self, *args: t.Any, **kwargs: t.Any) -&gt;'TemplateStream':\n+        try:\n+            return self.environment.concat(  # type: ignore\n+                [n async for n in self.root_render_func(ctx)]  # type: ignore\n+            )\n+        except Exception:\n+            return self.environment.handle_exception()\n+\n+    def stream(self, *args: t.Any, **kwargs: t.Any) -&gt; \"TemplateStream\":\n         \"\"\"Works exactly like :meth:`generate` but returns a\n         :class:`TemplateStream`.\n         \"\"\"\n-        pass\n+        return TemplateStream(self.generate(*args, **kwargs))\n\n-    def generate(self, *args: t.Any, **kwargs: t.Any) -&gt;t.Iterator[str]:\n+    def generate(self, *args: t.Any, **kwargs: t.Any) -&gt; t.Iterator[str]:\n         \"\"\"For very large templates it can be useful to not render the whole\n         template at once but evaluate each statement after another and yield\n         piece for piece.  This method basically does exactly that and returns\n@@ -767,17 +1340,47 @@ class Template:\n\n         It accepts the same arguments as :meth:`render`.\n         \"\"\"\n-        pass\n+        if self.environment.is_async:\n+            import asyncio\n+\n+            async def to_list() -&gt; t.List[str]:\n+                return [x async for x in self.generate_async(*args, **kwargs)]\n+\n+            yield from asyncio.run(to_list())\n+            return\n\n-    async def generate_async(self, *args: t.Any, **kwargs: t.Any\n-        ) -&gt;t.AsyncIterator[str]:\n+        ctx = self.new_context(dict(*args, **kwargs))\n+\n+        try:\n+            yield from self.root_render_func(ctx)\n+        except Exception:\n+            yield self.environment.handle_exception()\n+\n+    async def generate_async(\n+        self, *args: t.Any, **kwargs: t.Any\n+    ) -&gt; t.AsyncIterator[str]:\n         \"\"\"An async version of :meth:`generate`.  Works very similarly but\n         returns an async iterator instead.\n         \"\"\"\n-        pass\n-\n-    def new_context(self, vars: t.Optional[t.Dict[str, t.Any]]=None, shared:\n-        bool=False, locals: t.Optional[t.Mapping[str, t.Any]]=None) -&gt;Context:\n+        if not self.environment.is_async:\n+            raise RuntimeError(\n+                \"The environment was not created with async mode enabled.\"\n+            )\n+\n+        ctx = self.new_context(dict(*args, **kwargs))\n+\n+        try:\n+            async for event in self.root_render_func(ctx):  # type: ignore\n+                yield event\n+        except Exception:\n+            yield self.environment.handle_exception()\n+\n+    def new_context(\n+        self,\n+        vars: t.Optional[t.Dict[str, t.Any]] = None,\n+        shared: bool = False,\n+        locals: t.Optional[t.Mapping[str, t.Any]] = None,\n+    ) -&gt; Context:\n         \"\"\"Create a new :class:`Context` for this template.  The vars\n         provided will be passed to the template.  Per default the globals\n         are added to the context.  If shared is set to `True` the data\n@@ -785,32 +1388,45 @@ class Template:\n\n         `locals` can be a dict of local variables for internal usage.\n         \"\"\"\n-        pass\n-\n-    def make_module(self, vars: t.Optional[t.Dict[str, t.Any]]=None, shared:\n-        bool=False, locals: t.Optional[t.Mapping[str, t.Any]]=None\n-        ) -&gt;'TemplateModule':\n+        return new_context(\n+            self.environment, self.name, self.blocks, vars, shared, self.globals, locals\n+        )\n+\n+    def make_module(\n+        self,\n+        vars: t.Optional[t.Dict[str, t.Any]] = None,\n+        shared: bool = False,\n+        locals: t.Optional[t.Mapping[str, t.Any]] = None,\n+    ) -&gt; \"TemplateModule\":\n         \"\"\"This method works like the :attr:`module` attribute when called\n         without arguments but it will evaluate the template on every call\n         rather than caching it.  It's also possible to provide\n         a dict which is then used as context.  The arguments are the same\n         as for the :meth:`new_context` method.\n         \"\"\"\n-        pass\n-\n-    async def make_module_async(self, vars: t.Optional[t.Dict[str, t.Any]]=\n-        None, shared: bool=False, locals: t.Optional[t.Mapping[str, t.Any]]\n-        =None) -&gt;'TemplateModule':\n+        ctx = self.new_context(vars, shared, locals)\n+        return TemplateModule(self, ctx)\n+\n+    async def make_module_async(\n+        self,\n+        vars: t.Optional[t.Dict[str, t.Any]] = None,\n+        shared: bool = False,\n+        locals: t.Optional[t.Mapping[str, t.Any]] = None,\n+    ) -&gt; \"TemplateModule\":\n         \"\"\"As template module creation can invoke template code for\n         asynchronous executions this method must be used instead of the\n         normal :meth:`make_module` one.  Likewise the module attribute\n         becomes unavailable in async mode.\n         \"\"\"\n-        pass\n+        ctx = self.new_context(vars, shared, locals)\n+        return TemplateModule(\n+            self,\n+            ctx,\n+            [x async for x in self.root_render_func(ctx)],  # type: ignore\n+        )\n\n     @internalcode\n-    def _get_default_module(self, ctx: t.Optional[Context]=None\n-        ) -&gt;'TemplateModule':\n+    def _get_default_module(self, ctx: t.Optional[Context] = None) -&gt; \"TemplateModule\":\n         \"\"\"If a context is passed in, this means that the template was\n         imported. Imported templates have access to the current\n         template's globals by default, but they can only be accessed via\n@@ -822,10 +1438,36 @@ class Template:\n         cached because the template can be imported elsewhere, and it\n         should have access to only the current template's globals.\n         \"\"\"\n-        pass\n+        if self.environment.is_async:\n+            raise RuntimeError(\"Module is not available in async mode.\")\n+\n+        if ctx is not None:\n+            keys = ctx.globals_keys - self.globals.keys()\n+\n+            if keys:\n+                return self.make_module({k: ctx.parent[k] for k in keys})\n+\n+        if self._module is None:\n+            self._module = self.make_module()\n+\n+        return self._module\n+\n+    async def _get_default_module_async(\n+        self, ctx: t.Optional[Context] = None\n+    ) -&gt; \"TemplateModule\":\n+        if ctx is not None:\n+            keys = ctx.globals_keys - self.globals.keys()\n+\n+            if keys:\n+                return await self.make_module_async({k: ctx.parent[k] for k in keys})\n+\n+        if self._module is None:\n+            self._module = await self.make_module_async()\n+\n+        return self._module\n\n     @property\n-    def module(self) -&gt;'TemplateModule':\n+    def module(self) -&gt; \"TemplateModule\":\n         \"\"\"The template as module.  This is used for imports in the\n         template runtime but is also useful if one wants to access\n         exported template variables from the Python layer:\n@@ -838,30 +1480,41 @@ class Template:\n\n         This attribute is not available if async mode is enabled.\n         \"\"\"\n-        pass\n+        return self._get_default_module()\n\n-    def get_corresponding_lineno(self, lineno: int) -&gt;int:\n+    def get_corresponding_lineno(self, lineno: int) -&gt; int:\n         \"\"\"Return the source line number of a line number in the\n         generated bytecode as they are not in sync.\n         \"\"\"\n-        pass\n+        for template_line, code_line in reversed(self.debug_info):\n+            if code_line &lt;= lineno:\n+                return template_line\n+        return 1\n\n     @property\n-    def is_up_to_date(self) -&gt;bool:\n+    def is_up_to_date(self) -&gt; bool:\n         \"\"\"If this variable is `False` there is a newer version available.\"\"\"\n-        pass\n+        if self._uptodate is None:\n+            return True\n+        return self._uptodate()\n\n     @property\n-    def debug_info(self) -&gt;t.List[t.Tuple[int, int]]:\n+    def debug_info(self) -&gt; t.List[t.Tuple[int, int]]:\n         \"\"\"The debug info mapping.\"\"\"\n-        pass\n+        if self._debug_info:\n+            return [\n+                tuple(map(int, x.split(\"=\")))  # type: ignore\n+                for x in self._debug_info.split(\"&amp;\")\n+            ]\n+\n+        return []\n\n-    def __repr__(self) -&gt;str:\n+    def __repr__(self) -&gt; str:\n         if self.name is None:\n-            name = f'memory:{id(self):x}'\n+            name = f\"memory:{id(self):x}\"\n         else:\n             name = repr(self.name)\n-        return f'&lt;{type(self).__name__} {name}&gt;'\n+        return f\"&lt;{type(self).__name__} {name}&gt;\"\n\n\n class TemplateModule:\n@@ -870,30 +1523,38 @@ class TemplateModule:\n     converting it into a string renders the contents.\n     \"\"\"\n\n-    def __init__(self, template: Template, context: Context, body_stream: t\n-        .Optional[t.Iterable[str]]=None) -&gt;None:\n+    def __init__(\n+        self,\n+        template: Template,\n+        context: Context,\n+        body_stream: t.Optional[t.Iterable[str]] = None,\n+    ) -&gt; None:\n         if body_stream is None:\n             if context.environment.is_async:\n                 raise RuntimeError(\n-                    'Async mode requires a body stream to be passed to a template module. Use the async methods of the API you are using.'\n-                    )\n+                    \"Async mode requires a body stream to be passed to\"\n+                    \" a template module. Use the async methods of the\"\n+                    \" API you are using.\"\n+                )\n+\n             body_stream = list(template.root_render_func(context))\n+\n         self._body_stream = body_stream\n         self.__dict__.update(context.get_exported())\n         self.__name__ = template.name\n\n-    def __html__(self) -&gt;Markup:\n+    def __html__(self) -&gt; Markup:\n         return Markup(concat(self._body_stream))\n\n-    def __str__(self) -&gt;str:\n+    def __str__(self) -&gt; str:\n         return concat(self._body_stream)\n\n-    def __repr__(self) -&gt;str:\n+    def __repr__(self) -&gt; str:\n         if self.__name__ is None:\n-            name = f'memory:{id(self):x}'\n+            name = f\"memory:{id(self):x}\"\n         else:\n             name = repr(self.__name__)\n-        return f'&lt;{type(self).__name__} {name}&gt;'\n+        return f\"&lt;{type(self).__name__} {name}&gt;\"\n\n\n class TemplateExpression:\n@@ -902,14 +1563,14 @@ class TemplateExpression:\n     to the template with an expression it wraps.\n     \"\"\"\n\n-    def __init__(self, template: Template, undefined_to_none: bool) -&gt;None:\n+    def __init__(self, template: Template, undefined_to_none: bool) -&gt; None:\n         self._template = template\n         self._undefined_to_none = undefined_to_none\n\n-    def __call__(self, *args: t.Any, **kwargs: t.Any) -&gt;t.Optional[t.Any]:\n+    def __call__(self, *args: t.Any, **kwargs: t.Any) -&gt; t.Optional[t.Any]:\n         context = self._template.new_context(dict(*args, **kwargs))\n         consume(self._template.root_render_func(context))\n-        rv = context.vars['result']\n+        rv = context.vars[\"result\"]\n         if self._undefined_to_none and isinstance(rv, Undefined):\n             rv = None\n         return rv\n@@ -926,12 +1587,16 @@ class TemplateStream:\n     big templates to a client via WSGI which flushes after each iteration.\n     \"\"\"\n\n-    def __init__(self, gen: t.Iterator[str]) -&gt;None:\n+    def __init__(self, gen: t.Iterator[str]) -&gt; None:\n         self._gen = gen\n         self.disable_buffering()\n\n-    def dump(self, fp: t.Union[str, t.IO[bytes]], encoding: t.Optional[str]\n-        =None, errors: t.Optional[str]='strict') -&gt;None:\n+    def dump(\n+        self,\n+        fp: t.Union[str, t.IO[bytes]],\n+        encoding: t.Optional[str] = None,\n+        errors: t.Optional[str] = \"strict\",\n+    ) -&gt; None:\n         \"\"\"Dump the complete stream into a file or file-like object.\n         Per default strings are written, if you want to encode\n         before writing specify an `encoding`.\n@@ -940,21 +1605,71 @@ class TemplateStream:\n\n             Template('Hello {{ name }}!').stream(name='foo').dump('hello.html')\n         \"\"\"\n-        pass\n+        close = False\n\n-    def disable_buffering(self) -&gt;None:\n-        \"\"\"Disable the output buffering.\"\"\"\n-        pass\n+        if isinstance(fp, str):\n+            if encoding is None:\n+                encoding = \"utf-8\"\n\n-    def enable_buffering(self, size: int=5) -&gt;None:\n+            real_fp: t.IO[bytes] = open(fp, \"wb\")\n+            close = True\n+        else:\n+            real_fp = fp\n+\n+        try:\n+            if encoding is not None:\n+                iterable = (x.encode(encoding, errors) for x in self)  # type: ignore\n+            else:\n+                iterable = self  # type: ignore\n+\n+            if hasattr(real_fp, \"writelines\"):\n+                real_fp.writelines(iterable)\n+            else:\n+                for item in iterable:\n+                    real_fp.write(item)\n+        finally:\n+            if close:\n+                real_fp.close()\n+\n+    def disable_buffering(self) -&gt; None:\n+        \"\"\"Disable the output buffering.\"\"\"\n+        self._next = partial(next, self._gen)\n+        self.buffered = False\n+\n+    def _buffered_generator(self, size: int) -&gt; t.Iterator[str]:\n+        buf: t.List[str] = []\n+        c_size = 0\n+        push = buf.append\n+\n+        while True:\n+            try:\n+                while c_size &lt; size:\n+                    c = next(self._gen)\n+                    push(c)\n+                    if c:\n+                        c_size += 1\n+            except StopIteration:\n+                if not c_size:\n+                    return\n+            yield concat(buf)\n+            del buf[:]\n+            c_size = 0\n+\n+    def enable_buffering(self, size: int = 5) -&gt; None:\n         \"\"\"Enable buffering.  Buffer `size` items before yielding them.\"\"\"\n-        pass\n+        if size &lt;= 1:\n+            raise ValueError(\"buffer size too small\")\n+\n+        self.buffered = True\n+        self._next = partial(next, self._buffered_generator(size))\n\n-    def __iter__(self) -&gt;'TemplateStream':\n+    def __iter__(self) -&gt; \"TemplateStream\":\n         return self\n\n-    def __next__(self) -&gt;str:\n-        return self._next()\n+    def __next__(self) -&gt; str:\n+        return self._next()  # type: ignore\n\n\n+# hook in default template class.  if anyone reads this comment: ignore that\n+# it's possible to use custom templates ;-)\n Environment.template_class = Template\ndiff --git a/src/jinja2/exceptions.py b/src/jinja2/exceptions.py\nindex 39cc9cb..082ebe8 100644\n--- a/src/jinja2/exceptions.py\n+++ b/src/jinja2/exceptions.py\n@@ -1,4 +1,5 @@\n import typing as t\n+\n if t.TYPE_CHECKING:\n     from .runtime import Undefined\n\n@@ -6,9 +7,13 @@ if t.TYPE_CHECKING:\n class TemplateError(Exception):\n     \"\"\"Baseclass for all template errors.\"\"\"\n\n-    def __init__(self, message: t.Optional[str]=None) -&gt;None:\n+    def __init__(self, message: t.Optional[str] = None) -&gt; None:\n         super().__init__(message)\n\n+    @property\n+    def message(self) -&gt; t.Optional[str]:\n+        return self.args[0] if self.args else None\n+\n\n class TemplateNotFound(IOError, LookupError, TemplateError):\n     \"\"\"Raised if a template does not exist.\n@@ -17,21 +22,31 @@ class TemplateNotFound(IOError, LookupError, TemplateError):\n         If the given name is :class:`Undefined` and no message was\n         provided, an :exc:`UndefinedError` is raised.\n     \"\"\"\n+\n+    # Silence the Python warning about message being deprecated since\n+    # it's not valid here.\n     message: t.Optional[str] = None\n\n-    def __init__(self, name: t.Optional[t.Union[str, 'Undefined']], message:\n-        t.Optional[str]=None) -&gt;None:\n+    def __init__(\n+        self,\n+        name: t.Optional[t.Union[str, \"Undefined\"]],\n+        message: t.Optional[str] = None,\n+    ) -&gt; None:\n         IOError.__init__(self, name)\n+\n         if message is None:\n             from .runtime import Undefined\n+\n             if isinstance(name, Undefined):\n                 name._fail_with_undefined_error()\n+\n             message = name\n+\n         self.message = message\n         self.name = name\n         self.templates = [name]\n\n-    def __str__(self) -&gt;str:\n+    def __str__(self) -&gt; str:\n         return str(self.message)\n\n\n@@ -47,18 +62,25 @@ class TemplatesNotFound(TemplateNotFound):\n     .. versionadded:: 2.2\n     \"\"\"\n\n-    def __init__(self, names: t.Sequence[t.Union[str, 'Undefined']]=(),\n-        message: t.Optional[str]=None) -&gt;None:\n+    def __init__(\n+        self,\n+        names: t.Sequence[t.Union[str, \"Undefined\"]] = (),\n+        message: t.Optional[str] = None,\n+    ) -&gt; None:\n         if message is None:\n             from .runtime import Undefined\n+\n             parts = []\n+\n             for name in names:\n                 if isinstance(name, Undefined):\n                     parts.append(name._undefined_message)\n                 else:\n                     parts.append(name)\n-            parts_str = ', '.join(map(str, parts))\n-            message = f'none of the templates given were found: {parts_str}'\n+\n+            parts_str = \", \".join(map(str, parts))\n+            message = f\"none of the templates given were found: {parts_str}\"\n+\n         super().__init__(names[-1] if names else None, message)\n         self.templates = list(names)\n\n@@ -66,35 +88,52 @@ class TemplatesNotFound(TemplateNotFound):\n class TemplateSyntaxError(TemplateError):\n     \"\"\"Raised to tell the user that there is a problem with the template.\"\"\"\n\n-    def __init__(self, message: str, lineno: int, name: t.Optional[str]=\n-        None, filename: t.Optional[str]=None) -&gt;None:\n+    def __init__(\n+        self,\n+        message: str,\n+        lineno: int,\n+        name: t.Optional[str] = None,\n+        filename: t.Optional[str] = None,\n+    ) -&gt; None:\n         super().__init__(message)\n         self.lineno = lineno\n         self.name = name\n         self.filename = filename\n         self.source: t.Optional[str] = None\n+\n+        # this is set to True if the debug.translate_syntax_error\n+        # function translated the syntax error into a new traceback\n         self.translated = False\n\n-    def __str__(self) -&gt;str:\n+    def __str__(self) -&gt; str:\n+        # for translated errors we only return the message\n         if self.translated:\n             return t.cast(str, self.message)\n-        location = f'line {self.lineno}'\n+\n+        # otherwise attach some stuff\n+        location = f\"line {self.lineno}\"\n         name = self.filename or self.name\n         if name:\n             location = f'File \"{name}\", {location}'\n-        lines = [t.cast(str, self.message), '  ' + location]\n+        lines = [t.cast(str, self.message), \"  \" + location]\n+\n+        # if the source is set, add the line to the output\n         if self.source is not None:\n             try:\n                 line = self.source.splitlines()[self.lineno - 1]\n             except IndexError:\n                 pass\n             else:\n-                lines.append('    ' + line.strip())\n-        return '\\n'.join(lines)\n+                lines.append(\"    \" + line.strip())\n+\n+        return \"\\n\".join(lines)\n\n-    def __reduce__(self):\n-        return self.__class__, (self.message, self.lineno, self.name, self.\n-            filename)\n+    def __reduce__(self):  # type: ignore\n+        # https://bugs.python.org/issue1692335 Exceptions that take\n+        # multiple required arguments have problems with pickling.\n+        # Without this, raises TypeError: __init__() missing 1 required\n+        # positional argument: 'lineno'\n+        return self.__class__, (self.message, self.lineno, self.name, self.filename)\n\n\n class TemplateAssertionError(TemplateSyntaxError):\ndiff --git a/src/jinja2/ext.py b/src/jinja2/ext.py\nindex 337f30c..8d0810c 100644\n--- a/src/jinja2/ext.py\n+++ b/src/jinja2/ext.py\n@@ -1,35 +1,55 @@\n \"\"\"Extension API for adding custom tags and behavior.\"\"\"\n+\n import pprint\n import re\n import typing as t\n+\n from markupsafe import Markup\n+\n from . import defaults\n from . import nodes\n from .environment import Environment\n from .exceptions import TemplateAssertionError\n from .exceptions import TemplateSyntaxError\n-from .runtime import concat\n+from .runtime import concat  # type: ignore\n from .runtime import Context\n from .runtime import Undefined\n from .utils import import_string\n from .utils import pass_context\n+\n if t.TYPE_CHECKING:\n     import typing_extensions as te\n+\n     from .lexer import Token\n     from .lexer import TokenStream\n     from .parser import Parser\n\n-\n     class _TranslationsBasic(te.Protocol):\n-        pass\n+        def gettext(self, message: str) -&gt; str: ...\n\n+        def ngettext(self, singular: str, plural: str, n: int) -&gt; str:\n+            pass\n\n     class _TranslationsContext(_TranslationsBasic):\n-        pass\n+        def pgettext(self, context: str, message: str) -&gt; str: ...\n+\n+        def npgettext(\n+            self, context: str, singular: str, plural: str, n: int\n+        ) -&gt; str: ...\n+\n     _SupportedTranslations = t.Union[_TranslationsBasic, _TranslationsContext]\n-GETTEXT_FUNCTIONS: t.Tuple[str, ...] = ('_', 'gettext', 'ngettext',\n-    'pgettext', 'npgettext')\n-_ws_re = re.compile('\\\\s*\\\\n\\\\s*')\n+\n+\n+# I18N functions available in Jinja templates. If the I18N library\n+# provides ugettext, it will be assigned to gettext.\n+GETTEXT_FUNCTIONS: t.Tuple[str, ...] = (\n+    \"_\",\n+    \"gettext\",\n+    \"ngettext\",\n+    \"pgettext\",\n+    \"npgettext\",\n+)\n+_ws_re = re.compile(r\"\\s*\\n\\s*\")\n\n\n class Extension:\n@@ -50,48 +70,62 @@ class Extension:\n     is a terrible name, ``fragment_cache_prefix`` on the other hand is a good\n     name as includes the name of the extension (fragment cache).\n     \"\"\"\n+\n     identifier: t.ClassVar[str]\n\n-    def __init_subclass__(cls) -&gt;None:\n-        cls.identifier = f'{cls.__module__}.{cls.__name__}'\n+    def __init_subclass__(cls) -&gt; None:\n+        cls.identifier = f\"{cls.__module__}.{cls.__name__}\"\n+\n+    #: if this extension parses this is the list of tags it's listening to.\n     tags: t.Set[str] = set()\n+\n+    #: the priority of that extension.  This is especially useful for\n+    #: extensions that preprocess values.  A lower value means higher\n+    #: priority.\n+    #:\n+    #: .. versionadded:: 2.4\n     priority = 100\n\n-    def __init__(self, environment: Environment) -&gt;None:\n+    def __init__(self, environment: Environment) -&gt; None:\n         self.environment = environment\n\n-    def bind(self, environment: Environment) -&gt;'Extension':\n+    def bind(self, environment: Environment) -&gt; \"Extension\":\n         \"\"\"Create a copy of this extension bound to another environment.\"\"\"\n-        pass\n-\n-    def preprocess(self, source: str, name: t.Optional[str], filename: t.\n-        Optional[str]=None) -&gt;str:\n+        rv = object.__new__(self.__class__)\n+        rv.__dict__.update(self.__dict__)\n+        rv.environment = environment\n+        return rv\n+\n+    def preprocess(\n+        self, source: str, name: t.Optional[str], filename: t.Optional[str] = None\n+    ) -&gt; str:\n         \"\"\"This method is called before the actual lexing and can be used to\n         preprocess the source.  The `filename` is optional.  The return value\n         must be the preprocessed source.\n         \"\"\"\n-        pass\n+        return source\n\n-    def filter_stream(self, stream: 'TokenStream') -&gt;t.Union['TokenStream',\n-        t.Iterable['Token']]:\n+    def filter_stream(\n+        self, stream: \"TokenStream\"\n+    ) -&gt; t.Union[\"TokenStream\", t.Iterable[\"Token\"]]:\n         \"\"\"It's passed a :class:`~jinja2.lexer.TokenStream` that can be used\n         to filter tokens returned.  This method has to return an iterable of\n         :class:`~jinja2.lexer.Token`\\\\s, but it doesn't have to return a\n         :class:`~jinja2.lexer.TokenStream`.\n         \"\"\"\n-        pass\n+        return stream\n\n-    def parse(self, parser: 'Parser') -&gt;t.Union[nodes.Node, t.List[nodes.Node]\n-        ]:\n+    def parse(self, parser: \"Parser\") -&gt; t.Union[nodes.Node, t.List[nodes.Node]]:\n         \"\"\"If any of the :attr:`tags` matched this method is called with the\n         parser as first argument.  The token the parser stream is pointing at\n         is the name token that matched.  This method has to return one or a\n         list of multiple nodes.\n         \"\"\"\n-        pass\n+        raise NotImplementedError()\n\n-    def attr(self, name: str, lineno: t.Optional[int]=None\n-        ) -&gt;nodes.ExtensionAttribute:\n+    def attr(\n+        self, name: str, lineno: t.Optional[int] = None\n+    ) -&gt; nodes.ExtensionAttribute:\n         \"\"\"Return an attribute node for the current extension.  This is useful\n         to pass constants on extensions to generated template code.\n\n@@ -99,59 +133,483 @@ class Extension:\n\n             self.attr('_my_attribute', lineno=lineno)\n         \"\"\"\n-        pass\n-\n-    def call_method(self, name: str, args: t.Optional[t.List[nodes.Expr]]=\n-        None, kwargs: t.Optional[t.List[nodes.Keyword]]=None, dyn_args: t.\n-        Optional[nodes.Expr]=None, dyn_kwargs: t.Optional[nodes.Expr]=None,\n-        lineno: t.Optional[int]=None) -&gt;nodes.Call:\n+        return nodes.ExtensionAttribute(self.identifier, name, lineno=lineno)\n+\n+    def call_method(\n+        self,\n+        name: str,\n+        args: t.Optional[t.List[nodes.Expr]] = None,\n+        kwargs: t.Optional[t.List[nodes.Keyword]] = None,\n+        dyn_args: t.Optional[nodes.Expr] = None,\n+        dyn_kwargs: t.Optional[nodes.Expr] = None,\n+        lineno: t.Optional[int] = None,\n+    ) -&gt; nodes.Call:\n         \"\"\"Call a method of the extension.  This is a shortcut for\n         :meth:`attr` + :class:`jinja2.nodes.Call`.\n         \"\"\"\n-        pass\n+        if args is None:\n+            args = []\n+        if kwargs is None:\n+            kwargs = []\n+        return nodes.Call(\n+            self.attr(name, lineno=lineno),\n+            args,\n+            kwargs,\n+            dyn_args,\n+            dyn_kwargs,\n+            lineno=lineno,\n+        )\n+\n+\n+@pass_context\n+def _gettext_alias(\n+    __context: Context, *args: t.Any, **kwargs: t.Any\n+) -&gt; t.Union[t.Any, Undefined]:\n+    return __context.call(__context.resolve(\"gettext\"), *args, **kwargs)\n+\n+\n+def _make_new_gettext(func: t.Callable[[str], str]) -&gt; t.Callable[..., str]:\n+    @pass_context\n+    def gettext(__context: Context, __string: str, **variables: t.Any) -&gt; str:\n+        rv = __context.call(func, __string)\n+        if __context.eval_ctx.autoescape:\n+            rv = Markup(rv)\n+        # Always treat as a format string, even if there are no\n+        # variables. This makes translation strings more consistent\n+        # and predictable. This requires escaping\n+        return rv % variables  # type: ignore\n+\n+    return gettext\n+\n+\n+def _make_new_ngettext(func: t.Callable[[str, str, int], str]) -&gt; t.Callable[..., str]:\n+    @pass_context\n+    def ngettext(\n+        __context: Context,\n+        __singular: str,\n+        __plural: str,\n+        __num: int,\n+        **variables: t.Any,\n+    ) -&gt; str:\n+        variables.setdefault(\"num\", __num)\n+        rv = __context.call(func, __singular, __plural, __num)\n+        if __context.eval_ctx.autoescape:\n+            rv = Markup(rv)\n+        # Always treat as a format string, see gettext comment above.\n+        return rv % variables  # type: ignore\n+\n+    return ngettext\n+\n+\n+def _make_new_pgettext(func: t.Callable[[str, str], str]) -&gt; t.Callable[..., str]:\n+    @pass_context\n+    def pgettext(\n+        __context: Context, __string_ctx: str, __string: str, **variables: t.Any\n+    ) -&gt; str:\n+        variables.setdefault(\"context\", __string_ctx)\n+        rv = __context.call(func, __string_ctx, __string)\n+\n+        if __context.eval_ctx.autoescape:\n+            rv = Markup(rv)\n+\n+        # Always treat as a format string, see gettext comment above.\n+        return rv % variables  # type: ignore\n+\n+    return pgettext\n+\n+\n+def _make_new_npgettext(\n+    func: t.Callable[[str, str, str, int], str],\n+) -&gt; t.Callable[..., str]:\n+    @pass_context\n+    def npgettext(\n+        __context: Context,\n+        __string_ctx: str,\n+        __singular: str,\n+        __plural: str,\n+        __num: int,\n+        **variables: t.Any,\n+    ) -&gt; str:\n+        variables.setdefault(\"context\", __string_ctx)\n+        variables.setdefault(\"num\", __num)\n+        rv = __context.call(func, __string_ctx, __singular, __plural, __num)\n+\n+        if __context.eval_ctx.autoescape:\n+            rv = Markup(rv)\n+\n+        # Always treat as a format string, see gettext comment above.\n+        return rv % variables  # type: ignore\n+\n+    return npgettext\n\n\n class InternationalizationExtension(Extension):\n     \"\"\"This extension adds gettext support to Jinja.\"\"\"\n-    tags = {'trans'}\n\n-    def __init__(self, environment: Environment) -&gt;None:\n+    tags = {\"trans\"}\n+\n+    # TODO: the i18n extension is currently reevaluating values in a few\n+    # situations.  Take this example:\n+    #   {% trans count=something() %}{{ count }} foo{% pluralize\n+    #     %}{{ count }} fooss{% endtrans %}\n+    # something is called twice here.  One time for the gettext value and\n+    # the other time for the n-parameter of the ngettext function.\n+\n+    def __init__(self, environment: Environment) -&gt; None:\n         super().__init__(environment)\n-        environment.globals['_'] = _gettext_alias\n-        environment.extend(install_gettext_translations=self._install,\n+        environment.globals[\"_\"] = _gettext_alias\n+        environment.extend(\n+            install_gettext_translations=self._install,\n             install_null_translations=self._install_null,\n             install_gettext_callables=self._install_callables,\n             uninstall_gettext_translations=self._uninstall,\n-            extract_translations=self._extract, newstyle_gettext=False)\n-\n-    def parse(self, parser: 'Parser') -&gt;t.Union[nodes.Node, t.List[nodes.Node]\n-        ]:\n+            extract_translations=self._extract,\n+            newstyle_gettext=False,\n+        )\n+\n+    def _install(\n+        self, translations: \"_SupportedTranslations\", newstyle: t.Optional[bool] = None\n+    ) -&gt; None:\n+        # ugettext and ungettext are preferred in case the I18N library\n+        # is providing compatibility with older Python versions.\n+        gettext = getattr(translations, \"ugettext\", None)\n+        if gettext is None:\n+            gettext = translations.gettext\n+        ngettext = getattr(translations, \"ungettext\", None)\n+        if ngettext is None:\n+            ngettext = translations.ngettext\n+\n+        pgettext = getattr(translations, \"pgettext\", None)\n+        npgettext = getattr(translations, \"npgettext\", None)\n+        self._install_callables(\n+            gettext, ngettext, newstyle=newstyle, pgettext=pgettext, npgettext=npgettext\n+        )\n+\n+    def _install_null(self, newstyle: t.Optional[bool] = None) -&gt; None:\n+        import gettext\n+\n+        translations = gettext.NullTranslations()\n+\n+        if hasattr(translations, \"pgettext\"):\n+            # Python &lt; 3.8\n+            pgettext = translations.pgettext\n+        else:\n+\n+            def pgettext(c: str, s: str) -&gt; str:  # type: ignore[misc]\n+                return s\n+\n+        if hasattr(translations, \"npgettext\"):\n+            npgettext = translations.npgettext\n+        else:\n+\n+            def npgettext(c: str, s: str, p: str, n: int) -&gt; str:  # type: ignore[misc]\n+                return s if n == 1 else p\n+\n+        self._install_callables(\n+            gettext=translations.gettext,\n+            ngettext=translations.ngettext,\n+            newstyle=newstyle,\n+            pgettext=pgettext,\n+            npgettext=npgettext,\n+        )\n+\n+    def _install_callables(\n+        self,\n+        gettext: t.Callable[[str], str],\n+        ngettext: t.Callable[[str, str, int], str],\n+        newstyle: t.Optional[bool] = None,\n+        pgettext: t.Optional[t.Callable[[str, str], str]] = None,\n+        npgettext: t.Optional[t.Callable[[str, str, str, int], str]] = None,\n+    ) -&gt; None:\n+        if newstyle is not None:\n+            self.environment.newstyle_gettext = newstyle  # type: ignore\n+        if self.environment.newstyle_gettext:  # type: ignore\n+            gettext = _make_new_gettext(gettext)\n+            ngettext = _make_new_ngettext(ngettext)\n+\n+            if pgettext is not None:\n+                pgettext = _make_new_pgettext(pgettext)\n+\n+            if npgettext is not None:\n+                npgettext = _make_new_npgettext(npgettext)\n+\n+        self.environment.globals.update(\n+            gettext=gettext, ngettext=ngettext, pgettext=pgettext, npgettext=npgettext\n+        )\n+\n+    def _uninstall(self, translations: \"_SupportedTranslations\") -&gt; None:\n+        for key in (\"gettext\", \"ngettext\", \"pgettext\", \"npgettext\"):\n+            self.environment.globals.pop(key, None)\n+\n+    def _extract(\n+        self,\n+        source: t.Union[str, nodes.Template],\n+        gettext_functions: t.Sequence[str] = GETTEXT_FUNCTIONS,\n+    ) -&gt; t.Iterator[\n+        t.Tuple[int, str, t.Union[t.Optional[str], t.Tuple[t.Optional[str], ...]]]\n+    ]:\n+        if isinstance(source, str):\n+            source = self.environment.parse(source)\n+        return extract_from_ast(source, gettext_functions)\n+\n+    def parse(self, parser: \"Parser\") -&gt; t.Union[nodes.Node, t.List[nodes.Node]]:\n         \"\"\"Parse a translatable tag.\"\"\"\n-        pass\n-\n-    def _parse_block(self, parser: 'Parser', allow_pluralize: bool) -&gt;t.Tuple[\n-        t.List[str], str]:\n+        lineno = next(parser.stream).lineno\n+\n+        context = None\n+        context_token = parser.stream.next_if(\"string\")\n+\n+        if context_token is not None:\n+            context = context_token.value\n+\n+        # find all the variables referenced.  Additionally a variable can be\n+        # defined in the body of the trans block too, but this is checked at\n+        # a later state.\n+        plural_expr: t.Optional[nodes.Expr] = None\n+        plural_expr_assignment: t.Optional[nodes.Assign] = None\n+        num_called_num = False\n+        variables: t.Dict[str, nodes.Expr] = {}\n+        trimmed = None\n+        while parser.stream.current.type != \"block_end\":\n+            if variables:\n+                parser.stream.expect(\"comma\")\n+\n+            # skip colon for python compatibility\n+            if parser.stream.skip_if(\"colon\"):\n+                break\n+\n+            token = parser.stream.expect(\"name\")\n+            if token.value in variables:\n+                parser.fail(\n+                    f\"translatable variable {token.value!r} defined twice.\",\n+                    token.lineno,\n+                    exc=TemplateAssertionError,\n+                )\n+\n+            # expressions\n+            if parser.stream.current.type == \"assign\":\n+                next(parser.stream)\n+                variables[token.value] = var = parser.parse_expression()\n+            elif trimmed is None and token.value in (\"trimmed\", \"notrimmed\"):\n+                trimmed = token.value == \"trimmed\"\n+                continue\n+            else:\n+                variables[token.value] = var = nodes.Name(token.value, \"load\")\n+\n+            if plural_expr is None:\n+                if isinstance(var, nodes.Call):\n+                    plural_expr = nodes.Name(\"_trans\", \"load\")\n+                    variables[token.value] = plural_expr\n+                    plural_expr_assignment = nodes.Assign(\n+                        nodes.Name(\"_trans\", \"store\"), var\n+                    )\n+                else:\n+                    plural_expr = var\n+                num_called_num = token.value == \"num\"\n+\n+        parser.stream.expect(\"block_end\")\n+\n+        plural = None\n+        have_plural = False\n+        referenced = set()\n+\n+        # now parse until endtrans or pluralize\n+        singular_names, singular = self._parse_block(parser, True)\n+        if singular_names:\n+            referenced.update(singular_names)\n+            if plural_expr is None:\n+                plural_expr = nodes.Name(singular_names[0], \"load\")\n+                num_called_num = singular_names[0] == \"num\"\n+\n+        # if we have a pluralize block, we parse that too\n+        if parser.stream.current.test(\"name:pluralize\"):\n+            have_plural = True\n+            next(parser.stream)\n+            if parser.stream.current.type != \"block_end\":\n+                token = parser.stream.expect(\"name\")\n+                if token.value not in variables:\n+                    parser.fail(\n+                        f\"unknown variable {token.value!r} for pluralization\",\n+                        token.lineno,\n+                        exc=TemplateAssertionError,\n+                    )\n+                plural_expr = variables[token.value]\n+                num_called_num = token.value == \"num\"\n+            parser.stream.expect(\"block_end\")\n+            plural_names, plural = self._parse_block(parser, False)\n+            next(parser.stream)\n+            referenced.update(plural_names)\n+        else:\n+            next(parser.stream)\n+\n+        # register free names as simple name expressions\n+        for name in referenced:\n+            if name not in variables:\n+                variables[name] = nodes.Name(name, \"load\")\n+\n+        if not have_plural:\n+            plural_expr = None\n+        elif plural_expr is None:\n+            parser.fail(\"pluralize without variables\", lineno)\n+\n+        if trimmed is None:\n+            trimmed = self.environment.policies[\"ext.i18n.trimmed\"]\n+        if trimmed:\n+            singular = self._trim_whitespace(singular)\n+            if plural:\n+                plural = self._trim_whitespace(plural)\n+\n+        node = self._make_node(\n+            singular,\n+            plural,\n+            context,\n+            variables,\n+            plural_expr,\n+            bool(referenced),\n+            num_called_num and have_plural,\n+        )\n+        node.set_lineno(lineno)\n+        if plural_expr_assignment is not None:\n+            return [plural_expr_assignment, node]\n+        else:\n+            return node\n+\n+    def _trim_whitespace(self, string: str, _ws_re: t.Pattern[str] = _ws_re) -&gt; str:\n+        return _ws_re.sub(\" \", string.strip())\n+\n+    def _parse_block(\n+        self, parser: \"Parser\", allow_pluralize: bool\n+    ) -&gt; t.Tuple[t.List[str], str]:\n         \"\"\"Parse until the next block tag with a given name.\"\"\"\n-        pass\n-\n-    def _make_node(self, singular: str, plural: t.Optional[str], context: t\n-        .Optional[str], variables: t.Dict[str, nodes.Expr], plural_expr: t.\n-        Optional[nodes.Expr], vars_referenced: bool, num_called_num: bool\n-        ) -&gt;nodes.Output:\n+        referenced = []\n+        buf = []\n+\n+        while True:\n+            if parser.stream.current.type == \"data\":\n+                buf.append(parser.stream.current.value.replace(\"%\", \"%%\"))\n+                next(parser.stream)\n+            elif parser.stream.current.type == \"variable_begin\":\n+                next(parser.stream)\n+                name = parser.stream.expect(\"name\").value\n+                referenced.append(name)\n+                buf.append(f\"%({name})s\")\n+                parser.stream.expect(\"variable_end\")\n+            elif parser.stream.current.type == \"block_begin\":\n+                next(parser.stream)\n+                block_name = (\n+                    parser.stream.current.value\n+                    if parser.stream.current.type == \"name\"\n+                    else None\n+                )\n+                if block_name == \"endtrans\":\n+                    break\n+                elif block_name == \"pluralize\":\n+                    if allow_pluralize:\n+                        break\n+                    parser.fail(\n+                        \"a translatable section can have only one pluralize section\"\n+                    )\n+                elif block_name == \"trans\":\n+                    parser.fail(\n+                        \"trans blocks can't be nested; did you mean `endtrans`?\"\n+                    )\n+                parser.fail(\n+                    f\"control structures in translatable sections are not allowed; \"\n+                    f\"saw `{block_name}`\"\n+                )\n+            elif parser.stream.eos:\n+                parser.fail(\"unclosed translation block\")\n+            else:\n+                raise RuntimeError(\"internal parser error\")\n+\n+        return referenced, concat(buf)\n+\n+    def _make_node(\n+        self,\n+        singular: str,\n+        plural: t.Optional[str],\n+        context: t.Optional[str],\n+        variables: t.Dict[str, nodes.Expr],\n+        plural_expr: t.Optional[nodes.Expr],\n+        vars_referenced: bool,\n+        num_called_num: bool,\n+    ) -&gt; nodes.Output:\n         \"\"\"Generates a useful node from the data provided.\"\"\"\n-        pass\n+        newstyle = self.environment.newstyle_gettext  # type: ignore\n+        node: nodes.Expr\n+\n+        # no variables referenced?  no need to escape for old style\n+        # gettext invocations only if there are vars.\n+        if not vars_referenced and not newstyle:\n+            singular = singular.replace(\"%%\", \"%\")\n+            if plural:\n+                plural = plural.replace(\"%%\", \"%\")\n+\n+        func_name = \"gettext\"\n+        func_args: t.List[nodes.Expr] = [nodes.Const(singular)]\n+\n+        if context is not None:\n+            func_args.insert(0, nodes.Const(context))\n+            func_name = f\"p{func_name}\"\n+\n+        if plural_expr is not None:\n+            func_name = f\"n{func_name}\"\n+            func_args.extend((nodes.Const(plural), plural_expr))\n+\n+        node = nodes.Call(nodes.Name(func_name, \"load\"), func_args, [], None, None)\n+\n+        # in case newstyle gettext is used, the method is powerful\n+        # enough to handle the variable expansion and autoescape\n+        # handling itself\n+        if newstyle:\n+            for key, value in variables.items():\n+                # the function adds that later anyways in case num was\n+                # called num, so just skip it.\n+                if num_called_num and key == \"num\":\n+                    continue\n+                node.kwargs.append(nodes.Keyword(key, value))\n+\n+        # otherwise do that here\n+        else:\n+            # mark the return value as safe if we are in an\n+            # environment with autoescaping turned on\n+            node = nodes.MarkSafeIfAutoescape(node)\n+            if variables:\n+                node = nodes.Mod(\n+                    node,\n+                    nodes.Dict(\n+                        [\n+                            nodes.Pair(nodes.Const(key), value)\n+                            for key, value in variables.items()\n+                        ]\n+                    ),\n+                )\n+        return nodes.Output([node])\n\n\n class ExprStmtExtension(Extension):\n     \"\"\"Adds a `do` tag to Jinja that works like the print statement just\n     that it doesn't print the return value.\n     \"\"\"\n-    tags = {'do'}\n+\n+    tags = {\"do\"}\n+\n+    def parse(self, parser: \"Parser\") -&gt; nodes.ExprStmt:\n+        node = nodes.ExprStmt(lineno=next(parser.stream).lineno)\n+        node.node = parser.parse_tuple()\n+        return node\n\n\n class LoopControlExtension(Extension):\n     \"\"\"Adds break and continue to the template engine.\"\"\"\n-    tags = {'break', 'continue'}\n+\n+    tags = {\"break\", \"continue\"}\n+\n+    def parse(self, parser: \"Parser\") -&gt; t.Union[nodes.Break, nodes.Continue]:\n+        token = next(parser.stream)\n+        if token.value == \"break\":\n+            return nodes.Break(lineno=token.lineno)\n+        return nodes.Continue(lineno=token.lineno)\n\n\n class DebugExtension(Extension):\n@@ -174,12 +632,33 @@ class DebugExtension(Extension):\n\n     .. versionadded:: 2.11.0\n     \"\"\"\n-    tags = {'debug'}\n\n+    tags = {\"debug\"}\n\n-def extract_from_ast(ast: nodes.Template, gettext_functions: t.Sequence[str\n-    ]=GETTEXT_FUNCTIONS, babel_style: bool=True) -&gt;t.Iterator[t.Tuple[int,\n-    str, t.Union[t.Optional[str], t.Tuple[t.Optional[str], ...]]]]:\n+    def parse(self, parser: \"Parser\") -&gt; nodes.Output:\n+        lineno = parser.stream.expect(\"name:debug\").lineno\n+        context = nodes.ContextReference()\n+        result = self.call_method(\"_render\", [context], lineno=lineno)\n+        return nodes.Output([result], lineno=lineno)\n+\n+    def _render(self, context: Context) -&gt; str:\n+        result = {\n+            \"context\": context.get_all(),\n+            \"filters\": sorted(self.environment.filters.keys()),\n+            \"tests\": sorted(self.environment.tests.keys()),\n+        }\n+\n+        # Set the depth since the intent is to show the top few names.\n+        return pprint.pformat(result, depth=3, compact=True)\n+\n+\n+def extract_from_ast(\n+    ast: nodes.Template,\n+    gettext_functions: t.Sequence[str] = GETTEXT_FUNCTIONS,\n+    babel_style: bool = True,\n+) -&gt; t.Iterator[\n+    t.Tuple[int, str, t.Union[t.Optional[str], t.Tuple[t.Optional[str], ...]]]\n+]:\n     \"\"\"Extract localizable strings from the given template node.  Per\n     default this function returns matches in babel style that means non string\n     parameters as well as keyword arguments are returned as `None`.  This\n@@ -214,7 +693,42 @@ def extract_from_ast(ast: nodes.Template, gettext_functions: t.Sequence[str\n     to extract any comments.  For comment support you have to use the babel\n     extraction interface or extract comments yourself.\n     \"\"\"\n-    pass\n+    out: t.Union[t.Optional[str], t.Tuple[t.Optional[str], ...]]\n+\n+    for node in ast.find_all(nodes.Call):\n+        if (\n+            not isinstance(node.node, nodes.Name)\n+            or node.node.name not in gettext_functions\n+        ):\n+            continue\n+\n+        strings: t.List[t.Optional[str]] = []\n+\n+        for arg in node.args:\n+            if isinstance(arg, nodes.Const) and isinstance(arg.value, str):\n+                strings.append(arg.value)\n+            else:\n+                strings.append(None)\n+\n+        for _ in node.kwargs:\n+            strings.append(None)\n+        if node.dyn_args is not None:\n+            strings.append(None)\n+        if node.dyn_kwargs is not None:\n+            strings.append(None)\n+\n+        if not babel_style:\n+            out = tuple(x for x in strings if x is not None)\n+\n+            if not out:\n+                continue\n+        else:\n+            if len(strings) == 1:\n+                out = strings[0]\n+            else:\n+                out = tuple(strings)\n+\n+        yield node.lineno, node.node.name, out\n\n\n class _CommentFinder:\n@@ -224,18 +738,49 @@ class _CommentFinder:\n     usable value.\n     \"\"\"\n\n-    def __init__(self, tokens: t.Sequence[t.Tuple[int, str, str]],\n-        comment_tags: t.Sequence[str]) -&gt;None:\n+    def __init__(\n+        self, tokens: t.Sequence[t.Tuple[int, str, str]], comment_tags: t.Sequence[str]\n+    ) -&gt; None:\n         self.tokens = tokens\n         self.comment_tags = comment_tags\n         self.offset = 0\n         self.last_lineno = 0\n\n-\n-def babel_extract(fileobj: t.BinaryIO, keywords: t.Sequence[str],\n-    comment_tags: t.Sequence[str], options: t.Dict[str, t.Any]) -&gt;t.Iterator[t\n-    .Tuple[int, str, t.Union[t.Optional[str], t.Tuple[t.Optional[str], ...]\n-    ], t.List[str]]]:\n+    def find_backwards(self, offset: int) -&gt; t.List[str]:\n+        try:\n+            for _, token_type, token_value in reversed(\n+                self.tokens[self.offset : offset]\n+            ):\n+                if token_type in (\"comment\", \"linecomment\"):\n+                    try:\n+                        prefix, comment = token_value.split(None, 1)\n+                    except ValueError:\n+                        continue\n+                    if prefix in self.comment_tags:\n+                        return [comment.rstrip()]\n+            return []\n+        finally:\n+            self.offset = offset\n+\n+    def find_comments(self, lineno: int) -&gt; t.List[str]:\n+        if not self.comment_tags or self.last_lineno &gt; lineno:\n+            return []\n+        for idx, (token_lineno, _, _) in enumerate(self.tokens[self.offset :]):\n+            if token_lineno &gt; lineno:\n+                return self.find_backwards(self.offset + idx)\n+        return self.find_backwards(len(self.tokens))\n+\n+\n+def babel_extract(\n+    fileobj: t.BinaryIO,\n+    keywords: t.Sequence[str],\n+    comment_tags: t.Sequence[str],\n+    options: t.Dict[str, t.Any],\n+) -&gt; t.Iterator[\n+    t.Tuple[\n+        int, str, t.Union[t.Optional[str], t.Tuple[t.Optional[str], ...]], t.List[str]\n+    ]\n+]:\n     \"\"\"Babel extraction method for Jinja templates.\n\n     .. versionchanged:: 2.3\n@@ -263,9 +808,62 @@ def babel_extract(fileobj: t.BinaryIO, keywords: t.Sequence[str],\n     :return: an iterator over ``(lineno, funcname, message, comments)`` tuples.\n              (comments will be empty currently)\n     \"\"\"\n-    pass\n-\n-\n+    extensions: t.Dict[t.Type[Extension], None] = {}\n+\n+    for extension_name in options.get(\"extensions\", \"\").split(\",\"):\n+        extension_name = extension_name.strip()\n+\n+        if not extension_name:\n+            continue\n+\n+        extensions[import_string(extension_name)] = None\n+\n+    if InternationalizationExtension not in extensions:\n+        extensions[InternationalizationExtension] = None\n+\n+    def getbool(options: t.Mapping[str, str], key: str, default: bool = False) -&gt; bool:\n+        return options.get(key, str(default)).lower() in {\"1\", \"on\", \"yes\", \"true\"}\n+\n+    silent = getbool(options, \"silent\", True)\n+    environment = Environment(\n+        options.get(\"block_start_string\", defaults.BLOCK_START_STRING),\n+        options.get(\"block_end_string\", defaults.BLOCK_END_STRING),\n+        options.get(\"variable_start_string\", defaults.VARIABLE_START_STRING),\n+        options.get(\"variable_end_string\", defaults.VARIABLE_END_STRING),\n+        options.get(\"comment_start_string\", defaults.COMMENT_START_STRING),\n+        options.get(\"comment_end_string\", defaults.COMMENT_END_STRING),\n+        options.get(\"line_statement_prefix\") or defaults.LINE_STATEMENT_PREFIX,\n+        options.get(\"line_comment_prefix\") or defaults.LINE_COMMENT_PREFIX,\n+        getbool(options, \"trim_blocks\", defaults.TRIM_BLOCKS),\n+        getbool(options, \"lstrip_blocks\", defaults.LSTRIP_BLOCKS),\n+        defaults.NEWLINE_SEQUENCE,\n+        getbool(options, \"keep_trailing_newline\", defaults.KEEP_TRAILING_NEWLINE),\n+        tuple(extensions),\n+        cache_size=0,\n+        auto_reload=False,\n+    )\n+\n+    if getbool(options, \"trimmed\"):\n+        environment.policies[\"ext.i18n.trimmed\"] = True\n+    if getbool(options, \"newstyle_gettext\"):\n+        environment.newstyle_gettext = True  # type: ignore\n+\n+    source = fileobj.read().decode(options.get(\"encoding\", \"utf-8\"))\n+    try:\n+        node = environment.parse(source)\n+        tokens = list(environment.lex(environment.preprocess(source)))\n+    except TemplateSyntaxError:\n+        if not silent:\n+            raise\n+        # skip templates with syntax errors\n+        return\n+\n+    finder = _CommentFinder(tokens, comment_tags)\n+    for lineno, func, message in extract_from_ast(node, keywords):\n+        yield lineno, func, message, finder.find_comments(lineno)\n+\n+\n+#: nicer import names\n i18n = InternationalizationExtension\n do = ExprStmtExtension\n loopcontrols = LoopControlExtension\ndiff --git a/src/jinja2/filters.py b/src/jinja2/filters.py\nindex 9498dc3..acd1197 100644\n--- a/src/jinja2/filters.py\n+++ b/src/jinja2/filters.py\n@@ -1,4 +1,5 @@\n \"\"\"Built-in template filters used with the ``|`` operator.\"\"\"\n+\n import math\n import random\n import re\n@@ -7,9 +8,11 @@ import typing as t\n from collections import abc\n from itertools import chain\n from itertools import groupby\n+\n from markupsafe import escape\n from markupsafe import Markup\n from markupsafe import soft_str\n+\n from .async_utils import async_variant\n from .async_utils import auto_aiter\n from .async_utils import auto_await\n@@ -23,43 +26,67 @@ from .utils import pass_eval_context\n from .utils import pformat\n from .utils import url_quote\n from .utils import urlize\n+\n if t.TYPE_CHECKING:\n     import typing_extensions as te\n+\n     from .environment import Environment\n     from .nodes import EvalContext\n     from .runtime import Context\n-    from .sandbox import SandboxedEnvironment\n-\n+    from .sandbox import SandboxedEnvironment  # noqa: F401\n\n     class HasHTML(te.Protocol):\n-\n-        def __html__(self) -&gt;str:\n+        def __html__(self) -&gt; str:\n             pass\n-F = t.TypeVar('F', bound=t.Callable[..., t.Any])\n-K = t.TypeVar('K')\n-V = t.TypeVar('V')\n\n\n-def ignore_case(value: V) -&gt;V:\n+F = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n+K = t.TypeVar(\"K\")\n+V = t.TypeVar(\"V\")\n+\n+\n+def ignore_case(value: V) -&gt; V:\n     \"\"\"For use as a postprocessor for :func:`make_attrgetter`. Converts strings\n     to lowercase and returns other types as-is.\"\"\"\n-    pass\n+    if isinstance(value, str):\n+        return t.cast(V, value.lower())\n+\n+    return value\n\n\n-def make_attrgetter(environment: 'Environment', attribute: t.Optional[t.\n-    Union[str, int]], postprocess: t.Optional[t.Callable[[t.Any], t.Any]]=\n-    None, default: t.Optional[t.Any]=None) -&gt;t.Callable[[t.Any], t.Any]:\n+def make_attrgetter(\n+    environment: \"Environment\",\n+    attribute: t.Optional[t.Union[str, int]],\n+    postprocess: t.Optional[t.Callable[[t.Any], t.Any]] = None,\n+    default: t.Optional[t.Any] = None,\n+) -&gt; t.Callable[[t.Any], t.Any]:\n     \"\"\"Returns a callable that looks up the given attribute from a\n     passed object with the rules of the environment.  Dots are allowed\n     to access attributes of attributes.  Integer parts in paths are\n     looked up as integers.\n     \"\"\"\n-    pass\n+    parts = _prepare_attribute_parts(attribute)\n\n+    def attrgetter(item: t.Any) -&gt; t.Any:\n+        for part in parts:\n+            item = environment.getitem(item, part)\n\n-def make_multi_attrgetter(environment: 'Environment', attribute: t.Optional\n-    [t.Union[str, int]], postprocess: t.Optional[t.Callable[[t.Any], t.Any]\n-    ]=None) -&gt;t.Callable[[t.Any], t.List[t.Any]]:\n+            if default is not None and isinstance(item, Undefined):\n+                item = default\n+\n+        if postprocess is not None:\n+            item = postprocess(item)\n+\n+        return item\n+\n+    return attrgetter\n+\n+\n+def make_multi_attrgetter(\n+    environment: \"Environment\",\n+    attribute: t.Optional[t.Union[str, int]],\n+    postprocess: t.Optional[t.Callable[[t.Any], t.Any]] = None,\n+) -&gt; t.Callable[[t.Any], t.List[t.Any]]:\n     \"\"\"Returns a callable that looks up the given comma separated\n     attributes from a passed object with the rules of the environment.\n     Dots are allowed to access attributes of each attribute.  Integer\n@@ -70,16 +97,55 @@ def make_multi_attrgetter(environment: 'Environment', attribute: t.Optional\n\n     Examples of attribute: \"attr1,attr2\", \"attr1.inner1.0,attr2.inner2.0\", etc.\n     \"\"\"\n-    pass\n+    if isinstance(attribute, str):\n+        split: t.Sequence[t.Union[str, int, None]] = attribute.split(\",\")\n+    else:\n+        split = [attribute]\n+\n+    parts = [_prepare_attribute_parts(item) for item in split]\n+\n+    def attrgetter(item: t.Any) -&gt; t.List[t.Any]:\n+        items = [None] * len(parts)\n+\n+        for i, attribute_part in enumerate(parts):\n+            item_i = item\n+\n+            for part in attribute_part:\n+                item_i = environment.getitem(item_i, part)\n\n+            if postprocess is not None:\n+                item_i = postprocess(item_i)\n\n-def do_forceescape(value: 't.Union[str, HasHTML]') -&gt;Markup:\n+            items[i] = item_i\n+\n+        return items\n+\n+    return attrgetter\n+\n+\n+def _prepare_attribute_parts(\n+    attr: t.Optional[t.Union[str, int]],\n+) -&gt; t.List[t.Union[str, int]]:\n+    if attr is None:\n+        return []\n+\n+    if isinstance(attr, str):\n+        return [int(x) if x.isdigit() else x for x in attr.split(\".\")]\n+\n+    return [attr]\n+\n+\n+def do_forceescape(value: \"t.Union[str, HasHTML]\") -&gt; Markup:\n     \"\"\"Enforce HTML escaping.  This will probably double escape variables.\"\"\"\n-    pass\n+    if hasattr(value, \"__html__\"):\n+        value = t.cast(\"HasHTML\", value).__html__()\n+\n+    return escape(str(value))\n\n\n-def do_urlencode(value: t.Union[str, t.Mapping[str, t.Any], t.Iterable[t.\n-    Tuple[str, t.Any]]]) -&gt;str:\n+def do_urlencode(\n+    value: t.Union[str, t.Mapping[str, t.Any], t.Iterable[t.Tuple[str, t.Any]]],\n+) -&gt; str:\n     \"\"\"Quote data for use in a URL path or query using UTF-8.\n\n     Basic wrapper around :func:`urllib.parse.quote` when given a\n@@ -95,12 +161,23 @@ def do_urlencode(value: t.Union[str, t.Mapping[str, t.Any], t.Iterable[t.\n\n     .. versionadded:: 2.7\n     \"\"\"\n-    pass\n+    if isinstance(value, str) or not isinstance(value, abc.Iterable):\n+        return url_quote(value)\n+\n+    if isinstance(value, dict):\n+        items: t.Iterable[t.Tuple[str, t.Any]] = value.items()\n+    else:\n+        items = value  # type: ignore\n+\n+    return \"&amp;\".join(\n+        f\"{url_quote(k, for_qs=True)}={url_quote(v, for_qs=True)}\" for k, v in items\n+    )\n\n\n @pass_eval_context\n-def do_replace(eval_ctx: 'EvalContext', s: str, old: str, new: str, count:\n-    t.Optional[int]=None) -&gt;str:\n+def do_replace(\n+    eval_ctx: \"EvalContext\", s: str, old: str, new: str, count: t.Optional[int] = None\n+) -&gt; str:\n     \"\"\"Return a copy of the value with all occurrences of a substring\n     replaced with a new one. The first argument is the substring\n     that should be replaced, the second is the replacement string.\n@@ -115,21 +192,35 @@ def do_replace(eval_ctx: 'EvalContext', s: str, old: str, new: str, count:\n         {{ \"aaaaargh\"|replace(\"a\", \"d'oh, \", 2) }}\n             -&gt; d'oh, d'oh, aaargh\n     \"\"\"\n-    pass\n+    if count is None:\n+        count = -1\n+\n+    if not eval_ctx.autoescape:\n+        return str(s).replace(str(old), str(new), count)\n+\n+    if (\n+        hasattr(old, \"__html__\")\n+        or hasattr(new, \"__html__\")\n+        and not hasattr(s, \"__html__\")\n+    ):\n+        s = escape(s)\n+    else:\n+        s = soft_str(s)\n+\n+    return s.replace(soft_str(old), soft_str(new), count)\n\n\n-def do_upper(s: str) -&gt;str:\n+def do_upper(s: str) -&gt; str:\n     \"\"\"Convert a value to uppercase.\"\"\"\n-    pass\n+    return soft_str(s).upper()\n\n\n-def do_lower(s: str) -&gt;str:\n+def do_lower(s: str) -&gt; str:\n     \"\"\"Convert a value to lowercase.\"\"\"\n-    pass\n+    return soft_str(s).lower()\n\n\n-def do_items(value: t.Union[t.Mapping[K, V], Undefined]) -&gt;t.Iterator[t.\n-    Tuple[K, V]]:\n+def do_items(value: t.Union[t.Mapping[K, V], Undefined]) -&gt; t.Iterator[t.Tuple[K, V]]:\n     \"\"\"Return an iterator over the ``(key, value)`` items of a mapping.\n\n     ``x|items`` is the same as ``x.items()``, except if ``x`` is\n@@ -150,15 +241,24 @@ def do_items(value: t.Union[t.Mapping[K, V], Undefined]) -&gt;t.Iterator[t.\n\n     .. versionadded:: 3.1\n     \"\"\"\n-    pass\n+    if isinstance(value, Undefined):\n+        return\n\n+    if not isinstance(value, abc.Mapping):\n+        raise TypeError(\"Can only get item pairs from a mapping.\")\n\n-_attr_key_re = re.compile('[\\\\s/&gt;=]', flags=re.ASCII)\n+    yield from value.items()\n+\n+\n+# Check for characters that would move the parser state from key to value.\n+# https://html.spec.whatwg.org/#attribute-name-state\n+_attr_key_re = re.compile(r\"[\\s/&gt;=]\", flags=re.ASCII)\n\n\n @pass_eval_context\n-def do_xmlattr(eval_ctx: 'EvalContext', d: t.Mapping[str, t.Any], autospace:\n-    bool=True) -&gt;str:\n+def do_xmlattr(\n+    eval_ctx: \"EvalContext\", d: t.Mapping[str, t.Any], autospace: bool = True\n+) -&gt; str:\n     \"\"\"Create an SGML/XML attribute string based on the items in a dict.\n\n     **Values** that are neither ``none`` nor ``undefined`` are automatically\n@@ -195,29 +295,57 @@ def do_xmlattr(eval_ctx: 'EvalContext', d: t.Mapping[str, t.Any], autospace:\n     .. versionchanged:: 3.1.3\n         Keys with spaces are not allowed.\n     \"\"\"\n-    pass\n+    items = []\n+\n+    for key, value in d.items():\n+        if value is None or isinstance(value, Undefined):\n+            continue\n+\n+        if _attr_key_re.search(key) is not None:\n+            raise ValueError(f\"Invalid character in attribute name: {key!r}\")\n\n+        items.append(f'{escape(key)}=\"{escape(value)}\"')\n\n-def do_capitalize(s: str) -&gt;str:\n+    rv = \" \".join(items)\n+\n+    if autospace and rv:\n+        rv = \" \" + rv\n+\n+    if eval_ctx.autoescape:\n+        rv = Markup(rv)\n+\n+    return rv\n+\n+\n+def do_capitalize(s: str) -&gt; str:\n     \"\"\"Capitalize a value. The first character will be uppercase, all others\n     lowercase.\n     \"\"\"\n-    pass\n+    return soft_str(s).capitalize()\n\n\n-_word_beginning_split_re = re.compile('([-\\\\s({\\\\[&lt;]+)')\n+_word_beginning_split_re = re.compile(r\"([-\\s({\\[&lt;]+)\")\n\n\n-def do_title(s: str) -&gt;str:\n+def do_title(s: str) -&gt; str:\n     \"\"\"Return a titlecased version of the value. I.e. words will start with\n     uppercase letters, all remaining characters are lowercase.\n     \"\"\"\n-    pass\n-\n-\n-def do_dictsort(value: t.Mapping[K, V], case_sensitive: bool=False, by:\n-    'te.Literal[\"key\", \"value\"]'='key', reverse: bool=False) -&gt;t.List[t.\n-    Tuple[K, V]]:\n+    return \"\".join(\n+        [\n+            item[0].upper() + item[1:].lower()\n+            for item in _word_beginning_split_re.split(soft_str(s))\n+            if item\n+        ]\n+    )\n+\n+\n+def do_dictsort(\n+    value: t.Mapping[K, V],\n+    case_sensitive: bool = False,\n+    by: 'te.Literal[\"key\", \"value\"]' = \"key\",\n+    reverse: bool = False,\n+) -&gt; t.List[t.Tuple[K, V]]:\n     \"\"\"Sort a dict and yield (key, value) pairs. Python dicts may not\n     be in the order you want to display them in, so sort them first.\n\n@@ -235,13 +363,32 @@ def do_dictsort(value: t.Mapping[K, V], case_sensitive: bool=False, by:\n         {% for key, value in mydict|dictsort(false, 'value') %}\n             sort the dict by value, case insensitive\n     \"\"\"\n-    pass\n+    if by == \"key\":\n+        pos = 0\n+    elif by == \"value\":\n+        pos = 1\n+    else:\n+        raise FilterArgumentError('You can only sort by either \"key\" or \"value\"')\n+\n+    def sort_func(item: t.Tuple[t.Any, t.Any]) -&gt; t.Any:\n+        value = item[pos]\n+\n+        if not case_sensitive:\n+            value = ignore_case(value)\n+\n+        return value\n+\n+    return sorted(value.items(), key=sort_func, reverse=reverse)\n\n\n @pass_environment\n-def do_sort(environment: 'Environment', value: 't.Iterable[V]', reverse:\n-    bool=False, case_sensitive: bool=False, attribute: t.Optional[t.Union[\n-    str, int]]=None) -&gt;'t.List[V]':\n+def do_sort(\n+    environment: \"Environment\",\n+    value: \"t.Iterable[V]\",\n+    reverse: bool = False,\n+    case_sensitive: bool = False,\n+    attribute: t.Optional[t.Union[str, int]] = None,\n+) -&gt; \"t.List[V]\":\n     \"\"\"Sort an iterable using Python's :func:`sorted`.\n\n     .. sourcecode:: jinja\n@@ -284,13 +431,19 @@ def do_sort(environment: 'Environment', value: 't.Iterable[V]', reverse:\n     .. versionchanged:: 2.6\n        The ``attribute`` parameter was added.\n     \"\"\"\n-    pass\n+    key_func = make_multi_attrgetter(\n+        environment, attribute, postprocess=ignore_case if not case_sensitive else None\n+    )\n+    return sorted(value, key=key_func, reverse=reverse)\n\n\n @pass_environment\n-def do_unique(environment: 'Environment', value: 't.Iterable[V]',\n-    case_sensitive: bool=False, attribute: t.Optional[t.Union[str, int]]=None\n-    ) -&gt;'t.Iterator[V]':\n+def do_unique(\n+    environment: \"Environment\",\n+    value: \"t.Iterable[V]\",\n+    case_sensitive: bool = False,\n+    attribute: t.Optional[t.Union[str, int]] = None,\n+) -&gt; \"t.Iterator[V]\":\n     \"\"\"Returns a list of unique items from the given iterable.\n\n     .. sourcecode:: jinja\n@@ -304,13 +457,46 @@ def do_unique(environment: 'Environment', value: 't.Iterable[V]',\n     :param case_sensitive: Treat upper and lower case strings as distinct.\n     :param attribute: Filter objects with unique values for this attribute.\n     \"\"\"\n-    pass\n+    getter = make_attrgetter(\n+        environment, attribute, postprocess=ignore_case if not case_sensitive else None\n+    )\n+    seen = set()\n+\n+    for item in value:\n+        key = getter(item)\n+\n+        if key not in seen:\n+            seen.add(key)\n+            yield item\n+\n+\n+def _min_or_max(\n+    environment: \"Environment\",\n+    value: \"t.Iterable[V]\",\n+    func: \"t.Callable[..., V]\",\n+    case_sensitive: bool,\n+    attribute: t.Optional[t.Union[str, int]],\n+) -&gt; \"t.Union[V, Undefined]\":\n+    it = iter(value)\n+\n+    try:\n+        first = next(it)\n+    except StopIteration:\n+        return environment.undefined(\"No aggregated item, sequence was empty.\")\n+\n+    key_func = make_attrgetter(\n+        environment, attribute, postprocess=ignore_case if not case_sensitive else None\n+    )\n+    return func(chain([first], it), key=key_func)\n\n\n @pass_environment\n-def do_min(environment: 'Environment', value: 't.Iterable[V]',\n-    case_sensitive: bool=False, attribute: t.Optional[t.Union[str, int]]=None\n-    ) -&gt;'t.Union[V, Undefined]':\n+def do_min(\n+    environment: \"Environment\",\n+    value: \"t.Iterable[V]\",\n+    case_sensitive: bool = False,\n+    attribute: t.Optional[t.Union[str, int]] = None,\n+) -&gt; \"t.Union[V, Undefined]\":\n     \"\"\"Return the smallest item from the sequence.\n\n     .. sourcecode:: jinja\n@@ -321,13 +507,16 @@ def do_min(environment: 'Environment', value: 't.Iterable[V]',\n     :param case_sensitive: Treat upper and lower case strings as distinct.\n     :param attribute: Get the object with the min value of this attribute.\n     \"\"\"\n-    pass\n+    return _min_or_max(environment, value, min, case_sensitive, attribute)\n\n\n @pass_environment\n-def do_max(environment: 'Environment', value: 't.Iterable[V]',\n-    case_sensitive: bool=False, attribute: t.Optional[t.Union[str, int]]=None\n-    ) -&gt;'t.Union[V, Undefined]':\n+def do_max(\n+    environment: \"Environment\",\n+    value: \"t.Iterable[V]\",\n+    case_sensitive: bool = False,\n+    attribute: t.Optional[t.Union[str, int]] = None,\n+) -&gt; \"t.Union[V, Undefined]\":\n     \"\"\"Return the largest item from the sequence.\n\n     .. sourcecode:: jinja\n@@ -338,10 +527,14 @@ def do_max(environment: 'Environment', value: 't.Iterable[V]',\n     :param case_sensitive: Treat upper and lower case strings as distinct.\n     :param attribute: Get the object with the max value of this attribute.\n     \"\"\"\n-    pass\n+    return _min_or_max(environment, value, max, case_sensitive, attribute)\n\n\n-def do_default(value: V, default_value: V='', boolean: bool=False) -&gt;V:\n+def do_default(\n+    value: V,\n+    default_value: V = \"\",  # type: ignore\n+    boolean: bool = False,\n+) -&gt; V:\n     \"\"\"If the value is undefined it will return the passed default value,\n     otherwise the value of the variable:\n\n@@ -364,12 +557,19 @@ def do_default(value: V, default_value: V='', boolean: bool=False) -&gt;V:\n        on nested elements and attributes that may contain undefined values\n        in the chain without getting an :exc:`~jinja2.UndefinedError`.\n     \"\"\"\n-    pass\n+    if isinstance(value, Undefined) or (boolean and not value):\n+        return default_value\n+\n+    return value\n\n\n @pass_eval_context\n-def sync_do_join(eval_ctx: 'EvalContext', value: t.Iterable[t.Any], d: str=\n-    '', attribute: t.Optional[t.Union[str, int]]=None) -&gt;str:\n+def sync_do_join(\n+    eval_ctx: \"EvalContext\",\n+    value: t.Iterable[t.Any],\n+    d: str = \"\",\n+    attribute: t.Optional[t.Union[str, int]] = None,\n+) -&gt; str:\n     \"\"\"Return a string which is the concatenation of the strings in the\n     sequence. The separator between elements is an empty string per\n     default, you can define it with the optional parameter:\n@@ -391,24 +591,76 @@ def sync_do_join(eval_ctx: 'EvalContext', value: t.Iterable[t.Any], d: str=\n     .. versionadded:: 2.6\n        The `attribute` parameter was added.\n     \"\"\"\n-    pass\n+    if attribute is not None:\n+        value = map(make_attrgetter(eval_ctx.environment, attribute), value)\n\n+    # no automatic escaping?  joining is a lot easier then\n+    if not eval_ctx.autoescape:\n+        return str(d).join(map(str, value))\n\n-def do_center(value: str, width: int=80) -&gt;str:\n+    # if the delimiter doesn't have an html representation we check\n+    # if any of the items has.  If yes we do a coercion to Markup\n+    if not hasattr(d, \"__html__\"):\n+        value = list(value)\n+        do_escape = False\n+\n+        for idx, item in enumerate(value):\n+            if hasattr(item, \"__html__\"):\n+                do_escape = True\n+            else:\n+                value[idx] = str(item)\n+\n+        if do_escape:\n+            d = escape(d)\n+        else:\n+            d = str(d)\n+\n+        return d.join(value)\n+\n+    # no html involved, to normal joining\n+    return soft_str(d).join(map(soft_str, value))\n+\n+\n+@async_variant(sync_do_join)  # type: ignore\n+async def do_join(\n+    eval_ctx: \"EvalContext\",\n+    value: t.Union[t.AsyncIterable[t.Any], t.Iterable[t.Any]],\n+    d: str = \"\",\n+    attribute: t.Optional[t.Union[str, int]] = None,\n+) -&gt; str:\n+    return sync_do_join(eval_ctx, await auto_to_list(value), d, attribute)\n+\n+\n+def do_center(value: str, width: int = 80) -&gt; str:\n     \"\"\"Centers the value in a field of a given width.\"\"\"\n-    pass\n+    return soft_str(value).center(width)\n\n\n @pass_environment\n-def sync_do_first(environment: 'Environment', seq: 't.Iterable[V]'\n-    ) -&gt;'t.Union[V, Undefined]':\n+def sync_do_first(\n+    environment: \"Environment\", seq: \"t.Iterable[V]\"\n+) -&gt; \"t.Union[V, Undefined]\":\n     \"\"\"Return the first item of a sequence.\"\"\"\n-    pass\n+    try:\n+        return next(iter(seq))\n+    except StopIteration:\n+        return environment.undefined(\"No first item, sequence was empty.\")\n+\n+\n+@async_variant(sync_do_first)  # type: ignore\n+async def do_first(\n+    environment: \"Environment\", seq: \"t.Union[t.AsyncIterable[V], t.Iterable[V]]\"\n+) -&gt; \"t.Union[V, Undefined]\":\n+    try:\n+        return await auto_aiter(seq).__anext__()\n+    except StopAsyncIteration:\n+        return environment.undefined(\"No first item, sequence was empty.\")\n\n\n @pass_environment\n-def do_last(environment: 'Environment', seq: 't.Reversible[V]'\n-    ) -&gt;'t.Union[V, Undefined]':\n+def do_last(\n+    environment: \"Environment\", seq: \"t.Reversible[V]\"\n+) -&gt; \"t.Union[V, Undefined]\":\n     \"\"\"Return the last item of a sequence.\n\n     Note: Does not work with generators. You may want to explicitly\n@@ -418,39 +670,75 @@ def do_last(environment: 'Environment', seq: 't.Reversible[V]'\n\n         {{ data | selectattr('name', '==', 'Jinja') | list | last }}\n     \"\"\"\n-    pass\n+    try:\n+        return next(iter(reversed(seq)))\n+    except StopIteration:\n+        return environment.undefined(\"No last item, sequence was empty.\")\n+\n+\n+# No async do_last, it may not be safe in async mode.\n\n\n @pass_context\n-def do_random(context: 'Context', seq: 't.Sequence[V]'\n-    ) -&gt;'t.Union[V, Undefined]':\n+def do_random(context: \"Context\", seq: \"t.Sequence[V]\") -&gt; \"t.Union[V, Undefined]\":\n     \"\"\"Return a random item from the sequence.\"\"\"\n-    pass\n+    try:\n+        return random.choice(seq)\n+    except IndexError:\n+        return context.environment.undefined(\"No random item, sequence was empty.\")\n\n\n-def do_filesizeformat(value: t.Union[str, float, int], binary: bool=False\n-    ) -&gt;str:\n+def do_filesizeformat(value: t.Union[str, float, int], binary: bool = False) -&gt; str:\n     \"\"\"Format the value like a 'human-readable' file size (i.e. 13 kB,\n     4.1 MB, 102 Bytes, etc).  Per default decimal prefixes are used (Mega,\n     Giga, etc.), if the second parameter is set to `True` the binary\n     prefixes are used (Mebi, Gibi).\n     \"\"\"\n-    pass\n-\n-\n-def do_pprint(value: t.Any) -&gt;str:\n+    bytes = float(value)\n+    base = 1024 if binary else 1000\n+    prefixes = [\n+        (\"KiB\" if binary else \"kB\"),\n+        (\"MiB\" if binary else \"MB\"),\n+        (\"GiB\" if binary else \"GB\"),\n+        (\"TiB\" if binary else \"TB\"),\n+        (\"PiB\" if binary else \"PB\"),\n+        (\"EiB\" if binary else \"EB\"),\n+        (\"ZiB\" if binary else \"ZB\"),\n+        (\"YiB\" if binary else \"YB\"),\n+    ]\n+\n+    if bytes == 1:\n+        return \"1 Byte\"\n+    elif bytes &lt; base:\n+        return f\"{int(bytes)} Bytes\"\n+    else:\n+        for i, prefix in enumerate(prefixes):\n+            unit = base ** (i + 2)\n+\n+            if bytes &lt; unit:\n+                return f\"{base * bytes / unit:.1f} {prefix}\"\n+\n+        return f\"{base * bytes / unit:.1f} {prefix}\"\n+\n+\n+def do_pprint(value: t.Any) -&gt; str:\n     \"\"\"Pretty print a variable. Useful for debugging.\"\"\"\n-    pass\n+    return pformat(value)\n\n\n-_uri_scheme_re = re.compile('^([\\\\w.+-]{2,}:(/){0,2})$')\n+_uri_scheme_re = re.compile(r\"^([\\w.+-]{2,}:(/){0,2})$\")\n\n\n @pass_eval_context\n-def do_urlize(eval_ctx: 'EvalContext', value: str, trim_url_limit: t.\n-    Optional[int]=None, nofollow: bool=False, target: t.Optional[str]=None,\n-    rel: t.Optional[str]=None, extra_schemes: t.Optional[t.Iterable[str]]=None\n-    ) -&gt;str:\n+def do_urlize(\n+    eval_ctx: \"EvalContext\",\n+    value: str,\n+    trim_url_limit: t.Optional[int] = None,\n+    nofollow: bool = False,\n+    target: t.Optional[str] = None,\n+    rel: t.Optional[str] = None,\n+    extra_schemes: t.Optional[t.Iterable[str]] = None,\n+) -&gt; str:\n     \"\"\"Convert URLs in text into clickable links.\n\n     This may not recognize links in some situations. Usually, a more\n@@ -488,11 +776,42 @@ def do_urlize(eval_ctx: 'EvalContext', value: str, trim_url_limit: t.\n     .. versionchanged:: 2.8\n        The ``target`` parameter was added.\n     \"\"\"\n-    pass\n+    policies = eval_ctx.environment.policies\n+    rel_parts = set((rel or \"\").split())\n+\n+    if nofollow:\n+        rel_parts.add(\"nofollow\")\n+\n+    rel_parts.update((policies[\"urlize.rel\"] or \"\").split())\n+    rel = \" \".join(sorted(rel_parts)) or None\n+\n+    if target is None:\n+        target = policies[\"urlize.target\"]\n+\n+    if extra_schemes is None:\n+        extra_schemes = policies[\"urlize.extra_schemes\"] or ()\n\n+    for scheme in extra_schemes:\n+        if _uri_scheme_re.fullmatch(scheme) is None:\n+            raise FilterArgumentError(f\"{scheme!r} is not a valid URI scheme prefix.\")\n\n-def do_indent(s: str, width: t.Union[int, str]=4, first: bool=False, blank:\n-    bool=False) -&gt;str:\n+    rv = urlize(\n+        value,\n+        trim_url_limit=trim_url_limit,\n+        rel=rel,\n+        target=target,\n+        extra_schemes=extra_schemes,\n+    )\n+\n+    if eval_ctx.autoescape:\n+        rv = Markup(rv)\n+\n+    return rv\n+\n+\n+def do_indent(\n+    s: str, width: t.Union[int, str] = 4, first: bool = False, blank: bool = False\n+) -&gt; str:\n     \"\"\"Return a copy of the string with each line indented by 4 spaces. The\n     first line and blank lines are not indented by default.\n\n@@ -508,12 +827,45 @@ def do_indent(s: str, width: t.Union[int, str]=4, first: bool=False, blank:\n\n         Rename the ``indentfirst`` argument to ``first``.\n     \"\"\"\n-    pass\n+    if isinstance(width, str):\n+        indention = width\n+    else:\n+        indention = \" \" * width\n+\n+    newline = \"\\n\"\n+\n+    if isinstance(s, Markup):\n+        indention = Markup(indention)\n+        newline = Markup(newline)\n+\n+    s += newline  # this quirk is necessary for splitlines method\n+\n+    if blank:\n+        rv = (newline + indention).join(s.splitlines())\n+    else:\n+        lines = s.splitlines()\n+        rv = lines.pop(0)\n+\n+        if lines:\n+            rv += newline + newline.join(\n+                indention + line if line else line for line in lines\n+            )\n+\n+    if first:\n+        rv = indention + rv\n+\n+    return rv\n\n\n @pass_environment\n-def do_truncate(env: 'Environment', s: str, length: int=255, killwords:\n-    bool=False, end: str='...', leeway: t.Optional[int]=None) -&gt;str:\n+def do_truncate(\n+    env: \"Environment\",\n+    s: str,\n+    length: int = 255,\n+    killwords: bool = False,\n+    end: str = \"...\",\n+    leeway: t.Optional[int] = None,\n+) -&gt; str:\n     \"\"\"Return a truncated copy of the string. The length is specified\n     with the first parameter which defaults to ``255``. If the second\n     parameter is ``true`` the filter will cut the text at length. Otherwise\n@@ -537,13 +889,31 @@ def do_truncate(env: 'Environment', s: str, length: int=255, killwords:\n     The default leeway on newer Jinja versions is 5 and was 0 before but\n     can be reconfigured globally.\n     \"\"\"\n-    pass\n+    if leeway is None:\n+        leeway = env.policies[\"truncate.leeway\"]\n+\n+    assert length &gt;= len(end), f\"expected length &gt;= {len(end)}, got {length}\"\n+    assert leeway &gt;= 0, f\"expected leeway &gt;= 0, got {leeway}\"\n+\n+    if len(s) &lt;= length + leeway:\n+        return s\n+\n+    if killwords:\n+        return s[: length - len(end)] + end\n+\n+    result = s[: length - len(end)].rsplit(\" \", 1)[0]\n+    return result + end\n\n\n @pass_environment\n-def do_wordwrap(environment: 'Environment', s: str, width: int=79,\n-    break_long_words: bool=True, wrapstring: t.Optional[str]=None,\n-    break_on_hyphens: bool=True) -&gt;str:\n+def do_wordwrap(\n+    environment: \"Environment\",\n+    s: str,\n+    width: int = 79,\n+    break_long_words: bool = True,\n+    wrapstring: t.Optional[str] = None,\n+    break_on_hyphens: bool = True,\n+) -&gt; str:\n     \"\"\"Wrap a string to the given width. Existing newlines are treated\n     as paragraphs to be wrapped separately.\n\n@@ -565,18 +935,41 @@ def do_wordwrap(environment: 'Environment', s: str, width: int=79,\n     .. versionchanged:: 2.7\n         Added the ``wrapstring`` parameter.\n     \"\"\"\n-    pass\n-\n-\n-_word_re = re.compile('\\\\w+')\n-\n-\n-def do_wordcount(s: str) -&gt;int:\n+    import textwrap\n+\n+    if wrapstring is None:\n+        wrapstring = environment.newline_sequence\n+\n+    # textwrap.wrap doesn't consider existing newlines when wrapping.\n+    # If the string has a newline before width, wrap will still insert\n+    # a newline at width, resulting in a short line. Instead, split and\n+    # wrap each paragraph individually.\n+    return wrapstring.join(\n+        [\n+            wrapstring.join(\n+                textwrap.wrap(\n+                    line,\n+                    width=width,\n+                    expand_tabs=False,\n+                    replace_whitespace=False,\n+                    break_long_words=break_long_words,\n+                    break_on_hyphens=break_on_hyphens,\n+                )\n+            )\n+            for line in s.splitlines()\n+        ]\n+    )\n+\n+\n+_word_re = re.compile(r\"\\w+\")\n+\n+\n+def do_wordcount(s: str) -&gt; int:\n     \"\"\"Count the words in that string.\"\"\"\n-    pass\n+    return len(_word_re.findall(soft_str(s)))\n\n\n-def do_int(value: t.Any, default: int=0, base: int=10) -&gt;int:\n+def do_int(value: t.Any, default: int = 0, base: int = 10) -&gt; int:\n     \"\"\"Convert the value into an integer. If the\n     conversion doesn't work it will return ``0``. You can\n     override this default using the first parameter. You\n@@ -585,18 +978,31 @@ def do_int(value: t.Any, default: int=0, base: int=10) -&gt;int:\n     0b, 0o and 0x for bases 2, 8 and 16 respectively.\n     The base is ignored for decimal numbers and non-string values.\n     \"\"\"\n-    pass\n+    try:\n+        if isinstance(value, str):\n+            return int(value, base)\n\n+        return int(value)\n+    except (TypeError, ValueError):\n+        # this quirk is necessary so that \"42.23\"|int gives 42.\n+        try:\n+            return int(float(value))\n+        except (TypeError, ValueError):\n+            return default\n\n-def do_float(value: t.Any, default: float=0.0) -&gt;float:\n+\n+def do_float(value: t.Any, default: float = 0.0) -&gt; float:\n     \"\"\"Convert the value into a floating point number. If the\n     conversion doesn't work it will return ``0.0``. You can\n     override this default using the first parameter.\n     \"\"\"\n-    pass\n+    try:\n+        return float(value)\n+    except (TypeError, ValueError):\n+        return default\n\n\n-def do_format(value: str, *args: t.Any, **kwargs: t.Any) -&gt;str:\n+def do_format(value: str, *args: t.Any, **kwargs: t.Any) -&gt; str:\n     \"\"\"Apply the given values to a `printf-style`_ format string, like\n     ``string % values``.\n\n@@ -616,21 +1022,30 @@ def do_format(value: str, *args: t.Any, **kwargs: t.Any) -&gt;str:\n     .. _printf-style: https://docs.python.org/library/stdtypes.html\n         #printf-style-string-formatting\n     \"\"\"\n-    pass\n+    if args and kwargs:\n+        raise FilterArgumentError(\n+            \"can't handle positional and keyword arguments at the same time\"\n+        )\n+\n+    return soft_str(value) % (kwargs or args)\n\n\n-def do_trim(value: str, chars: t.Optional[str]=None) -&gt;str:\n+def do_trim(value: str, chars: t.Optional[str] = None) -&gt; str:\n     \"\"\"Strip leading and trailing characters, by default whitespace.\"\"\"\n-    pass\n+    return soft_str(value).strip(chars)\n\n\n-def do_striptags(value: 't.Union[str, HasHTML]') -&gt;str:\n+def do_striptags(value: \"t.Union[str, HasHTML]\") -&gt; str:\n     \"\"\"Strip SGML/XML tags and replace adjacent whitespace by one space.\"\"\"\n-    pass\n+    if hasattr(value, \"__html__\"):\n+        value = t.cast(\"HasHTML\", value).__html__()\n+\n+    return Markup(str(value)).striptags()\n\n\n-def sync_do_slice(value: 't.Collection[V]', slices: int, fill_with:\n-    't.Optional[V]'=None) -&gt;'t.Iterator[t.List[V]]':\n+def sync_do_slice(\n+    value: \"t.Collection[V]\", slices: int, fill_with: \"t.Optional[V]\" = None\n+) -&gt; \"t.Iterator[t.List[V]]\":\n     \"\"\"Slice an iterator and return a list of lists containing\n     those items. Useful if you want to create a div containing\n     three ul tags that represent columns:\n@@ -650,11 +1065,39 @@ def sync_do_slice(value: 't.Collection[V]', slices: int, fill_with:\n     If you pass it a second argument it's used to fill missing\n     values on the last iteration.\n     \"\"\"\n-    pass\n+    seq = list(value)\n+    length = len(seq)\n+    items_per_slice = length // slices\n+    slices_with_extra = length % slices\n+    offset = 0\n+\n+    for slice_number in range(slices):\n+        start = offset + slice_number * items_per_slice\n+\n+        if slice_number &lt; slices_with_extra:\n+            offset += 1\n+\n+        end = offset + (slice_number + 1) * items_per_slice\n+        tmp = seq[start:end]\n+\n+        if fill_with is not None and slice_number &gt;= slices_with_extra:\n+            tmp.append(fill_with)\n+\n+        yield tmp\n+\n\n+@async_variant(sync_do_slice)  # type: ignore\n+async def do_slice(\n+    value: \"t.Union[t.AsyncIterable[V], t.Iterable[V]]\",\n+    slices: int,\n+    fill_with: t.Optional[t.Any] = None,\n+) -&gt; \"t.Iterator[t.List[V]]\":\n+    return sync_do_slice(await auto_to_list(value), slices, fill_with)\n\n-def do_batch(value: 't.Iterable[V]', linecount: int, fill_with:\n-    't.Optional[V]'=None) -&gt;'t.Iterator[t.List[V]]':\n+\n+def do_batch(\n+    value: \"t.Iterable[V]\", linecount: int, fill_with: \"t.Optional[V]\" = None\n+) -&gt; \"t.Iterator[t.List[V]]\":\n     \"\"\"\n     A filter that batches items. It works pretty much like `slice`\n     just the other way round. It returns a list of lists with the\n@@ -673,11 +1116,27 @@ def do_batch(value: 't.Iterable[V]', linecount: int, fill_with:\n         {%- endfor %}\n         &lt;/table&gt;\n     \"\"\"\n-    pass\n+    tmp: \"t.List[V]\" = []\n+\n+    for item in value:\n+        if len(tmp) == linecount:\n+            yield tmp\n+            tmp = []\n+\n+        tmp.append(item)\n+\n+    if tmp:\n+        if fill_with is not None and len(tmp) &lt; linecount:\n+            tmp += [fill_with] * (linecount - len(tmp))\n+\n+        yield tmp\n\n\n-def do_round(value: float, precision: int=0, method:\n-    'te.Literal[\"common\", \"ceil\", \"floor\"]'='common') -&gt;float:\n+def do_round(\n+    value: float,\n+    precision: int = 0,\n+    method: 'te.Literal[\"common\", \"ceil\", \"floor\"]' = \"common\",\n+) -&gt; float:\n     \"\"\"Round the number to a given precision. The first\n     parameter specifies the precision (default is ``0``), the\n     second the rounding method:\n@@ -703,24 +1162,37 @@ def do_round(value: float, precision: int=0, method:\n         {{ 42.55|round|int }}\n             -&gt; 43\n     \"\"\"\n-    pass\n+    if method not in {\"common\", \"ceil\", \"floor\"}:\n+        raise FilterArgumentError(\"method must be common, ceil or floor\")\n+\n+    if method == \"common\":\n+        return round(value, precision)\n+\n+    func = getattr(math, method)\n+    return t.cast(float, func(value * (10**precision)) / (10**precision))\n\n\n class _GroupTuple(t.NamedTuple):\n     grouper: t.Any\n     list: t.List[t.Any]\n\n-    def __repr__(self) -&gt;str:\n+    # Use the regular tuple repr to hide this subclass if users print\n+    # out the value during debugging.\n+    def __repr__(self) -&gt; str:\n         return tuple.__repr__(self)\n\n-    def __str__(self) -&gt;str:\n+    def __str__(self) -&gt; str:\n         return tuple.__str__(self)\n\n\n @pass_environment\n-def sync_do_groupby(environment: 'Environment', value: 't.Iterable[V]',\n-    attribute: t.Union[str, int], default: t.Optional[t.Any]=None,\n-    case_sensitive: bool=False) -&gt;'t.List[_GroupTuple]':\n+def sync_do_groupby(\n+    environment: \"Environment\",\n+    value: \"t.Iterable[V]\",\n+    attribute: t.Union[str, int],\n+    default: t.Optional[t.Any] = None,\n+    case_sensitive: bool = False,\n+) -&gt; \"t.List[_GroupTuple]\":\n     \"\"\"Group a sequence of objects by an attribute using Python's\n     :func:`itertools.groupby`. The attribute can use dot notation for\n     nested access, like ``\"address.city\"``. Unlike Python's ``groupby``,\n@@ -778,12 +1250,59 @@ def sync_do_groupby(environment: 'Environment', value: 't.Iterable[V]',\n     .. versionchanged:: 2.6\n         The attribute supports dot notation for nested access.\n     \"\"\"\n-    pass\n+    expr = make_attrgetter(\n+        environment,\n+        attribute,\n+        postprocess=ignore_case if not case_sensitive else None,\n+        default=default,\n+    )\n+    out = [\n+        _GroupTuple(key, list(values))\n+        for key, values in groupby(sorted(value, key=expr), expr)\n+    ]\n+\n+    if not case_sensitive:\n+        # Return the real key from the first value instead of the lowercase key.\n+        output_expr = make_attrgetter(environment, attribute, default=default)\n+        out = [_GroupTuple(output_expr(values[0]), values) for _, values in out]\n+\n+    return out\n+\n+\n+@async_variant(sync_do_groupby)  # type: ignore\n+async def do_groupby(\n+    environment: \"Environment\",\n+    value: \"t.Union[t.AsyncIterable[V], t.Iterable[V]]\",\n+    attribute: t.Union[str, int],\n+    default: t.Optional[t.Any] = None,\n+    case_sensitive: bool = False,\n+) -&gt; \"t.List[_GroupTuple]\":\n+    expr = make_attrgetter(\n+        environment,\n+        attribute,\n+        postprocess=ignore_case if not case_sensitive else None,\n+        default=default,\n+    )\n+    out = [\n+        _GroupTuple(key, await auto_to_list(values))\n+        for key, values in groupby(sorted(await auto_to_list(value), key=expr), expr)\n+    ]\n+\n+    if not case_sensitive:\n+        # Return the real key from the first value instead of the lowercase key.\n+        output_expr = make_attrgetter(environment, attribute, default=default)\n+        out = [_GroupTuple(output_expr(values[0]), values) for _, values in out]\n+\n+    return out\n\n\n @pass_environment\n-def sync_do_sum(environment: 'Environment', iterable: 't.Iterable[V]',\n-    attribute: t.Optional[t.Union[str, int]]=None, start: V=0) -&gt;V:\n+def sync_do_sum(\n+    environment: \"Environment\",\n+    iterable: \"t.Iterable[V]\",\n+    attribute: t.Optional[t.Union[str, int]] = None,\n+    start: V = 0,  # type: ignore\n+) -&gt; V:\n     \"\"\"Returns the sum of a sequence of numbers plus the value of parameter\n     'start' (which defaults to 0).  When the sequence is empty it returns\n     start.\n@@ -798,51 +1317,139 @@ def sync_do_sum(environment: 'Environment', iterable: 't.Iterable[V]',\n        The ``attribute`` parameter was added to allow summing up over\n        attributes.  Also the ``start`` parameter was moved on to the right.\n     \"\"\"\n-    pass\n+    if attribute is not None:\n+        iterable = map(make_attrgetter(environment, attribute), iterable)\n+\n+    return sum(iterable, start)  # type: ignore[no-any-return, call-overload]\n+\n\n+@async_variant(sync_do_sum)  # type: ignore\n+async def do_sum(\n+    environment: \"Environment\",\n+    iterable: \"t.Union[t.AsyncIterable[V], t.Iterable[V]]\",\n+    attribute: t.Optional[t.Union[str, int]] = None,\n+    start: V = 0,  # type: ignore\n+) -&gt; V:\n+    rv = start\n\n-def sync_do_list(value: 't.Iterable[V]') -&gt;'t.List[V]':\n+    if attribute is not None:\n+        func = make_attrgetter(environment, attribute)\n+    else:\n+\n+        def func(x: V) -&gt; V:\n+            return x\n+\n+    async for item in auto_aiter(iterable):\n+        rv += func(item)\n+\n+    return rv\n+\n+\n+def sync_do_list(value: \"t.Iterable[V]\") -&gt; \"t.List[V]\":\n     \"\"\"Convert the value into a list.  If it was a string the returned list\n     will be a list of characters.\n     \"\"\"\n-    pass\n+    return list(value)\n\n\n-def do_mark_safe(value: str) -&gt;Markup:\n+@async_variant(sync_do_list)  # type: ignore\n+async def do_list(value: \"t.Union[t.AsyncIterable[V], t.Iterable[V]]\") -&gt; \"t.List[V]\":\n+    return await auto_to_list(value)\n+\n+\n+def do_mark_safe(value: str) -&gt; Markup:\n     \"\"\"Mark the value as safe which means that in an environment with automatic\n     escaping enabled this variable will not be escaped.\n     \"\"\"\n-    pass\n+    return Markup(value)\n\n\n-def do_mark_unsafe(value: str) -&gt;str:\n+def do_mark_unsafe(value: str) -&gt; str:\n     \"\"\"Mark a value as unsafe.  This is the reverse operation for :func:`safe`.\"\"\"\n-    pass\n+    return str(value)\n+\n+\n+@typing.overload\n+def do_reverse(value: str) -&gt; str: ...\n\n\n-def do_reverse(value: t.Union[str, t.Iterable[V]]) -&gt;t.Union[str, t.Iterable[V]\n-    ]:\n+@typing.overload\n+def do_reverse(value: \"t.Iterable[V]\") -&gt; \"t.Iterable[V]\": ...\n+\n+\n+def do_reverse(value: t.Union[str, t.Iterable[V]]) -&gt; t.Union[str, t.Iterable[V]]:\n     \"\"\"Reverse the object or return an iterator that iterates over it the other\n     way round.\n     \"\"\"\n-    pass\n+    if isinstance(value, str):\n+        return value[::-1]\n+\n+    try:\n+        return reversed(value)  # type: ignore\n+    except TypeError:\n+        try:\n+            rv = list(value)\n+            rv.reverse()\n+            return rv\n+        except TypeError as e:\n+            raise FilterArgumentError(\"argument must be iterable\") from e\n\n\n @pass_environment\n-def do_attr(environment: 'Environment', obj: t.Any, name: str) -&gt;t.Union[\n-    Undefined, t.Any]:\n+def do_attr(\n+    environment: \"Environment\", obj: t.Any, name: str\n+) -&gt; t.Union[Undefined, t.Any]:\n     \"\"\"Get an attribute of an object.  ``foo|attr(\"bar\")`` works like\n     ``foo.bar`` just that always an attribute is returned and items are not\n     looked up.\n\n     See :ref:`Notes on subscriptions &lt;notes-on-subscriptions&gt;` for more details.\n     \"\"\"\n-    pass\n+    try:\n+        name = str(name)\n+    except UnicodeError:\n+        pass\n+    else:\n+        try:\n+            value = getattr(obj, name)\n+        except AttributeError:\n+            pass\n+        else:\n+            if environment.sandboxed:\n+                environment = t.cast(\"SandboxedEnvironment\", environment)\n+\n+                if not environment.is_safe_attribute(obj, name, value):\n+                    return environment.unsafe_undefined(obj, name)\n+\n+            return value\n+\n+    return environment.undefined(obj=obj, name=name)\n+\n+\n+@typing.overload\n+def sync_do_map(\n+    context: \"Context\",\n+    value: t.Iterable[t.Any],\n+    name: str,\n+    *args: t.Any,\n+    **kwargs: t.Any,\n+) -&gt; t.Iterable[t.Any]: ...\n+\n+\n+@typing.overload\n+def sync_do_map(\n+    context: \"Context\",\n+    value: t.Iterable[t.Any],\n+    *,\n+    attribute: str = ...,\n+    default: t.Optional[t.Any] = None,\n+) -&gt; t.Iterable[t.Any]: ...\n\n\n @pass_context\n-def sync_do_map(context: 'Context', value: t.Iterable[t.Any], *args: t.Any,\n-    **kwargs: t.Any) -&gt;t.Iterable[t.Any]:\n+def sync_do_map(\n+    context: \"Context\", value: t.Iterable[t.Any], *args: t.Any, **kwargs: t.Any\n+) -&gt; t.Iterable[t.Any]:\n     \"\"\"Applies a filter on a sequence of objects or looks up an attribute.\n     This is useful when dealing with lists of objects but you are really\n     only interested in a certain value of it.\n@@ -882,12 +1489,51 @@ def sync_do_map(context: 'Context', value: t.Iterable[t.Any], *args: t.Any,\n\n     .. versionadded:: 2.7\n     \"\"\"\n-    pass\n+    if value:\n+        func = prepare_map(context, args, kwargs)\n+\n+        for item in value:\n+            yield func(item)\n+\n+\n+@typing.overload\n+def do_map(\n+    context: \"Context\",\n+    value: t.Union[t.AsyncIterable[t.Any], t.Iterable[t.Any]],\n+    name: str,\n+    *args: t.Any,\n+    **kwargs: t.Any,\n+) -&gt; t.Iterable[t.Any]: ...\n+\n+\n+@typing.overload\n+def do_map(\n+    context: \"Context\",\n+    value: t.Union[t.AsyncIterable[t.Any], t.Iterable[t.Any]],\n+    *,\n+    attribute: str = ...,\n+    default: t.Optional[t.Any] = None,\n+) -&gt; t.Iterable[t.Any]: ...\n+\n+\n+@async_variant(sync_do_map)  # type: ignore\n+async def do_map(\n+    context: \"Context\",\n+    value: t.Union[t.AsyncIterable[t.Any], t.Iterable[t.Any]],\n+    *args: t.Any,\n+    **kwargs: t.Any,\n+) -&gt; t.AsyncIterable[t.Any]:\n+    if value:\n+        func = prepare_map(context, args, kwargs)\n+\n+        async for item in auto_aiter(value):\n+            yield await auto_await(func(item))\n\n\n @pass_context\n-def sync_do_select(context: 'Context', value: 't.Iterable[V]', *args: t.Any,\n-    **kwargs: t.Any) -&gt;'t.Iterator[V]':\n+def sync_do_select(\n+    context: \"Context\", value: \"t.Iterable[V]\", *args: t.Any, **kwargs: t.Any\n+) -&gt; \"t.Iterator[V]\":\n     \"\"\"Filters a sequence of objects by applying a test to each object,\n     and only selecting the objects with the test succeeding.\n\n@@ -912,12 +1558,23 @@ def sync_do_select(context: 'Context', value: 't.Iterable[V]', *args: t.Any,\n\n     .. versionadded:: 2.7\n     \"\"\"\n-    pass\n+    return select_or_reject(context, value, args, kwargs, lambda x: x, False)\n+\n+\n+@async_variant(sync_do_select)  # type: ignore\n+async def do_select(\n+    context: \"Context\",\n+    value: \"t.Union[t.AsyncIterable[V], t.Iterable[V]]\",\n+    *args: t.Any,\n+    **kwargs: t.Any,\n+) -&gt; \"t.AsyncIterator[V]\":\n+    return async_select_or_reject(context, value, args, kwargs, lambda x: x, False)\n\n\n @pass_context\n-def sync_do_reject(context: 'Context', value: 't.Iterable[V]', *args: t.Any,\n-    **kwargs: t.Any) -&gt;'t.Iterator[V]':\n+def sync_do_reject(\n+    context: \"Context\", value: \"t.Iterable[V]\", *args: t.Any, **kwargs: t.Any\n+) -&gt; \"t.Iterator[V]\":\n     \"\"\"Filters a sequence of objects by applying a test to each object,\n     and rejecting the objects with the test succeeding.\n\n@@ -937,12 +1594,23 @@ def sync_do_reject(context: 'Context', value: 't.Iterable[V]', *args: t.Any,\n\n     .. versionadded:: 2.7\n     \"\"\"\n-    pass\n+    return select_or_reject(context, value, args, kwargs, lambda x: not x, False)\n+\n+\n+@async_variant(sync_do_reject)  # type: ignore\n+async def do_reject(\n+    context: \"Context\",\n+    value: \"t.Union[t.AsyncIterable[V], t.Iterable[V]]\",\n+    *args: t.Any,\n+    **kwargs: t.Any,\n+) -&gt; \"t.AsyncIterator[V]\":\n+    return async_select_or_reject(context, value, args, kwargs, lambda x: not x, False)\n\n\n @pass_context\n-def sync_do_selectattr(context: 'Context', value: 't.Iterable[V]', *args: t\n-    .Any, **kwargs: t.Any) -&gt;'t.Iterator[V]':\n+def sync_do_selectattr(\n+    context: \"Context\", value: \"t.Iterable[V]\", *args: t.Any, **kwargs: t.Any\n+) -&gt; \"t.Iterator[V]\":\n     \"\"\"Filters a sequence of objects by applying a test to the specified\n     attribute of each object, and only selecting the objects with the\n     test succeeding.\n@@ -966,12 +1634,23 @@ def sync_do_selectattr(context: 'Context', value: 't.Iterable[V]', *args: t\n\n     .. versionadded:: 2.7\n     \"\"\"\n-    pass\n+    return select_or_reject(context, value, args, kwargs, lambda x: x, True)\n+\n+\n+@async_variant(sync_do_selectattr)  # type: ignore\n+async def do_selectattr(\n+    context: \"Context\",\n+    value: \"t.Union[t.AsyncIterable[V], t.Iterable[V]]\",\n+    *args: t.Any,\n+    **kwargs: t.Any,\n+) -&gt; \"t.AsyncIterator[V]\":\n+    return async_select_or_reject(context, value, args, kwargs, lambda x: x, True)\n\n\n @pass_context\n-def sync_do_rejectattr(context: 'Context', value: 't.Iterable[V]', *args: t\n-    .Any, **kwargs: t.Any) -&gt;'t.Iterator[V]':\n+def sync_do_rejectattr(\n+    context: \"Context\", value: \"t.Iterable[V]\", *args: t.Any, **kwargs: t.Any\n+) -&gt; \"t.Iterator[V]\":\n     \"\"\"Filters a sequence of objects by applying a test to the specified\n     attribute of each object, and rejecting the objects with the test\n     succeeding.\n@@ -993,12 +1672,23 @@ def sync_do_rejectattr(context: 'Context', value: 't.Iterable[V]', *args: t\n\n     .. versionadded:: 2.7\n     \"\"\"\n-    pass\n+    return select_or_reject(context, value, args, kwargs, lambda x: not x, True)\n+\n+\n+@async_variant(sync_do_rejectattr)  # type: ignore\n+async def do_rejectattr(\n+    context: \"Context\",\n+    value: \"t.Union[t.AsyncIterable[V], t.Iterable[V]]\",\n+    *args: t.Any,\n+    **kwargs: t.Any,\n+) -&gt; \"t.AsyncIterator[V]\":\n+    return async_select_or_reject(context, value, args, kwargs, lambda x: not x, True)\n\n\n @pass_eval_context\n-def do_tojson(eval_ctx: 'EvalContext', value: t.Any, indent: t.Optional[int\n-    ]=None) -&gt;Markup:\n+def do_tojson(\n+    eval_ctx: \"EvalContext\", value: t.Any, indent: t.Optional[int] = None\n+) -&gt; Markup:\n     \"\"\"Serialize an object to a string of JSON, and mark it safe to\n     render in HTML. This filter is only for use in HTML documents.\n\n@@ -1013,23 +1703,164 @@ def do_tojson(eval_ctx: 'EvalContext', value: t.Any, indent: t.Optional[int\n\n     .. versionadded:: 2.9\n     \"\"\"\n-    pass\n-\n-\n-FILTERS = {'abs': abs, 'attr': do_attr, 'batch': do_batch, 'capitalize':\n-    do_capitalize, 'center': do_center, 'count': len, 'd': do_default,\n-    'default': do_default, 'dictsort': do_dictsort, 'e': escape, 'escape':\n-    escape, 'filesizeformat': do_filesizeformat, 'first': do_first, 'float':\n-    do_float, 'forceescape': do_forceescape, 'format': do_format, 'groupby':\n-    do_groupby, 'indent': do_indent, 'int': do_int, 'join': do_join, 'last':\n-    do_last, 'length': len, 'list': do_list, 'lower': do_lower, 'items':\n-    do_items, 'map': do_map, 'min': do_min, 'max': do_max, 'pprint':\n-    do_pprint, 'random': do_random, 'reject': do_reject, 'rejectattr':\n-    do_rejectattr, 'replace': do_replace, 'reverse': do_reverse, 'round':\n-    do_round, 'safe': do_mark_safe, 'select': do_select, 'selectattr':\n-    do_selectattr, 'slice': do_slice, 'sort': do_sort, 'string': soft_str,\n-    'striptags': do_striptags, 'sum': do_sum, 'title': do_title, 'trim':\n-    do_trim, 'truncate': do_truncate, 'unique': do_unique, 'upper':\n-    do_upper, 'urlencode': do_urlencode, 'urlize': do_urlize, 'wordcount':\n-    do_wordcount, 'wordwrap': do_wordwrap, 'xmlattr': do_xmlattr, 'tojson':\n-    do_tojson}\n+    policies = eval_ctx.environment.policies\n+    dumps = policies[\"json.dumps_function\"]\n+    kwargs = policies[\"json.dumps_kwargs\"]\n+\n+    if indent is not None:\n+        kwargs = kwargs.copy()\n+        kwargs[\"indent\"] = indent\n+\n+    return htmlsafe_json_dumps(value, dumps=dumps, **kwargs)\n+\n+\n+def prepare_map(\n+    context: \"Context\", args: t.Tuple[t.Any, ...], kwargs: t.Dict[str, t.Any]\n+) -&gt; t.Callable[[t.Any], t.Any]:\n+    if not args and \"attribute\" in kwargs:\n+        attribute = kwargs.pop(\"attribute\")\n+        default = kwargs.pop(\"default\", None)\n+\n+        if kwargs:\n+            raise FilterArgumentError(\n+                f\"Unexpected keyword argument {next(iter(kwargs))!r}\"\n+            )\n+\n+        func = make_attrgetter(context.environment, attribute, default=default)\n+    else:\n+        try:\n+            name = args[0]\n+            args = args[1:]\n+        except LookupError:\n+            raise FilterArgumentError(\"map requires a filter argument\") from None\n+\n+        def func(item: t.Any) -&gt; t.Any:\n+            return context.environment.call_filter(\n+                name, item, args, kwargs, context=context\n+            )\n+\n+    return func\n+\n+\n+def prepare_select_or_reject(\n+    context: \"Context\",\n+    args: t.Tuple[t.Any, ...],\n+    kwargs: t.Dict[str, t.Any],\n+    modfunc: t.Callable[[t.Any], t.Any],\n+    lookup_attr: bool,\n+) -&gt; t.Callable[[t.Any], t.Any]:\n+    if lookup_attr:\n+        try:\n+            attr = args[0]\n+        except LookupError:\n+            raise FilterArgumentError(\"Missing parameter for attribute name\") from None\n+\n+        transfunc = make_attrgetter(context.environment, attr)\n+        off = 1\n+    else:\n+        off = 0\n+\n+        def transfunc(x: V) -&gt; V:\n+            return x\n+\n+    try:\n+        name = args[off]\n+        args = args[1 + off :]\n+\n+        def func(item: t.Any) -&gt; t.Any:\n+            return context.environment.call_test(name, item, args, kwargs)\n+\n+    except LookupError:\n+        func = bool  # type: ignore\n+\n+    return lambda item: modfunc(func(transfunc(item)))\n+\n+\n+def select_or_reject(\n+    context: \"Context\",\n+    value: \"t.Iterable[V]\",\n+    args: t.Tuple[t.Any, ...],\n+    kwargs: t.Dict[str, t.Any],\n+    modfunc: t.Callable[[t.Any], t.Any],\n+    lookup_attr: bool,\n+) -&gt; \"t.Iterator[V]\":\n+    if value:\n+        func = prepare_select_or_reject(context, args, kwargs, modfunc, lookup_attr)\n+\n+        for item in value:\n+            if func(item):\n+                yield item\n+\n+\n+async def async_select_or_reject(\n+    context: \"Context\",\n+    value: \"t.Union[t.AsyncIterable[V], t.Iterable[V]]\",\n+    args: t.Tuple[t.Any, ...],\n+    kwargs: t.Dict[str, t.Any],\n+    modfunc: t.Callable[[t.Any], t.Any],\n+    lookup_attr: bool,\n+) -&gt; \"t.AsyncIterator[V]\":\n+    if value:\n+        func = prepare_select_or_reject(context, args, kwargs, modfunc, lookup_attr)\n+\n+        async for item in auto_aiter(value):\n+            if func(item):\n+                yield item\n+\n+\n+FILTERS = {\n+    \"abs\": abs,\n+    \"attr\": do_attr,\n+    \"batch\": do_batch,\n+    \"capitalize\": do_capitalize,\n+    \"center\": do_center,\n+    \"count\": len,\n+    \"d\": do_default,\n+    \"default\": do_default,\n+    \"dictsort\": do_dictsort,\n+    \"e\": escape,\n+    \"escape\": escape,\n+    \"filesizeformat\": do_filesizeformat,\n+    \"first\": do_first,\n+    \"float\": do_float,\n+    \"forceescape\": do_forceescape,\n+    \"format\": do_format,\n+    \"groupby\": do_groupby,\n+    \"indent\": do_indent,\n+    \"int\": do_int,\n+    \"join\": do_join,\n+    \"last\": do_last,\n+    \"length\": len,\n+    \"list\": do_list,\n+    \"lower\": do_lower,\n+    \"items\": do_items,\n+    \"map\": do_map,\n+    \"min\": do_min,\n+    \"max\": do_max,\n+    \"pprint\": do_pprint,\n+    \"random\": do_random,\n+    \"reject\": do_reject,\n+    \"rejectattr\": do_rejectattr,\n+    \"replace\": do_replace,\n+    \"reverse\": do_reverse,\n+    \"round\": do_round,\n+    \"safe\": do_mark_safe,\n+    \"select\": do_select,\n+    \"selectattr\": do_selectattr,\n+    \"slice\": do_slice,\n+    \"sort\": do_sort,\n+    \"string\": soft_str,\n+    \"striptags\": do_striptags,\n+    \"sum\": do_sum,\n+    \"title\": do_title,\n+    \"trim\": do_trim,\n+    \"truncate\": do_truncate,\n+    \"unique\": do_unique,\n+    \"upper\": do_upper,\n+    \"urlencode\": do_urlencode,\n+    \"urlize\": do_urlize,\n+    \"wordcount\": do_wordcount,\n+    \"wordwrap\": do_wordwrap,\n+    \"xmlattr\": do_xmlattr,\n+    \"tojson\": do_tojson,\n+}\ndiff --git a/src/jinja2/idtracking.py b/src/jinja2/idtracking.py\nindex a1d69ca..995ebaa 100644\n--- a/src/jinja2/idtracking.py\n+++ b/src/jinja2/idtracking.py\n@@ -1,32 +1,184 @@\n import typing as t\n+\n from . import nodes\n from .visitor import NodeVisitor\n-VAR_LOAD_PARAMETER = 'param'\n-VAR_LOAD_RESOLVE = 'resolve'\n-VAR_LOAD_ALIAS = 'alias'\n-VAR_LOAD_UNDEFINED = 'undefined'\n\n+VAR_LOAD_PARAMETER = \"param\"\n+VAR_LOAD_RESOLVE = \"resolve\"\n+VAR_LOAD_ALIAS = \"alias\"\n+VAR_LOAD_UNDEFINED = \"undefined\"\n+\n+\n+def find_symbols(\n+    nodes: t.Iterable[nodes.Node], parent_symbols: t.Optional[\"Symbols\"] = None\n+) -&gt; \"Symbols\":\n+    sym = Symbols(parent=parent_symbols)\n+    visitor = FrameSymbolVisitor(sym)\n+    for node in nodes:\n+        visitor.visit(node)\n+    return sym\n\n-class Symbols:\n\n-    def __init__(self, parent: t.Optional['Symbols']=None, level: t.\n-        Optional[int]=None) -&gt;None:\n+def symbols_for_node(\n+    node: nodes.Node, parent_symbols: t.Optional[\"Symbols\"] = None\n+) -&gt; \"Symbols\":\n+    sym = Symbols(parent=parent_symbols)\n+    sym.analyze_node(node)\n+    return sym\n+\n+\n+class Symbols:\n+    def __init__(\n+        self, parent: t.Optional[\"Symbols\"] = None, level: t.Optional[int] = None\n+    ) -&gt; None:\n         if level is None:\n             if parent is None:\n                 level = 0\n             else:\n                 level = parent.level + 1\n+\n         self.level: int = level\n         self.parent = parent\n         self.refs: t.Dict[str, str] = {}\n         self.loads: t.Dict[str, t.Any] = {}\n         self.stores: t.Set[str] = set()\n\n+    def analyze_node(self, node: nodes.Node, **kwargs: t.Any) -&gt; None:\n+        visitor = RootVisitor(self)\n+        visitor.visit(node, **kwargs)\n\n-class RootVisitor(NodeVisitor):\n+    def _define_ref(\n+        self, name: str, load: t.Optional[t.Tuple[str, t.Optional[str]]] = None\n+    ) -&gt; str:\n+        ident = f\"l_{self.level}_{name}\"\n+        self.refs[name] = ident\n+        if load is not None:\n+            self.loads[ident] = load\n+        return ident\n+\n+    def find_load(self, target: str) -&gt; t.Optional[t.Any]:\n+        if target in self.loads:\n+            return self.loads[target]\n+\n+        if self.parent is not None:\n+            return self.parent.find_load(target)\n+\n+        return None\n+\n+    def find_ref(self, name: str) -&gt; t.Optional[str]:\n+        if name in self.refs:\n+            return self.refs[name]\n+\n+        if self.parent is not None:\n+            return self.parent.find_ref(name)\n+\n+        return None\n+\n+    def ref(self, name: str) -&gt; str:\n+        rv = self.find_ref(name)\n+        if rv is None:\n+            raise AssertionError(\n+                \"Tried to resolve a name to a reference that was\"\n+                f\" unknown to the frame ({name!r})\"\n+            )\n+        return rv\n+\n+    def copy(self) -&gt; \"Symbols\":\n+        rv = object.__new__(self.__class__)\n+        rv.__dict__.update(self.__dict__)\n+        rv.refs = self.refs.copy()\n+        rv.loads = self.loads.copy()\n+        rv.stores = self.stores.copy()\n+        return rv\n+\n+    def store(self, name: str) -&gt; None:\n+        self.stores.add(name)\n+\n+        # If we have not see the name referenced yet, we need to figure\n+        # out what to set it to.\n+        if name not in self.refs:\n+            # If there is a parent scope we check if the name has a\n+            # reference there.  If it does it means we might have to alias\n+            # to a variable there.\n+            if self.parent is not None:\n+                outer_ref = self.parent.find_ref(name)\n+                if outer_ref is not None:\n+                    self._define_ref(name, load=(VAR_LOAD_ALIAS, outer_ref))\n+                    return\n+\n+            # Otherwise we can just set it to undefined.\n+            self._define_ref(name, load=(VAR_LOAD_UNDEFINED, None))\n+\n+    def declare_parameter(self, name: str) -&gt; str:\n+        self.stores.add(name)\n+        return self._define_ref(name, load=(VAR_LOAD_PARAMETER, None))\n+\n+    def load(self, name: str) -&gt; None:\n+        if self.find_ref(name) is None:\n+            self._define_ref(name, load=(VAR_LOAD_RESOLVE, name))\n+\n+    def branch_update(self, branch_symbols: t.Sequence[\"Symbols\"]) -&gt; None:\n+        stores: t.Dict[str, int] = {}\n+        for branch in branch_symbols:\n+            for target in branch.stores:\n+                if target in self.stores:\n+                    continue\n+                stores[target] = stores.get(target, 0) + 1\n+\n+        for sym in branch_symbols:\n+            self.refs.update(sym.refs)\n+            self.loads.update(sym.loads)\n+            self.stores.update(sym.stores)\n+\n+        for name, branch_count in stores.items():\n+            if branch_count == len(branch_symbols):\n+                continue\n+\n+            target = self.find_ref(name)  # type: ignore\n+            assert target is not None, \"should not happen\"\n+\n+            if self.parent is not None:\n+                outer_target = self.parent.find_ref(name)\n+                if outer_target is not None:\n+                    self.loads[target] = (VAR_LOAD_ALIAS, outer_target)\n+                    continue\n+            self.loads[target] = (VAR_LOAD_RESOLVE, name)\n+\n+    def dump_stores(self) -&gt; t.Dict[str, str]:\n+        rv: t.Dict[str, str] = {}\n+        node: t.Optional[\"Symbols\"] = self\n+\n+        while node is not None:\n+            for name in sorted(node.stores):\n+                if name not in rv:\n+                    rv[name] = self.find_ref(name)  # type: ignore\n+\n+            node = node.parent\n\n-    def __init__(self, symbols: 'Symbols') -&gt;None:\n+        return rv\n+\n+    def dump_param_targets(self) -&gt; t.Set[str]:\n+        rv = set()\n+        node: t.Optional[\"Symbols\"] = self\n+\n+        while node is not None:\n+            for target, (instr, _) in self.loads.items():\n+                if instr == VAR_LOAD_PARAMETER:\n+                    rv.add(target)\n+\n+            node = node.parent\n+\n+        return rv\n+\n+\n+class RootVisitor(NodeVisitor):\n+    def __init__(self, symbols: \"Symbols\") -&gt; None:\n         self.sym_visitor = FrameSymbolVisitor(symbols)\n+\n+    def _simple_visit(self, node: nodes.Node, **kwargs: t.Any) -&gt; None:\n+        for child in node.iter_child_nodes():\n+            self.sym_visitor.visit(child)\n+\n     visit_Template = _simple_visit\n     visit_Block = _simple_visit\n     visit_Macro = _simple_visit\n@@ -35,42 +187,132 @@ class RootVisitor(NodeVisitor):\n     visit_If = _simple_visit\n     visit_ScopedEvalContextModifier = _simple_visit\n\n+    def visit_AssignBlock(self, node: nodes.AssignBlock, **kwargs: t.Any) -&gt; None:\n+        for child in node.body:\n+            self.sym_visitor.visit(child)\n+\n+    def visit_CallBlock(self, node: nodes.CallBlock, **kwargs: t.Any) -&gt; None:\n+        for child in node.iter_child_nodes(exclude=(\"call\",)):\n+            self.sym_visitor.visit(child)\n+\n+    def visit_OverlayScope(self, node: nodes.OverlayScope, **kwargs: t.Any) -&gt; None:\n+        for child in node.body:\n+            self.sym_visitor.visit(child)\n+\n+    def visit_For(\n+        self, node: nodes.For, for_branch: str = \"body\", **kwargs: t.Any\n+    ) -&gt; None:\n+        if for_branch == \"body\":\n+            self.sym_visitor.visit(node.target, store_as_param=True)\n+            branch = node.body\n+        elif for_branch == \"else\":\n+            branch = node.else_\n+        elif for_branch == \"test\":\n+            self.sym_visitor.visit(node.target, store_as_param=True)\n+            if node.test is not None:\n+                self.sym_visitor.visit(node.test)\n+            return\n+        else:\n+            raise RuntimeError(\"Unknown for branch\")\n+\n+        if branch:\n+            for item in branch:\n+                self.sym_visitor.visit(item)\n+\n+    def visit_With(self, node: nodes.With, **kwargs: t.Any) -&gt; None:\n+        for target in node.targets:\n+            self.sym_visitor.visit(target)\n+        for child in node.body:\n+            self.sym_visitor.visit(child)\n+\n+    def generic_visit(self, node: nodes.Node, *args: t.Any, **kwargs: t.Any) -&gt; None:\n+        raise NotImplementedError(f\"Cannot find symbols for {type(node).__name__!r}\")\n+\n\n class FrameSymbolVisitor(NodeVisitor):\n     \"\"\"A visitor for `Frame.inspect`.\"\"\"\n\n-    def __init__(self, symbols: 'Symbols') -&gt;None:\n+    def __init__(self, symbols: \"Symbols\") -&gt; None:\n         self.symbols = symbols\n\n-    def visit_Name(self, node: nodes.Name, store_as_param: bool=False, **\n-        kwargs: t.Any) -&gt;None:\n+    def visit_Name(\n+        self, node: nodes.Name, store_as_param: bool = False, **kwargs: t.Any\n+    ) -&gt; None:\n         \"\"\"All assignments to names go through this function.\"\"\"\n-        pass\n+        if store_as_param or node.ctx == \"param\":\n+            self.symbols.declare_parameter(node.name)\n+        elif node.ctx == \"store\":\n+            self.symbols.store(node.name)\n+        elif node.ctx == \"load\":\n+            self.symbols.load(node.name)\n+\n+    def visit_NSRef(self, node: nodes.NSRef, **kwargs: t.Any) -&gt; None:\n+        self.symbols.load(node.name)\n+\n+    def visit_If(self, node: nodes.If, **kwargs: t.Any) -&gt; None:\n+        self.visit(node.test, **kwargs)\n+        original_symbols = self.symbols\n+\n+        def inner_visit(nodes: t.Iterable[nodes.Node]) -&gt; \"Symbols\":\n+            self.symbols = rv = original_symbols.copy()\n+\n+            for subnode in nodes:\n+                self.visit(subnode, **kwargs)\n+\n+            self.symbols = original_symbols\n+            return rv\n+\n+        body_symbols = inner_visit(node.body)\n+        elif_symbols = inner_visit(node.elif_)\n+        else_symbols = inner_visit(node.else_ or ())\n+        self.symbols.branch_update([body_symbols, elif_symbols, else_symbols])\n+\n+    def visit_Macro(self, node: nodes.Macro, **kwargs: t.Any) -&gt; None:\n+        self.symbols.store(node.name)\n\n-    def visit_Assign(self, node: nodes.Assign, **kwargs: t.Any) -&gt;None:\n+    def visit_Import(self, node: nodes.Import, **kwargs: t.Any) -&gt; None:\n+        self.generic_visit(node, **kwargs)\n+        self.symbols.store(node.target)\n+\n+    def visit_FromImport(self, node: nodes.FromImport, **kwargs: t.Any) -&gt; None:\n+        self.generic_visit(node, **kwargs)\n+\n+        for name in node.names:\n+            if isinstance(name, tuple):\n+                self.symbols.store(name[1])\n+            else:\n+                self.symbols.store(name)\n+\n+    def visit_Assign(self, node: nodes.Assign, **kwargs: t.Any) -&gt; None:\n         \"\"\"Visit assignments in the correct order.\"\"\"\n-        pass\n+        self.visit(node.node, **kwargs)\n+        self.visit(node.target, **kwargs)\n\n-    def visit_For(self, node: nodes.For, **kwargs: t.Any) -&gt;None:\n+    def visit_For(self, node: nodes.For, **kwargs: t.Any) -&gt; None:\n         \"\"\"Visiting stops at for blocks.  However the block sequence\n         is visited as part of the outer scope.\n         \"\"\"\n-        pass\n+        self.visit(node.iter, **kwargs)\n+\n+    def visit_CallBlock(self, node: nodes.CallBlock, **kwargs: t.Any) -&gt; None:\n+        self.visit(node.call, **kwargs)\n+\n+    def visit_FilterBlock(self, node: nodes.FilterBlock, **kwargs: t.Any) -&gt; None:\n+        self.visit(node.filter, **kwargs)\n+\n+    def visit_With(self, node: nodes.With, **kwargs: t.Any) -&gt; None:\n+        for target in node.values:\n+            self.visit(target)\n\n-    def visit_AssignBlock(self, node: nodes.AssignBlock, **kwargs: t.Any\n-        ) -&gt;None:\n+    def visit_AssignBlock(self, node: nodes.AssignBlock, **kwargs: t.Any) -&gt; None:\n         \"\"\"Stop visiting at block assigns.\"\"\"\n-        pass\n+        self.visit(node.target, **kwargs)\n\n-    def visit_Scope(self, node: nodes.Scope, **kwargs: t.Any) -&gt;None:\n+    def visit_Scope(self, node: nodes.Scope, **kwargs: t.Any) -&gt; None:\n         \"\"\"Stop visiting at scopes.\"\"\"\n-        pass\n\n-    def visit_Block(self, node: nodes.Block, **kwargs: t.Any) -&gt;None:\n+    def visit_Block(self, node: nodes.Block, **kwargs: t.Any) -&gt; None:\n         \"\"\"Stop visiting at blocks.\"\"\"\n-        pass\n\n-    def visit_OverlayScope(self, node: nodes.OverlayScope, **kwargs: t.Any\n-        ) -&gt;None:\n+    def visit_OverlayScope(self, node: nodes.OverlayScope, **kwargs: t.Any) -&gt; None:\n         \"\"\"Do not visit into overlay scopes.\"\"\"\n-        pass\ndiff --git a/src/jinja2/lexer.py b/src/jinja2/lexer.py\nindex 2281b7e..62b0471 100644\n--- a/src/jinja2/lexer.py\n+++ b/src/jinja2/lexer.py\n@@ -3,138 +3,252 @@ is used to do some preprocessing. It filters out invalid operators like\n the bitshift operators we don't allow in templates. It separates\n template code and python code in expressions.\n \"\"\"\n+\n import re\n import typing as t\n from ast import literal_eval\n from collections import deque\n from sys import intern\n+\n from ._identifier import pattern as name_re\n from .exceptions import TemplateSyntaxError\n from .utils import LRUCache\n+\n if t.TYPE_CHECKING:\n     import typing_extensions as te\n+\n     from .environment import Environment\n-_lexer_cache: t.MutableMapping[t.Tuple, 'Lexer'] = LRUCache(50)\n-whitespace_re = re.compile('\\\\s+')\n-newline_re = re.compile('(\\\\r\\\\n|\\\\r|\\\\n)')\n+\n+# cache for the lexers. Exists in order to be able to have multiple\n+# environments with the same lexer\n+_lexer_cache: t.MutableMapping[t.Tuple, \"Lexer\"] = LRUCache(50)  # type: ignore\n+\n+# static regular expressions\n+whitespace_re = re.compile(r\"\\s+\")\n+newline_re = re.compile(r\"(\\r\\n|\\r|\\n)\")\n string_re = re.compile(\n-    '(\\'([^\\'\\\\\\\\]*(?:\\\\\\\\.[^\\'\\\\\\\\]*)*)\\'|\"([^\"\\\\\\\\]*(?:\\\\\\\\.[^\"\\\\\\\\]*)*)\")',\n-    re.S)\n+    r\"('([^'\\\\]*(?:\\\\.[^'\\\\]*)*)'\" r'|\"([^\"\\\\]*(?:\\\\.[^\"\\\\]*)*)\")', re.S\n+)\n integer_re = re.compile(\n-    \"\"\"\n+    r\"\"\"\n     (\n         0b(_?[0-1])+ # binary\n     |\n         0o(_?[0-7])+ # octal\n     |\n-        0x(_?[\\\\da-f])+ # hex\n+        0x(_?[\\da-f])+ # hex\n     |\n-        [1-9](_?\\\\d)* # decimal\n+        [1-9](_?\\d)* # decimal\n     |\n         0(_?0)* # decimal zero\n     )\n-    \"\"\"\n-    , re.IGNORECASE | re.VERBOSE)\n+    \"\"\",\n+    re.IGNORECASE | re.VERBOSE,\n+)\n float_re = re.compile(\n-    \"\"\"\n-    (?&lt;!\\\\.)  # doesn't start with a .\n-    (\\\\d+_)*\\\\d+  # digits, possibly _ separated\n+    r\"\"\"\n+    (?&lt;!\\.)  # doesn't start with a .\n+    (\\d+_)*\\d+  # digits, possibly _ separated\n     (\n-        (\\\\.(\\\\d+_)*\\\\d+)?  # optional fractional part\n-        e[+\\\\-]?(\\\\d+_)*\\\\d+  # exponent part\n+        (\\.(\\d+_)*\\d+)?  # optional fractional part\n+        e[+\\-]?(\\d+_)*\\d+  # exponent part\n     |\n-        \\\\.(\\\\d+_)*\\\\d+  # required fractional part\n+        \\.(\\d+_)*\\d+  # required fractional part\n     )\n-    \"\"\"\n-    , re.IGNORECASE | re.VERBOSE)\n-TOKEN_ADD = intern('add')\n-TOKEN_ASSIGN = intern('assign')\n-TOKEN_COLON = intern('colon')\n-TOKEN_COMMA = intern('comma')\n-TOKEN_DIV = intern('div')\n-TOKEN_DOT = intern('dot')\n-TOKEN_EQ = intern('eq')\n-TOKEN_FLOORDIV = intern('floordiv')\n-TOKEN_GT = intern('gt')\n-TOKEN_GTEQ = intern('gteq')\n-TOKEN_LBRACE = intern('lbrace')\n-TOKEN_LBRACKET = intern('lbracket')\n-TOKEN_LPAREN = intern('lparen')\n-TOKEN_LT = intern('lt')\n-TOKEN_LTEQ = intern('lteq')\n-TOKEN_MOD = intern('mod')\n-TOKEN_MUL = intern('mul')\n-TOKEN_NE = intern('ne')\n-TOKEN_PIPE = intern('pipe')\n-TOKEN_POW = intern('pow')\n-TOKEN_RBRACE = intern('rbrace')\n-TOKEN_RBRACKET = intern('rbracket')\n-TOKEN_RPAREN = intern('rparen')\n-TOKEN_SEMICOLON = intern('semicolon')\n-TOKEN_SUB = intern('sub')\n-TOKEN_TILDE = intern('tilde')\n-TOKEN_WHITESPACE = intern('whitespace')\n-TOKEN_FLOAT = intern('float')\n-TOKEN_INTEGER = intern('integer')\n-TOKEN_NAME = intern('name')\n-TOKEN_STRING = intern('string')\n-TOKEN_OPERATOR = intern('operator')\n-TOKEN_BLOCK_BEGIN = intern('block_begin')\n-TOKEN_BLOCK_END = intern('block_end')\n-TOKEN_VARIABLE_BEGIN = intern('variable_begin')\n-TOKEN_VARIABLE_END = intern('variable_end')\n-TOKEN_RAW_BEGIN = intern('raw_begin')\n-TOKEN_RAW_END = intern('raw_end')\n-TOKEN_COMMENT_BEGIN = intern('comment_begin')\n-TOKEN_COMMENT_END = intern('comment_end')\n-TOKEN_COMMENT = intern('comment')\n-TOKEN_LINESTATEMENT_BEGIN = intern('linestatement_begin')\n-TOKEN_LINESTATEMENT_END = intern('linestatement_end')\n-TOKEN_LINECOMMENT_BEGIN = intern('linecomment_begin')\n-TOKEN_LINECOMMENT_END = intern('linecomment_end')\n-TOKEN_LINECOMMENT = intern('linecomment')\n-TOKEN_DATA = intern('data')\n-TOKEN_INITIAL = intern('initial')\n-TOKEN_EOF = intern('eof')\n-operators = {'+': TOKEN_ADD, '-': TOKEN_SUB, '/': TOKEN_DIV, '//':\n-    TOKEN_FLOORDIV, '*': TOKEN_MUL, '%': TOKEN_MOD, '**': TOKEN_POW, '~':\n-    TOKEN_TILDE, '[': TOKEN_LBRACKET, ']': TOKEN_RBRACKET, '(':\n-    TOKEN_LPAREN, ')': TOKEN_RPAREN, '{': TOKEN_LBRACE, '}': TOKEN_RBRACE,\n-    '==': TOKEN_EQ, '!=': TOKEN_NE, '&gt;': TOKEN_GT, '&gt;=': TOKEN_GTEQ, '&lt;':\n-    TOKEN_LT, '&lt;=': TOKEN_LTEQ, '=': TOKEN_ASSIGN, '.': TOKEN_DOT, ':':\n-    TOKEN_COLON, '|': TOKEN_PIPE, ',': TOKEN_COMMA, ';': TOKEN_SEMICOLON}\n+    \"\"\",\n+    re.IGNORECASE | re.VERBOSE,\n+)\n+\n+# internal the tokens and keep references to them\n+TOKEN_ADD = intern(\"add\")\n+TOKEN_ASSIGN = intern(\"assign\")\n+TOKEN_COLON = intern(\"colon\")\n+TOKEN_COMMA = intern(\"comma\")\n+TOKEN_DIV = intern(\"div\")\n+TOKEN_DOT = intern(\"dot\")\n+TOKEN_EQ = intern(\"eq\")\n+TOKEN_FLOORDIV = intern(\"floordiv\")\n+TOKEN_GT = intern(\"gt\")\n+TOKEN_GTEQ = intern(\"gteq\")\n+TOKEN_LBRACE = intern(\"lbrace\")\n+TOKEN_LBRACKET = intern(\"lbracket\")\n+TOKEN_LPAREN = intern(\"lparen\")\n+TOKEN_LT = intern(\"lt\")\n+TOKEN_LTEQ = intern(\"lteq\")\n+TOKEN_MOD = intern(\"mod\")\n+TOKEN_MUL = intern(\"mul\")\n+TOKEN_NE = intern(\"ne\")\n+TOKEN_PIPE = intern(\"pipe\")\n+TOKEN_POW = intern(\"pow\")\n+TOKEN_RBRACE = intern(\"rbrace\")\n+TOKEN_RBRACKET = intern(\"rbracket\")\n+TOKEN_RPAREN = intern(\"rparen\")\n+TOKEN_SEMICOLON = intern(\"semicolon\")\n+TOKEN_SUB = intern(\"sub\")\n+TOKEN_TILDE = intern(\"tilde\")\n+TOKEN_WHITESPACE = intern(\"whitespace\")\n+TOKEN_FLOAT = intern(\"float\")\n+TOKEN_INTEGER = intern(\"integer\")\n+TOKEN_NAME = intern(\"name\")\n+TOKEN_STRING = intern(\"string\")\n+TOKEN_OPERATOR = intern(\"operator\")\n+TOKEN_BLOCK_BEGIN = intern(\"block_begin\")\n+TOKEN_BLOCK_END = intern(\"block_end\")\n+TOKEN_VARIABLE_BEGIN = intern(\"variable_begin\")\n+TOKEN_VARIABLE_END = intern(\"variable_end\")\n+TOKEN_RAW_BEGIN = intern(\"raw_begin\")\n+TOKEN_RAW_END = intern(\"raw_end\")\n+TOKEN_COMMENT_BEGIN = intern(\"comment_begin\")\n+TOKEN_COMMENT_END = intern(\"comment_end\")\n+TOKEN_COMMENT = intern(\"comment\")\n+TOKEN_LINESTATEMENT_BEGIN = intern(\"linestatement_begin\")\n+TOKEN_LINESTATEMENT_END = intern(\"linestatement_end\")\n+TOKEN_LINECOMMENT_BEGIN = intern(\"linecomment_begin\")\n+TOKEN_LINECOMMENT_END = intern(\"linecomment_end\")\n+TOKEN_LINECOMMENT = intern(\"linecomment\")\n+TOKEN_DATA = intern(\"data\")\n+TOKEN_INITIAL = intern(\"initial\")\n+TOKEN_EOF = intern(\"eof\")\n+\n+# bind operators to token types\n+operators = {\n+    \"+\": TOKEN_ADD,\n+    \"-\": TOKEN_SUB,\n+    \"/\": TOKEN_DIV,\n+    \"//\": TOKEN_FLOORDIV,\n+    \"*\": TOKEN_MUL,\n+    \"%\": TOKEN_MOD,\n+    \"**\": TOKEN_POW,\n+    \"~\": TOKEN_TILDE,\n+    \"[\": TOKEN_LBRACKET,\n+    \"]\": TOKEN_RBRACKET,\n+    \"(\": TOKEN_LPAREN,\n+    \")\": TOKEN_RPAREN,\n+    \"{\": TOKEN_LBRACE,\n+    \"}\": TOKEN_RBRACE,\n+    \"==\": TOKEN_EQ,\n+    \"!=\": TOKEN_NE,\n+    \"&gt;\": TOKEN_GT,\n+    \"&gt;=\": TOKEN_GTEQ,\n+    \"&lt;\": TOKEN_LT,\n+    \"&lt;=\": TOKEN_LTEQ,\n+    \"=\": TOKEN_ASSIGN,\n+    \".\": TOKEN_DOT,\n+    \":\": TOKEN_COLON,\n+    \"|\": TOKEN_PIPE,\n+    \",\": TOKEN_COMMA,\n+    \";\": TOKEN_SEMICOLON,\n+}\n+\n reverse_operators = {v: k for k, v in operators.items()}\n-assert len(operators) == len(reverse_operators), 'operators dropped'\n+assert len(operators) == len(reverse_operators), \"operators dropped\"\n operator_re = re.compile(\n     f\"({'|'.join(re.escape(x) for x in sorted(operators, key=lambda x: -len(x)))})\"\n-    )\n-ignored_tokens = frozenset([TOKEN_COMMENT_BEGIN, TOKEN_COMMENT,\n-    TOKEN_COMMENT_END, TOKEN_WHITESPACE, TOKEN_LINECOMMENT_BEGIN,\n-    TOKEN_LINECOMMENT_END, TOKEN_LINECOMMENT])\n-ignore_if_empty = frozenset([TOKEN_WHITESPACE, TOKEN_DATA, TOKEN_COMMENT,\n-    TOKEN_LINECOMMENT])\n-\n-\n-def describe_token(token: 'Token') -&gt;str:\n+)\n+\n+ignored_tokens = frozenset(\n+    [\n+        TOKEN_COMMENT_BEGIN,\n+        TOKEN_COMMENT,\n+        TOKEN_COMMENT_END,\n+        TOKEN_WHITESPACE,\n+        TOKEN_LINECOMMENT_BEGIN,\n+        TOKEN_LINECOMMENT_END,\n+        TOKEN_LINECOMMENT,\n+    ]\n+)\n+ignore_if_empty = frozenset(\n+    [TOKEN_WHITESPACE, TOKEN_DATA, TOKEN_COMMENT, TOKEN_LINECOMMENT]\n+)\n+\n+\n+def _describe_token_type(token_type: str) -&gt; str:\n+    if token_type in reverse_operators:\n+        return reverse_operators[token_type]\n+\n+    return {\n+        TOKEN_COMMENT_BEGIN: \"begin of comment\",\n+        TOKEN_COMMENT_END: \"end of comment\",\n+        TOKEN_COMMENT: \"comment\",\n+        TOKEN_LINECOMMENT: \"comment\",\n+        TOKEN_BLOCK_BEGIN: \"begin of statement block\",\n+        TOKEN_BLOCK_END: \"end of statement block\",\n+        TOKEN_VARIABLE_BEGIN: \"begin of print statement\",\n+        TOKEN_VARIABLE_END: \"end of print statement\",\n+        TOKEN_LINESTATEMENT_BEGIN: \"begin of line statement\",\n+        TOKEN_LINESTATEMENT_END: \"end of line statement\",\n+        TOKEN_DATA: \"template data / text\",\n+        TOKEN_EOF: \"end of template\",\n+    }.get(token_type, token_type)\n+\n+\n+def describe_token(token: \"Token\") -&gt; str:\n     \"\"\"Returns a description of the token.\"\"\"\n-    pass\n+    if token.type == TOKEN_NAME:\n+        return token.value\n\n+    return _describe_token_type(token.type)\n\n-def describe_token_expr(expr: str) -&gt;str:\n+\n+def describe_token_expr(expr: str) -&gt; str:\n     \"\"\"Like `describe_token` but for token expressions.\"\"\"\n-    pass\n+    if \":\" in expr:\n+        type, value = expr.split(\":\", 1)\n+\n+        if type == TOKEN_NAME:\n+            return value\n+    else:\n+        type = expr\n+\n+    return _describe_token_type(type)\n\n\n-def count_newlines(value: str) -&gt;int:\n+def count_newlines(value: str) -&gt; int:\n     \"\"\"Count the number of newline characters in the string.  This is\n     useful for extensions that filter a stream.\n     \"\"\"\n-    pass\n+    return len(newline_re.findall(value))\n\n\n-def compile_rules(environment: 'Environment') -&gt;t.List[t.Tuple[str, str]]:\n+def compile_rules(environment: \"Environment\") -&gt; t.List[t.Tuple[str, str]]:\n     \"\"\"Compiles all the rules from the environment into a list of rules.\"\"\"\n-    pass\n+    e = re.escape\n+    rules = [\n+        (\n+            len(environment.comment_start_string),\n+            TOKEN_COMMENT_BEGIN,\n+            e(environment.comment_start_string),\n+        ),\n+        (\n+            len(environment.block_start_string),\n+            TOKEN_BLOCK_BEGIN,\n+            e(environment.block_start_string),\n+        ),\n+        (\n+            len(environment.variable_start_string),\n+            TOKEN_VARIABLE_BEGIN,\n+            e(environment.variable_start_string),\n+        ),\n+    ]\n+\n+    if environment.line_statement_prefix is not None:\n+        rules.append(\n+            (\n+                len(environment.line_statement_prefix),\n+                TOKEN_LINESTATEMENT_BEGIN,\n+                r\"^[ \\t\\v]*\" + e(environment.line_statement_prefix),\n+            )\n+        )\n+    if environment.line_comment_prefix is not None:\n+        rules.append(\n+            (\n+                len(environment.line_comment_prefix),\n+                TOKEN_LINECOMMENT_BEGIN,\n+                r\"(?:^|(?&lt;=\\S))[^\\S\\r\\n]*\" + e(environment.line_comment_prefix),\n+            )\n+        )\n+\n+    return [x[1:] for x in sorted(rules, reverse=True)]\n\n\n class Failure:\n@@ -142,12 +256,13 @@ class Failure:\n     Used by the `Lexer` to specify known errors.\n     \"\"\"\n\n-    def __init__(self, message: str, cls: t.Type[TemplateSyntaxError]=\n-        TemplateSyntaxError) -&gt;None:\n+    def __init__(\n+        self, message: str, cls: t.Type[TemplateSyntaxError] = TemplateSyntaxError\n+    ) -&gt; None:\n         self.message = message\n         self.error_class = cls\n\n-    def __call__(self, lineno: int, filename: str) -&gt;'te.NoReturn':\n+    def __call__(self, lineno: int, filename: str) -&gt; \"te.NoReturn\":\n         raise self.error_class(self.message, lineno, filename)\n\n\n@@ -156,19 +271,27 @@ class Token(t.NamedTuple):\n     type: str\n     value: str\n\n-    def __str__(self) -&gt;str:\n+    def __str__(self) -&gt; str:\n         return describe_token(self)\n\n-    def test(self, expr: str) -&gt;bool:\n+    def test(self, expr: str) -&gt; bool:\n         \"\"\"Test a token against a token expression.  This can either be a\n         token type or ``'token_type:token_value'``.  This can only test\n         against string values and types.\n         \"\"\"\n-        pass\n+        # here we do a regular string equality check as test_any is usually\n+        # passed an iterable of not interned strings.\n+        if self.type == expr:\n+            return True\n+\n+        if \":\" in expr:\n+            return expr.split(\":\", 1) == [self.type, self.value]\n+\n+        return False\n\n-    def test_any(self, *iterable: str) -&gt;bool:\n+    def test_any(self, *iterable: str) -&gt; bool:\n         \"\"\"Test against multiple token expressions.\"\"\"\n-        pass\n+        return any(self.test(expr) for expr in iterable)\n\n\n class TokenStreamIterator:\n@@ -176,17 +299,19 @@ class TokenStreamIterator:\n     until the eof token is reached.\n     \"\"\"\n\n-    def __init__(self, stream: 'TokenStream') -&gt;None:\n+    def __init__(self, stream: \"TokenStream\") -&gt; None:\n         self.stream = stream\n\n-    def __iter__(self) -&gt;'TokenStreamIterator':\n+    def __iter__(self) -&gt; \"TokenStreamIterator\":\n         return self\n\n-    def __next__(self) -&gt;Token:\n+    def __next__(self) -&gt; Token:\n         token = self.stream.current\n+\n         if token.type is TOKEN_EOF:\n             self.stream.close()\n             raise StopIteration\n+\n         next(self.stream)\n         return token\n\n@@ -197,55 +322,68 @@ class TokenStream:\n     one token ahead.  The current active token is stored as :attr:`current`.\n     \"\"\"\n\n-    def __init__(self, generator: t.Iterable[Token], name: t.Optional[str],\n-        filename: t.Optional[str]):\n+    def __init__(\n+        self,\n+        generator: t.Iterable[Token],\n+        name: t.Optional[str],\n+        filename: t.Optional[str],\n+    ):\n         self._iter = iter(generator)\n-        self._pushed: 'te.Deque[Token]' = deque()\n+        self._pushed: \"te.Deque[Token]\" = deque()\n         self.name = name\n         self.filename = filename\n         self.closed = False\n-        self.current = Token(1, TOKEN_INITIAL, '')\n+        self.current = Token(1, TOKEN_INITIAL, \"\")\n         next(self)\n\n-    def __iter__(self) -&gt;TokenStreamIterator:\n+    def __iter__(self) -&gt; TokenStreamIterator:\n         return TokenStreamIterator(self)\n\n-    def __bool__(self) -&gt;bool:\n+    def __bool__(self) -&gt; bool:\n         return bool(self._pushed) or self.current.type is not TOKEN_EOF\n\n     @property\n-    def eos(self) -&gt;bool:\n+    def eos(self) -&gt; bool:\n         \"\"\"Are we at the end of the stream?\"\"\"\n-        pass\n+        return not self\n\n-    def push(self, token: Token) -&gt;None:\n+    def push(self, token: Token) -&gt; None:\n         \"\"\"Push a token back to the stream.\"\"\"\n-        pass\n+        self._pushed.append(token)\n\n-    def look(self) -&gt;Token:\n+    def look(self) -&gt; Token:\n         \"\"\"Look at the next token.\"\"\"\n-        pass\n+        old_token = next(self)\n+        result = self.current\n+        self.push(result)\n+        self.current = old_token\n+        return result\n\n-    def skip(self, n: int=1) -&gt;None:\n+    def skip(self, n: int = 1) -&gt; None:\n         \"\"\"Got n tokens ahead.\"\"\"\n-        pass\n+        for _ in range(n):\n+            next(self)\n\n-    def next_if(self, expr: str) -&gt;t.Optional[Token]:\n+    def next_if(self, expr: str) -&gt; t.Optional[Token]:\n         \"\"\"Perform the token test and return the token if it matched.\n         Otherwise the return value is `None`.\n         \"\"\"\n-        pass\n+        if self.current.test(expr):\n+            return next(self)\n+\n+        return None\n\n-    def skip_if(self, expr: str) -&gt;bool:\n+    def skip_if(self, expr: str) -&gt; bool:\n         \"\"\"Like :meth:`next_if` but only returns `True` or `False`.\"\"\"\n-        pass\n+        return self.next_if(expr) is not None\n\n-    def __next__(self) -&gt;Token:\n+    def __next__(self) -&gt; Token:\n         \"\"\"Go one token ahead and return the old one.\n\n         Use the built-in :func:`next` instead of calling this directly.\n         \"\"\"\n         rv = self.current\n+\n         if self._pushed:\n             self.current = self._pushed.popleft()\n         elif self.current.type is not TOKEN_EOF:\n@@ -253,31 +391,74 @@ class TokenStream:\n                 self.current = next(self._iter)\n             except StopIteration:\n                 self.close()\n+\n         return rv\n\n-    def close(self) -&gt;None:\n+    def close(self) -&gt; None:\n         \"\"\"Close the stream.\"\"\"\n-        pass\n+        self.current = Token(self.current.lineno, TOKEN_EOF, \"\")\n+        self._iter = iter(())\n+        self.closed = True\n\n-    def expect(self, expr: str) -&gt;Token:\n+    def expect(self, expr: str) -&gt; Token:\n         \"\"\"Expect a given token type and return it.  This accepts the same\n         argument as :meth:`jinja2.lexer.Token.test`.\n         \"\"\"\n-        pass\n+        if not self.current.test(expr):\n+            expr = describe_token_expr(expr)\n+\n+            if self.current.type is TOKEN_EOF:\n+                raise TemplateSyntaxError(\n+                    f\"unexpected end of template, expected {expr!r}.\",\n+                    self.current.lineno,\n+                    self.name,\n+                    self.filename,\n+                )\n+\n+            raise TemplateSyntaxError(\n+                f\"expected token {expr!r}, got {describe_token(self.current)!r}\",\n+                self.current.lineno,\n+                self.name,\n+                self.filename,\n+            )\n\n+        return next(self)\n\n-def get_lexer(environment: 'Environment') -&gt;'Lexer':\n+\n+def get_lexer(environment: \"Environment\") -&gt; \"Lexer\":\n     \"\"\"Return a lexer which is probably cached.\"\"\"\n-    pass\n+    key = (\n+        environment.block_start_string,\n+        environment.block_end_string,\n+        environment.variable_start_string,\n+        environment.variable_end_string,\n+        environment.comment_start_string,\n+        environment.comment_end_string,\n+        environment.line_statement_prefix,\n+        environment.line_comment_prefix,\n+        environment.trim_blocks,\n+        environment.lstrip_blocks,\n+        environment.newline_sequence,\n+        environment.keep_trailing_newline,\n+    )\n+    lexer = _lexer_cache.get(key)\n+\n+    if lexer is None:\n+        _lexer_cache[key] = lexer = Lexer(environment)\n\n+    return lexer\n\n-class OptionalLStrip(tuple):\n+\n+class OptionalLStrip(tuple):  # type: ignore[type-arg]\n     \"\"\"A special tuple for marking a point in the state that can have\n     lstrip applied.\n     \"\"\"\n+\n     __slots__ = ()\n\n-    def __new__(cls, *members, **kwargs):\n+    # Even though it looks like a no-op, creating instances fails\n+    # without this.\n+    def __new__(cls, *members, **kwargs):  # type: ignore\n         return super().__new__(cls, members)\n\n\n@@ -295,73 +476,203 @@ class Lexer:\n     Multiple environments can share the same lexer.\n     \"\"\"\n\n-    def __init__(self, environment: 'Environment') -&gt;None:\n+    def __init__(self, environment: \"Environment\") -&gt; None:\n+        # shortcuts\n         e = re.escape\n\n-        def c(x: str) -&gt;t.Pattern[str]:\n+        def c(x: str) -&gt; t.Pattern[str]:\n             return re.compile(x, re.M | re.S)\n-        tag_rules: t.List[_Rule] = [_Rule(whitespace_re, TOKEN_WHITESPACE,\n-            None), _Rule(float_re, TOKEN_FLOAT, None), _Rule(integer_re,\n-            TOKEN_INTEGER, None), _Rule(name_re, TOKEN_NAME, None), _Rule(\n-            string_re, TOKEN_STRING, None), _Rule(operator_re,\n-            TOKEN_OPERATOR, None)]\n+\n+        # lexing rules for tags\n+        tag_rules: t.List[_Rule] = [\n+            _Rule(whitespace_re, TOKEN_WHITESPACE, None),\n+            _Rule(float_re, TOKEN_FLOAT, None),\n+            _Rule(integer_re, TOKEN_INTEGER, None),\n+            _Rule(name_re, TOKEN_NAME, None),\n+            _Rule(string_re, TOKEN_STRING, None),\n+            _Rule(operator_re, TOKEN_OPERATOR, None),\n+        ]\n+\n+        # assemble the root lexing rule. because \"|\" is ungreedy\n+        # we have to sort by length so that the lexer continues working\n+        # as expected when we have parsing rules like &lt;% for block and\n+        # &lt;%= for variables. (if someone wants asp like syntax)\n+        # variables are just part of the rules if variable processing\n+        # is required.\n         root_tag_rules = compile_rules(environment)\n+\n         block_start_re = e(environment.block_start_string)\n         block_end_re = e(environment.block_end_string)\n         comment_end_re = e(environment.comment_end_string)\n         variable_end_re = e(environment.variable_end_string)\n-        block_suffix_re = '\\\\n?' if environment.trim_blocks else ''\n+\n+        # block suffix if trimming is enabled\n+        block_suffix_re = \"\\\\n?\" if environment.trim_blocks else \"\"\n+\n         self.lstrip_blocks = environment.lstrip_blocks\n+\n         self.newline_sequence = environment.newline_sequence\n         self.keep_trailing_newline = environment.keep_trailing_newline\n+\n         root_raw_re = (\n-            f'(?P&lt;raw_begin&gt;{block_start_re}(\\\\-|\\\\+|)\\\\s*raw\\\\s*(?:\\\\-{block_end_re}\\\\s*|{block_end_re}))'\n-            )\n-        root_parts_re = '|'.join([root_raw_re] + [f'(?P&lt;{n}&gt;{r}(\\\\-|\\\\+|))' for\n-            n, r in root_tag_rules])\n-        self.rules: t.Dict[str, t.List[_Rule]] = {'root': [_Rule(c(\n-            f'(.*?)(?:{root_parts_re})'), OptionalLStrip(TOKEN_DATA,\n-            '#bygroup'), '#bygroup'), _Rule(c('.+'), TOKEN_DATA, None)],\n-            TOKEN_COMMENT_BEGIN: [_Rule(c(\n-            f'(.*?)((?:\\\\+{comment_end_re}|\\\\-{comment_end_re}\\\\s*|{comment_end_re}{block_suffix_re}))'\n-            ), (TOKEN_COMMENT, TOKEN_COMMENT_END), '#pop'), _Rule(c('(.)'),\n-            (Failure('Missing end of comment tag'),), None)],\n-            TOKEN_BLOCK_BEGIN: [_Rule(c(\n-            f'(?:\\\\+{block_end_re}|\\\\-{block_end_re}\\\\s*|{block_end_re}{block_suffix_re})'\n-            ), TOKEN_BLOCK_END, '#pop')] + tag_rules, TOKEN_VARIABLE_BEGIN:\n-            [_Rule(c(f'\\\\-{variable_end_re}\\\\s*|{variable_end_re}'),\n-            TOKEN_VARIABLE_END, '#pop')] + tag_rules, TOKEN_RAW_BEGIN: [\n-            _Rule(c(\n-            f'(.*?)((?:{block_start_re}(\\\\-|\\\\+|))\\\\s*endraw\\\\s*(?:\\\\+{block_end_re}|\\\\-{block_end_re}\\\\s*|{block_end_re}{block_suffix_re}))'\n-            ), OptionalLStrip(TOKEN_DATA, TOKEN_RAW_END), '#pop'), _Rule(c(\n-            '(.)'), (Failure('Missing end of raw directive'),), None)],\n-            TOKEN_LINESTATEMENT_BEGIN: [_Rule(c('\\\\s*(\\\\n|$)'),\n-            TOKEN_LINESTATEMENT_END, '#pop')] + tag_rules,\n-            TOKEN_LINECOMMENT_BEGIN: [_Rule(c('(.*?)()(?=\\\\n|$)'), (\n-            TOKEN_LINECOMMENT, TOKEN_LINECOMMENT_END), '#pop')]}\n-\n-    def _normalize_newlines(self, value: str) -&gt;str:\n+            rf\"(?P&lt;raw_begin&gt;{block_start_re}(\\-|\\+|)\\s*raw\\s*\"\n+            rf\"(?:\\-{block_end_re}\\s*|{block_end_re}))\"\n+        )\n+        root_parts_re = \"|\".join(\n+            [root_raw_re] + [rf\"(?P&lt;{n}&gt;{r}(\\-|\\+|))\" for n, r in root_tag_rules]\n+        )\n+\n+        # global lexing rules\n+        self.rules: t.Dict[str, t.List[_Rule]] = {\n+            \"root\": [\n+                # directives\n+                _Rule(\n+                    c(rf\"(.*?)(?:{root_parts_re})\"),\n+                    OptionalLStrip(TOKEN_DATA, \"#bygroup\"),  # type: ignore\n+                    \"#bygroup\",\n+                ),\n+                # data\n+                _Rule(c(\".+\"), TOKEN_DATA, None),\n+            ],\n+            # comments\n+            TOKEN_COMMENT_BEGIN: [\n+                _Rule(\n+                    c(\n+                        rf\"(.*?)((?:\\+{comment_end_re}|\\-{comment_end_re}\\s*\"\n+                        rf\"|{comment_end_re}{block_suffix_re}))\"\n+                    ),\n+                    (TOKEN_COMMENT, TOKEN_COMMENT_END),\n+                    \"#pop\",\n+                ),\n+                _Rule(c(r\"(.)\"), (Failure(\"Missing end of comment tag\"),), None),\n+            ],\n+            # blocks\n+            TOKEN_BLOCK_BEGIN: [\n+                _Rule(\n+                    c(\n+                        rf\"(?:\\+{block_end_re}|\\-{block_end_re}\\s*\"\n+                        rf\"|{block_end_re}{block_suffix_re})\"\n+                    ),\n+                    TOKEN_BLOCK_END,\n+                    \"#pop\",\n+                ),\n+            ]\n+            + tag_rules,\n+            # variables\n+            TOKEN_VARIABLE_BEGIN: [\n+                _Rule(\n+                    c(rf\"\\-{variable_end_re}\\s*|{variable_end_re}\"),\n+                    TOKEN_VARIABLE_END,\n+                    \"#pop\",\n+                )\n+            ]\n+            + tag_rules,\n+            # raw block\n+            TOKEN_RAW_BEGIN: [\n+                _Rule(\n+                    c(\n+                        rf\"(.*?)((?:{block_start_re}(\\-|\\+|))\\s*endraw\\s*\"\n+                        rf\"(?:\\+{block_end_re}|\\-{block_end_re}\\s*\"\n+                        rf\"|{block_end_re}{block_suffix_re}))\"\n+                    ),\n+                    OptionalLStrip(TOKEN_DATA, TOKEN_RAW_END),  # type: ignore\n+                    \"#pop\",\n+                ),\n+                _Rule(c(r\"(.)\"), (Failure(\"Missing end of raw directive\"),), None),\n+            ],\n+            # line statements\n+            TOKEN_LINESTATEMENT_BEGIN: [\n+                _Rule(c(r\"\\s*(\\n|$)\"), TOKEN_LINESTATEMENT_END, \"#pop\")\n+            ]\n+            + tag_rules,\n+            # line comments\n+            TOKEN_LINECOMMENT_BEGIN: [\n+                _Rule(\n+                    c(r\"(.*?)()(?=\\n|$)\"),\n+                    (TOKEN_LINECOMMENT, TOKEN_LINECOMMENT_END),\n+                    \"#pop\",\n+                )\n+            ],\n+        }\n+\n+    def _normalize_newlines(self, value: str) -&gt; str:\n         \"\"\"Replace all newlines with the configured sequence in strings\n         and template data.\n         \"\"\"\n-        pass\n-\n-    def tokenize(self, source: str, name: t.Optional[str]=None, filename: t\n-        .Optional[str]=None, state: t.Optional[str]=None) -&gt;TokenStream:\n+        return newline_re.sub(self.newline_sequence, value)\n+\n+    def tokenize(\n+        self,\n+        source: str,\n+        name: t.Optional[str] = None,\n+        filename: t.Optional[str] = None,\n+        state: t.Optional[str] = None,\n+    ) -&gt; TokenStream:\n         \"\"\"Calls tokeniter + tokenize and wraps it in a token stream.\"\"\"\n-        pass\n-\n-    def wrap(self, stream: t.Iterable[t.Tuple[int, str, str]], name: t.\n-        Optional[str]=None, filename: t.Optional[str]=None) -&gt;t.Iterator[Token\n-        ]:\n+        stream = self.tokeniter(source, name, filename, state)\n+        return TokenStream(self.wrap(stream, name, filename), name, filename)\n+\n+    def wrap(\n+        self,\n+        stream: t.Iterable[t.Tuple[int, str, str]],\n+        name: t.Optional[str] = None,\n+        filename: t.Optional[str] = None,\n+    ) -&gt; t.Iterator[Token]:\n         \"\"\"This is called with the stream as returned by `tokenize` and wraps\n         every token in a :class:`Token` and converts the value.\n         \"\"\"\n-        pass\n-\n-    def tokeniter(self, source: str, name: t.Optional[str], filename: t.\n-        Optional[str]=None, state: t.Optional[str]=None) -&gt;t.Iterator[t.\n-        Tuple[int, str, str]]:\n+        for lineno, token, value_str in stream:\n+            if token in ignored_tokens:\n+                continue\n+\n+            value: t.Any = value_str\n+\n+            if token == TOKEN_LINESTATEMENT_BEGIN:\n+                token = TOKEN_BLOCK_BEGIN\n+            elif token == TOKEN_LINESTATEMENT_END:\n+                token = TOKEN_BLOCK_END\n+            # we are not interested in those tokens in the parser\n+            elif token in (TOKEN_RAW_BEGIN, TOKEN_RAW_END):\n+                continue\n+            elif token == TOKEN_DATA:\n+                value = self._normalize_newlines(value_str)\n+            elif token == \"keyword\":\n+                token = value_str\n+            elif token == TOKEN_NAME:\n+                value = value_str\n+\n+                if not value.isidentifier():\n+                    raise TemplateSyntaxError(\n+                        \"Invalid character in identifier\", lineno, name, filename\n+                    )\n+            elif token == TOKEN_STRING:\n+                # try to unescape string\n+                try:\n+                    value = (\n+                        self._normalize_newlines(value_str[1:-1])\n+                        .encode(\"ascii\", \"backslashreplace\")\n+                        .decode(\"unicode-escape\")\n+                    )\n+                except Exception as e:\n+                    msg = str(e).split(\":\")[-1].strip()\n+                    raise TemplateSyntaxError(msg, lineno, name, filename) from e\n+            elif token == TOKEN_INTEGER:\n+                value = int(value_str.replace(\"_\", \"\"), 0)\n+            elif token == TOKEN_FLOAT:\n+                # remove all \"_\" first to support more Python versions\n+                value = literal_eval(value_str.replace(\"_\", \"\"))\n+            elif token == TOKEN_OPERATOR:\n+                token = operators[value_str]\n+\n+            yield Token(lineno, token, value)\n+\n+    def tokeniter(\n+        self,\n+        source: str,\n+        name: t.Optional[str],\n+        filename: t.Optional[str] = None,\n+        state: t.Optional[str] = None,\n+    ) -&gt; t.Iterator[t.Tuple[int, str, str]]:\n         \"\"\"This method tokenizes the text and returns the tokens in a\n         generator. Use this method if you just want to tokenize a template.\n\n@@ -369,4 +680,189 @@ class Lexer:\n             Only ``\\\\n``, ``\\\\r\\\\n`` and ``\\\\r`` are treated as line\n             breaks.\n         \"\"\"\n-        pass\n+        lines = newline_re.split(source)[::2]\n+\n+        if not self.keep_trailing_newline and lines[-1] == \"\":\n+            del lines[-1]\n+\n+        source = \"\\n\".join(lines)\n+        pos = 0\n+        lineno = 1\n+        stack = [\"root\"]\n+\n+        if state is not None and state != \"root\":\n+            assert state in (\"variable\", \"block\"), \"invalid state\"\n+            stack.append(state + \"_begin\")\n+\n+        statetokens = self.rules[stack[-1]]\n+        source_length = len(source)\n+        balancing_stack: t.List[str] = []\n+        newlines_stripped = 0\n+        line_starting = True\n+\n+        while True:\n+            # tokenizer loop\n+            for regex, tokens, new_state in statetokens:\n+                m = regex.match(source, pos)\n+\n+                # if no match we try again with the next rule\n+                if m is None:\n+                    continue\n+\n+                # we only match blocks and variables if braces / parentheses\n+                # are balanced. continue parsing with the lower rule which\n+                # is the operator rule. do this only if the end tags look\n+                # like operators\n+                if balancing_stack and tokens in (\n+                    TOKEN_VARIABLE_END,\n+                    TOKEN_BLOCK_END,\n+                    TOKEN_LINESTATEMENT_END,\n+                ):\n+                    continue\n+\n+                # tuples support more options\n+                if isinstance(tokens, tuple):\n+                    groups: t.Sequence[str] = m.groups()\n+\n+                    if isinstance(tokens, OptionalLStrip):\n+                        # Rule supports lstrip. Match will look like\n+                        # text, block type, whitespace control, type, control, ...\n+                        text = groups[0]\n+                        # Skipping the text and first type, every other group is the\n+                        # whitespace control for each type. One of the groups will be\n+                        # -, +, or empty string instead of None.\n+                        strip_sign = next(g for g in groups[2::2] if g is not None)\n+\n+                        if strip_sign == \"-\":\n+                            # Strip all whitespace between the text and the tag.\n+                            stripped = text.rstrip()\n+                            newlines_stripped = text[len(stripped) :].count(\"\\n\")\n+                            groups = [stripped, *groups[1:]]\n+                        elif (\n+                            # Not marked for preserving whitespace.\n+                            strip_sign != \"+\"\n+                            # lstrip is enabled.\n+                            and self.lstrip_blocks\n+                            # Not a variable expression.\n+                            and not m.groupdict().get(TOKEN_VARIABLE_BEGIN)\n+                        ):\n+                            # The start of text between the last newline and the tag.\n+                            l_pos = text.rfind(\"\\n\") + 1\n+\n+                            if l_pos &gt; 0 or line_starting:\n+                                # If there's only whitespace between the newline and the\n+                                # tag, strip it.\n+                                if whitespace_re.fullmatch(text, l_pos):\n+                                    groups = [text[:l_pos], *groups[1:]]\n+\n+                    for idx, token in enumerate(tokens):\n+                        # failure group\n+                        if token.__class__ is Failure:\n+                            raise token(lineno, filename)\n+                        # bygroup is a bit more complex, in that case we\n+                        # yield for the current token the first named\n+                        # group that matched\n+                        elif token == \"#bygroup\":\n+                            for key, value in m.groupdict().items():\n+                                if value is not None:\n+                                    yield lineno, key, value\n+                                    lineno += value.count(\"\\n\")\n+                                    break\n+                            else:\n+                                raise RuntimeError(\n+                                    f\"{regex!r} wanted to resolve the token dynamically\"\n+                                    \" but no group matched\"\n+                                )\n+                        # normal group\n+                        else:\n+                            data = groups[idx]\n+\n+                            if data or token not in ignore_if_empty:\n+                                yield lineno, token, data\n+\n+                            lineno += data.count(\"\\n\") + newlines_stripped\n+                            newlines_stripped = 0\n+\n+                # strings as token just are yielded as it.\n+                else:\n+                    data = m.group()\n+\n+                    # update brace/parentheses balance\n+                    if tokens == TOKEN_OPERATOR:\n+                        if data == \"{\":\n+                            balancing_stack.append(\"}\")\n+                        elif data == \"(\":\n+                            balancing_stack.append(\")\")\n+                        elif data == \"[\":\n+                            balancing_stack.append(\"]\")\n+                        elif data in (\"}\", \")\", \"]\"):\n+                            if not balancing_stack:\n+                                raise TemplateSyntaxError(\n+                                    f\"unexpected '{data}'\", lineno, name, filename\n+                                )\n+\n+                            expected_op = balancing_stack.pop()\n+\n+                            if expected_op != data:\n+                                raise TemplateSyntaxError(\n+                                    f\"unexpected '{data}', expected '{expected_op}'\",\n+                                    lineno,\n+                                    name,\n+                                    filename,\n+                                )\n+\n+                    # yield items\n+                    if data or tokens not in ignore_if_empty:\n+                        yield lineno, tokens, data\n+\n+                    lineno += data.count(\"\\n\")\n+\n+                line_starting = m.group()[-1:] == \"\\n\"\n+                # fetch new position into new variable so that we can check\n+                # if there is a internal parsing error which would result\n+                # in an infinite loop\n+                pos2 = m.end()\n+\n+                # handle state changes\n+                if new_state is not None:\n+                    # remove the uppermost state\n+                    if new_state == \"#pop\":\n+                        stack.pop()\n+                    # resolve the new state by group checking\n+                    elif new_state == \"#bygroup\":\n+                        for key, value in m.groupdict().items():\n+                            if value is not None:\n+                                stack.append(key)\n+                                break\n+                        else:\n+                            raise RuntimeError(\n+                                f\"{regex!r} wanted to resolve the new state dynamically\"\n+                                f\" but no group matched\"\n+                            )\n+                    # direct state name given\n+                    else:\n+                        stack.append(new_state)\n+\n+                    statetokens = self.rules[stack[-1]]\n+                # we are still at the same position and no stack change.\n+                # this means a loop without break condition, avoid that and\n+                # raise error\n+                elif pos2 == pos:\n+                    raise RuntimeError(\n+                        f\"{regex!r} yielded empty string without stack change\"\n+                    )\n+\n+                # publish new function and start again\n+                pos = pos2\n+                break\n+            # if loop terminated without break we haven't found a single match\n+            # either we are at the end of the file or we have a problem\n+            else:\n+                # end of text\n+                if pos &gt;= source_length:\n+                    return\n+\n+                # something went wrong\n+                raise TemplateSyntaxError(\n+                    f\"unexpected char {source[pos]!r} at {pos}\", lineno, name, filename\n+                )\ndiff --git a/src/jinja2/loaders.py b/src/jinja2/loaders.py\nindex f336510..9eaf647 100644\n--- a/src/jinja2/loaders.py\n+++ b/src/jinja2/loaders.py\n@@ -1,6 +1,7 @@\n \"\"\"API and implementations for loading templates from different data\n sources.\n \"\"\"\n+\n import importlib.util\n import os\n import posixpath\n@@ -12,18 +13,30 @@ from collections import abc\n from hashlib import sha1\n from importlib import import_module\n from types import ModuleType\n+\n from .exceptions import TemplateNotFound\n from .utils import internalcode\n+\n if t.TYPE_CHECKING:\n     from .environment import Environment\n     from .environment import Template\n\n\n-def split_template_path(template: str) -&gt;t.List[str]:\n+def split_template_path(template: str) -&gt; t.List[str]:\n     \"\"\"Split a path into segments and perform a sanity check.  If it detects\n     '..' in the path it will raise a `TemplateNotFound` error.\n     \"\"\"\n-    pass\n+    pieces = []\n+    for piece in template.split(\"/\"):\n+        if (\n+            os.path.sep in piece\n+            or (os.path.altsep and os.path.altsep in piece)\n+            or piece == os.path.pardir\n+        ):\n+            raise TemplateNotFound(template)\n+        elif piece and piece != \".\":\n+            pieces.append(piece)\n+    return pieces\n\n\n class BaseLoader:\n@@ -52,10 +65,16 @@ class BaseLoader:\n                     source = f.read()\n                 return source, path, lambda: mtime == getmtime(path)\n     \"\"\"\n+\n+    #: if set to `False` it indicates that the loader cannot provide access\n+    #: to the source of templates.\n+    #:\n+    #: .. versionadded:: 2.4\n     has_source_access = True\n\n-    def get_source(self, environment: 'Environment', template: str) -&gt;t.Tuple[\n-        str, t.Optional[str], t.Optional[t.Callable[[], bool]]]:\n+    def get_source(\n+        self, environment: \"Environment\", template: str\n+    ) -&gt; t.Tuple[str, t.Optional[str], t.Optional[t.Callable[[], bool]]]:\n         \"\"\"Get the template source, filename and reload helper for a template.\n         It's passed the environment and template name and has to return a\n         tuple in the form ``(source, filename, uptodate)`` or raise a\n@@ -73,24 +92,61 @@ class BaseLoader:\n         old state somewhere (for example in a closure).  If it returns `False`\n         the template will be reloaded.\n         \"\"\"\n-        pass\n+        if not self.has_source_access:\n+            raise RuntimeError(\n+                f\"{type(self).__name__} cannot provide access to the source\"\n+            )\n+        raise TemplateNotFound(template)\n\n-    def list_templates(self) -&gt;t.List[str]:\n+    def list_templates(self) -&gt; t.List[str]:\n         \"\"\"Iterates over all templates.  If the loader does not support that\n         it should raise a :exc:`TypeError` which is the default behavior.\n         \"\"\"\n-        pass\n+        raise TypeError(\"this loader cannot iterate over all templates\")\n\n     @internalcode\n-    def load(self, environment: 'Environment', name: str, globals: t.\n-        Optional[t.MutableMapping[str, t.Any]]=None) -&gt;'Template':\n+    def load(\n+        self,\n+        environment: \"Environment\",\n+        name: str,\n+        globals: t.Optional[t.MutableMapping[str, t.Any]] = None,\n+    ) -&gt; \"Template\":\n         \"\"\"Loads a template.  This method looks up the template in the cache\n         or loads one by calling :meth:`get_source`.  Subclasses should not\n         override this method as loaders working on collections of other\n         loaders (such as :class:`PrefixLoader` or :class:`ChoiceLoader`)\n         will not call this method but `get_source` directly.\n         \"\"\"\n-        pass\n+        code = None\n+        if globals is None:\n+            globals = {}\n+\n+        # first we try to get the source for this template together\n+        # with the filename and the uptodate function.\n+        source, filename, uptodate = self.get_source(environment, name)\n+\n+        # try to load the code from the bytecode cache if there is a\n+        # bytecode cache configured.\n+        bcc = environment.bytecode_cache\n+        if bcc is not None:\n+            bucket = bcc.get_bucket(environment, name, filename, source)\n+            code = bucket.code\n+\n+        # if we don't have code so far (not cached, no longer up to\n+        # date) etc. we compile the template\n+        if code is None:\n+            code = environment.compile(source, name, filename)\n+\n+        # if the bytecode cache is available and the bucket doesn't\n+        # have a code so far, we give the bucket the new code and put\n+        # it back to the bytecode cache.\n+        if bcc is not None and bucket.code is None:\n+            bucket.code = code\n+            bcc.set_bucket(bucket)\n+\n+        return environment.template_class.from_code(\n+            environment, code, globals, uptodate\n+        )\n\n\n class FileSystemLoader(BaseLoader):\n@@ -120,16 +176,67 @@ class FileSystemLoader(BaseLoader):\n         Added the ``followlinks`` parameter.\n     \"\"\"\n\n-    def __init__(self, searchpath: t.Union[str, 'os.PathLike[str]', t.\n-        Sequence[t.Union[str, 'os.PathLike[str]']]], encoding: str='utf-8',\n-        followlinks: bool=False) -&gt;None:\n-        if not isinstance(searchpath, abc.Iterable) or isinstance(searchpath,\n-            str):\n+    def __init__(\n+        self,\n+        searchpath: t.Union[\n+            str, \"os.PathLike[str]\", t.Sequence[t.Union[str, \"os.PathLike[str]\"]]\n+        ],\n+        encoding: str = \"utf-8\",\n+        followlinks: bool = False,\n+    ) -&gt; None:\n+        if not isinstance(searchpath, abc.Iterable) or isinstance(searchpath, str):\n             searchpath = [searchpath]\n+\n         self.searchpath = [os.fspath(p) for p in searchpath]\n         self.encoding = encoding\n         self.followlinks = followlinks\n\n+    def get_source(\n+        self, environment: \"Environment\", template: str\n+    ) -&gt; t.Tuple[str, str, t.Callable[[], bool]]:\n+        pieces = split_template_path(template)\n+\n+        for searchpath in self.searchpath:\n+            # Use posixpath even on Windows to avoid \"drive:\" or UNC\n+            # segments breaking out of the search directory.\n+            filename = posixpath.join(searchpath, *pieces)\n+\n+            if os.path.isfile(filename):\n+                break\n+        else:\n+            raise TemplateNotFound(template)\n+\n+        with open(filename, encoding=self.encoding) as f:\n+            contents = f.read()\n+\n+        mtime = os.path.getmtime(filename)\n+\n+        def uptodate() -&gt; bool:\n+            try:\n+                return os.path.getmtime(filename) == mtime\n+            except OSError:\n+                return False\n+\n+        # Use normpath to convert Windows altsep to sep.\n+        return contents, os.path.normpath(filename), uptodate\n+\n+    def list_templates(self) -&gt; t.List[str]:\n+        found = set()\n+        for searchpath in self.searchpath:\n+            walk_dir = os.walk(searchpath, followlinks=self.followlinks)\n+            for dirpath, _, filenames in walk_dir:\n+                for filename in filenames:\n+                    template = (\n+                        os.path.join(dirpath, filename)[len(searchpath) :]\n+                        .strip(os.path.sep)\n+                        .replace(os.path.sep, \"/\")\n+                    )\n+                    if template[:2] == \"./\":\n+                        template = template[2:]\n+                    if template not in found:\n+                        found.add(template)\n+        return sorted(found)\n+\n\n class PackageLoader(BaseLoader):\n     \"\"\"Load templates from a directory in a Python package.\n@@ -164,46 +271,138 @@ class PackageLoader(BaseLoader):\n         Limited PEP 420 namespace package support.\n     \"\"\"\n\n-    def __init__(self, package_name: str, package_path: 'str'='templates',\n-        encoding: str='utf-8') -&gt;None:\n+    def __init__(\n+        self,\n+        package_name: str,\n+        package_path: \"str\" = \"templates\",\n+        encoding: str = \"utf-8\",\n+    ) -&gt; None:\n         package_path = os.path.normpath(package_path).rstrip(os.path.sep)\n+\n+        # normpath preserves \".\", which isn't valid in zip paths.\n         if package_path == os.path.curdir:\n-            package_path = ''\n+            package_path = \"\"\n         elif package_path[:2] == os.path.curdir + os.path.sep:\n             package_path = package_path[2:]\n+\n         self.package_path = package_path\n         self.package_name = package_name\n         self.encoding = encoding\n+\n+        # Make sure the package exists. This also makes namespace\n+        # packages work, otherwise get_loader returns None.\n         import_module(package_name)\n         spec = importlib.util.find_spec(package_name)\n-        assert spec is not None, 'An import spec was not found for the package.'\n+        assert spec is not None, \"An import spec was not found for the package.\"\n         loader = spec.loader\n-        assert loader is not None, 'A loader was not found for the package.'\n+        assert loader is not None, \"A loader was not found for the package.\"\n         self._loader = loader\n         self._archive = None\n         template_root = None\n+\n         if isinstance(loader, zipimport.zipimporter):\n             self._archive = loader.archive\n-            pkgdir = next(iter(spec.submodule_search_locations))\n-            template_root = os.path.join(pkgdir, package_path).rstrip(os.\n-                path.sep)\n+            pkgdir = next(iter(spec.submodule_search_locations))  # type: ignore\n+            template_root = os.path.join(pkgdir, package_path).rstrip(os.path.sep)\n         else:\n             roots: t.List[str] = []\n+\n+            # One element for regular packages, multiple for namespace\n+            # packages, or None for single module file.\n             if spec.submodule_search_locations:\n                 roots.extend(spec.submodule_search_locations)\n+            # A single module file, use the parent directory instead.\n             elif spec.origin is not None:\n                 roots.append(os.path.dirname(spec.origin))\n+\n             for root in roots:\n                 root = os.path.join(root, package_path)\n+\n                 if os.path.isdir(root):\n                     template_root = root\n                     break\n+\n         if template_root is None:\n             raise ValueError(\n-                f'The {package_name!r} package was not installed in a way that PackageLoader understands.'\n-                )\n+                f\"The {package_name!r} package was not installed in a\"\n+                \" way that PackageLoader understands.\"\n+            )\n+\n         self._template_root = template_root\n\n+    def get_source(\n+        self, environment: \"Environment\", template: str\n+    ) -&gt; t.Tuple[str, str, t.Optional[t.Callable[[], bool]]]:\n+        # Use posixpath even on Windows to avoid \"drive:\" or UNC\n+        # segments breaking out of the search directory. Use normpath to\n+        # convert Windows altsep to sep.\n+        p = os.path.normpath(\n+            posixpath.join(self._template_root, *split_template_path(template))\n+        )\n+        up_to_date: t.Optional[t.Callable[[], bool]]\n+\n+        if self._archive is None:\n+            # Package is a directory.\n+            if not os.path.isfile(p):\n+                raise TemplateNotFound(template)\n+\n+            with open(p, \"rb\") as f:\n+                source = f.read()\n+\n+            mtime = os.path.getmtime(p)\n+\n+            def up_to_date() -&gt; bool:\n+                return os.path.isfile(p) and os.path.getmtime(p) == mtime\n+\n+        else:\n+            # Package is a zip file.\n+            try:\n+                source = self._loader.get_data(p)  # type: ignore\n+            except OSError as e:\n+                raise TemplateNotFound(template) from e\n+\n+            # Could use the zip's mtime for all template mtimes, but\n+            # would need to safely reload the module if it's out of\n+            # date, so just report it as always current.\n+            up_to_date = None\n+\n+        return source.decode(self.encoding), p, up_to_date\n+\n+    def list_templates(self) -&gt; t.List[str]:\n+        results: t.List[str] = []\n+\n+        if self._archive is None:\n+            # Package is a directory.\n+            offset = len(self._template_root)\n+\n+            for dirpath, _, filenames in os.walk(self._template_root):\n+                dirpath = dirpath[offset:].lstrip(os.path.sep)\n+                results.extend(\n+                    os.path.join(dirpath, name).replace(os.path.sep, \"/\")\n+                    for name in filenames\n+                )\n+        else:\n+            if not hasattr(self._loader, \"_files\"):\n+                raise TypeError(\n+                    \"This zip import does not have the required\"\n+                    \" metadata to list templates.\"\n+                )\n+\n+            # Package is a zip file.\n+            prefix = (\n+                self._template_root[len(self._archive) :].lstrip(os.path.sep)\n+                + os.path.sep\n+            )\n+            offset = len(prefix)\n+\n+            for name in self._loader._files.keys():\n+                # Find names under the templates directory that aren't directories.\n+                if name.startswith(prefix) and name[-1] != os.path.sep:\n+                    results.append(name[offset:].replace(os.path.sep, \"/\"))\n+\n+        results.sort()\n+        return results\n+\n\n class DictLoader(BaseLoader):\n     \"\"\"Loads a template from a Python dict mapping template names to\n@@ -214,9 +413,20 @@ class DictLoader(BaseLoader):\n     Because auto reloading is rarely useful this is disabled per default.\n     \"\"\"\n\n-    def __init__(self, mapping: t.Mapping[str, str]) -&gt;None:\n+    def __init__(self, mapping: t.Mapping[str, str]) -&gt; None:\n         self.mapping = mapping\n\n+    def get_source(\n+        self, environment: \"Environment\", template: str\n+    ) -&gt; t.Tuple[str, None, t.Callable[[], bool]]:\n+        if template in self.mapping:\n+            source = self.mapping[template]\n+            return source, None, lambda: source == self.mapping.get(template)\n+        raise TemplateNotFound(template)\n+\n+    def list_templates(self) -&gt; t.List[str]:\n+        return sorted(self.mapping)\n+\n\n class FunctionLoader(BaseLoader):\n     \"\"\"A loader that is passed a function which does the loading.  The\n@@ -236,11 +446,32 @@ class FunctionLoader(BaseLoader):\n     return value.\n     \"\"\"\n\n-    def __init__(self, load_func: t.Callable[[str], t.Optional[t.Union[str,\n-        t.Tuple[str, t.Optional[str], t.Optional[t.Callable[[], bool]]]]]]\n-        ) -&gt;None:\n+    def __init__(\n+        self,\n+        load_func: t.Callable[\n+            [str],\n+            t.Optional[\n+                t.Union[\n+                    str, t.Tuple[str, t.Optional[str], t.Optional[t.Callable[[], bool]]]\n+                ]\n+            ],\n+        ],\n+    ) -&gt; None:\n         self.load_func = load_func\n\n+    def get_source(\n+        self, environment: \"Environment\", template: str\n+    ) -&gt; t.Tuple[str, t.Optional[str], t.Optional[t.Callable[[], bool]]]:\n+        rv = self.load_func(template)\n+\n+        if rv is None:\n+            raise TemplateNotFound(template)\n+\n+        if isinstance(rv, str):\n+            return rv, None, None\n+\n+        return rv\n+\n\n class PrefixLoader(BaseLoader):\n     \"\"\"A loader that is passed a dict of loaders where each loader is bound\n@@ -257,11 +488,53 @@ class PrefixLoader(BaseLoader):\n     by loading ``'app2/index.html'`` the file from the second.\n     \"\"\"\n\n-    def __init__(self, mapping: t.Mapping[str, BaseLoader], delimiter: str='/'\n-        ) -&gt;None:\n+    def __init__(\n+        self, mapping: t.Mapping[str, BaseLoader], delimiter: str = \"/\"\n+    ) -&gt; None:\n         self.mapping = mapping\n         self.delimiter = delimiter\n\n+    def get_loader(self, template: str) -&gt; t.Tuple[BaseLoader, str]:\n+        try:\n+            prefix, name = template.split(self.delimiter, 1)\n+            loader = self.mapping[prefix]\n+        except (ValueError, KeyError) as e:\n+            raise TemplateNotFound(template) from e\n+        return loader, name\n+\n+    def get_source(\n+        self, environment: \"Environment\", template: str\n+    ) -&gt; t.Tuple[str, t.Optional[str], t.Optional[t.Callable[[], bool]]]:\n+        loader, name = self.get_loader(template)\n+        try:\n+            return loader.get_source(environment, name)\n+        except TemplateNotFound as e:\n+            # re-raise the exception with the correct filename here.\n+            # (the one that includes the prefix)\n+            raise TemplateNotFound(template) from e\n+\n+    @internalcode\n+    def load(\n+        self,\n+        environment: \"Environment\",\n+        name: str,\n+        globals: t.Optional[t.MutableMapping[str, t.Any]] = None,\n+    ) -&gt; \"Template\":\n+        loader, local_name = self.get_loader(name)\n+        try:\n+            return loader.load(environment, local_name, globals)\n+        except TemplateNotFound as e:\n+            # re-raise the exception with the correct filename here.\n+            # (the one that includes the prefix)\n+            raise TemplateNotFound(name) from e\n+\n+    def list_templates(self) -&gt; t.List[str]:\n+        result = []\n+        for prefix, loader in self.mapping.items():\n+            for template in loader.list_templates():\n+                result.append(prefix + self.delimiter + template)\n+        return result\n+\n\n class ChoiceLoader(BaseLoader):\n     \"\"\"This loader works like the `PrefixLoader` just that no prefix is\n@@ -277,9 +550,39 @@ class ChoiceLoader(BaseLoader):\n     from a different location.\n     \"\"\"\n\n-    def __init__(self, loaders: t.Sequence[BaseLoader]) -&gt;None:\n+    def __init__(self, loaders: t.Sequence[BaseLoader]) -&gt; None:\n         self.loaders = loaders\n\n+    def get_source(\n+        self, environment: \"Environment\", template: str\n+    ) -&gt; t.Tuple[str, t.Optional[str], t.Optional[t.Callable[[], bool]]]:\n+        for loader in self.loaders:\n+            try:\n+                return loader.get_source(environment, template)\n+            except TemplateNotFound:\n+                pass\n+        raise TemplateNotFound(template)\n+\n+    @internalcode\n+    def load(\n+        self,\n+        environment: \"Environment\",\n+        name: str,\n+        globals: t.Optional[t.MutableMapping[str, t.Any]] = None,\n+    ) -&gt; \"Template\":\n+        for loader in self.loaders:\n+            try:\n+                return loader.load(environment, name, globals)\n+            except TemplateNotFound:\n+                pass\n+        raise TemplateNotFound(name)\n+\n+    def list_templates(self) -&gt; t.List[str]:\n+        found = set()\n+        for loader in self.loaders:\n+            found.update(loader.list_templates())\n+        return sorted(found)\n+\n\n class _TemplateModule(ModuleType):\n     \"\"\"Like a normal module but with support for weak references\"\"\"\n@@ -297,16 +600,68 @@ class ModuleLoader(BaseLoader):\n\n     Templates can be precompiled with :meth:`Environment.compile_templates`.\n     \"\"\"\n+\n     has_source_access = False\n\n-    def __init__(self, path: t.Union[str, 'os.PathLike[str]', t.Sequence[t.\n-        Union[str, 'os.PathLike[str]']]]) -&gt;None:\n-        package_name = f'_jinja2_module_templates_{id(self):x}'\n+    def __init__(\n+        self,\n+        path: t.Union[\n+            str, \"os.PathLike[str]\", t.Sequence[t.Union[str, \"os.PathLike[str]\"]]\n+        ],\n+    ) -&gt; None:\n+        package_name = f\"_jinja2_module_templates_{id(self):x}\"\n+\n+        # create a fake module that looks for the templates in the\n+        # path given.\n         mod = _TemplateModule(package_name)\n+\n         if not isinstance(path, abc.Iterable) or isinstance(path, str):\n             path = [path]\n+\n         mod.__path__ = [os.fspath(p) for p in path]\n-        sys.modules[package_name] = weakref.proxy(mod, lambda x: sys.\n-            modules.pop(package_name, None))\n+\n+        sys.modules[package_name] = weakref.proxy(\n+            mod, lambda x: sys.modules.pop(package_name, None)\n+        )\n+\n+        # the only strong reference, the sys.modules entry is weak\n+        # so that the garbage collector can remove it once the\n+        # loader that created it goes out of business.\n         self.module = mod\n         self.package_name = package_name\n+\n+    @staticmethod\n+    def get_template_key(name: str) -&gt; str:\n+        return \"tmpl_\" + sha1(name.encode(\"utf-8\")).hexdigest()\n+\n+    @staticmethod\n+    def get_module_filename(name: str) -&gt; str:\n+        return ModuleLoader.get_template_key(name) + \".py\"\n+\n+    @internalcode\n+    def load(\n+        self,\n+        environment: \"Environment\",\n+        name: str,\n+        globals: t.Optional[t.MutableMapping[str, t.Any]] = None,\n+    ) -&gt; \"Template\":\n+        key = self.get_template_key(name)\n+        module = f\"{self.package_name}.{key}\"\n+        mod = getattr(self.module, module, None)\n+\n+        if mod is None:\n+            try:\n+                mod = __import__(module, None, None, [\"root\"])\n+            except ImportError as e:\n+                raise TemplateNotFound(name) from e\n+\n+            # remove the entry from sys.modules, we only want the attribute\n+            # on the module object we have stored on the loader.\n+            sys.modules.pop(module, None)\n+\n+        if globals is None:\n+            globals = {}\n+\n+        return environment.template_class.from_module_dict(\n+            environment, mod.__dict__, globals\n+        )\ndiff --git a/src/jinja2/meta.py b/src/jinja2/meta.py\nindex 37016c7..298499e 100644\n--- a/src/jinja2/meta.py\n+++ b/src/jinja2/meta.py\n@@ -1,10 +1,13 @@\n \"\"\"Functions that expose information about templates that might be\n interesting for introspection.\n \"\"\"\n+\n import typing as t\n+\n from . import nodes\n from .compiler import CodeGenerator\n from .compiler import Frame\n+\n if t.TYPE_CHECKING:\n     from .environment import Environment\n\n@@ -12,20 +15,23 @@ if t.TYPE_CHECKING:\n class TrackingCodeGenerator(CodeGenerator):\n     \"\"\"We abuse the code generator for introspection.\"\"\"\n\n-    def __init__(self, environment: 'Environment') -&gt;None:\n-        super().__init__(environment, '&lt;introspection&gt;', '&lt;introspection&gt;')\n+    def __init__(self, environment: \"Environment\") -&gt; None:\n+        super().__init__(environment, \"&lt;introspection&gt;\", \"&lt;introspection&gt;\")\n         self.undeclared_identifiers: t.Set[str] = set()\n\n-    def write(self, x: str) -&gt;None:\n+    def write(self, x: str) -&gt; None:\n         \"\"\"Don't write.\"\"\"\n-        pass\n\n-    def enter_frame(self, frame: Frame) -&gt;None:\n+    def enter_frame(self, frame: Frame) -&gt; None:\n         \"\"\"Remember all undeclared identifiers.\"\"\"\n-        pass\n+        super().enter_frame(frame)\n+\n+        for _, (action, param) in frame.symbols.loads.items():\n+            if action == \"resolve\" and param not in self.environment.globals:\n+                self.undeclared_identifiers.add(param)\n\n\n-def find_undeclared_variables(ast: nodes.Template) -&gt;t.Set[str]:\n+def find_undeclared_variables(ast: nodes.Template) -&gt; t.Set[str]:\n     \"\"\"Returns a set of all variables in the AST that will be looked up from\n     the context at runtime.  Because at compile time it's not known which\n     variables will be used depending on the path the execution takes at\n@@ -44,16 +50,16 @@ def find_undeclared_variables(ast: nodes.Template) -&gt;t.Set[str]:\n        :exc:`TemplateAssertionError` during compilation and as a matter of\n        fact this function can currently raise that exception as well.\n     \"\"\"\n-    pass\n+    codegen = TrackingCodeGenerator(ast.environment)  # type: ignore\n+    codegen.visit(ast)\n+    return codegen.undeclared_identifiers\n\n\n-_ref_types = nodes.Extends, nodes.FromImport, nodes.Import, nodes.Include\n-_RefType = t.Union[nodes.Extends, nodes.FromImport, nodes.Import, nodes.Include\n-    ]\n+_ref_types = (nodes.Extends, nodes.FromImport, nodes.Import, nodes.Include)\n+_RefType = t.Union[nodes.Extends, nodes.FromImport, nodes.Import, nodes.Include]\n\n\n-def find_referenced_templates(ast: nodes.Template) -&gt;t.Iterator[t.Optional[str]\n-    ]:\n+def find_referenced_templates(ast: nodes.Template) -&gt; t.Iterator[t.Optional[str]]:\n     \"\"\"Finds all the referenced templates from the AST.  This will return an\n     iterator over all the hardcoded template extensions, inclusions and\n     imports.  If dynamic inheritance or inclusion is used, `None` will be\n@@ -68,4 +74,39 @@ def find_referenced_templates(ast: nodes.Template) -&gt;t.Iterator[t.Optional[str]\n     This function is useful for dependency tracking.  For example if you want\n     to rebuild parts of the website after a layout template has changed.\n     \"\"\"\n-    pass\n+    template_name: t.Any\n+\n+    for node in ast.find_all(_ref_types):\n+        template: nodes.Expr = node.template  # type: ignore\n+\n+        if not isinstance(template, nodes.Const):\n+            # a tuple with some non consts in there\n+            if isinstance(template, (nodes.Tuple, nodes.List)):\n+                for template_name in template.items:\n+                    # something const, only yield the strings and ignore\n+                    # non-string consts that really just make no sense\n+                    if isinstance(template_name, nodes.Const):\n+                        if isinstance(template_name.value, str):\n+                            yield template_name.value\n+                    # something dynamic in there\n+                    else:\n+                        yield None\n+            # something dynamic we don't know about here\n+            else:\n+                yield None\n+            continue\n+        # constant is a basestring, direct template name\n+        if isinstance(template.value, str):\n+            yield template.value\n+        # a tuple or list (latter *should* not happen) made of consts,\n+        # yield the consts that are strings.  We could warn here for\n+        # non string values\n+        elif isinstance(node, nodes.Include) and isinstance(\n+            template.value, (tuple, list)\n+        ):\n+            for template_name in template.value:\n+                if isinstance(template_name, str):\n+                    yield template_name\n+        # something else we don't care about, we could warn here\n+        else:\n+            yield None\ndiff --git a/src/jinja2/nativetypes.py b/src/jinja2/nativetypes.py\nindex 9eae726..71db8cc 100644\n--- a/src/jinja2/nativetypes.py\n+++ b/src/jinja2/nativetypes.py\n@@ -4,6 +4,7 @@ from ast import parse\n from itertools import chain\n from itertools import islice\n from types import GeneratorType\n+\n from . import nodes\n from .compiler import CodeGenerator\n from .compiler import Frame\n@@ -12,7 +13,7 @@ from .environment import Environment\n from .environment import Template\n\n\n-def native_concat(values: t.Iterable[t.Any]) -&gt;t.Optional[t.Any]:\n+def native_concat(values: t.Iterable[t.Any]) -&gt; t.Optional[t.Any]:\n     \"\"\"Return a native Python type from the list of compiled nodes. If\n     the result is a single node, its value is returned. Otherwise, the\n     nodes are concatenated as strings. If the result can be parsed with\n@@ -21,7 +22,29 @@ def native_concat(values: t.Iterable[t.Any]) -&gt;t.Optional[t.Any]:\n\n     :param values: Iterable of outputs to concatenate.\n     \"\"\"\n-    pass\n+    head = list(islice(values, 2))\n+\n+    if not head:\n+        return None\n+\n+    if len(head) == 1:\n+        raw = head[0]\n+        if not isinstance(raw, str):\n+            return raw\n+    else:\n+        if isinstance(values, GeneratorType):\n+            values = chain(head, values)\n+        raw = \"\".join([str(v) for v in values])\n+\n+    try:\n+        return literal_eval(\n+            # In Python 3.10+ ast.literal_eval removes leading spaces/tabs\n+            # from the given string. For backwards compatibility we need to\n+            # parse the string ourselves without removing leading spaces/tabs.\n+            parse(raw, mode=\"eval\")\n+        )\n+    except (ValueError, SyntaxError, MemoryError):\n+        return raw\n\n\n class NativeCodeGenerator(CodeGenerator):\n@@ -29,24 +52,79 @@ class NativeCodeGenerator(CodeGenerator):\n     ``str()`` around output nodes.\n     \"\"\"\n\n+    @staticmethod\n+    def _default_finalize(value: t.Any) -&gt; t.Any:\n+        return value\n+\n+    def _output_const_repr(self, group: t.Iterable[t.Any]) -&gt; str:\n+        return repr(\"\".join([str(v) for v in group]))\n+\n+    def _output_child_to_const(\n+        self, node: nodes.Expr, frame: Frame, finalize: CodeGenerator._FinalizeInfo\n+    ) -&gt; t.Any:\n+        const = node.as_const(frame.eval_ctx)\n+\n+        if not has_safe_repr(const):\n+            raise nodes.Impossible()\n+\n+        if isinstance(node, nodes.TemplateData):\n+            return const\n+\n+        return finalize.const(const)  # type: ignore\n+\n+    def _output_child_pre(\n+        self, node: nodes.Expr, frame: Frame, finalize: CodeGenerator._FinalizeInfo\n+    ) -&gt; None:\n+        if finalize.src is not None:\n+            self.write(finalize.src)\n+\n+    def _output_child_post(\n+        self, node: nodes.Expr, frame: Frame, finalize: CodeGenerator._FinalizeInfo\n+    ) -&gt; None:\n+        if finalize.src is not None:\n+            self.write(\")\")\n+\n\n class NativeEnvironment(Environment):\n     \"\"\"An environment that renders templates to native Python types.\"\"\"\n+\n     code_generator_class = NativeCodeGenerator\n-    concat = staticmethod(native_concat)\n+    concat = staticmethod(native_concat)  # type: ignore\n\n\n class NativeTemplate(Template):\n     environment_class = NativeEnvironment\n\n-    def render(self, *args: t.Any, **kwargs: t.Any) -&gt;t.Any:\n+    def render(self, *args: t.Any, **kwargs: t.Any) -&gt; t.Any:\n         \"\"\"Render the template to produce a native Python type. If the\n         result is a single node, its value is returned. Otherwise, the\n         nodes are concatenated as strings. If the result can be parsed\n         with :func:`ast.literal_eval`, the parsed value is returned.\n         Otherwise, the string is returned.\n         \"\"\"\n-        pass\n+        ctx = self.new_context(dict(*args, **kwargs))\n+\n+        try:\n+            return self.environment_class.concat(  # type: ignore\n+                self.root_render_func(ctx)\n+            )\n+        except Exception:\n+            return self.environment.handle_exception()\n+\n+    async def render_async(self, *args: t.Any, **kwargs: t.Any) -&gt; t.Any:\n+        if not self.environment.is_async:\n+            raise RuntimeError(\n+                \"The environment was not created with async mode enabled.\"\n+            )\n+\n+        ctx = self.new_context(dict(*args, **kwargs))\n+\n+        try:\n+            return self.environment_class.concat(  # type: ignore\n+                [n async for n in self.root_render_func(ctx)]  # type: ignore\n+            )\n+        except Exception:\n+            return self.environment.handle_exception()\n\n\n NativeEnvironment.template_class = NativeTemplate\ndiff --git a/src/jinja2/nodes.py b/src/jinja2/nodes.py\nindex 4ec1d17..2f93b90 100644\n--- a/src/jinja2/nodes.py\n+++ b/src/jinja2/nodes.py\n@@ -2,25 +2,49 @@\n some node tree helper functions used by the parser and compiler in order\n to normalize nodes.\n \"\"\"\n+\n import inspect\n import operator\n import typing as t\n from collections import deque\n+\n from markupsafe import Markup\n+\n from .utils import _PassArg\n+\n if t.TYPE_CHECKING:\n     import typing_extensions as te\n+\n     from .environment import Environment\n-_NodeBound = t.TypeVar('_NodeBound', bound='Node')\n-_binop_to_func: t.Dict[str, t.Callable[[t.Any, t.Any], t.Any]] = {'*':\n-    operator.mul, '/': operator.truediv, '//': operator.floordiv, '**':\n-    operator.pow, '%': operator.mod, '+': operator.add, '-': operator.sub}\n-_uaop_to_func: t.Dict[str, t.Callable[[t.Any], t.Any]] = {'not': operator.\n-    not_, '+': operator.pos, '-': operator.neg}\n-_cmpop_to_func: t.Dict[str, t.Callable[[t.Any, t.Any], t.Any]] = {'eq':\n-    operator.eq, 'ne': operator.ne, 'gt': operator.gt, 'gteq': operator.ge,\n-    'lt': operator.lt, 'lteq': operator.le, 'in': lambda a, b: a in b,\n-    'notin': lambda a, b: a not in b}\n+\n+_NodeBound = t.TypeVar(\"_NodeBound\", bound=\"Node\")\n+\n+_binop_to_func: t.Dict[str, t.Callable[[t.Any, t.Any], t.Any]] = {\n+    \"*\": operator.mul,\n+    \"/\": operator.truediv,\n+    \"//\": operator.floordiv,\n+    \"**\": operator.pow,\n+    \"%\": operator.mod,\n+    \"+\": operator.add,\n+    \"-\": operator.sub,\n+}\n+\n+_uaop_to_func: t.Dict[str, t.Callable[[t.Any], t.Any]] = {\n+    \"not\": operator.not_,\n+    \"+\": operator.pos,\n+    \"-\": operator.neg,\n+}\n+\n+_cmpop_to_func: t.Dict[str, t.Callable[[t.Any, t.Any], t.Any]] = {\n+    \"eq\": operator.eq,\n+    \"ne\": operator.ne,\n+    \"gt\": operator.gt,\n+    \"gteq\": operator.ge,\n+    \"lt\": operator.lt,\n+    \"lteq\": operator.le,\n+    \"in\": lambda a, b: a in b,\n+    \"notin\": lambda a, b: a not in b,\n+}\n\n\n class Impossible(Exception):\n@@ -32,15 +56,15 @@ class NodeType(type):\n     inheritance.  fields and attributes from the parent class are\n     automatically forwarded to the child.\"\"\"\n\n-    def __new__(mcs, name, bases, d):\n-        for attr in ('fields', 'attributes'):\n+    def __new__(mcs, name, bases, d):  # type: ignore\n+        for attr in \"fields\", \"attributes\":\n             storage: t.List[t.Tuple[str, ...]] = []\n             storage.extend(getattr(bases[0] if bases else object, attr, ()))\n             storage.extend(d.get(attr, ()))\n-            assert len(bases) &lt;= 1, 'multiple inheritance not allowed'\n-            assert len(storage) == len(set(storage)), 'layout conflict'\n+            assert len(bases) &lt;= 1, \"multiple inheritance not allowed\"\n+            assert len(storage) == len(set(storage)), \"layout conflict\"\n             d[attr] = tuple(storage)\n-        d.setdefault('abstract', False)\n+        d.setdefault(\"abstract\", False)\n         return type.__new__(mcs, name, bases, d)\n\n\n@@ -49,8 +73,9 @@ class EvalContext:\n     to it in extensions.\n     \"\"\"\n\n-    def __init__(self, environment: 'Environment', template_name: t.\n-        Optional[str]=None) -&gt;None:\n+    def __init__(\n+        self, environment: \"Environment\", template_name: t.Optional[str] = None\n+    ) -&gt; None:\n         self.environment = environment\n         if callable(environment.autoescape):\n             self.autoescape = environment.autoescape(template_name)\n@@ -58,6 +83,24 @@ class EvalContext:\n             self.autoescape = environment.autoescape\n         self.volatile = False\n\n+    def save(self) -&gt; t.Mapping[str, t.Any]:\n+        return self.__dict__.copy()\n+\n+    def revert(self, old: t.Mapping[str, t.Any]) -&gt; None:\n+        self.__dict__.clear()\n+        self.__dict__.update(old)\n+\n+\n+def get_eval_context(node: \"Node\", ctx: t.Optional[EvalContext]) -&gt; EvalContext:\n+    if ctx is None:\n+        if node.environment is None:\n+            raise RuntimeError(\n+                \"if no eval context is passed, the node must have an\"\n+                \" attached environment.\"\n+            )\n+        return EvalContext(node.environment)\n+    return ctx\n+\n\n class Node(metaclass=NodeType):\n     \"\"\"Baseclass for all Jinja nodes.  There are a number of nodes available\n@@ -75,96 +118,176 @@ class Node(metaclass=NodeType):\n     The `environment` attribute is set at the end of the parsing process for\n     all nodes automatically.\n     \"\"\"\n+\n     fields: t.Tuple[str, ...] = ()\n-    attributes: t.Tuple[str, ...] = ('lineno', 'environment')\n+    attributes: t.Tuple[str, ...] = (\"lineno\", \"environment\")\n     abstract = True\n+\n     lineno: int\n-    environment: t.Optional['Environment']\n+    environment: t.Optional[\"Environment\"]\n\n-    def __init__(self, *fields: t.Any, **attributes: t.Any) -&gt;None:\n+    def __init__(self, *fields: t.Any, **attributes: t.Any) -&gt; None:\n         if self.abstract:\n-            raise TypeError('abstract nodes are not instantiable')\n+            raise TypeError(\"abstract nodes are not instantiable\")\n         if fields:\n             if len(fields) != len(self.fields):\n                 if not self.fields:\n-                    raise TypeError(\n-                        f'{type(self).__name__!r} takes 0 arguments')\n+                    raise TypeError(f\"{type(self).__name__!r} takes 0 arguments\")\n                 raise TypeError(\n-                    f\"{type(self).__name__!r} takes 0 or {len(self.fields)} argument{'s' if len(self.fields) != 1 else ''}\"\n-                    )\n+                    f\"{type(self).__name__!r} takes 0 or {len(self.fields)}\"\n+                    f\" argument{'s' if len(self.fields) != 1 else ''}\"\n+                )\n             for name, arg in zip(self.fields, fields):\n                 setattr(self, name, arg)\n         for attr in self.attributes:\n             setattr(self, attr, attributes.pop(attr, None))\n         if attributes:\n-            raise TypeError(f'unknown attribute {next(iter(attributes))!r}')\n+            raise TypeError(f\"unknown attribute {next(iter(attributes))!r}\")\n\n-    def iter_fields(self, exclude: t.Optional[t.Container[str]]=None, only:\n-        t.Optional[t.Container[str]]=None) -&gt;t.Iterator[t.Tuple[str, t.Any]]:\n+    def iter_fields(\n+        self,\n+        exclude: t.Optional[t.Container[str]] = None,\n+        only: t.Optional[t.Container[str]] = None,\n+    ) -&gt; t.Iterator[t.Tuple[str, t.Any]]:\n         \"\"\"This method iterates over all fields that are defined and yields\n         ``(key, value)`` tuples.  Per default all fields are returned, but\n         it's possible to limit that to some fields by providing the `only`\n         parameter or to exclude some using the `exclude` parameter.  Both\n         should be sets or tuples of field names.\n         \"\"\"\n-        pass\n-\n-    def iter_child_nodes(self, exclude: t.Optional[t.Container[str]]=None,\n-        only: t.Optional[t.Container[str]]=None) -&gt;t.Iterator['Node']:\n+        for name in self.fields:\n+            if (\n+                (exclude is None and only is None)\n+                or (exclude is not None and name not in exclude)\n+                or (only is not None and name in only)\n+            ):\n+                try:\n+                    yield name, getattr(self, name)\n+                except AttributeError:\n+                    pass\n+\n+    def iter_child_nodes(\n+        self,\n+        exclude: t.Optional[t.Container[str]] = None,\n+        only: t.Optional[t.Container[str]] = None,\n+    ) -&gt; t.Iterator[\"Node\"]:\n         \"\"\"Iterates over all direct child nodes of the node.  This iterates\n         over all fields and yields the values of they are nodes.  If the value\n         of a field is a list all the nodes in that list are returned.\n         \"\"\"\n-        pass\n-\n-    def find(self, node_type: t.Type[_NodeBound]) -&gt;t.Optional[_NodeBound]:\n+        for _, item in self.iter_fields(exclude, only):\n+            if isinstance(item, list):\n+                for n in item:\n+                    if isinstance(n, Node):\n+                        yield n\n+            elif isinstance(item, Node):\n+                yield item\n+\n+    def find(self, node_type: t.Type[_NodeBound]) -&gt; t.Optional[_NodeBound]:\n         \"\"\"Find the first node of a given type.  If no such node exists the\n         return value is `None`.\n         \"\"\"\n-        pass\n+        for result in self.find_all(node_type):\n+            return result\n+\n+        return None\n\n-    def find_all(self, node_type: t.Union[t.Type[_NodeBound], t.Tuple[t.\n-        Type[_NodeBound], ...]]) -&gt;t.Iterator[_NodeBound]:\n+    def find_all(\n+        self, node_type: t.Union[t.Type[_NodeBound], t.Tuple[t.Type[_NodeBound], ...]]\n+    ) -&gt; t.Iterator[_NodeBound]:\n         \"\"\"Find all the nodes of a given type.  If the type is a tuple,\n         the check is performed for any of the tuple items.\n         \"\"\"\n-        pass\n+        for child in self.iter_child_nodes():\n+            if isinstance(child, node_type):\n+                yield child  # type: ignore\n+            yield from child.find_all(node_type)\n\n-    def set_ctx(self, ctx: str) -&gt;'Node':\n+    def set_ctx(self, ctx: str) -&gt; \"Node\":\n         \"\"\"Reset the context of a node and all child nodes.  Per default the\n         parser will all generate nodes that have a 'load' context as it's the\n         most common one.  This method is used in the parser to set assignment\n         targets and other nodes to a store context.\n         \"\"\"\n-        pass\n-\n-    def set_lineno(self, lineno: int, override: bool=False) -&gt;'Node':\n+        todo = deque([self])\n+        while todo:\n+            node = todo.popleft()\n+            if \"ctx\" in node.fields:\n+                node.ctx = ctx  # type: ignore\n+            todo.extend(node.iter_child_nodes())\n+        return self\n+\n+    def set_lineno(self, lineno: int, override: bool = False) -&gt; \"Node\":\n         \"\"\"Set the line numbers of the node and children.\"\"\"\n-        pass\n-\n-    def set_environment(self, environment: 'Environment') -&gt;'Node':\n+        todo = deque([self])\n+        while todo:\n+            node = todo.popleft()\n+            if \"lineno\" in node.attributes:\n+                if node.lineno is None or override:\n+                    node.lineno = lineno\n+            todo.extend(node.iter_child_nodes())\n+        return self\n+\n+    def set_environment(self, environment: \"Environment\") -&gt; \"Node\":\n         \"\"\"Set the environment for all nodes.\"\"\"\n-        pass\n-\n-    def __eq__(self, other: t.Any) -&gt;bool:\n+        todo = deque([self])\n+        while todo:\n+            node = todo.popleft()\n+            node.environment = environment\n+            todo.extend(node.iter_child_nodes())\n+        return self\n+\n+    def __eq__(self, other: t.Any) -&gt; bool:\n         if type(self) is not type(other):\n             return NotImplemented\n+\n         return tuple(self.iter_fields()) == tuple(other.iter_fields())\n+\n     __hash__ = object.__hash__\n\n-    def __repr__(self) -&gt;str:\n-        args_str = ', '.join(f'{a}={getattr(self, a, None)!r}' for a in\n-            self.fields)\n-        return f'{type(self).__name__}({args_str})'\n+    def __repr__(self) -&gt; str:\n+        args_str = \", \".join(f\"{a}={getattr(self, a, None)!r}\" for a in self.fields)\n+        return f\"{type(self).__name__}({args_str})\"\n+\n+    def dump(self) -&gt; str:\n+        def _dump(node: t.Union[Node, t.Any]) -&gt; None:\n+            if not isinstance(node, Node):\n+                buf.append(repr(node))\n+                return\n+\n+            buf.append(f\"nodes.{type(node).__name__}(\")\n+            if not node.fields:\n+                buf.append(\")\")\n+                return\n+            for idx, field in enumerate(node.fields):\n+                if idx:\n+                    buf.append(\", \")\n+                value = getattr(node, field)\n+                if isinstance(value, list):\n+                    buf.append(\"[\")\n+                    for idx, item in enumerate(value):\n+                        if idx:\n+                            buf.append(\", \")\n+                        _dump(item)\n+                    buf.append(\"]\")\n+                else:\n+                    _dump(value)\n+            buf.append(\")\")\n+\n+        buf: t.List[str] = []\n+        _dump(self)\n+        return \"\".join(buf)\n\n\n class Stmt(Node):\n     \"\"\"Base node for all statements.\"\"\"\n+\n     abstract = True\n\n\n class Helper(Node):\n     \"\"\"Nodes that exist in a specific context only.\"\"\"\n+\n     abstract = True\n\n\n@@ -172,7 +295,8 @@ class Template(Node):\n     \"\"\"Node that represents a template.  This must be the outermost node that\n     is passed to the compiler.\n     \"\"\"\n-    fields = 'body',\n+\n+    fields = (\"body\",)\n     body: t.List[Node]\n\n\n@@ -180,14 +304,16 @@ class Output(Stmt):\n     \"\"\"A node that holds multiple expressions which are then printed out.\n     This is used both for the `print` statement and the regular template data.\n     \"\"\"\n-    fields = 'nodes',\n-    nodes: t.List['Expr']\n+\n+    fields = (\"nodes\",)\n+    nodes: t.List[\"Expr\"]\n\n\n class Extends(Stmt):\n     \"\"\"Represents an extends statement.\"\"\"\n-    fields = 'template',\n-    template: 'Expr'\n+\n+    fields = (\"template\",)\n+    template: \"Expr\"\n\n\n class For(Stmt):\n@@ -198,7 +324,8 @@ class For(Stmt):\n\n     For filtered nodes an expression can be stored as `test`, otherwise `None`.\n     \"\"\"\n-    fields = 'target', 'iter', 'body', 'else_', 'test', 'recursive'\n+\n+    fields = (\"target\", \"iter\", \"body\", \"else_\", \"test\", \"recursive\")\n     target: Node\n     iter: Node\n     body: t.List[Node]\n@@ -209,10 +336,11 @@ class For(Stmt):\n\n class If(Stmt):\n     \"\"\"If `test` is true, `body` is rendered, else `else_`.\"\"\"\n-    fields = 'test', 'body', 'elif_', 'else_'\n+\n+    fields = (\"test\", \"body\", \"elif_\", \"else_\")\n     test: Node\n     body: t.List[Node]\n-    elif_: t.List['If']\n+    elif_: t.List[\"If\"]\n     else_: t.List[Node]\n\n\n@@ -221,10 +349,11 @@ class Macro(Stmt):\n     arguments and `defaults` a list of defaults if there are any.  `body` is\n     a list of nodes for the macro body.\n     \"\"\"\n-    fields = 'name', 'args', 'defaults', 'body'\n+\n+    fields = (\"name\", \"args\", \"defaults\", \"body\")\n     name: str\n-    args: t.List['Name']\n-    defaults: t.List['Expr']\n+    args: t.List[\"Name\"]\n+    defaults: t.List[\"Expr\"]\n     body: t.List[Node]\n\n\n@@ -232,18 +361,20 @@ class CallBlock(Stmt):\n     \"\"\"Like a macro without a name but a call instead.  `call` is called with\n     the unnamed macro as `caller` argument this node holds.\n     \"\"\"\n-    fields = 'call', 'args', 'defaults', 'body'\n-    call: 'Call'\n-    args: t.List['Name']\n-    defaults: t.List['Expr']\n+\n+    fields = (\"call\", \"args\", \"defaults\", \"body\")\n+    call: \"Call\"\n+    args: t.List[\"Name\"]\n+    defaults: t.List[\"Expr\"]\n     body: t.List[Node]\n\n\n class FilterBlock(Stmt):\n     \"\"\"Node for filter sections.\"\"\"\n-    fields = 'body', 'filter'\n+\n+    fields = (\"body\", \"filter\")\n     body: t.List[Node]\n-    filter: 'Filter'\n+    filter: \"Filter\"\n\n\n class With(Stmt):\n@@ -252,9 +383,10 @@ class With(Stmt):\n\n     .. versionadded:: 2.9.3\n     \"\"\"\n-    fields = 'targets', 'values', 'body'\n-    targets: t.List['Expr']\n-    values: t.List['Expr']\n+\n+    fields = (\"targets\", \"values\", \"body\")\n+    targets: t.List[\"Expr\"]\n+    values: t.List[\"Expr\"]\n     body: t.List[Node]\n\n\n@@ -264,7 +396,8 @@ class Block(Stmt):\n     .. versionchanged:: 3.0.0\n         the `required` field was added.\n     \"\"\"\n-    fields = 'name', 'body', 'scoped', 'required'\n+\n+    fields = (\"name\", \"body\", \"scoped\", \"required\")\n     name: str\n     body: t.List[Node]\n     scoped: bool\n@@ -273,16 +406,18 @@ class Block(Stmt):\n\n class Include(Stmt):\n     \"\"\"A node that represents the include tag.\"\"\"\n-    fields = 'template', 'with_context', 'ignore_missing'\n-    template: 'Expr'\n+\n+    fields = (\"template\", \"with_context\", \"ignore_missing\")\n+    template: \"Expr\"\n     with_context: bool\n     ignore_missing: bool\n\n\n class Import(Stmt):\n     \"\"\"A node that represents the import tag.\"\"\"\n-    fields = 'template', 'target', 'with_context'\n-    template: 'Expr'\n+\n+    fields = (\"template\", \"target\", \"with_context\")\n+    template: \"Expr\"\n     target: str\n     with_context: bool\n\n@@ -298,38 +433,43 @@ class FromImport(Stmt):\n\n     The list of names may contain tuples if aliases are wanted.\n     \"\"\"\n-    fields = 'template', 'names', 'with_context'\n-    template: 'Expr'\n+\n+    fields = (\"template\", \"names\", \"with_context\")\n+    template: \"Expr\"\n     names: t.List[t.Union[str, t.Tuple[str, str]]]\n     with_context: bool\n\n\n class ExprStmt(Stmt):\n     \"\"\"A statement that evaluates an expression and discards the result.\"\"\"\n-    fields = 'node',\n+\n+    fields = (\"node\",)\n     node: Node\n\n\n class Assign(Stmt):\n     \"\"\"Assigns an expression to a target.\"\"\"\n-    fields = 'target', 'node'\n-    target: 'Expr'\n+\n+    fields = (\"target\", \"node\")\n+    target: \"Expr\"\n     node: Node\n\n\n class AssignBlock(Stmt):\n     \"\"\"Assigns a block to a target.\"\"\"\n-    fields = 'target', 'filter', 'body'\n-    target: 'Expr'\n-    filter: t.Optional['Filter']\n+\n+    fields = (\"target\", \"filter\", \"body\")\n+    target: \"Expr\"\n+    filter: t.Optional[\"Filter\"]\n     body: t.List[Node]\n\n\n class Expr(Node):\n     \"\"\"Baseclass for all expressions.\"\"\"\n+\n     abstract = True\n\n-    def as_const(self, eval_ctx: t.Optional[EvalContext]=None) -&gt;t.Any:\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; t.Any:\n         \"\"\"Return the value of the expression as constant or raise\n         :exc:`Impossible` if this was not possible.\n\n@@ -340,29 +480,61 @@ class Expr(Node):\n         .. versionchanged:: 2.4\n            the `eval_ctx` parameter was added.\n         \"\"\"\n-        pass\n+        raise Impossible()\n\n-    def can_assign(self) -&gt;bool:\n+    def can_assign(self) -&gt; bool:\n         \"\"\"Check if it's possible to assign something to this node.\"\"\"\n-        pass\n+        return False\n\n\n class BinExpr(Expr):\n     \"\"\"Baseclass for all binary expressions.\"\"\"\n-    fields = 'left', 'right'\n+\n+    fields = (\"left\", \"right\")\n     left: Expr\n     right: Expr\n     operator: str\n     abstract = True\n\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; t.Any:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+\n+        # intercepted operators cannot be folded at compile time\n+        if (\n+            eval_ctx.environment.sandboxed\n+            and self.operator in eval_ctx.environment.intercepted_binops  # type: ignore\n+        ):\n+            raise Impossible()\n+        f = _binop_to_func[self.operator]\n+        try:\n+            return f(self.left.as_const(eval_ctx), self.right.as_const(eval_ctx))\n+        except Exception as e:\n+            raise Impossible() from e\n+\n\n class UnaryExpr(Expr):\n     \"\"\"Baseclass for all unary expressions.\"\"\"\n-    fields = 'node',\n+\n+    fields = (\"node\",)\n     node: Expr\n     operator: str\n     abstract = True\n\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; t.Any:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+\n+        # intercepted operators cannot be folded at compile time\n+        if (\n+            eval_ctx.environment.sandboxed\n+            and self.operator in eval_ctx.environment.intercepted_unops  # type: ignore\n+        ):\n+            raise Impossible()\n+        f = _uaop_to_func[self.operator]\n+        try:\n+            return f(self.node.as_const(eval_ctx))\n+        except Exception as e:\n+            raise Impossible() from e\n+\n\n class Name(Expr):\n     \"\"\"Looks up a name or stores a value in a name.\n@@ -372,20 +544,33 @@ class Name(Expr):\n     -   `load`: load that name\n     -   `param`: like `store` but if the name was defined as function parameter.\n     \"\"\"\n-    fields = 'name', 'ctx'\n+\n+    fields = (\"name\", \"ctx\")\n     name: str\n     ctx: str\n\n+    def can_assign(self) -&gt; bool:\n+        return self.name not in {\"true\", \"false\", \"none\", \"True\", \"False\", \"None\"}\n+\n\n class NSRef(Expr):\n     \"\"\"Reference to a namespace value assignment\"\"\"\n-    fields = 'name', 'attr'\n+\n+    fields = (\"name\", \"attr\")\n     name: str\n     attr: str\n\n+    def can_assign(self) -&gt; bool:\n+        # We don't need any special checks here; NSRef assignments have a\n+        # runtime check to ensure the target is a namespace object which will\n+        # have been checked already as it is created using a normal assignment\n+        # which goes through a `Name` node.\n+        return True\n+\n\n class Literal(Expr):\n     \"\"\"Baseclass for literals.\"\"\"\n+\n     abstract = True\n\n\n@@ -395,75 +580,164 @@ class Const(Literal):\n     complex values such as lists too.  Only constants with a safe\n     representation (objects where ``eval(repr(x)) == x`` is true).\n     \"\"\"\n-    fields = 'value',\n+\n+    fields = (\"value\",)\n     value: t.Any\n\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; t.Any:\n+        return self.value\n+\n     @classmethod\n-    def from_untrusted(cls, value: t.Any, lineno: t.Optional[int]=None,\n-        environment: 't.Optional[Environment]'=None) -&gt;'Const':\n+    def from_untrusted(\n+        cls,\n+        value: t.Any,\n+        lineno: t.Optional[int] = None,\n+        environment: \"t.Optional[Environment]\" = None,\n+    ) -&gt; \"Const\":\n         \"\"\"Return a const object if the value is representable as\n         constant value in the generated code, otherwise it will raise\n         an `Impossible` exception.\n         \"\"\"\n-        pass\n+        from .compiler import has_safe_repr\n+\n+        if not has_safe_repr(value):\n+            raise Impossible()\n+        return cls(value, lineno=lineno, environment=environment)\n\n\n class TemplateData(Literal):\n     \"\"\"A constant template string.\"\"\"\n-    fields = 'data',\n+\n+    fields = (\"data\",)\n     data: str\n\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; str:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        if eval_ctx.volatile:\n+            raise Impossible()\n+        if eval_ctx.autoescape:\n+            return Markup(self.data)\n+        return self.data\n+\n\n class Tuple(Literal):\n     \"\"\"For loop unpacking and some other things like multiple arguments\n     for subscripts.  Like for :class:`Name` `ctx` specifies if the tuple\n     is used for loading the names or storing.\n     \"\"\"\n-    fields = 'items', 'ctx'\n+\n+    fields = (\"items\", \"ctx\")\n     items: t.List[Expr]\n     ctx: str\n\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; t.Tuple[t.Any, ...]:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return tuple(x.as_const(eval_ctx) for x in self.items)\n+\n+    def can_assign(self) -&gt; bool:\n+        for item in self.items:\n+            if not item.can_assign():\n+                return False\n+        return True\n+\n\n class List(Literal):\n     \"\"\"Any list literal such as ``[1, 2, 3]``\"\"\"\n-    fields = 'items',\n+\n+    fields = (\"items\",)\n     items: t.List[Expr]\n\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; t.List[t.Any]:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return [x.as_const(eval_ctx) for x in self.items]\n+\n\n class Dict(Literal):\n     \"\"\"Any dict literal such as ``{1: 2, 3: 4}``.  The items must be a list of\n     :class:`Pair` nodes.\n     \"\"\"\n-    fields = 'items',\n-    items: t.List['Pair']\n+\n+    fields = (\"items\",)\n+    items: t.List[\"Pair\"]\n+\n+    def as_const(\n+        self, eval_ctx: t.Optional[EvalContext] = None\n+    ) -&gt; t.Dict[t.Any, t.Any]:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return dict(x.as_const(eval_ctx) for x in self.items)\n\n\n class Pair(Helper):\n     \"\"\"A key, value pair for dicts.\"\"\"\n-    fields = 'key', 'value'\n+\n+    fields = (\"key\", \"value\")\n     key: Expr\n     value: Expr\n\n+    def as_const(\n+        self, eval_ctx: t.Optional[EvalContext] = None\n+    ) -&gt; t.Tuple[t.Any, t.Any]:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return self.key.as_const(eval_ctx), self.value.as_const(eval_ctx)\n+\n\n class Keyword(Helper):\n     \"\"\"A key, value pair for keyword arguments where key is a string.\"\"\"\n-    fields = 'key', 'value'\n+\n+    fields = (\"key\", \"value\")\n     key: str\n     value: Expr\n\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; t.Tuple[str, t.Any]:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return self.key, self.value.as_const(eval_ctx)\n+\n\n class CondExpr(Expr):\n     \"\"\"A conditional expression (inline if expression).  (``{{\n     foo if bar else baz }}``)\n     \"\"\"\n-    fields = 'test', 'expr1', 'expr2'\n+\n+    fields = (\"test\", \"expr1\", \"expr2\")\n     test: Expr\n     expr1: Expr\n     expr2: t.Optional[Expr]\n\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; t.Any:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        if self.test.as_const(eval_ctx):\n+            return self.expr1.as_const(eval_ctx)\n+\n+        # if we evaluate to an undefined object, we better do that at runtime\n+        if self.expr2 is None:\n+            raise Impossible()\n+\n+        return self.expr2.as_const(eval_ctx)\n+\n+\n+def args_as_const(\n+    node: t.Union[\"_FilterTestCommon\", \"Call\"], eval_ctx: t.Optional[EvalContext]\n+) -&gt; t.Tuple[t.List[t.Any], t.Dict[t.Any, t.Any]]:\n+    args = [x.as_const(eval_ctx) for x in node.args]\n+    kwargs = dict(x.as_const(eval_ctx) for x in node.kwargs)\n+\n+    if node.dyn_args is not None:\n+        try:\n+            args.extend(node.dyn_args.as_const(eval_ctx))\n+        except Exception as e:\n+            raise Impossible() from e\n+\n+    if node.dyn_kwargs is not None:\n+        try:\n+            kwargs.update(node.dyn_kwargs.as_const(eval_ctx))\n+        except Exception as e:\n+            raise Impossible() from e\n+\n+    return args, kwargs\n+\n\n class _FilterTestCommon(Expr):\n-    fields = 'node', 'name', 'args', 'kwargs', 'dyn_args', 'dyn_kwargs'\n+    fields = (\"node\", \"name\", \"args\", \"kwargs\", \"dyn_args\", \"dyn_kwargs\")\n     node: Expr\n     name: str\n     args: t.List[Expr]\n@@ -473,6 +747,42 @@ class _FilterTestCommon(Expr):\n     abstract = True\n     _is_filter = True\n\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; t.Any:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+\n+        if eval_ctx.volatile:\n+            raise Impossible()\n+\n+        if self._is_filter:\n+            env_map = eval_ctx.environment.filters\n+        else:\n+            env_map = eval_ctx.environment.tests\n+\n+        func = env_map.get(self.name)\n+        pass_arg = _PassArg.from_obj(func)  # type: ignore\n+\n+        if func is None or pass_arg is _PassArg.context:\n+            raise Impossible()\n+\n+        if eval_ctx.environment.is_async and (\n+            getattr(func, \"jinja_async_variant\", False) is True\n+            or inspect.iscoroutinefunction(func)\n+        ):\n+            raise Impossible()\n+\n+        args, kwargs = args_as_const(self, eval_ctx)\n+        args.insert(0, self.node.as_const(eval_ctx))\n+\n+        if pass_arg is _PassArg.eval_context:\n+            args.insert(0, eval_ctx)\n+        elif pass_arg is _PassArg.environment:\n+            args.insert(0, eval_ctx.environment)\n+\n+        try:\n+            return func(*args, **kwargs)\n+        except Exception as e:\n+            raise Impossible() from e\n+\n\n class Filter(_FilterTestCommon):\n     \"\"\"Apply a filter to an expression. ``name`` is the name of the\n@@ -481,7 +791,14 @@ class Filter(_FilterTestCommon):\n     If ``node`` is ``None``, the filter is being used in a filter block\n     and is applied to the content of the block.\n     \"\"\"\n-    node: t.Optional[Expr]\n+\n+    node: t.Optional[Expr]  # type: ignore\n+\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; t.Any:\n+        if self.node is None:\n+            raise Impossible()\n+\n+        return super().as_const(eval_ctx=eval_ctx)\n\n\n class Test(_FilterTestCommon):\n@@ -493,6 +810,7 @@ class Test(_FilterTestCommon):\n         check for volatile, async, and ``@pass_context`` etc.\n         decorators.\n     \"\"\"\n+\n     _is_filter = False\n\n\n@@ -503,7 +821,8 @@ class Call(Expr):\n     node for dynamic positional (``*args``) or keyword (``**kwargs``)\n     arguments.\n     \"\"\"\n-    fields = 'node', 'args', 'kwargs', 'dyn_args', 'dyn_kwargs'\n+\n+    fields = (\"node\", \"args\", \"kwargs\", \"dyn_args\", \"dyn_kwargs\")\n     node: Expr\n     args: t.List[Expr]\n     kwargs: t.List[Keyword]\n@@ -513,123 +832,209 @@ class Call(Expr):\n\n class Getitem(Expr):\n     \"\"\"Get an attribute or item from an expression and prefer the item.\"\"\"\n-    fields = 'node', 'arg', 'ctx'\n+\n+    fields = (\"node\", \"arg\", \"ctx\")\n     node: Expr\n     arg: Expr\n     ctx: str\n\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; t.Any:\n+        if self.ctx != \"load\":\n+            raise Impossible()\n+\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+\n+        try:\n+            return eval_ctx.environment.getitem(\n+                self.node.as_const(eval_ctx), self.arg.as_const(eval_ctx)\n+            )\n+        except Exception as e:\n+            raise Impossible() from e\n+\n\n class Getattr(Expr):\n     \"\"\"Get an attribute or item from an expression that is a ascii-only\n     bytestring and prefer the attribute.\n     \"\"\"\n-    fields = 'node', 'attr', 'ctx'\n+\n+    fields = (\"node\", \"attr\", \"ctx\")\n     node: Expr\n     attr: str\n     ctx: str\n\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; t.Any:\n+        if self.ctx != \"load\":\n+            raise Impossible()\n+\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+\n+        try:\n+            return eval_ctx.environment.getattr(self.node.as_const(eval_ctx), self.attr)\n+        except Exception as e:\n+            raise Impossible() from e\n+\n\n class Slice(Expr):\n     \"\"\"Represents a slice object.  This must only be used as argument for\n     :class:`Subscript`.\n     \"\"\"\n-    fields = 'start', 'stop', 'step'\n+\n+    fields = (\"start\", \"stop\", \"step\")\n     start: t.Optional[Expr]\n     stop: t.Optional[Expr]\n     step: t.Optional[Expr]\n\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; slice:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+\n+        def const(obj: t.Optional[Expr]) -&gt; t.Optional[t.Any]:\n+            if obj is None:\n+                return None\n+            return obj.as_const(eval_ctx)\n+\n+        return slice(const(self.start), const(self.stop), const(self.step))\n+\n\n class Concat(Expr):\n     \"\"\"Concatenates the list of expressions provided after converting\n     them to strings.\n     \"\"\"\n-    fields = 'nodes',\n+\n+    fields = (\"nodes\",)\n     nodes: t.List[Expr]\n\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; str:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return \"\".join(str(x.as_const(eval_ctx)) for x in self.nodes)\n+\n\n class Compare(Expr):\n     \"\"\"Compares an expression with some other expressions.  `ops` must be a\n     list of :class:`Operand`\\\\s.\n     \"\"\"\n-    fields = 'expr', 'ops'\n+\n+    fields = (\"expr\", \"ops\")\n     expr: Expr\n-    ops: t.List['Operand']\n+    ops: t.List[\"Operand\"]\n+\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; t.Any:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        result = value = self.expr.as_const(eval_ctx)\n+\n+        try:\n+            for op in self.ops:\n+                new_value = op.expr.as_const(eval_ctx)\n+                result = _cmpop_to_func[op.op](value, new_value)\n+\n+                if not result:\n+                    return False\n+\n+                value = new_value\n+        except Exception as e:\n+            raise Impossible() from e\n+\n+        return result\n\n\n class Operand(Helper):\n     \"\"\"Holds an operator and an expression.\"\"\"\n-    fields = 'op', 'expr'\n+\n+    fields = (\"op\", \"expr\")\n     op: str\n     expr: Expr\n\n\n class Mul(BinExpr):\n     \"\"\"Multiplies the left with the right node.\"\"\"\n-    operator = '*'\n+\n+    operator = \"*\"\n\n\n class Div(BinExpr):\n     \"\"\"Divides the left by the right node.\"\"\"\n-    operator = '/'\n+\n+    operator = \"/\"\n\n\n class FloorDiv(BinExpr):\n     \"\"\"Divides the left by the right node and converts the\n     result into an integer by truncating.\n     \"\"\"\n-    operator = '//'\n+\n+    operator = \"//\"\n\n\n class Add(BinExpr):\n     \"\"\"Add the left to the right node.\"\"\"\n-    operator = '+'\n+\n+    operator = \"+\"\n\n\n class Sub(BinExpr):\n     \"\"\"Subtract the right from the left node.\"\"\"\n-    operator = '-'\n+\n+    operator = \"-\"\n\n\n class Mod(BinExpr):\n     \"\"\"Left modulo right.\"\"\"\n-    operator = '%'\n+\n+    operator = \"%\"\n\n\n class Pow(BinExpr):\n     \"\"\"Left to the power of right.\"\"\"\n-    operator = '**'\n+\n+    operator = \"**\"\n\n\n class And(BinExpr):\n     \"\"\"Short circuited AND.\"\"\"\n-    operator = 'and'\n+\n+    operator = \"and\"\n+\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; t.Any:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return self.left.as_const(eval_ctx) and self.right.as_const(eval_ctx)\n\n\n class Or(BinExpr):\n     \"\"\"Short circuited OR.\"\"\"\n-    operator = 'or'\n+\n+    operator = \"or\"\n+\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; t.Any:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return self.left.as_const(eval_ctx) or self.right.as_const(eval_ctx)\n\n\n class Not(UnaryExpr):\n     \"\"\"Negate the expression.\"\"\"\n-    operator = 'not'\n+\n+    operator = \"not\"\n\n\n class Neg(UnaryExpr):\n     \"\"\"Make the expression negative.\"\"\"\n-    operator = '-'\n+\n+    operator = \"-\"\n\n\n class Pos(UnaryExpr):\n     \"\"\"Make the expression positive (noop for most expressions)\"\"\"\n-    operator = '+'\n+\n+    operator = \"+\"\n+\n+\n+# Helpers for extensions\n\n\n class EnvironmentAttribute(Expr):\n     \"\"\"Loads an attribute from the environment object.  This is useful for\n     extensions that want to call a callback stored on the environment.\n     \"\"\"\n-    fields = 'name',\n+\n+    fields = (\"name\",)\n     name: str\n\n\n@@ -640,7 +1045,8 @@ class ExtensionAttribute(Expr):\n     This node is usually constructed by calling the\n     :meth:`~jinja2.ext.Extension.attr` method on an extension.\n     \"\"\"\n-    fields = 'identifier', 'name'\n+\n+    fields = (\"identifier\", \"name\")\n     identifier: str\n     name: str\n\n@@ -651,7 +1057,8 @@ class ImportedName(Expr):\n     function from the cgi module on evaluation.  Imports are optimized by the\n     compiler so there is no need to assign them to local variables.\n     \"\"\"\n-    fields = 'importname',\n+\n+    fields = (\"importname\",)\n     importname: str\n\n\n@@ -662,20 +1069,27 @@ class InternalName(Expr):\n     a new identifier for you.  This identifier is not available from the\n     template and is not treated specially by the compiler.\n     \"\"\"\n-    fields = 'name',\n+\n+    fields = (\"name\",)\n     name: str\n\n-    def __init__(self) -&gt;None:\n+    def __init__(self) -&gt; None:\n         raise TypeError(\n-            \"Can't create internal names.  Use the `free_identifier` method on a parser.\"\n-            )\n+            \"Can't create internal names.  Use the \"\n+            \"`free_identifier` method on a parser.\"\n+        )\n\n\n class MarkSafe(Expr):\n     \"\"\"Mark the wrapped expression as safe (wrap it as `Markup`).\"\"\"\n-    fields = 'expr',\n+\n+    fields = (\"expr\",)\n     expr: Expr\n\n+    def as_const(self, eval_ctx: t.Optional[EvalContext] = None) -&gt; Markup:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        return Markup(self.expr.as_const(eval_ctx))\n+\n\n class MarkSafeIfAutoescape(Expr):\n     \"\"\"Mark the wrapped expression as safe (wrap it as `Markup`) but\n@@ -683,9 +1097,21 @@ class MarkSafeIfAutoescape(Expr):\n\n     .. versionadded:: 2.5\n     \"\"\"\n-    fields = 'expr',\n+\n+    fields = (\"expr\",)\n     expr: Expr\n\n+    def as_const(\n+        self, eval_ctx: t.Optional[EvalContext] = None\n+    ) -&gt; t.Union[Markup, t.Any]:\n+        eval_ctx = get_eval_context(self, eval_ctx)\n+        if eval_ctx.volatile:\n+            raise Impossible()\n+        expr = self.expr.as_const(eval_ctx)\n+        if eval_ctx.autoescape:\n+            return Markup(expr)\n+        return expr\n+\n\n class ContextReference(Expr):\n     \"\"\"Returns the current template context.  It can be used like a\n@@ -724,7 +1150,8 @@ class Break(Stmt):\n\n class Scope(Stmt):\n     \"\"\"An artificial scope.\"\"\"\n-    fields = 'body',\n+\n+    fields = (\"body\",)\n     body: t.List[Node]\n\n\n@@ -741,7 +1168,8 @@ class OverlayScope(Stmt):\n\n     .. versionadded:: 2.10\n     \"\"\"\n-    fields = 'context', 'body'\n+\n+    fields = (\"context\", \"body\")\n     context: Expr\n     body: t.List[Node]\n\n@@ -754,7 +1182,8 @@ class EvalContextModifier(Stmt):\n\n         EvalContextModifier(options=[Keyword('autoescape', Const(True))])\n     \"\"\"\n-    fields = 'options',\n+\n+    fields = (\"options\",)\n     options: t.List[Keyword]\n\n\n@@ -763,9 +1192,15 @@ class ScopedEvalContextModifier(EvalContextModifier):\n     :class:`EvalContextModifier` but will only modify the\n     :class:`~jinja2.nodes.EvalContext` for nodes in the :attr:`body`.\n     \"\"\"\n-    fields = 'body',\n+\n+    fields = (\"body\",)\n     body: t.List[Node]\n\n\n-NodeType.__new__ = staticmethod(_failing_new)\n+# make sure nobody creates custom nodes\n+def _failing_new(*args: t.Any, **kwargs: t.Any) -&gt; \"te.NoReturn\":\n+    raise TypeError(\"can't create custom node types\")\n+\n+\n+NodeType.__new__ = staticmethod(_failing_new)  # type: ignore\n del _failing_new\ndiff --git a/src/jinja2/optimizer.py b/src/jinja2/optimizer.py\nindex 53d50e4..32d1c71 100644\n--- a/src/jinja2/optimizer.py\n+++ b/src/jinja2/optimizer.py\n@@ -7,20 +7,42 @@ want. For example, loop unrolling doesn't work because unrolled loops\n would have a different scope. The solution would be a second syntax tree\n that stored the scoping rules.\n \"\"\"\n+\n import typing as t\n+\n from . import nodes\n from .visitor import NodeTransformer\n+\n if t.TYPE_CHECKING:\n     from .environment import Environment\n\n\n-def optimize(node: nodes.Node, environment: 'Environment') -&gt;nodes.Node:\n+def optimize(node: nodes.Node, environment: \"Environment\") -&gt; nodes.Node:\n     \"\"\"The context hint can be used to perform an static optimization\n     based on the context given.\"\"\"\n-    pass\n+    optimizer = Optimizer(environment)\n+    return t.cast(nodes.Node, optimizer.visit(node))\n\n\n class Optimizer(NodeTransformer):\n-\n-    def __init__(self, environment: 't.Optional[Environment]') -&gt;None:\n+    def __init__(self, environment: \"t.Optional[Environment]\") -&gt; None:\n         self.environment = environment\n+\n+    def generic_visit(\n+        self, node: nodes.Node, *args: t.Any, **kwargs: t.Any\n+    ) -&gt; nodes.Node:\n+        node = super().generic_visit(node, *args, **kwargs)\n+\n+        # Do constant folding. Some other nodes besides Expr have\n+        # as_const, but folding them causes errors later on.\n+        if isinstance(node, nodes.Expr):\n+            try:\n+                return nodes.Const.from_untrusted(\n+                    node.as_const(args[0] if args else None),\n+                    lineno=node.lineno,\n+                    environment=self.environment,\n+                )\n+            except nodes.Impossible:\n+                pass\n+\n+        return node\ndiff --git a/src/jinja2/parser.py b/src/jinja2/parser.py\nindex 05ce33d..0ec997f 100644\n--- a/src/jinja2/parser.py\n+++ b/src/jinja2/parser.py\n@@ -1,22 +1,48 @@\n \"\"\"Parse tokens from the lexer into nodes for the compiler.\"\"\"\n+\n import typing\n import typing as t\n+\n from . import nodes\n from .exceptions import TemplateAssertionError\n from .exceptions import TemplateSyntaxError\n from .lexer import describe_token\n from .lexer import describe_token_expr\n+\n if t.TYPE_CHECKING:\n     import typing_extensions as te\n+\n     from .environment import Environment\n-_ImportInclude = t.TypeVar('_ImportInclude', nodes.Import, nodes.Include)\n-_MacroCall = t.TypeVar('_MacroCall', nodes.Macro, nodes.CallBlock)\n-_statement_keywords = frozenset(['for', 'if', 'block', 'extends', 'print',\n-    'macro', 'include', 'from', 'import', 'set', 'with', 'autoescape'])\n-_compare_operators = frozenset(['eq', 'ne', 'lt', 'lteq', 'gt', 'gteq'])\n-_math_nodes: t.Dict[str, t.Type[nodes.Expr]] = {'add': nodes.Add, 'sub':\n-    nodes.Sub, 'mul': nodes.Mul, 'div': nodes.Div, 'floordiv': nodes.\n-    FloorDiv, 'mod': nodes.Mod}\n+\n+_ImportInclude = t.TypeVar(\"_ImportInclude\", nodes.Import, nodes.Include)\n+_MacroCall = t.TypeVar(\"_MacroCall\", nodes.Macro, nodes.CallBlock)\n+\n+_statement_keywords = frozenset(\n+    [\n+        \"for\",\n+        \"if\",\n+        \"block\",\n+        \"extends\",\n+        \"print\",\n+        \"macro\",\n+        \"include\",\n+        \"from\",\n+        \"import\",\n+        \"set\",\n+        \"with\",\n+        \"autoescape\",\n+    ]\n+)\n+_compare_operators = frozenset([\"eq\", \"ne\", \"lt\", \"lteq\", \"gt\", \"gteq\"])\n+\n+_math_nodes: t.Dict[str, t.Type[nodes.Expr]] = {\n+    \"add\": nodes.Add,\n+    \"sub\": nodes.Sub,\n+    \"mul\": nodes.Mul,\n+    \"div\": nodes.Div,\n+    \"floordiv\": nodes.FloorDiv,\n+    \"mod\": nodes.Mod,\n+}\n\n\n class Parser:\n@@ -24,16 +50,22 @@ class Parser:\n     extensions and can be used to parse expressions or statements.\n     \"\"\"\n\n-    def __init__(self, environment: 'Environment', source: str, name: t.\n-        Optional[str]=None, filename: t.Optional[str]=None, state: t.\n-        Optional[str]=None) -&gt;None:\n+    def __init__(\n+        self,\n+        environment: \"Environment\",\n+        source: str,\n+        name: t.Optional[str] = None,\n+        filename: t.Optional[str] = None,\n+        state: t.Optional[str] = None,\n+    ) -&gt; None:\n         self.environment = environment\n         self.stream = environment._tokenize(source, name, filename, state)\n         self.name = name\n         self.filename = filename\n         self.closed = False\n-        self.extensions: t.Dict[str, t.Callable[['Parser'], t.Union[nodes.\n-            Node, t.List[nodes.Node]]]] = {}\n+        self.extensions: t.Dict[\n+            str, t.Callable[[\"Parser\"], t.Union[nodes.Node, t.List[nodes.Node]]]\n+        ] = {}\n         for extension in environment.iter_extensions():\n             for tag in extension.tags:\n                 self.extensions[tag] = extension.parse\n@@ -41,43 +73,129 @@ class Parser:\n         self._tag_stack: t.List[str] = []\n         self._end_token_stack: t.List[t.Tuple[str, ...]] = []\n\n-    def fail(self, msg: str, lineno: t.Optional[int]=None, exc: t.Type[\n-        TemplateSyntaxError]=TemplateSyntaxError) -&gt;'te.NoReturn':\n+    def fail(\n+        self,\n+        msg: str,\n+        lineno: t.Optional[int] = None,\n+        exc: t.Type[TemplateSyntaxError] = TemplateSyntaxError,\n+    ) -&gt; \"te.NoReturn\":\n         \"\"\"Convenience method that raises `exc` with the message, passed\n         line number or last line number as well as the current name and\n         filename.\n         \"\"\"\n-        pass\n+        if lineno is None:\n+            lineno = self.stream.current.lineno\n+        raise exc(msg, lineno, self.name, self.filename)\n+\n+    def _fail_ut_eof(\n+        self,\n+        name: t.Optional[str],\n+        end_token_stack: t.List[t.Tuple[str, ...]],\n+        lineno: t.Optional[int],\n+    ) -&gt; \"te.NoReturn\":\n+        expected: t.Set[str] = set()\n+        for exprs in end_token_stack:\n+            expected.update(map(describe_token_expr, exprs))\n+        if end_token_stack:\n+            currently_looking: t.Optional[str] = \" or \".join(\n+                map(repr, map(describe_token_expr, end_token_stack[-1]))\n+            )\n+        else:\n+            currently_looking = None\n+\n+        if name is None:\n+            message = [\"Unexpected end of template.\"]\n+        else:\n+            message = [f\"Encountered unknown tag {name!r}.\"]\n+\n+        if currently_looking:\n+            if name is not None and name in expected:\n+                message.append(\n+                    \"You probably made a nesting mistake. Jinja is expecting this tag,\"\n+                    f\" but currently looking for {currently_looking}.\"\n+                )\n+            else:\n+                message.append(\n+                    f\"Jinja was looking for the following tags: {currently_looking}.\"\n+                )\n+\n+        if self._tag_stack:\n+            message.append(\n+                \"The innermost block that needs to be closed is\"\n+                f\" {self._tag_stack[-1]!r}.\"\n+            )\n\n-    def fail_unknown_tag(self, name: str, lineno: t.Optional[int]=None\n-        ) -&gt;'te.NoReturn':\n+        self.fail(\" \".join(message), lineno)\n+\n+    def fail_unknown_tag(\n+        self, name: str, lineno: t.Optional[int] = None\n+    ) -&gt; \"te.NoReturn\":\n         \"\"\"Called if the parser encounters an unknown tag.  Tries to fail\n         with a human readable error message that could help to identify\n         the problem.\n         \"\"\"\n-        pass\n+        self._fail_ut_eof(name, self._end_token_stack, lineno)\n\n-    def fail_eof(self, end_tokens: t.Optional[t.Tuple[str, ...]]=None,\n-        lineno: t.Optional[int]=None) -&gt;'te.NoReturn':\n+    def fail_eof(\n+        self,\n+        end_tokens: t.Optional[t.Tuple[str, ...]] = None,\n+        lineno: t.Optional[int] = None,\n+    ) -&gt; \"te.NoReturn\":\n         \"\"\"Like fail_unknown_tag but for end of template situations.\"\"\"\n-        pass\n+        stack = list(self._end_token_stack)\n+        if end_tokens is not None:\n+            stack.append(end_tokens)\n+        self._fail_ut_eof(None, stack, lineno)\n\n-    def is_tuple_end(self, extra_end_rules: t.Optional[t.Tuple[str, ...]]=None\n-        ) -&gt;bool:\n+    def is_tuple_end(\n+        self, extra_end_rules: t.Optional[t.Tuple[str, ...]] = None\n+    ) -&gt; bool:\n         \"\"\"Are we at the end of a tuple?\"\"\"\n-        pass\n+        if self.stream.current.type in (\"variable_end\", \"block_end\", \"rparen\"):\n+            return True\n+        elif extra_end_rules is not None:\n+            return self.stream.current.test_any(extra_end_rules)  # type: ignore\n+        return False\n\n-    def free_identifier(self, lineno: t.Optional[int]=None\n-        ) -&gt;nodes.InternalName:\n+    def free_identifier(self, lineno: t.Optional[int] = None) -&gt; nodes.InternalName:\n         \"\"\"Return a new free identifier as :class:`~jinja2.nodes.InternalName`.\"\"\"\n-        pass\n+        self._last_identifier += 1\n+        rv = object.__new__(nodes.InternalName)\n+        nodes.Node.__init__(rv, f\"fi{self._last_identifier}\", lineno=lineno)\n+        return rv\n\n-    def parse_statement(self) -&gt;t.Union[nodes.Node, t.List[nodes.Node]]:\n+    def parse_statement(self) -&gt; t.Union[nodes.Node, t.List[nodes.Node]]:\n         \"\"\"Parse a single statement.\"\"\"\n-        pass\n+        token = self.stream.current\n+        if token.type != \"name\":\n+            self.fail(\"tag name expected\", token.lineno)\n+        self._tag_stack.append(token.value)\n+        pop_tag = True\n+        try:\n+            if token.value in _statement_keywords:\n+                f = getattr(self, f\"parse_{self.stream.current.value}\")\n+                return f()  # type: ignore\n+            if token.value == \"call\":\n+                return self.parse_call_block()\n+            if token.value == \"filter\":\n+                return self.parse_filter_block()\n+            ext = self.extensions.get(token.value)\n+            if ext is not None:\n+                return ext(self)\n+\n+            # did not work out, remove the token we pushed by accident\n+            # from the stack so that the unknown tag fail function can\n+            # produce a proper error message.\n+            self._tag_stack.pop()\n+            pop_tag = False\n+            self.fail_unknown_tag(token.value, token.lineno)\n+        finally:\n+            if pop_tag:\n+                self._tag_stack.pop()\n\n-    def parse_statements(self, end_tokens: t.Tuple[str, ...], drop_needle:\n-        bool=False) -&gt;t.List[nodes.Node]:\n+    def parse_statements(\n+        self, end_tokens: t.Tuple[str, ...], drop_needle: bool = False\n+    ) -&gt; t.List[nodes.Node]:\n         \"\"\"Parse multiple statements into a list until one of the end tokens\n         is reached.  This is used to parse the body of statements as it also\n         parses template data if appropriate.  The parser checks first if the\n@@ -87,24 +205,278 @@ class Parser:\n         the call is the matched end token.  If this is not wanted `drop_needle`\n         can be set to `True` and the end token is removed.\n         \"\"\"\n-        pass\n+        # the first token may be a colon for python compatibility\n+        self.stream.skip_if(\"colon\")\n+\n+        # in the future it would be possible to add whole code sections\n+        # by adding some sort of end of statement token and parsing those here.\n+        self.stream.expect(\"block_end\")\n+        result = self.subparse(end_tokens)\n\n-    def parse_set(self) -&gt;t.Union[nodes.Assign, nodes.AssignBlock]:\n+        # we reached the end of the template too early, the subparser\n+        # does not check for this, so we do that now\n+        if self.stream.current.type == \"eof\":\n+            self.fail_eof(end_tokens)\n+\n+        if drop_needle:\n+            next(self.stream)\n+        return result\n+\n+    def parse_set(self) -&gt; t.Union[nodes.Assign, nodes.AssignBlock]:\n         \"\"\"Parse an assign statement.\"\"\"\n-        pass\n+        lineno = next(self.stream).lineno\n+        target = self.parse_assign_target(with_namespace=True)\n+        if self.stream.skip_if(\"assign\"):\n+            expr = self.parse_tuple()\n+            return nodes.Assign(target, expr, lineno=lineno)\n+        filter_node = self.parse_filter(None)\n+        body = self.parse_statements((\"name:endset\",), drop_needle=True)\n+        return nodes.AssignBlock(target, filter_node, body, lineno=lineno)\n\n-    def parse_for(self) -&gt;nodes.For:\n+    def parse_for(self) -&gt; nodes.For:\n         \"\"\"Parse a for loop.\"\"\"\n-        pass\n+        lineno = self.stream.expect(\"name:for\").lineno\n+        target = self.parse_assign_target(extra_end_rules=(\"name:in\",))\n+        self.stream.expect(\"name:in\")\n+        iter = self.parse_tuple(\n+            with_condexpr=False, extra_end_rules=(\"name:recursive\",)\n+        )\n+        test = None\n+        if self.stream.skip_if(\"name:if\"):\n+            test = self.parse_expression()\n+        recursive = self.stream.skip_if(\"name:recursive\")\n+        body = self.parse_statements((\"name:endfor\", \"name:else\"))\n+        if next(self.stream).value == \"endfor\":\n+            else_ = []\n+        else:\n+            else_ = self.parse_statements((\"name:endfor\",), drop_needle=True)\n+        return nodes.For(target, iter, body, else_, test, recursive, lineno=lineno)\n\n-    def parse_if(self) -&gt;nodes.If:\n+    def parse_if(self) -&gt; nodes.If:\n         \"\"\"Parse an if construct.\"\"\"\n-        pass\n+        node = result = nodes.If(lineno=self.stream.expect(\"name:if\").lineno)\n+        while True:\n+            node.test = self.parse_tuple(with_condexpr=False)\n+            node.body = self.parse_statements((\"name:elif\", \"name:else\", \"name:endif\"))\n+            node.elif_ = []\n+            node.else_ = []\n+            token = next(self.stream)\n+            if token.test(\"name:elif\"):\n+                node = nodes.If(lineno=self.stream.current.lineno)\n+                result.elif_.append(node)\n+                continue\n+            elif token.test(\"name:else\"):\n+                result.else_ = self.parse_statements((\"name:endif\",), drop_needle=True)\n+            break\n+        return result\n+\n+    def parse_with(self) -&gt; nodes.With:\n+        node = nodes.With(lineno=next(self.stream).lineno)\n+        targets: t.List[nodes.Expr] = []\n+        values: t.List[nodes.Expr] = []\n+        while self.stream.current.type != \"block_end\":\n+            if targets:\n+                self.stream.expect(\"comma\")\n+            target = self.parse_assign_target()\n+            target.set_ctx(\"param\")\n+            targets.append(target)\n+            self.stream.expect(\"assign\")\n+            values.append(self.parse_expression())\n+        node.targets = targets\n+        node.values = values\n+        node.body = self.parse_statements((\"name:endwith\",), drop_needle=True)\n+        return node\n+\n+    def parse_autoescape(self) -&gt; nodes.Scope:\n+        node = nodes.ScopedEvalContextModifier(lineno=next(self.stream).lineno)\n+        node.options = [nodes.Keyword(\"autoescape\", self.parse_expression())]\n+        node.body = self.parse_statements((\"name:endautoescape\",), drop_needle=True)\n+        return nodes.Scope([node])\n+\n+    def parse_block(self) -&gt; nodes.Block:\n+        node = nodes.Block(lineno=next(self.stream).lineno)\n+        node.name = self.stream.expect(\"name\").value\n+        node.scoped = self.stream.skip_if(\"name:scoped\")\n+        node.required = self.stream.skip_if(\"name:required\")\n+\n+        # common problem people encounter when switching from django\n+        # to jinja.  we do not support hyphens in block names, so let's\n+        # raise a nicer error message in that case.\n+        if self.stream.current.type == \"sub\":\n+            self.fail(\n+                \"Block names in Jinja have to be valid Python identifiers and may not\"\n+                \" contain hyphens, use an underscore instead.\"\n+            )\n+\n+        node.body = self.parse_statements((\"name:endblock\",), drop_needle=True)\n+\n+        # enforce that required blocks only contain whitespace or comments\n+        # by asserting that the body, if not empty, is just TemplateData nodes\n+        # with whitespace data\n+        if node.required:\n+            for body_node in node.body:\n+                if not isinstance(body_node, nodes.Output) or any(\n+                    not isinstance(output_node, nodes.TemplateData)\n+                    or not output_node.data.isspace()\n+                    for output_node in body_node.nodes\n+                ):\n+                    self.fail(\"Required blocks can only contain comments or whitespace\")\n\n-    def parse_assign_target(self, with_tuple: bool=True, name_only: bool=\n-        False, extra_end_rules: t.Optional[t.Tuple[str, ...]]=None,\n-        with_namespace: bool=False) -&gt;t.Union[nodes.NSRef, nodes.Name,\n-        nodes.Tuple]:\n+        self.stream.skip_if(\"name:\" + node.name)\n+        return node\n+\n+    def parse_extends(self) -&gt; nodes.Extends:\n+        node = nodes.Extends(lineno=next(self.stream).lineno)\n+        node.template = self.parse_expression()\n+        return node\n+\n+    def parse_import_context(\n+        self, node: _ImportInclude, default: bool\n+    ) -&gt; _ImportInclude:\n+        if self.stream.current.test_any(\n+            \"name:with\", \"name:without\"\n+        ) and self.stream.look().test(\"name:context\"):\n+            node.with_context = next(self.stream).value == \"with\"\n+            self.stream.skip()\n+        else:\n+            node.with_context = default\n+        return node\n+\n+    def parse_include(self) -&gt; nodes.Include:\n+        node = nodes.Include(lineno=next(self.stream).lineno)\n+        node.template = self.parse_expression()\n+        if self.stream.current.test(\"name:ignore\") and self.stream.look().test(\n+            \"name:missing\"\n+        ):\n+            node.ignore_missing = True\n+            self.stream.skip(2)\n+        else:\n+            node.ignore_missing = False\n+        return self.parse_import_context(node, True)\n+\n+    def parse_import(self) -&gt; nodes.Import:\n+        node = nodes.Import(lineno=next(self.stream).lineno)\n+        node.template = self.parse_expression()\n+        self.stream.expect(\"name:as\")\n+        node.target = self.parse_assign_target(name_only=True).name\n+        return self.parse_import_context(node, False)\n+\n+    def parse_from(self) -&gt; nodes.FromImport:\n+        node = nodes.FromImport(lineno=next(self.stream).lineno)\n+        node.template = self.parse_expression()\n+        self.stream.expect(\"name:import\")\n+        node.names = []\n+\n+        def parse_context() -&gt; bool:\n+            if self.stream.current.value in {\n+                \"with\",\n+                \"without\",\n+            } and self.stream.look().test(\"name:context\"):\n+                node.with_context = next(self.stream).value == \"with\"\n+                self.stream.skip()\n+                return True\n+            return False\n+\n+        while True:\n+            if node.names:\n+                self.stream.expect(\"comma\")\n+            if self.stream.current.type == \"name\":\n+                if parse_context():\n+                    break\n+                target = self.parse_assign_target(name_only=True)\n+                if target.name.startswith(\"_\"):\n+                    self.fail(\n+                        \"names starting with an underline can not be imported\",\n+                        target.lineno,\n+                        exc=TemplateAssertionError,\n+                    )\n+                if self.stream.skip_if(\"name:as\"):\n+                    alias = self.parse_assign_target(name_only=True)\n+                    node.names.append((target.name, alias.name))\n+                else:\n+                    node.names.append(target.name)\n+                if parse_context() or self.stream.current.type != \"comma\":\n+                    break\n+            else:\n+                self.stream.expect(\"name\")\n+        if not hasattr(node, \"with_context\"):\n+            node.with_context = False\n+        return node\n+\n+    def parse_signature(self, node: _MacroCall) -&gt; None:\n+        args = node.args = []\n+        defaults = node.defaults = []\n+        self.stream.expect(\"lparen\")\n+        while self.stream.current.type != \"rparen\":\n+            if args:\n+                self.stream.expect(\"comma\")\n+            arg = self.parse_assign_target(name_only=True)\n+            arg.set_ctx(\"param\")\n+            if self.stream.skip_if(\"assign\"):\n+                defaults.append(self.parse_expression())\n+            elif defaults:\n+                self.fail(\"non-default argument follows default argument\")\n+            args.append(arg)\n+        self.stream.expect(\"rparen\")\n+\n+    def parse_call_block(self) -&gt; nodes.CallBlock:\n+        node = nodes.CallBlock(lineno=next(self.stream).lineno)\n+        if self.stream.current.type == \"lparen\":\n+            self.parse_signature(node)\n+        else:\n+            node.args = []\n+            node.defaults = []\n+\n+        call_node = self.parse_expression()\n+        if not isinstance(call_node, nodes.Call):\n+            self.fail(\"expected call\", node.lineno)\n+        node.call = call_node\n+        node.body = self.parse_statements((\"name:endcall\",), drop_needle=True)\n+        return node\n+\n+    def parse_filter_block(self) -&gt; nodes.FilterBlock:\n+        node = nodes.FilterBlock(lineno=next(self.stream).lineno)\n+        node.filter = self.parse_filter(None, start_inline=True)  # type: ignore\n+        node.body = self.parse_statements((\"name:endfilter\",), drop_needle=True)\n+        return node\n+\n+    def parse_macro(self) -&gt; nodes.Macro:\n+        node = nodes.Macro(lineno=next(self.stream).lineno)\n+        node.name = self.parse_assign_target(name_only=True).name\n+        self.parse_signature(node)\n+        node.body = self.parse_statements((\"name:endmacro\",), drop_needle=True)\n+        return node\n+\n+    def parse_print(self) -&gt; nodes.Output:\n+        node = nodes.Output(lineno=next(self.stream).lineno)\n+        node.nodes = []\n+        while self.stream.current.type != \"block_end\":\n+            if node.nodes:\n+                self.stream.expect(\"comma\")\n+            node.nodes.append(self.parse_expression())\n+        return node\n+\n+    @typing.overload\n+    def parse_assign_target(\n+        self, with_tuple: bool = ..., name_only: \"te.Literal[True]\" = ...\n+    ) -&gt; nodes.Name: ...\n+\n+    @typing.overload\n+    def parse_assign_target(\n+        self,\n+        with_tuple: bool = True,\n+        name_only: bool = False,\n+        extra_end_rules: t.Optional[t.Tuple[str, ...]] = None,\n+        with_namespace: bool = False,\n+    ) -&gt; t.Union[nodes.NSRef, nodes.Name, nodes.Tuple]: ...\n+\n+    def parse_assign_target(\n+        self,\n+        with_tuple: bool = True,\n+        name_only: bool = False,\n+        extra_end_rules: t.Optional[t.Tuple[str, ...]] = None,\n+        with_namespace: bool = False,\n+    ) -&gt; t.Union[nodes.NSRef, nodes.Name, nodes.Tuple]:\n         \"\"\"Parse an assignment target.  As Jinja allows assignments to\n         tuples, this function can parse all allowed assignment targets.  Per\n         default assignments to tuples are parsed, that can be disable however\n@@ -113,18 +485,205 @@ class Parser:\n         parameter is forwarded to the tuple parsing function.  If\n         `with_namespace` is enabled, a namespace assignment may be parsed.\n         \"\"\"\n-        pass\n+        target: nodes.Expr\n+\n+        if with_namespace and self.stream.look().type == \"dot\":\n+            token = self.stream.expect(\"name\")\n+            next(self.stream)  # dot\n+            attr = self.stream.expect(\"name\")\n+            target = nodes.NSRef(token.value, attr.value, lineno=token.lineno)\n+        elif name_only:\n+            token = self.stream.expect(\"name\")\n+            target = nodes.Name(token.value, \"store\", lineno=token.lineno)\n+        else:\n+            if with_tuple:\n+                target = self.parse_tuple(\n+                    simplified=True, extra_end_rules=extra_end_rules\n+                )\n+            else:\n+                target = self.parse_primary()\n\n-    def parse_expression(self, with_condexpr: bool=True) -&gt;nodes.Expr:\n+            target.set_ctx(\"store\")\n+\n+        if not target.can_assign():\n+            self.fail(\n+                f\"can't assign to {type(target).__name__.lower()!r}\", target.lineno\n+            )\n+\n+        return target  # type: ignore\n+\n+    def parse_expression(self, with_condexpr: bool = True) -&gt; nodes.Expr:\n         \"\"\"Parse an expression.  Per default all expressions are parsed, if\n         the optional `with_condexpr` parameter is set to `False` conditional\n         expressions are not parsed.\n         \"\"\"\n-        pass\n+        if with_condexpr:\n+            return self.parse_condexpr()\n+        return self.parse_or()\n+\n+    def parse_condexpr(self) -&gt; nodes.Expr:\n+        lineno = self.stream.current.lineno\n+        expr1 = self.parse_or()\n+        expr3: t.Optional[nodes.Expr]\n+\n+        while self.stream.skip_if(\"name:if\"):\n+            expr2 = self.parse_or()\n+            if self.stream.skip_if(\"name:else\"):\n+                expr3 = self.parse_condexpr()\n+            else:\n+                expr3 = None\n+            expr1 = nodes.CondExpr(expr2, expr1, expr3, lineno=lineno)\n+            lineno = self.stream.current.lineno\n+        return expr1\n\n-    def parse_tuple(self, simplified: bool=False, with_condexpr: bool=True,\n-        extra_end_rules: t.Optional[t.Tuple[str, ...]]=None,\n-        explicit_parentheses: bool=False) -&gt;t.Union[nodes.Tuple, nodes.Expr]:\n+    def parse_or(self) -&gt; nodes.Expr:\n+        lineno = self.stream.current.lineno\n+        left = self.parse_and()\n+        while self.stream.skip_if(\"name:or\"):\n+            right = self.parse_and()\n+            left = nodes.Or(left, right, lineno=lineno)\n+            lineno = self.stream.current.lineno\n+        return left\n+\n+    def parse_and(self) -&gt; nodes.Expr:\n+        lineno = self.stream.current.lineno\n+        left = self.parse_not()\n+        while self.stream.skip_if(\"name:and\"):\n+            right = self.parse_not()\n+            left = nodes.And(left, right, lineno=lineno)\n+            lineno = self.stream.current.lineno\n+        return left\n+\n+    def parse_not(self) -&gt; nodes.Expr:\n+        if self.stream.current.test(\"name:not\"):\n+            lineno = next(self.stream).lineno\n+            return nodes.Not(self.parse_not(), lineno=lineno)\n+        return self.parse_compare()\n+\n+    def parse_compare(self) -&gt; nodes.Expr:\n+        lineno = self.stream.current.lineno\n+        expr = self.parse_math1()\n+        ops = []\n+        while True:\n+            token_type = self.stream.current.type\n+            if token_type in _compare_operators:\n+                next(self.stream)\n+                ops.append(nodes.Operand(token_type, self.parse_math1()))\n+            elif self.stream.skip_if(\"name:in\"):\n+                ops.append(nodes.Operand(\"in\", self.parse_math1()))\n+            elif self.stream.current.test(\"name:not\") and self.stream.look().test(\n+                \"name:in\"\n+            ):\n+                self.stream.skip(2)\n+                ops.append(nodes.Operand(\"notin\", self.parse_math1()))\n+            else:\n+                break\n+            lineno = self.stream.current.lineno\n+        if not ops:\n+            return expr\n+        return nodes.Compare(expr, ops, lineno=lineno)\n+\n+    def parse_math1(self) -&gt; nodes.Expr:\n+        lineno = self.stream.current.lineno\n+        left = self.parse_concat()\n+        while self.stream.current.type in (\"add\", \"sub\"):\n+            cls = _math_nodes[self.stream.current.type]\n+            next(self.stream)\n+            right = self.parse_concat()\n+            left = cls(left, right, lineno=lineno)\n+            lineno = self.stream.current.lineno\n+        return left\n+\n+    def parse_concat(self) -&gt; nodes.Expr:\n+        lineno = self.stream.current.lineno\n+        args = [self.parse_math2()]\n+        while self.stream.current.type == \"tilde\":\n+            next(self.stream)\n+            args.append(self.parse_math2())\n+        if len(args) == 1:\n+            return args[0]\n+        return nodes.Concat(args, lineno=lineno)\n+\n+    def parse_math2(self) -&gt; nodes.Expr:\n+        lineno = self.stream.current.lineno\n+        left = self.parse_pow()\n+        while self.stream.current.type in (\"mul\", \"div\", \"floordiv\", \"mod\"):\n+            cls = _math_nodes[self.stream.current.type]\n+            next(self.stream)\n+            right = self.parse_pow()\n+            left = cls(left, right, lineno=lineno)\n+            lineno = self.stream.current.lineno\n+        return left\n+\n+    def parse_pow(self) -&gt; nodes.Expr:\n+        lineno = self.stream.current.lineno\n+        left = self.parse_unary()\n+        while self.stream.current.type == \"pow\":\n+            next(self.stream)\n+            right = self.parse_unary()\n+            left = nodes.Pow(left, right, lineno=lineno)\n+            lineno = self.stream.current.lineno\n+        return left\n+\n+    def parse_unary(self, with_filter: bool = True) -&gt; nodes.Expr:\n+        token_type = self.stream.current.type\n+        lineno = self.stream.current.lineno\n+        node: nodes.Expr\n+\n+        if token_type == \"sub\":\n+            next(self.stream)\n+            node = nodes.Neg(self.parse_unary(False), lineno=lineno)\n+        elif token_type == \"add\":\n+            next(self.stream)\n+            node = nodes.Pos(self.parse_unary(False), lineno=lineno)\n+        else:\n+            node = self.parse_primary()\n+        node = self.parse_postfix(node)\n+        if with_filter:\n+            node = self.parse_filter_expr(node)\n+        return node\n+\n+    def parse_primary(self) -&gt; nodes.Expr:\n+        token = self.stream.current\n+        node: nodes.Expr\n+        if token.type == \"name\":\n+            if token.value in (\"true\", \"false\", \"True\", \"False\"):\n+                node = nodes.Const(token.value in (\"true\", \"True\"), lineno=token.lineno)\n+            elif token.value in (\"none\", \"None\"):\n+                node = nodes.Const(None, lineno=token.lineno)\n+            else:\n+                node = nodes.Name(token.value, \"load\", lineno=token.lineno)\n+            next(self.stream)\n+        elif token.type == \"string\":\n+            next(self.stream)\n+            buf = [token.value]\n+            lineno = token.lineno\n+            while self.stream.current.type == \"string\":\n+                buf.append(self.stream.current.value)\n+                next(self.stream)\n+            node = nodes.Const(\"\".join(buf), lineno=lineno)\n+        elif token.type in (\"integer\", \"float\"):\n+            next(self.stream)\n+            node = nodes.Const(token.value, lineno=token.lineno)\n+        elif token.type == \"lparen\":\n+            next(self.stream)\n+            node = self.parse_tuple(explicit_parentheses=True)\n+            self.stream.expect(\"rparen\")\n+        elif token.type == \"lbracket\":\n+            node = self.parse_list()\n+        elif token.type == \"lbrace\":\n+            node = self.parse_dict()\n+        else:\n+            self.fail(f\"unexpected {describe_token(token)!r}\", token.lineno)\n+        return node\n+\n+    def parse_tuple(\n+        self,\n+        simplified: bool = False,\n+        with_condexpr: bool = True,\n+        extra_end_rules: t.Optional[t.Tuple[str, ...]] = None,\n+        explicit_parentheses: bool = False,\n+    ) -&gt; t.Union[nodes.Tuple, nodes.Expr]:\n         \"\"\"Works like `parse_expression` but if multiple expressions are\n         delimited by a comma a :class:`~jinja2.nodes.Tuple` node is created.\n         This method could also return a regular expression instead of a tuple\n@@ -143,8 +702,340 @@ class Parser:\n         expression in parentheses.  This is used to figure out if an empty\n         tuple is a valid expression or not.\n         \"\"\"\n-        pass\n+        lineno = self.stream.current.lineno\n+        if simplified:\n+            parse = self.parse_primary\n+        elif with_condexpr:\n+            parse = self.parse_expression\n+        else:\n+\n+            def parse() -&gt; nodes.Expr:\n+                return self.parse_expression(with_condexpr=False)\n+\n+        args: t.List[nodes.Expr] = []\n+        is_tuple = False\n+\n+        while True:\n+            if args:\n+                self.stream.expect(\"comma\")\n+            if self.is_tuple_end(extra_end_rules):\n+                break\n+            args.append(parse())\n+            if self.stream.current.type == \"comma\":\n+                is_tuple = True\n+            else:\n+                break\n+            lineno = self.stream.current.lineno\n+\n+        if not is_tuple:\n+            if args:\n+                return args[0]\n+\n+            # if we don't have explicit parentheses, an empty tuple is\n+            # not a valid expression.  This would mean nothing (literally\n+            # nothing) in the spot of an expression would be an empty\n+            # tuple.\n+            if not explicit_parentheses:\n+                self.fail(\n+                    \"Expected an expression,\"\n+                    f\" got {describe_token(self.stream.current)!r}\"\n+                )\n+\n+        return nodes.Tuple(args, \"load\", lineno=lineno)\n+\n+    def parse_list(self) -&gt; nodes.List:\n+        token = self.stream.expect(\"lbracket\")\n+        items: t.List[nodes.Expr] = []\n+        while self.stream.current.type != \"rbracket\":\n+            if items:\n+                self.stream.expect(\"comma\")\n+            if self.stream.current.type == \"rbracket\":\n+                break\n+            items.append(self.parse_expression())\n+        self.stream.expect(\"rbracket\")\n+        return nodes.List(items, lineno=token.lineno)\n+\n+    def parse_dict(self) -&gt; nodes.Dict:\n+        token = self.stream.expect(\"lbrace\")\n+        items: t.List[nodes.Pair] = []\n+        while self.stream.current.type != \"rbrace\":\n+            if items:\n+                self.stream.expect(\"comma\")\n+            if self.stream.current.type == \"rbrace\":\n+                break\n+            key = self.parse_expression()\n+            self.stream.expect(\"colon\")\n+            value = self.parse_expression()\n+            items.append(nodes.Pair(key, value, lineno=key.lineno))\n+        self.stream.expect(\"rbrace\")\n+        return nodes.Dict(items, lineno=token.lineno)\n+\n+    def parse_postfix(self, node: nodes.Expr) -&gt; nodes.Expr:\n+        while True:\n+            token_type = self.stream.current.type\n+            if token_type == \"dot\" or token_type == \"lbracket\":\n+                node = self.parse_subscript(node)\n+            # calls are valid both after postfix expressions (getattr\n+            # and getitem) as well as filters and tests\n+            elif token_type == \"lparen\":\n+                node = self.parse_call(node)\n+            else:\n+                break\n+        return node\n+\n+    def parse_filter_expr(self, node: nodes.Expr) -&gt; nodes.Expr:\n+        while True:\n+            token_type = self.stream.current.type\n+            if token_type == \"pipe\":\n+                node = self.parse_filter(node)  # type: ignore\n+            elif token_type == \"name\" and self.stream.current.value == \"is\":\n+                node = self.parse_test(node)\n+            # calls are valid both after postfix expressions (getattr\n+            # and getitem) as well as filters and tests\n+            elif token_type == \"lparen\":\n+                node = self.parse_call(node)\n+            else:\n+                break\n+        return node\n+\n+    def parse_subscript(\n+        self, node: nodes.Expr\n+    ) -&gt; t.Union[nodes.Getattr, nodes.Getitem]:\n+        token = next(self.stream)\n+        arg: nodes.Expr\n+\n+        if token.type == \"dot\":\n+            attr_token = self.stream.current\n+            next(self.stream)\n+            if attr_token.type == \"name\":\n+                return nodes.Getattr(\n+                    node, attr_token.value, \"load\", lineno=token.lineno\n+                )\n+            elif attr_token.type != \"integer\":\n+                self.fail(\"expected name or number\", attr_token.lineno)\n+            arg = nodes.Const(attr_token.value, lineno=attr_token.lineno)\n+            return nodes.Getitem(node, arg, \"load\", lineno=token.lineno)\n+        if token.type == \"lbracket\":\n+            args: t.List[nodes.Expr] = []\n+            while self.stream.current.type != \"rbracket\":\n+                if args:\n+                    self.stream.expect(\"comma\")\n+                args.append(self.parse_subscribed())\n+            self.stream.expect(\"rbracket\")\n+            if len(args) == 1:\n+                arg = args[0]\n+            else:\n+                arg = nodes.Tuple(args, \"load\", lineno=token.lineno)\n+            return nodes.Getitem(node, arg, \"load\", lineno=token.lineno)\n+        self.fail(\"expected subscript expression\", token.lineno)\n+\n+    def parse_subscribed(self) -&gt; nodes.Expr:\n+        lineno = self.stream.current.lineno\n+        args: t.List[t.Optional[nodes.Expr]]\n+\n+        if self.stream.current.type == \"colon\":\n+            next(self.stream)\n+            args = [None]\n+        else:\n+            node = self.parse_expression()\n+            if self.stream.current.type != \"colon\":\n+                return node\n+            next(self.stream)\n+            args = [node]\n+\n+        if self.stream.current.type == \"colon\":\n+            args.append(None)\n+        elif self.stream.current.type not in (\"rbracket\", \"comma\"):\n+            args.append(self.parse_expression())\n+        else:\n+            args.append(None)\n+\n+        if self.stream.current.type == \"colon\":\n+            next(self.stream)\n+            if self.stream.current.type not in (\"rbracket\", \"comma\"):\n+                args.append(self.parse_expression())\n+            else:\n+                args.append(None)\n+        else:\n+            args.append(None)\n+\n+        return nodes.Slice(lineno=lineno, *args)  # noqa: B026\n+\n+    def parse_call_args(\n+        self,\n+    ) -&gt; t.Tuple[\n+        t.List[nodes.Expr],\n+        t.List[nodes.Keyword],\n+        t.Optional[nodes.Expr],\n+        t.Optional[nodes.Expr],\n+    ]:\n+        token = self.stream.expect(\"lparen\")\n+        args = []\n+        kwargs = []\n+        dyn_args = None\n+        dyn_kwargs = None\n+        require_comma = False\n+\n+        def ensure(expr: bool) -&gt; None:\n+            if not expr:\n+                self.fail(\"invalid syntax for function call expression\", token.lineno)\n+\n+        while self.stream.current.type != \"rparen\":\n+            if require_comma:\n+                self.stream.expect(\"comma\")\n+\n+                # support for trailing comma\n+                if self.stream.current.type == \"rparen\":\n+                    break\n+\n+            if self.stream.current.type == \"mul\":\n+                ensure(dyn_args is None and dyn_kwargs is None)\n+                next(self.stream)\n+                dyn_args = self.parse_expression()\n+            elif self.stream.current.type == \"pow\":\n+                ensure(dyn_kwargs is None)\n+                next(self.stream)\n+                dyn_kwargs = self.parse_expression()\n+            else:\n+                if (\n+                    self.stream.current.type == \"name\"\n+                    and self.stream.look().type == \"assign\"\n+                ):\n+                    # Parsing a kwarg\n+                    ensure(dyn_kwargs is None)\n+                    key = self.stream.current.value\n+                    self.stream.skip(2)\n+                    value = self.parse_expression()\n+                    kwargs.append(nodes.Keyword(key, value, lineno=value.lineno))\n+                else:\n+                    # Parsing an arg\n+                    ensure(dyn_args is None and dyn_kwargs is None and not kwargs)\n+                    args.append(self.parse_expression())\n+\n+            require_comma = True\n+\n+        self.stream.expect(\"rparen\")\n+        return args, kwargs, dyn_args, dyn_kwargs\n+\n+    def parse_call(self, node: nodes.Expr) -&gt; nodes.Call:\n+        # The lparen will be expected in parse_call_args, but the lineno\n+        # needs to be recorded before the stream is advanced.\n+        token = self.stream.current\n+        args, kwargs, dyn_args, dyn_kwargs = self.parse_call_args()\n+        return nodes.Call(node, args, kwargs, dyn_args, dyn_kwargs, lineno=token.lineno)\n+\n+    def parse_filter(\n+        self, node: t.Optional[nodes.Expr], start_inline: bool = False\n+    ) -&gt; t.Optional[nodes.Expr]:\n+        while self.stream.current.type == \"pipe\" or start_inline:\n+            if not start_inline:\n+                next(self.stream)\n+            token = self.stream.expect(\"name\")\n+            name = token.value\n+            while self.stream.current.type == \"dot\":\n+                next(self.stream)\n+                name += \".\" + self.stream.expect(\"name\").value\n+            if self.stream.current.type == \"lparen\":\n+                args, kwargs, dyn_args, dyn_kwargs = self.parse_call_args()\n+            else:\n+                args = []\n+                kwargs = []\n+                dyn_args = dyn_kwargs = None\n+            node = nodes.Filter(\n+                node, name, args, kwargs, dyn_args, dyn_kwargs, lineno=token.lineno\n+            )\n+            start_inline = False\n+        return node\n+\n+    def parse_test(self, node: nodes.Expr) -&gt; nodes.Expr:\n+        token = next(self.stream)\n+        if self.stream.current.test(\"name:not\"):\n+            next(self.stream)\n+            negated = True\n+        else:\n+            negated = False\n+        name = self.stream.expect(\"name\").value\n+        while self.stream.current.type == \"dot\":\n+            next(self.stream)\n+            name += \".\" + self.stream.expect(\"name\").value\n+        dyn_args = dyn_kwargs = None\n+        kwargs: t.List[nodes.Keyword] = []\n+        if self.stream.current.type == \"lparen\":\n+            args, kwargs, dyn_args, dyn_kwargs = self.parse_call_args()\n+        elif self.stream.current.type in {\n+            \"name\",\n+            \"string\",\n+            \"integer\",\n+            \"float\",\n+            \"lparen\",\n+            \"lbracket\",\n+            \"lbrace\",\n+        } and not self.stream.current.test_any(\"name:else\", \"name:or\", \"name:and\"):\n+            if self.stream.current.test(\"name:is\"):\n+                self.fail(\"You cannot chain multiple tests with is\")\n+            arg_node = self.parse_primary()\n+            arg_node = self.parse_postfix(arg_node)\n+            args = [arg_node]\n+        else:\n+            args = []\n+        node = nodes.Test(\n+            node, name, args, kwargs, dyn_args, dyn_kwargs, lineno=token.lineno\n+        )\n+        if negated:\n+            node = nodes.Not(node, lineno=token.lineno)\n+        return node\n+\n+    def subparse(\n+        self, end_tokens: t.Optional[t.Tuple[str, ...]] = None\n+    ) -&gt; t.List[nodes.Node]:\n+        body: t.List[nodes.Node] = []\n+        data_buffer: t.List[nodes.Node] = []\n+        add_data = data_buffer.append\n+\n+        if end_tokens is not None:\n+            self._end_token_stack.append(end_tokens)\n+\n+        def flush_data() -&gt; None:\n+            if data_buffer:\n+                lineno = data_buffer[0].lineno\n+                body.append(nodes.Output(data_buffer[:], lineno=lineno))\n+                del data_buffer[:]\n+\n+        try:\n+            while self.stream:\n+                token = self.stream.current\n+                if token.type == \"data\":\n+                    if token.value:\n+                        add_data(nodes.TemplateData(token.value, lineno=token.lineno))\n+                    next(self.stream)\n+                elif token.type == \"variable_begin\":\n+                    next(self.stream)\n+                    add_data(self.parse_tuple(with_condexpr=True))\n+                    self.stream.expect(\"variable_end\")\n+                elif token.type == \"block_begin\":\n+                    flush_data()\n+                    next(self.stream)\n+                    if end_tokens is not None and self.stream.current.test_any(\n+                        *end_tokens\n+                    ):\n+                        return body\n+                    rv = self.parse_statement()\n+                    if isinstance(rv, list):\n+                        body.extend(rv)\n+                    else:\n+                        body.append(rv)\n+                    self.stream.expect(\"block_end\")\n+                else:\n+                    raise AssertionError(\"internal parsing error\")\n+\n+            flush_data()\n+        finally:\n+            if end_tokens is not None:\n+                self._end_token_stack.pop()\n+        return body\n\n-    def parse(self) -&gt;nodes.Template:\n+    def parse(self) -&gt; nodes.Template:\n         \"\"\"Parse the whole template into a `Template` node.\"\"\"\n-        pass\n+        result = nodes.Template(self.subparse(), lineno=1)\n+        result.set_environment(self.environment)\n+        return result\ndiff --git a/src/jinja2/runtime.py b/src/jinja2/runtime.py\nindex c88211d..4325c8d 100644\n--- a/src/jinja2/runtime.py\n+++ b/src/jinja2/runtime.py\n@@ -1,82 +1,144 @@\n \"\"\"The runtime functions and state used by compiled templates.\"\"\"\n+\n import functools\n import sys\n import typing as t\n from collections import abc\n from itertools import chain\n-from markupsafe import escape\n+\n+from markupsafe import escape  # noqa: F401\n from markupsafe import Markup\n from markupsafe import soft_str\n+\n from .async_utils import auto_aiter\n-from .async_utils import auto_await\n-from .exceptions import TemplateNotFound\n-from .exceptions import TemplateRuntimeError\n+from .async_utils import auto_await  # noqa: F401\n+from .exceptions import TemplateNotFound  # noqa: F401\n+from .exceptions import TemplateRuntimeError  # noqa: F401\n from .exceptions import UndefinedError\n from .nodes import EvalContext\n from .utils import _PassArg\n from .utils import concat\n from .utils import internalcode\n from .utils import missing\n-from .utils import Namespace\n+from .utils import Namespace  # noqa: F401\n from .utils import object_type_repr\n from .utils import pass_eval_context\n-V = t.TypeVar('V')\n-F = t.TypeVar('F', bound=t.Callable[..., t.Any])\n+\n+V = t.TypeVar(\"V\")\n+F = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n+\n if t.TYPE_CHECKING:\n     import logging\n+\n     import typing_extensions as te\n-    from .environment import Environment\n\n+    from .environment import Environment\n\n     class LoopRenderFunc(te.Protocol):\n-\n-        def __call__(self, reciter: t.Iterable[V], loop_render_func:\n-            'LoopRenderFunc', depth: int=0) -&gt;str:\n-            ...\n-exported = ['LoopContext', 'TemplateReference', 'Macro', 'Markup',\n-    'TemplateRuntimeError', 'missing', 'escape', 'markup_join', 'str_join',\n-    'identity', 'TemplateNotFound', 'Namespace', 'Undefined', 'internalcode']\n-async_exported = ['AsyncLoopContext', 'auto_aiter', 'auto_await']\n-\n-\n-def identity(x: V) -&gt;V:\n+        def __call__(\n+            self,\n+            reciter: t.Iterable[V],\n+            loop_render_func: \"LoopRenderFunc\",\n+            depth: int = 0,\n+        ) -&gt; str: ...\n+\n+\n+# these variables are exported to the template runtime\n+exported = [\n+    \"LoopContext\",\n+    \"TemplateReference\",\n+    \"Macro\",\n+    \"Markup\",\n+    \"TemplateRuntimeError\",\n+    \"missing\",\n+    \"escape\",\n+    \"markup_join\",\n+    \"str_join\",\n+    \"identity\",\n+    \"TemplateNotFound\",\n+    \"Namespace\",\n+    \"Undefined\",\n+    \"internalcode\",\n+]\n+async_exported = [\n+    \"AsyncLoopContext\",\n+    \"auto_aiter\",\n+    \"auto_await\",\n+]\n+\n+\n+def identity(x: V) -&gt; V:\n     \"\"\"Returns its argument. Useful for certain things in the\n     environment.\n     \"\"\"\n-    pass\n+    return x\n\n\n-def markup_join(seq: t.Iterable[t.Any]) -&gt;str:\n+def markup_join(seq: t.Iterable[t.Any]) -&gt; str:\n     \"\"\"Concatenation that escapes if necessary and converts to string.\"\"\"\n-    pass\n+    buf = []\n+    iterator = map(soft_str, seq)\n+    for arg in iterator:\n+        buf.append(arg)\n+        if hasattr(arg, \"__html__\"):\n+            return Markup(\"\").join(chain(buf, iterator))\n+    return concat(buf)\n\n\n-def str_join(seq: t.Iterable[t.Any]) -&gt;str:\n+def str_join(seq: t.Iterable[t.Any]) -&gt; str:\n     \"\"\"Simple args to string conversion and concatenation.\"\"\"\n-    pass\n-\n-\n-def new_context(environment: 'Environment', template_name: t.Optional[str],\n-    blocks: t.Dict[str, t.Callable[['Context'], t.Iterator[str]]], vars: t.\n-    Optional[t.Dict[str, t.Any]]=None, shared: bool=False, globals: t.\n-    Optional[t.MutableMapping[str, t.Any]]=None, locals: t.Optional[t.\n-    Mapping[str, t.Any]]=None) -&gt;'Context':\n+    return concat(map(str, seq))\n+\n+\n+def new_context(\n+    environment: \"Environment\",\n+    template_name: t.Optional[str],\n+    blocks: t.Dict[str, t.Callable[[\"Context\"], t.Iterator[str]]],\n+    vars: t.Optional[t.Dict[str, t.Any]] = None,\n+    shared: bool = False,\n+    globals: t.Optional[t.MutableMapping[str, t.Any]] = None,\n+    locals: t.Optional[t.Mapping[str, t.Any]] = None,\n+) -&gt; \"Context\":\n     \"\"\"Internal helper for context creation.\"\"\"\n-    pass\n+    if vars is None:\n+        vars = {}\n+    if shared:\n+        parent = vars\n+    else:\n+        parent = dict(globals or (), **vars)\n+    if locals:\n+        # if the parent is shared a copy should be created because\n+        # we don't want to modify the dict passed\n+        if shared:\n+            parent = dict(parent)\n+        for key, value in locals.items():\n+            if value is not missing:\n+                parent[key] = value\n+    return environment.context_class(\n+        environment, parent, template_name, blocks, globals=globals\n+    )\n\n\n class TemplateReference:\n     \"\"\"The `self` in templates.\"\"\"\n\n-    def __init__(self, context: 'Context') -&gt;None:\n+    def __init__(self, context: \"Context\") -&gt; None:\n         self.__context = context\n\n-    def __getitem__(self, name: str) -&gt;t.Any:\n+    def __getitem__(self, name: str) -&gt; t.Any:\n         blocks = self.__context.blocks[name]\n         return BlockReference(name, self.__context, blocks, 0)\n\n-    def __repr__(self) -&gt;str:\n-        return f'&lt;{type(self).__name__} {self.__context.name!r}&gt;'\n+    def __repr__(self) -&gt; str:\n+        return f\"&lt;{type(self).__name__} {self.__context.name!r}&gt;\"\n+\n+\n+def _dict_method_all(dict_method: F) -&gt; F:\n+    @functools.wraps(dict_method)\n+    def f_all(self: \"Context\") -&gt; t.Any:\n+        return dict_method(self.get_all())\n+\n+    return t.cast(F, f_all)\n\n\n @abc.Mapping.register\n@@ -100,34 +162,54 @@ class Context:\n     :class:`Undefined` object for missing variables.\n     \"\"\"\n\n-    def __init__(self, environment: 'Environment', parent: t.Dict[str, t.\n-        Any], name: t.Optional[str], blocks: t.Dict[str, t.Callable[[\n-        'Context'], t.Iterator[str]]], globals: t.Optional[t.MutableMapping\n-        [str, t.Any]]=None):\n+    def __init__(\n+        self,\n+        environment: \"Environment\",\n+        parent: t.Dict[str, t.Any],\n+        name: t.Optional[str],\n+        blocks: t.Dict[str, t.Callable[[\"Context\"], t.Iterator[str]]],\n+        globals: t.Optional[t.MutableMapping[str, t.Any]] = None,\n+    ):\n         self.parent = parent\n         self.vars: t.Dict[str, t.Any] = {}\n-        self.environment: 'Environment' = environment\n+        self.environment: \"Environment\" = environment\n         self.eval_ctx = EvalContext(self.environment, name)\n         self.exported_vars: t.Set[str] = set()\n         self.name = name\n         self.globals_keys = set() if globals is None else set(globals)\n+\n+        # create the initial mapping of blocks.  Whenever template inheritance\n+        # takes place the runtime will update this mapping with the new blocks\n+        # from the template.\n         self.blocks = {k: [v] for k, v in blocks.items()}\n\n-    def super(self, name: str, current: t.Callable[['Context'], t.Iterator[\n-        str]]) -&gt;t.Union['BlockReference', 'Undefined']:\n+    def super(\n+        self, name: str, current: t.Callable[[\"Context\"], t.Iterator[str]]\n+    ) -&gt; t.Union[\"BlockReference\", \"Undefined\"]:\n         \"\"\"Render a parent block.\"\"\"\n-        pass\n-\n-    def get(self, key: str, default: t.Any=None) -&gt;t.Any:\n+        try:\n+            blocks = self.blocks[name]\n+            index = blocks.index(current) + 1\n+            blocks[index]\n+        except LookupError:\n+            return self.environment.undefined(\n+                f\"there is no parent block called {name!r}.\", name=\"super\"\n+            )\n+        return BlockReference(name, self, blocks, index)\n+\n+    def get(self, key: str, default: t.Any = None) -&gt; t.Any:\n         \"\"\"Look up a variable by name, or return a default if the key is\n         not found.\n\n         :param key: The variable name to look up.\n         :param default: The value to return if the key is not found.\n         \"\"\"\n-        pass\n+        try:\n+            return self[key]\n+        except KeyError:\n+            return default\n\n-    def resolve(self, key: str) -&gt;t.Union[t.Any, 'Undefined']:\n+    def resolve(self, key: str) -&gt; t.Union[t.Any, \"Undefined\"]:\n         \"\"\"Look up a variable by name, or return an :class:`Undefined`\n         object if the key is not found.\n\n@@ -137,9 +219,14 @@ class Context:\n\n         :param key: The variable name to look up.\n         \"\"\"\n-        pass\n+        rv = self.resolve_or_missing(key)\n+\n+        if rv is missing:\n+            return self.environment.undefined(name=key)\n+\n+        return rv\n\n-    def resolve_or_missing(self, key: str) -&gt;t.Any:\n+    def resolve_or_missing(self, key: str) -&gt; t.Any:\n         \"\"\"Look up a variable by name, or return a ``missing`` sentinel\n         if the key is not found.\n\n@@ -149,77 +236,156 @@ class Context:\n\n         :param key: The variable name to look up.\n         \"\"\"\n-        pass\n+        if key in self.vars:\n+            return self.vars[key]\n+\n+        if key in self.parent:\n+            return self.parent[key]\n\n-    def get_exported(self) -&gt;t.Dict[str, t.Any]:\n+        return missing\n+\n+    def get_exported(self) -&gt; t.Dict[str, t.Any]:\n         \"\"\"Get a new dict with the exported variables.\"\"\"\n-        pass\n+        return {k: self.vars[k] for k in self.exported_vars}\n\n-    def get_all(self) -&gt;t.Dict[str, t.Any]:\n+    def get_all(self) -&gt; t.Dict[str, t.Any]:\n         \"\"\"Return the complete context as dict including the exported\n         variables.  For optimizations reasons this might not return an\n         actual copy so be careful with using it.\n         \"\"\"\n-        pass\n+        if not self.vars:\n+            return self.parent\n+        if not self.parent:\n+            return self.vars\n+        return dict(self.parent, **self.vars)\n\n     @internalcode\n-    def call(__self, __obj: t.Callable[..., t.Any], *args: t.Any, **kwargs:\n-        t.Any) -&gt;t.Union[t.Any, 'Undefined']:\n+    def call(\n+        __self,\n+        __obj: t.Callable[..., t.Any],\n+        *args: t.Any,\n+        **kwargs: t.Any,  # noqa: B902\n+    ) -&gt; t.Union[t.Any, \"Undefined\"]:\n         \"\"\"Call the callable with the arguments and keyword arguments\n         provided but inject the active context or environment as first\n         argument if the callable has :func:`pass_context` or\n         :func:`pass_environment`.\n         \"\"\"\n-        pass\n-\n-    def derived(self, locals: t.Optional[t.Dict[str, t.Any]]=None) -&gt;'Context':\n+        if __debug__:\n+            __traceback_hide__ = True  # noqa\n+\n+        # Allow callable classes to take a context\n+        if (\n+            hasattr(__obj, \"__call__\")  # noqa: B004\n+            and _PassArg.from_obj(__obj.__call__) is not None\n+        ):\n+            __obj = __obj.__call__\n+\n+        pass_arg = _PassArg.from_obj(__obj)\n+\n+        if pass_arg is _PassArg.context:\n+            # the active context should have access to variables set in\n+            # loops and blocks without mutating the context itself\n+            if kwargs.get(\"_loop_vars\"):\n+                __self = __self.derived(kwargs[\"_loop_vars\"])\n+            if kwargs.get(\"_block_vars\"):\n+                __self = __self.derived(kwargs[\"_block_vars\"])\n+            args = (__self,) + args\n+        elif pass_arg is _PassArg.eval_context:\n+            args = (__self.eval_ctx,) + args\n+        elif pass_arg is _PassArg.environment:\n+            args = (__self.environment,) + args\n+\n+        kwargs.pop(\"_block_vars\", None)\n+        kwargs.pop(\"_loop_vars\", None)\n+\n+        try:\n+            return __obj(*args, **kwargs)\n+        except StopIteration:\n+            return __self.environment.undefined(\n+                \"value was undefined because a callable raised a\"\n+                \" StopIteration exception\"\n+            )\n+\n+    def derived(self, locals: t.Optional[t.Dict[str, t.Any]] = None) -&gt; \"Context\":\n         \"\"\"Internal helper function to create a derived context.  This is\n         used in situations where the system needs a new context in the same\n         template that is independent.\n         \"\"\"\n-        pass\n+        context = new_context(\n+            self.environment, self.name, {}, self.get_all(), True, None, locals\n+        )\n+        context.eval_ctx = self.eval_ctx\n+        context.blocks.update((k, list(v)) for k, v in self.blocks.items())\n+        return context\n+\n     keys = _dict_method_all(dict.keys)\n     values = _dict_method_all(dict.values)\n     items = _dict_method_all(dict.items)\n\n-    def __contains__(self, name: str) -&gt;bool:\n+    def __contains__(self, name: str) -&gt; bool:\n         return name in self.vars or name in self.parent\n\n-    def __getitem__(self, key: str) -&gt;t.Any:\n+    def __getitem__(self, key: str) -&gt; t.Any:\n         \"\"\"Look up a variable by name with ``[]`` syntax, or raise a\n         ``KeyError`` if the key is not found.\n         \"\"\"\n         item = self.resolve_or_missing(key)\n+\n         if item is missing:\n             raise KeyError(key)\n+\n         return item\n\n-    def __repr__(self) -&gt;str:\n-        return f'&lt;{type(self).__name__} {self.get_all()!r} of {self.name!r}&gt;'\n+    def __repr__(self) -&gt; str:\n+        return f\"&lt;{type(self).__name__} {self.get_all()!r} of {self.name!r}&gt;\"\n\n\n class BlockReference:\n     \"\"\"One block on a template reference.\"\"\"\n\n-    def __init__(self, name: str, context: 'Context', stack: t.List[t.\n-        Callable[['Context'], t.Iterator[str]]], depth: int) -&gt;None:\n+    def __init__(\n+        self,\n+        name: str,\n+        context: \"Context\",\n+        stack: t.List[t.Callable[[\"Context\"], t.Iterator[str]]],\n+        depth: int,\n+    ) -&gt; None:\n         self.name = name\n         self._context = context\n         self._stack = stack\n         self._depth = depth\n\n     @property\n-    def super(self) -&gt;t.Union['BlockReference', 'Undefined']:\n+    def super(self) -&gt; t.Union[\"BlockReference\", \"Undefined\"]:\n         \"\"\"Super the block.\"\"\"\n-        pass\n+        if self._depth + 1 &gt;= len(self._stack):\n+            return self._context.environment.undefined(\n+                f\"there is no parent block called {self.name!r}.\", name=\"super\"\n+            )\n+        return BlockReference(self.name, self._context, self._stack, self._depth + 1)\n\n     @internalcode\n-    def __call__(self) -&gt;str:\n+    async def _async_call(self) -&gt; str:\n+        rv = concat(\n+            [x async for x in self._stack[self._depth](self._context)]  # type: ignore\n+        )\n+\n+        if self._context.eval_ctx.autoescape:\n+            return Markup(rv)\n+\n+        return rv\n+\n+    @internalcode\n+    def __call__(self) -&gt; str:\n         if self._context.environment.is_async:\n-            return self._async_call()\n+            return self._async_call()  # type: ignore\n+\n         rv = concat(self._stack[self._depth](self._context))\n+\n         if self._context.eval_ctx.autoescape:\n             return Markup(rv)\n+\n         return rv\n\n\n@@ -227,16 +393,23 @@ class LoopContext:\n     \"\"\"A wrapper iterable for dynamic ``for`` loops, with information\n     about the loop and iteration.\n     \"\"\"\n+\n+    #: Current iteration of the loop, starting at 0.\n     index0 = -1\n+\n     _length: t.Optional[int] = None\n     _after: t.Any = missing\n     _current: t.Any = missing\n     _before: t.Any = missing\n     _last_changed_value: t.Any = missing\n\n-    def __init__(self, iterable: t.Iterable[V], undefined: t.Type[\n-        'Undefined'], recurse: t.Optional['LoopRenderFunc']=None, depth0: int=0\n-        ) -&gt;None:\n+    def __init__(\n+        self,\n+        iterable: t.Iterable[V],\n+        undefined: t.Type[\"Undefined\"],\n+        recurse: t.Optional[\"LoopRenderFunc\"] = None,\n+        depth0: int = 0,\n+    ) -&gt; None:\n         \"\"\"\n         :param iterable: Iterable to wrap.\n         :param undefined: :class:`Undefined` class to use for next and\n@@ -249,78 +422,100 @@ class LoopContext:\n         self._iterator = self._to_iterator(iterable)\n         self._undefined = undefined\n         self._recurse = recurse\n+        #: How many levels deep a recursive loop currently is, starting at 0.\n         self.depth0 = depth0\n\n+    @staticmethod\n+    def _to_iterator(iterable: t.Iterable[V]) -&gt; t.Iterator[V]:\n+        return iter(iterable)\n+\n     @property\n-    def length(self) -&gt;int:\n+    def length(self) -&gt; int:\n         \"\"\"Length of the iterable.\n\n         If the iterable is a generator or otherwise does not have a\n         size, it is eagerly evaluated to get a size.\n         \"\"\"\n-        pass\n+        if self._length is not None:\n+            return self._length\n+\n+        try:\n+            self._length = len(self._iterable)  # type: ignore\n+        except TypeError:\n+            iterable = list(self._iterator)\n+            self._iterator = self._to_iterator(iterable)\n+            self._length = len(iterable) + self.index + (self._after is not missing)\n\n-    def __len__(self) -&gt;int:\n+        return self._length\n+\n+    def __len__(self) -&gt; int:\n         return self.length\n\n     @property\n-    def depth(self) -&gt;int:\n+    def depth(self) -&gt; int:\n         \"\"\"How many levels deep a recursive loop currently is, starting at 1.\"\"\"\n-        pass\n+        return self.depth0 + 1\n\n     @property\n-    def index(self) -&gt;int:\n+    def index(self) -&gt; int:\n         \"\"\"Current iteration of the loop, starting at 1.\"\"\"\n-        pass\n+        return self.index0 + 1\n\n     @property\n-    def revindex0(self) -&gt;int:\n+    def revindex0(self) -&gt; int:\n         \"\"\"Number of iterations from the end of the loop, ending at 0.\n\n         Requires calculating :attr:`length`.\n         \"\"\"\n-        pass\n+        return self.length - self.index\n\n     @property\n-    def revindex(self) -&gt;int:\n+    def revindex(self) -&gt; int:\n         \"\"\"Number of iterations from the end of the loop, ending at 1.\n\n         Requires calculating :attr:`length`.\n         \"\"\"\n-        pass\n+        return self.length - self.index0\n\n     @property\n-    def first(self) -&gt;bool:\n+    def first(self) -&gt; bool:\n         \"\"\"Whether this is the first iteration of the loop.\"\"\"\n-        pass\n+        return self.index0 == 0\n\n-    def _peek_next(self) -&gt;t.Any:\n+    def _peek_next(self) -&gt; t.Any:\n         \"\"\"Return the next element in the iterable, or :data:`missing`\n         if the iterable is exhausted. Only peeks one item ahead, caching\n         the result in :attr:`_last` for use in subsequent checks. The\n         cache is reset when :meth:`__next__` is called.\n         \"\"\"\n-        pass\n+        if self._after is not missing:\n+            return self._after\n+\n+        self._after = next(self._iterator, missing)\n+        return self._after\n\n     @property\n-    def last(self) -&gt;bool:\n+    def last(self) -&gt; bool:\n         \"\"\"Whether this is the last iteration of the loop.\n\n         Causes the iterable to advance early. See\n         :func:`itertools.groupby` for issues this can cause.\n         The :func:`groupby` filter avoids that issue.\n         \"\"\"\n-        pass\n+        return self._peek_next() is missing\n\n     @property\n-    def previtem(self) -&gt;t.Union[t.Any, 'Undefined']:\n+    def previtem(self) -&gt; t.Union[t.Any, \"Undefined\"]:\n         \"\"\"The item in the previous iteration. Undefined during the\n         first iteration.\n         \"\"\"\n-        pass\n+        if self.first:\n+            return self._undefined(\"there is no previous item\")\n+\n+        return self._before\n\n     @property\n-    def nextitem(self) -&gt;t.Union[t.Any, 'Undefined']:\n+    def nextitem(self) -&gt; t.Union[t.Any, \"Undefined\"]:\n         \"\"\"The item in the next iteration. Undefined during the last\n         iteration.\n\n@@ -328,40 +523,53 @@ class LoopContext:\n         :func:`itertools.groupby` for issues this can cause.\n         The :func:`jinja-filters.groupby` filter avoids that issue.\n         \"\"\"\n-        pass\n+        rv = self._peek_next()\n+\n+        if rv is missing:\n+            return self._undefined(\"there is no next item\")\n+\n+        return rv\n\n-    def cycle(self, *args: V) -&gt;V:\n+    def cycle(self, *args: V) -&gt; V:\n         \"\"\"Return a value from the given args, cycling through based on\n         the current :attr:`index0`.\n\n         :param args: One or more values to cycle through.\n         \"\"\"\n-        pass\n+        if not args:\n+            raise TypeError(\"no items for cycling given\")\n\n-    def changed(self, *value: t.Any) -&gt;bool:\n+        return args[self.index0 % len(args)]\n+\n+    def changed(self, *value: t.Any) -&gt; bool:\n         \"\"\"Return ``True`` if previously called with a different value\n         (including when called for the first time).\n\n         :param value: One or more values to compare to the last call.\n         \"\"\"\n-        pass\n+        if self._last_changed_value != value:\n+            self._last_changed_value = value\n+            return True\n+\n+        return False\n\n-    def __iter__(self) -&gt;'LoopContext':\n+    def __iter__(self) -&gt; \"LoopContext\":\n         return self\n\n-    def __next__(self) -&gt;t.Tuple[t.Any, 'LoopContext']:\n+    def __next__(self) -&gt; t.Tuple[t.Any, \"LoopContext\"]:\n         if self._after is not missing:\n             rv = self._after\n             self._after = missing\n         else:\n             rv = next(self._iterator)\n+\n         self.index0 += 1\n         self._before = self._current\n         self._current = rv\n         return rv, self\n\n     @internalcode\n-    def __call__(self, iterable: t.Iterable[V]) -&gt;str:\n+    def __call__(self, iterable: t.Iterable[V]) -&gt; str:\n         \"\"\"When iterating over nested data, render the body of the loop\n         recursively with the given inner iterable data.\n\n@@ -370,25 +578,79 @@ class LoopContext:\n         if self._recurse is None:\n             raise TypeError(\n                 \"The loop must have the 'recursive' marker to be called recursively.\"\n-                )\n+            )\n+\n         return self._recurse(iterable, self._recurse, depth=self.depth)\n\n-    def __repr__(self) -&gt;str:\n-        return f'&lt;{type(self).__name__} {self.index}/{self.length}&gt;'\n+    def __repr__(self) -&gt; str:\n+        return f\"&lt;{type(self).__name__} {self.index}/{self.length}&gt;\"\n\n\n class AsyncLoopContext(LoopContext):\n-    _iterator: t.AsyncIterator[t.Any]\n+    _iterator: t.AsyncIterator[t.Any]  # type: ignore\n+\n+    @staticmethod\n+    def _to_iterator(  # type: ignore\n+        iterable: t.Union[t.Iterable[V], t.AsyncIterable[V]],\n+    ) -&gt; t.AsyncIterator[V]:\n+        return auto_aiter(iterable)\n+\n+    @property\n+    async def length(self) -&gt; int:  # type: ignore\n+        if self._length is not None:\n+            return self._length\n+\n+        try:\n+            self._length = len(self._iterable)  # type: ignore\n+        except TypeError:\n+            iterable = [x async for x in self._iterator]\n+            self._iterator = self._to_iterator(iterable)\n+            self._length = len(iterable) + self.index + (self._after is not missing)\n+\n+        return self._length\n\n-    def __aiter__(self) -&gt;'AsyncLoopContext':\n+    @property\n+    async def revindex0(self) -&gt; int:  # type: ignore\n+        return await self.length - self.index\n+\n+    @property\n+    async def revindex(self) -&gt; int:  # type: ignore\n+        return await self.length - self.index0\n+\n+    async def _peek_next(self) -&gt; t.Any:\n+        if self._after is not missing:\n+            return self._after\n+\n+        try:\n+            self._after = await self._iterator.__anext__()\n+        except StopAsyncIteration:\n+            self._after = missing\n+\n+        return self._after\n+\n+    @property\n+    async def last(self) -&gt; bool:  # type: ignore\n+        return await self._peek_next() is missing\n+\n+    @property\n+    async def nextitem(self) -&gt; t.Union[t.Any, \"Undefined\"]:\n+        rv = await self._peek_next()\n+\n+        if rv is missing:\n+            return self._undefined(\"there is no next item\")\n+\n+        return rv\n+\n+    def __aiter__(self) -&gt; \"AsyncLoopContext\":\n         return self\n\n-    async def __anext__(self) -&gt;t.Tuple[t.Any, 'AsyncLoopContext']:\n+    async def __anext__(self) -&gt; t.Tuple[t.Any, \"AsyncLoopContext\"]:\n         if self._after is not missing:\n             rv = self._after\n             self._after = missing\n         else:\n             rv = await self._iterator.__anext__()\n+\n         self.index0 += 1\n         self._before = self._current\n         self._current = rv\n@@ -398,10 +660,17 @@ class AsyncLoopContext(LoopContext):\n class Macro:\n     \"\"\"Wraps a macro function.\"\"\"\n\n-    def __init__(self, environment: 'Environment', func: t.Callable[...,\n-        str], name: str, arguments: t.List[str], catch_kwargs: bool,\n-        catch_varargs: bool, caller: bool, default_autoescape: t.Optional[\n-        bool]=None):\n+    def __init__(\n+        self,\n+        environment: \"Environment\",\n+        func: t.Callable[..., str],\n+        name: str,\n+        arguments: t.List[str],\n+        catch_kwargs: bool,\n+        catch_varargs: bool,\n+        caller: bool,\n+        default_autoescape: t.Optional[bool] = None,\n+    ):\n         self._environment = environment\n         self._func = func\n         self._argument_count = len(arguments)\n@@ -410,63 +679,116 @@ class Macro:\n         self.catch_kwargs = catch_kwargs\n         self.catch_varargs = catch_varargs\n         self.caller = caller\n-        self.explicit_caller = 'caller' in arguments\n+        self.explicit_caller = \"caller\" in arguments\n+\n         if default_autoescape is None:\n             if callable(environment.autoescape):\n                 default_autoescape = environment.autoescape(None)\n             else:\n                 default_autoescape = environment.autoescape\n+\n         self._default_autoescape = default_autoescape\n\n     @internalcode\n     @pass_eval_context\n-    def __call__(self, *args: t.Any, **kwargs: t.Any) -&gt;str:\n+    def __call__(self, *args: t.Any, **kwargs: t.Any) -&gt; str:\n+        # This requires a bit of explanation,  In the past we used to\n+        # decide largely based on compile-time information if a macro is\n+        # safe or unsafe.  While there was a volatile mode it was largely\n+        # unused for deciding on escaping.  This turns out to be\n+        # problematic for macros because whether a macro is safe depends not\n+        # on the escape mode when it was defined, but rather when it was used.\n+        #\n+        # Because however we export macros from the module system and\n+        # there are historic callers that do not pass an eval context (and\n+        # will continue to not pass one), we need to perform an instance\n+        # check here.\n+        #\n+        # This is considered safe because an eval context is not a valid\n+        # argument to callables otherwise anyway.  Worst case here is\n+        # that if no eval context is passed we fall back to the compile\n+        # time autoescape flag.\n         if args and isinstance(args[0], EvalContext):\n             autoescape = args[0].autoescape\n             args = args[1:]\n         else:\n             autoescape = self._default_autoescape\n-        arguments = list(args[:self._argument_count])\n+\n+        # try to consume the positional arguments\n+        arguments = list(args[: self._argument_count])\n         off = len(arguments)\n+\n+        # For information why this is necessary refer to the handling\n+        # of caller in the `macro_body` handler in the compiler.\n         found_caller = False\n+\n+        # if the number of arguments consumed is not the number of\n+        # arguments expected we start filling in keyword arguments\n+        # and defaults.\n         if off != self._argument_count:\n-            for name in self.arguments[len(arguments):]:\n+            for name in self.arguments[len(arguments) :]:\n                 try:\n                     value = kwargs.pop(name)\n                 except KeyError:\n                     value = missing\n-                if name == 'caller':\n+                if name == \"caller\":\n                     found_caller = True\n                 arguments.append(value)\n         else:\n             found_caller = self.explicit_caller\n+\n+        # it's important that the order of these arguments does not change\n+        # if not also changed in the compiler's `function_scoping` method.\n+        # the order is caller, keyword arguments, positional arguments!\n         if self.caller and not found_caller:\n-            caller = kwargs.pop('caller', None)\n+            caller = kwargs.pop(\"caller\", None)\n             if caller is None:\n-                caller = self._environment.undefined('No caller defined',\n-                    name='caller')\n+                caller = self._environment.undefined(\"No caller defined\", name=\"caller\")\n             arguments.append(caller)\n+\n         if self.catch_kwargs:\n             arguments.append(kwargs)\n         elif kwargs:\n-            if 'caller' in kwargs:\n+            if \"caller\" in kwargs:\n                 raise TypeError(\n-                    f'macro {self.name!r} was invoked with two values for the special caller argument. This is most likely a bug.'\n-                    )\n-            raise TypeError(\n-                f'macro {self.name!r} takes no keyword argument {next(iter(kwargs))!r}'\n+                    f\"macro {self.name!r} was invoked with two values for the special\"\n+                    \" caller argument. This is most likely a bug.\"\n                 )\n+            raise TypeError(\n+                f\"macro {self.name!r} takes no keyword argument {next(iter(kwargs))!r}\"\n+            )\n         if self.catch_varargs:\n-            arguments.append(args[self._argument_count:])\n+            arguments.append(args[self._argument_count :])\n         elif len(args) &gt; self._argument_count:\n             raise TypeError(\n-                f'macro {self.name!r} takes not more than {len(self.arguments)} argument(s)'\n-                )\n+                f\"macro {self.name!r} takes not more than\"\n+                f\" {len(self.arguments)} argument(s)\"\n+            )\n+\n         return self._invoke(arguments, autoescape)\n\n-    def __repr__(self) -&gt;str:\n-        name = 'anonymous' if self.name is None else repr(self.name)\n-        return f'&lt;{type(self).__name__} {name}&gt;'\n+    async def _async_invoke(self, arguments: t.List[t.Any], autoescape: bool) -&gt; str:\n+        rv = await self._func(*arguments)  # type: ignore\n+\n+        if autoescape:\n+            return Markup(rv)\n+\n+        return rv  # type: ignore\n+\n+    def _invoke(self, arguments: t.List[t.Any], autoescape: bool) -&gt; str:\n+        if self._environment.is_async:\n+            return self._async_invoke(arguments, autoescape)  # type: ignore\n+\n+        rv = self._func(*arguments)\n+\n+        if autoescape:\n+            rv = Markup(rv)\n+\n+        return rv\n+\n+    def __repr__(self) -&gt; str:\n+        name = \"anonymous\" if self.name is None else repr(self.name)\n+        return f\"&lt;{type(self).__name__} {name}&gt;\"\n\n\n class Undefined:\n@@ -483,37 +805,64 @@ class Undefined:\n       ...\n     jinja2.exceptions.UndefinedError: 'foo' is undefined\n     \"\"\"\n-    __slots__ = ('_undefined_hint', '_undefined_obj', '_undefined_name',\n-        '_undefined_exception')\n\n-    def __init__(self, hint: t.Optional[str]=None, obj: t.Any=missing, name:\n-        t.Optional[str]=None, exc: t.Type[TemplateRuntimeError]=UndefinedError\n-        ) -&gt;None:\n+    __slots__ = (\n+        \"_undefined_hint\",\n+        \"_undefined_obj\",\n+        \"_undefined_name\",\n+        \"_undefined_exception\",\n+    )\n+\n+    def __init__(\n+        self,\n+        hint: t.Optional[str] = None,\n+        obj: t.Any = missing,\n+        name: t.Optional[str] = None,\n+        exc: t.Type[TemplateRuntimeError] = UndefinedError,\n+    ) -&gt; None:\n         self._undefined_hint = hint\n         self._undefined_obj = obj\n         self._undefined_name = name\n         self._undefined_exception = exc\n\n     @property\n-    def _undefined_message(self) -&gt;str:\n+    def _undefined_message(self) -&gt; str:\n         \"\"\"Build a message about the undefined value based on how it was\n         accessed.\n         \"\"\"\n-        pass\n+        if self._undefined_hint:\n+            return self._undefined_hint\n+\n+        if self._undefined_obj is missing:\n+            return f\"{self._undefined_name!r} is undefined\"\n+\n+        if not isinstance(self._undefined_name, str):\n+            return (\n+                f\"{object_type_repr(self._undefined_obj)} has no\"\n+                f\" element {self._undefined_name!r}\"\n+            )\n+\n+        return (\n+            f\"{object_type_repr(self._undefined_obj)!r} has no\"\n+            f\" attribute {self._undefined_name!r}\"\n+        )\n\n     @internalcode\n-    def _fail_with_undefined_error(self, *args: t.Any, **kwargs: t.Any\n-        ) -&gt;'te.NoReturn':\n+    def _fail_with_undefined_error(\n+        self, *args: t.Any, **kwargs: t.Any\n+    ) -&gt; \"te.NoReturn\":\n         \"\"\"Raise an :exc:`UndefinedError` when operations are performed\n         on the undefined value.\n         \"\"\"\n-        pass\n+        raise self._undefined_exception(self._undefined_message)\n\n     @internalcode\n-    def __getattr__(self, name: str) -&gt;t.Any:\n-        if name[:2] == '__':\n+    def __getattr__(self, name: str) -&gt; t.Any:\n+        if name[:2] == \"__\":\n             raise AttributeError(name)\n+\n         return self._fail_with_undefined_error()\n+\n     __add__ = __radd__ = __sub__ = __rsub__ = _fail_with_undefined_error\n     __mul__ = __rmul__ = __div__ = __rdiv__ = _fail_with_undefined_error\n     __truediv__ = __rtruediv__ = _fail_with_undefined_error\n@@ -525,37 +874,38 @@ class Undefined:\n     __int__ = __float__ = __complex__ = _fail_with_undefined_error\n     __pow__ = __rpow__ = _fail_with_undefined_error\n\n-    def __eq__(self, other: t.Any) -&gt;bool:\n+    def __eq__(self, other: t.Any) -&gt; bool:\n         return type(self) is type(other)\n\n-    def __ne__(self, other: t.Any) -&gt;bool:\n+    def __ne__(self, other: t.Any) -&gt; bool:\n         return not self.__eq__(other)\n\n-    def __hash__(self) -&gt;int:\n+    def __hash__(self) -&gt; int:\n         return id(type(self))\n\n-    def __str__(self) -&gt;str:\n-        return ''\n+    def __str__(self) -&gt; str:\n+        return \"\"\n\n-    def __len__(self) -&gt;int:\n+    def __len__(self) -&gt; int:\n         return 0\n\n-    def __iter__(self) -&gt;t.Iterator[t.Any]:\n+    def __iter__(self) -&gt; t.Iterator[t.Any]:\n         yield from ()\n\n-    async def __aiter__(self) -&gt;t.AsyncIterator[t.Any]:\n+    async def __aiter__(self) -&gt; t.AsyncIterator[t.Any]:\n         for _ in ():\n             yield\n\n-    def __bool__(self) -&gt;bool:\n+    def __bool__(self) -&gt; bool:\n         return False\n\n-    def __repr__(self) -&gt;str:\n-        return 'Undefined'\n+    def __repr__(self) -&gt; str:\n+        return \"Undefined\"\n\n\n-def make_logging_undefined(logger: t.Optional['logging.Logger']=None, base:\n-    t.Type[Undefined]=Undefined) -&gt;t.Type[Undefined]:\n+def make_logging_undefined(\n+    logger: t.Optional[\"logging.Logger\"] = None, base: t.Type[Undefined] = Undefined\n+) -&gt; t.Type[Undefined]:\n     \"\"\"Given a logger object this returns a new undefined class that will\n     log certain failures.  It will log iterations and printing.  If no\n     logger is given a default logger is created.\n@@ -575,7 +925,40 @@ def make_logging_undefined(logger: t.Optional['logging.Logger']=None, base:\n     :param base: the base class to add logging functionality to.  This\n                  defaults to :class:`Undefined`.\n     \"\"\"\n-    pass\n+    if logger is None:\n+        import logging\n+\n+        logger = logging.getLogger(__name__)\n+        logger.addHandler(logging.StreamHandler(sys.stderr))\n+\n+    def _log_message(undef: Undefined) -&gt; None:\n+        logger.warning(\"Template variable warning: %s\", undef._undefined_message)\n+\n+    class LoggingUndefined(base):  # type: ignore\n+        __slots__ = ()\n+\n+        def _fail_with_undefined_error(  # type: ignore\n+            self, *args: t.Any, **kwargs: t.Any\n+        ) -&gt; \"te.NoReturn\":\n+            try:\n+                super()._fail_with_undefined_error(*args, **kwargs)\n+            except self._undefined_exception as e:\n+                logger.error(\"Template variable error: %s\", e)  # type: ignore\n+                raise e\n+\n+        def __str__(self) -&gt; str:\n+            _log_message(self)\n+            return super().__str__()  # type: ignore\n+\n+        def __iter__(self) -&gt; t.Iterator[t.Any]:\n+            _log_message(self)\n+            return super().__iter__()  # type: ignore\n+\n+        def __bool__(self) -&gt; bool:\n+            _log_message(self)\n+            return super().__bool__()  # type: ignore\n+\n+    return LoggingUndefined\n\n\n class ChainableUndefined(Undefined):\n@@ -593,14 +976,16 @@ class ChainableUndefined(Undefined):\n\n     .. versionadded:: 2.11.0\n     \"\"\"\n+\n     __slots__ = ()\n\n-    def __html__(self) -&gt;str:\n+    def __html__(self) -&gt; str:\n         return str(self)\n\n-    def __getattr__(self, _: str) -&gt;'ChainableUndefined':\n+    def __getattr__(self, _: str) -&gt; \"ChainableUndefined\":\n         return self\n-    __getitem__ = __getattr__\n+\n+    __getitem__ = __getattr__  # type: ignore\n\n\n class DebugUndefined(Undefined):\n@@ -616,18 +1001,23 @@ class DebugUndefined(Undefined):\n       ...\n     jinja2.exceptions.UndefinedError: 'foo' is undefined\n     \"\"\"\n+\n     __slots__ = ()\n\n-    def __str__(self) -&gt;str:\n+    def __str__(self) -&gt; str:\n         if self._undefined_hint:\n-            message = f'undefined value printed: {self._undefined_hint}'\n+            message = f\"undefined value printed: {self._undefined_hint}\"\n+\n         elif self._undefined_obj is missing:\n-            message = self._undefined_name\n+            message = self._undefined_name  # type: ignore\n+\n         else:\n             message = (\n-                f'no such element: {object_type_repr(self._undefined_obj)}[{self._undefined_name!r}]'\n-                )\n-        return f'{{{{ {message} }}}}'\n+                f\"no such element: {object_type_repr(self._undefined_obj)}\"\n+                f\"[{self._undefined_name!r}]\"\n+            )\n+\n+        return f\"{{{{ {message} }}}}\"\n\n\n class StrictUndefined(Undefined):\n@@ -649,12 +1039,18 @@ class StrictUndefined(Undefined):\n       ...\n     jinja2.exceptions.UndefinedError: 'foo' is undefined\n     \"\"\"\n+\n     __slots__ = ()\n     __iter__ = __str__ = __len__ = Undefined._fail_with_undefined_error\n-    __eq__ = __ne__ = __bool__ = __hash__ = (Undefined.\n-        _fail_with_undefined_error)\n+    __eq__ = __ne__ = __bool__ = __hash__ = Undefined._fail_with_undefined_error\n     __contains__ = Undefined._fail_with_undefined_error\n\n\n-del (Undefined.__slots__, ChainableUndefined.__slots__, DebugUndefined.\n-    __slots__, StrictUndefined.__slots__)\n+# Remove slots attributes, after the metaclass is applied they are\n+# unneeded and contain wrong data for subclasses.\n+del (\n+    Undefined.__slots__,\n+    ChainableUndefined.__slots__,\n+    DebugUndefined.__slots__,\n+    StrictUndefined.__slots__,\n+)\ndiff --git a/src/jinja2/sandbox.py b/src/jinja2/sandbox.py\nindex b73a983..0b4fc12 100644\n--- a/src/jinja2/sandbox.py\n+++ b/src/jinja2/sandbox.py\n@@ -1,44 +1,116 @@\n \"\"\"A sandbox layer that ensures unsafe operations cannot be performed.\n Useful when the template itself comes from an untrusted source.\n \"\"\"\n+\n import operator\n import types\n import typing as t\n from collections import abc\n from collections import deque\n from string import Formatter\n-from _string import formatter_field_name_split\n+\n+from _string import formatter_field_name_split  # type: ignore\n from markupsafe import EscapeFormatter\n from markupsafe import Markup\n+\n from .environment import Environment\n from .exceptions import SecurityError\n from .runtime import Context\n from .runtime import Undefined\n-F = t.TypeVar('F', bound=t.Callable[..., t.Any])\n+\n+F = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n+\n+#: maximum number of items a range may produce\n MAX_RANGE = 100000\n+\n+#: Unsafe function attributes.\n UNSAFE_FUNCTION_ATTRIBUTES: t.Set[str] = set()\n+\n+#: Unsafe method attributes. Function attributes are unsafe for methods too.\n UNSAFE_METHOD_ATTRIBUTES: t.Set[str] = set()\n-UNSAFE_GENERATOR_ATTRIBUTES = {'gi_frame', 'gi_code'}\n-UNSAFE_COROUTINE_ATTRIBUTES = {'cr_frame', 'cr_code'}\n-UNSAFE_ASYNC_GENERATOR_ATTRIBUTES = {'ag_code', 'ag_frame'}\n-_mutable_spec: t.Tuple[t.Tuple[t.Type[t.Any], t.FrozenSet[str]], ...] = ((\n-    abc.MutableSet, frozenset(['add', 'clear', 'difference_update',\n-    'discard', 'pop', 'remove', 'symmetric_difference_update', 'update'])),\n-    (abc.MutableMapping, frozenset(['clear', 'pop', 'popitem', 'setdefault',\n-    'update'])), (abc.MutableSequence, frozenset(['append', 'reverse',\n-    'insert', 'sort', 'extend', 'remove'])), (deque, frozenset(['append',\n-    'appendleft', 'clear', 'extend', 'extendleft', 'pop', 'popleft',\n-    'remove', 'rotate'])))\n-\n-\n-def safe_range(*args: int) -&gt;range:\n+\n+#: unsafe generator attributes.\n+UNSAFE_GENERATOR_ATTRIBUTES = {\"gi_frame\", \"gi_code\"}\n+\n+#: unsafe attributes on coroutines\n+UNSAFE_COROUTINE_ATTRIBUTES = {\"cr_frame\", \"cr_code\"}\n+\n+#: unsafe attributes on async generators\n+UNSAFE_ASYNC_GENERATOR_ATTRIBUTES = {\"ag_code\", \"ag_frame\"}\n+\n+_mutable_spec: t.Tuple[t.Tuple[t.Type[t.Any], t.FrozenSet[str]], ...] = (\n+    (\n+        abc.MutableSet,\n+        frozenset(\n+            [\n+                \"add\",\n+                \"clear\",\n+                \"difference_update\",\n+                \"discard\",\n+                \"pop\",\n+                \"remove\",\n+                \"symmetric_difference_update\",\n+                \"update\",\n+            ]\n+        ),\n+    ),\n+    (\n+        abc.MutableMapping,\n+        frozenset([\"clear\", \"pop\", \"popitem\", \"setdefault\", \"update\"]),\n+    ),\n+    (\n+        abc.MutableSequence,\n+        frozenset([\"append\", \"reverse\", \"insert\", \"sort\", \"extend\", \"remove\"]),\n+    ),\n+    (\n+        deque,\n+        frozenset(\n+            [\n+                \"append\",\n+                \"appendleft\",\n+                \"clear\",\n+                \"extend\",\n+                \"extendleft\",\n+                \"pop\",\n+                \"popleft\",\n+                \"remove\",\n+                \"rotate\",\n+            ]\n+        ),\n+    ),\n+)\n+\n+\n+def inspect_format_method(callable: t.Callable[..., t.Any]) -&gt; t.Optional[str]:\n+    if not isinstance(\n+        callable, (types.MethodType, types.BuiltinMethodType)\n+    ) or callable.__name__ not in (\"format\", \"format_map\"):\n+        return None\n+\n+    obj = callable.__self__\n+\n+    if isinstance(obj, str):\n+        return obj\n+\n+    return None\n+\n+\n+def safe_range(*args: int) -&gt; range:\n     \"\"\"A range that can't generate ranges with a length of more than\n     MAX_RANGE items.\n     \"\"\"\n-    pass\n+    rng = range(*args)\n+\n+    if len(rng) &gt; MAX_RANGE:\n+        raise OverflowError(\n+            \"Range too big. The sandbox blocks ranges larger than\"\n+            f\" MAX_RANGE ({MAX_RANGE}).\"\n+        )\n+\n+    return rng\n\n\n-def unsafe(f: F) -&gt;F:\n+def unsafe(f: F) -&gt; F:\n     \"\"\"Marks a function or method as unsafe.\n\n     .. code-block: python\n@@ -47,10 +119,11 @@ def unsafe(f: F) -&gt;F:\n         def delete(self):\n             pass\n     \"\"\"\n-    pass\n+    f.unsafe_callable = True  # type: ignore\n+    return f\n\n\n-def is_internal_attribute(obj: t.Any, attr: str) -&gt;bool:\n+def is_internal_attribute(obj: t.Any, attr: str) -&gt; bool:\n     \"\"\"Test if the attribute given is an internal python attribute.  For\n     example this function returns `True` for the `func_code` attribute of\n     python objects.  This is useful if the environment method\n@@ -62,10 +135,32 @@ def is_internal_attribute(obj: t.Any, attr: str) -&gt;bool:\n     &gt;&gt;&gt; is_internal_attribute(str, \"upper\")\n     False\n     \"\"\"\n-    pass\n-\n-\n-def modifies_known_mutable(obj: t.Any, attr: str) -&gt;bool:\n+    if isinstance(obj, types.FunctionType):\n+        if attr in UNSAFE_FUNCTION_ATTRIBUTES:\n+            return True\n+    elif isinstance(obj, types.MethodType):\n+        if attr in UNSAFE_FUNCTION_ATTRIBUTES or attr in UNSAFE_METHOD_ATTRIBUTES:\n+            return True\n+    elif isinstance(obj, type):\n+        if attr == \"mro\":\n+            return True\n+    elif isinstance(obj, (types.CodeType, types.TracebackType, types.FrameType)):\n+        return True\n+    elif isinstance(obj, types.GeneratorType):\n+        if attr in UNSAFE_GENERATOR_ATTRIBUTES:\n+            return True\n+    elif hasattr(types, \"CoroutineType\") and isinstance(obj, types.CoroutineType):\n+        if attr in UNSAFE_COROUTINE_ATTRIBUTES:\n+            return True\n+    elif hasattr(types, \"AsyncGeneratorType\") and isinstance(\n+        obj, types.AsyncGeneratorType\n+    ):\n+        if attr in UNSAFE_ASYNC_GENERATOR_ATTRIBUTES:\n+            return True\n+    return attr.startswith(\"__\")\n+\n+\n+def modifies_known_mutable(obj: t.Any, attr: str) -&gt; bool:\n     \"\"\"This function checks if an attribute on a builtin mutable object\n     (list, dict, set or deque) or the corresponding ABCs would modify it\n     if called.\n@@ -84,7 +179,10 @@ def modifies_known_mutable(obj: t.Any, attr: str) -&gt;bool:\n     &gt;&gt;&gt; modifies_known_mutable(\"foo\", \"upper\")\n     False\n     \"\"\"\n-    pass\n+    for typespec, unsafe in _mutable_spec:\n+        if isinstance(obj, typespec):\n+            return attr in unsafe\n+    return False\n\n\n class SandboxedEnvironment(Environment):\n@@ -97,86 +195,203 @@ class SandboxedEnvironment(Environment):\n     raised.  However also other exceptions may occur during the rendering so\n     the caller has to ensure that all exceptions are caught.\n     \"\"\"\n+\n     sandboxed = True\n-    default_binop_table: t.Dict[str, t.Callable[[t.Any, t.Any], t.Any]] = {'+':\n-        operator.add, '-': operator.sub, '*': operator.mul, '/': operator.\n-        truediv, '//': operator.floordiv, '**': operator.pow, '%': operator.mod\n-        }\n-    default_unop_table: t.Dict[str, t.Callable[[t.Any], t.Any]] = {'+':\n-        operator.pos, '-': operator.neg}\n+\n+    #: default callback table for the binary operators.  A copy of this is\n+    #: available on each instance of a sandboxed environment as\n+    #: :attr:`binop_table`\n+    default_binop_table: t.Dict[str, t.Callable[[t.Any, t.Any], t.Any]] = {\n+        \"+\": operator.add,\n+        \"-\": operator.sub,\n+        \"*\": operator.mul,\n+        \"/\": operator.truediv,\n+        \"//\": operator.floordiv,\n+        \"**\": operator.pow,\n+        \"%\": operator.mod,\n+    }\n+\n+    #: default callback table for the unary operators.  A copy of this is\n+    #: available on each instance of a sandboxed environment as\n+    #: :attr:`unop_table`\n+    default_unop_table: t.Dict[str, t.Callable[[t.Any], t.Any]] = {\n+        \"+\": operator.pos,\n+        \"-\": operator.neg,\n+    }\n+\n+    #: a set of binary operators that should be intercepted.  Each operator\n+    #: that is added to this set (empty by default) is delegated to the\n+    #: :meth:`call_binop` method that will perform the operator.  The default\n+    #: operator callback is specified by :attr:`binop_table`.\n+    #:\n+    #: The following binary operators are interceptable:\n+    #: ``//``, ``%``, ``+``, ``*``, ``-``, ``/``, and ``**``\n+    #:\n+    #: The default operation form the operator table corresponds to the\n+    #: builtin function.  Intercepted calls are always slower than the native\n+    #: operator call, so make sure only to intercept the ones you are\n+    #: interested in.\n+    #:\n+    #: .. versionadded:: 2.6\n     intercepted_binops: t.FrozenSet[str] = frozenset()\n+\n+    #: a set of unary operators that should be intercepted.  Each operator\n+    #: that is added to this set (empty by default) is delegated to the\n+    #: :meth:`call_unop` method that will perform the operator.  The default\n+    #: operator callback is specified by :attr:`unop_table`.\n+    #:\n+    #: The following unary operators are interceptable: ``+``, ``-``\n+    #:\n+    #: The default operation form the operator table corresponds to the\n+    #: builtin function.  Intercepted calls are always slower than the native\n+    #: operator call, so make sure only to intercept the ones you are\n+    #: interested in.\n+    #:\n+    #: .. versionadded:: 2.6\n     intercepted_unops: t.FrozenSet[str] = frozenset()\n\n-    def __init__(self, *args: t.Any, **kwargs: t.Any) -&gt;None:\n+    def __init__(self, *args: t.Any, **kwargs: t.Any) -&gt; None:\n         super().__init__(*args, **kwargs)\n-        self.globals['range'] = safe_range\n+        self.globals[\"range\"] = safe_range\n         self.binop_table = self.default_binop_table.copy()\n         self.unop_table = self.default_unop_table.copy()\n\n-    def is_safe_attribute(self, obj: t.Any, attr: str, value: t.Any) -&gt;bool:\n+    def is_safe_attribute(self, obj: t.Any, attr: str, value: t.Any) -&gt; bool:\n         \"\"\"The sandboxed environment will call this method to check if the\n         attribute of an object is safe to access.  Per default all attributes\n         starting with an underscore are considered private as well as the\n         special attributes of internal python objects as returned by the\n         :func:`is_internal_attribute` function.\n         \"\"\"\n-        pass\n+        return not (attr.startswith(\"_\") or is_internal_attribute(obj, attr))\n\n-    def is_safe_callable(self, obj: t.Any) -&gt;bool:\n+    def is_safe_callable(self, obj: t.Any) -&gt; bool:\n         \"\"\"Check if an object is safely callable. By default callables\n         are considered safe unless decorated with :func:`unsafe`.\n\n         This also recognizes the Django convention of setting\n         ``func.alters_data = True``.\n         \"\"\"\n-        pass\n+        return not (\n+            getattr(obj, \"unsafe_callable\", False) or getattr(obj, \"alters_data\", False)\n+        )\n\n-    def call_binop(self, context: Context, operator: str, left: t.Any,\n-        right: t.Any) -&gt;t.Any:\n+    def call_binop(\n+        self, context: Context, operator: str, left: t.Any, right: t.Any\n+    ) -&gt; t.Any:\n         \"\"\"For intercepted binary operator calls (:meth:`intercepted_binops`)\n         this function is executed instead of the builtin operator.  This can\n         be used to fine tune the behavior of certain operators.\n\n         .. versionadded:: 2.6\n         \"\"\"\n-        pass\n+        return self.binop_table[operator](left, right)\n\n-    def call_unop(self, context: Context, operator: str, arg: t.Any) -&gt;t.Any:\n+    def call_unop(self, context: Context, operator: str, arg: t.Any) -&gt; t.Any:\n         \"\"\"For intercepted unary operator calls (:meth:`intercepted_unops`)\n         this function is executed instead of the builtin operator.  This can\n         be used to fine tune the behavior of certain operators.\n\n         .. versionadded:: 2.6\n         \"\"\"\n-        pass\n+        return self.unop_table[operator](arg)\n\n-    def getitem(self, obj: t.Any, argument: t.Union[str, t.Any]) -&gt;t.Union[\n-        t.Any, Undefined]:\n+    def getitem(\n+        self, obj: t.Any, argument: t.Union[str, t.Any]\n+    ) -&gt; t.Union[t.Any, Undefined]:\n         \"\"\"Subscribe an object from sandboxed code.\"\"\"\n-        pass\n-\n-    def getattr(self, obj: t.Any, attribute: str) -&gt;t.Union[t.Any, Undefined]:\n+        try:\n+            return obj[argument]\n+        except (TypeError, LookupError):\n+            if isinstance(argument, str):\n+                try:\n+                    attr = str(argument)\n+                except Exception:\n+                    pass\n+                else:\n+                    try:\n+                        value = getattr(obj, attr)\n+                    except AttributeError:\n+                        pass\n+                    else:\n+                        if self.is_safe_attribute(obj, argument, value):\n+                            return value\n+                        return self.unsafe_undefined(obj, argument)\n+        return self.undefined(obj=obj, name=argument)\n+\n+    def getattr(self, obj: t.Any, attribute: str) -&gt; t.Union[t.Any, Undefined]:\n         \"\"\"Subscribe an object from sandboxed code and prefer the\n         attribute.  The attribute passed *must* be a bytestring.\n         \"\"\"\n-        pass\n-\n-    def unsafe_undefined(self, obj: t.Any, attribute: str) -&gt;Undefined:\n+        try:\n+            value = getattr(obj, attribute)\n+        except AttributeError:\n+            try:\n+                return obj[attribute]\n+            except (TypeError, LookupError):\n+                pass\n+        else:\n+            if self.is_safe_attribute(obj, attribute, value):\n+                return value\n+            return self.unsafe_undefined(obj, attribute)\n+        return self.undefined(obj=obj, name=attribute)\n+\n+    def unsafe_undefined(self, obj: t.Any, attribute: str) -&gt; Undefined:\n         \"\"\"Return an undefined object for unsafe attributes.\"\"\"\n-        pass\n-\n-    def format_string(self, s: str, args: t.Tuple[t.Any, ...], kwargs: t.\n-        Dict[str, t.Any], format_func: t.Optional[t.Callable[..., t.Any]]=None\n-        ) -&gt;str:\n+        return self.undefined(\n+            f\"access to attribute {attribute!r} of\"\n+            f\" {type(obj).__name__!r} object is unsafe.\",\n+            name=attribute,\n+            obj=obj,\n+            exc=SecurityError,\n+        )\n+\n+    def format_string(\n+        self,\n+        s: str,\n+        args: t.Tuple[t.Any, ...],\n+        kwargs: t.Dict[str, t.Any],\n+        format_func: t.Optional[t.Callable[..., t.Any]] = None,\n+    ) -&gt; str:\n         \"\"\"If a format call is detected, then this is routed through this\n         method so that our safety sandbox can be used for it.\n         \"\"\"\n-        pass\n-\n-    def call(__self, __context: Context, __obj: t.Any, *args: t.Any, **\n-        kwargs: t.Any) -&gt;t.Any:\n+        formatter: SandboxedFormatter\n+        if isinstance(s, Markup):\n+            formatter = SandboxedEscapeFormatter(self, escape=s.escape)\n+        else:\n+            formatter = SandboxedFormatter(self)\n+\n+        if format_func is not None and format_func.__name__ == \"format_map\":\n+            if len(args) != 1 or kwargs:\n+                raise TypeError(\n+                    \"format_map() takes exactly one argument\"\n+                    f\" {len(args) + (kwargs is not None)} given\"\n+                )\n+\n+            kwargs = args[0]\n+            args = ()\n+\n+        rv = formatter.vformat(s, args, kwargs)\n+        return type(s)(rv)\n+\n+    def call(\n+        __self,  # noqa: B902\n+        __context: Context,\n+        __obj: t.Any,\n+        *args: t.Any,\n+        **kwargs: t.Any,\n+    ) -&gt; t.Any:\n         \"\"\"Call an object from sandboxed code.\"\"\"\n-        pass\n+        fmt = inspect_format_method(__obj)\n+        if fmt is not None:\n+            return __self.format_string(fmt, args, kwargs, __obj)\n+\n+        # the double prefixes are to avoid double keyword argument\n+        # errors when proxying the call.\n+        if not __self.is_safe_callable(__obj):\n+            raise SecurityError(f\"{__obj!r} is not safely callable\")\n+        return __context.call(__obj, *args, **kwargs)\n\n\n class ImmutableSandboxedEnvironment(SandboxedEnvironment):\n@@ -185,13 +400,30 @@ class ImmutableSandboxedEnvironment(SandboxedEnvironment):\n     `dict` by using the :func:`modifies_known_mutable` function.\n     \"\"\"\n\n+    def is_safe_attribute(self, obj: t.Any, attr: str, value: t.Any) -&gt; bool:\n+        if not super().is_safe_attribute(obj, attr, value):\n+            return False\n\n-class SandboxedFormatter(Formatter):\n+        return not modifies_known_mutable(obj, attr)\n\n-    def __init__(self, env: Environment, **kwargs: t.Any) -&gt;None:\n+\n+class SandboxedFormatter(Formatter):\n+    def __init__(self, env: Environment, **kwargs: t.Any) -&gt; None:\n         self._env = env\n         super().__init__(**kwargs)\n\n+    def get_field(\n+        self, field_name: str, args: t.Sequence[t.Any], kwargs: t.Mapping[str, t.Any]\n+    ) -&gt; t.Tuple[t.Any, str]:\n+        first, rest = formatter_field_name_split(field_name)\n+        obj = self.get_value(first, args, kwargs)\n+        for is_attr, i in rest:\n+            if is_attr:\n+                obj = self._env.getattr(obj, i)\n+            else:\n+                obj = self._env.getitem(obj, i)\n+        return obj, first\n+\n\n class SandboxedEscapeFormatter(SandboxedFormatter, EscapeFormatter):\n     pass\ndiff --git a/src/jinja2/tests.py b/src/jinja2/tests.py\nindex 2823a4b..1a59e37 100644\n--- a/src/jinja2/tests.py\n+++ b/src/jinja2/tests.py\n@@ -1,30 +1,33 @@\n \"\"\"Built-in template tests used with the ``is`` operator.\"\"\"\n+\n import operator\n import typing as t\n from collections import abc\n from numbers import Number\n+\n from .runtime import Undefined\n from .utils import pass_environment\n+\n if t.TYPE_CHECKING:\n     from .environment import Environment\n\n\n-def test_odd(value: int) -&gt;bool:\n+def test_odd(value: int) -&gt; bool:\n     \"\"\"Return true if the variable is odd.\"\"\"\n-    pass\n+    return value % 2 == 1\n\n\n-def test_even(value: int) -&gt;bool:\n+def test_even(value: int) -&gt; bool:\n     \"\"\"Return true if the variable is even.\"\"\"\n-    pass\n+    return value % 2 == 0\n\n\n-def test_divisibleby(value: int, num: int) -&gt;bool:\n+def test_divisibleby(value: int, num: int) -&gt; bool:\n     \"\"\"Check if a variable is divisible by a number.\"\"\"\n-    pass\n+    return value % num == 0\n\n\n-def test_defined(value: t.Any) -&gt;bool:\n+def test_defined(value: t.Any) -&gt; bool:\n     \"\"\"Return true if the variable is defined:\n\n     .. sourcecode:: jinja\n@@ -38,16 +41,16 @@ def test_defined(value: t.Any) -&gt;bool:\n     See the :func:`default` filter for a simple way to set undefined\n     variables.\n     \"\"\"\n-    pass\n+    return not isinstance(value, Undefined)\n\n\n-def test_undefined(value: t.Any) -&gt;bool:\n+def test_undefined(value: t.Any) -&gt; bool:\n     \"\"\"Like :func:`defined` but the other way round.\"\"\"\n-    pass\n+    return isinstance(value, Undefined)\n\n\n @pass_environment\n-def test_filter(env: 'Environment', value: str) -&gt;bool:\n+def test_filter(env: \"Environment\", value: str) -&gt; bool:\n     \"\"\"Check if a filter exists by name. Useful if a filter may be\n     optionally available.\n\n@@ -61,11 +64,11 @@ def test_filter(env: 'Environment', value: str) -&gt;bool:\n\n     .. versionadded:: 3.0\n     \"\"\"\n-    pass\n+    return value in env.filters\n\n\n @pass_environment\n-def test_test(env: 'Environment', value: str) -&gt;bool:\n+def test_test(env: \"Environment\", value: str) -&gt; bool:\n     \"\"\"Check if a test exists by name. Useful if a test may be\n     optionally available.\n\n@@ -83,90 +86,98 @@ def test_test(env: 'Environment', value: str) -&gt;bool:\n\n     .. versionadded:: 3.0\n     \"\"\"\n-    pass\n+    return value in env.tests\n\n\n-def test_none(value: t.Any) -&gt;bool:\n+def test_none(value: t.Any) -&gt; bool:\n     \"\"\"Return true if the variable is none.\"\"\"\n-    pass\n+    return value is None\n\n\n-def test_boolean(value: t.Any) -&gt;bool:\n+def test_boolean(value: t.Any) -&gt; bool:\n     \"\"\"Return true if the object is a boolean value.\n\n     .. versionadded:: 2.11\n     \"\"\"\n-    pass\n+    return value is True or value is False\n\n\n-def test_false(value: t.Any) -&gt;bool:\n+def test_false(value: t.Any) -&gt; bool:\n     \"\"\"Return true if the object is False.\n\n     .. versionadded:: 2.11\n     \"\"\"\n-    pass\n+    return value is False\n\n\n-def test_true(value: t.Any) -&gt;bool:\n+def test_true(value: t.Any) -&gt; bool:\n     \"\"\"Return true if the object is True.\n\n     .. versionadded:: 2.11\n     \"\"\"\n-    pass\n+    return value is True\n\n\n-def test_integer(value: t.Any) -&gt;bool:\n+# NOTE: The existing 'number' test matches booleans and floats\n+def test_integer(value: t.Any) -&gt; bool:\n     \"\"\"Return true if the object is an integer.\n\n     .. versionadded:: 2.11\n     \"\"\"\n-    pass\n+    return isinstance(value, int) and value is not True and value is not False\n\n\n-def test_float(value: t.Any) -&gt;bool:\n+# NOTE: The existing 'number' test matches booleans and integers\n+def test_float(value: t.Any) -&gt; bool:\n     \"\"\"Return true if the object is a float.\n\n     .. versionadded:: 2.11\n     \"\"\"\n-    pass\n+    return isinstance(value, float)\n\n\n-def test_lower(value: str) -&gt;bool:\n+def test_lower(value: str) -&gt; bool:\n     \"\"\"Return true if the variable is lowercased.\"\"\"\n-    pass\n+    return str(value).islower()\n\n\n-def test_upper(value: str) -&gt;bool:\n+def test_upper(value: str) -&gt; bool:\n     \"\"\"Return true if the variable is uppercased.\"\"\"\n-    pass\n+    return str(value).isupper()\n\n\n-def test_string(value: t.Any) -&gt;bool:\n+def test_string(value: t.Any) -&gt; bool:\n     \"\"\"Return true if the object is a string.\"\"\"\n-    pass\n+    return isinstance(value, str)\n\n\n-def test_mapping(value: t.Any) -&gt;bool:\n+def test_mapping(value: t.Any) -&gt; bool:\n     \"\"\"Return true if the object is a mapping (dict etc.).\n\n     .. versionadded:: 2.6\n     \"\"\"\n-    pass\n+    return isinstance(value, abc.Mapping)\n\n\n-def test_number(value: t.Any) -&gt;bool:\n+def test_number(value: t.Any) -&gt; bool:\n     \"\"\"Return true if the variable is a number.\"\"\"\n-    pass\n+    return isinstance(value, Number)\n\n\n-def test_sequence(value: t.Any) -&gt;bool:\n+def test_sequence(value: t.Any) -&gt; bool:\n     \"\"\"Return true if the variable is a sequence. Sequences are variables\n     that are iterable.\n     \"\"\"\n-    pass\n+    try:\n+        len(value)\n+        value.__getitem__  # noqa B018\n+    except Exception:\n+        return False\n\n+    return True\n\n-def test_sameas(value: t.Any, other: t.Any) -&gt;bool:\n+\n+def test_sameas(value: t.Any, other: t.Any) -&gt; bool:\n     \"\"\"Check if an object points to the same memory address than another\n     object:\n\n@@ -176,37 +187,70 @@ def test_sameas(value: t.Any, other: t.Any) -&gt;bool:\n             the foo attribute really is the `False` singleton\n         {% endif %}\n     \"\"\"\n-    pass\n+    return value is other\n\n\n-def test_iterable(value: t.Any) -&gt;bool:\n+def test_iterable(value: t.Any) -&gt; bool:\n     \"\"\"Check if it's possible to iterate over an object.\"\"\"\n-    pass\n+    try:\n+        iter(value)\n+    except TypeError:\n+        return False\n+\n+    return True\n\n\n-def test_escaped(value: t.Any) -&gt;bool:\n+def test_escaped(value: t.Any) -&gt; bool:\n     \"\"\"Check if the value is escaped.\"\"\"\n-    pass\n+    return hasattr(value, \"__html__\")\n\n\n-def test_in(value: t.Any, seq: t.Container[t.Any]) -&gt;bool:\n+def test_in(value: t.Any, seq: t.Container[t.Any]) -&gt; bool:\n     \"\"\"Check if value is in seq.\n\n     .. versionadded:: 2.10\n     \"\"\"\n-    pass\n-\n-\n-TESTS = {'odd': test_odd, 'even': test_even, 'divisibleby':\n-    test_divisibleby, 'defined': test_defined, 'undefined': test_undefined,\n-    'filter': test_filter, 'test': test_test, 'none': test_none, 'boolean':\n-    test_boolean, 'false': test_false, 'true': test_true, 'integer':\n-    test_integer, 'float': test_float, 'lower': test_lower, 'upper':\n-    test_upper, 'string': test_string, 'mapping': test_mapping, 'number':\n-    test_number, 'sequence': test_sequence, 'iterable': test_iterable,\n-    'callable': callable, 'sameas': test_sameas, 'escaped': test_escaped,\n-    'in': test_in, '==': operator.eq, 'eq': operator.eq, 'equalto':\n-    operator.eq, '!=': operator.ne, 'ne': operator.ne, '&gt;': operator.gt,\n-    'gt': operator.gt, 'greaterthan': operator.gt, 'ge': operator.ge, '&gt;=':\n-    operator.ge, '&lt;': operator.lt, 'lt': operator.lt, 'lessthan': operator.\n-    lt, '&lt;=': operator.le, 'le': operator.le}\n+    return value in seq\n+\n+\n+TESTS = {\n+    \"odd\": test_odd,\n+    \"even\": test_even,\n+    \"divisibleby\": test_divisibleby,\n+    \"defined\": test_defined,\n+    \"undefined\": test_undefined,\n+    \"filter\": test_filter,\n+    \"test\": test_test,\n+    \"none\": test_none,\n+    \"boolean\": test_boolean,\n+    \"false\": test_false,\n+    \"true\": test_true,\n+    \"integer\": test_integer,\n+    \"float\": test_float,\n+    \"lower\": test_lower,\n+    \"upper\": test_upper,\n+    \"string\": test_string,\n+    \"mapping\": test_mapping,\n+    \"number\": test_number,\n+    \"sequence\": test_sequence,\n+    \"iterable\": test_iterable,\n+    \"callable\": callable,\n+    \"sameas\": test_sameas,\n+    \"escaped\": test_escaped,\n+    \"in\": test_in,\n+    \"==\": operator.eq,\n+    \"eq\": operator.eq,\n+    \"equalto\": operator.eq,\n+    \"!=\": operator.ne,\n+    \"ne\": operator.ne,\n+    \"&gt;\": operator.gt,\n+    \"gt\": operator.gt,\n+    \"greaterthan\": operator.gt,\n+    \"ge\": operator.ge,\n+    \"&gt;=\": operator.ge,\n+    \"&lt;\": operator.lt,\n+    \"lt\": operator.lt,\n+    \"lessthan\": operator.lt,\n+    \"&lt;=\": operator.le,\n+    \"le\": operator.le,\n+}\ndiff --git a/src/jinja2/utils.py b/src/jinja2/utils.py\nindex 7563812..7fb7693 100644\n--- a/src/jinja2/utils.py\n+++ b/src/jinja2/utils.py\n@@ -10,16 +10,23 @@ from random import randrange\n from threading import Lock\n from types import CodeType\n from urllib.parse import quote_from_bytes\n+\n import markupsafe\n+\n if t.TYPE_CHECKING:\n     import typing_extensions as te\n-F = t.TypeVar('F', bound=t.Callable[..., t.Any])\n-missing: t.Any = type('MissingType', (), {'__repr__': lambda x: 'missing'})()\n+\n+F = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n+\n+# special singleton representing missing values for the runtime\n+missing: t.Any = type(\"MissingType\", (), {\"__repr__\": lambda x: \"missing\"})()\n+\n internal_code: t.MutableSet[CodeType] = set()\n-concat = ''.join\n+\n+concat = \"\".join\n\n\n-def pass_context(f: F) -&gt;F:\n+def pass_context(f: F) -&gt; F:\n     \"\"\"Pass the :class:`~jinja2.runtime.Context` as the first argument\n     to the decorated function when called while rendering a template.\n\n@@ -32,10 +39,11 @@ def pass_context(f: F) -&gt;F:\n     .. versionadded:: 3.0.0\n         Replaces ``contextfunction`` and ``contextfilter``.\n     \"\"\"\n-    pass\n+    f.jinja_pass_arg = _PassArg.context  # type: ignore\n+    return f\n\n\n-def pass_eval_context(f: F) -&gt;F:\n+def pass_eval_context(f: F) -&gt; F:\n     \"\"\"Pass the :class:`~jinja2.nodes.EvalContext` as the first argument\n     to the decorated function when called while rendering a template.\n     See :ref:`eval-context`.\n@@ -48,10 +56,11 @@ def pass_eval_context(f: F) -&gt;F:\n     .. versionadded:: 3.0.0\n         Replaces ``evalcontextfunction`` and ``evalcontextfilter``.\n     \"\"\"\n-    pass\n+    f.jinja_pass_arg = _PassArg.eval_context  # type: ignore\n+    return f\n\n\n-def pass_environment(f: F) -&gt;F:\n+def pass_environment(f: F) -&gt; F:\n     \"\"\"Pass the :class:`~jinja2.Environment` as the first argument to\n     the decorated function when called while rendering a template.\n\n@@ -60,7 +69,8 @@ def pass_environment(f: F) -&gt;F:\n     .. versionadded:: 3.0.0\n         Replaces ``environmentfunction`` and ``environmentfilter``.\n     \"\"\"\n-    pass\n+    f.jinja_pass_arg = _PassArg.environment  # type: ignore\n+    return f\n\n\n class _PassArg(enum.Enum):\n@@ -68,13 +78,21 @@ class _PassArg(enum.Enum):\n     eval_context = enum.auto()\n     environment = enum.auto()\n\n+    @classmethod\n+    def from_obj(cls, obj: F) -&gt; t.Optional[\"_PassArg\"]:\n+        if hasattr(obj, \"jinja_pass_arg\"):\n+            return obj.jinja_pass_arg  # type: ignore\n+\n+        return None\n+\n\n-def internalcode(f: F) -&gt;F:\n+def internalcode(f: F) -&gt; F:\n     \"\"\"Marks the function as internally used\"\"\"\n-    pass\n+    internal_code.add(f.__code__)\n+    return f\n\n\n-def is_undefined(obj: t.Any) -&gt;bool:\n+def is_undefined(obj: t.Any) -&gt; bool:\n     \"\"\"Check if the object passed is undefined.  This does nothing more than\n     performing an instance check against :class:`Undefined` but looks nicer.\n     This can be used for custom filters or tests that want to react to\n@@ -86,24 +104,31 @@ def is_undefined(obj: t.Any) -&gt;bool:\n                 return default\n             return var\n     \"\"\"\n-    pass\n+    from .runtime import Undefined\n\n+    return isinstance(obj, Undefined)\n\n-def consume(iterable: t.Iterable[t.Any]) -&gt;None:\n+\n+def consume(iterable: t.Iterable[t.Any]) -&gt; None:\n     \"\"\"Consumes an iterable without doing anything with it.\"\"\"\n-    pass\n+    for _ in iterable:\n+        pass\n\n\n-def clear_caches() -&gt;None:\n+def clear_caches() -&gt; None:\n     \"\"\"Jinja keeps internal caches for environments and lexers.  These are\n     used so that Jinja doesn't have to recreate environments and lexers all\n     the time.  Normally you don't have to care about that but if you are\n     measuring memory consumption you may want to clean the caches.\n     \"\"\"\n-    pass\n+    from .environment import get_spontaneous_environment\n+    from .lexer import _lexer_cache\n\n+    get_spontaneous_environment.cache_clear()\n+    _lexer_cache.clear()\n\n-def import_string(import_name: str, silent: bool=False) -&gt;t.Any:\n+\n+def import_string(import_name: str, silent: bool = False) -&gt; t.Any:\n     \"\"\"Imports an object based on a string.  This is useful if you want to\n     use import paths as endpoints or something similar.  An import path can\n     be specified either in dotted notation (``xml.sax.saxutils.escape``)\n@@ -114,62 +139,92 @@ def import_string(import_name: str, silent: bool=False) -&gt;t.Any:\n\n     :return: imported object\n     \"\"\"\n-    pass\n-\n-\n-def open_if_exists(filename: str, mode: str='rb') -&gt;t.Optional[t.IO[t.Any]]:\n+    try:\n+        if \":\" in import_name:\n+            module, obj = import_name.split(\":\", 1)\n+        elif \".\" in import_name:\n+            module, _, obj = import_name.rpartition(\".\")\n+        else:\n+            return __import__(import_name)\n+        return getattr(__import__(module, None, None, [obj]), obj)\n+    except (ImportError, AttributeError):\n+        if not silent:\n+            raise\n+\n+\n+def open_if_exists(filename: str, mode: str = \"rb\") -&gt; t.Optional[t.IO[t.Any]]:\n     \"\"\"Returns a file descriptor for the filename if that file exists,\n     otherwise ``None``.\n     \"\"\"\n-    pass\n+    if not os.path.isfile(filename):\n+        return None\n+\n+    return open(filename, mode)\n\n\n-def object_type_repr(obj: t.Any) -&gt;str:\n+def object_type_repr(obj: t.Any) -&gt; str:\n     \"\"\"Returns the name of the object's type.  For some recognized\n     singletons the name of the object is returned instead. (For\n     example for `None` and `Ellipsis`).\n     \"\"\"\n-    pass\n+    if obj is None:\n+        return \"None\"\n+    elif obj is Ellipsis:\n+        return \"Ellipsis\"\n+\n+    cls = type(obj)\n\n+    if cls.__module__ == \"builtins\":\n+        return f\"{cls.__name__} object\"\n\n-def pformat(obj: t.Any) -&gt;str:\n+    return f\"{cls.__module__}.{cls.__name__} object\"\n+\n+\n+def pformat(obj: t.Any) -&gt; str:\n     \"\"\"Format an object using :func:`pprint.pformat`.\"\"\"\n-    pass\n+    from pprint import pformat\n+\n+    return pformat(obj)\n\n\n _http_re = re.compile(\n-    \"\"\"\n+    r\"\"\"\n     ^\n     (\n-        (https?://|www\\\\.)  # scheme or www\n-        (([\\\\w%-]+\\\\.)+)?  # subdomain\n+        (https?://|www\\.)  # scheme or www\n+        (([\\w%-]+\\.)+)?  # subdomain\n         (\n             [a-z]{2,63}  # basic tld\n         |\n-            xn--[\\\\w%]{2,59}  # idna tld\n+            xn--[\\w%]{2,59}  # idna tld\n         )\n     |\n-        ([\\\\w%-]{2,63}\\\\.)+  # basic domain\n+        ([\\w%-]{2,63}\\.)+  # basic domain\n         (com|net|int|edu|gov|org|info|mil)  # basic tld\n     |\n         (https?://)  # scheme\n         (\n-            (([\\\\d]{1,3})(\\\\.[\\\\d]{1,3}){3})  # IPv4\n+            (([\\d]{1,3})(\\.[\\d]{1,3}){3})  # IPv4\n         |\n-            (\\\\[([\\\\da-f]{0,4}:){2}([\\\\da-f]{0,4}:?){1,6}])  # IPv6\n+            (\\[([\\da-f]{0,4}:){2}([\\da-f]{0,4}:?){1,6}])  # IPv6\n         )\n     )\n-    (?::[\\\\d]{1,5})?  # port\n-    (?:[/?#]\\\\S*)?  # path, query, and fragment\n+    (?::[\\d]{1,5})?  # port\n+    (?:[/?#]\\S*)?  # path, query, and fragment\n     $\n-    \"\"\"\n-    , re.IGNORECASE | re.VERBOSE)\n-_email_re = re.compile('^\\\\S+@\\\\w[\\\\w.-]*\\\\.\\\\w+$')\n-\n-\n-def urlize(text: str, trim_url_limit: t.Optional[int]=None, rel: t.Optional\n-    [str]=None, target: t.Optional[str]=None, extra_schemes: t.Optional[t.\n-    Iterable[str]]=None) -&gt;str:\n+    \"\"\",\n+    re.IGNORECASE | re.VERBOSE,\n+)\n+_email_re = re.compile(r\"^\\S+@\\w[\\w.-]*\\.\\w+$\")\n+\n+\n+def urlize(\n+    text: str,\n+    trim_url_limit: t.Optional[int] = None,\n+    rel: t.Optional[str] = None,\n+    target: t.Optional[str] = None,\n+    extra_schemes: t.Optional[t.Iterable[str]] = None,\n+) -&gt; str:\n     \"\"\"Convert URLs in text into clickable links.\n\n     This may not recognize links in some situations. Usually, a more\n@@ -201,16 +256,145 @@ def urlize(text: str, trim_url_limit: t.Optional[int]=None, rel: t.Optional\n         or without the ``mailto:`` scheme. Validate IP addresses. Ignore\n         parentheses and brackets in more cases.\n     \"\"\"\n-    pass\n-\n-\n-def generate_lorem_ipsum(n: int=5, html: bool=True, min: int=20, max: int=100\n-    ) -&gt;str:\n+    if trim_url_limit is not None:\n+\n+        def trim_url(x: str) -&gt; str:\n+            if len(x) &gt; trim_url_limit:\n+                return f\"{x[:trim_url_limit]}...\"\n+\n+            return x\n+\n+    else:\n+\n+        def trim_url(x: str) -&gt; str:\n+            return x\n+\n+    words = re.split(r\"(\\s+)\", str(markupsafe.escape(text)))\n+    rel_attr = f' rel=\"{markupsafe.escape(rel)}\"' if rel else \"\"\n+    target_attr = f' target=\"{markupsafe.escape(target)}\"' if target else \"\"\n+\n+    for i, word in enumerate(words):\n+        head, middle, tail = \"\", word, \"\"\n+        match = re.match(r\"^([(&lt;]|&amp;lt;)+\", middle)\n+\n+        if match:\n+            head = match.group()\n+            middle = middle[match.end() :]\n+\n+        # Unlike lead, which is anchored to the start of the string,\n+        # need to check that the string ends with any of the characters\n+        # before trying to match all of them, to avoid backtracking.\n+        if middle.endswith((\")\", \"&gt;\", \".\", \",\", \"\\n\", \"&amp;gt;\")):\n+            match = re.search(r\"([)&gt;.,\\n]|&amp;gt;)+$\", middle)\n+\n+            if match:\n+                tail = match.group()\n+                middle = middle[: match.start()]\n+\n+        # Prefer balancing parentheses in URLs instead of ignoring a\n+        # trailing character.\n+        for start_char, end_char in (\"(\", \")\"), (\"&lt;\", \"&gt;\"), (\"&amp;lt;\", \"&amp;gt;\"):\n+            start_count = middle.count(start_char)\n+\n+            if start_count &lt;= middle.count(end_char):\n+                # Balanced, or lighter on the left\n+                continue\n+\n+            # Move as many as possible from the tail to balance\n+            for _ in range(min(start_count, tail.count(end_char))):\n+                end_index = tail.index(end_char) + len(end_char)\n+                # Move anything in the tail before the end char too\n+                middle += tail[:end_index]\n+                tail = tail[end_index:]\n+\n+        if _http_re.match(middle):\n+            if middle.startswith(\"https://\") or middle.startswith(\"http://\"):\n+                middle = (\n+                    f'&lt;a href=\"{middle}\"{rel_attr}{target_attr}&gt;{trim_url(middle)}&lt;/a&gt;'\n+                )\n+            else:\n+                middle = (\n+                    f'&lt;a href=\"https://{middle}\"{rel_attr}{target_attr}&gt;'\n+                    f\"{trim_url(middle)}&lt;/a&gt;\"\n+                )\n+\n+        elif middle.startswith(\"mailto:\") and _email_re.match(middle[7:]):\n+            middle = f'&lt;a href=\"{middle}\"&gt;{middle[7:]}&lt;/a&gt;'\n+\n+        elif (\n+            \"@\" in middle\n+            and not middle.startswith(\"www.\")\n+            and \":\" not in middle\n+            and _email_re.match(middle)\n+        ):\n+            middle = f'&lt;a href=\"mailto:{middle}\"&gt;{middle}&lt;/a&gt;'\n+\n+        elif extra_schemes is not None:\n+            for scheme in extra_schemes:\n+                if middle != scheme and middle.startswith(scheme):\n+                    middle = f'&lt;a href=\"{middle}\"{rel_attr}{target_attr}&gt;{middle}&lt;/a&gt;'\n+\n+        words[i] = f\"{head}{middle}{tail}\"\n+\n+    return \"\".join(words)\n+\n+\n+def generate_lorem_ipsum(\n+    n: int = 5, html: bool = True, min: int = 20, max: int = 100\n+) -&gt; str:\n     \"\"\"Generate some lorem ipsum for the template.\"\"\"\n-    pass\n+    from .constants import LOREM_IPSUM_WORDS\n+\n+    words = LOREM_IPSUM_WORDS.split()\n+    result = []\n+\n+    for _ in range(n):\n+        next_capitalized = True\n+        last_comma = last_fullstop = 0\n+        word = None\n+        last = None\n+        p = []\n+\n+        # each paragraph contains out of 20 to 100 words.\n+        for idx, _ in enumerate(range(randrange(min, max))):\n+            while True:\n+                word = choice(words)\n+                if word != last:\n+                    last = word\n+                    break\n+            if next_capitalized:\n+                word = word.capitalize()\n+                next_capitalized = False\n+            # add commas\n+            if idx - randrange(3, 8) &gt; last_comma:\n+                last_comma = idx\n+                last_fullstop += 2\n+                word += \",\"\n+            # add end of sentences\n+            if idx - randrange(10, 20) &gt; last_fullstop:\n+                last_comma = last_fullstop = idx\n+                word += \".\"\n+                next_capitalized = True\n+            p.append(word)\n+\n+        # ensure that the paragraph ends with a dot.\n+        p_str = \" \".join(p)\n+\n+        if p_str.endswith(\",\"):\n+            p_str = p_str[:-1] + \".\"\n+        elif not p_str.endswith(\".\"):\n+            p_str += \".\"\n+\n+        result.append(p_str)\n+\n+    if not html:\n+        return \"\\n\\n\".join(result)\n+    return markupsafe.Markup(\n+        \"\\n\".join(f\"&lt;p&gt;{markupsafe.escape(x)}&lt;/p&gt;\" for x in result)\n+    )\n\n\n-def url_quote(obj: t.Any, charset: str='utf-8', for_qs: bool=False) -&gt;str:\n+def url_quote(obj: t.Any, charset: str = \"utf-8\", for_qs: bool = False) -&gt; str:\n     \"\"\"Quote a string for use in a URL using the given charset.\n\n     :param obj: String or bytes to quote. Other types are converted to\n@@ -218,60 +402,99 @@ def url_quote(obj: t.Any, charset: str='utf-8', for_qs: bool=False) -&gt;str:\n     :param charset: Encode text to bytes using this charset.\n     :param for_qs: Quote \"/\" and use \"+\" for spaces.\n     \"\"\"\n-    pass\n+    if not isinstance(obj, bytes):\n+        if not isinstance(obj, str):\n+            obj = str(obj)\n+\n+        obj = obj.encode(charset)\n+\n+    safe = b\"\" if for_qs else b\"/\"\n+    rv = quote_from_bytes(obj, safe)\n+\n+    if for_qs:\n+        rv = rv.replace(\"%20\", \"+\")\n+\n+    return rv\n\n\n @abc.MutableMapping.register\n class LRUCache:\n     \"\"\"A simple LRU Cache implementation.\"\"\"\n\n-    def __init__(self, capacity: int) -&gt;None:\n+    # this is fast for small capacities (something below 1000) but doesn't\n+    # scale.  But as long as it's only used as storage for templates this\n+    # won't do any harm.\n+\n+    def __init__(self, capacity: int) -&gt; None:\n         self.capacity = capacity\n         self._mapping: t.Dict[t.Any, t.Any] = {}\n-        self._queue: 'te.Deque[t.Any]' = deque()\n+        self._queue: \"te.Deque[t.Any]\" = deque()\n         self._postinit()\n\n-    def __getstate__(self) -&gt;t.Mapping[str, t.Any]:\n-        return {'capacity': self.capacity, '_mapping': self._mapping,\n-            '_queue': self._queue}\n-\n-    def __setstate__(self, d: t.Mapping[str, t.Any]) -&gt;None:\n+    def _postinit(self) -&gt; None:\n+        # alias all queue methods for faster lookup\n+        self._popleft = self._queue.popleft\n+        self._pop = self._queue.pop\n+        self._remove = self._queue.remove\n+        self._wlock = Lock()\n+        self._append = self._queue.append\n+\n+    def __getstate__(self) -&gt; t.Mapping[str, t.Any]:\n+        return {\n+            \"capacity\": self.capacity,\n+            \"_mapping\": self._mapping,\n+            \"_queue\": self._queue,\n+        }\n+\n+    def __setstate__(self, d: t.Mapping[str, t.Any]) -&gt; None:\n         self.__dict__.update(d)\n         self._postinit()\n\n-    def __getnewargs__(self) -&gt;t.Tuple[t.Any, ...]:\n-        return self.capacity,\n+    def __getnewargs__(self) -&gt; t.Tuple[t.Any, ...]:\n+        return (self.capacity,)\n\n-    def copy(self) -&gt;'LRUCache':\n+    def copy(self) -&gt; \"LRUCache\":\n         \"\"\"Return a shallow copy of the instance.\"\"\"\n-        pass\n+        rv = self.__class__(self.capacity)\n+        rv._mapping.update(self._mapping)\n+        rv._queue.extend(self._queue)\n+        return rv\n\n-    def get(self, key: t.Any, default: t.Any=None) -&gt;t.Any:\n+    def get(self, key: t.Any, default: t.Any = None) -&gt; t.Any:\n         \"\"\"Return an item from the cache dict or `default`\"\"\"\n-        pass\n+        try:\n+            return self[key]\n+        except KeyError:\n+            return default\n\n-    def setdefault(self, key: t.Any, default: t.Any=None) -&gt;t.Any:\n+    def setdefault(self, key: t.Any, default: t.Any = None) -&gt; t.Any:\n         \"\"\"Set `default` if the key is not in the cache otherwise\n         leave unchanged. Return the value of this key.\n         \"\"\"\n-        pass\n+        try:\n+            return self[key]\n+        except KeyError:\n+            self[key] = default\n+            return default\n\n-    def clear(self) -&gt;None:\n+    def clear(self) -&gt; None:\n         \"\"\"Clear the cache.\"\"\"\n-        pass\n+        with self._wlock:\n+            self._mapping.clear()\n+            self._queue.clear()\n\n-    def __contains__(self, key: t.Any) -&gt;bool:\n+    def __contains__(self, key: t.Any) -&gt; bool:\n         \"\"\"Check if a key exists in this cache.\"\"\"\n         return key in self._mapping\n\n-    def __len__(self) -&gt;int:\n+    def __len__(self) -&gt; int:\n         \"\"\"Return the current size of the cache.\"\"\"\n         return len(self._mapping)\n\n-    def __repr__(self) -&gt;str:\n-        return f'&lt;{type(self).__name__} {self._mapping!r}&gt;'\n+    def __repr__(self) -&gt; str:\n+        return f\"&lt;{type(self).__name__} {self._mapping!r}&gt;\"\n\n-    def __getitem__(self, key: t.Any) -&gt;t.Any:\n+    def __getitem__(self, key: t.Any) -&gt; t.Any:\n         \"\"\"Get an item from the cache. Moves the item up so that it has the\n         highest priority then.\n\n@@ -279,15 +502,21 @@ class LRUCache:\n         \"\"\"\n         with self._wlock:\n             rv = self._mapping[key]\n+\n             if self._queue[-1] != key:\n                 try:\n                     self._remove(key)\n                 except ValueError:\n+                    # if something removed the key from the container\n+                    # when we read, ignore the ValueError that we would\n+                    # get otherwise.\n                     pass\n+\n                 self._append(key)\n+\n             return rv\n\n-    def __setitem__(self, key: t.Any, value: t.Any) -&gt;None:\n+    def __setitem__(self, key: t.Any, value: t.Any) -&gt; None:\n         \"\"\"Sets the value for an item. Moves the item up so that it\n         has the highest priority then.\n         \"\"\"\n@@ -296,46 +525,54 @@ class LRUCache:\n                 self._remove(key)\n             elif len(self._mapping) == self.capacity:\n                 del self._mapping[self._popleft()]\n+\n             self._append(key)\n             self._mapping[key] = value\n\n-    def __delitem__(self, key: t.Any) -&gt;None:\n+    def __delitem__(self, key: t.Any) -&gt; None:\n         \"\"\"Remove an item from the cache dict.\n         Raise a `KeyError` if it does not exist.\n         \"\"\"\n         with self._wlock:\n             del self._mapping[key]\n+\n             try:\n                 self._remove(key)\n             except ValueError:\n                 pass\n\n-    def items(self) -&gt;t.Iterable[t.Tuple[t.Any, t.Any]]:\n+    def items(self) -&gt; t.Iterable[t.Tuple[t.Any, t.Any]]:\n         \"\"\"Return a list of items.\"\"\"\n-        pass\n+        result = [(key, self._mapping[key]) for key in list(self._queue)]\n+        result.reverse()\n+        return result\n\n-    def values(self) -&gt;t.Iterable[t.Any]:\n+    def values(self) -&gt; t.Iterable[t.Any]:\n         \"\"\"Return a list of all values.\"\"\"\n-        pass\n+        return [x[1] for x in self.items()]\n\n-    def keys(self) -&gt;t.Iterable[t.Any]:\n+    def keys(self) -&gt; t.Iterable[t.Any]:\n         \"\"\"Return a list of all keys ordered by most recent usage.\"\"\"\n-        pass\n+        return list(self)\n\n-    def __iter__(self) -&gt;t.Iterator[t.Any]:\n+    def __iter__(self) -&gt; t.Iterator[t.Any]:\n         return reversed(tuple(self._queue))\n\n-    def __reversed__(self) -&gt;t.Iterator[t.Any]:\n+    def __reversed__(self) -&gt; t.Iterator[t.Any]:\n         \"\"\"Iterate over the keys in the cache dict, oldest items\n         coming first.\n         \"\"\"\n         return iter(tuple(self._queue))\n+\n     __copy__ = copy\n\n\n-def select_autoescape(enabled_extensions: t.Collection[str]=('html', 'htm',\n-    'xml'), disabled_extensions: t.Collection[str]=(), default_for_string:\n-    bool=True, default: bool=False) -&gt;t.Callable[[t.Optional[str]], bool]:\n+def select_autoescape(\n+    enabled_extensions: t.Collection[str] = (\"html\", \"htm\", \"xml\"),\n+    disabled_extensions: t.Collection[str] = (),\n+    default_for_string: bool = True,\n+    default: bool = False,\n+) -&gt; t.Callable[[t.Optional[str]], bool]:\n     \"\"\"Intelligently sets the initial value of autoescaping based on the\n     filename of the template.  This is the recommended way to configure\n     autoescaping if you do not want to write a custom function yourself.\n@@ -370,11 +607,25 @@ def select_autoescape(enabled_extensions: t.Collection[str]=('html', 'htm',\n\n     .. versionadded:: 2.9\n     \"\"\"\n-    pass\n+    enabled_patterns = tuple(f\".{x.lstrip('.').lower()}\" for x in enabled_extensions)\n+    disabled_patterns = tuple(f\".{x.lstrip('.').lower()}\" for x in disabled_extensions)\n+\n+    def autoescape(template_name: t.Optional[str]) -&gt; bool:\n+        if template_name is None:\n+            return default_for_string\n+        template_name = template_name.lower()\n+        if template_name.endswith(enabled_patterns):\n+            return True\n+        if template_name.endswith(disabled_patterns):\n+            return False\n+        return default\n\n+    return autoescape\n\n-def htmlsafe_json_dumps(obj: t.Any, dumps: t.Optional[t.Callable[..., str]]\n-    =None, **kwargs: t.Any) -&gt;markupsafe.Markup:\n+\n+def htmlsafe_json_dumps(\n+    obj: t.Any, dumps: t.Optional[t.Callable[..., str]] = None, **kwargs: t.Any\n+) -&gt; markupsafe.Markup:\n     \"\"\"Serialize an object to a string of JSON with :func:`json.dumps`,\n     then replace HTML-unsafe characters with Unicode escapes and mark\n     the result safe with :class:`~markupsafe.Markup`.\n@@ -400,7 +651,16 @@ def htmlsafe_json_dumps(obj: t.Any, dumps: t.Optional[t.Callable[..., str]]\n\n     .. versionadded:: 2.9\n     \"\"\"\n-    pass\n+    if dumps is None:\n+        dumps = json.dumps\n+\n+    return markupsafe.Markup(\n+        dumps(obj, **kwargs)\n+        .replace(\"&lt;\", \"\\\\u003c\")\n+        .replace(\"&gt;\", \"\\\\u003e\")\n+        .replace(\"&amp;\", \"\\\\u0026\")\n+        .replace(\"'\", \"\\\\u0027\")\n+    )\n\n\n class Cycler:\n@@ -429,42 +689,45 @@ class Cycler:\n     .. versionadded:: 2.1\n     \"\"\"\n\n-    def __init__(self, *items: t.Any) -&gt;None:\n+    def __init__(self, *items: t.Any) -&gt; None:\n         if not items:\n-            raise RuntimeError('at least one item has to be provided')\n+            raise RuntimeError(\"at least one item has to be provided\")\n         self.items = items\n         self.pos = 0\n\n-    def reset(self) -&gt;None:\n+    def reset(self) -&gt; None:\n         \"\"\"Resets the current item to the first item.\"\"\"\n-        pass\n+        self.pos = 0\n\n     @property\n-    def current(self) -&gt;t.Any:\n+    def current(self) -&gt; t.Any:\n         \"\"\"Return the current item. Equivalent to the item that will be\n         returned next time :meth:`next` is called.\n         \"\"\"\n-        pass\n+        return self.items[self.pos]\n\n-    def next(self) -&gt;t.Any:\n+    def next(self) -&gt; t.Any:\n         \"\"\"Return the current item, then advance :attr:`current` to the\n         next item.\n         \"\"\"\n-        pass\n+        rv = self.current\n+        self.pos = (self.pos + 1) % len(self.items)\n+        return rv\n+\n     __next__ = next\n\n\n class Joiner:\n     \"\"\"A joining helper for templates.\"\"\"\n\n-    def __init__(self, sep: str=', ') -&gt;None:\n+    def __init__(self, sep: str = \", \") -&gt; None:\n         self.sep = sep\n         self.used = False\n\n-    def __call__(self) -&gt;str:\n+    def __call__(self) -&gt; str:\n         if not self.used:\n             self.used = True\n-            return ''\n+            return \"\"\n         return self.sep\n\n\n@@ -472,20 +735,21 @@ class Namespace:\n     \"\"\"A namespace object that can hold arbitrary attributes.  It may be\n     initialized from a dictionary or with keyword arguments.\"\"\"\n\n-    def __init__(*args: t.Any, **kwargs: t.Any) -&gt;None:\n+    def __init__(*args: t.Any, **kwargs: t.Any) -&gt; None:  # noqa: B902\n         self, args = args[0], args[1:]\n         self.__attrs = dict(*args, **kwargs)\n\n-    def __getattribute__(self, name: str) -&gt;t.Any:\n-        if name in {'_Namespace__attrs', '__class__'}:\n+    def __getattribute__(self, name: str) -&gt; t.Any:\n+        # __class__ is needed for the awaitable check in async mode\n+        if name in {\"_Namespace__attrs\", \"__class__\"}:\n             return object.__getattribute__(self, name)\n         try:\n             return self.__attrs[name]\n         except KeyError:\n             raise AttributeError(name) from None\n\n-    def __setitem__(self, name: str, value: t.Any) -&gt;None:\n+    def __setitem__(self, name: str, value: t.Any) -&gt; None:\n         self.__attrs[name] = value\n\n-    def __repr__(self) -&gt;str:\n-        return f'&lt;Namespace {self.__attrs!r}&gt;'\n+    def __repr__(self) -&gt; str:\n+        return f\"&lt;Namespace {self.__attrs!r}&gt;\"\ndiff --git a/src/jinja2/visitor.py b/src/jinja2/visitor.py\nindex ebb34c6..7b8e180 100644\n--- a/src/jinja2/visitor.py\n+++ b/src/jinja2/visitor.py\n@@ -1,16 +1,16 @@\n \"\"\"API for traversing the AST nodes. Implemented by the compiler and\n meta introspection.\n \"\"\"\n+\n import typing as t\n+\n from .nodes import Node\n+\n if t.TYPE_CHECKING:\n     import typing_extensions as te\n\n-\n     class VisitCallable(te.Protocol):\n-\n-        def __call__(self, node: Node, *args: t.Any, **kwargs: t.Any) -&gt;t.Any:\n-            ...\n+        def __call__(self, node: Node, *args: t.Any, **kwargs: t.Any) -&gt; t.Any: ...\n\n\n class NodeVisitor:\n@@ -25,20 +25,26 @@ class NodeVisitor:\n     (return value `None`) the `generic_visit` visitor is used instead.\n     \"\"\"\n\n-    def get_visitor(self, node: Node) -&gt;'t.Optional[VisitCallable]':\n+    def get_visitor(self, node: Node) -&gt; \"t.Optional[VisitCallable]\":\n         \"\"\"Return the visitor function for this node or `None` if no visitor\n         exists for this node.  In that case the generic visit function is\n         used instead.\n         \"\"\"\n-        pass\n+        return getattr(self, f\"visit_{type(node).__name__}\", None)\n\n-    def visit(self, node: Node, *args: t.Any, **kwargs: t.Any) -&gt;t.Any:\n+    def visit(self, node: Node, *args: t.Any, **kwargs: t.Any) -&gt; t.Any:\n         \"\"\"Visit a node.\"\"\"\n-        pass\n+        f = self.get_visitor(node)\n\n-    def generic_visit(self, node: Node, *args: t.Any, **kwargs: t.Any) -&gt;t.Any:\n+        if f is not None:\n+            return f(node, *args, **kwargs)\n+\n+        return self.generic_visit(node, *args, **kwargs)\n+\n+    def generic_visit(self, node: Node, *args: t.Any, **kwargs: t.Any) -&gt; t.Any:\n         \"\"\"Called if no explicit visitor function exists for a node.\"\"\"\n-        pass\n+        for child_node in node.iter_child_nodes():\n+            self.visit(child_node, *args, **kwargs)\n\n\n class NodeTransformer(NodeVisitor):\n@@ -52,9 +58,35 @@ class NodeTransformer(NodeVisitor):\n     replacement takes place.\n     \"\"\"\n\n-    def visit_list(self, node: Node, *args: t.Any, **kwargs: t.Any) -&gt;t.List[\n-        Node]:\n+    def generic_visit(self, node: Node, *args: t.Any, **kwargs: t.Any) -&gt; Node:\n+        for field, old_value in node.iter_fields():\n+            if isinstance(old_value, list):\n+                new_values = []\n+                for value in old_value:\n+                    if isinstance(value, Node):\n+                        value = self.visit(value, *args, **kwargs)\n+                        if value is None:\n+                            continue\n+                        elif not isinstance(value, Node):\n+                            new_values.extend(value)\n+                            continue\n+                    new_values.append(value)\n+                old_value[:] = new_values\n+            elif isinstance(old_value, Node):\n+                new_node = self.visit(old_value, *args, **kwargs)\n+                if new_node is None:\n+                    delattr(node, field)\n+                else:\n+                    setattr(node, field, new_node)\n+        return node\n+\n+    def visit_list(self, node: Node, *args: t.Any, **kwargs: t.Any) -&gt; t.List[Node]:\n         \"\"\"As transformers may return lists in some places this method\n         can be used to enforce a list as return value.\n         \"\"\"\n-        pass\n+        rv = self.visit(node, *args, **kwargs)\n+\n+        if not isinstance(rv, list):\n+            return [rv]\n+\n+        return rv\n</code></pre>"},{"location":"analysis_reference_marshmallow/","title":"Analysis reference marshmallow","text":"<p>back to reference summary</p>"},{"location":"analysis_reference_marshmallow/#submission-name-reference","title":"Submission Name: reference","text":""},{"location":"analysis_reference_marshmallow/#repository-marshmallow","title":"Repository: marshmallow","text":""},{"location":"analysis_reference_marshmallow/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count passed 1229 total 1229 collected 1229"},{"location":"analysis_reference_marshmallow/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_reference_marshmallow/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/src/marshmallow/base.py b/src/marshmallow/base.py\nindex 5849d2e..e82848d 100644\n--- a/src/marshmallow/base.py\n+++ b/src/marshmallow/base.py\n@@ -7,16 +7,59 @@ These are necessary to avoid circular imports between schema.py and fields.py.\n     This module is treated as private API.\n     Users should not need to use this module directly.\n \"\"\"\n+\n from __future__ import annotations\n+\n from abc import ABC, abstractmethod\n\n\n class FieldABC(ABC):\n     \"\"\"Abstract base class from which all Field classes inherit.\"\"\"\n+\n     parent = None\n     name = None\n     root = None\n\n+    @abstractmethod\n+    def serialize(self, attr, obj, accessor=None):\n+        pass\n+\n+    @abstractmethod\n+    def deserialize(self, value):\n+        pass\n+\n+    @abstractmethod\n+    def _serialize(self, value, attr, obj, **kwargs):\n+        pass\n+\n+    @abstractmethod\n+    def _deserialize(self, value, attr, data, **kwargs):\n+        pass\n+\n\n class SchemaABC(ABC):\n     \"\"\"Abstract base class from which all Schemas inherit.\"\"\"\n+\n+    @abstractmethod\n+    def dump(self, obj, *, many: bool | None = None):\n+        pass\n+\n+    @abstractmethod\n+    def dumps(self, obj, *, many: bool | None = None):\n+        pass\n+\n+    @abstractmethod\n+    def load(self, data, *, many: bool | None = None, partial=None, unknown=None):\n+        pass\n+\n+    @abstractmethod\n+    def loads(\n+        self,\n+        json_data,\n+        *,\n+        many: bool | None = None,\n+        partial=None,\n+        unknown=None,\n+        **kwargs,\n+    ):\n+        pass\ndiff --git a/src/marshmallow/class_registry.py b/src/marshmallow/class_registry.py\nindex 249b898..810d115 100644\n--- a/src/marshmallow/class_registry.py\n+++ b/src/marshmallow/class_registry.py\n@@ -7,16 +7,26 @@ class:`fields.Nested &lt;marshmallow.fields.Nested&gt;`.\n     This module is treated as private API.\n     Users should not need to use this module directly.\n \"\"\"\n+\n from __future__ import annotations\n+\n import typing\n+\n from marshmallow.exceptions import RegistryError\n+\n if typing.TYPE_CHECKING:\n     from marshmallow import Schema\n+\n     SchemaType = typing.Type[Schema]\n-_registry = {}\n\n+# {\n+#   &lt;class_name&gt;: &lt;list of class objects&gt;\n+#   &lt;module_path_to_class&gt;: &lt;list of class objects&gt;\n+# }\n+_registry = {}  # type: dict[str, list[SchemaType]]\n\n-def register(classname: str, cls: SchemaType) -&gt;None:\n+\n+def register(classname: str, cls: SchemaType) -&gt; None:\n     \"\"\"Add a class to the registry of serializer classes. When a class is\n     registered, an entry for both its classname and its full, module-qualified\n     path are added to the registry.\n@@ -35,14 +45,50 @@ def register(classname: str, cls: SchemaType) -&gt;None:\n         # }\n\n     \"\"\"\n-    pass\n+    # Module where the class is located\n+    module = cls.__module__\n+    # Full module path to the class\n+    # e.g. user.schemas.UserSchema\n+    fullpath = \".\".join([module, classname])\n+    # If the class is already registered; need to check if the entries are\n+    # in the same module as cls to avoid having multiple instances of the same\n+    # class in the registry\n+    if classname in _registry and not any(\n+        each.__module__ == module for each in _registry[classname]\n+    ):\n+        _registry[classname].append(cls)\n+    elif classname not in _registry:\n+        _registry[classname] = [cls]\n\n+    # Also register the full path\n+    if fullpath not in _registry:\n+        _registry.setdefault(fullpath, []).append(cls)\n+    else:\n+        # If fullpath does exist, replace existing entry\n+        _registry[fullpath] = [cls]\n+    return None\n\n-def get_class(classname: str, all: bool=False) -&gt;(list[SchemaType] | SchemaType\n-    ):\n+\n+def get_class(classname: str, all: bool = False) -&gt; list[SchemaType] | SchemaType:\n     \"\"\"Retrieve a class from the registry.\n\n     :raises: marshmallow.exceptions.RegistryError if the class cannot be found\n         or if there are multiple entries for the given class name.\n     \"\"\"\n-    pass\n+    try:\n+        classes = _registry[classname]\n+    except KeyError as error:\n+        raise RegistryError(\n+            f\"Class with name {classname!r} was not found. You may need \"\n+            \"to import the class.\"\n+        ) from error\n+    if len(classes) &gt; 1:\n+        if all:\n+            return _registry[classname]\n+        raise RegistryError(\n+            f\"Multiple classes with name {classname!r} \"\n+            \"were found. Please use the full, \"\n+            \"module-qualified path.\"\n+        )\n+    else:\n+        return _registry[classname][0]\ndiff --git a/src/marshmallow/decorators.py b/src/marshmallow/decorators.py\nindex d78f5be..dafca95 100644\n--- a/src/marshmallow/decorators.py\n+++ b/src/marshmallow/decorators.py\n@@ -64,32 +64,38 @@ Example: ::\n     If you need to guarantee order of different processing steps, you should put\n     them in the same processing method.\n \"\"\"\n+\n from __future__ import annotations\n+\n import functools\n from typing import Any, Callable, cast\n-PRE_DUMP = 'pre_dump'\n-POST_DUMP = 'post_dump'\n-PRE_LOAD = 'pre_load'\n-POST_LOAD = 'post_load'\n-VALIDATES = 'validates'\n-VALIDATES_SCHEMA = 'validates_schema'\n+\n+PRE_DUMP = \"pre_dump\"\n+POST_DUMP = \"post_dump\"\n+PRE_LOAD = \"pre_load\"\n+POST_LOAD = \"post_load\"\n+VALIDATES = \"validates\"\n+VALIDATES_SCHEMA = \"validates_schema\"\n\n\n class MarshmallowHook:\n     __marshmallow_hook__: dict[tuple[str, bool] | str, Any] | None = None\n\n\n-def validates(field_name: str) -&gt;Callable[..., Any]:\n+def validates(field_name: str) -&gt; Callable[..., Any]:\n     \"\"\"Register a field validator.\n\n     :param str field_name: Name of the field that the method validates.\n     \"\"\"\n-    pass\n+    return set_hook(None, VALIDATES, field_name=field_name)\n\n\n-def validates_schema(fn: (Callable[..., Any] | None)=None, pass_many: bool=\n-    False, pass_original: bool=False, skip_on_field_errors: bool=True\n-    ) -&gt;Callable[..., Any]:\n+def validates_schema(\n+    fn: Callable[..., Any] | None = None,\n+    pass_many: bool = False,\n+    pass_original: bool = False,\n+    skip_on_field_errors: bool = True,\n+) -&gt; Callable[..., Any]:\n     \"\"\"Register a schema-level validator.\n\n     By default it receives a single object at a time, transparently handling the ``many``\n@@ -109,11 +115,17 @@ def validates_schema(fn: (Callable[..., Any] | None)=None, pass_many: bool=\n         ``partial`` and ``many`` are always passed as keyword arguments to\n         the decorated method.\n     \"\"\"\n-    pass\n+    return set_hook(\n+        fn,\n+        (VALIDATES_SCHEMA, pass_many),\n+        pass_original=pass_original,\n+        skip_on_field_errors=skip_on_field_errors,\n+    )\n\n\n-def pre_dump(fn: (Callable[..., Any] | None)=None, pass_many: bool=False\n-    ) -&gt;Callable[..., Any]:\n+def pre_dump(\n+    fn: Callable[..., Any] | None = None, pass_many: bool = False\n+) -&gt; Callable[..., Any]:\n     \"\"\"Register a method to invoke before serializing an object. The method\n     receives the object to be serialized and returns the processed object.\n\n@@ -124,11 +136,14 @@ def pre_dump(fn: (Callable[..., Any] | None)=None, pass_many: bool=False\n     .. versionchanged:: 3.0.0\n         ``many`` is always passed as a keyword arguments to the decorated method.\n     \"\"\"\n-    pass\n+    return set_hook(fn, (PRE_DUMP, pass_many))\n\n\n-def post_dump(fn: (Callable[..., Any] | None)=None, pass_many: bool=False,\n-    pass_original: bool=False) -&gt;Callable[..., Any]:\n+def post_dump(\n+    fn: Callable[..., Any] | None = None,\n+    pass_many: bool = False,\n+    pass_original: bool = False,\n+) -&gt; Callable[..., Any]:\n     \"\"\"Register a method to invoke after serializing an object. The method\n     receives the serialized object and returns the processed object.\n\n@@ -142,11 +157,12 @@ def post_dump(fn: (Callable[..., Any] | None)=None, pass_many: bool=False,\n     .. versionchanged:: 3.0.0\n         ``many`` is always passed as a keyword arguments to the decorated method.\n     \"\"\"\n-    pass\n+    return set_hook(fn, (POST_DUMP, pass_many), pass_original=pass_original)\n\n\n-def pre_load(fn: (Callable[..., Any] | None)=None, pass_many: bool=False\n-    ) -&gt;Callable[..., Any]:\n+def pre_load(\n+    fn: Callable[..., Any] | None = None, pass_many: bool = False\n+) -&gt; Callable[..., Any]:\n     \"\"\"Register a method to invoke before deserializing an object. The method\n     receives the data to be deserialized and returns the processed data.\n\n@@ -158,11 +174,14 @@ def pre_load(fn: (Callable[..., Any] | None)=None, pass_many: bool=False\n         ``partial`` and ``many`` are always passed as keyword arguments to\n         the decorated method.\n     \"\"\"\n-    pass\n+    return set_hook(fn, (PRE_LOAD, pass_many))\n\n\n-def post_load(fn: (Callable[..., Any] | None)=None, pass_many: bool=False,\n-    pass_original: bool=False) -&gt;Callable[..., Any]:\n+def post_load(\n+    fn: Callable[..., Any] | None = None,\n+    pass_many: bool = False,\n+    pass_original: bool = False,\n+) -&gt; Callable[..., Any]:\n     \"\"\"Register a method to invoke after deserializing an object. The method\n     receives the deserialized data and returns the processed data.\n\n@@ -177,11 +196,12 @@ def post_load(fn: (Callable[..., Any] | None)=None, pass_many: bool=False,\n         ``partial`` and ``many`` are always passed as keyword arguments to\n         the decorated method.\n     \"\"\"\n-    pass\n+    return set_hook(fn, (POST_LOAD, pass_many), pass_original=pass_original)\n\n\n-def set_hook(fn: (Callable[..., Any] | None), key: (tuple[str, bool] | str),\n-    **kwargs: Any) -&gt;Callable[..., Any]:\n+def set_hook(\n+    fn: Callable[..., Any] | None, key: tuple[str, bool] | str, **kwargs: Any\n+) -&gt; Callable[..., Any]:\n     \"\"\"Mark decorated function as a hook to be picked up later.\n     You should not need to use this method directly.\n\n@@ -192,4 +212,20 @@ def set_hook(fn: (Callable[..., Any] | None), key: (tuple[str, bool] | str),\n     :return: Decorated function if supplied, else this decorator with its args\n         bound.\n     \"\"\"\n-    pass\n+    # Allow using this as either a decorator or a decorator factory.\n+    if fn is None:\n+        return functools.partial(set_hook, key=key, **kwargs)\n+\n+    # Set a __marshmallow_hook__ attribute instead of wrapping in some class,\n+    # because I still want this to end up as a normal (unbound) method.\n+    function = cast(MarshmallowHook, fn)\n+    try:\n+        hook_config = function.__marshmallow_hook__\n+    except AttributeError:\n+        function.__marshmallow_hook__ = hook_config = {}\n+    # Also save the kwargs for the tagged function on\n+    # __marshmallow_hook__, keyed by (&lt;tag&gt;, &lt;pass_many&gt;)\n+    if hook_config is not None:\n+        hook_config[key] = kwargs\n+\n+    return fn\ndiff --git a/src/marshmallow/error_store.py b/src/marshmallow/error_store.py\nindex a659aaf..72b7037 100644\n--- a/src/marshmallow/error_store.py\n+++ b/src/marshmallow/error_store.py\n@@ -5,14 +5,25 @@\n     This module is treated as private API.\n     Users should not need to use this module directly.\n \"\"\"\n+\n from marshmallow.exceptions import SCHEMA\n\n\n class ErrorStore:\n-\n     def __init__(self):\n+        #: Dictionary of errors stored during serialization\n         self.errors = {}\n\n+    def store_error(self, messages, field_name=SCHEMA, index=None):\n+        # field error  -&gt; store/merge error messages under field name key\n+        # schema error -&gt; if string or list, store/merge under _schema key\n+        #              -&gt; if dict, store/merge with other top-level keys\n+        if field_name != SCHEMA or not isinstance(messages, dict):\n+            messages = {field_name: messages}\n+        if index is not None:\n+            messages = {index: messages}\n+        self.errors = merge_errors(self.errors, messages)\n+\n\n def merge_errors(errors1, errors2):\n     \"\"\"Deeply merge two error messages.\n@@ -20,4 +31,30 @@ def merge_errors(errors1, errors2):\n     The format of ``errors1`` and ``errors2`` matches the ``message``\n     parameter of :exc:`marshmallow.exceptions.ValidationError`.\n     \"\"\"\n-    pass\n+    if not errors1:\n+        return errors2\n+    if not errors2:\n+        return errors1\n+    if isinstance(errors1, list):\n+        if isinstance(errors2, list):\n+            return errors1 + errors2\n+        if isinstance(errors2, dict):\n+            return dict(errors2, **{SCHEMA: merge_errors(errors1, errors2.get(SCHEMA))})\n+        return errors1 + [errors2]\n+    if isinstance(errors1, dict):\n+        if isinstance(errors2, list):\n+            return dict(errors1, **{SCHEMA: merge_errors(errors1.get(SCHEMA), errors2)})\n+        if isinstance(errors2, dict):\n+            errors = dict(errors1)\n+            for key, val in errors2.items():\n+                if key in errors:\n+                    errors[key] = merge_errors(errors[key], val)\n+                else:\n+                    errors[key] = val\n+            return errors\n+        return dict(errors1, **{SCHEMA: merge_errors(errors1.get(SCHEMA), errors2)})\n+    if isinstance(errors2, list):\n+        return [errors1] + errors2\n+    if isinstance(errors2, dict):\n+        return dict(errors2, **{SCHEMA: merge_errors(errors1, errors2.get(SCHEMA))})\n+    return [errors1, errors2]\ndiff --git a/src/marshmallow/exceptions.py b/src/marshmallow/exceptions.py\nindex 52e36c1..096b6bd 100644\n--- a/src/marshmallow/exceptions.py\n+++ b/src/marshmallow/exceptions.py\n@@ -1,7 +1,11 @@\n \"\"\"Exception classes for marshmallow-related errors.\"\"\"\n+\n from __future__ import annotations\n+\n import typing\n-SCHEMA = '_schema'\n+\n+# Key used for schema-level validation errors\n+SCHEMA = \"_schema\"\n\n\n class MarshmallowError(Exception):\n@@ -21,18 +25,37 @@ class ValidationError(MarshmallowError):\n     :param valid_data: Valid (de)serialized data.\n     \"\"\"\n\n-    def __init__(self, message: (str | list | dict), field_name: str=SCHEMA,\n-        data: (typing.Mapping[str, typing.Any] | typing.Iterable[typing.\n-        Mapping[str, typing.Any]] | None)=None, valid_data: (list[dict[str,\n-        typing.Any]] | dict[str, typing.Any] | None)=None, **kwargs):\n-        self.messages = [message] if isinstance(message, (str, bytes)\n-            ) else message\n+    def __init__(\n+        self,\n+        message: str | list | dict,\n+        field_name: str = SCHEMA,\n+        data: typing.Mapping[str, typing.Any]\n+        | typing.Iterable[typing.Mapping[str, typing.Any]]\n+        | None = None,\n+        valid_data: list[dict[str, typing.Any]] | dict[str, typing.Any] | None = None,\n+        **kwargs,\n+    ):\n+        self.messages = [message] if isinstance(message, (str, bytes)) else message\n         self.field_name = field_name\n         self.data = data\n         self.valid_data = valid_data\n         self.kwargs = kwargs\n         super().__init__(message)\n\n+    def normalized_messages(self):\n+        if self.field_name == SCHEMA and isinstance(self.messages, dict):\n+            return self.messages\n+        return {self.field_name: self.messages}\n+\n+    @property\n+    def messages_dict(self) -&gt; dict[str, typing.Any]:\n+        if not isinstance(self.messages, dict):\n+            raise TypeError(\n+                \"cannot access 'messages_dict' when 'messages' is of type \"\n+                + type(self.messages).__name__\n+            )\n+        return self.messages\n+\n\n class RegistryError(NameError):\n     \"\"\"Raised when an invalid operation is performed on the serializer\ndiff --git a/src/marshmallow/fields.py b/src/marshmallow/fields.py\nindex 8656a56..ceb32aa 100644\n--- a/src/marshmallow/fields.py\n+++ b/src/marshmallow/fields.py\n@@ -1,5 +1,7 @@\n \"\"\"Field classes for various types of data.\"\"\"\n+\n from __future__ import annotations\n+\n import collections\n import copy\n import datetime as dt\n@@ -12,20 +14,66 @@ import uuid\n import warnings\n from collections.abc import Mapping as _Mapping\n from enum import Enum as EnumType\n+\n from marshmallow import class_registry, types, utils, validate\n from marshmallow.base import FieldABC, SchemaABC\n-from marshmallow.exceptions import FieldInstanceResolutionError, StringNotCollectionError, ValidationError\n-from marshmallow.utils import is_aware, is_collection, resolve_field_instance\n-from marshmallow.utils import missing as missing_\n+from marshmallow.exceptions import (\n+    FieldInstanceResolutionError,\n+    StringNotCollectionError,\n+    ValidationError,\n+)\n+from marshmallow.utils import (\n+    is_aware,\n+    is_collection,\n+    resolve_field_instance,\n+)\n+from marshmallow.utils import (\n+    missing as missing_,\n+)\n from marshmallow.validate import And, Length\n from marshmallow.warnings import RemovedInMarshmallow4Warning\n-__all__ = ['Field', 'Raw', 'Nested', 'Mapping', 'Dict', 'List', 'Tuple',\n-    'String', 'UUID', 'Number', 'Integer', 'Decimal', 'Boolean', 'Float',\n-    'DateTime', 'NaiveDateTime', 'AwareDateTime', 'Time', 'Date',\n-    'TimeDelta', 'Url', 'URL', 'Email', 'IP', 'IPv4', 'IPv6', 'IPInterface',\n-    'IPv4Interface', 'IPv6Interface', 'Enum', 'Method', 'Function', 'Str',\n-    'Bool', 'Int', 'Constant', 'Pluck']\n-_T = typing.TypeVar('_T')\n+\n+__all__ = [\n+    \"Field\",\n+    \"Raw\",\n+    \"Nested\",\n+    \"Mapping\",\n+    \"Dict\",\n+    \"List\",\n+    \"Tuple\",\n+    \"String\",\n+    \"UUID\",\n+    \"Number\",\n+    \"Integer\",\n+    \"Decimal\",\n+    \"Boolean\",\n+    \"Float\",\n+    \"DateTime\",\n+    \"NaiveDateTime\",\n+    \"AwareDateTime\",\n+    \"Time\",\n+    \"Date\",\n+    \"TimeDelta\",\n+    \"Url\",\n+    \"URL\",\n+    \"Email\",\n+    \"IP\",\n+    \"IPv4\",\n+    \"IPv6\",\n+    \"IPInterface\",\n+    \"IPv4Interface\",\n+    \"IPv6Interface\",\n+    \"Enum\",\n+    \"Method\",\n+    \"Function\",\n+    \"Str\",\n+    \"Bool\",\n+    \"Int\",\n+    \"Constant\",\n+    \"Pluck\",\n+]\n+\n+_T = typing.TypeVar(\"_T\")\n\n\n class Field(FieldABC):\n@@ -89,34 +137,65 @@ class Field(FieldABC):\n         Add ``data_key`` parameter for the specifying the key in the input and\n         output data. This parameter replaced both ``load_from`` and ``dump_to``.\n     \"\"\"\n+\n+    # Some fields, such as Method fields and Function fields, are not expected\n+    #  to exist as attributes on the objects to serialize. Set this to False\n+    #  for those fields\n     _CHECK_ATTRIBUTE = True\n-    default_error_messages = {'required':\n-        'Missing data for required field.', 'null':\n-        'Field may not be null.', 'validator_failed': 'Invalid value.'}\n-\n-    def __init__(self, *, load_default: typing.Any=missing_, missing:\n-        typing.Any=missing_, dump_default: typing.Any=missing_, default:\n-        typing.Any=missing_, data_key: (str | None)=None, attribute: (str |\n-        None)=None, validate: (None | typing.Callable[[typing.Any], typing.\n-        Any] | typing.Iterable[typing.Callable[[typing.Any], typing.Any]])=\n-        None, required: bool=False, allow_none: (bool | None)=None,\n-        load_only: bool=False, dump_only: bool=False, error_messages: (dict\n-        [str, str] | None)=None, metadata: (typing.Mapping[str, typing.Any] |\n-        None)=None, **additional_metadata) -&gt;None:\n+\n+    #: Default error messages for various kinds of errors. The keys in this dictionary\n+    #: are passed to `Field.make_error`. The values are error messages passed to\n+    #: :exc:`marshmallow.exceptions.ValidationError`.\n+    default_error_messages = {\n+        \"required\": \"Missing data for required field.\",\n+        \"null\": \"Field may not be null.\",\n+        \"validator_failed\": \"Invalid value.\",\n+    }\n+\n+    def __init__(\n+        self,\n+        *,\n+        load_default: typing.Any = missing_,\n+        missing: typing.Any = missing_,\n+        dump_default: typing.Any = missing_,\n+        default: typing.Any = missing_,\n+        data_key: str | None = None,\n+        attribute: str | None = None,\n+        validate: (\n+            None\n+            | typing.Callable[[typing.Any], typing.Any]\n+            | typing.Iterable[typing.Callable[[typing.Any], typing.Any]]\n+        ) = None,\n+        required: bool = False,\n+        allow_none: bool | None = None,\n+        load_only: bool = False,\n+        dump_only: bool = False,\n+        error_messages: dict[str, str] | None = None,\n+        metadata: typing.Mapping[str, typing.Any] | None = None,\n+        **additional_metadata,\n+    ) -&gt; None:\n+        # handle deprecated `default` and `missing` parameters\n         if default is not missing_:\n             warnings.warn(\n-                \"The 'default' argument to fields is deprecated. Use 'dump_default' instead.\"\n-                , RemovedInMarshmallow4Warning, stacklevel=2)\n+                \"The 'default' argument to fields is deprecated. \"\n+                \"Use 'dump_default' instead.\",\n+                RemovedInMarshmallow4Warning,\n+                stacklevel=2,\n+            )\n             if dump_default is missing_:\n                 dump_default = default\n         if missing is not missing_:\n             warnings.warn(\n-                \"The 'missing' argument to fields is deprecated. Use 'load_default' instead.\"\n-                , RemovedInMarshmallow4Warning, stacklevel=2)\n+                \"The 'missing' argument to fields is deprecated. \"\n+                \"Use 'load_default' instead.\",\n+                RemovedInMarshmallow4Warning,\n+                stacklevel=2,\n+            )\n             if load_default is missing_:\n                 load_default = missing\n         self.dump_default = dump_default\n         self.load_default = load_default\n+\n         self.attribute = attribute\n         self.data_key = data_key\n         self.validate = validate\n@@ -128,32 +207,46 @@ class Field(FieldABC):\n             self.validators = list(validate)\n         else:\n             raise ValueError(\n-                \"The 'validate' parameter must be a callable or a collection of callables.\"\n-                )\n-        self.allow_none = (load_default is None if allow_none is None else\n-            allow_none)\n+                \"The 'validate' parameter must be a callable \"\n+                \"or a collection of callables.\"\n+            )\n+\n+        # If allow_none is None and load_default is None\n+        # None should be considered valid by default\n+        self.allow_none = load_default is None if allow_none is None else allow_none\n         self.load_only = load_only\n         self.dump_only = dump_only\n         if required is True and load_default is not missing_:\n-            raise ValueError(\n-                \"'load_default' must not be set for required fields.\")\n+            raise ValueError(\"'load_default' must not be set for required fields.\")\n         self.required = required\n+\n         metadata = metadata or {}\n         self.metadata = {**metadata, **additional_metadata}\n         if additional_metadata:\n             warnings.warn(\n-                f'Passing field metadata as keyword arguments is deprecated. Use the explicit `metadata=...` argument instead. Additional metadata: {additional_metadata}'\n-                , RemovedInMarshmallow4Warning, stacklevel=2)\n-        messages = {}\n+                \"Passing field metadata as keyword arguments is deprecated. Use the \"\n+                \"explicit `metadata=...` argument instead. \"\n+                f\"Additional metadata: {additional_metadata}\",\n+                RemovedInMarshmallow4Warning,\n+                stacklevel=2,\n+            )\n+\n+        # Collect default error message from self and parent classes\n+        messages = {}  # type: dict[str, str]\n         for cls in reversed(self.__class__.__mro__):\n-            messages.update(getattr(cls, 'default_error_messages', {}))\n+            messages.update(getattr(cls, \"default_error_messages\", {}))\n         messages.update(error_messages or {})\n         self.error_messages = messages\n\n-    def __repr__(self) -&gt;str:\n+    def __repr__(self) -&gt; str:\n         return (\n-            f'&lt;fields.{self.__class__.__name__}(dump_default={self.dump_default!r}, attribute={self.attribute!r}, validate={self.validate}, required={self.required}, load_only={self.load_only}, dump_only={self.dump_only}, load_default={self.load_default}, allow_none={self.allow_none}, error_messages={self.error_messages})&gt;'\n-            )\n+            f\"&lt;fields.{self.__class__.__name__}(dump_default={self.dump_default!r}, \"\n+            f\"attribute={self.attribute!r}, \"\n+            f\"validate={self.validate}, required={self.required}, \"\n+            f\"load_only={self.load_only}, dump_only={self.dump_only}, \"\n+            f\"load_default={self.load_default}, allow_none={self.allow_none}, \"\n+            f\"error_messages={self.error_messages})&gt;\"\n+        )\n\n     def __deepcopy__(self, memo):\n         return copy.copy(self)\n@@ -166,19 +259,36 @@ class Field(FieldABC):\n         :param callable accessor: A callable used to retrieve the value of `attr` from\n             the object `obj`. Defaults to `marshmallow.utils.get_value`.\n         \"\"\"\n-        pass\n+        accessor_func = accessor or utils.get_value\n+        check_key = attr if self.attribute is None else self.attribute\n+        return accessor_func(obj, check_key, default)\n\n     def _validate(self, value):\n         \"\"\"Perform validation on ``value``. Raise a :exc:`ValidationError` if validation\n         does not succeed.\n         \"\"\"\n-        pass\n+        self._validate_all(value)\n\n-    def make_error(self, key: str, **kwargs) -&gt;ValidationError:\n+    @property\n+    def _validate_all(self):\n+        return And(*self.validators, error=self.error_messages[\"validator_failed\"])\n+\n+    def make_error(self, key: str, **kwargs) -&gt; ValidationError:\n         \"\"\"Helper method to make a `ValidationError` with an error message\n         from ``self.error_messages``.\n         \"\"\"\n-        pass\n+        try:\n+            msg = self.error_messages[key]\n+        except KeyError as error:\n+            class_name = self.__class__.__name__\n+            message = (\n+                f\"ValidationError raised by `{class_name}`, but error key `{key}` does \"\n+                \"not exist in the `error_messages` dictionary.\"\n+            )\n+            raise AssertionError(message) from error\n+        if isinstance(msg, (str, bytes)):\n+            msg = msg.format(**kwargs)\n+        return ValidationError(msg)\n\n     def fail(self, key: str, **kwargs):\n         \"\"\"Helper method that raises a `ValidationError` with an error message\n@@ -187,17 +297,30 @@ class Field(FieldABC):\n         .. deprecated:: 3.0.0\n             Use `make_error &lt;marshmallow.fields.Field.make_error&gt;` instead.\n         \"\"\"\n-        pass\n+        warnings.warn(\n+            f'`Field.fail` is deprecated. Use `raise self.make_error(\"{key}\", ...)` instead.',\n+            RemovedInMarshmallow4Warning,\n+            stacklevel=2,\n+        )\n+        raise self.make_error(key=key, **kwargs)\n\n     def _validate_missing(self, value):\n         \"\"\"Validate missing values. Raise a :exc:`ValidationError` if\n         `value` should be considered missing.\n         \"\"\"\n-        pass\n-\n-    def serialize(self, attr: str, obj: typing.Any, accessor: (typing.\n-        Callable[[typing.Any, str, typing.Any], typing.Any] | None)=None,\n-        **kwargs):\n+        if value is missing_ and self.required:\n+            raise self.make_error(\"required\")\n+        if value is None and not self.allow_none:\n+            raise self.make_error(\"null\")\n+\n+    def serialize(\n+        self,\n+        attr: str,\n+        obj: typing.Any,\n+        accessor: typing.Callable[[typing.Any, str, typing.Any], typing.Any]\n+        | None = None,\n+        **kwargs,\n+    ):\n         \"\"\"Pulls the value for the given key from the object, applies the\n         field's formatting and returns the result.\n\n@@ -206,10 +329,24 @@ class Field(FieldABC):\n         :param accessor: Function used to access values from ``obj``.\n         :param kwargs: Field-specific keyword arguments.\n         \"\"\"\n-        pass\n-\n-    def deserialize(self, value: typing.Any, attr: (str | None)=None, data:\n-        (typing.Mapping[str, typing.Any] | None)=None, **kwargs):\n+        if self._CHECK_ATTRIBUTE:\n+            value = self.get_value(obj, attr, accessor=accessor)\n+            if value is missing_:\n+                default = self.dump_default\n+                value = default() if callable(default) else default\n+            if value is missing_:\n+                return value\n+        else:\n+            value = None\n+        return self._serialize(value, attr, obj, **kwargs)\n+\n+    def deserialize(\n+        self,\n+        value: typing.Any,\n+        attr: str | None = None,\n+        data: typing.Mapping[str, typing.Any] | None = None,\n+        **kwargs,\n+    ):\n         \"\"\"Deserialize ``value``.\n\n         :param value: The value to deserialize.\n@@ -219,7 +356,19 @@ class Field(FieldABC):\n         :raise ValidationError: If an invalid value is passed or if a required value\n             is missing.\n         \"\"\"\n-        pass\n+        # Validate required fields, deserialize, then validate\n+        # deserialized value\n+        self._validate_missing(value)\n+        if value is missing_:\n+            _miss = self.load_default\n+            return _miss() if callable(_miss) else _miss\n+        if self.allow_none and value is None:\n+            return None\n+        output = self._deserialize(value, attr, data, **kwargs)\n+        self._validate(output)\n+        return output\n+\n+    # Methods for concrete classes to override.\n\n     def _bind_to_schema(self, field_name, schema):\n         \"\"\"Update field with values from its parent schema. Called by\n@@ -228,10 +377,15 @@ class Field(FieldABC):\n         :param str field_name: Field name set in schema.\n         :param Schema|Field schema: Parent object.\n         \"\"\"\n-        pass\n-\n-    def _serialize(self, value: typing.Any, attr: (str | None), obj: typing\n-        .Any, **kwargs):\n+        self.parent = self.parent or schema\n+        self.name = self.name or field_name\n+        self.root = self.root or (\n+            self.parent.root if isinstance(self.parent, FieldABC) else self.parent\n+        )\n+\n+    def _serialize(\n+        self, value: typing.Any, attr: str | None, obj: typing.Any, **kwargs\n+    ):\n         \"\"\"Serializes ``value`` to a basic Python datatype. Noop by default.\n         Concrete :class:`Field` classes should implement this method.\n\n@@ -249,10 +403,15 @@ class Field(FieldABC):\n         :param dict kwargs: Field-specific keyword arguments.\n         :return: The serialized value\n         \"\"\"\n-        pass\n-\n-    def _deserialize(self, value: typing.Any, attr: (str | None), data: (\n-        typing.Mapping[str, typing.Any] | None), **kwargs):\n+        return value\n+\n+    def _deserialize(\n+        self,\n+        value: typing.Any,\n+        attr: str | None,\n+        data: typing.Mapping[str, typing.Any] | None,\n+        **kwargs,\n+    ):\n         \"\"\"Deserialize value. Concrete :class:`Field` classes should implement this method.\n\n         :param value: The value to be deserialized.\n@@ -268,12 +427,56 @@ class Field(FieldABC):\n         .. versionchanged:: 3.0.0\n             Added ``**kwargs`` to signature.\n         \"\"\"\n-        pass\n+        return value\n+\n+    # Properties\n\n     @property\n     def context(self):\n         \"\"\"The context dictionary for the parent :class:`Schema`.\"\"\"\n-        pass\n+        return self.parent.context\n+\n+    # the default and missing properties are provided for compatibility and\n+    # emit warnings when they are accessed and set\n+    @property\n+    def default(self):\n+        warnings.warn(\n+            \"The 'default' attribute of fields is deprecated. \"\n+            \"Use 'dump_default' instead.\",\n+            RemovedInMarshmallow4Warning,\n+            stacklevel=2,\n+        )\n+        return self.dump_default\n+\n+    @default.setter\n+    def default(self, value):\n+        warnings.warn(\n+            \"The 'default' attribute of fields is deprecated. \"\n+            \"Use 'dump_default' instead.\",\n+            RemovedInMarshmallow4Warning,\n+            stacklevel=2,\n+        )\n+        self.dump_default = value\n+\n+    @property\n+    def missing(self):\n+        warnings.warn(\n+            \"The 'missing' attribute of fields is deprecated. \"\n+            \"Use 'load_default' instead.\",\n+            RemovedInMarshmallow4Warning,\n+            stacklevel=2,\n+        )\n+        return self.load_default\n+\n+    @missing.setter\n+    def missing(self, value):\n+        warnings.warn(\n+            \"The 'missing' attribute of fields is deprecated. \"\n+            \"Use 'load_default' instead.\",\n+            RemovedInMarshmallow4Warning,\n+            stacklevel=2,\n+        )\n+        self.load_default = value\n\n\n class Raw(Field):\n@@ -325,30 +528,46 @@ class Nested(Field):\n         fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`.\n     :param kwargs: The same keyword arguments that :class:`Field` receives.\n     \"\"\"\n-    default_error_messages = {'type': 'Invalid type.'}\n-\n-    def __init__(self, nested: (SchemaABC | type | str | dict[str, Field |\n-        type] | typing.Callable[[], SchemaABC | type | dict[str, Field |\n-        type]]), *, dump_default: typing.Any=missing_, default: typing.Any=\n-        missing_, only: (types.StrSequenceOrSet | None)=None, exclude:\n-        types.StrSequenceOrSet=(), many: bool=False, unknown: (str | None)=\n-        None, **kwargs):\n+\n+    #: Default error messages.\n+    default_error_messages = {\"type\": \"Invalid type.\"}\n+\n+    def __init__(\n+        self,\n+        nested: SchemaABC\n+        | type\n+        | str\n+        | dict[str, Field | type]\n+        | typing.Callable[[], SchemaABC | type | dict[str, Field | type]],\n+        *,\n+        dump_default: typing.Any = missing_,\n+        default: typing.Any = missing_,\n+        only: types.StrSequenceOrSet | None = None,\n+        exclude: types.StrSequenceOrSet = (),\n+        many: bool = False,\n+        unknown: str | None = None,\n+        **kwargs,\n+    ):\n+        # Raise error if only or exclude is passed as string, not list of strings\n         if only is not None and not is_collection(only):\n-            raise StringNotCollectionError(\n-                '\"only\" should be a collection of strings.')\n+            raise StringNotCollectionError('\"only\" should be a collection of strings.')\n         if not is_collection(exclude):\n             raise StringNotCollectionError(\n-                '\"exclude\" should be a collection of strings.')\n-        if nested == 'self':\n+                '\"exclude\" should be a collection of strings.'\n+            )\n+        if nested == \"self\":\n             warnings.warn(\n-                \"Passing 'self' to `Nested` is deprecated. Use `Nested(lambda: MySchema(...))` instead.\"\n-                , RemovedInMarshmallow4Warning, stacklevel=2)\n+                \"Passing 'self' to `Nested` is deprecated. \"\n+                \"Use `Nested(lambda: MySchema(...))` instead.\",\n+                RemovedInMarshmallow4Warning,\n+                stacklevel=2,\n+            )\n         self.nested = nested\n         self.only = only\n         self.exclude = exclude\n         self.many = many\n         self.unknown = unknown\n-        self._schema = None\n+        self._schema = None  # Cached Schema instance\n         super().__init__(default=default, dump_default=dump_default, **kwargs)\n\n     @property\n@@ -358,7 +577,86 @@ class Nested(Field):\n         .. versionchanged:: 1.0.0\n             Renamed from `serializer` to `schema`.\n         \"\"\"\n-        pass\n+        if not self._schema:\n+            # Inherit context from parent.\n+            context = getattr(self.parent, \"context\", {})\n+            if callable(self.nested) and not isinstance(self.nested, type):\n+                nested = self.nested()\n+            else:\n+                nested = self.nested\n+            if isinstance(nested, dict):\n+                # defer the import of `marshmallow.schema` to avoid circular imports\n+                from marshmallow.schema import Schema\n+\n+                nested = Schema.from_dict(nested)\n+\n+            if isinstance(nested, SchemaABC):\n+                self._schema = copy.copy(nested)\n+                self._schema.context.update(context)\n+                # Respect only and exclude passed from parent and re-initialize fields\n+                set_class = self._schema.set_class\n+                if self.only is not None:\n+                    if self._schema.only is not None:\n+                        original = self._schema.only\n+                    else:  # only=None -&gt; all fields\n+                        original = self._schema.fields.keys()\n+                    self._schema.only = set_class(self.only) &amp; set_class(original)\n+                if self.exclude:\n+                    original = self._schema.exclude\n+                    self._schema.exclude = set_class(self.exclude) | set_class(original)\n+                self._schema._init_fields()\n+            else:\n+                if isinstance(nested, type) and issubclass(nested, SchemaABC):\n+                    schema_class = nested\n+                elif not isinstance(nested, (str, bytes)):\n+                    raise ValueError(\n+                        \"`Nested` fields must be passed a \"\n+                        f\"`Schema`, not {nested.__class__}.\"\n+                    )\n+                elif nested == \"self\":\n+                    schema_class = self.root.__class__\n+                else:\n+                    schema_class = class_registry.get_class(nested)\n+                self._schema = schema_class(\n+                    many=self.many,\n+                    only=self.only,\n+                    exclude=self.exclude,\n+                    context=context,\n+                    load_only=self._nested_normalized_option(\"load_only\"),\n+                    dump_only=self._nested_normalized_option(\"dump_only\"),\n+                )\n+        return self._schema\n+\n+    def _nested_normalized_option(self, option_name: str) -&gt; list[str]:\n+        nested_field = f\"{self.name}.\"\n+        return [\n+            field.split(nested_field, 1)[1]\n+            for field in getattr(self.root, option_name, set())\n+            if field.startswith(nested_field)\n+        ]\n+\n+    def _serialize(self, nested_obj, attr, obj, **kwargs):\n+        # Load up the schema first. This allows a RegistryError to be raised\n+        # if an invalid schema name was passed\n+        schema = self.schema\n+        if nested_obj is None:\n+            return None\n+        many = schema.many or self.many\n+        return schema.dump(nested_obj, many=many)\n+\n+    def _test_collection(self, value):\n+        many = self.schema.many or self.many\n+        if many and not utils.is_collection(value):\n+            raise self.make_error(\"type\", input=value, type=value.__class__.__name__)\n+\n+    def _load(self, value, data, partial=None):\n+        try:\n+            valid_data = self.schema.load(value, unknown=self.unknown, partial=partial)\n+        except ValidationError as error:\n+            raise ValidationError(\n+                error.messages, valid_data=error.valid_data\n+            ) from error\n+        return valid_data\n\n     def _deserialize(self, value, attr, data, partial=None, **kwargs):\n         \"\"\"Same as :meth:`Field._deserialize` with additional ``partial`` argument.\n@@ -369,7 +667,8 @@ class Nested(Field):\n         .. versionchanged:: 3.0.0\n             Add ``partial`` parameter.\n         \"\"\"\n-        pass\n+        self._test_collection(value)\n+        return self._load(value, data, partial=partial)\n\n\n class Pluck(Nested):\n@@ -399,11 +698,36 @@ class Pluck(Nested):\n     :param kwargs: The same keyword arguments that :class:`Nested` receives.\n     \"\"\"\n\n-    def __init__(self, nested: (SchemaABC | type | str | typing.Callable[[],\n-        SchemaABC]), field_name: str, **kwargs):\n+    def __init__(\n+        self,\n+        nested: SchemaABC | type | str | typing.Callable[[], SchemaABC],\n+        field_name: str,\n+        **kwargs,\n+    ):\n         super().__init__(nested, only=(field_name,), **kwargs)\n         self.field_name = field_name\n\n+    @property\n+    def _field_data_key(self):\n+        only_field = self.schema.fields[self.field_name]\n+        return only_field.data_key or self.field_name\n+\n+    def _serialize(self, nested_obj, attr, obj, **kwargs):\n+        ret = super()._serialize(nested_obj, attr, obj, **kwargs)\n+        if ret is None:\n+            return None\n+        if self.many:\n+            return utils.pluck(ret, key=self._field_data_key)\n+        return ret[self._field_data_key]\n+\n+    def _deserialize(self, value, attr, data, partial=None, **kwargs):\n+        self._test_collection(value)\n+        if self.many:\n+            value = [{self._field_data_key: v} for v in value]\n+        else:\n+            value = {self._field_data_key: value}\n+        return self._load(value, data, partial=partial)\n+\n\n class List(Field):\n     \"\"\"A list field, composed with another `Field` class or\n@@ -423,20 +747,53 @@ class List(Field):\n     .. versionchanged:: 3.0.0rc9\n         Does not serialize scalar values to single-item lists.\n     \"\"\"\n-    default_error_messages = {'invalid': 'Not a valid list.'}\n\n-    def __init__(self, cls_or_instance: (Field | type), **kwargs):\n+    #: Default error messages.\n+    default_error_messages = {\"invalid\": \"Not a valid list.\"}\n+\n+    def __init__(self, cls_or_instance: Field | type, **kwargs):\n         super().__init__(**kwargs)\n         try:\n             self.inner = resolve_field_instance(cls_or_instance)\n         except FieldInstanceResolutionError as error:\n             raise ValueError(\n-                'The list elements must be a subclass or instance of marshmallow.base.FieldABC.'\n-                ) from error\n+                \"The list elements must be a subclass or instance of \"\n+                \"marshmallow.base.FieldABC.\"\n+            ) from error\n         if isinstance(self.inner, Nested):\n             self.only = self.inner.only\n             self.exclude = self.inner.exclude\n\n+    def _bind_to_schema(self, field_name, schema):\n+        super()._bind_to_schema(field_name, schema)\n+        self.inner = copy.deepcopy(self.inner)\n+        self.inner._bind_to_schema(field_name, self)\n+        if isinstance(self.inner, Nested):\n+            self.inner.only = self.only\n+            self.inner.exclude = self.exclude\n+\n+    def _serialize(self, value, attr, obj, **kwargs) -&gt; list[typing.Any] | None:\n+        if value is None:\n+            return None\n+        return [self.inner._serialize(each, attr, obj, **kwargs) for each in value]\n+\n+    def _deserialize(self, value, attr, data, **kwargs) -&gt; list[typing.Any]:\n+        if not utils.is_collection(value):\n+            raise self.make_error(\"invalid\")\n+\n+        result = []\n+        errors = {}\n+        for idx, each in enumerate(value):\n+            try:\n+                result.append(self.inner.deserialize(each, **kwargs))\n+            except ValidationError as error:\n+                if error.valid_data is not None:\n+                    result.append(error.valid_data)\n+                errors.update({idx: error.messages})\n+        if errors:\n+            raise ValidationError(errors, valid_data=result)\n+        return result\n+\n\n class Tuple(Field):\n     \"\"\"A tuple field, composed of a fixed number of other `Field` classes or\n@@ -457,40 +814,118 @@ class Tuple(Field):\n\n     .. versionadded:: 3.0.0rc4\n     \"\"\"\n-    default_error_messages = {'invalid': 'Not a valid tuple.'}\n+\n+    #: Default error messages.\n+    default_error_messages = {\"invalid\": \"Not a valid tuple.\"}\n\n     def __init__(self, tuple_fields, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n         if not utils.is_collection(tuple_fields):\n             raise ValueError(\n-                'tuple_fields must be an iterable of Field classes or instances.'\n-                )\n+                \"tuple_fields must be an iterable of Field classes or \" \"instances.\"\n+            )\n+\n         try:\n-            self.tuple_fields = [resolve_field_instance(cls_or_instance) for\n-                cls_or_instance in tuple_fields]\n+            self.tuple_fields = [\n+                resolve_field_instance(cls_or_instance)\n+                for cls_or_instance in tuple_fields\n+            ]\n         except FieldInstanceResolutionError as error:\n             raise ValueError(\n-                'Elements of \"tuple_fields\" must be subclasses or instances of marshmallow.base.FieldABC.'\n-                ) from error\n+                'Elements of \"tuple_fields\" must be subclasses or '\n+                \"instances of marshmallow.base.FieldABC.\"\n+            ) from error\n+\n         self.validate_length = Length(equal=len(self.tuple_fields))\n\n+    def _bind_to_schema(self, field_name, schema):\n+        super()._bind_to_schema(field_name, schema)\n+        new_tuple_fields = []\n+        for field in self.tuple_fields:\n+            field = copy.deepcopy(field)\n+            field._bind_to_schema(field_name, self)\n+            new_tuple_fields.append(field)\n+\n+        self.tuple_fields = new_tuple_fields\n+\n+    def _serialize(self, value, attr, obj, **kwargs) -&gt; tuple | None:\n+        if value is None:\n+            return None\n+\n+        return tuple(\n+            field._serialize(each, attr, obj, **kwargs)\n+            for field, each in zip(self.tuple_fields, value)\n+        )\n+\n+    def _deserialize(self, value, attr, data, **kwargs) -&gt; tuple:\n+        if not utils.is_collection(value):\n+            raise self.make_error(\"invalid\")\n+\n+        self.validate_length(value)\n+\n+        result = []\n+        errors = {}\n+\n+        for idx, (field, each) in enumerate(zip(self.tuple_fields, value)):\n+            try:\n+                result.append(field.deserialize(each, **kwargs))\n+            except ValidationError as error:\n+                if error.valid_data is not None:\n+                    result.append(error.valid_data)\n+                errors.update({idx: error.messages})\n+        if errors:\n+            raise ValidationError(errors, valid_data=result)\n+\n+        return tuple(result)\n+\n\n class String(Field):\n     \"\"\"A string field.\n\n     :param kwargs: The same keyword arguments that :class:`Field` receives.\n     \"\"\"\n-    default_error_messages = {'invalid': 'Not a valid string.',\n-        'invalid_utf8': 'Not a valid utf-8 string.'}\n+\n+    #: Default error messages.\n+    default_error_messages = {\n+        \"invalid\": \"Not a valid string.\",\n+        \"invalid_utf8\": \"Not a valid utf-8 string.\",\n+    }\n+\n+    def _serialize(self, value, attr, obj, **kwargs) -&gt; str | None:\n+        if value is None:\n+            return None\n+        return utils.ensure_text_type(value)\n+\n+    def _deserialize(self, value, attr, data, **kwargs) -&gt; typing.Any:\n+        if not isinstance(value, (str, bytes)):\n+            raise self.make_error(\"invalid\")\n+        try:\n+            return utils.ensure_text_type(value)\n+        except UnicodeDecodeError as error:\n+            raise self.make_error(\"invalid_utf8\") from error\n\n\n class UUID(String):\n     \"\"\"A UUID field.\"\"\"\n-    default_error_messages = {'invalid_uuid': 'Not a valid UUID.'}\n\n-    def _validated(self, value) -&gt;(uuid.UUID | None):\n+    #: Default error messages.\n+    default_error_messages = {\"invalid_uuid\": \"Not a valid UUID.\"}\n+\n+    def _validated(self, value) -&gt; uuid.UUID | None:\n         \"\"\"Format the value or raise a :exc:`ValidationError` if an error occurs.\"\"\"\n-        pass\n+        if value is None:\n+            return None\n+        if isinstance(value, uuid.UUID):\n+            return value\n+        try:\n+            if isinstance(value, bytes) and len(value) == 16:\n+                return uuid.UUID(bytes=value)\n+            return uuid.UUID(value)\n+        except (ValueError, AttributeError, TypeError) as error:\n+            raise self.make_error(\"invalid_uuid\") from error\n+\n+    def _deserialize(self, value, attr, data, **kwargs) -&gt; uuid.UUID | None:\n+        return self._validated(value)\n\n\n class Number(Field):\n@@ -499,25 +934,49 @@ class Number(Field):\n     :param bool as_string: If `True`, format the serialized value as a string.\n     :param kwargs: The same keyword arguments that :class:`Field` receives.\n     \"\"\"\n-    num_type = float\n-    default_error_messages = {'invalid': 'Not a valid number.', 'too_large':\n-        'Number too large.'}\n\n-    def __init__(self, *, as_string: bool=False, **kwargs):\n+    num_type = float  # type: typing.Type\n+\n+    #: Default error messages.\n+    default_error_messages = {\n+        \"invalid\": \"Not a valid number.\",\n+        \"too_large\": \"Number too large.\",\n+    }\n+\n+    def __init__(self, *, as_string: bool = False, **kwargs):\n         self.as_string = as_string\n         super().__init__(**kwargs)\n\n-    def _format_num(self, value) -&gt;typing.Any:\n+    def _format_num(self, value) -&gt; typing.Any:\n         \"\"\"Return the number value for value, given this field's `num_type`.\"\"\"\n-        pass\n+        return self.num_type(value)\n\n-    def _validated(self, value) -&gt;(_T | None):\n+    def _validated(self, value) -&gt; _T | None:\n         \"\"\"Format the value or raise a :exc:`ValidationError` if an error occurs.\"\"\"\n-        pass\n+        if value is None:\n+            return None\n+        # (value is True or value is False) is ~5x faster than isinstance(value, bool)\n+        if value is True or value is False:\n+            raise self.make_error(\"invalid\", input=value)\n+        try:\n+            return self._format_num(value)\n+        except (TypeError, ValueError) as error:\n+            raise self.make_error(\"invalid\", input=value) from error\n+        except OverflowError as error:\n+            raise self.make_error(\"too_large\", input=value) from error\n\n-    def _serialize(self, value, attr, obj, **kwargs) -&gt;(str | _T | None):\n+    def _to_string(self, value) -&gt; str:\n+        return str(value)\n+\n+    def _serialize(self, value, attr, obj, **kwargs) -&gt; str | _T | None:\n         \"\"\"Return a string if `self.as_string=True`, otherwise return this field's `num_type`.\"\"\"\n-        pass\n+        if value is None:\n+            return None\n+        ret = self._format_num(value)  # type: _T\n+        return self._to_string(ret) if self.as_string else ret\n+\n+    def _deserialize(self, value, attr, data, **kwargs) -&gt; _T | None:\n+        return self._validated(value)\n\n\n class Integer(Number):\n@@ -527,13 +986,22 @@ class Integer(Number):\n         Otherwise, any value castable to `int` is valid.\n     :param kwargs: The same keyword arguments that :class:`Number` receives.\n     \"\"\"\n+\n     num_type = int\n-    default_error_messages = {'invalid': 'Not a valid integer.'}\n\n-    def __init__(self, *, strict: bool=False, **kwargs):\n+    #: Default error messages.\n+    default_error_messages = {\"invalid\": \"Not a valid integer.\"}\n+\n+    def __init__(self, *, strict: bool = False, **kwargs):\n         self.strict = strict\n         super().__init__(**kwargs)\n\n+    # override Number\n+    def _validated(self, value):\n+        if self.strict and not isinstance(value, numbers.Integral):\n+            raise self.make_error(\"invalid\", input=value)\n+        return super()._validated(value)\n+\n\n class Float(Number):\n     \"\"\"A double as an IEEE-754 double precision string.\n@@ -543,15 +1011,25 @@ class Float(Number):\n     :param bool as_string: If `True`, format the value as a string.\n     :param kwargs: The same keyword arguments that :class:`Number` receives.\n     \"\"\"\n+\n     num_type = float\n-    default_error_messages = {'special':\n-        'Special numeric values (nan or infinity) are not permitted.'}\n\n-    def __init__(self, *, allow_nan: bool=False, as_string: bool=False, **\n-        kwargs):\n+    #: Default error messages.\n+    default_error_messages = {\n+        \"special\": \"Special numeric values (nan or infinity) are not permitted.\"\n+    }\n+\n+    def __init__(self, *, allow_nan: bool = False, as_string: bool = False, **kwargs):\n         self.allow_nan = allow_nan\n         super().__init__(as_string=as_string, **kwargs)\n\n+    def _validated(self, value):\n+        num = super()._validated(value)\n+        if self.allow_nan is False:\n+            if math.isnan(num) or num == float(\"inf\") or num == float(\"-inf\"):\n+                raise self.make_error(\"special\")\n+        return num\n+\n\n class Decimal(Number):\n     \"\"\"A field that (de)serializes to the Python ``decimal.Decimal`` type.\n@@ -589,18 +1067,54 @@ class Decimal(Number):\n\n     .. versionadded:: 1.2.0\n     \"\"\"\n+\n     num_type = decimal.Decimal\n-    default_error_messages = {'special':\n-        'Special numeric values (nan or infinity) are not permitted.'}\n\n-    def __init__(self, places: (int | None)=None, rounding: (str | None)=\n-        None, *, allow_nan: bool=False, as_string: bool=False, **kwargs):\n-        self.places = decimal.Decimal((0, (1,), -places)\n-            ) if places is not None else None\n+    #: Default error messages.\n+    default_error_messages = {\n+        \"special\": \"Special numeric values (nan or infinity) are not permitted.\"\n+    }\n+\n+    def __init__(\n+        self,\n+        places: int | None = None,\n+        rounding: str | None = None,\n+        *,\n+        allow_nan: bool = False,\n+        as_string: bool = False,\n+        **kwargs,\n+    ):\n+        self.places = (\n+            decimal.Decimal((0, (1,), -places)) if places is not None else None\n+        )\n         self.rounding = rounding\n         self.allow_nan = allow_nan\n         super().__init__(as_string=as_string, **kwargs)\n\n+    # override Number\n+    def _format_num(self, value):\n+        num = decimal.Decimal(str(value))\n+        if self.allow_nan:\n+            if num.is_nan():\n+                return decimal.Decimal(\"NaN\")  # avoid sNaN, -sNaN and -NaN\n+        if self.places is not None and num.is_finite():\n+            num = num.quantize(self.places, rounding=self.rounding)\n+        return num\n+\n+    # override Number\n+    def _validated(self, value):\n+        try:\n+            num = super()._validated(value)\n+        except decimal.InvalidOperation as error:\n+            raise self.make_error(\"invalid\") from error\n+        if not self.allow_nan and (num.is_nan() or num.is_infinite()):\n+            raise self.make_error(\"special\")\n+        return num\n+\n+    # override Number\n+    def _to_string(self, value):\n+        return format(value, \"f\")\n+\n\n class Boolean(Field):\n     \"\"\"A boolean field.\n@@ -612,20 +1126,92 @@ class Boolean(Field):\n         `marshmallow.fields.Boolean.falsy` will be used.\n     :param kwargs: The same keyword arguments that :class:`Field` receives.\n     \"\"\"\n-    truthy = {'t', 'T', 'true', 'True', 'TRUE', 'on', 'On', 'ON', 'y', 'Y',\n-        'yes', 'Yes', 'YES', '1', 1}\n-    falsy = {'f', 'F', 'false', 'False', 'FALSE', 'off', 'Off', 'OFF', 'n',\n-        'N', 'no', 'No', 'NO', '0', 0}\n-    default_error_messages = {'invalid': 'Not a valid boolean.'}\n-\n-    def __init__(self, *, truthy: (set | None)=None, falsy: (set | None)=\n-        None, **kwargs):\n+\n+    #: Default truthy values.\n+    truthy = {\n+        \"t\",\n+        \"T\",\n+        \"true\",\n+        \"True\",\n+        \"TRUE\",\n+        \"on\",\n+        \"On\",\n+        \"ON\",\n+        \"y\",\n+        \"Y\",\n+        \"yes\",\n+        \"Yes\",\n+        \"YES\",\n+        \"1\",\n+        1,\n+        # Equal to 1\n+        # True,\n+    }\n+    #: Default falsy values.\n+    falsy = {\n+        \"f\",\n+        \"F\",\n+        \"false\",\n+        \"False\",\n+        \"FALSE\",\n+        \"off\",\n+        \"Off\",\n+        \"OFF\",\n+        \"n\",\n+        \"N\",\n+        \"no\",\n+        \"No\",\n+        \"NO\",\n+        \"0\",\n+        0,\n+        # Equal to 0\n+        # 0.0,\n+        # False,\n+    }\n+\n+    #: Default error messages.\n+    default_error_messages = {\"invalid\": \"Not a valid boolean.\"}\n+\n+    def __init__(\n+        self,\n+        *,\n+        truthy: set | None = None,\n+        falsy: set | None = None,\n+        **kwargs,\n+    ):\n         super().__init__(**kwargs)\n+\n         if truthy is not None:\n             self.truthy = set(truthy)\n         if falsy is not None:\n             self.falsy = set(falsy)\n\n+    def _serialize(self, value, attr, obj, **kwargs):\n+        if value is None:\n+            return None\n+\n+        try:\n+            if value in self.truthy:\n+                return True\n+            if value in self.falsy:\n+                return False\n+        except TypeError:\n+            pass\n+\n+        return bool(value)\n+\n+    def _deserialize(self, value, attr, data, **kwargs):\n+        if not self.truthy:\n+            return bool(value)\n+        try:\n+            if value in self.truthy:\n+                return True\n+            if value in self.falsy:\n+                return False\n+        except TypeError as error:\n+            raise self.make_error(\"invalid\", input=value) from error\n+        raise self.make_error(\"invalid\", input=value)\n+\n\n class DateTime(Field):\n     \"\"\"A formatted datetime string.\n@@ -642,24 +1228,78 @@ class DateTime(Field):\n     .. versionchanged:: 3.19\n         Add timestamp as a format.\n     \"\"\"\n-    SERIALIZATION_FUNCS = {'iso': utils.isoformat, 'iso8601': utils.\n-        isoformat, 'rfc': utils.rfcformat, 'rfc822': utils.rfcformat,\n-        'timestamp': utils.timestamp, 'timestamp_ms': utils.timestamp_ms}\n-    DESERIALIZATION_FUNCS = {'iso': utils.from_iso_datetime, 'iso8601':\n-        utils.from_iso_datetime, 'rfc': utils.from_rfc, 'rfc822': utils.\n-        from_rfc, 'timestamp': utils.from_timestamp, 'timestamp_ms': utils.\n-        from_timestamp_ms}\n-    DEFAULT_FORMAT = 'iso'\n-    OBJ_TYPE = 'datetime'\n-    SCHEMA_OPTS_VAR_NAME = 'datetimeformat'\n-    default_error_messages = {'invalid': 'Not a valid {obj_type}.',\n-        'invalid_awareness': 'Not a valid {awareness} {obj_type}.',\n-        'format': '\"{input}\" cannot be formatted as a {obj_type}.'}\n-\n-    def __init__(self, format: (str | None)=None, **kwargs) -&gt;None:\n+\n+    SERIALIZATION_FUNCS = {\n+        \"iso\": utils.isoformat,\n+        \"iso8601\": utils.isoformat,\n+        \"rfc\": utils.rfcformat,\n+        \"rfc822\": utils.rfcformat,\n+        \"timestamp\": utils.timestamp,\n+        \"timestamp_ms\": utils.timestamp_ms,\n+    }  # type: typing.Dict[str, typing.Callable[[typing.Any], str | float]]\n+\n+    DESERIALIZATION_FUNCS = {\n+        \"iso\": utils.from_iso_datetime,\n+        \"iso8601\": utils.from_iso_datetime,\n+        \"rfc\": utils.from_rfc,\n+        \"rfc822\": utils.from_rfc,\n+        \"timestamp\": utils.from_timestamp,\n+        \"timestamp_ms\": utils.from_timestamp_ms,\n+    }  # type: typing.Dict[str, typing.Callable[[str], typing.Any]]\n+\n+    DEFAULT_FORMAT = \"iso\"\n+\n+    OBJ_TYPE = \"datetime\"\n+\n+    SCHEMA_OPTS_VAR_NAME = \"datetimeformat\"\n+\n+    #: Default error messages.\n+    default_error_messages = {\n+        \"invalid\": \"Not a valid {obj_type}.\",\n+        \"invalid_awareness\": \"Not a valid {awareness} {obj_type}.\",\n+        \"format\": '\"{input}\" cannot be formatted as a {obj_type}.',\n+    }\n+\n+    def __init__(self, format: str | None = None, **kwargs) -&gt; None:\n         super().__init__(**kwargs)\n+        # Allow this to be None. It may be set later in the ``_serialize``\n+        # or ``_deserialize`` methods. This allows a Schema to dynamically set the\n+        # format, e.g. from a Meta option\n         self.format = format\n\n+    def _bind_to_schema(self, field_name, schema):\n+        super()._bind_to_schema(field_name, schema)\n+        self.format = (\n+            self.format\n+            or getattr(self.root.opts, self.SCHEMA_OPTS_VAR_NAME)\n+            or self.DEFAULT_FORMAT\n+        )\n+\n+    def _serialize(self, value, attr, obj, **kwargs) -&gt; str | float | None:\n+        if value is None:\n+            return None\n+        data_format = self.format or self.DEFAULT_FORMAT\n+        format_func = self.SERIALIZATION_FUNCS.get(data_format)\n+        if format_func:\n+            return format_func(value)\n+        return value.strftime(data_format)\n+\n+    def _deserialize(self, value, attr, data, **kwargs) -&gt; dt.datetime:\n+        data_format = self.format or self.DEFAULT_FORMAT\n+        func = self.DESERIALIZATION_FUNCS.get(data_format)\n+        try:\n+            if func:\n+                return func(value)\n+            return self._make_object_from_format(value, data_format)\n+        except (TypeError, AttributeError, ValueError) as error:\n+            raise self.make_error(\n+                \"invalid\", input=value, obj_type=self.OBJ_TYPE\n+            ) from error\n+\n+    @staticmethod\n+    def _make_object_from_format(value, data_format) -&gt; dt.datetime:\n+        return dt.datetime.strptime(value, data_format)\n+\n\n class NaiveDateTime(DateTime):\n     \"\"\"A formatted naive datetime string.\n@@ -673,13 +1313,31 @@ class NaiveDateTime(DateTime):\n\n     .. versionadded:: 3.0.0rc9\n     \"\"\"\n-    AWARENESS = 'naive'\n\n-    def __init__(self, format: (str | None)=None, *, timezone: (dt.timezone |\n-        None)=None, **kwargs) -&gt;None:\n+    AWARENESS = \"naive\"\n+\n+    def __init__(\n+        self,\n+        format: str | None = None,\n+        *,\n+        timezone: dt.timezone | None = None,\n+        **kwargs,\n+    ) -&gt; None:\n         super().__init__(format=format, **kwargs)\n         self.timezone = timezone\n\n+    def _deserialize(self, value, attr, data, **kwargs) -&gt; dt.datetime:\n+        ret = super()._deserialize(value, attr, data, **kwargs)\n+        if is_aware(ret):\n+            if self.timezone is None:\n+                raise self.make_error(\n+                    \"invalid_awareness\",\n+                    awareness=self.AWARENESS,\n+                    obj_type=self.OBJ_TYPE,\n+                )\n+            ret = ret.astimezone(self.timezone).replace(tzinfo=None)\n+        return ret\n+\n\n class AwareDateTime(DateTime):\n     \"\"\"A formatted aware datetime string.\n@@ -692,13 +1350,31 @@ class AwareDateTime(DateTime):\n\n     .. versionadded:: 3.0.0rc9\n     \"\"\"\n-    AWARENESS = 'aware'\n\n-    def __init__(self, format: (str | None)=None, *, default_timezone: (dt.\n-        tzinfo | None)=None, **kwargs) -&gt;None:\n+    AWARENESS = \"aware\"\n+\n+    def __init__(\n+        self,\n+        format: str | None = None,\n+        *,\n+        default_timezone: dt.tzinfo | None = None,\n+        **kwargs,\n+    ) -&gt; None:\n         super().__init__(format=format, **kwargs)\n         self.default_timezone = default_timezone\n\n+    def _deserialize(self, value, attr, data, **kwargs) -&gt; dt.datetime:\n+        ret = super()._deserialize(value, attr, data, **kwargs)\n+        if not is_aware(ret):\n+            if self.default_timezone is None:\n+                raise self.make_error(\n+                    \"invalid_awareness\",\n+                    awareness=self.AWARENESS,\n+                    obj_type=self.OBJ_TYPE,\n+                )\n+            ret = ret.replace(tzinfo=self.default_timezone)\n+        return ret\n+\n\n class Time(DateTime):\n     \"\"\"A formatted time string.\n@@ -709,13 +1385,20 @@ class Time(DateTime):\n         If `None`, defaults to \"iso\".\n     :param kwargs: The same keyword arguments that :class:`Field` receives.\n     \"\"\"\n-    SERIALIZATION_FUNCS = {'iso': utils.to_iso_time, 'iso8601': utils.\n-        to_iso_time}\n-    DESERIALIZATION_FUNCS = {'iso': utils.from_iso_time, 'iso8601': utils.\n-        from_iso_time}\n-    DEFAULT_FORMAT = 'iso'\n-    OBJ_TYPE = 'time'\n-    SCHEMA_OPTS_VAR_NAME = 'timeformat'\n+\n+    SERIALIZATION_FUNCS = {\"iso\": utils.to_iso_time, \"iso8601\": utils.to_iso_time}\n+\n+    DESERIALIZATION_FUNCS = {\"iso\": utils.from_iso_time, \"iso8601\": utils.from_iso_time}\n+\n+    DEFAULT_FORMAT = \"iso\"\n+\n+    OBJ_TYPE = \"time\"\n+\n+    SCHEMA_OPTS_VAR_NAME = \"timeformat\"\n+\n+    @staticmethod\n+    def _make_object_from_format(value, data_format):\n+        return dt.datetime.strptime(value, data_format).time()\n\n\n class Date(DateTime):\n@@ -725,15 +1408,26 @@ class Date(DateTime):\n         If `None`, defaults to \"iso\".\n     :param kwargs: The same keyword arguments that :class:`Field` receives.\n     \"\"\"\n-    default_error_messages = {'invalid': 'Not a valid date.', 'format':\n-        '\"{input}\" cannot be formatted as a date.'}\n-    SERIALIZATION_FUNCS = {'iso': utils.to_iso_date, 'iso8601': utils.\n-        to_iso_date}\n-    DESERIALIZATION_FUNCS = {'iso': utils.from_iso_date, 'iso8601': utils.\n-        from_iso_date}\n-    DEFAULT_FORMAT = 'iso'\n-    OBJ_TYPE = 'date'\n-    SCHEMA_OPTS_VAR_NAME = 'dateformat'\n+\n+    #: Default error messages.\n+    default_error_messages = {\n+        \"invalid\": \"Not a valid date.\",\n+        \"format\": '\"{input}\" cannot be formatted as a date.',\n+    }\n+\n+    SERIALIZATION_FUNCS = {\"iso\": utils.to_iso_date, \"iso8601\": utils.to_iso_date}\n+\n+    DESERIALIZATION_FUNCS = {\"iso\": utils.from_iso_date, \"iso8601\": utils.from_iso_date}\n+\n+    DEFAULT_FORMAT = \"iso\"\n+\n+    OBJ_TYPE = \"date\"\n+\n+    SCHEMA_OPTS_VAR_NAME = \"dateformat\"\n+\n+    @staticmethod\n+    def _make_object_from_format(value, data_format):\n+        return dt.datetime.strptime(value, data_format).date()\n\n\n class TimeDelta(Field):\n@@ -768,32 +1462,77 @@ class TimeDelta(Field):\n         Allow (de)serialization to `float` through use of a new `serialization_type` parameter.\n         `int` is the default to retain previous behaviour.\n     \"\"\"\n-    DAYS = 'days'\n-    SECONDS = 'seconds'\n-    MICROSECONDS = 'microseconds'\n-    MILLISECONDS = 'milliseconds'\n-    MINUTES = 'minutes'\n-    HOURS = 'hours'\n-    WEEKS = 'weeks'\n-    default_error_messages = {'invalid': 'Not a valid period of time.',\n-        'format': '{input!r} cannot be formatted as a timedelta.'}\n-\n-    def __init__(self, precision: str=SECONDS, serialization_type: type[int |\n-        float]=int, **kwargs):\n+\n+    DAYS = \"days\"\n+    SECONDS = \"seconds\"\n+    MICROSECONDS = \"microseconds\"\n+    MILLISECONDS = \"milliseconds\"\n+    MINUTES = \"minutes\"\n+    HOURS = \"hours\"\n+    WEEKS = \"weeks\"\n+\n+    #: Default error messages.\n+    default_error_messages = {\n+        \"invalid\": \"Not a valid period of time.\",\n+        \"format\": \"{input!r} cannot be formatted as a timedelta.\",\n+    }\n+\n+    def __init__(\n+        self,\n+        precision: str = SECONDS,\n+        serialization_type: type[int | float] = int,\n+        **kwargs,\n+    ):\n         precision = precision.lower()\n-        units = (self.DAYS, self.SECONDS, self.MICROSECONDS, self.\n-            MILLISECONDS, self.MINUTES, self.HOURS, self.WEEKS)\n+        units = (\n+            self.DAYS,\n+            self.SECONDS,\n+            self.MICROSECONDS,\n+            self.MILLISECONDS,\n+            self.MINUTES,\n+            self.HOURS,\n+            self.WEEKS,\n+        )\n+\n         if precision not in units:\n-            msg = 'The precision must be {} or \"{}\".'.format(', '.join([\n-                f'\"{each}\"' for each in units[:-1]]), units[-1])\n+            msg = 'The precision must be {} or \"{}\".'.format(\n+                \", \".join([f'\"{each}\"' for each in units[:-1]]), units[-1]\n+            )\n             raise ValueError(msg)\n+\n         if serialization_type not in (int, float):\n-            raise ValueError(\n-                'The serialization type must be one of int or float')\n+            raise ValueError(\"The serialization type must be one of int or float\")\n+\n         self.precision = precision\n         self.serialization_type = serialization_type\n         super().__init__(**kwargs)\n\n+    def _serialize(self, value, attr, obj, **kwargs):\n+        if value is None:\n+            return None\n+\n+        base_unit = dt.timedelta(**{self.precision: 1})\n+\n+        if self.serialization_type is int:\n+            delta = utils.timedelta_to_microseconds(value)\n+            unit = utils.timedelta_to_microseconds(base_unit)\n+            return delta // unit\n+        assert self.serialization_type is float\n+        return value.total_seconds() / base_unit.total_seconds()\n+\n+    def _deserialize(self, value, attr, data, **kwargs):\n+        try:\n+            value = self.serialization_type(value)\n+        except (TypeError, ValueError) as error:\n+            raise self.make_error(\"invalid\") from error\n+\n+        kwargs = {self.precision: value}\n+\n+        try:\n+            return dt.timedelta(**kwargs)\n+        except OverflowError as error:\n+            raise self.make_error(\"invalid\") from error\n+\n\n class Mapping(Field):\n     \"\"\"An abstract class for objects with key-value pairs.\n@@ -808,11 +1547,18 @@ class Mapping(Field):\n\n     .. versionadded:: 3.0.0rc4\n     \"\"\"\n+\n     mapping_type = dict\n-    default_error_messages = {'invalid': 'Not a valid mapping type.'}\n\n-    def __init__(self, keys: (Field | type | None)=None, values: (Field |\n-        type | None)=None, **kwargs):\n+    #: Default error messages.\n+    default_error_messages = {\"invalid\": \"Not a valid mapping type.\"}\n+\n+    def __init__(\n+        self,\n+        keys: Field | type | None = None,\n+        values: Field | type | None = None,\n+        **kwargs,\n+    ):\n         super().__init__(**kwargs)\n         if keys is None:\n             self.key_field = None\n@@ -821,8 +1567,10 @@ class Mapping(Field):\n                 self.key_field = resolve_field_instance(keys)\n             except FieldInstanceResolutionError as error:\n                 raise ValueError(\n-                    '\"keys\" must be a subclass or instance of marshmallow.base.FieldABC.'\n-                    ) from error\n+                    '\"keys\" must be a subclass or instance of '\n+                    \"marshmallow.base.FieldABC.\"\n+                ) from error\n+\n         if values is None:\n             self.value_field = None\n         else:\n@@ -830,12 +1578,94 @@ class Mapping(Field):\n                 self.value_field = resolve_field_instance(values)\n             except FieldInstanceResolutionError as error:\n                 raise ValueError(\n-                    '\"values\" must be a subclass or instance of marshmallow.base.FieldABC.'\n-                    ) from error\n+                    '\"values\" must be a subclass or instance of '\n+                    \"marshmallow.base.FieldABC.\"\n+                ) from error\n             if isinstance(self.value_field, Nested):\n                 self.only = self.value_field.only\n                 self.exclude = self.value_field.exclude\n\n+    def _bind_to_schema(self, field_name, schema):\n+        super()._bind_to_schema(field_name, schema)\n+        if self.value_field:\n+            self.value_field = copy.deepcopy(self.value_field)\n+            self.value_field._bind_to_schema(field_name, self)\n+        if isinstance(self.value_field, Nested):\n+            self.value_field.only = self.only\n+            self.value_field.exclude = self.exclude\n+        if self.key_field:\n+            self.key_field = copy.deepcopy(self.key_field)\n+            self.key_field._bind_to_schema(field_name, self)\n+\n+    def _serialize(self, value, attr, obj, **kwargs):\n+        if value is None:\n+            return None\n+        if not self.value_field and not self.key_field:\n+            return self.mapping_type(value)\n+\n+        # \u00a0Serialize keys\n+        if self.key_field is None:\n+            keys = {k: k for k in value.keys()}\n+        else:\n+            keys = {\n+                k: self.key_field._serialize(k, None, None, **kwargs)\n+                for k in value.keys()\n+            }\n+\n+        # \u00a0Serialize values\n+        result = self.mapping_type()\n+        if self.value_field is None:\n+            for k, v in value.items():\n+                if k in keys:\n+                    result[keys[k]] = v\n+        else:\n+            for k, v in value.items():\n+                result[keys[k]] = self.value_field._serialize(v, None, None, **kwargs)\n+\n+        return result\n+\n+    def _deserialize(self, value, attr, data, **kwargs):\n+        if not isinstance(value, _Mapping):\n+            raise self.make_error(\"invalid\")\n+        if not self.value_field and not self.key_field:\n+            return self.mapping_type(value)\n+\n+        errors = collections.defaultdict(dict)\n+\n+        # \u00a0Deserialize keys\n+        if self.key_field is None:\n+            keys = {k: k for k in value.keys()}\n+        else:\n+            keys = {}\n+            for key in value.keys():\n+                try:\n+                    keys[key] = self.key_field.deserialize(key, **kwargs)\n+                except ValidationError as error:\n+                    errors[key][\"key\"] = error.messages\n+\n+        # \u00a0Deserialize values\n+        result = self.mapping_type()\n+        if self.value_field is None:\n+            for k, v in value.items():\n+                if k in keys:\n+                    result[keys[k]] = v\n+        else:\n+            for key, val in value.items():\n+                try:\n+                    deser_val = self.value_field.deserialize(val, **kwargs)\n+                except ValidationError as error:\n+                    errors[key][\"value\"] = error.messages\n+                    if error.valid_data is not None and key in keys:\n+                        result[keys[key]] = error.valid_data\n+                else:\n+                    if key in keys:\n+                        result[keys[key]] = deser_val\n+\n+        if errors:\n+            raise ValidationError(errors, valid_data=result)\n+\n+        return result\n+\n\n class Dict(Mapping):\n     \"\"\"A dict field. Supports dicts and dict-like objects. Extends\n@@ -849,6 +1679,7 @@ class Dict(Mapping):\n\n     .. versionadded:: 2.1.0\n     \"\"\"\n+\n     mapping_type = dict\n\n\n@@ -862,18 +1693,32 @@ class Url(String):\n         ``ftp``, and ``ftps`` are allowed.\n     :param kwargs: The same keyword arguments that :class:`String` receives.\n     \"\"\"\n-    default_error_messages = {'invalid': 'Not a valid URL.'}\n\n-    def __init__(self, *, relative: bool=False, absolute: bool=True,\n-        schemes: (types.StrSequenceOrSet | None)=None, require_tld: bool=\n-        True, **kwargs):\n+    #: Default error messages.\n+    default_error_messages = {\"invalid\": \"Not a valid URL.\"}\n+\n+    def __init__(\n+        self,\n+        *,\n+        relative: bool = False,\n+        absolute: bool = True,\n+        schemes: types.StrSequenceOrSet | None = None,\n+        require_tld: bool = True,\n+        **kwargs,\n+    ):\n         super().__init__(**kwargs)\n+\n         self.relative = relative\n         self.absolute = absolute\n         self.require_tld = require_tld\n-        validator = validate.URL(relative=self.relative, absolute=self.\n-            absolute, schemes=schemes, require_tld=self.require_tld, error=\n-            self.error_messages['invalid'])\n+        # Insert validation into self.validators so that multiple errors can be stored.\n+        validator = validate.URL(\n+            relative=self.relative,\n+            absolute=self.absolute,\n+            schemes=schemes,\n+            require_tld=self.require_tld,\n+            error=self.error_messages[\"invalid\"],\n+        )\n         self.validators.insert(0, validator)\n\n\n@@ -883,11 +1728,14 @@ class Email(String):\n     :param args: The same positional arguments that :class:`String` receives.\n     :param kwargs: The same keyword arguments that :class:`String` receives.\n     \"\"\"\n-    default_error_messages = {'invalid': 'Not a valid email address.'}\n\n-    def __init__(self, *args, **kwargs) -&gt;None:\n+    #: Default error messages.\n+    default_error_messages = {\"invalid\": \"Not a valid email address.\"}\n+\n+    def __init__(self, *args, **kwargs) -&gt; None:\n         super().__init__(*args, **kwargs)\n-        validator = validate.Email(error=self.error_messages['invalid'])\n+        # Insert validation into self.validators so that multiple errors can be stored.\n+        validator = validate.Email(error=self.error_messages[\"invalid\"])\n         self.validators.insert(0, validator)\n\n\n@@ -899,20 +1747,43 @@ class IP(Field):\n\n     .. versionadded:: 3.8.0\n     \"\"\"\n-    default_error_messages = {'invalid_ip': 'Not a valid IP address.'}\n-    DESERIALIZATION_CLASS = None\n+\n+    default_error_messages = {\"invalid_ip\": \"Not a valid IP address.\"}\n+\n+    DESERIALIZATION_CLASS = None  # type: typing.Optional[typing.Type]\n\n     def __init__(self, *args, exploded=False, **kwargs):\n         super().__init__(*args, **kwargs)\n         self.exploded = exploded\n\n+    def _serialize(self, value, attr, obj, **kwargs) -&gt; str | None:\n+        if value is None:\n+            return None\n+        if self.exploded:\n+            return value.exploded\n+        return value.compressed\n+\n+    def _deserialize(\n+        self, value, attr, data, **kwargs\n+    ) -&gt; ipaddress.IPv4Address | ipaddress.IPv6Address | None:\n+        if value is None:\n+            return None\n+        try:\n+            return (self.DESERIALIZATION_CLASS or ipaddress.ip_address)(\n+                utils.ensure_text_type(value)\n+            )\n+        except (ValueError, TypeError) as error:\n+            raise self.make_error(\"invalid_ip\") from error\n+\n\n class IPv4(IP):\n     \"\"\"A IPv4 address field.\n\n     .. versionadded:: 3.8.0\n     \"\"\"\n-    default_error_messages = {'invalid_ip': 'Not a valid IPv4 address.'}\n+\n+    default_error_messages = {\"invalid_ip\": \"Not a valid IPv4 address.\"}\n+\n     DESERIALIZATION_CLASS = ipaddress.IPv4Address\n\n\n@@ -921,7 +1792,9 @@ class IPv6(IP):\n\n     .. versionadded:: 3.8.0\n     \"\"\"\n-    default_error_messages = {'invalid_ip': 'Not a valid IPv6 address.'}\n+\n+    default_error_messages = {\"invalid_ip\": \"Not a valid IPv6 address.\"}\n+\n     DESERIALIZATION_CLASS = ipaddress.IPv6Address\n\n\n@@ -938,26 +1811,48 @@ class IPInterface(Field):\n     :param bool exploded: If `True`, serialize ipv6 interface in long form, ie. with groups\n         consisting entirely of zeros included.\n     \"\"\"\n-    default_error_messages = {'invalid_ip_interface':\n-        'Not a valid IP interface.'}\n-    DESERIALIZATION_CLASS = None\n\n-    def __init__(self, *args, exploded: bool=False, **kwargs):\n+    default_error_messages = {\"invalid_ip_interface\": \"Not a valid IP interface.\"}\n+\n+    DESERIALIZATION_CLASS = None  # type: typing.Optional[typing.Type]\n+\n+    def __init__(self, *args, exploded: bool = False, **kwargs):\n         super().__init__(*args, **kwargs)\n         self.exploded = exploded\n\n+    def _serialize(self, value, attr, obj, **kwargs) -&gt; str | None:\n+        if value is None:\n+            return None\n+        if self.exploded:\n+            return value.exploded\n+        return value.compressed\n+\n+    def _deserialize(self, value, attr, data, **kwargs) -&gt; None | (\n+        ipaddress.IPv4Interface | ipaddress.IPv6Interface\n+    ):\n+        if value is None:\n+            return None\n+        try:\n+            return (self.DESERIALIZATION_CLASS or ipaddress.ip_interface)(\n+                utils.ensure_text_type(value)\n+            )\n+        except (ValueError, TypeError) as error:\n+            raise self.make_error(\"invalid_ip_interface\") from error\n+\n\n class IPv4Interface(IPInterface):\n     \"\"\"A IPv4 Network Interface field.\"\"\"\n-    default_error_messages = {'invalid_ip_interface':\n-        'Not a valid IPv4 interface.'}\n+\n+    default_error_messages = {\"invalid_ip_interface\": \"Not a valid IPv4 interface.\"}\n+\n     DESERIALIZATION_CLASS = ipaddress.IPv4Interface\n\n\n class IPv6Interface(IPInterface):\n     \"\"\"A IPv6 Network Interface field.\"\"\"\n-    default_error_messages = {'invalid_ip_interface':\n-        'Not a valid IPv6 interface.'}\n+\n+    default_error_messages = {\"invalid_ip_interface\": \"Not a valid IPv6 interface.\"}\n+\n     DESERIALIZATION_CLASS = ipaddress.IPv6Interface\n\n\n@@ -974,17 +1869,29 @@ class Enum(Field):\n\n     .. versionadded:: 3.18.0\n     \"\"\"\n-    default_error_messages = {'unknown': 'Must be one of: {choices}.'}\n\n-    def __init__(self, enum: type[EnumType], *, by_value: (bool | Field |\n-        type)=False, **kwargs):\n+    default_error_messages = {\n+        \"unknown\": \"Must be one of: {choices}.\",\n+    }\n+\n+    def __init__(\n+        self,\n+        enum: type[EnumType],\n+        *,\n+        by_value: bool | Field | type = False,\n+        **kwargs,\n+    ):\n         super().__init__(**kwargs)\n         self.enum = enum\n         self.by_value = by_value\n+\n+        # Serialization by name\n         if by_value is False:\n             self.field: Field = String()\n-            self.choices_text = ', '.join(str(self.field._serialize(m, None,\n-                None)) for m in enum.__members__)\n+            self.choices_text = \", \".join(\n+                str(self.field._serialize(m, None, None)) for m in enum.__members__\n+            )\n+        # Serialization by value\n         else:\n             if by_value is True:\n                 self.field = Field()\n@@ -993,10 +1900,33 @@ class Enum(Field):\n                     self.field = resolve_field_instance(by_value)\n                 except FieldInstanceResolutionError as error:\n                     raise ValueError(\n-                        '\"by_value\" must be either a bool or a subclass or instance of marshmallow.base.FieldABC.'\n-                        ) from error\n-            self.choices_text = ', '.join(str(self.field._serialize(m.value,\n-                None, None)) for m in enum)\n+                        '\"by_value\" must be either a bool or a subclass or instance of '\n+                        \"marshmallow.base.FieldABC.\"\n+                    ) from error\n+            self.choices_text = \", \".join(\n+                str(self.field._serialize(m.value, None, None)) for m in enum\n+            )\n+\n+    def _serialize(self, value, attr, obj, **kwargs):\n+        if value is None:\n+            return None\n+        if self.by_value:\n+            val = value.value\n+        else:\n+            val = value.name\n+        return self.field._serialize(val, attr, obj, **kwargs)\n+\n+    def _deserialize(self, value, attr, data, **kwargs):\n+        val = self.field._deserialize(value, attr, data, **kwargs)\n+        if self.by_value:\n+            try:\n+                return self.enum(val)\n+            except ValueError as error:\n+                raise self.make_error(\"unknown\", choices=self.choices_text) from error\n+        try:\n+            return getattr(self.enum, val)\n+        except AttributeError as error:\n+            raise self.make_error(\"unknown\", choices=self.choices_text) from error\n\n\n class Method(Field):\n@@ -1019,18 +1949,47 @@ class Method(Field):\n     .. versionchanged:: 3.0.0\n         Removed ``method_name`` parameter.\n     \"\"\"\n+\n     _CHECK_ATTRIBUTE = False\n\n-    def __init__(self, serialize: (str | None)=None, deserialize: (str |\n-        None)=None, **kwargs):\n-        kwargs['dump_only'] = bool(serialize) and not bool(deserialize)\n-        kwargs['load_only'] = bool(deserialize) and not bool(serialize)\n+    def __init__(\n+        self,\n+        serialize: str | None = None,\n+        deserialize: str | None = None,\n+        **kwargs,\n+    ):\n+        # Set dump_only and load_only based on arguments\n+        kwargs[\"dump_only\"] = bool(serialize) and not bool(deserialize)\n+        kwargs[\"load_only\"] = bool(deserialize) and not bool(serialize)\n         super().__init__(**kwargs)\n         self.serialize_method_name = serialize\n         self.deserialize_method_name = deserialize\n         self._serialize_method = None\n         self._deserialize_method = None\n\n+    def _bind_to_schema(self, field_name, schema):\n+        if self.serialize_method_name:\n+            self._serialize_method = utils.callable_or_raise(\n+                getattr(schema, self.serialize_method_name)\n+            )\n+\n+        if self.deserialize_method_name:\n+            self._deserialize_method = utils.callable_or_raise(\n+                getattr(schema, self.deserialize_method_name)\n+            )\n+\n+        super()._bind_to_schema(field_name, schema)\n+\n+    def _serialize(self, value, attr, obj, **kwargs):\n+        if self._serialize_method is not None:\n+            return self._serialize_method(obj)\n+        return missing_\n+\n+    def _deserialize(self, value, attr, data, **kwargs):\n+        if self._deserialize_method is not None:\n+            return self._deserialize_method(value)\n+        return value\n+\n\n class Function(Field):\n     \"\"\"A field that takes the value returned by a function.\n@@ -1054,18 +2013,45 @@ class Function(Field):\n     .. versionchanged:: 3.0.0a1\n         Removed ``func`` parameter.\n     \"\"\"\n+\n     _CHECK_ATTRIBUTE = False\n\n-    def __init__(self, serialize: (None | typing.Callable[[typing.Any],\n-        typing.Any] | typing.Callable[[typing.Any, dict], typing.Any])=None,\n-        deserialize: (None | typing.Callable[[typing.Any], typing.Any] |\n-        typing.Callable[[typing.Any, dict], typing.Any])=None, **kwargs):\n-        kwargs['dump_only'] = bool(serialize) and not bool(deserialize)\n-        kwargs['load_only'] = bool(deserialize) and not bool(serialize)\n+    def __init__(\n+        self,\n+        serialize: (\n+            None\n+            | typing.Callable[[typing.Any], typing.Any]\n+            | typing.Callable[[typing.Any, dict], typing.Any]\n+        ) = None,\n+        deserialize: (\n+            None\n+            | typing.Callable[[typing.Any], typing.Any]\n+            | typing.Callable[[typing.Any, dict], typing.Any]\n+        ) = None,\n+        **kwargs,\n+    ):\n+        # Set dump_only and load_only based on arguments\n+        kwargs[\"dump_only\"] = bool(serialize) and not bool(deserialize)\n+        kwargs[\"load_only\"] = bool(deserialize) and not bool(serialize)\n         super().__init__(**kwargs)\n         self.serialize_func = serialize and utils.callable_or_raise(serialize)\n-        self.deserialize_func = deserialize and utils.callable_or_raise(\n-            deserialize)\n+        self.deserialize_func = deserialize and utils.callable_or_raise(deserialize)\n+\n+    def _serialize(self, value, attr, obj, **kwargs):\n+        return self._call_or_raise(self.serialize_func, obj, attr)\n+\n+    def _deserialize(self, value, attr, data, **kwargs):\n+        if self.deserialize_func:\n+            return self._call_or_raise(self.deserialize_func, value, attr)\n+        return value\n+\n+    def _call_or_raise(self, func, value, attr):\n+        if len(utils.get_func_args(func)) &gt; 1:\n+            if self.parent.context is None:\n+                msg = f\"No context available for Function field {attr!r}\"\n+                raise ValidationError(msg)\n+            return func(value, self.parent.context)\n+        return func(value)\n\n\n class Constant(Field):\n@@ -1077,6 +2063,7 @@ class Constant(Field):\n\n     .. versionadded:: 2.0.0\n     \"\"\"\n+\n     _CHECK_ATTRIBUTE = False\n\n     def __init__(self, constant: typing.Any, **kwargs):\n@@ -1085,6 +2072,12 @@ class Constant(Field):\n         self.load_default = constant\n         self.dump_default = constant\n\n+    def _serialize(self, value, *args, **kwargs):\n+        return self.constant\n+\n+    def _deserialize(self, value, *args, **kwargs):\n+        return self.constant\n+\n\n class Inferred(Field):\n     \"\"\"A field that infers how to serialize, based on the value type.\n@@ -1097,9 +2090,24 @@ class Inferred(Field):\n\n     def __init__(self):\n         super().__init__()\n+        # We memoize the fields to avoid creating and binding new fields\n+        # every time on serialization.\n         self._field_cache = {}\n\n+    def _serialize(self, value, attr, obj, **kwargs):\n+        field_cls = self.root.TYPE_MAPPING.get(type(value))\n+        if field_cls is None:\n+            field = super()\n+        else:\n+            field = self._field_cache.get(field_cls)\n+            if field is None:\n+                field = field_cls()\n+                field._bind_to_schema(self.name, self.parent)\n+                self._field_cache[field_cls] = field\n+        return field._serialize(value, attr, obj, **kwargs)\n+\n\n+# Aliases\n URL = Url\n Str = String\n Bool = Boolean\ndiff --git a/src/marshmallow/orderedset.py b/src/marshmallow/orderedset.py\nindex 35553ec..7ce0723 100644\n--- a/src/marshmallow/orderedset.py\n+++ b/src/marshmallow/orderedset.py\n@@ -1,12 +1,33 @@\n+# OrderedSet\n+# Copyright (c) 2009 Raymond Hettinger\n+#\n+# Permission is hereby granted, free of charge, to any person\n+# obtaining a copy of this software and associated documentation files\n+# (the \"Software\"), to deal in the Software without restriction,\n+# including without limitation the rights to use, copy, modify, merge,\n+# publish, distribute, sublicense, and/or sell copies of the Software,\n+# and to permit persons to whom the Software is furnished to do so,\n+# subject to the following conditions:\n+#\n+#     The above copyright notice and this permission notice shall be\n+#     included in all copies or substantial portions of the Software.\n+#\n+#     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n+#     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n+#     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n+#     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n+#     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n+#     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n+#     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n+#     OTHER DEALINGS IN THE SOFTWARE.\n from collections.abc import MutableSet\n\n\n class OrderedSet(MutableSet):\n-\n     def __init__(self, iterable=None):\n         self.end = end = []\n-        end += [None, end, end]\n-        self.map = {}\n+        end += [None, end, end]  # sentinel node for doubly linked list\n+        self.map = {}  # key --&gt; [key, prev, next]\n         if iterable is not None:\n             self |= iterable\n\n@@ -16,6 +37,18 @@ class OrderedSet(MutableSet):\n     def __contains__(self, key):\n         return key in self.map\n\n+    def add(self, key):\n+        if key not in self.map:\n+            end = self.end\n+            curr = end[1]\n+            curr[2] = end[1] = self.map[key] = [key, curr, end]\n+\n+    def discard(self, key):\n+        if key in self.map:\n+            key, prev, next = self.map.pop(key)\n+            prev[2] = next\n+            next[1] = prev\n+\n     def __iter__(self):\n         end = self.end\n         curr = end[2]\n@@ -30,10 +63,17 @@ class OrderedSet(MutableSet):\n             yield curr[0]\n             curr = curr[1]\n\n+    def pop(self, last=True):\n+        if not self:\n+            raise KeyError(\"set is empty\")\n+        key = self.end[1][0] if last else self.end[2][0]\n+        self.discard(key)\n+        return key\n+\n     def __repr__(self):\n         if not self:\n-            return f'{self.__class__.__name__}()'\n-        return f'{self.__class__.__name__}({list(self)!r})'\n+            return f\"{self.__class__.__name__}()\"\n+        return f\"{self.__class__.__name__}({list(self)!r})\"\n\n     def __eq__(self, other):\n         if isinstance(other, OrderedSet):\n@@ -41,9 +81,9 @@ class OrderedSet(MutableSet):\n         return set(self) == set(other)\n\n\n-if __name__ == '__main__':\n-    s = OrderedSet('abracadaba')\n-    t = OrderedSet('simsalabim')\n+if __name__ == \"__main__\":\n+    s = OrderedSet(\"abracadaba\")\n+    t = OrderedSet(\"simsalabim\")\n     print(s | t)\n     print(s &amp; t)\n     print(s - t)\ndiff --git a/src/marshmallow/schema.py b/src/marshmallow/schema.py\nindex 1e6eabf..23b43c4 100644\n--- a/src/marshmallow/schema.py\n+++ b/src/marshmallow/schema.py\n@@ -1,5 +1,7 @@\n \"\"\"The :class:`Schema` class, including its metaclass and options (class Meta).\"\"\"\n+\n from __future__ import annotations\n+\n import copy\n import datetime as dt\n import decimal\n@@ -11,15 +13,34 @@ import warnings\n from abc import ABCMeta\n from collections import OrderedDict, defaultdict\n from collections.abc import Mapping\n+\n from marshmallow import base, class_registry, types\n from marshmallow import fields as ma_fields\n-from marshmallow.decorators import POST_DUMP, POST_LOAD, PRE_DUMP, PRE_LOAD, VALIDATES, VALIDATES_SCHEMA\n+from marshmallow.decorators import (\n+    POST_DUMP,\n+    POST_LOAD,\n+    PRE_DUMP,\n+    PRE_LOAD,\n+    VALIDATES,\n+    VALIDATES_SCHEMA,\n+)\n from marshmallow.error_store import ErrorStore\n from marshmallow.exceptions import StringNotCollectionError, ValidationError\n from marshmallow.orderedset import OrderedSet\n-from marshmallow.utils import EXCLUDE, INCLUDE, RAISE, get_value, is_collection, is_instance_or_subclass, missing, set_value, validate_unknown_parameter_value\n+from marshmallow.utils import (\n+    EXCLUDE,\n+    INCLUDE,\n+    RAISE,\n+    get_value,\n+    is_collection,\n+    is_instance_or_subclass,\n+    missing,\n+    set_value,\n+    validate_unknown_parameter_value,\n+)\n from marshmallow.warnings import RemovedInMarshmallow4Warning\n-_T = typing.TypeVar('_T')\n+\n+_T = typing.TypeVar(\"_T\")\n\n\n def _get_fields(attrs):\n@@ -27,9 +48,15 @@ def _get_fields(attrs):\n\n     :param attrs: Mapping of class attributes\n     \"\"\"\n-    pass\n+    return [\n+        (field_name, field_value)\n+        for field_name, field_value in attrs.items()\n+        if is_instance_or_subclass(field_value, base.FieldABC)\n+    ]\n\n\n+# This function allows Schemas to inherit from non-Schema classes and ensures\n+#   inheritance according to the MRO\n def _get_fields_by_mro(klass):\n     \"\"\"Collect fields from a class, following its method resolution order. The\n     class itself is excluded from the search; only its parents are checked. Get\n@@ -37,7 +64,17 @@ def _get_fields_by_mro(klass):\n\n     :param type klass: Class whose fields to retrieve\n     \"\"\"\n-    pass\n+    mro = inspect.getmro(klass)\n+    # Loop over mro in reverse to maintain correct order of fields\n+    return sum(\n+        (\n+            _get_fields(\n+                getattr(base, \"_declared_fields\", base.__dict__),\n+            )\n+            for base in mro[:0:-1]\n+        ),\n+        [],\n+    )\n\n\n class SchemaMeta(ABCMeta):\n@@ -48,31 +85,51 @@ class SchemaMeta(ABCMeta):\n     \"\"\"\n\n     def __new__(mcs, name, bases, attrs):\n-        meta = attrs.get('Meta')\n-        ordered = getattr(meta, 'ordered', False)\n+        meta = attrs.get(\"Meta\")\n+        ordered = getattr(meta, \"ordered\", False)\n         if not ordered:\n+            # Inherit 'ordered' option\n+            # Warning: We loop through bases instead of MRO because we don't\n+            # yet have access to the class object\n+            # (i.e. can't call super before we have fields)\n             for base_ in bases:\n-                if hasattr(base_, 'Meta') and hasattr(base_.Meta, 'ordered'):\n+                if hasattr(base_, \"Meta\") and hasattr(base_.Meta, \"ordered\"):\n                     ordered = base_.Meta.ordered\n                     break\n             else:\n                 ordered = False\n         cls_fields = _get_fields(attrs)\n+        # Remove fields from list of class attributes to avoid shadowing\n+        # Schema attributes/methods in case of name conflict\n         for field_name, _ in cls_fields:\n             del attrs[field_name]\n         klass = super().__new__(mcs, name, bases, attrs)\n         inherited_fields = _get_fields_by_mro(klass)\n+\n         meta = klass.Meta\n+        # Set klass.opts in __new__ rather than __init__ so that it is accessible in\n+        # get_declared_fields\n         klass.opts = klass.OPTIONS_CLASS(meta, ordered=ordered)\n+        # Add fields specified in the `include` class Meta option\n         cls_fields += list(klass.opts.include.items())\n-        klass._declared_fields = mcs.get_declared_fields(klass=klass,\n-            cls_fields=cls_fields, inherited_fields=inherited_fields,\n-            dict_cls=dict)\n+\n+        # Assign _declared_fields on class\n+        klass._declared_fields = mcs.get_declared_fields(\n+            klass=klass,\n+            cls_fields=cls_fields,\n+            inherited_fields=inherited_fields,\n+            dict_cls=dict,\n+        )\n         return klass\n\n     @classmethod\n-    def get_declared_fields(mcs, klass: type, cls_fields: list,\n-        inherited_fields: list, dict_cls: type=dict):\n+    def get_declared_fields(\n+        mcs,\n+        klass: type,\n+        cls_fields: list,\n+        inherited_fields: list,\n+        dict_cls: type = dict,\n+    ):\n         \"\"\"Returns a dictionary of field_name =&gt; `Field` pairs declared on the class.\n         This is exposed mainly so that plugins can add additional fields, e.g. fields\n         computed from class Meta options.\n@@ -83,7 +140,7 @@ class SchemaMeta(ABCMeta):\n         :param inherited_fields: Inherited fields.\n         :param dict_cls: dict-like class to use for dict output Default to ``dict``.\n         \"\"\"\n-        pass\n+        return dict_cls(inherited_fields + cls_fields)\n\n     def __init__(cls, name, bases, attrs):\n         super().__init__(name, bases, attrs)\n@@ -91,51 +148,84 @@ class SchemaMeta(ABCMeta):\n             class_registry.register(name, cls)\n         cls._hooks = cls.resolve_hooks()\n\n-    def resolve_hooks(cls) -&gt;dict[types.Tag, list[str]]:\n+    def resolve_hooks(cls) -&gt; dict[types.Tag, list[str]]:\n         \"\"\"Add in the decorated processors\n\n         By doing this after constructing the class, we let standard inheritance\n         do all the hard work.\n         \"\"\"\n-        pass\n+        mro = inspect.getmro(cls)\n+\n+        hooks = defaultdict(list)  # type: typing.Dict[types.Tag, typing.List[str]]\n+\n+        for attr_name in dir(cls):\n+            # Need to look up the actual descriptor, not whatever might be\n+            # bound to the class. This needs to come from the __dict__ of the\n+            # declaring class.\n+            for parent in mro:\n+                try:\n+                    attr = parent.__dict__[attr_name]\n+                except KeyError:\n+                    continue\n+                else:\n+                    break\n+            else:\n+                # In case we didn't find the attribute and didn't break above.\n+                # We should never hit this - it's just here for completeness\n+                # to exclude the possibility of attr being undefined.\n+                continue\n+\n+            try:\n+                hook_config = attr.__marshmallow_hook__\n+            except AttributeError:\n+                pass\n+            else:\n+                for key in hook_config.keys():\n+                    # Use name here so we can get the bound method later, in\n+                    # case the processor was a descriptor or something.\n+                    hooks[key].append(attr_name)\n+\n+        return hooks\n\n\n class SchemaOpts:\n     \"\"\"class Meta options for the :class:`Schema`. Defines defaults.\"\"\"\n\n-    def __init__(self, meta, ordered: bool=False):\n-        self.fields = getattr(meta, 'fields', ())\n+    def __init__(self, meta, ordered: bool = False):\n+        self.fields = getattr(meta, \"fields\", ())\n         if not isinstance(self.fields, (list, tuple)):\n-            raise ValueError('`fields` option must be a list or tuple.')\n-        self.additional = getattr(meta, 'additional', ())\n+            raise ValueError(\"`fields` option must be a list or tuple.\")\n+        self.additional = getattr(meta, \"additional\", ())\n         if not isinstance(self.additional, (list, tuple)):\n-            raise ValueError('`additional` option must be a list or tuple.')\n+            raise ValueError(\"`additional` option must be a list or tuple.\")\n         if self.fields and self.additional:\n             raise ValueError(\n-                'Cannot set both `fields` and `additional` options for the same Schema.'\n-                )\n-        self.exclude = getattr(meta, 'exclude', ())\n+                \"Cannot set both `fields` and `additional` options\"\n+                \" for the same Schema.\"\n+            )\n+        self.exclude = getattr(meta, \"exclude\", ())\n         if not isinstance(self.exclude, (list, tuple)):\n-            raise ValueError('`exclude` must be a list or tuple.')\n-        self.dateformat = getattr(meta, 'dateformat', None)\n-        self.datetimeformat = getattr(meta, 'datetimeformat', None)\n-        self.timeformat = getattr(meta, 'timeformat', None)\n-        if hasattr(meta, 'json_module'):\n+            raise ValueError(\"`exclude` must be a list or tuple.\")\n+        self.dateformat = getattr(meta, \"dateformat\", None)\n+        self.datetimeformat = getattr(meta, \"datetimeformat\", None)\n+        self.timeformat = getattr(meta, \"timeformat\", None)\n+        if hasattr(meta, \"json_module\"):\n             warnings.warn(\n-                'The json_module class Meta option is deprecated. Use render_module instead.'\n-                , RemovedInMarshmallow4Warning, stacklevel=2)\n-            render_module = getattr(meta, 'json_module', json)\n+                \"The json_module class Meta option is deprecated. Use render_module instead.\",\n+                RemovedInMarshmallow4Warning,\n+                stacklevel=2,\n+            )\n+            render_module = getattr(meta, \"json_module\", json)\n         else:\n             render_module = json\n-        self.render_module = getattr(meta, 'render_module', render_module)\n-        self.ordered = getattr(meta, 'ordered', ordered)\n-        self.index_errors = getattr(meta, 'index_errors', True)\n-        self.include = getattr(meta, 'include', {})\n-        self.load_only = getattr(meta, 'load_only', ())\n-        self.dump_only = getattr(meta, 'dump_only', ())\n-        self.unknown = validate_unknown_parameter_value(getattr(meta,\n-            'unknown', RAISE))\n-        self.register = getattr(meta, 'register', True)\n+        self.render_module = getattr(meta, \"render_module\", render_module)\n+        self.ordered = getattr(meta, \"ordered\", ordered)\n+        self.index_errors = getattr(meta, \"index_errors\", True)\n+        self.include = getattr(meta, \"include\", {})\n+        self.load_only = getattr(meta, \"load_only\", ())\n+        self.dump_only = getattr(meta, \"dump_only\", ())\n+        self.unknown = validate_unknown_parameter_value(getattr(meta, \"unknown\", RAISE))\n+        self.register = getattr(meta, \"register\", True)\n\n\n class Schema(base.SchemaABC, metaclass=SchemaMeta):\n@@ -197,21 +287,39 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n         `__accessor__` and `__error_handler__` are deprecated. Implement the\n         `handle_error` and `get_attribute` methods instead.\n     \"\"\"\n-    TYPE_MAPPING = {str: ma_fields.String, bytes: ma_fields.String, dt.\n-        datetime: ma_fields.DateTime, float: ma_fields.Float, bool:\n-        ma_fields.Boolean, tuple: ma_fields.Raw, list: ma_fields.Raw, set:\n-        ma_fields.Raw, int: ma_fields.Integer, uuid.UUID: ma_fields.UUID,\n-        dt.time: ma_fields.Time, dt.date: ma_fields.Date, dt.timedelta:\n-        ma_fields.TimeDelta, decimal.Decimal: ma_fields.Decimal}\n-    error_messages = {}\n-    _default_error_messages = {'type': 'Invalid input type.', 'unknown':\n-        'Unknown field.'}\n-    OPTIONS_CLASS = SchemaOpts\n+\n+    TYPE_MAPPING = {\n+        str: ma_fields.String,\n+        bytes: ma_fields.String,\n+        dt.datetime: ma_fields.DateTime,\n+        float: ma_fields.Float,\n+        bool: ma_fields.Boolean,\n+        tuple: ma_fields.Raw,\n+        list: ma_fields.Raw,\n+        set: ma_fields.Raw,\n+        int: ma_fields.Integer,\n+        uuid.UUID: ma_fields.UUID,\n+        dt.time: ma_fields.Time,\n+        dt.date: ma_fields.Date,\n+        dt.timedelta: ma_fields.TimeDelta,\n+        decimal.Decimal: ma_fields.Decimal,\n+    }  # type: typing.Dict[type, typing.Type[ma_fields.Field]]\n+    #: Overrides for default schema-level error messages\n+    error_messages = {}  # type: typing.Dict[str, str]\n+\n+    _default_error_messages = {\n+        \"type\": \"Invalid input type.\",\n+        \"unknown\": \"Unknown field.\",\n+    }  # type: typing.Dict[str, str]\n+\n+    OPTIONS_CLASS = SchemaOpts  # type: type\n+\n     set_class = OrderedSet\n-    opts = None\n-    _declared_fields = {}\n-    _hooks = {}\n\n+    # These get set by SchemaMeta\n+    opts = None  # type: SchemaOpts\n+    _declared_fields = {}  # type: typing.Dict[str, ma_fields.Field]\n+    _hooks = {}  # type: typing.Dict[types.Tag, typing.List[str]]\n\n     class Meta:\n         \"\"\"Options object for a Schema.\n@@ -252,47 +360,67 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n             usage is critical. Defaults to `True`.\n         \"\"\"\n\n-    def __init__(self, *, only: (types.StrSequenceOrSet | None)=None,\n-        exclude: types.StrSequenceOrSet=(), many: bool=False, context: (\n-        dict | None)=None, load_only: types.StrSequenceOrSet=(), dump_only:\n-        types.StrSequenceOrSet=(), partial: (bool | types.StrSequenceOrSet |\n-        None)=None, unknown: (str | None)=None):\n+    def __init__(\n+        self,\n+        *,\n+        only: types.StrSequenceOrSet | None = None,\n+        exclude: types.StrSequenceOrSet = (),\n+        many: bool = False,\n+        context: dict | None = None,\n+        load_only: types.StrSequenceOrSet = (),\n+        dump_only: types.StrSequenceOrSet = (),\n+        partial: bool | types.StrSequenceOrSet | None = None,\n+        unknown: str | None = None,\n+    ):\n+        # Raise error if only or exclude is passed as string, not list of strings\n         if only is not None and not is_collection(only):\n-            raise StringNotCollectionError('\"only\" should be a list of strings'\n-                )\n+            raise StringNotCollectionError('\"only\" should be a list of strings')\n         if not is_collection(exclude):\n-            raise StringNotCollectionError(\n-                '\"exclude\" should be a list of strings')\n+            raise StringNotCollectionError('\"exclude\" should be a list of strings')\n+        # copy declared fields from metaclass\n         self.declared_fields = copy.deepcopy(self._declared_fields)\n         self.many = many\n         self.only = only\n         self.exclude: set[typing.Any] | typing.MutableSet[typing.Any] = set(\n-            self.opts.exclude) | set(exclude)\n+            self.opts.exclude\n+        ) | set(exclude)\n         self.ordered = self.opts.ordered\n         self.load_only = set(load_only) or set(self.opts.load_only)\n         self.dump_only = set(dump_only) or set(self.opts.dump_only)\n         self.partial = partial\n-        self.unknown = (self.opts.unknown if unknown is None else\n-            validate_unknown_parameter_value(unknown))\n+        self.unknown = (\n+            self.opts.unknown\n+            if unknown is None\n+            else validate_unknown_parameter_value(unknown)\n+        )\n         self.context = context or {}\n         self._normalize_nested_options()\n-        self.fields = {}\n-        self.load_fields = {}\n-        self.dump_fields = {}\n+        #: Dictionary mapping field_names -&gt; :class:`Field` objects\n+        self.fields = {}  # type: typing.Dict[str, ma_fields.Field]\n+        self.load_fields = {}  # type: typing.Dict[str, ma_fields.Field]\n+        self.dump_fields = {}  # type: typing.Dict[str, ma_fields.Field]\n         self._init_fields()\n         messages = {}\n         messages.update(self._default_error_messages)\n         for cls in reversed(self.__class__.__mro__):\n-            messages.update(getattr(cls, 'error_messages', {}))\n+            messages.update(getattr(cls, \"error_messages\", {}))\n         messages.update(self.error_messages or {})\n         self.error_messages = messages\n\n-    def __repr__(self) -&gt;str:\n-        return f'&lt;{self.__class__.__name__}(many={self.many})&gt;'\n+    def __repr__(self) -&gt; str:\n+        return f\"&lt;{self.__class__.__name__}(many={self.many})&gt;\"\n+\n+    @property\n+    def dict_class(self) -&gt; type:\n+        return OrderedDict if self.ordered else dict\n\n     @classmethod\n-    def from_dict(cls, fields: dict[str, ma_fields.Field | type], *, name:\n-        str='GeneratedSchema') -&gt;type:\n+    def from_dict(\n+        cls,\n+        fields: dict[str, ma_fields.Field | type],\n+        *,\n+        name: str = \"GeneratedSchema\",\n+    ) -&gt; type:\n         \"\"\"Generate a `Schema` class given a dictionary of fields.\n\n         .. code-block:: python\n@@ -311,10 +439,18 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n\n         .. versionadded:: 3.0.0\n         \"\"\"\n-        pass\n-\n-    def handle_error(self, error: ValidationError, data: typing.Any, *,\n-        many: bool, **kwargs):\n+        attrs = fields.copy()\n+        attrs[\"Meta\"] = type(\n+            \"GeneratedMeta\", (getattr(cls, \"Meta\", object),), {\"register\": False}\n+        )\n+        schema_cls = type(name, (cls,), attrs)\n+        return schema_cls\n+\n+    ##### Override-able methods #####\n+\n+    def handle_error(\n+        self, error: ValidationError, data: typing.Any, *, many: bool, **kwargs\n+    ):\n         \"\"\"Custom error handler function for the schema.\n\n         :param error: The `ValidationError` raised during (de)serialization.\n@@ -337,11 +473,12 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n         .. versionchanged:: 3.0.0a1\n             Changed position of ``obj`` and ``attr``.\n         \"\"\"\n-        pass\n+        return get_value(obj, attr, default)\n+\n+    ##### Serialization/Deserialization API #####\n\n     @staticmethod\n-    def _call_and_store(getter_func, data, *, field_name, error_store,\n-        index=None):\n+    def _call_and_store(getter_func, data, *, field_name, error_store, index=None):\n         \"\"\"Call ``getter_func`` with ``data`` as its argument, and store any `ValidationErrors`.\n\n         :param callable getter_func: Function for getting the serialized/deserialized\n@@ -351,9 +488,16 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n         :param int index: Index of the item being validated, if validating a collection,\n             otherwise `None`.\n         \"\"\"\n-        pass\n-\n-    def _serialize(self, obj: (_T | typing.Iterable[_T]), *, many: bool=False):\n+        try:\n+            value = getter_func(data)\n+        except ValidationError as error:\n+            error_store.store_error(error.messages, field_name, index=index)\n+            # When a Nested field fails validation, the marshalled data is stored\n+            # on the ValidationError's valid_data attribute\n+            return error.valid_data or missing\n+        return value\n+\n+    def _serialize(self, obj: _T | typing.Iterable[_T], *, many: bool = False):\n         \"\"\"Serialize ``obj``.\n\n         :param obj: The object(s) to serialize.\n@@ -363,9 +507,21 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n         .. versionchanged:: 1.0.0\n             Renamed from ``marshal``.\n         \"\"\"\n-        pass\n-\n-    def dump(self, obj: typing.Any, *, many: (bool | None)=None):\n+        if many and obj is not None:\n+            return [\n+                self._serialize(d, many=False)\n+                for d in typing.cast(typing.Iterable[_T], obj)\n+            ]\n+        ret = self.dict_class()\n+        for attr_name, field_obj in self.dump_fields.items():\n+            value = field_obj.serialize(attr_name, obj, accessor=self.get_attribute)\n+            if value is missing:\n+                continue\n+            key = field_obj.data_key if field_obj.data_key is not None else attr_name\n+            ret[key] = value\n+        return ret\n+\n+    def dump(self, obj: typing.Any, *, many: bool | None = None):\n         \"\"\"Serialize an object to native Python data types according to this\n         Schema's fields.\n\n@@ -382,10 +538,24 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n         .. versionchanged:: 3.0.0rc9\n             Validation no longer occurs upon serialization.\n         \"\"\"\n-        pass\n+        many = self.many if many is None else bool(many)\n+        if self._has_processors(PRE_DUMP):\n+            processed_obj = self._invoke_dump_processors(\n+                PRE_DUMP, obj, many=many, original_data=obj\n+            )\n+        else:\n+            processed_obj = obj\n\n-    def dumps(self, obj: typing.Any, *args, many: (bool | None)=None, **kwargs\n-        ):\n+        result = self._serialize(processed_obj, many=many)\n+\n+        if self._has_processors(POST_DUMP):\n+            result = self._invoke_dump_processors(\n+                POST_DUMP, result, many=many, original_data=obj\n+            )\n+\n+        return result\n+\n+    def dumps(self, obj: typing.Any, *args, many: bool | None = None, **kwargs):\n         \"\"\"Same as :meth:`dump`, except return a JSON-encoded string.\n\n         :param obj: The object to serialize.\n@@ -399,12 +569,22 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n             A :exc:`ValidationError &lt;marshmallow.exceptions.ValidationError&gt;` is raised\n             if ``obj`` is invalid.\n         \"\"\"\n-        pass\n-\n-    def _deserialize(self, data: (typing.Mapping[str, typing.Any] | typing.\n-        Iterable[typing.Mapping[str, typing.Any]]), *, error_store:\n-        ErrorStore, many: bool=False, partial=None, unknown=RAISE, index=None\n-        ) -&gt;(_T | list[_T]):\n+        serialized = self.dump(obj, many=many)\n+        return self.opts.render_module.dumps(serialized, *args, **kwargs)\n+\n+    def _deserialize(\n+        self,\n+        data: (\n+            typing.Mapping[str, typing.Any]\n+            | typing.Iterable[typing.Mapping[str, typing.Any]]\n+        ),\n+        *,\n+        error_store: ErrorStore,\n+        many: bool = False,\n+        partial=None,\n+        unknown=RAISE,\n+        index=None,\n+    ) -&gt; _T | list[_T]:\n         \"\"\"Deserialize ``data``.\n\n         :param dict data: The data to deserialize.\n@@ -420,12 +600,105 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n             serializing a collection, otherwise `None`.\n         :return: A dictionary of the deserialized data.\n         \"\"\"\n-        pass\n-\n-    def load(self, data: (typing.Mapping[str, typing.Any] | typing.Iterable\n-        [typing.Mapping[str, typing.Any]]), *, many: (bool | None)=None,\n-        partial: (bool | types.StrSequenceOrSet | None)=None, unknown: (str |\n-        None)=None):\n+        index_errors = self.opts.index_errors\n+        index = index if index_errors else None\n+        if many:\n+            if not is_collection(data):\n+                error_store.store_error([self.error_messages[\"type\"]], index=index)\n+                ret_l = []  # type: typing.List[_T]\n+            else:\n+                ret_l = [\n+                    typing.cast(\n+                        _T,\n+                        self._deserialize(\n+                            typing.cast(typing.Mapping[str, typing.Any], d),\n+                            error_store=error_store,\n+                            many=False,\n+                            partial=partial,\n+                            unknown=unknown,\n+                            index=idx,\n+                        ),\n+                    )\n+                    for idx, d in enumerate(data)\n+                ]\n+            return ret_l\n+        ret_d = self.dict_class()\n+        # Check data is a dict\n+        if not isinstance(data, Mapping):\n+            error_store.store_error([self.error_messages[\"type\"]], index=index)\n+        else:\n+            partial_is_collection = is_collection(partial)\n+            for attr_name, field_obj in self.load_fields.items():\n+                field_name = (\n+                    field_obj.data_key if field_obj.data_key is not None else attr_name\n+                )\n+                raw_value = data.get(field_name, missing)\n+                if raw_value is missing:\n+                    # Ignore missing field if we're allowed to.\n+                    if partial is True or (\n+                        partial_is_collection and attr_name in partial\n+                    ):\n+                        continue\n+                d_kwargs = {}\n+                # Allow partial loading of nested schemas.\n+                if partial_is_collection:\n+                    prefix = field_name + \".\"\n+                    len_prefix = len(prefix)\n+                    sub_partial = [\n+                        f[len_prefix:] for f in partial if f.startswith(prefix)\n+                    ]\n+                    d_kwargs[\"partial\"] = sub_partial\n+                elif partial is not None:\n+                    d_kwargs[\"partial\"] = partial\n+\n+                def getter(\n+                    val, field_obj=field_obj, field_name=field_name, d_kwargs=d_kwargs\n+                ):\n+                    return field_obj.deserialize(\n+                        val,\n+                        field_name,\n+                        data,\n+                        **d_kwargs,\n+                    )\n+\n+                value = self._call_and_store(\n+                    getter_func=getter,\n+                    data=raw_value,\n+                    field_name=field_name,\n+                    error_store=error_store,\n+                    index=index,\n+                )\n+                if value is not missing:\n+                    key = field_obj.attribute or attr_name\n+                    set_value(ret_d, key, value)\n+            if unknown != EXCLUDE:\n+                fields = {\n+                    field_obj.data_key if field_obj.data_key is not None else field_name\n+                    for field_name, field_obj in self.load_fields.items()\n+                }\n+                for key in set(data) - fields:\n+                    value = data[key]\n+                    if unknown == INCLUDE:\n+                        ret_d[key] = value\n+                    elif unknown == RAISE:\n+                        error_store.store_error(\n+                            [self.error_messages[\"unknown\"]],\n+                            key,\n+                            (index if index_errors else None),\n+                        )\n+        return ret_d\n+\n+    def load(\n+        self,\n+        data: (\n+            typing.Mapping[str, typing.Any]\n+            | typing.Iterable[typing.Mapping[str, typing.Any]]\n+        ),\n+        *,\n+        many: bool | None = None,\n+        partial: bool | types.StrSequenceOrSet | None = None,\n+        unknown: str | None = None,\n+    ):\n         \"\"\"Deserialize a data structure to an object defined by this Schema's fields.\n\n         :param data: The data to deserialize.\n@@ -446,11 +719,19 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n             A :exc:`ValidationError &lt;marshmallow.exceptions.ValidationError&gt;` is raised\n             if invalid data are passed.\n         \"\"\"\n-        pass\n-\n-    def loads(self, json_data: str, *, many: (bool | None)=None, partial: (\n-        bool | types.StrSequenceOrSet | None)=None, unknown: (str | None)=\n-        None, **kwargs):\n+        return self._do_load(\n+            data, many=many, partial=partial, unknown=unknown, postprocess=True\n+        )\n+\n+    def loads(\n+        self,\n+        json_data: str,\n+        *,\n+        many: bool | None = None,\n+        partial: bool | types.StrSequenceOrSet | None = None,\n+        unknown: str | None = None,\n+        **kwargs,\n+    ):\n         \"\"\"Same as :meth:`load`, except it takes a JSON string as input.\n\n         :param json_data: A JSON string of the data to deserialize.\n@@ -471,12 +752,39 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n             A :exc:`ValidationError &lt;marshmallow.exceptions.ValidationError&gt;` is raised\n             if invalid data are passed.\n         \"\"\"\n-        pass\n-\n-    def validate(self, data: (typing.Mapping[str, typing.Any] | typing.\n-        Iterable[typing.Mapping[str, typing.Any]]), *, many: (bool | None)=\n-        None, partial: (bool | types.StrSequenceOrSet | None)=None) -&gt;dict[\n-        str, list[str]]:\n+        data = self.opts.render_module.loads(json_data, **kwargs)\n+        return self.load(data, many=many, partial=partial, unknown=unknown)\n+\n+    def _run_validator(\n+        self,\n+        validator_func,\n+        output,\n+        *,\n+        original_data,\n+        error_store,\n+        many,\n+        partial,\n+        pass_original,\n+        index=None,\n+    ):\n+        try:\n+            if pass_original:  # Pass original, raw data (before unmarshalling)\n+                validator_func(output, original_data, partial=partial, many=many)\n+            else:\n+                validator_func(output, partial=partial, many=many)\n+        except ValidationError as err:\n+            error_store.store_error(err.messages, err.field_name, index=index)\n+\n+    def validate(\n+        self,\n+        data: (\n+            typing.Mapping[str, typing.Any]\n+            | typing.Iterable[typing.Mapping[str, typing.Any]]\n+        ),\n+        *,\n+        many: bool | None = None,\n+        partial: bool | types.StrSequenceOrSet | None = None,\n+    ) -&gt; dict[str, list[str]]:\n         \"\"\"Validate `data` against the schema, returning a dictionary of\n         validation errors.\n\n@@ -491,12 +799,26 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n\n         .. versionadded:: 1.1.0\n         \"\"\"\n-        pass\n-\n-    def _do_load(self, data: (typing.Mapping[str, typing.Any] | typing.\n-        Iterable[typing.Mapping[str, typing.Any]]), *, many: (bool | None)=\n-        None, partial: (bool | types.StrSequenceOrSet | None)=None, unknown:\n-        (str | None)=None, postprocess: bool=True):\n+        try:\n+            self._do_load(data, many=many, partial=partial, postprocess=False)\n+        except ValidationError as exc:\n+            return typing.cast(typing.Dict[str, typing.List[str]], exc.messages)\n+        return {}\n+\n+    ##### Private Helpers #####\n+\n+    def _do_load(\n+        self,\n+        data: (\n+            typing.Mapping[str, typing.Any]\n+            | typing.Iterable[typing.Mapping[str, typing.Any]]\n+        ),\n+        *,\n+        many: bool | None = None,\n+        partial: bool | types.StrSequenceOrSet | None = None,\n+        unknown: str | None = None,\n+        postprocess: bool = True,\n+    ):\n         \"\"\"Deserialize `data`, returning the deserialized result.\n         This method is private API.\n\n@@ -513,41 +835,394 @@ class Schema(base.SchemaABC, metaclass=SchemaMeta):\n         :param postprocess: Whether to run post_load methods..\n         :return: Deserialized data\n         \"\"\"\n-        pass\n-\n-    def _normalize_nested_options(self) -&gt;None:\n+        error_store = ErrorStore()\n+        errors = {}  # type: dict[str, list[str]]\n+        many = self.many if many is None else bool(many)\n+        unknown = (\n+            self.unknown\n+            if unknown is None\n+            else validate_unknown_parameter_value(unknown)\n+        )\n+        if partial is None:\n+            partial = self.partial\n+        # Run preprocessors\n+        if self._has_processors(PRE_LOAD):\n+            try:\n+                processed_data = self._invoke_load_processors(\n+                    PRE_LOAD, data, many=many, original_data=data, partial=partial\n+                )\n+            except ValidationError as err:\n+                errors = err.normalized_messages()\n+                result = None  # type: list | dict | None\n+        else:\n+            processed_data = data\n+        if not errors:\n+            # Deserialize data\n+            result = self._deserialize(\n+                processed_data,\n+                error_store=error_store,\n+                many=many,\n+                partial=partial,\n+                unknown=unknown,\n+            )\n+            # Run field-level validation\n+            self._invoke_field_validators(\n+                error_store=error_store, data=result, many=many\n+            )\n+            # Run schema-level validation\n+            if self._has_processors(VALIDATES_SCHEMA):\n+                field_errors = bool(error_store.errors)\n+                self._invoke_schema_validators(\n+                    error_store=error_store,\n+                    pass_many=True,\n+                    data=result,\n+                    original_data=data,\n+                    many=many,\n+                    partial=partial,\n+                    field_errors=field_errors,\n+                )\n+                self._invoke_schema_validators(\n+                    error_store=error_store,\n+                    pass_many=False,\n+                    data=result,\n+                    original_data=data,\n+                    many=many,\n+                    partial=partial,\n+                    field_errors=field_errors,\n+                )\n+            errors = error_store.errors\n+            # Run post processors\n+            if not errors and postprocess and self._has_processors(POST_LOAD):\n+                try:\n+                    result = self._invoke_load_processors(\n+                        POST_LOAD,\n+                        result,\n+                        many=many,\n+                        original_data=data,\n+                        partial=partial,\n+                    )\n+                except ValidationError as err:\n+                    errors = err.normalized_messages()\n+        if errors:\n+            exc = ValidationError(errors, data=data, valid_data=result)\n+            self.handle_error(exc, data, many=many, partial=partial)\n+            raise exc\n+\n+        return result\n+\n+    def _normalize_nested_options(self) -&gt; None:\n         \"\"\"Apply then flatten nested schema options.\n         This method is private API.\n         \"\"\"\n-        pass\n-\n-    def __apply_nested_option(self, option_name, field_names, set_operation\n-        ) -&gt;None:\n+        if self.only is not None:\n+            # Apply the only option to nested fields.\n+            self.__apply_nested_option(\"only\", self.only, \"intersection\")\n+            # Remove the child field names from the only option.\n+            self.only = self.set_class([field.split(\".\", 1)[0] for field in self.only])\n+        if self.exclude:\n+            # Apply the exclude option to nested fields.\n+            self.__apply_nested_option(\"exclude\", self.exclude, \"union\")\n+            # Remove the parent field names from the exclude option.\n+            self.exclude = self.set_class(\n+                [field for field in self.exclude if \".\" not in field]\n+            )\n+\n+    def __apply_nested_option(self, option_name, field_names, set_operation) -&gt; None:\n         \"\"\"Apply nested options to nested fields\"\"\"\n-        pass\n-\n-    def _init_fields(self) -&gt;None:\n+        # Split nested field names on the first dot.\n+        nested_fields = [name.split(\".\", 1) for name in field_names if \".\" in name]\n+        # Partition the nested field names by parent field.\n+        nested_options = defaultdict(list)  # type: defaultdict\n+        for parent, nested_names in nested_fields:\n+            nested_options[parent].append(nested_names)\n+        # Apply the nested field options.\n+        for key, options in iter(nested_options.items()):\n+            new_options = self.set_class(options)\n+            original_options = getattr(self.declared_fields[key], option_name, ())\n+            if original_options:\n+                if set_operation == \"union\":\n+                    new_options |= self.set_class(original_options)\n+                if set_operation == \"intersection\":\n+                    new_options &amp;= self.set_class(original_options)\n+            setattr(self.declared_fields[key], option_name, new_options)\n+\n+    def _init_fields(self) -&gt; None:\n         \"\"\"Update self.fields, self.load_fields, and self.dump_fields based on schema options.\n         This method is private API.\n         \"\"\"\n-        pass\n+        if self.opts.fields:\n+            available_field_names = self.set_class(self.opts.fields)\n+        else:\n+            available_field_names = self.set_class(self.declared_fields.keys())\n+            if self.opts.additional:\n+                available_field_names |= self.set_class(self.opts.additional)\n+\n+        invalid_fields = self.set_class()\n+\n+        if self.only is not None:\n+            # Return only fields specified in only option\n+            field_names: typing.AbstractSet[typing.Any] = self.set_class(self.only)\n+\n+            invalid_fields |= field_names - available_field_names\n+        else:\n+            field_names = available_field_names\n+\n+        # If \"exclude\" option or param is specified, remove those fields.\n+        if self.exclude:\n+            # Note that this isn't available_field_names, since we want to\n+            # apply \"only\" for the actual calculation.\n+            field_names = field_names - self.exclude\n+            invalid_fields |= self.exclude - available_field_names\n+\n+        if invalid_fields:\n+            message = f\"Invalid fields for {self}: {invalid_fields}.\"\n+            raise ValueError(message)\n+\n+        fields_dict = self.dict_class()\n+        for field_name in field_names:\n+            field_obj = self.declared_fields.get(field_name, ma_fields.Inferred())\n+            self._bind_field(field_name, field_obj)\n+            fields_dict[field_name] = field_obj\n+\n+        load_fields, dump_fields = self.dict_class(), self.dict_class()\n+        for field_name, field_obj in fields_dict.items():\n+            if not field_obj.dump_only:\n+                load_fields[field_name] = field_obj\n+            if not field_obj.load_only:\n+                dump_fields[field_name] = field_obj\n+\n+        dump_data_keys = [\n+            field_obj.data_key if field_obj.data_key is not None else name\n+            for name, field_obj in dump_fields.items()\n+        ]\n+        if len(dump_data_keys) != len(set(dump_data_keys)):\n+            data_keys_duplicates = {\n+                x for x in dump_data_keys if dump_data_keys.count(x) &gt; 1\n+            }\n+            raise ValueError(\n+                \"The data_key argument for one or more fields collides \"\n+                \"with another field's name or data_key argument. \"\n+                \"Check the following field names and \"\n+                f\"data_key arguments: {list(data_keys_duplicates)}\"\n+            )\n+        load_attributes = [obj.attribute or name for name, obj in load_fields.items()]\n+        if len(load_attributes) != len(set(load_attributes)):\n+            attributes_duplicates = {\n+                x for x in load_attributes if load_attributes.count(x) &gt; 1\n+            }\n+            raise ValueError(\n+                \"The attribute argument for one or more fields collides \"\n+                \"with another field's name or attribute argument. \"\n+                \"Check the following field names and \"\n+                f\"attribute arguments: {list(attributes_duplicates)}\"\n+            )\n\n-    def on_bind_field(self, field_name: str, field_obj: ma_fields.Field\n-        ) -&gt;None:\n+        self.fields = fields_dict\n+        self.dump_fields = dump_fields\n+        self.load_fields = load_fields\n+\n+    def on_bind_field(self, field_name: str, field_obj: ma_fields.Field) -&gt; None:\n         \"\"\"Hook to modify a field when it is bound to the `Schema`.\n\n         No-op by default.\n         \"\"\"\n-        pass\n+        return None\n\n-    def _bind_field(self, field_name: str, field_obj: ma_fields.Field) -&gt;None:\n+    def _bind_field(self, field_name: str, field_obj: ma_fields.Field) -&gt; None:\n         \"\"\"Bind field to the schema, setting any necessary attributes on the\n         field (e.g. parent and name).\n\n         Also set field load_only and dump_only values if field_name was\n         specified in ``class Meta``.\n         \"\"\"\n-        pass\n+        if field_name in self.load_only:\n+            field_obj.load_only = True\n+        if field_name in self.dump_only:\n+            field_obj.dump_only = True\n+        try:\n+            field_obj._bind_to_schema(field_name, self)\n+        except TypeError as error:\n+            # Field declared as a class, not an instance. Ignore type checking because\n+            # we handle unsupported arg types, i.e. this is dead code from\n+            # the type checker's perspective.\n+            if isinstance(field_obj, type) and issubclass(field_obj, base.FieldABC):\n+                msg = (\n+                    f'Field for \"{field_name}\" must be declared as a '\n+                    \"Field instance, not a class. \"\n+                    f'Did you mean \"fields.{field_obj.__name__}()\"?'  # type: ignore\n+                )\n+                raise TypeError(msg) from error\n+            raise error\n+        self.on_bind_field(field_name, field_obj)\n+\n+    def _has_processors(self, tag) -&gt; bool:\n+        return bool(self._hooks[(tag, True)] or self._hooks[(tag, False)])\n+\n+    def _invoke_dump_processors(\n+        self, tag: str, data, *, many: bool, original_data=None\n+    ):\n+        # The pass_many post-dump processors may do things like add an envelope, so\n+        # invoke those after invoking the non-pass_many processors which will expect\n+        # to get a list of items.\n+        data = self._invoke_processors(\n+            tag, pass_many=False, data=data, many=many, original_data=original_data\n+        )\n+        data = self._invoke_processors(\n+            tag, pass_many=True, data=data, many=many, original_data=original_data\n+        )\n+        return data\n+\n+    def _invoke_load_processors(\n+        self,\n+        tag: str,\n+        data,\n+        *,\n+        many: bool,\n+        original_data,\n+        partial: bool | types.StrSequenceOrSet | None,\n+    ):\n+        # This has to invert the order of the dump processors, so run the pass_many\n+        # processors first.\n+        data = self._invoke_processors(\n+            tag,\n+            pass_many=True,\n+            data=data,\n+            many=many,\n+            original_data=original_data,\n+            partial=partial,\n+        )\n+        data = self._invoke_processors(\n+            tag,\n+            pass_many=False,\n+            data=data,\n+            many=many,\n+            original_data=original_data,\n+            partial=partial,\n+        )\n+        return data\n+\n+    def _invoke_field_validators(self, *, error_store: ErrorStore, data, many: bool):\n+        for attr_name in self._hooks[VALIDATES]:\n+            validator = getattr(self, attr_name)\n+            validator_kwargs = validator.__marshmallow_hook__[VALIDATES]\n+            field_name = validator_kwargs[\"field_name\"]\n+\n+            try:\n+                field_obj = self.fields[field_name]\n+            except KeyError as error:\n+                if field_name in self.declared_fields:\n+                    continue\n+                raise ValueError(f'\"{field_name}\" field does not exist.') from error\n+\n+            data_key = (\n+                field_obj.data_key if field_obj.data_key is not None else field_name\n+            )\n+            if many:\n+                for idx, item in enumerate(data):\n+                    try:\n+                        value = item[field_obj.attribute or field_name]\n+                    except KeyError:\n+                        pass\n+                    else:\n+                        validated_value = self._call_and_store(\n+                            getter_func=validator,\n+                            data=value,\n+                            field_name=data_key,\n+                            error_store=error_store,\n+                            index=(idx if self.opts.index_errors else None),\n+                        )\n+                        if validated_value is missing:\n+                            data[idx].pop(field_name, None)\n+            else:\n+                try:\n+                    value = data[field_obj.attribute or field_name]\n+                except KeyError:\n+                    pass\n+                else:\n+                    validated_value = self._call_and_store(\n+                        getter_func=validator,\n+                        data=value,\n+                        field_name=data_key,\n+                        error_store=error_store,\n+                    )\n+                    if validated_value is missing:\n+                        data.pop(field_name, None)\n+\n+    def _invoke_schema_validators(\n+        self,\n+        *,\n+        error_store: ErrorStore,\n+        pass_many: bool,\n+        data,\n+        original_data,\n+        many: bool,\n+        partial: bool | types.StrSequenceOrSet | None,\n+        field_errors: bool = False,\n+    ):\n+        for attr_name in self._hooks[(VALIDATES_SCHEMA, pass_many)]:\n+            validator = getattr(self, attr_name)\n+            validator_kwargs = validator.__marshmallow_hook__[\n+                (VALIDATES_SCHEMA, pass_many)\n+            ]\n+            if field_errors and validator_kwargs[\"skip_on_field_errors\"]:\n+                continue\n+            pass_original = validator_kwargs.get(\"pass_original\", False)\n+\n+            if many and not pass_many:\n+                for idx, (item, orig) in enumerate(zip(data, original_data)):\n+                    self._run_validator(\n+                        validator,\n+                        item,\n+                        original_data=orig,\n+                        error_store=error_store,\n+                        many=many,\n+                        partial=partial,\n+                        index=idx,\n+                        pass_original=pass_original,\n+                    )\n+            else:\n+                self._run_validator(\n+                    validator,\n+                    data,\n+                    original_data=original_data,\n+                    error_store=error_store,\n+                    many=many,\n+                    pass_original=pass_original,\n+                    partial=partial,\n+                )\n+\n+    def _invoke_processors(\n+        self,\n+        tag: str,\n+        *,\n+        pass_many: bool,\n+        data,\n+        many: bool,\n+        original_data=None,\n+        **kwargs,\n+    ):\n+        key = (tag, pass_many)\n+        for attr_name in self._hooks[key]:\n+            # This will be a bound method.\n+            processor = getattr(self, attr_name)\n+\n+            processor_kwargs = processor.__marshmallow_hook__[key]\n+            pass_original = processor_kwargs.get(\"pass_original\", False)\n+\n+            if many and not pass_many:\n+                if pass_original:\n+                    data = [\n+                        processor(item, original, many=many, **kwargs)\n+                        for item, original in zip(data, original_data)\n+                    ]\n+                else:\n+                    data = [processor(item, many=many, **kwargs) for item in data]\n+            else:\n+                if pass_original:\n+                    data = processor(data, original_data, many=many, **kwargs)\n+                else:\n+                    data = processor(data, many=many, **kwargs)\n+        return data\n\n\n-BaseSchema = Schema\n+BaseSchema = Schema  # for backwards compatibility\ndiff --git a/src/marshmallow/types.py b/src/marshmallow/types.py\nindex 43103ae..ce31c05 100644\n--- a/src/marshmallow/types.py\n+++ b/src/marshmallow/types.py\n@@ -4,7 +4,9 @@\n\n     This module is provisional. Types may be modified, added, and removed between minor releases.\n \"\"\"\n+\n import typing\n+\n StrSequenceOrSet = typing.Union[typing.Sequence[str], typing.AbstractSet[str]]\n Tag = typing.Union[str, typing.Tuple[str, bool]]\n Validator = typing.Callable[[typing.Any], typing.Any]\ndiff --git a/src/marshmallow/utils.py b/src/marshmallow/utils.py\nindex 1c71b57..a5fe726 100644\n--- a/src/marshmallow/utils.py\n+++ b/src/marshmallow/utils.py\n@@ -1,5 +1,7 @@\n \"\"\"Utility methods for marshmallow.\"\"\"\n+\n from __future__ import annotations\n+\n import collections\n import datetime as dt\n import functools\n@@ -11,17 +13,18 @@ import warnings\n from collections.abc import Mapping\n from email.utils import format_datetime, parsedate_to_datetime\n from pprint import pprint as py_pprint\n+\n from marshmallow.base import FieldABC\n from marshmallow.exceptions import FieldInstanceResolutionError\n from marshmallow.warnings import RemovedInMarshmallow4Warning\n-EXCLUDE = 'exclude'\n-INCLUDE = 'include'\n-RAISE = 'raise'\n+\n+EXCLUDE = \"exclude\"\n+INCLUDE = \"include\"\n+RAISE = \"raise\"\n _UNKNOWN_VALUES = {EXCLUDE, INCLUDE, RAISE}\n\n\n class _Missing:\n-\n     def __bool__(self):\n         return False\n\n@@ -32,40 +35,46 @@ class _Missing:\n         return self\n\n     def __repr__(self):\n-        return '&lt;marshmallow.missing&gt;'\n+        return \"&lt;marshmallow.missing&gt;\"\n\n\n+# Singleton value that indicates that a field's value is missing from input\n+# dict passed to :meth:`Schema.load`. If the field's value is not required,\n+# it's ``default`` value is used.\n missing = _Missing()\n\n\n-def is_generator(obj) -&gt;bool:\n+def is_generator(obj) -&gt; bool:\n     \"\"\"Return True if ``obj`` is a generator\"\"\"\n-    pass\n+    return inspect.isgeneratorfunction(obj) or inspect.isgenerator(obj)\n\n\n-def is_iterable_but_not_string(obj) -&gt;bool:\n+def is_iterable_but_not_string(obj) -&gt; bool:\n     \"\"\"Return True if ``obj`` is an iterable object that isn't a string.\"\"\"\n-    pass\n+    return (hasattr(obj, \"__iter__\") and not hasattr(obj, \"strip\")) or is_generator(obj)\n\n\n-def is_collection(obj) -&gt;bool:\n+def is_collection(obj) -&gt; bool:\n     \"\"\"Return True if ``obj`` is a collection type, e.g list, tuple, queryset.\"\"\"\n-    pass\n+    return is_iterable_but_not_string(obj) and not isinstance(obj, Mapping)\n\n\n-def is_instance_or_subclass(val, class_) -&gt;bool:\n+def is_instance_or_subclass(val, class_) -&gt; bool:\n     \"\"\"Return True if ``val`` is either a subclass or instance of ``class_``.\"\"\"\n-    pass\n+    try:\n+        return issubclass(val, class_)\n+    except TypeError:\n+        return isinstance(val, class_)\n\n\n-def is_keyed_tuple(obj) -&gt;bool:\n+def is_keyed_tuple(obj) -&gt; bool:\n     \"\"\"Return True if ``obj`` has keyed tuple behavior, such as\n     namedtuples or SQLAlchemy's KeyedTuples.\n     \"\"\"\n-    pass\n+    return isinstance(obj, tuple) and hasattr(obj, \"_fields\")\n\n\n-def pprint(obj, *args, **kwargs) -&gt;None:\n+def pprint(obj, *args, **kwargs) -&gt; None:\n     \"\"\"Pretty-printing function that can pretty-print OrderedDicts\n     like regular dictionaries. Useful for printing the output of\n     :meth:`marshmallow.Schema.dump`.\n@@ -73,38 +82,65 @@ def pprint(obj, *args, **kwargs) -&gt;None:\n     .. deprecated:: 3.7.0\n         marshmallow.pprint will be removed in marshmallow 4.\n     \"\"\"\n-    pass\n+    warnings.warn(\n+        \"marshmallow's pprint function is deprecated and will be removed in marshmallow 4.\",\n+        RemovedInMarshmallow4Warning,\n+        stacklevel=2,\n+    )\n+    if isinstance(obj, collections.OrderedDict):\n+        print(json.dumps(obj, *args, **kwargs))\n+    else:\n+        py_pprint(obj, *args, **kwargs)\n+\n\n+# https://stackoverflow.com/a/27596917\n+def is_aware(datetime: dt.datetime) -&gt; bool:\n+    return (\n+        datetime.tzinfo is not None and datetime.tzinfo.utcoffset(datetime) is not None\n+    )\n\n-def from_rfc(datestring: str) -&gt;dt.datetime:\n+\n+def from_rfc(datestring: str) -&gt; dt.datetime:\n     \"\"\"Parse a RFC822-formatted datetime string and return a datetime object.\n\n     https://stackoverflow.com/questions/885015/how-to-parse-a-rfc-2822-date-time-into-a-python-datetime  # noqa: B950\n     \"\"\"\n-    pass\n+    return parsedate_to_datetime(datestring)\n\n\n-def rfcformat(datetime: dt.datetime) -&gt;str:\n+def rfcformat(datetime: dt.datetime) -&gt; str:\n     \"\"\"Return the RFC822-formatted representation of a datetime object.\n\n     :param datetime datetime: The datetime.\n     \"\"\"\n-    pass\n+    return format_datetime(datetime)\n+\n\n+# Hat tip to Django for ISO8601 deserialization functions\n\n _iso8601_datetime_re = re.compile(\n-    '(?P&lt;year&gt;\\\\d{4})-(?P&lt;month&gt;\\\\d{1,2})-(?P&lt;day&gt;\\\\d{1,2})[T ](?P&lt;hour&gt;\\\\d{1,2}):(?P&lt;minute&gt;\\\\d{1,2})(?::(?P&lt;second&gt;\\\\d{1,2})(?:\\\\.(?P&lt;microsecond&gt;\\\\d{1,6})\\\\d{0,6})?)?(?P&lt;tzinfo&gt;Z|[+-]\\\\d{2}(?::?\\\\d{2})?)?$'\n-    )\n-_iso8601_date_re = re.compile(\n-    '(?P&lt;year&gt;\\\\d{4})-(?P&lt;month&gt;\\\\d{1,2})-(?P&lt;day&gt;\\\\d{1,2})$')\n+    r\"(?P&lt;year&gt;\\d{4})-(?P&lt;month&gt;\\d{1,2})-(?P&lt;day&gt;\\d{1,2})\"\n+    r\"[T ](?P&lt;hour&gt;\\d{1,2}):(?P&lt;minute&gt;\\d{1,2})\"\n+    r\"(?::(?P&lt;second&gt;\\d{1,2})(?:\\.(?P&lt;microsecond&gt;\\d{1,6})\\d{0,6})?)?\"\n+    r\"(?P&lt;tzinfo&gt;Z|[+-]\\d{2}(?::?\\d{2})?)?$\"\n+)\n+\n+_iso8601_date_re = re.compile(r\"(?P&lt;year&gt;\\d{4})-(?P&lt;month&gt;\\d{1,2})-(?P&lt;day&gt;\\d{1,2})$\")\n+\n _iso8601_time_re = re.compile(\n-    '(?P&lt;hour&gt;\\\\d{1,2}):(?P&lt;minute&gt;\\\\d{1,2})(?::(?P&lt;second&gt;\\\\d{1,2})(?:\\\\.(?P&lt;microsecond&gt;\\\\d{1,6})\\\\d{0,6})?)?'\n-    )\n+    r\"(?P&lt;hour&gt;\\d{1,2}):(?P&lt;minute&gt;\\d{1,2})\"\n+    r\"(?::(?P&lt;second&gt;\\d{1,2})(?:\\.(?P&lt;microsecond&gt;\\d{1,6})\\d{0,6})?)?\"\n+)\n\n\n-def get_fixed_timezone(offset: (int | float | dt.timedelta)) -&gt;dt.timezone:\n+def get_fixed_timezone(offset: int | float | dt.timedelta) -&gt; dt.timezone:\n     \"\"\"Return a tzinfo instance with a fixed offset from UTC.\"\"\"\n-    pass\n+    if isinstance(offset, dt.timedelta):\n+        offset = offset.total_seconds() // 60\n+    sign = \"-\" if offset &lt; 0 else \"+\"\n+    hhmm = \"%02d%02d\" % divmod(abs(offset), 60)\n+    name = sign + hhmm\n+    return dt.timezone(dt.timedelta(minutes=offset), name)\n\n\n def from_iso_datetime(value):\n@@ -113,7 +149,23 @@ def from_iso_datetime(value):\n     This function supports time zone offsets. When the input contains one,\n     the output uses a timezone with a fixed offset from UTC.\n     \"\"\"\n-    pass\n+    match = _iso8601_datetime_re.match(value)\n+    if not match:\n+        raise ValueError(\"Not a valid ISO8601-formatted datetime string\")\n+    kw = match.groupdict()\n+    kw[\"microsecond\"] = kw[\"microsecond\"] and kw[\"microsecond\"].ljust(6, \"0\")\n+    tzinfo = kw.pop(\"tzinfo\")\n+    if tzinfo == \"Z\":\n+        tzinfo = dt.timezone.utc\n+    elif tzinfo is not None:\n+        offset_mins = int(tzinfo[-2:]) if len(tzinfo) &gt; 3 else 0\n+        offset = 60 * int(tzinfo[1:3]) + offset_mins\n+        if tzinfo[0] == \"-\":\n+            offset = -offset\n+        tzinfo = get_fixed_timezone(offset)\n+    kw = {k: int(v) for k, v in kw.items() if v is not None}\n+    kw[\"tzinfo\"] = tzinfo\n+    return dt.datetime(**kw)\n\n\n def from_iso_time(value):\n@@ -121,20 +173,79 @@ def from_iso_time(value):\n\n     This function doesn't support time zone offsets.\n     \"\"\"\n-    pass\n+    match = _iso8601_time_re.match(value)\n+    if not match:\n+        raise ValueError(\"Not a valid ISO8601-formatted time string\")\n+    kw = match.groupdict()\n+    kw[\"microsecond\"] = kw[\"microsecond\"] and kw[\"microsecond\"].ljust(6, \"0\")\n+    kw = {k: int(v) for k, v in kw.items() if v is not None}\n+    return dt.time(**kw)\n\n\n def from_iso_date(value):\n     \"\"\"Parse a string and return a datetime.date.\"\"\"\n-    pass\n+    match = _iso8601_date_re.match(value)\n+    if not match:\n+        raise ValueError(\"Not a valid ISO8601-formatted date string\")\n+    kw = {k: int(v) for k, v in match.groupdict().items()}\n+    return dt.date(**kw)\n+\n+\n+def from_timestamp(value: typing.Any) -&gt; dt.datetime:\n+    if value is True or value is False:\n+        raise ValueError(\"Not a valid POSIX timestamp\")\n+    value = float(value)\n+    if value &lt; 0:\n+        raise ValueError(\"Not a valid POSIX timestamp\")\n+\n+    # Load a timestamp with utc as timezone to prevent using system timezone.\n+    # Then set timezone to None, to let the Field handle adding timezone info.\n+    try:\n+        return dt.datetime.fromtimestamp(value, tz=dt.timezone.utc).replace(tzinfo=None)\n+    except OverflowError as exc:\n+        raise ValueError(\"Timestamp is too large\") from exc\n+    except OSError as exc:\n+        raise ValueError(\"Error converting value to datetime\") from exc\n+\n+\n+def from_timestamp_ms(value: typing.Any) -&gt; dt.datetime:\n+    value = float(value)\n+    return from_timestamp(value / 1000)\n+\n\n+def timestamp(\n+    value: dt.datetime,\n+) -&gt; float:\n+    if not is_aware(value):\n+        # When a date is naive, use UTC as zone info to prevent using system timezone.\n+        value = value.replace(tzinfo=dt.timezone.utc)\n+    return value.timestamp()\n\n-def isoformat(datetime: dt.datetime) -&gt;str:\n+\n+def timestamp_ms(value: dt.datetime) -&gt; float:\n+    return timestamp(value) * 1000\n+\n+\n+def isoformat(datetime: dt.datetime) -&gt; str:\n     \"\"\"Return the ISO8601-formatted representation of a datetime object.\n\n     :param datetime datetime: The datetime.\n     \"\"\"\n-    pass\n+    return datetime.isoformat()\n+\n+\n+def to_iso_time(time: dt.time) -&gt; str:\n+    return dt.time.isoformat(time)\n+\n+\n+def to_iso_date(date: dt.date) -&gt; str:\n+    return dt.date.isoformat(date)\n+\n+\n+def ensure_text_type(val: str | bytes) -&gt; str:\n+    if isinstance(val, bytes):\n+        val = val.decode(\"utf-8\")\n+    return str(val)\n\n\n def pluck(dictlist: list[dict[str, typing.Any]], key: str):\n@@ -145,10 +256,13 @@ def pluck(dictlist: list[dict[str, typing.Any]], key: str):\n         &gt;&gt;&gt; pluck(dlist, 'id')\n         [1, 2]\n     \"\"\"\n-    pass\n+    return [d[key] for d in dictlist]\n+\n\n+# Various utilities for pulling keyed values from objects\n\n-def get_value(obj, key: (int | str), default=missing):\n+\n+def get_value(obj, key: int | str, default=missing):\n     \"\"\"Helper for pulling a keyed value off various types of objects. Fields use\n     this method by default to access attributes of the source object. For object `x`\n     and attribute `i`, this method first tries to access `x[i]`, and then falls back to\n@@ -159,7 +273,29 @@ def get_value(obj, key: (int | str), default=missing):\n         `get_value` will never check the value `x.i`. Consider overriding\n         `marshmallow.fields.Field.get_value` in this case.\n     \"\"\"\n-    pass\n+    if not isinstance(key, int) and \".\" in key:\n+        return _get_value_for_keys(obj, key.split(\".\"), default)\n+    else:\n+        return _get_value_for_key(obj, key, default)\n+\n+\n+def _get_value_for_keys(obj, keys, default):\n+    if len(keys) == 1:\n+        return _get_value_for_key(obj, keys[0], default)\n+    else:\n+        return _get_value_for_keys(\n+            _get_value_for_key(obj, keys[0], default), keys[1:], default\n+        )\n+\n+\n+def _get_value_for_key(obj, key, default):\n+    if not hasattr(obj, \"__getitem__\"):\n+        return getattr(obj, key, default)\n+\n+    try:\n+        return obj[key]\n+    except (KeyError, IndexError, TypeError, AttributeError):\n+        return getattr(obj, key, default)\n\n\n def set_value(dct: dict[str, typing.Any], key: str, value: typing.Any):\n@@ -173,22 +309,42 @@ def set_value(dct: dict[str, typing.Any], key: str, value: typing.Any):\n         &gt;&gt;&gt; d\n         {'foo': {'bar': 42}}\n     \"\"\"\n-    pass\n+    if \".\" in key:\n+        head, rest = key.split(\".\", 1)\n+        target = dct.setdefault(head, {})\n+        if not isinstance(target, dict):\n+            raise ValueError(\n+                f\"Cannot set {key} in {head} \" f\"due to existing value: {target}\"\n+            )\n+        set_value(target, rest, value)\n+    else:\n+        dct[key] = value\n\n\n def callable_or_raise(obj):\n     \"\"\"Check that an object is callable, else raise a :exc:`TypeError`.\"\"\"\n-    pass\n+    if not callable(obj):\n+        raise TypeError(f\"Object {obj!r} is not callable.\")\n+    return obj\n+\n+\n+def _signature(func: typing.Callable) -&gt; list[str]:\n+    return list(inspect.signature(func).parameters.keys())\n\n\n-def get_func_args(func: typing.Callable) -&gt;list[str]:\n+def get_func_args(func: typing.Callable) -&gt; list[str]:\n     \"\"\"Given a callable, return a list of argument names. Handles\n     `functools.partial` objects and class-based callables.\n\n     .. versionchanged:: 3.0.0a1\n         Do not return bound arguments, eg. ``self``.\n     \"\"\"\n-    pass\n+    if inspect.isfunction(func) or inspect.ismethod(func):\n+        return _signature(func)\n+    if isinstance(func, functools.partial):\n+        return _signature(func.func)\n+    # Callable class\n+    return _signature(func)\n\n\n def resolve_field_instance(cls_or_instance):\n@@ -196,12 +352,27 @@ def resolve_field_instance(cls_or_instance):\n\n     :param type|Schema cls_or_instance: Marshmallow Schema class or instance.\n     \"\"\"\n-    pass\n+    if isinstance(cls_or_instance, type):\n+        if not issubclass(cls_or_instance, FieldABC):\n+            raise FieldInstanceResolutionError\n+        return cls_or_instance()\n+    else:\n+        if not isinstance(cls_or_instance, FieldABC):\n+            raise FieldInstanceResolutionError\n+        return cls_or_instance\n\n\n-def timedelta_to_microseconds(value: dt.timedelta) -&gt;int:\n+def timedelta_to_microseconds(value: dt.timedelta) -&gt; int:\n     \"\"\"Compute the total microseconds of a timedelta\n\n     https://github.com/python/cpython/blob/bb3e0c240bc60fe08d332ff5955d54197f79751c/Lib/datetime.py#L665-L667  # noqa: B950\n     \"\"\"\n-    pass\n+    return (value.days * (24 * 3600) + value.seconds) * 1000000 + value.microseconds\n+\n+\n+def validate_unknown_parameter_value(obj: typing.Any) -&gt; str:\n+    if obj not in _UNKNOWN_VALUES:\n+        raise ValueError(\n+            f\"Object {obj!r} is not a valid value for the 'unknown' parameter\"\n+        )\n+    return obj\ndiff --git a/src/marshmallow/validate.py b/src/marshmallow/validate.py\nindex 3cc3b97..e4536d8 100644\n--- a/src/marshmallow/validate.py\n+++ b/src/marshmallow/validate.py\n@@ -1,13 +1,17 @@\n \"\"\"Validation classes for various types of data.\"\"\"\n+\n from __future__ import annotations\n+\n import re\n import typing\n from abc import ABC, abstractmethod\n from itertools import zip_longest\n from operator import attrgetter\n+\n from marshmallow import types\n from marshmallow.exceptions import ValidationError\n-_T = typing.TypeVar('_T')\n+\n+_T = typing.TypeVar(\"_T\")\n\n\n class Validator(ABC):\n@@ -17,22 +21,23 @@ class Validator(ABC):\n         This class does not provide any validation behavior. It is only used to\n         add a useful `__repr__` implementation for validators.\n     \"\"\"\n-    error = None\n\n-    def __repr__(self) -&gt;str:\n+    error = None  # type: str | None\n+\n+    def __repr__(self) -&gt; str:\n         args = self._repr_args()\n-        args = f'{args}, ' if args else ''\n-        return f'&lt;{self.__class__.__name__}({args}error={self.error!r})&gt;'\n+        args = f\"{args}, \" if args else \"\"\n\n-    def _repr_args(self) -&gt;str:\n+        return f\"&lt;{self.__class__.__name__}({args}error={self.error!r})&gt;\"\n+\n+    def _repr_args(self) -&gt; str:\n         \"\"\"A string representation of the args passed to this validator. Used by\n         `__repr__`.\n         \"\"\"\n-        pass\n+        return \"\"\n\n     @abstractmethod\n-    def __call__(self, value: typing.Any) -&gt;typing.Any:\n-        ...\n+    def __call__(self, value: typing.Any) -&gt; typing.Any: ...\n\n\n class And(Validator):\n@@ -55,13 +60,17 @@ class And(Validator):\n     :param validators: Validators to combine.\n     :param error: Error message to use when a validator returns ``False``.\n     \"\"\"\n-    default_error_message = 'Invalid value.'\n\n-    def __init__(self, *validators: types.Validator, error: (str | None)=None):\n+    default_error_message = \"Invalid value.\"\n+\n+    def __init__(self, *validators: types.Validator, error: str | None = None):\n         self.validators = tuple(validators)\n-        self.error = error or self.default_error_message\n+        self.error = error or self.default_error_message  # type: str\n\n-    def __call__(self, value: typing.Any) -&gt;typing.Any:\n+    def _repr_args(self) -&gt; str:\n+        return f\"validators={self.validators!r}\"\n+\n+    def __call__(self, value: typing.Any) -&gt; typing.Any:\n         errors = []\n         kwargs = {}\n         for validator in self.validators:\n@@ -74,6 +83,7 @@ class And(Validator):\n                 if isinstance(err.messages, dict):\n                     errors.append(err.messages)\n                 else:\n+                    # FIXME : Get rid of cast\n                     errors.extend(typing.cast(list, err.messages))\n         if errors:\n             raise ValidationError(errors, **kwargs)\n@@ -92,47 +102,121 @@ class URL(Validator):\n     :param require_tld: Whether to reject non-FQDN hostnames.\n     \"\"\"\n\n-\n     class RegexMemoizer:\n-\n         def __init__(self):\n             self._memoized = {}\n\n-        def __call__(self, relative: bool, absolute: bool, require_tld: bool\n-            ) -&gt;typing.Pattern:\n-            key = relative, absolute, require_tld\n+        def _regex_generator(\n+            self, relative: bool, absolute: bool, require_tld: bool\n+        ) -&gt; typing.Pattern:\n+            hostname_variants = [\n+                # a normal domain name, expressed in [A-Z0-9] chars with hyphens allowed only in the middle\n+                # note that the regex will be compiled with IGNORECASE, so these are upper and lowercase chars\n+                (\n+                    r\"(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+\"\n+                    r\"(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)\"\n+                ),\n+                # or the special string 'localhost'\n+                r\"localhost\",\n+                # or IPv4\n+                r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",\n+                # or IPv6\n+                r\"\\[[A-F0-9]*:[A-F0-9:]+\\]\",\n+            ]\n+            if not require_tld:\n+                # allow dotless hostnames\n+                hostname_variants.append(r\"(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.?)\")\n+\n+            absolute_part = \"\".join(\n+                (\n+                    # scheme (e.g. 'https://', 'ftp://', etc)\n+                    # this is validated separately against allowed schemes, so in the regex\n+                    # we simply want to capture its existence\n+                    r\"(?:[a-z0-9\\.\\-\\+]*)://\",\n+                    # userinfo, for URLs encoding authentication\n+                    # e.g. 'ftp://foo:bar@ftp.example.org/'\n+                    r\"(?:(?:[a-z0-9\\-._~!$&amp;'()*+,;=:]|%[0-9a-f]{2})*@)?\",\n+                    # netloc, the hostname/domain part of the URL plus the optional port\n+                    r\"(?:\",\n+                    \"|\".join(hostname_variants),\n+                    r\")\",\n+                    r\"(?::\\d+)?\",\n+                )\n+            )\n+            relative_part = r\"(?:/?|[/?]\\S+)\\Z\"\n+\n+            if relative:\n+                if absolute:\n+                    parts: tuple[str, ...] = (\n+                        r\"^(\",\n+                        absolute_part,\n+                        r\")?\",\n+                        relative_part,\n+                    )\n+                else:\n+                    parts = (r\"^\", relative_part)\n+            else:\n+                parts = (r\"^\", absolute_part, relative_part)\n+\n+            return re.compile(\"\".join(parts), re.IGNORECASE)\n+\n+        def __call__(\n+            self, relative: bool, absolute: bool, require_tld: bool\n+        ) -&gt; typing.Pattern:\n+            key = (relative, absolute, require_tld)\n             if key not in self._memoized:\n-                self._memoized[key] = self._regex_generator(relative,\n-                    absolute, require_tld)\n+                self._memoized[key] = self._regex_generator(\n+                    relative, absolute, require_tld\n+                )\n+\n             return self._memoized[key]\n+\n     _regex = RegexMemoizer()\n-    default_message = 'Not a valid URL.'\n-    default_schemes = {'http', 'https', 'ftp', 'ftps'}\n\n-    def __init__(self, *, relative: bool=False, absolute: bool=True,\n-        schemes: (types.StrSequenceOrSet | None)=None, require_tld: bool=\n-        True, error: (str | None)=None):\n+    default_message = \"Not a valid URL.\"\n+    default_schemes = {\"http\", \"https\", \"ftp\", \"ftps\"}\n+\n+    def __init__(\n+        self,\n+        *,\n+        relative: bool = False,\n+        absolute: bool = True,\n+        schemes: types.StrSequenceOrSet | None = None,\n+        require_tld: bool = True,\n+        error: str | None = None,\n+    ):\n         if not relative and not absolute:\n             raise ValueError(\n-                'URL validation cannot set both relative and absolute to False.'\n-                )\n+                \"URL validation cannot set both relative and absolute to False.\"\n+            )\n         self.relative = relative\n         self.absolute = absolute\n-        self.error = error or self.default_message\n+        self.error = error or self.default_message  # type: str\n         self.schemes = schemes or self.default_schemes\n         self.require_tld = require_tld\n\n-    def __call__(self, value: str) -&gt;str:\n+    def _repr_args(self) -&gt; str:\n+        return f\"relative={self.relative!r}, absolute={self.absolute!r}\"\n+\n+    def _format_error(self, value) -&gt; str:\n+        return self.error.format(input=value)\n+\n+    def __call__(self, value: str) -&gt; str:\n         message = self._format_error(value)\n         if not value:\n             raise ValidationError(message)\n-        if '://' in value:\n-            scheme = value.split('://')[0].lower()\n+\n+        # Check first if the scheme is valid\n+        if \"://\" in value:\n+            scheme = value.split(\"://\")[0].lower()\n             if scheme not in self.schemes:\n                 raise ValidationError(message)\n+\n         regex = self._regex(self.relative, self.absolute, self.require_tld)\n+\n         if not regex.search(value):\n             raise ValidationError(message)\n+\n         return value\n\n\n@@ -142,35 +226,57 @@ class Email(Validator):\n     :param error: Error message to raise in case of a validation error. Can be\n         interpolated with `{input}`.\n     \"\"\"\n+\n     USER_REGEX = re.compile(\n-        '(^[-!#$%&amp;\\'*+/=?^`{}|~\\\\w]+(\\\\.[-!#$%&amp;\\'*+/=?^`{}|~\\\\w]+)*\\\\Z|^\"([\\\\001-\\\\010\\\\013\\\\014\\\\016-\\\\037!#-\\\\[\\\\]-\\\\177]|\\\\\\\\[\\\\001-\\\\011\\\\013\\\\014\\\\016-\\\\177])*\"\\\\Z)'\n-        , re.IGNORECASE | re.UNICODE)\n+        r\"(^[-!#$%&amp;'*+/=?^`{}|~\\w]+(\\.[-!#$%&amp;'*+/=?^`{}|~\\w]+)*\\Z\"  # dot-atom\n+        # quoted-string\n+        r'|^\"([\\001-\\010\\013\\014\\016-\\037!#-\\[\\]-\\177]'\n+        r'|\\\\[\\001-\\011\\013\\014\\016-\\177])*\"\\Z)',\n+        re.IGNORECASE | re.UNICODE,\n+    )\n+\n     DOMAIN_REGEX = re.compile(\n-        '(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}|[A-Z0-9-]{2,})\\\\Z|^\\\\[(25[0-5]|2[0-4]\\\\d|[0-1]?\\\\d?\\\\d)(\\\\.(25[0-5]|2[0-4]\\\\d|[0-1]?\\\\d?\\\\d)){3}\\\\]\\\\Z'\n-        , re.IGNORECASE | re.UNICODE)\n-    DOMAIN_WHITELIST = 'localhost',\n-    default_message = 'Not a valid email address.'\n+        # domain\n+        r\"(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+\"\n+        r\"(?:[A-Z]{2,6}|[A-Z0-9-]{2,})\\Z\"\n+        # literal form, ipv4 address (SMTP 4.1.3)\n+        r\"|^\\[(25[0-5]|2[0-4]\\d|[0-1]?\\d?\\d)\"\n+        r\"(\\.(25[0-5]|2[0-4]\\d|[0-1]?\\d?\\d)){3}\\]\\Z\",\n+        re.IGNORECASE | re.UNICODE,\n+    )\n+\n+    DOMAIN_WHITELIST = (\"localhost\",)\n\n-    def __init__(self, *, error: (str | None)=None):\n-        self.error = error or self.default_message\n+    default_message = \"Not a valid email address.\"\n\n-    def __call__(self, value: str) -&gt;str:\n+    def __init__(self, *, error: str | None = None):\n+        self.error = error or self.default_message  # type: str\n+\n+    def _format_error(self, value: str) -&gt; str:\n+        return self.error.format(input=value)\n+\n+    def __call__(self, value: str) -&gt; str:\n         message = self._format_error(value)\n-        if not value or '@' not in value:\n+\n+        if not value or \"@\" not in value:\n             raise ValidationError(message)\n-        user_part, domain_part = value.rsplit('@', 1)\n+\n+        user_part, domain_part = value.rsplit(\"@\", 1)\n+\n         if not self.USER_REGEX.match(user_part):\n             raise ValidationError(message)\n+\n         if domain_part not in self.DOMAIN_WHITELIST:\n             if not self.DOMAIN_REGEX.match(domain_part):\n                 try:\n-                    domain_part = domain_part.encode('idna').decode('ascii')\n+                    domain_part = domain_part.encode(\"idna\").decode(\"ascii\")\n                 except UnicodeError:\n                     pass\n                 else:\n                     if self.DOMAIN_REGEX.match(domain_part):\n                         return value\n                 raise ValidationError(message)\n+\n         return value\n\n\n@@ -192,40 +298,62 @@ class Range(Validator):\n     :param error: Error message to raise in case of a validation error.\n         Can be interpolated with `{input}`, `{min}` and `{max}`.\n     \"\"\"\n-    message_min = 'Must be {min_op} {{min}}.'\n-    message_max = 'Must be {max_op} {{max}}.'\n-    message_all = 'Must be {min_op} {{min}} and {max_op} {{max}}.'\n-    message_gte = 'greater than or equal to'\n-    message_gt = 'greater than'\n-    message_lte = 'less than or equal to'\n-    message_lt = 'less than'\n-\n-    def __init__(self, min=None, max=None, *, min_inclusive: bool=True,\n-        max_inclusive: bool=True, error: (str | None)=None):\n+\n+    message_min = \"Must be {min_op} {{min}}.\"\n+    message_max = \"Must be {max_op} {{max}}.\"\n+    message_all = \"Must be {min_op} {{min}} and {max_op} {{max}}.\"\n+\n+    message_gte = \"greater than or equal to\"\n+    message_gt = \"greater than\"\n+    message_lte = \"less than or equal to\"\n+    message_lt = \"less than\"\n+\n+    def __init__(\n+        self,\n+        min=None,\n+        max=None,\n+        *,\n+        min_inclusive: bool = True,\n+        max_inclusive: bool = True,\n+        error: str | None = None,\n+    ):\n         self.min = min\n         self.max = max\n         self.error = error\n         self.min_inclusive = min_inclusive\n         self.max_inclusive = max_inclusive\n-        self.message_min = self.message_min.format(min_op=self.message_gte if\n-            self.min_inclusive else self.message_gt)\n-        self.message_max = self.message_max.format(max_op=self.message_lte if\n-            self.max_inclusive else self.message_lt)\n-        self.message_all = self.message_all.format(min_op=self.message_gte if\n-            self.min_inclusive else self.message_gt, max_op=self.\n-            message_lte if self.max_inclusive else self.message_lt)\n-\n-    def __call__(self, value: _T) -&gt;_T:\n-        if self.min is not None and (value &lt; self.min if self.min_inclusive\n-             else value &lt;= self.min):\n-            message = (self.message_min if self.max is None else self.\n-                message_all)\n+\n+        # interpolate messages based on bound inclusivity\n+        self.message_min = self.message_min.format(\n+            min_op=self.message_gte if self.min_inclusive else self.message_gt\n+        )\n+        self.message_max = self.message_max.format(\n+            max_op=self.message_lte if self.max_inclusive else self.message_lt\n+        )\n+        self.message_all = self.message_all.format(\n+            min_op=self.message_gte if self.min_inclusive else self.message_gt,\n+            max_op=self.message_lte if self.max_inclusive else self.message_lt,\n+        )\n+\n+    def _repr_args(self) -&gt; str:\n+        return f\"min={self.min!r}, max={self.max!r}, min_inclusive={self.min_inclusive!r}, max_inclusive={self.max_inclusive!r}\"\n+\n+    def _format_error(self, value: _T, message: str) -&gt; str:\n+        return (self.error or message).format(input=value, min=self.min, max=self.max)\n+\n+    def __call__(self, value: _T) -&gt; _T:\n+        if self.min is not None and (\n+            value &lt; self.min if self.min_inclusive else value &lt;= self.min\n+        ):\n+            message = self.message_min if self.max is None else self.message_all\n             raise ValidationError(self._format_error(value, message))\n-        if self.max is not None and (value &gt; self.max if self.max_inclusive\n-             else value &gt;= self.max):\n-            message = (self.message_max if self.min is None else self.\n-                message_all)\n+\n+        if self.max is not None and (\n+            value &gt; self.max if self.max_inclusive else value &gt;= self.max\n+        ):\n+            message = self.message_max if self.min is None else self.message_all\n             raise ValidationError(self._format_error(value, message))\n+\n         return value\n\n\n@@ -243,37 +371,55 @@ class Length(Validator):\n     :param error: Error message to raise in case of a validation error.\n         Can be interpolated with `{input}`, `{min}` and `{max}`.\n     \"\"\"\n-    message_min = 'Shorter than minimum length {min}.'\n-    message_max = 'Longer than maximum length {max}.'\n-    message_all = 'Length must be between {min} and {max}.'\n-    message_equal = 'Length must be {equal}.'\n\n-    def __init__(self, min: (int | None)=None, max: (int | None)=None, *,\n-        equal: (int | None)=None, error: (str | None)=None):\n+    message_min = \"Shorter than minimum length {min}.\"\n+    message_max = \"Longer than maximum length {max}.\"\n+    message_all = \"Length must be between {min} and {max}.\"\n+    message_equal = \"Length must be {equal}.\"\n+\n+    def __init__(\n+        self,\n+        min: int | None = None,\n+        max: int | None = None,\n+        *,\n+        equal: int | None = None,\n+        error: str | None = None,\n+    ):\n         if equal is not None and any([min, max]):\n             raise ValueError(\n-                'The `equal` parameter was provided, maximum or minimum parameter must not be provided.'\n-                )\n+                \"The `equal` parameter was provided, maximum or \"\n+                \"minimum parameter must not be provided.\"\n+            )\n+\n         self.min = min\n         self.max = max\n         self.error = error\n         self.equal = equal\n\n-    def __call__(self, value: typing.Sized) -&gt;typing.Sized:\n+    def _repr_args(self) -&gt; str:\n+        return f\"min={self.min!r}, max={self.max!r}, equal={self.equal!r}\"\n+\n+    def _format_error(self, value: typing.Sized, message: str) -&gt; str:\n+        return (self.error or message).format(\n+            input=value, min=self.min, max=self.max, equal=self.equal\n+        )\n+\n+    def __call__(self, value: typing.Sized) -&gt; typing.Sized:\n         length = len(value)\n+\n         if self.equal is not None:\n             if length != self.equal:\n-                raise ValidationError(self._format_error(value, self.\n-                    message_equal))\n+                raise ValidationError(self._format_error(value, self.message_equal))\n             return value\n+\n         if self.min is not None and length &lt; self.min:\n-            message = (self.message_min if self.max is None else self.\n-                message_all)\n+            message = self.message_min if self.max is None else self.message_all\n             raise ValidationError(self._format_error(value, message))\n+\n         if self.max is not None and length &gt; self.max:\n-            message = (self.message_max if self.min is None else self.\n-                message_all)\n+            message = self.message_max if self.min is None else self.message_all\n             raise ValidationError(self._format_error(value, message))\n+\n         return value\n\n\n@@ -285,13 +431,20 @@ class Equal(Validator):\n     :param error: Error message to raise in case of a validation error.\n         Can be interpolated with `{input}` and `{other}`.\n     \"\"\"\n-    default_message = 'Must be equal to {other}.'\n\n-    def __init__(self, comparable, *, error: (str | None)=None):\n+    default_message = \"Must be equal to {other}.\"\n+\n+    def __init__(self, comparable, *, error: str | None = None):\n         self.comparable = comparable\n-        self.error = error or self.default_message\n+        self.error = error or self.default_message  # type: str\n+\n+    def _repr_args(self) -&gt; str:\n+        return f\"comparable={self.comparable!r}\"\n\n-    def __call__(self, value: _T) -&gt;_T:\n+    def _format_error(self, value: _T) -&gt; str:\n+        return self.error.format(input=value, other=self.comparable)\n+\n+    def __call__(self, value: _T) -&gt; _T:\n         if value != self.comparable:\n             raise ValidationError(self._format_error(value))\n         return value\n@@ -311,25 +464,37 @@ class Regexp(Validator):\n     :param error: Error message to raise in case of a validation error.\n         Can be interpolated with `{input}` and `{regex}`.\n     \"\"\"\n-    default_message = 'String does not match expected pattern.'\n\n-    def __init__(self, regex: (str | bytes | typing.Pattern), flags: int=0,\n-        *, error: (str | None)=None):\n-        self.regex = re.compile(regex, flags) if isinstance(regex, (str, bytes)\n-            ) else regex\n-        self.error = error or self.default_message\n+    default_message = \"String does not match expected pattern.\"\n+\n+    def __init__(\n+        self,\n+        regex: str | bytes | typing.Pattern,\n+        flags: int = 0,\n+        *,\n+        error: str | None = None,\n+    ):\n+        self.regex = (\n+            re.compile(regex, flags) if isinstance(regex, (str, bytes)) else regex\n+        )\n+        self.error = error or self.default_message  # type: str\n+\n+    def _repr_args(self) -&gt; str:\n+        return f\"regex={self.regex!r}\"\n+\n+    def _format_error(self, value: str | bytes) -&gt; str:\n+        return self.error.format(input=value, regex=self.regex.pattern)\n\n     @typing.overload\n-    def __call__(self, value: str) -&gt;str:\n-        ...\n+    def __call__(self, value: str) -&gt; str: ...\n\n     @typing.overload\n-    def __call__(self, value: bytes) -&gt;bytes:\n-        ...\n+    def __call__(self, value: bytes) -&gt; bytes: ...\n\n     def __call__(self, value):\n         if self.regex.match(value) is None:\n             raise ValidationError(self._format_error(value))\n+\n         return value\n\n\n@@ -344,17 +509,26 @@ class Predicate(Validator):\n         Can be interpolated with `{input}` and `{method}`.\n     :param kwargs: Additional keyword arguments to pass to the method.\n     \"\"\"\n-    default_message = 'Invalid input.'\n\n-    def __init__(self, method: str, *, error: (str | None)=None, **kwargs):\n+    default_message = \"Invalid input.\"\n+\n+    def __init__(self, method: str, *, error: str | None = None, **kwargs):\n         self.method = method\n-        self.error = error or self.default_message\n+        self.error = error or self.default_message  # type: str\n         self.kwargs = kwargs\n\n-    def __call__(self, value: typing.Any) -&gt;typing.Any:\n+    def _repr_args(self) -&gt; str:\n+        return f\"method={self.method!r}, kwargs={self.kwargs!r}\"\n+\n+    def _format_error(self, value: typing.Any) -&gt; str:\n+        return self.error.format(input=value, method=self.method)\n+\n+    def __call__(self, value: typing.Any) -&gt; typing.Any:\n         method = getattr(value, self.method)\n+\n         if not method(**self.kwargs):\n             raise ValidationError(self._format_error(value))\n+\n         return value\n\n\n@@ -365,19 +539,27 @@ class NoneOf(Validator):\n     :param error: Error message to raise in case of a validation error. Can be\n         interpolated using `{input}` and `{values}`.\n     \"\"\"\n-    default_message = 'Invalid input.'\n\n-    def __init__(self, iterable: typing.Iterable, *, error: (str | None)=None):\n+    default_message = \"Invalid input.\"\n+\n+    def __init__(self, iterable: typing.Iterable, *, error: str | None = None):\n         self.iterable = iterable\n-        self.values_text = ', '.join(str(each) for each in self.iterable)\n-        self.error = error or self.default_message\n+        self.values_text = \", \".join(str(each) for each in self.iterable)\n+        self.error = error or self.default_message  # type: str\n\n-    def __call__(self, value: typing.Any) -&gt;typing.Any:\n+    def _repr_args(self) -&gt; str:\n+        return f\"iterable={self.iterable!r}\"\n+\n+    def _format_error(self, value) -&gt; str:\n+        return self.error.format(input=value, values=self.values_text)\n+\n+    def __call__(self, value: typing.Any) -&gt; typing.Any:\n         try:\n             if value in self.iterable:\n                 raise ValidationError(self._format_error(value))\n         except TypeError:\n             pass\n+\n         return value\n\n\n@@ -389,26 +571,43 @@ class OneOf(Validator):\n     :param error: Error message to raise in case of a validation error. Can be\n         interpolated with `{input}`, `{choices}` and `{labels}`.\n     \"\"\"\n-    default_message = 'Must be one of: {choices}.'\n\n-    def __init__(self, choices: typing.Iterable, labels: (typing.Iterable[\n-        str] | None)=None, *, error: (str | None)=None):\n+    default_message = \"Must be one of: {choices}.\"\n+\n+    def __init__(\n+        self,\n+        choices: typing.Iterable,\n+        labels: typing.Iterable[str] | None = None,\n+        *,\n+        error: str | None = None,\n+    ):\n         self.choices = choices\n-        self.choices_text = ', '.join(str(choice) for choice in self.choices)\n+        self.choices_text = \", \".join(str(choice) for choice in self.choices)\n         self.labels = labels if labels is not None else []\n-        self.labels_text = ', '.join(str(label) for label in self.labels)\n-        self.error = error or self.default_message\n+        self.labels_text = \", \".join(str(label) for label in self.labels)\n+        self.error = error or self.default_message  # type: str\n\n-    def __call__(self, value: typing.Any) -&gt;typing.Any:\n+    def _repr_args(self) -&gt; str:\n+        return f\"choices={self.choices!r}, labels={self.labels!r}\"\n+\n+    def _format_error(self, value) -&gt; str:\n+        return self.error.format(\n+            input=value, choices=self.choices_text, labels=self.labels_text\n+        )\n+\n+    def __call__(self, value: typing.Any) -&gt; typing.Any:\n         try:\n             if value not in self.choices:\n                 raise ValidationError(self._format_error(value))\n         except TypeError as error:\n             raise ValidationError(self._format_error(value)) from error\n+\n         return value\n\n-    def options(self, valuegetter: (str | typing.Callable[[typing.Any],\n-        typing.Any])=str) -&gt;typing.Iterable[tuple[typing.Any, str]]:\n+    def options(\n+        self,\n+        valuegetter: str | typing.Callable[[typing.Any], typing.Any] = str,\n+    ) -&gt; typing.Iterable[tuple[typing.Any, str]]:\n         \"\"\"Return a generator over the (value, label) pairs, where value\n         is a string associated with each choice. This convenience method\n         is useful to populate, for instance, a form select field.\n@@ -419,7 +618,10 @@ class OneOf(Validator):\n             of an attribute of the choice objects. Defaults to `str()`\n             or `str()`.\n         \"\"\"\n-        pass\n+        valuegetter = valuegetter if callable(valuegetter) else attrgetter(valuegetter)\n+        pairs = zip_longest(self.choices, self.labels, fillvalue=\"\")\n+\n+        return ((valuegetter(choice), label) for choice, label in pairs)\n\n\n class ContainsOnly(OneOf):\n@@ -437,10 +639,15 @@ class ContainsOnly(OneOf):\n         Empty input is considered valid. Use `validate.Length(min=1) &lt;marshmallow.validate.Length&gt;`\n         to validate against empty inputs.\n     \"\"\"\n-    default_message = (\n-        'One or more of the choices you made was not in: {choices}.')\n\n-    def __call__(self, value: typing.Sequence[_T]) -&gt;typing.Sequence[_T]:\n+    default_message = \"One or more of the choices you made was not in: {choices}.\"\n+\n+    def _format_error(self, value) -&gt; str:\n+        value_text = \", \".join(str(val) for val in value)\n+        return super()._format_error(value_text)\n+\n+    def __call__(self, value: typing.Sequence[_T]) -&gt; typing.Sequence[_T]:\n+        # We can't use set.issubset because does not handle unhashable types\n         for val in value:\n             if val not in self.choices:\n                 raise ValidationError(self._format_error(value))\n@@ -457,9 +664,14 @@ class ContainsNoneOf(NoneOf):\n\n     .. versionadded:: 3.6.0\n     \"\"\"\n-    default_message = 'One or more of the choices you made was in: {values}.'\n\n-    def __call__(self, value: typing.Sequence[_T]) -&gt;typing.Sequence[_T]:\n+    default_message = \"One or more of the choices you made was in: {values}.\"\n+\n+    def _format_error(self, value) -&gt; str:\n+        value_text = \", \".join(str(val) for val in value)\n+        return super()._format_error(value_text)\n+\n+    def __call__(self, value: typing.Sequence[_T]) -&gt; typing.Sequence[_T]:\n         for val in value:\n             if val in self.iterable:\n                 raise ValidationError(self._format_error(value))\n</code></pre>"},{"location":"analysis_reference_simpy/","title":"Analysis reference simpy","text":"<p>back to reference summary</p>"},{"location":"analysis_reference_simpy/#submission-name-reference","title":"Submission Name: reference","text":""},{"location":"analysis_reference_simpy/#repository-simpy","title":"Repository: simpy","text":""},{"location":"analysis_reference_simpy/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count passed 140 total 140 collected 150 deselected 10"},{"location":"analysis_reference_simpy/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_reference_simpy/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/src/simpy/core.py b/src/simpy/core.py\nindex 10c88fb..a479855 100644\n--- a/src/simpy/core.py\n+++ b/src/simpy/core.py\n@@ -3,12 +3,37 @@ Core components for event-discrete simulation environments.\n\n \"\"\"\n from __future__ import annotations\n+\n from heapq import heappop, heappush\n from itertools import count\n from types import MethodType\n-from typing import TYPE_CHECKING, Any, Generic, Iterable, List, Optional, Tuple, Type, TypeVar, Union\n-from simpy.events import NORMAL, URGENT, AllOf, AnyOf, Event, EventPriority, Process, ProcessGenerator, Timeout\n-Infinity: float = float('inf')\n+from typing import (\n+    TYPE_CHECKING,\n+    Any,\n+    Generic,\n+    Iterable,\n+    List,\n+    Optional,\n+    Tuple,\n+    Type,\n+    TypeVar,\n+    Union,\n+)\n+\n+from simpy.events import (\n+    NORMAL,\n+    URGENT,\n+    AllOf,\n+    AnyOf,\n+    Event,\n+    EventPriority,\n+    Process,\n+    ProcessGenerator,\n+    Timeout,\n+)\n+\n+Infinity: float = float('inf')  #: Convenience alias for infinity\n+\n T = TypeVar('T')\n\n\n@@ -24,17 +49,23 @@ class BoundClass(Generic[T]):\n     def __init__(self, cls: Type[T]):\n         self.cls = cls\n\n-    def __get__(self, instance: Optional[BoundClass], owner: Optional[Type[\n-        BoundClass]]=None) -&gt;Union[Type[T], MethodType]:\n+    def __get__(\n+        self,\n+        instance: Optional[BoundClass],\n+        owner: Optional[Type[BoundClass]] = None,\n+    ) -&gt; Union[Type[T], MethodType]:\n         if instance is None:\n             return self.cls\n         return MethodType(self.cls, instance)\n\n     @staticmethod\n-    def bind_early(instance: object) -&gt;None:\n+    def bind_early(instance: object) -&gt; None:\n         \"\"\"Bind all :class:`BoundClass` attributes of the *instance's* class\n         to the instance itself to increase performance.\"\"\"\n-        pass\n+        for name, obj in instance.__class__.__dict__.items():\n+            if type(obj) is BoundClass:\n+                bound_class = getattr(instance, name)\n+                setattr(instance, name, bound_class)\n\n\n class EmptySchedule(Exception):\n@@ -46,10 +77,13 @@ class StopSimulation(Exception):\n     \"\"\"Indicates that the simulation should stop now.\"\"\"\n\n     @classmethod\n-    def callback(cls, event: Event) -&gt;None:\n+    def callback(cls, event: Event) -&gt; None:\n         \"\"\"Used as callback in :meth:`Environment.run()` to stop the simulation\n         when the *until* event occurred.\"\"\"\n-        pass\n+        if event.ok:\n+            raise cls(event.value)\n+        else:\n+            raise event._value\n\n\n SimTime = Union[int, float]\n@@ -67,50 +101,59 @@ class Environment:\n\n     \"\"\"\n\n-    def __init__(self, initial_time: SimTime=0):\n+    def __init__(self, initial_time: SimTime = 0):\n         self._now = initial_time\n-        self._queue: List[Tuple[SimTime, EventPriority, int, Event]] = []\n-        self._eid = count()\n+        self._queue: List[\n+            Tuple[SimTime, EventPriority, int, Event]\n+        ] = []  # The list of all currently scheduled events.\n+        self._eid = count()  # Counter for event IDs\n         self._active_proc: Optional[Process] = None\n+\n+        # Bind all BoundClass instances to \"self\" to improve performance.\n         BoundClass.bind_early(self)\n\n     @property\n-    def now(self) -&gt;SimTime:\n+    def now(self) -&gt; SimTime:\n         \"\"\"The current simulation time.\"\"\"\n-        pass\n+        return self._now\n\n     @property\n-    def active_process(self) -&gt;Optional[Process]:\n+    def active_process(self) -&gt; Optional[Process]:\n         \"\"\"The currently active process of the environment.\"\"\"\n-        pass\n+        return self._active_proc\n+\n     if TYPE_CHECKING:\n+        # This block is only evaluated when type checking with, e.g. Mypy.\n+        # These are the effective types of the methods created with BoundClass\n+        # magic and are thus a useful reference for SimPy users as well as for\n+        # static type checking.\n\n-        def process(self, generator: ProcessGenerator) -&gt;Process:\n+        def process(self, generator: ProcessGenerator) -&gt; Process:\n             \"\"\"Create a new :class:`~simpy.events.Process` instance for\n             *generator*.\"\"\"\n-            pass\n+            return Process(self, generator)\n\n-        def timeout(self, delay: SimTime=0, value: Optional[Any]=None\n-            ) -&gt;Timeout:\n+        def timeout(self, delay: SimTime = 0, value: Optional[Any] = None) -&gt; Timeout:\n             \"\"\"Return a new :class:`~simpy.events.Timeout` event with a *delay*\n             and, optionally, a *value*.\"\"\"\n-            pass\n+            return Timeout(self, delay, value)\n\n-        def event(self) -&gt;Event:\n+        def event(self) -&gt; Event:\n             \"\"\"Return a new :class:`~simpy.events.Event` instance.\n\n             Yielding this event suspends a process until another process\n             triggers the event.\n             \"\"\"\n-            pass\n+            return Event(self)\n\n-        def all_of(self, events: Iterable[Event]) -&gt;AllOf:\n+        def all_of(self, events: Iterable[Event]) -&gt; AllOf:\n             \"\"\"Return a :class:`~simpy.events.AllOf` condition for *events*.\"\"\"\n-            pass\n+            return AllOf(self, events)\n\n-        def any_of(self, events: Iterable[Event]) -&gt;AnyOf:\n+        def any_of(self, events: Iterable[Event]) -&gt; AnyOf:\n             \"\"\"Return a :class:`~simpy.events.AnyOf` condition for *events*.\"\"\"\n-            pass\n+            return AnyOf(self, events)\n+\n     else:\n         process = BoundClass(Process)\n         timeout = BoundClass(Timeout)\n@@ -118,25 +161,49 @@ class Environment:\n         all_of = BoundClass(AllOf)\n         any_of = BoundClass(AnyOf)\n\n-    def schedule(self, event: Event, priority: EventPriority=NORMAL, delay:\n-        SimTime=0) -&gt;None:\n+    def schedule(\n+        self,\n+        event: Event,\n+        priority: EventPriority = NORMAL,\n+        delay: SimTime = 0,\n+    ) -&gt; None:\n         \"\"\"Schedule an *event* with a given *priority* and a *delay*.\"\"\"\n-        pass\n+        heappush(self._queue, (self._now + delay, priority, next(self._eid), event))\n\n-    def peek(self) -&gt;SimTime:\n+    def peek(self) -&gt; SimTime:\n         \"\"\"Get the time of the next scheduled event. Return\n         :data:`~simpy.core.Infinity` if there is no further event.\"\"\"\n-        pass\n+        try:\n+            return self._queue[0][0]\n+        except IndexError:\n+            return Infinity\n\n-    def step(self) -&gt;None:\n+    def step(self) -&gt; None:\n         \"\"\"Process the next event.\n\n         Raise an :exc:`EmptySchedule` if no further events are available.\n\n         \"\"\"\n-        pass\n-\n-    def run(self, until: Optional[Union[SimTime, Event]]=None) -&gt;Optional[Any]:\n+        try:\n+            self._now, _, _, event = heappop(self._queue)\n+        except IndexError:\n+            raise EmptySchedule from None\n+\n+        # Process callbacks of the event. Set the events callbacks to None\n+        # immediately to prevent concurrent modifications.\n+        callbacks, event.callbacks = event.callbacks, None  # type: ignore\n+        for callback in callbacks:\n+            callback(event)\n+\n+        if not event._ok and not hasattr(event, '_defused'):\n+            # The event has failed and has not been defused. Crash the\n+            # environment.\n+            # Create a copy of the failure exception with a new traceback.\n+            exc = type(event._value)(*event._value.args)\n+            exc.__cause__ = event._value\n+            raise exc\n+\n+    def run(self, until: Optional[Union[SimTime, Event]] = None) -&gt; Optional[Any]:\n         \"\"\"Executes :meth:`step()` until the given criterion *until* is met.\n\n         - If it is ``None`` (which is the default), this method will return\n@@ -151,4 +218,39 @@ class Environment:\n           until the environment's time reaches *until*.\n\n         \"\"\"\n-        pass\n+        if until is not None:\n+            if not isinstance(until, Event):\n+                # Assume that *until* is a number if it is not None and\n+                # not an event.  Create a Timeout(until) in this case.\n+                at: SimTime = until if isinstance(until, int) else float(until)\n+\n+                if at &lt;= self.now:\n+                    raise ValueError(\n+                        f'until ({at}) must be greater than the current simulation time'\n+                    )\n+\n+                # Schedule the event before all regular timeouts.\n+                until = Event(self)\n+                until._ok = True\n+                until._value = None\n+                self.schedule(until, URGENT, at - self.now)\n+\n+            elif until.callbacks is None:\n+                # Until event has already been processed.\n+                return until.value\n+\n+            until.callbacks.append(StopSimulation.callback)\n+\n+        try:\n+            while True:\n+                self.step()\n+        except StopSimulation as exc:\n+            return exc.args[0]  # == until.value\n+        except EmptySchedule:\n+            if until is not None:\n+                assert not until.triggered\n+                raise RuntimeError(\n+                    f'No scheduled events left but \"until\" event was not '\n+                    f'triggered: {until}'\n+                ) from None\n+        return None\ndiff --git a/src/simpy/events.py b/src/simpy/events.py\nindex 128ed75..28d4433 100644\n--- a/src/simpy/events.py\n+++ b/src/simpy/events.py\n@@ -14,14 +14,34 @@ used, there are several specialized subclasses of it.\n\n \"\"\"\n from __future__ import annotations\n-from typing import TYPE_CHECKING, Any, Callable, Dict, Generator, Iterable, Iterator, List, NewType, Optional, Tuple, TypeVar\n+\n+from typing import (\n+    TYPE_CHECKING,\n+    Any,\n+    Callable,\n+    Dict,\n+    Generator,\n+    Iterable,\n+    Iterator,\n+    List,\n+    NewType,\n+    Optional,\n+    Tuple,\n+    TypeVar,\n+)\n+\n from simpy.exceptions import Interrupt\n+\n if TYPE_CHECKING:\n     from types import FrameType\n+\n     from simpy.core import Environment, SimTime\n+\n PENDING: object = object()\n \"\"\"Unique object to identify pending values of events.\"\"\"\n+\n EventPriority = NewType('EventPriority', int)\n+\n URGENT: EventPriority = EventPriority(0)\n \"\"\"Priority of interrupts and process initialization events.\"\"\"\n NORMAL: EventPriority = EventPriority(1)\n@@ -58,6 +78,7 @@ class Event:\n     of them.\n\n     \"\"\"\n+\n     _ok: bool\n     _defused: bool\n     _value: Any = PENDING\n@@ -68,29 +89,29 @@ class Event:\n         self.callbacks: EventCallbacks = []\n         \"\"\"List of functions that are called when the event is processed.\"\"\"\n\n-    def __repr__(self) -&gt;str:\n+    def __repr__(self) -&gt; str:\n         \"\"\"Return the description of the event (see :meth:`_desc`) with the id\n         of the event.\"\"\"\n         return f'&lt;{self._desc()} object at {id(self):#x}&gt;'\n\n-    def _desc(self) -&gt;str:\n+    def _desc(self) -&gt; str:\n         \"\"\"Return a string *Event()*.\"\"\"\n-        pass\n+        return f'{self.__class__.__name__}()'\n\n     @property\n-    def triggered(self) -&gt;bool:\n+    def triggered(self) -&gt; bool:\n         \"\"\"Becomes ``True`` if the event has been triggered and its callbacks\n         are about to be invoked.\"\"\"\n-        pass\n+        return self._value is not PENDING\n\n     @property\n-    def processed(self) -&gt;bool:\n+    def processed(self) -&gt; bool:\n         \"\"\"Becomes ``True`` if the event has been processed (e.g., its\n         callbacks have been invoked).\"\"\"\n-        pass\n+        return self.callbacks is None\n\n     @property\n-    def ok(self) -&gt;bool:\n+    def ok(self) -&gt; bool:\n         \"\"\"Becomes ``True`` when the event has been triggered successfully.\n\n         A \"successful\" event is one triggered with :meth:`succeed()`.\n@@ -98,10 +119,10 @@ class Event:\n         :raises AttributeError: if accessed before the event is triggered.\n\n         \"\"\"\n-        pass\n+        return self._ok\n\n     @property\n-    def defused(self) -&gt;bool:\n+    def defused(self) -&gt; bool:\n         \"\"\"Becomes ``True`` when the failed event's exception is \"defused\".\n\n         When an event fails (i.e. with :meth:`fail()`), the failed event's\n@@ -115,10 +136,14 @@ class Event:\n         processed by the :class:`~simpy.core.Environment`.\n\n         \"\"\"\n-        pass\n+        return hasattr(self, '_defused')\n+\n+    @defused.setter\n+    def defused(self, value: bool) -&gt; None:\n+        self._defused = True\n\n     @property\n-    def value(self) -&gt;Optional[Any]:\n+    def value(self) -&gt; Optional[Any]:\n         \"\"\"The value of the event if it is available.\n\n         The value is available when the event has been triggered.\n@@ -126,9 +151,11 @@ class Event:\n         Raises :exc:`AttributeError` if the value is not yet available.\n\n         \"\"\"\n-        pass\n+        if self._value is PENDING:\n+            raise AttributeError(f'Value of {self} is not yet available')\n+        return self._value\n\n-    def trigger(self, event: Event) -&gt;None:\n+    def trigger(self, event: Event) -&gt; None:\n         \"\"\"Trigger the event with the state and value of the provided *event*.\n         Return *self* (this event instance).\n\n@@ -136,18 +163,26 @@ class Event:\n         chain reactions.\n\n         \"\"\"\n-        pass\n+        self._ok = event._ok\n+        self._value = event._value\n+        self.env.schedule(self)\n\n-    def succeed(self, value: Optional[Any]=None) -&gt;Event:\n+    def succeed(self, value: Optional[Any] = None) -&gt; Event:\n         \"\"\"Set the event's value, mark it as successful and schedule it for\n         processing by the environment. Returns the event instance.\n\n         Raises :exc:`RuntimeError` if this event has already been triggerd.\n\n         \"\"\"\n-        pass\n+        if self._value is not PENDING:\n+            raise RuntimeError(f'{self} has already been triggered')\n\n-    def fail(self, exception: Exception) -&gt;Event:\n+        self._ok = True\n+        self._value = value\n+        self.env.schedule(self)\n+        return self\n+\n+    def fail(self, exception: Exception) -&gt; Event:\n         \"\"\"Set *exception* as the events value, mark it as failed and schedule\n         it for processing by the environment. Returns the event instance.\n\n@@ -156,14 +191,21 @@ class Event:\n         Raises :exc:`RuntimeError` if this event has already been triggered.\n\n         \"\"\"\n-        pass\n+        if self._value is not PENDING:\n+            raise RuntimeError(f'{self} has already been triggered')\n+        if not isinstance(exception, BaseException):\n+            raise TypeError(f'{exception} is not an exception.')\n+        self._ok = False\n+        self._value = exception\n+        self.env.schedule(self)\n+        return self\n\n-    def __and__(self, other: Event) -&gt;Condition:\n+    def __and__(self, other: Event) -&gt; Condition:\n         \"\"\"Return a :class:`~simpy.events.Condition` that will be triggered if\n         both, this event and *other*, have been processed.\"\"\"\n         return Condition(self.env, Condition.all_events, [self, other])\n\n-    def __or__(self, other: Event) -&gt;Condition:\n+    def __or__(self, other: Event) -&gt; Condition:\n         \"\"\"Return a :class:`~simpy.events.Condition` that will be triggered if\n         either this event or *other* have been processed (or even both, if they\n         happened concurrently).\"\"\"\n@@ -184,10 +226,16 @@ class Timeout(Event):\n\n     \"\"\"\n\n-    def __init__(self, env: Environment, delay: SimTime, value: Optional[\n-        Any]=None):\n+    def __init__(\n+        self,\n+        env: Environment,\n+        delay: SimTime,\n+        value: Optional[Any] = None,\n+    ):\n         if delay &lt; 0:\n             raise ValueError(f'Negative delay {delay}')\n+        # NOTE: The following initialization code is inlined from\n+        # Event.__init__() for performance reasons.\n         self.env = env\n         self.callbacks: EventCallbacks = []\n         self._value = value\n@@ -195,9 +243,10 @@ class Timeout(Event):\n         self._ok = True\n         env.schedule(self, NORMAL, delay)\n\n-    def _desc(self) -&gt;str:\n+    def _desc(self) -&gt; str:\n         \"\"\"Return a string *Timeout(delay[, value=value])*.\"\"\"\n-        pass\n+        value_str = '' if self._value is None else f', value={self.value}'\n+        return f'{self.__class__.__name__}({self._delay}{value_str})'\n\n\n class Initialize(Event):\n@@ -208,9 +257,15 @@ class Initialize(Event):\n     \"\"\"\n\n     def __init__(self, env: Environment, process: Process):\n+        # NOTE: The following initialization code is inlined from\n+        # Event.__init__() for performance reasons.\n         self.env = env\n         self.callbacks: EventCallbacks = [process._resume]\n         self._value: Any = None\n+\n+        # The initialization events needs to be scheduled as urgent so that it\n+        # will be handled before interrupts. Otherwise, a process whose\n+        # generator has not yet been started could be interrupted.\n         self._ok = True\n         env.schedule(self, URGENT)\n\n@@ -224,19 +279,36 @@ class Interruption(Event):\n     \"\"\"\n\n     def __init__(self, process: Process, cause: Optional[Any]):\n+        # NOTE: The following initialization code is inlined from\n+        # Event.__init__() for performance reasons.\n         self.env = process.env\n         self.callbacks: EventCallbacks = [self._interrupt]\n         self._value = Interrupt(cause)\n         self._ok = False\n         self._defused = True\n+\n         if process._value is not PENDING:\n-            raise RuntimeError(\n-                f'{process} has terminated and cannot be interrupted.')\n+            raise RuntimeError(f'{process} has terminated and cannot be interrupted.')\n+\n         if process is self.env.active_process:\n             raise RuntimeError('A process is not allowed to interrupt itself.')\n+\n         self.process = process\n         self.env.schedule(self, URGENT)\n\n+    def _interrupt(self, event: Event) -&gt; None:\n+        # Ignore dead processes. Multiple concurrently scheduled interrupts\n+        # cause this situation. If the process dies while handling the first\n+        # one, the remaining interrupts must be ignored.\n+        if self.process._value is not PENDING:\n+            return\n+\n+        # A process never expects an interrupt and is always waiting for a\n+        # target event. Remove the process from the callbacks of the target.\n+        self.process._target.callbacks.remove(self.process._resume)\n+\n+        self.process._resume(self)\n+\n\n ProcessGenerator = Generator[Event, Any, Any]\n\n@@ -259,37 +331,50 @@ class Process(Event):\n\n     def __init__(self, env: Environment, generator: ProcessGenerator):\n         if not hasattr(generator, 'throw'):\n+            # Implementation note: Python implementations differ in the\n+            # generator types they provide. Cython adds its own generator type\n+            # in addition to the CPython type, which renders a type check\n+            # impractical. To work around this issue, we check for attribute\n+            # name instead of type and optimistically assume that all objects\n+            # with a ``throw`` attribute are generators.\n+            # Remove this workaround if it causes issues in production!\n             raise ValueError(f'{generator} is not a generator.')\n+\n+        # NOTE: The following initialization code is inlined from\n+        # Event.__init__() for performance reasons.\n         self.env = env\n         self.callbacks: EventCallbacks = []\n+\n         self._generator = generator\n+\n+        # Schedule the start of the execution of the process.\n         self._target: Event = Initialize(env, self)\n\n-    def _desc(self) -&gt;str:\n+    def _desc(self) -&gt; str:\n         \"\"\"Return a string *Process(process_func_name)*.\"\"\"\n-        pass\n+        return f'{self.__class__.__name__}({self.name})'\n\n     @property\n-    def target(self) -&gt;Event:\n+    def target(self) -&gt; Event:\n         \"\"\"The event that the process is currently waiting for.\n\n         Returns ``None`` if the process is dead, or it is currently being\n         interrupted.\n\n         \"\"\"\n-        pass\n+        return self._target\n\n     @property\n-    def name(self) -&gt;str:\n+    def name(self) -&gt; str:\n         \"\"\"Name of the function used to start the process.\"\"\"\n-        pass\n+        return self._generator.__name__  # type: ignore\n\n     @property\n-    def is_alive(self) -&gt;bool:\n+    def is_alive(self) -&gt; bool:\n         \"\"\"``True`` until the process generator exits.\"\"\"\n-        pass\n+        return self._value is PENDING\n\n-    def interrupt(self, cause: Optional[Any]=None) -&gt;None:\n+    def interrupt(self, cause: Optional[Any] = None) -&gt; None:\n         \"\"\"Interrupt this process optionally providing a *cause*.\n\n         A process cannot be interrupted if it already terminated. A process can\n@@ -297,13 +382,69 @@ class Process(Event):\n         cases.\n\n         \"\"\"\n-        pass\n+        Interruption(self, cause)\n\n-    def _resume(self, event: Event) -&gt;None:\n+    def _resume(self, event: Event) -&gt; None:\n         \"\"\"Resumes the execution of the process with the value of *event*. If\n         the process generator exits, the process itself will get triggered with\n         the return value or the exception of the generator.\"\"\"\n-        pass\n+        # Mark the current process as active.\n+        self.env._active_proc = self\n+\n+        while True:\n+            # Get next event from process\n+            try:\n+                if event._ok:\n+                    event = self._generator.send(event._value)\n+                else:\n+                    # The process has no choice but to handle the failed event\n+                    # (or fail itself).\n+                    event._defused = True\n+\n+                    # Create an exclusive copy of the exception for this\n+                    # process to prevent traceback modifications by other\n+                    # processes.\n+                    exc = type(event._value)(*event._value.args)\n+                    exc.__cause__ = event._value\n+                    event = self._generator.throw(exc)\n+            except StopIteration as e:\n+                # Process has terminated.\n+                event = None  # type: ignore\n+                self._ok = True\n+                self._value = e.args[0] if len(e.args) else None\n+                self.env.schedule(self)\n+                break\n+            except BaseException as e:\n+                # Process has failed.\n+                event = None  # type: ignore\n+                self._ok = False\n+                # Strip the frame of this function from the traceback as it\n+                # does not add any useful information.\n+                e.__traceback__ = e.__traceback__.tb_next  # type: ignore\n+                self._value = e\n+                self.env.schedule(self)\n+                break\n+\n+            # Process returned another event to wait upon.\n+            try:\n+                # Be optimistic and blindly access the callbacks attribute.\n+                if event.callbacks is not None:\n+                    # The event has not yet been triggered. Register callback\n+                    # to resume the process if that happens.\n+                    event.callbacks.append(self._resume)\n+                    break\n+            except AttributeError:\n+                # Our optimism didn't work out, figure out what went wrong and\n+                # inform the user.\n+                if hasattr(event, 'callbacks'):\n+                    raise\n+\n+                msg = f'Invalid yield value \"{event}\"'\n+                descr = _describe_frame(self._generator.gi_frame)\n+                raise RuntimeError(f'\\n{descr}{msg}') from None\n+\n+        self._target = event\n+        self.env._active_proc = None\n\n\n class ConditionValue:\n@@ -311,18 +452,19 @@ class ConditionValue:\n     dict-like access to the triggered events and their values. The events are\n     ordered by their occurrences in the condition.\"\"\"\n\n-    def __init__(self) -&gt;None:\n+    def __init__(self) -&gt; None:\n         self.events: List[Event] = []\n\n-    def __getitem__(self, key: Event) -&gt;Any:\n+    def __getitem__(self, key: Event) -&gt; Any:\n         if key not in self.events:\n             raise KeyError(str(key))\n+\n         return key._value\n\n-    def __contains__(self, key: Event) -&gt;bool:\n+    def __contains__(self, key: Event) -&gt; bool:\n         return key in self.events\n\n-    def __eq__(self, other: object) -&gt;bool:\n+    def __eq__(self, other: object) -&gt; bool:\n         if isinstance(other, ConditionValue):\n             return self.events == other.events\n         elif isinstance(other, dict):\n@@ -330,12 +472,24 @@ class ConditionValue:\n         else:\n             return NotImplemented\n\n-    def __repr__(self) -&gt;str:\n+    def __repr__(self) -&gt; str:\n         return f'&lt;ConditionValue {self.todict()}&gt;'\n\n-    def __iter__(self) -&gt;Iterator[Event]:\n+    def __iter__(self) -&gt; Iterator[Event]:\n         return self.keys()\n\n+    def keys(self) -&gt; Iterator[Event]:\n+        return (event for event in self.events)\n+\n+    def values(self) -&gt; Iterator[Any]:\n+        return (event._value for event in self.events)\n+\n+    def items(self) -&gt; Iterator[Tuple[Event, Any]]:\n+        return ((event, event._value) for event in self.events)\n+\n+    def todict(self) -&gt; Dict[Event, Any]:\n+        return {event: event._value for event in self.events}\n+\n\n class Condition(Event):\n     \"\"\"An event that gets triggered once the condition function *evaluate*\n@@ -359,42 +513,64 @@ class Condition(Event):\n\n     \"\"\"\n\n-    def __init__(self, env: Environment, evaluate: Callable[[Tuple[Event,\n-        ...], int], bool], events: Iterable[Event]):\n+    def __init__(\n+        self,\n+        env: Environment,\n+        evaluate: Callable[[Tuple[Event, ...], int], bool],\n+        events: Iterable[Event],\n+    ):\n         super().__init__(env)\n         self._evaluate = evaluate\n         self._events = tuple(events)\n         self._count = 0\n+\n         if not self._events:\n+            # Immediately succeed if no events are provided.\n             self.succeed(ConditionValue())\n             return\n+\n+        # Check if events belong to the same environment.\n         for event in self._events:\n             if self.env != event.env:\n                 raise ValueError(\n                     'It is not allowed to mix events from different environments'\n-                    )\n+                )\n+\n+        # Check if the condition is met for each processed event. Attach\n+        # _check() as a callback otherwise.\n         for event in self._events:\n             if event.callbacks is None:\n                 self._check(event)\n             else:\n                 event.callbacks.append(self._check)\n+\n+        # Register a callback which will build the value of this condition\n+        # after it has been triggered.\n         assert isinstance(self.callbacks, list)\n         self.callbacks.append(self._build_value)\n\n-    def _desc(self) -&gt;str:\n+    def _desc(self) -&gt; str:\n         \"\"\"Return a string *Condition(evaluate, [events])*.\"\"\"\n-        pass\n+        return f'{self.__class__.__name__}({self._evaluate.__name__}, {self._events})'\n\n-    def _populate_value(self, value: ConditionValue) -&gt;None:\n+    def _populate_value(self, value: ConditionValue) -&gt; None:\n         \"\"\"Populate the *value* by recursively visiting all nested\n         conditions.\"\"\"\n-        pass\n\n-    def _build_value(self, event: Event) -&gt;None:\n+        for event in self._events:\n+            if isinstance(event, Condition):\n+                event._populate_value(value)\n+            elif event.callbacks is None:\n+                value.events.append(event)\n+\n+    def _build_value(self, event: Event) -&gt; None:\n         \"\"\"Build the value of this condition.\"\"\"\n-        pass\n+        self._remove_check_callbacks()\n+        if event._ok:\n+            self._value = ConditionValue()\n+            self._populate_value(self._value)\n\n-    def _remove_check_callbacks(self) -&gt;None:\n+    def _remove_check_callbacks(self) -&gt; None:\n         \"\"\"Remove _check() callbacks from events recursively.\n\n         Once the condition has triggered, the condition's events no longer need\n@@ -403,24 +579,40 @@ class Condition(Event):\n         untriggered events.\n\n         \"\"\"\n-        pass\n+        for event in self._events:\n+            if event.callbacks and self._check in event.callbacks:\n+                event.callbacks.remove(self._check)\n+            if isinstance(event, Condition):\n+                event._remove_check_callbacks()\n\n-    def _check(self, event: Event) -&gt;None:\n+    def _check(self, event: Event) -&gt; None:\n         \"\"\"Check if the condition was already met and schedule the *event* if\n         so.\"\"\"\n-        pass\n+        if self._value is not PENDING:\n+            return\n+\n+        self._count += 1\n+\n+        if not event._ok:\n+            # Abort if the event has failed.\n+            event._defused = True\n+            self.fail(event._value)\n+        elif self._evaluate(self._events, self._count):\n+            # The condition has been met. The _build_value() callback will\n+            # populate the ConditionValue once this condition is processed.\n+            self.succeed()\n\n     @staticmethod\n-    def all_events(events: Tuple[Event, ...], count: int) -&gt;bool:\n+    def all_events(events: Tuple[Event, ...], count: int) -&gt; bool:\n         \"\"\"An evaluation function that returns ``True`` if all *events* have\n         been triggered.\"\"\"\n-        pass\n+        return len(events) == count\n\n     @staticmethod\n-    def any_events(events: Tuple[Event, ...], count: int) -&gt;bool:\n+    def any_events(events: Tuple[Event, ...], count: int) -&gt; bool:\n         \"\"\"An evaluation function that returns ``True`` if at least one of\n         *events* has been triggered.\"\"\"\n-        pass\n+        return count &gt; 0 or len(events) == 0\n\n\n class AllOf(Condition):\n@@ -445,6 +637,16 @@ class AnyOf(Condition):\n         super().__init__(env, Condition.any_events, events)\n\n\n-def _describe_frame(frame: FrameType) -&gt;str:\n+def _describe_frame(frame: FrameType) -&gt; str:\n     \"\"\"Print filename, line number and function name of a stack frame.\"\"\"\n-    pass\n+    filename, name = frame.f_code.co_filename, frame.f_code.co_name\n+    lineno = frame.f_lineno\n+\n+    with open(filename) as f:\n+        for no, line in enumerate(f):\n+            if no + 1 == lineno:\n+                return (\n+                    f'  File \"{filename}\", line {lineno}, in {name}\\n'\n+                    f'    {line.strip()}\\n'\n+                )\n+        return f'  File \"{filename}\", line {lineno}, in {name}\\n'\ndiff --git a/src/simpy/exceptions.py b/src/simpy/exceptions.py\nindex d45300e..5bbde43 100644\n--- a/src/simpy/exceptions.py\n+++ b/src/simpy/exceptions.py\n@@ -3,6 +3,7 @@ SimPy specific exceptions.\n\n \"\"\"\n from __future__ import annotations\n+\n from typing import Any, Optional\n\n\n@@ -25,10 +26,10 @@ class Interrupt(SimPyException):\n     def __init__(self, cause: Optional[Any]):\n         super().__init__(cause)\n\n-    def __str__(self) -&gt;str:\n+    def __str__(self) -&gt; str:\n         return f'{self.__class__.__name__}({self.cause!r})'\n\n     @property\n-    def cause(self) -&gt;Optional[Any]:\n+    def cause(self) -&gt; Optional[Any]:\n         \"\"\"The cause of the interrupt or ``None`` if no cause was provided.\"\"\"\n-        pass\n+        return self.args[0]\ndiff --git a/src/simpy/resources/base.py b/src/simpy/resources/base.py\nindex a7d0b96..4cf9ee1 100644\n--- a/src/simpy/resources/base.py\n+++ b/src/simpy/resources/base.py\n@@ -7,11 +7,25 @@ These events are triggered once the request has been completed.\n\n \"\"\"\n from __future__ import annotations\n-from typing import TYPE_CHECKING, ClassVar, ContextManager, Generic, MutableSequence, Optional, Type, TypeVar, Union\n+\n+from typing import (\n+    TYPE_CHECKING,\n+    ClassVar,\n+    ContextManager,\n+    Generic,\n+    MutableSequence,\n+    Optional,\n+    Type,\n+    TypeVar,\n+    Union,\n+)\n+\n from simpy.core import BoundClass, Environment\n from simpy.events import Event, Process\n+\n if TYPE_CHECKING:\n     from types import TracebackType\n+\n ResourceType = TypeVar('ResourceType', bound='BaseResource')\n\n\n@@ -34,20 +48,24 @@ class Put(Event, ContextManager['Put'], Generic[ResourceType]):\n         super().__init__(resource._env)\n         self.resource = resource\n         self.proc: Optional[Process] = self.env.active_process\n-        resource.put_queue.append(self)\n+\n+        resource.put_queue.append(self)  # pyright: ignore\n         self.callbacks.append(resource._trigger_get)\n         resource._trigger_put(None)\n\n-    def __enter__(self) -&gt;Put:\n+    def __enter__(self) -&gt; Put:\n         return self\n\n-    def __exit__(self, exc_type: Optional[Type[BaseException]], exc_value:\n-        Optional[BaseException], traceback: Optional[TracebackType]\n-        ) -&gt;Optional[bool]:\n+    def __exit__(\n+        self,\n+        exc_type: Optional[Type[BaseException]],\n+        exc_value: Optional[BaseException],\n+        traceback: Optional[TracebackType],\n+    ) -&gt; Optional[bool]:\n         self.cancel()\n         return None\n\n-    def cancel(self) -&gt;None:\n+    def cancel(self) -&gt; None:\n         \"\"\"Cancel this put request.\n\n         This method has to be called if the put request must be aborted, for\n@@ -58,7 +76,8 @@ class Put(Event, ContextManager['Put'], Generic[ResourceType]):\n         method is called automatically.\n\n         \"\"\"\n-        pass\n+        if not self.triggered:\n+            self.resource.put_queue.remove(self)  # pyright: ignore\n\n\n class Get(Event, ContextManager['Get'], Generic[ResourceType]):\n@@ -80,20 +99,24 @@ class Get(Event, ContextManager['Get'], Generic[ResourceType]):\n         super().__init__(resource._env)\n         self.resource = resource\n         self.proc = self.env.active_process\n-        resource.get_queue.append(self)\n+\n+        resource.get_queue.append(self)  # pyright: ignore\n         self.callbacks.append(resource._trigger_put)\n         resource._trigger_get(None)\n\n-    def __enter__(self) -&gt;Get:\n+    def __enter__(self) -&gt; Get:\n         return self\n\n-    def __exit__(self, exc_type: Optional[Type[BaseException]], exc_value:\n-        Optional[BaseException], traceback: Optional[TracebackType]\n-        ) -&gt;Optional[bool]:\n+    def __exit__(\n+        self,\n+        exc_type: Optional[Type[BaseException]],\n+        exc_value: Optional[BaseException],\n+        traceback: Optional[TracebackType],\n+    ) -&gt; Optional[bool]:\n         self.cancel()\n         return None\n\n-    def cancel(self) -&gt;None:\n+    def cancel(self) -&gt; None:\n         \"\"\"Cancel this get request.\n\n         This method has to be called if the get request must be aborted, for\n@@ -104,7 +127,8 @@ class Get(Event, ContextManager['Get'], Generic[ResourceType]):\n         method is called automatically.\n\n         \"\"\"\n-        pass\n+        if not self.triggered:\n+            self.resource.get_queue.remove(self)  # pyright: ignore\n\n\n PutType = TypeVar('PutType', bound=Put)\n@@ -129,11 +153,13 @@ class BaseResource(Generic[PutType, GetType]):\n       ``_do_get()`` and ``_do_put()``.\n\n     \"\"\"\n+\n     PutQueue: ClassVar[Type[MutableSequence]] = list\n     \"\"\"The type to be used for the :attr:`put_queue`. It is a plain\n     :class:`list` by default. The type must support index access (e.g.\n     ``__getitem__()`` and ``__len__()``) as well as provide ``append()`` and\n     ``pop()`` operations.\"\"\"\n+\n     GetQueue: ClassVar[Type[MutableSequence]] = list\n     \"\"\"The type to be used for the :attr:`get_queue`. It is a plain\n     :class:`list` by default. The type must support index access (e.g.\n@@ -147,30 +173,34 @@ class BaseResource(Generic[PutType, GetType]):\n         \"\"\"Queue of pending *put* requests.\"\"\"\n         self.get_queue: MutableSequence[GetType] = self.GetQueue()\n         \"\"\"Queue of pending *get* requests.\"\"\"\n+\n+        # Bind event constructors as methods\n         BoundClass.bind_early(self)\n\n     @property\n-    def capacity(self) -&gt;Union[float, int]:\n+    def capacity(self) -&gt; Union[float, int]:\n         \"\"\"Maximum capacity of the resource.\"\"\"\n-        pass\n+        return self._capacity\n+\n     if TYPE_CHECKING:\n\n-        def put(self) -&gt;Put:\n+        def put(self) -&gt; Put:\n             \"\"\"Request to put something into the resource and return a\n             :class:`Put` event, which gets triggered once the request\n             succeeds.\"\"\"\n-            pass\n+            return Put(self)\n\n-        def get(self) -&gt;Get:\n+        def get(self) -&gt; Get:\n             \"\"\"Request to get something from the resource and return a\n             :class:`Get` event, which gets triggered once the request\n             succeeds.\"\"\"\n-            pass\n+            return Get(self)\n+\n     else:\n         put = BoundClass(Put)\n         get = BoundClass(Get)\n\n-    def _do_put(self, event: PutType) -&gt;Optional[bool]:\n+    def _do_put(self, event: PutType) -&gt; Optional[bool]:\n         \"\"\"Perform the *put* operation.\n\n         This method needs to be implemented by subclasses. If the conditions\n@@ -181,9 +211,9 @@ class BaseResource(Generic[PutType, GetType]):\n         :attr:`put_queue`, as long as the return value does not evaluate\n         ``False``.\n         \"\"\"\n-        pass\n+        raise NotImplementedError(self)\n\n-    def _trigger_put(self, get_event: Optional[GetType]) -&gt;None:\n+    def _trigger_put(self, get_event: Optional[GetType]) -&gt; None:\n         \"\"\"This method is called once a new put event has been created or a get\n         event has been processed.\n\n@@ -191,9 +221,24 @@ class BaseResource(Generic[PutType, GetType]):\n         calls :meth:`_do_put` to check if the conditions for the event are met.\n         If :meth:`_do_put` returns ``False``, the iteration is stopped early.\n         \"\"\"\n-        pass\n\n-    def _do_get(self, event: GetType) -&gt;Optional[bool]:\n+        # Maintain queue invariant: All put requests must be untriggered.\n+        # This code is not very pythonic because the queue interface should be\n+        # simple (only append(), pop(), __getitem__() and __len__() are\n+        # required).\n+        idx = 0\n+        while idx &lt; len(self.put_queue):\n+            put_event = self.put_queue[idx]\n+            proceed = self._do_put(put_event)\n+            if not put_event.triggered:\n+                idx += 1\n+            elif self.put_queue.pop(idx) != put_event:\n+                raise RuntimeError('Put queue invariant violated')\n+\n+            if not proceed:\n+                break\n+\n+    def _do_get(self, event: GetType) -&gt; Optional[bool]:\n         \"\"\"Perform the *get* operation.\n\n         This method needs to be implemented by subclasses. If the conditions\n@@ -204,9 +249,9 @@ class BaseResource(Generic[PutType, GetType]):\n         :attr:`get_queue`, as long as the return value does not evaluate\n         ``False``.\n         \"\"\"\n-        pass\n+        raise NotImplementedError(self)\n\n-    def _trigger_get(self, put_event: Optional[PutType]) -&gt;None:\n+    def _trigger_get(self, put_event: Optional[PutType]) -&gt; None:\n         \"\"\"Trigger get events.\n\n         This method is called once a new get event has been created or a put\n@@ -216,4 +261,19 @@ class BaseResource(Generic[PutType, GetType]):\n         calls :meth:`_do_get` to check if the conditions for the event are met.\n         If :meth:`_do_get` returns ``False``, the iteration is stopped early.\n         \"\"\"\n-        pass\n+\n+        # Maintain queue invariant: All get requests must be untriggered.\n+        # This code is not very pythonic because the queue interface should be\n+        # simple (only append(), pop(), __getitem__() and __len__() are\n+        # required).\n+        idx = 0\n+        while idx &lt; len(self.get_queue):\n+            get_event = self.get_queue[idx]\n+            proceed = self._do_get(get_event)\n+            if not get_event.triggered:\n+                idx += 1\n+            elif self.get_queue.pop(idx) != get_event:\n+                raise RuntimeError('Get queue invariant violated')\n+\n+            if not proceed:\n+                break\ndiff --git a/src/simpy/resources/container.py b/src/simpy/resources/container.py\nindex 00aa6de..8fb6a2a 100644\n--- a/src/simpy/resources/container.py\n+++ b/src/simpy/resources/container.py\n@@ -8,9 +8,12 @@ fuel tanks.\n\n \"\"\"\n from __future__ import annotations\n+\n from typing import TYPE_CHECKING, Optional, Union\n+\n from simpy.core import BoundClass, Environment\n from simpy.resources import base\n+\n ContainerAmount = Union[int, float]\n\n\n@@ -27,6 +30,7 @@ class ContainerPut(base.Put):\n             raise ValueError(f'amount(={amount}) must be &gt; 0.')\n         self.amount = amount\n         \"\"\"The amount of matter to be put into the container.\"\"\"\n+\n         super().__init__(container)\n\n\n@@ -43,6 +47,7 @@ class ContainerGet(base.Get):\n             raise ValueError(f'amount(={amount}) must be &gt; 0.')\n         self.amount = amount\n         \"\"\"The amount of matter to be taken out of the container.\"\"\"\n+\n         super().__init__(container)\n\n\n@@ -63,30 +68,58 @@ class Container(base.BaseResource):\n\n     \"\"\"\n\n-    def __init__(self, env: Environment, capacity: ContainerAmount=float(\n-        'inf'), init: ContainerAmount=0):\n+    def __init__(\n+        self,\n+        env: Environment,\n+        capacity: ContainerAmount = float('inf'),\n+        init: ContainerAmount = 0,\n+    ):\n         if capacity &lt;= 0:\n             raise ValueError('\"capacity\" must be &gt; 0.')\n         if init &lt; 0:\n             raise ValueError('\"init\" must be &gt;= 0.')\n         if init &gt; capacity:\n             raise ValueError('\"init\" must be &lt;= \"capacity\".')\n+\n         super().__init__(env, capacity)\n+\n         self._level = init\n\n     @property\n-    def level(self) -&gt;ContainerAmount:\n+    def level(self) -&gt; ContainerAmount:\n         \"\"\"The current amount of the matter in the container.\"\"\"\n-        pass\n+        return self._level\n+\n     if TYPE_CHECKING:\n\n-        def put(self, amount: ContainerAmount) -&gt;ContainerPut:\n+        def put(  # type: ignore[override]\n+            self, amount: ContainerAmount\n+        ) -&gt; ContainerPut:\n             \"\"\"Request to put *amount* of matter into the container.\"\"\"\n-            pass\n+            return ContainerPut(self, amount)\n\n-        def get(self, amount: ContainerAmount) -&gt;ContainerGet:\n+        def get(  # type: ignore[override]\n+            self, amount: ContainerAmount\n+        ) -&gt; ContainerGet:\n             \"\"\"Request to get *amount* of matter out of the container.\"\"\"\n-            pass\n+            return ContainerGet(self, amount)\n+\n     else:\n         put = BoundClass(ContainerPut)\n         get = BoundClass(ContainerGet)\n+\n+    def _do_put(self, event: ContainerPut) -&gt; Optional[bool]:\n+        if self._capacity - self._level &gt;= event.amount:\n+            self._level += event.amount\n+            event.succeed()\n+            return True\n+        else:\n+            return None\n+\n+    def _do_get(self, event: ContainerGet) -&gt; Optional[bool]:\n+        if self._level &gt;= event.amount:\n+            self._level -= event.amount\n+            event.succeed()\n+            return True\n+        else:\n+            return None\ndiff --git a/src/simpy/resources/resource.py b/src/simpy/resources/resource.py\nindex 2c4f6dd..d48eb1c 100644\n--- a/src/simpy/resources/resource.py\n+++ b/src/simpy/resources/resource.py\n@@ -29,11 +29,15 @@ whose resource users can be preempted by requests with a higher priority.\n\n \"\"\"\n from __future__ import annotations\n+\n from typing import TYPE_CHECKING, Any, List, Optional, Type\n+\n from simpy.core import BoundClass, Environment, SimTime\n from simpy.resources import base\n+\n if TYPE_CHECKING:\n     from types import TracebackType\n+\n     from simpy.events import Process\n\n\n@@ -43,8 +47,12 @@ class Preempted:\n\n     \"\"\"\n\n-    def __init__(self, by: Optional[Process], usage_since: Optional[SimTime\n-        ], resource: Resource):\n+    def __init__(\n+        self,\n+        by: Optional[Process],\n+        usage_since: Optional[SimTime],\n+        resource: Resource,\n+    ):\n         self.by = by\n         \"\"\"The preempting :class:`simpy.events.Process`.\"\"\"\n         self.usage_since = usage_since\n@@ -67,13 +75,21 @@ class Request(base.Put):\n     a :keyword:`with` statement.\n\n     \"\"\"\n+\n     resource: Resource\n+\n+    #: The time at which the request succeeded.\n     usage_since: Optional[SimTime] = None\n\n-    def __exit__(self, exc_type: Optional[Type[BaseException]], exc_value:\n-        Optional[BaseException], traceback: Optional[TracebackType]\n-        ) -&gt;Optional[bool]:\n+    def __exit__(\n+        self,\n+        exc_type: Optional[Type[BaseException]],\n+        exc_value: Optional[BaseException],\n+        traceback: Optional[TracebackType],\n+    ) -&gt; Optional[bool]:\n         super().__exit__(exc_type, exc_value, traceback)\n+        # Don't release the resource on generator cleanups. This seems to\n+        # create un-claimable circular references otherwise.\n         if exc_type is not GeneratorExit:\n             self.resource.release(self)\n         return None\n@@ -103,21 +119,24 @@ class PriorityRequest(Request):\n\n     \"\"\"\n\n-    def __init__(self, resource: Resource, priority: int=0, preempt: bool=True\n-        ):\n+    def __init__(self, resource: Resource, priority: int = 0, preempt: bool = True):\n         self.priority = priority\n         \"\"\"The priority of this request. A smaller number means higher\n         priority.\"\"\"\n+\n         self.preempt = preempt\n         \"\"\"Indicates whether the request should preempt a resource user or not\n         (:class:`PriorityResource` ignores this flag).\"\"\"\n+\n         self.time = resource._env.now\n         \"\"\"The time at which the request was made.\"\"\"\n-        self.key = self.priority, self.time, not self.preempt\n+\n+        self.key = (self.priority, self.time, not self.preempt)\n         \"\"\"Key for sorting events. Consists of the priority (lower value is\n         more important), the time at which the request was made (earlier\n         requests are more important) and finally the preemption flag (preempt\n         requests are more important).\"\"\"\n+\n         super().__init__(resource)\n\n\n@@ -127,18 +146,22 @@ class SortedQueue(list):\n\n     \"\"\"\n\n-    def __init__(self, maxlen: Optional[int]=None):\n+    def __init__(self, maxlen: Optional[int] = None):\n         super().__init__()\n         self.maxlen = maxlen\n         \"\"\"Maximum length of the queue.\"\"\"\n\n-    def append(self, item: Any) -&gt;None:\n+    def append(self, item: Any) -&gt; None:\n         \"\"\"Sort *item* into the queue.\n\n         Raise a :exc:`RuntimeError` if the queue is full.\n\n         \"\"\"\n-        pass\n+        if self.maxlen is not None and len(self) &gt;= self.maxlen:\n+            raise RuntimeError('Cannot append event. Queue is full.')\n+\n+        super().append(item)\n+        super().sort(key=lambda e: e.key)\n\n\n class Resource(base.BaseResource):\n@@ -153,10 +176,12 @@ class Resource(base.BaseResource):\n\n     \"\"\"\n\n-    def __init__(self, env: Environment, capacity: int=1):\n+    def __init__(self, env: Environment, capacity: int = 1):\n         if capacity &lt;= 0:\n             raise ValueError('\"capacity\" must be &gt; 0.')\n+\n         super().__init__(env, capacity)\n+\n         self.users: List[Request] = []\n         \"\"\"List of :class:`Request` events for the processes that are currently\n         using the resource.\"\"\"\n@@ -166,22 +191,37 @@ class Resource(base.BaseResource):\n         \"\"\"\n\n     @property\n-    def count(self) -&gt;int:\n+    def count(self) -&gt; int:\n         \"\"\"Number of users currently using the resource.\"\"\"\n-        pass\n+        return len(self.users)\n+\n     if TYPE_CHECKING:\n\n-        def request(self) -&gt;Request:\n+        def request(self) -&gt; Request:\n             \"\"\"Request a usage slot.\"\"\"\n-            pass\n+            return Request(self)\n\n-        def release(self, request: Request) -&gt;Release:\n+        def release(self, request: Request) -&gt; Release:\n             \"\"\"Release a usage slot.\"\"\"\n-            pass\n+            return Release(self, request)\n+\n     else:\n         request = BoundClass(Request)\n         release = BoundClass(Release)\n\n+    def _do_put(self, event: Request) -&gt; None:\n+        if len(self.users) &lt; self.capacity:\n+            self.users.append(event)\n+            event.usage_since = self._env.now\n+            event.succeed()\n+\n+    def _do_get(self, event: Release) -&gt; None:\n+        try:\n+            self.users.remove(event.request)  # type: ignore\n+        except ValueError:\n+            pass\n+        event.succeed()\n+\n\n class PriorityResource(Resource):\n     \"\"\"A :class:`~simpy.resources.resource.Resource` supporting prioritized\n@@ -191,25 +231,30 @@ class PriorityResource(Resource):\n     order by their *priority* (that means lower values are more important).\n\n     \"\"\"\n+\n     PutQueue = SortedQueue\n     \"\"\"Type of the put queue. See\n     :attr:`~simpy.resources.base.BaseResource.put_queue` for details.\"\"\"\n+\n     GetQueue = list\n     \"\"\"Type of the get queue. See\n     :attr:`~simpy.resources.base.BaseResource.get_queue` for details.\"\"\"\n\n-    def __init__(self, env: Environment, capacity: int=1):\n+    def __init__(self, env: Environment, capacity: int = 1):\n         super().__init__(env, capacity)\n+\n     if TYPE_CHECKING:\n\n-        def request(self, priority: int=0, preempt: bool=True\n-            ) -&gt;PriorityRequest:\n+        def request(self, priority: int = 0, preempt: bool = True) -&gt; PriorityRequest:\n             \"\"\"Request a usage slot with the given *priority*.\"\"\"\n-            pass\n+            return PriorityRequest(self, priority, preempt)\n\n-        def release(self, request: PriorityRequest) -&gt;Release:\n+        def release(  # type: ignore[override]\n+            self, request: PriorityRequest\n+        ) -&gt; Release:\n             \"\"\"Release a usage slot.\"\"\"\n-            pass\n+            return Release(self, request)\n+\n     else:\n         request = BoundClass(PriorityRequest)\n         release = BoundClass(Release)\n@@ -223,4 +268,23 @@ class PreemptiveResource(PriorityResource):\n     cause.\n\n     \"\"\"\n-    users: List[PriorityRequest]\n+\n+    users: List[PriorityRequest]  # type: ignore\n+\n+    def _do_put(  # type: ignore[override]\n+        self, event: PriorityRequest\n+    ) -&gt; None:\n+        if len(self.users) &gt;= self.capacity and event.preempt:\n+            # Check if we can preempt another process\n+            preempt = sorted(self.users, key=lambda e: e.key)[-1]\n+            if preempt.key &gt; event.key:\n+                self.users.remove(preempt)\n+                preempt.proc.interrupt(  # type: ignore\n+                    Preempted(\n+                        by=event.proc,\n+                        usage_since=preempt.usage_since,\n+                        resource=self,\n+                    )\n+                )\n+\n+        return super()._do_put(event)\ndiff --git a/src/simpy/resources/store.py b/src/simpy/resources/store.py\nindex 5875e6d..13ac1ca 100644\n--- a/src/simpy/resources/store.py\n+++ b/src/simpy/resources/store.py\n@@ -9,8 +9,18 @@ matching a given criterion.\n\n \"\"\"\n from __future__ import annotations\n+\n from heapq import heappop, heappush\n-from typing import TYPE_CHECKING, Any, Callable, List, NamedTuple, Optional, Union\n+from typing import (\n+    TYPE_CHECKING,\n+    Any,\n+    Callable,\n+    List,\n+    NamedTuple,\n+    Optional,\n+    Union,\n+)\n+\n from simpy.core import BoundClass, Environment\n from simpy.resources import base\n\n@@ -45,8 +55,11 @@ class FilterStoreGet(StoreGet):\n\n     \"\"\"\n\n-    def __init__(self, resource: FilterStore, filter: Callable[[Any], bool]\n-        =lambda item: True):\n+    def __init__(\n+        self,\n+        resource: FilterStore,\n+        filter: Callable[[Any], bool] = lambda item: True,\n+    ):\n         self.filter = filter\n         \"\"\"The filter function to filter items in the store.\"\"\"\n         super().__init__(resource)\n@@ -62,26 +75,42 @@ class Store(base.BaseResource):\n\n     \"\"\"\n\n-    def __init__(self, env: Environment, capacity: Union[float, int]=float(\n-        'inf')):\n+    def __init__(self, env: Environment, capacity: Union[float, int] = float('inf')):\n         if capacity &lt;= 0:\n             raise ValueError('\"capacity\" must be &gt; 0.')\n+\n         super().__init__(env, capacity)\n+\n         self.items: List[Any] = []\n         \"\"\"List of the items available in the store.\"\"\"\n+\n     if TYPE_CHECKING:\n\n-        def put(self, item: Any) -&gt;StorePut:\n+        def put(  # type: ignore[override]\n+            self, item: Any\n+        ) -&gt; StorePut:\n             \"\"\"Request to put *item* into the store.\"\"\"\n-            pass\n+            return StorePut(self, item)\n\n-        def get(self) -&gt;StoreGet:\n+        def get(self) -&gt; StoreGet:  # type: ignore[override]\n             \"\"\"Request to get an *item* out of the store.\"\"\"\n-            pass\n+            return StoreGet(self)\n+\n     else:\n         put = BoundClass(StorePut)\n         get = BoundClass(StoreGet)\n\n+    def _do_put(self, event: StorePut) -&gt; Optional[bool]:\n+        if len(self.items) &lt; self._capacity:\n+            self.items.append(event.item)\n+            event.succeed()\n+        return None\n+\n+    def _do_get(self, event: StoreGet) -&gt; Optional[bool]:\n+        if self.items:\n+            event.succeed(self.items.pop(0))\n+        return None\n+\n\n class PriorityItem(NamedTuple):\n     \"\"\"Wrap an arbitrary *item* with an order-able *priority*.\n@@ -91,10 +120,16 @@ class PriorityItem(NamedTuple):\n     unorderable items in a :class:`PriorityStore` instance.\n\n     \"\"\"\n+\n+    #: Priority of the item.\n     priority: Any\n+\n+    #: The item to be stored.\n     item: Any\n\n-    def __lt__(self, other: PriorityItem) -&gt;bool:\n+    def __lt__(  # type: ignore[override]\n+        self, other: PriorityItem\n+    ) -&gt; bool:\n         return self.priority &lt; other.priority\n\n\n@@ -111,6 +146,17 @@ class PriorityStore(Store):\n\n     \"\"\"\n\n+    def _do_put(self, event: StorePut) -&gt; Optional[bool]:\n+        if len(self.items) &lt; self._capacity:\n+            heappush(self.items, event.item)\n+            event.succeed()\n+        return None\n+\n+    def _do_get(self, event: StoreGet) -&gt; Optional[bool]:\n+        if self.items:\n+            event.succeed(heappop(self.items))\n+        return None\n+\n\n class FilterStore(Store):\n     \"\"\"Resource with *capacity* slots for storing arbitrary objects supporting\n@@ -133,12 +179,25 @@ class FilterStore(Store):\n         want it.\n\n     \"\"\"\n+\n     if TYPE_CHECKING:\n\n-        def get(self, filter: Callable[[Any], bool]=lambda item: True\n-            ) -&gt;FilterStoreGet:\n+        def get(\n+            self, filter: Callable[[Any], bool] = lambda item: True\n+        ) -&gt; FilterStoreGet:\n             \"\"\"Request to get an *item*, for which *filter* returns ``True``,\n             out of the store.\"\"\"\n-            pass\n+            return FilterStoreGet(self, filter)\n+\n     else:\n         get = BoundClass(FilterStoreGet)\n+\n+    def _do_get(  # type: ignore[override]\n+        self, event: FilterStoreGet\n+    ) -&gt; Optional[bool]:\n+        for item in self.items:\n+            if event.filter(item):\n+                self.items.remove(item)\n+                event.succeed(item)\n+                break\n+        return True\ndiff --git a/src/simpy/rt.py b/src/simpy/rt.py\nindex 9d99392..284cb45 100644\n--- a/src/simpy/rt.py\n+++ b/src/simpy/rt.py\n@@ -3,6 +3,7 @@ with the real-time (aka *wall-clock time*).\n\n \"\"\"\n from time import monotonic, sleep\n+\n from simpy.core import EmptySchedule, Environment, Infinity, SimTime\n\n\n@@ -20,27 +21,32 @@ class RealtimeEnvironment(Environment):\n\n     \"\"\"\n\n-    def __init__(self, initial_time: SimTime=0, factor: float=1.0, strict:\n-        bool=True):\n+    def __init__(\n+        self,\n+        initial_time: SimTime = 0,\n+        factor: float = 1.0,\n+        strict: bool = True,\n+    ):\n         Environment.__init__(self, initial_time)\n+\n         self.env_start = initial_time\n         self.real_start = monotonic()\n         self._factor = factor\n         self._strict = strict\n\n     @property\n-    def factor(self) -&gt;float:\n+    def factor(self) -&gt; float:\n         \"\"\"Scaling factor of the real-time.\"\"\"\n-        pass\n+        return self._factor\n\n     @property\n-    def strict(self) -&gt;bool:\n+    def strict(self) -&gt; bool:\n         \"\"\"Running mode of the environment. :meth:`step()` will raise a\n         :exc:`RuntimeError` if this is set to ``True`` and the processing of\n         events takes too long.\"\"\"\n-        pass\n+        return self._strict\n\n-    def sync(self) -&gt;None:\n+    def sync(self) -&gt; None:\n         \"\"\"Synchronize the internal time with the current wall-clock time.\n\n         This can be useful to prevent :meth:`step()` from raising an error if\n@@ -48,9 +54,9 @@ class RealtimeEnvironment(Environment):\n         calling :meth:`run()` or :meth:`step()`.\n\n         \"\"\"\n-        pass\n+        self.real_start = monotonic()\n\n-    def step(self) -&gt;None:\n+    def step(self) -&gt; None:\n         \"\"\"Process the next event after enough real-time has passed for the\n         event to happen.\n\n@@ -59,4 +65,26 @@ class RealtimeEnvironment(Environment):\n         the event is processed too slowly.\n\n         \"\"\"\n-        pass\n+        evt_time = self.peek()\n+\n+        if evt_time is Infinity:\n+            raise EmptySchedule\n+\n+        real_time = self.real_start + (evt_time - self.env_start) * self.factor\n+\n+        if self.strict and monotonic() - real_time &gt; self.factor:\n+            # Events scheduled for time *t* may take just up to *t+1*\n+            # for their computation, before an error is raised.\n+            delta = monotonic() - real_time\n+            raise RuntimeError(f'Simulation too slow for real time ({delta:.3f}s).')\n+\n+        # Sleep in a loop to fix inaccuracies of windows (see\n+        # http://stackoverflow.com/a/15967564 for details) and to ignore\n+        # interrupts.\n+        while True:\n+            delta = real_time - monotonic()\n+            if delta &lt;= 0:\n+                break\n+            sleep(delta)\n+\n+        Environment.step(self)\ndiff --git a/src/simpy/util.py b/src/simpy/util.py\nindex 5e3a81a..7bb5d27 100644\n--- a/src/simpy/util.py\n+++ b/src/simpy/util.py\n@@ -6,12 +6,14 @@ A collection of utility functions:\n\n \"\"\"\n from typing import Generator\n+\n from simpy.core import Environment, SimTime\n from simpy.events import Event, Process, ProcessGenerator\n\n\n-def start_delayed(env: Environment, generator: ProcessGenerator, delay: SimTime\n-    ) -&gt;Process:\n+def start_delayed(\n+    env: Environment, generator: ProcessGenerator, delay: SimTime\n+) -&gt; Process:\n     \"\"\"Return a helper process that starts another process for *generator*\n     after a certain *delay*.\n\n@@ -33,10 +35,18 @@ def start_delayed(env: Environment, generator: ProcessGenerator, delay: SimTime\n     Raise a :exc:`ValueError` if ``delay &lt;= 0``.\n\n     \"\"\"\n-    pass\n+    if delay &lt;= 0:\n+        raise ValueError(f'delay(={delay}) must be &gt; 0.')\n+\n+    def starter() -&gt; Generator[Event, None, Process]:\n+        yield env.timeout(delay)\n+        proc = env.process(generator)\n+        return proc\n+\n+    return env.process(starter())\n\n\n-def subscribe_at(event: Event) -&gt;None:\n+def subscribe_at(event: Event) -&gt; None:\n     \"\"\"Register at the *event* to receive an interrupt when it occurs.\n\n     The most common use case for this is to pass\n@@ -45,4 +55,16 @@ def subscribe_at(event: Event) -&gt;None:\n     Raise a :exc:`RuntimeError` if ``event`` has already occurred.\n\n     \"\"\"\n-    pass\n+    env = event.env\n+    assert env.active_process is not None\n+    subscriber = env.active_process\n+\n+    def signaller(signaller: Event, receiver: Process) -&gt; ProcessGenerator:\n+        result = yield signaller\n+        if receiver.is_alive:\n+            receiver.interrupt((signaller, result))\n+\n+    if event.callbacks is not None:\n+        env.process(signaller(event, subscriber))\n+    else:\n+        raise RuntimeError(f'{event} has already terminated.')\n</code></pre>"},{"location":"analysis_reference_tinydb/","title":"Analysis reference tinydb","text":"<p>back to reference summary</p>"},{"location":"analysis_reference_tinydb/#submission-name-reference","title":"Submission Name: reference","text":""},{"location":"analysis_reference_tinydb/#repository-tinydb","title":"Repository: tinydb","text":""},{"location":"analysis_reference_tinydb/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count passed 201 total 201 collected 201"},{"location":"analysis_reference_tinydb/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_reference_tinydb/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/tinydb/database.py b/tinydb/database.py\nindex a4ce0e1..4a73c46 100644\n--- a/tinydb/database.py\n+++ b/tinydb/database.py\n@@ -2,10 +2,14 @@\n This module contains the main component of TinyDB: the database.\n \"\"\"\n from typing import Dict, Iterator, Set, Type\n+\n from . import JSONStorage\n from .storages import Storage\n from .table import Table, Document\n from .utils import with_typehint\n+\n+# The table's base class. This is used to add type hinting from the Table\n+# class to TinyDB. Currently, this supports PyCharm, Pyright/VS Code and MyPy.\n TableBase: Type[Table] = with_typehint(Table)\n\n\n@@ -63,28 +67,48 @@ class TinyDB(TableBase):\n     :param storage: The class of the storage to use. Will be initialized\n                     with ``args`` and ``kwargs``.\n     \"\"\"\n+\n+    #: The class that will be used to create table instances\n+    #:\n+    #: .. versionadded:: 4.0\n     table_class = Table\n+\n+    #: The name of the default table\n+    #:\n+    #: .. versionadded:: 4.0\n     default_table_name = '_default'\n+\n+    #: The class that will be used by default to create storage instances\n+    #:\n+    #: .. versionadded:: 4.0\n     default_storage_class = JSONStorage\n\n-    def __init__(self, *args, **kwargs) -&gt;None:\n+    def __init__(self, *args, **kwargs) -&gt; None:\n         \"\"\"\n         Create a new instance of TinyDB.\n         \"\"\"\n+\n         storage = kwargs.pop('storage', self.default_storage_class)\n+\n+        # Prepare the storage\n         self._storage: Storage = storage(*args, **kwargs)\n+\n         self._opened = True\n         self._tables: Dict[str, Table] = {}\n\n     def __repr__(self):\n-        args = ['tables={}'.format(list(self.tables())), 'tables_count={}'.\n-            format(len(self.tables())), 'default_table_documents_count={}'.\n-            format(self.__len__()), 'all_tables_documents_count={}'.format(\n-            ['{}={}'.format(table, len(self.table(table))) for table in\n-            self.tables()])]\n+        args = [\n+            'tables={}'.format(list(self.tables())),\n+            'tables_count={}'.format(len(self.tables())),\n+            'default_table_documents_count={}'.format(self.__len__()),\n+            'all_tables_documents_count={}'.format(\n+                ['{}={}'.format(table, len(self.table(table)))\n+                 for table in self.tables()]),\n+        ]\n+\n         return '&lt;{} {}&gt;'.format(type(self).__name__, ', '.join(args))\n\n-    def table(self, name: str, **kwargs) -&gt;Table:\n+    def table(self, name: str, **kwargs) -&gt; Table:\n         \"\"\"\n         Get access to a specific table.\n\n@@ -99,41 +123,95 @@ class TinyDB(TableBase):\n         :param name: The name of the table.\n         :param kwargs: Keyword arguments to pass to the table class constructor\n         \"\"\"\n-        pass\n\n-    def tables(self) -&gt;Set[str]:\n+        if name in self._tables:\n+            return self._tables[name]\n+\n+        table = self.table_class(self.storage, name, **kwargs)\n+        self._tables[name] = table\n+\n+        return table\n+\n+    def tables(self) -&gt; Set[str]:\n         \"\"\"\n         Get the names of all tables in the database.\n\n         :returns: a set of table names\n         \"\"\"\n-        pass\n\n-    def drop_tables(self) -&gt;None:\n+        # TinyDB stores data as a dict of tables like this:\n+        #\n+        #   {\n+        #       '_default': {\n+        #           0: {document...},\n+        #           1: {document...},\n+        #       },\n+        #       'table1': {\n+        #           ...\n+        #       }\n+        #   }\n+        #\n+        # To get a set of table names, we thus construct a set of this main\n+        # dict which returns a set of the dict keys which are the table names.\n+        #\n+        # Storage.read() may return ``None`` if the database file is empty,\n+        # so we need to consider this case to and return an empty set in this\n+        # case.\n+\n+        return set(self.storage.read() or {})\n+\n+    def drop_tables(self) -&gt; None:\n         \"\"\"\n         Drop all tables from the database. **CANNOT BE REVERSED!**\n         \"\"\"\n-        pass\n\n-    def drop_table(self, name: str) -&gt;None:\n+        # We drop all tables from this database by writing an empty dict\n+        # to the storage thereby returning to the initial state with no tables.\n+        self.storage.write({})\n+\n+        # After that we need to remember to empty the ``_tables`` dict, so we'll\n+        # create new table instances when a table is accessed again.\n+        self._tables.clear()\n+\n+    def drop_table(self, name: str) -&gt; None:\n         \"\"\"\n         Drop a specific table from the database. **CANNOT BE REVERSED!**\n\n         :param name: The name of the table to drop.\n         \"\"\"\n-        pass\n+\n+        # If the table is currently opened, we need to forget the table class\n+        # instance\n+        if name in self._tables:\n+            del self._tables[name]\n+\n+        data = self.storage.read()\n+\n+        # The database is uninitialized, there's nothing to do\n+        if data is None:\n+            return\n+\n+        # The table does not exist, there's nothing to do\n+        if name not in data:\n+            return\n+\n+        # Remove the table from the data dict\n+        del data[name]\n+\n+        # Store the updated data back to the storage\n+        self.storage.write(data)\n\n     @property\n-    def storage(self) -&gt;Storage:\n+    def storage(self) -&gt; Storage:\n         \"\"\"\n         Get the storage instance used for this TinyDB instance.\n\n         :return: This instance's storage\n         :rtype: Storage\n         \"\"\"\n-        pass\n+        return self._storage\n\n-    def close(self) -&gt;None:\n+    def close(self) -&gt; None:\n         \"\"\"\n         Close the database.\n\n@@ -148,7 +226,8 @@ class TinyDB(TableBase):\n\n         Upon leaving this context, the ``close`` method will be called.\n         \"\"\"\n-        pass\n+        self._opened = False\n+        self.storage.close()\n\n     def __enter__(self):\n         \"\"\"\n@@ -175,6 +254,9 @@ class TinyDB(TableBase):\n         \"\"\"\n         return getattr(self.table(self.default_table_name), name)\n\n+    # Here we forward magic methods to the default table instance. These are\n+    # not handled by __getattr__ so we need to forward them manually here\n+\n     def __len__(self):\n         \"\"\"\n         Get the total number of documents in the default table.\n@@ -185,7 +267,7 @@ class TinyDB(TableBase):\n         \"\"\"\n         return len(self.table(self.default_table_name))\n\n-    def __iter__(self) -&gt;Iterator[Document]:\n+    def __iter__(self) -&gt; Iterator[Document]:\n         \"\"\"\n         Return an iterator for the default table's documents.\n         \"\"\"\ndiff --git a/tinydb/middlewares.py b/tinydb/middlewares.py\nindex 50c2af2..7973012 100644\n--- a/tinydb/middlewares.py\n+++ b/tinydb/middlewares.py\n@@ -3,6 +3,7 @@ Contains the :class:`base class &lt;tinydb.middlewares.Middleware&gt;` for\n middlewares and implementations.\n \"\"\"\n from typing import Optional\n+\n from tinydb import Storage\n\n\n@@ -17,9 +18,9 @@ class Middleware:\n     constructor so the middleware chain can be configured properly.\n     \"\"\"\n\n-    def __init__(self, storage_cls) -&gt;None:\n+    def __init__(self, storage_cls) -&gt; None:\n         self._storage_cls = storage_cls\n-        self.storage: Storage = None\n+        self.storage: Storage = None  # type: ignore\n\n     def __call__(self, *args, **kwargs):\n         \"\"\"\n@@ -58,7 +59,9 @@ class Middleware:\n         nested Middleware that itself will initialize the next Middleware and\n         so on.\n         \"\"\"\n+\n         self.storage = self._storage_cls(*args, **kwargs)\n+\n         return self\n\n     def __getattr__(self, name):\n@@ -66,6 +69,7 @@ class Middleware:\n         Forward all unknown attribute calls to the underlying storage, so we\n         remain as transparent as possible.\n         \"\"\"\n+\n         return getattr(self.__dict__['storage'], name)\n\n\n@@ -77,15 +81,47 @@ class CachingMiddleware(Middleware):\n     the last DB state every :attr:`WRITE_CACHE_SIZE` time and reading always\n     from cache.\n     \"\"\"\n+\n+    #: The number of write operations to cache before writing to disc\n     WRITE_CACHE_SIZE = 1000\n\n     def __init__(self, storage_cls):\n+        # Initialize the parent constructor\n         super().__init__(storage_cls)\n+\n+        # Prepare the cache\n         self.cache = None\n         self._cache_modified_count = 0\n\n+    def read(self):\n+        if self.cache is None:\n+            # Empty cache: read from the storage\n+            self.cache = self.storage.read()\n+\n+        # Return the cached data\n+        return self.cache\n+\n+    def write(self, data):\n+        # Store data in cache\n+        self.cache = data\n+        self._cache_modified_count += 1\n+\n+        # Check if we need to flush the cache\n+        if self._cache_modified_count &gt;= self.WRITE_CACHE_SIZE:\n+            self.flush()\n+\n     def flush(self):\n         \"\"\"\n         Flush all unwritten data to disk.\n         \"\"\"\n-        pass\n+        if self._cache_modified_count &gt; 0:\n+            # Force-flush the cache by writing the data to the storage\n+            self.storage.write(self.cache)\n+            self._cache_modified_count = 0\n+\n+    def close(self):\n+        # Flush potentially unwritten data\n+        self.flush()\n+\n+        # Let the storage clean up too\n+        self.storage.close()\ndiff --git a/tinydb/mypy_plugin.py b/tinydb/mypy_plugin.py\nindex 5a0191a..cef1005 100644\n--- a/tinydb/mypy_plugin.py\n+++ b/tinydb/mypy_plugin.py\n@@ -1,14 +1,38 @@\n from typing import TypeVar, Optional, Callable, Dict\n+\n from mypy.nodes import NameExpr\n from mypy.options import Options\n from mypy.plugin import Plugin, DynamicClassDefContext\n+\n T = TypeVar('T')\n CB = Optional[Callable[[T], None]]\n DynamicClassDef = DynamicClassDefContext\n\n\n class TinyDBPlugin(Plugin):\n-\n     def __init__(self, options: Options):\n         super().__init__(options)\n+\n         self.named_placeholders: Dict[str, str] = {}\n+\n+    def get_dynamic_class_hook(self, fullname: str) -&gt; CB[DynamicClassDef]:\n+        if fullname == 'tinydb.utils.with_typehint':\n+            def hook(ctx: DynamicClassDefContext):\n+                klass = ctx.call.args[0]\n+                assert isinstance(klass, NameExpr)\n+\n+                type_name = klass.fullname\n+                assert type_name is not None\n+\n+                qualified = self.lookup_fully_qualified(type_name)\n+                assert qualified is not None\n+\n+                ctx.api.add_symbol_table_node(ctx.name, qualified)\n+\n+            return hook\n+\n+        return None\n+\n+\n+def plugin(_version: str):\n+    return TinyDBPlugin\ndiff --git a/tinydb/operations.py b/tinydb/operations.py\nindex fdfa678..47c3492 100644\n--- a/tinydb/operations.py\n+++ b/tinydb/operations.py\n@@ -13,39 +13,57 @@ def delete(field):\n     \"\"\"\n     Delete a given field from the document.\n     \"\"\"\n-    pass\n+    def transform(doc):\n+        del doc[field]\n+\n+    return transform\n\n\n def add(field, n):\n     \"\"\"\n     Add ``n`` to a given field in the document.\n     \"\"\"\n-    pass\n+    def transform(doc):\n+        doc[field] += n\n+\n+    return transform\n\n\n def subtract(field, n):\n     \"\"\"\n     Subtract ``n`` to a given field in the document.\n     \"\"\"\n-    pass\n+    def transform(doc):\n+        doc[field] -= n\n+\n+    return transform\n\n\n def set(field, val):\n     \"\"\"\n     Set a given field to ``val``.\n     \"\"\"\n-    pass\n+    def transform(doc):\n+        doc[field] = val\n+\n+    return transform\n\n\n def increment(field):\n     \"\"\"\n     Increment a given field in the document by 1.\n     \"\"\"\n-    pass\n+    def transform(doc):\n+        doc[field] += 1\n+\n+    return transform\n\n\n def decrement(field):\n     \"\"\"\n     Decrement a given field in the document by 1.\n     \"\"\"\n-    pass\n+    def transform(doc):\n+        doc[field] -= 1\n+\n+    return transform\ndiff --git a/tinydb/queries.py b/tinydb/queries.py\nindex 0ad5c7e..a797b4b 100644\n--- a/tinydb/queries.py\n+++ b/tinydb/queries.py\n@@ -15,15 +15,23 @@ True\n &gt;&gt;&gt; q({'val': 1})\n False\n \"\"\"\n+\n import re\n import sys\n from typing import Mapping, Tuple, Callable, Any, Union, List, Optional\n+\n from .utils import freeze\n+\n if sys.version_info &gt;= (3, 8):\n     from typing import Protocol\n else:\n     from typing_extensions import Protocol\n-__all__ = 'Query', 'QueryLike', 'where'\n+\n+__all__ = ('Query', 'QueryLike', 'where')\n+\n+\n+def is_sequence(obj):\n+    return hasattr(obj, '__iter__')\n\n\n class QueryLike(Protocol):\n@@ -45,12 +53,9 @@ class QueryLike(Protocol):\n\n     See also https://mypy.readthedocs.io/en/stable/protocols.html#simple-user-defined-protocols\n     \"\"\"\n+    def __call__(self, value: Mapping) -&gt; bool: ...\n\n-    def __call__(self, value: Mapping) -&gt;bool:\n-        ...\n-\n-    def __hash__(self) -&gt;int:\n-        ...\n+    def __hash__(self) -&gt; int: ...\n\n\n class QueryInstance:\n@@ -70,12 +75,14 @@ class QueryInstance:\n     instance can be used as a key in a dictionary.\n     \"\"\"\n\n-    def __init__(self, test: Callable[[Mapping], bool], hashval: Optional[\n-        Tuple]):\n+    def __init__(self, test: Callable[[Mapping], bool], hashval: Optional[Tuple]):\n         self._test = test\n         self._hash = hashval\n\n-    def __call__(self, value: Mapping) -&gt;bool:\n+    def is_cacheable(self) -&gt; bool:\n+        return self._hash is not None\n+\n+    def __call__(self, value: Mapping) -&gt; bool:\n         \"\"\"\n         Evaluate the query to check if it matches a specified value.\n\n@@ -84,7 +91,10 @@ class QueryInstance:\n         \"\"\"\n         return self._test(value)\n\n-    def __hash__(self) -&gt;int:\n+    def __hash__(self) -&gt; int:\n+        # We calculate the query hash by using the ``hashval`` object which\n+        # describes this query uniquely, so we can calculate a stable hash\n+        # value by simply hashing it\n         return hash(self._hash)\n\n     def __repr__(self):\n@@ -93,25 +103,32 @@ class QueryInstance:\n     def __eq__(self, other: object):\n         if isinstance(other, QueryInstance):\n             return self._hash == other._hash\n+\n         return False\n\n-    def __and__(self, other: 'QueryInstance') -&gt;'QueryInstance':\n+    # --- Query modifiers -----------------------------------------------------\n+\n+    def __and__(self, other: 'QueryInstance') -&gt; 'QueryInstance':\n+        # We use a frozenset for the hash as the AND operation is commutative\n+        # (a &amp; b == b &amp; a) and the frozenset does not consider the order of\n+        # elements\n         if self.is_cacheable() and other.is_cacheable():\n-            hashval = 'and', frozenset([self._hash, other._hash])\n+            hashval = ('and', frozenset([self._hash, other._hash]))\n         else:\n             hashval = None\n-        return QueryInstance(lambda value: self(value) and other(value),\n-            hashval)\n+        return QueryInstance(lambda value: self(value) and other(value), hashval)\n\n-    def __or__(self, other: 'QueryInstance') -&gt;'QueryInstance':\n+    def __or__(self, other: 'QueryInstance') -&gt; 'QueryInstance':\n+        # We use a frozenset for the hash as the OR operation is commutative\n+        # (a | b == b | a) and the frozenset does not consider the order of\n+        # elements\n         if self.is_cacheable() and other.is_cacheable():\n-            hashval = 'or', frozenset([self._hash, other._hash])\n+            hashval = ('or', frozenset([self._hash, other._hash]))\n         else:\n             hashval = None\n-        return QueryInstance(lambda value: self(value) or other(value), hashval\n-            )\n+        return QueryInstance(lambda value: self(value) or other(value), hashval)\n\n-    def __invert__(self) -&gt;'QueryInstance':\n+    def __invert__(self) -&gt; 'QueryInstance':\n         hashval = ('not', self._hash) if self.is_cacheable() else None\n         return QueryInstance(lambda value: not self(value), hashval)\n\n@@ -149,12 +166,18 @@ class Query(QueryInstance):\n     ``False`` depending on whether the documents match the query or not.\n     \"\"\"\n\n-    def __init__(self) -&gt;None:\n+    def __init__(self) -&gt; None:\n+        # The current path of fields to access when evaluating the object\n         self._path: Tuple[Union[str, Callable], ...] = ()\n\n+        # Prevent empty queries to be evaluated\n         def notest(_):\n             raise RuntimeError('Empty query was evaluated')\n-        super().__init__(test=notest, hashval=(None,))\n+\n+        super().__init__(\n+            test=notest,\n+            hashval=(None,)\n+        )\n\n     def __repr__(self):\n         return '{}()'.format(type(self).__name__)\n@@ -163,16 +186,36 @@ class Query(QueryInstance):\n         return super().__hash__()\n\n     def __getattr__(self, item: str):\n+        # Generate a new query object with the new query path\n+        # We use type(self) to get the class of the current query in case\n+        # someone uses a subclass of ``Query``\n         query = type(self)()\n+\n+        # Now we add the accessed item to the query path ...\n         query._path = self._path + (item,)\n+\n+        # ... and update the query hash\n         query._hash = ('path', query._path) if self.is_cacheable() else None\n+\n         return query\n\n     def __getitem__(self, item: str):\n+        # A different syntax for ``__getattr__``\n+\n+        # We cannot call ``getattr(item)`` here as it would try to resolve\n+        # the name as a method name first, only then call our ``__getattr__``\n+        # method. By calling ``__getattr__`` directly, we make sure that\n+        # calling e.g. ``Query()['test']`` will always generate a query for a\n+        # document's ``test`` field instead of returning a reference to the\n+        # ``Query.test`` method\n         return self.__getattr__(item)\n\n-    def _generate_test(self, test: Callable[[Any], bool], hashval: Tuple,\n-        allow_empty_path: bool=False) -&gt;QueryInstance:\n+    def _generate_test(\n+            self,\n+            test: Callable[[Any], bool],\n+            hashval: Tuple,\n+            allow_empty_path: bool = False\n+    ) -&gt; QueryInstance:\n         \"\"\"\n         Generate a query based on a test function that first resolves the query\n         path.\n@@ -181,7 +224,27 @@ class Query(QueryInstance):\n         :param hashval: The hash of the query.\n         :return: A :class:`~tinydb.queries.QueryInstance` object\n         \"\"\"\n-        pass\n+        if not self._path and not allow_empty_path:\n+            raise ValueError('Query has no path')\n+\n+        def runner(value):\n+            try:\n+                # Resolve the path\n+                for part in self._path:\n+                    if isinstance(part, str):\n+                        value = value[part]\n+                    else:\n+                        value = part(value)\n+            except (KeyError, TypeError):\n+                return False\n+            else:\n+                # Perform the specified test\n+                return test(value)\n+\n+        return QueryInstance(\n+            lambda value: runner(value),\n+            (hashval if self.is_cacheable() else None)\n+        )\n\n     def __eq__(self, rhs: Any):\n         \"\"\"\n@@ -191,8 +254,10 @@ class Query(QueryInstance):\n\n         :param rhs: The value to compare against\n         \"\"\"\n-        return self._generate_test(lambda value: value == rhs, ('==', self.\n-            _path, freeze(rhs)))\n+        return self._generate_test(\n+            lambda value: value == rhs,\n+            ('==', self._path, freeze(rhs))\n+        )\n\n     def __ne__(self, rhs: Any):\n         \"\"\"\n@@ -202,10 +267,12 @@ class Query(QueryInstance):\n\n         :param rhs: The value to compare against\n         \"\"\"\n-        return self._generate_test(lambda value: value != rhs, ('!=', self.\n-            _path, freeze(rhs)))\n+        return self._generate_test(\n+            lambda value: value != rhs,\n+            ('!=', self._path, freeze(rhs))\n+        )\n\n-    def __lt__(self, rhs: Any) -&gt;QueryInstance:\n+    def __lt__(self, rhs: Any) -&gt; QueryInstance:\n         \"\"\"\n         Test a dict value for being lower than another value.\n\n@@ -213,10 +280,12 @@ class Query(QueryInstance):\n\n         :param rhs: The value to compare against\n         \"\"\"\n-        return self._generate_test(lambda value: value &lt; rhs, ('&lt;', self.\n-            _path, rhs))\n+        return self._generate_test(\n+            lambda value: value &lt; rhs,\n+            ('&lt;', self._path, rhs)\n+        )\n\n-    def __le__(self, rhs: Any) -&gt;QueryInstance:\n+    def __le__(self, rhs: Any) -&gt; QueryInstance:\n         \"\"\"\n         Test a dict value for being lower than or equal to another value.\n\n@@ -224,10 +293,12 @@ class Query(QueryInstance):\n\n         :param rhs: The value to compare against\n         \"\"\"\n-        return self._generate_test(lambda value: value &lt;= rhs, ('&lt;=', self.\n-            _path, rhs))\n+        return self._generate_test(\n+            lambda value: value &lt;= rhs,\n+            ('&lt;=', self._path, rhs)\n+        )\n\n-    def __gt__(self, rhs: Any) -&gt;QueryInstance:\n+    def __gt__(self, rhs: Any) -&gt; QueryInstance:\n         \"\"\"\n         Test a dict value for being greater than another value.\n\n@@ -235,10 +306,12 @@ class Query(QueryInstance):\n\n         :param rhs: The value to compare against\n         \"\"\"\n-        return self._generate_test(lambda value: value &gt; rhs, ('&gt;', self.\n-            _path, rhs))\n+        return self._generate_test(\n+            lambda value: value &gt; rhs,\n+            ('&gt;', self._path, rhs)\n+        )\n\n-    def __ge__(self, rhs: Any) -&gt;QueryInstance:\n+    def __ge__(self, rhs: Any) -&gt; QueryInstance:\n         \"\"\"\n         Test a dict value for being greater than or equal to another value.\n\n@@ -246,18 +319,23 @@ class Query(QueryInstance):\n\n         :param rhs: The value to compare against\n         \"\"\"\n-        return self._generate_test(lambda value: value &gt;= rhs, ('&gt;=', self.\n-            _path, rhs))\n+        return self._generate_test(\n+            lambda value: value &gt;= rhs,\n+            ('&gt;=', self._path, rhs)\n+        )\n\n-    def exists(self) -&gt;QueryInstance:\n+    def exists(self) -&gt; QueryInstance:\n         \"\"\"\n         Test for a dict where a provided key exists.\n\n         &gt;&gt;&gt; Query().f1.exists()\n         \"\"\"\n-        pass\n+        return self._generate_test(\n+            lambda _: True,\n+            ('exists', self._path)\n+        )\n\n-    def matches(self, regex: str, flags: int=0) -&gt;QueryInstance:\n+    def matches(self, regex: str, flags: int = 0) -&gt; QueryInstance:\n         \"\"\"\n         Run a regex test against a dict value (whole string has to match).\n\n@@ -266,9 +344,15 @@ class Query(QueryInstance):\n         :param regex: The regular expression to use for matching\n         :param flags: regex flags to pass to ``re.match``\n         \"\"\"\n-        pass\n+        def test(value):\n+            if not isinstance(value, str):\n+                return False\n+\n+            return re.match(regex, value, flags) is not None\n+\n+        return self._generate_test(test, ('matches', self._path, regex))\n\n-    def search(self, regex: str, flags: int=0) -&gt;QueryInstance:\n+    def search(self, regex: str, flags: int = 0) -&gt; QueryInstance:\n         \"\"\"\n         Run a regex test against a dict value (only substring string has to\n         match).\n@@ -278,9 +362,16 @@ class Query(QueryInstance):\n         :param regex: The regular expression to use for matching\n         :param flags: regex flags to pass to ``re.match``\n         \"\"\"\n-        pass\n\n-    def test(self, func: Callable[[Mapping], bool], *args) -&gt;QueryInstance:\n+        def test(value):\n+            if not isinstance(value, str):\n+                return False\n+\n+            return re.search(regex, value, flags) is not None\n+\n+        return self._generate_test(test, ('search', self._path, regex))\n+\n+    def test(self, func: Callable[[Mapping], bool], *args) -&gt; QueryInstance:\n         \"\"\"\n         Run a user-defined test function against a dict value.\n\n@@ -300,9 +391,12 @@ class Query(QueryInstance):\n                      argument\n         :param args: Additional arguments to pass to the test function\n         \"\"\"\n-        pass\n+        return self._generate_test(\n+            lambda value: func(value, *args),\n+            ('test', self._path, func, args)\n+        )\n\n-    def any(self, cond: Union[QueryInstance, List[Any]]) -&gt;QueryInstance:\n+    def any(self, cond: Union[QueryInstance, List[Any]]) -&gt; QueryInstance:\n         \"\"\"\n         Check if a condition is met by any document in a list,\n         where a condition can also be a sequence (e.g. list).\n@@ -324,9 +418,20 @@ class Query(QueryInstance):\n                      a list of which at least one document has to be contained\n                      in the tested document.\n         \"\"\"\n-        pass\n+        if callable(cond):\n+            def test(value):\n+                return is_sequence(value) and any(cond(e) for e in value)\n+\n+        else:\n+            def test(value):\n+                return is_sequence(value) and any(e in cond for e in value)\n\n-    def all(self, cond: Union['QueryInstance', List[Any]]) -&gt;QueryInstance:\n+        return self._generate_test(\n+            lambda value: test(value),\n+            ('any', self._path, freeze(cond))\n+        )\n+\n+    def all(self, cond: Union['QueryInstance', List[Any]]) -&gt; QueryInstance:\n         \"\"\"\n         Check if a condition is met by all documents in a list,\n         where a condition can also be a sequence (e.g. list).\n@@ -346,9 +451,20 @@ class Query(QueryInstance):\n         :param cond: Either a query that all documents have to match or a list\n                      which has to be contained in the tested document.\n         \"\"\"\n-        pass\n+        if callable(cond):\n+            def test(value):\n+                return is_sequence(value) and all(cond(e) for e in value)\n+\n+        else:\n+            def test(value):\n+                return is_sequence(value) and all(e in value for e in cond)\n+\n+        return self._generate_test(\n+            lambda value: test(value),\n+            ('all', self._path, freeze(cond))\n+        )\n\n-    def one_of(self, items: List[Any]) -&gt;QueryInstance:\n+    def one_of(self, items: List[Any]) -&gt; QueryInstance:\n         \"\"\"\n         Check if the value is contained in a list or generator.\n\n@@ -356,26 +472,55 @@ class Query(QueryInstance):\n\n         :param items: The list of items to check with\n         \"\"\"\n-        pass\n+        return self._generate_test(\n+            lambda value: value in items,\n+            ('one_of', self._path, freeze(items))\n+        )\n\n-    def noop(self) -&gt;QueryInstance:\n+    def fragment(self, document: Mapping) -&gt; QueryInstance:\n+        def test(value):\n+            for key in document:\n+                if key not in value or value[key] != document[key]:\n+                    return False\n+\n+            return True\n+\n+        return self._generate_test(\n+            lambda value: test(value),\n+            ('fragment', freeze(document)),\n+            allow_empty_path=True\n+        )\n+\n+    def noop(self) -&gt; QueryInstance:\n         \"\"\"\n         Always evaluate to ``True``.\n\n         Useful for having a base value when composing queries dynamically.\n         \"\"\"\n-        pass\n\n-    def map(self, fn: Callable[[Any], Any]) -&gt;'Query':\n+        return QueryInstance(\n+            lambda value: True,\n+            ()\n+        )\n+\n+    def map(self, fn: Callable[[Any], Any]) -&gt; 'Query':\n         \"\"\"\n         Add a function to the query path. Similar to __getattr__ but for\n         arbitrary functions.\n         \"\"\"\n-        pass\n+        query = type(self)()\n+\n+        # Now we add the callable to the query path ...\n+        query._path = self._path + (fn,)\n\n+        # ... and kill the hash - callable objects can be mutable, so it's\n+        # harmful to cache their results.\n+        query._hash = None\n+\n+        return query\n\n-def where(key: str) -&gt;Query:\n+def where(key: str) -&gt; Query:\n     \"\"\"\n     A shorthand for ``Query()[key]``\n     \"\"\"\n-    pass\n+    return Query()[key]\ndiff --git a/tinydb/storages.py b/tinydb/storages.py\nindex 0ddc223..d5a2db7 100644\n--- a/tinydb/storages.py\n+++ b/tinydb/storages.py\n@@ -2,13 +2,15 @@\n Contains the :class:`base class &lt;tinydb.storages.Storage&gt;` for storages and\n implementations.\n \"\"\"\n+\n import io\n import json\n import os\n import warnings\n from abc import ABC, abstractmethod\n from typing import Dict, Any, Optional\n-__all__ = 'Storage', 'JSONStorage', 'MemoryStorage'\n+\n+__all__ = ('Storage', 'JSONStorage', 'MemoryStorage')\n\n\n def touch(path: str, create_dirs: bool):\n@@ -18,7 +20,17 @@ def touch(path: str, create_dirs: bool):\n     :param path: The file to create.\n     :param create_dirs: Whether to create all missing parent directories.\n     \"\"\"\n-    pass\n+    if create_dirs:\n+        base_dir = os.path.dirname(path)\n+\n+        # Check if we need to create missing parent directories\n+        if not os.path.exists(base_dir):\n+            os.makedirs(base_dir)\n+\n+    # Create the file by opening it in 'a' mode which creates the file if it\n+    # does not exist yet but does not modify its contents\n+    with open(path, 'a'):\n+        pass\n\n\n class Storage(ABC):\n@@ -29,8 +41,11 @@ class Storage(ABC):\n     some place (memory, file on disk, ...).\n     \"\"\"\n\n+    # Using ABCMeta as metaclass allows instantiating only storages that have\n+    # implemented read and write\n+\n     @abstractmethod\n-    def read(self) -&gt;Optional[Dict[str, Dict[str, Any]]]:\n+    def read(self) -&gt; Optional[Dict[str, Dict[str, Any]]]:\n         \"\"\"\n         Read the current state.\n\n@@ -38,10 +53,11 @@ class Storage(ABC):\n\n         Return ``None`` here to indicate that the storage is empty.\n         \"\"\"\n-        pass\n+\n+        raise NotImplementedError('To be overridden!')\n\n     @abstractmethod\n-    def write(self, data: Dict[str, Dict[str, Any]]) -&gt;None:\n+    def write(self, data: Dict[str, Dict[str, Any]]) -&gt; None:\n         \"\"\"\n         Write the current state of the database to the storage.\n\n@@ -49,12 +65,14 @@ class Storage(ABC):\n\n         :param data: The current state of the database.\n         \"\"\"\n-        pass\n\n-    def close(self) -&gt;None:\n+        raise NotImplementedError('To be overridden!')\n+\n+    def close(self) -&gt; None:\n         \"\"\"\n         Optional: Close open file handles, etc.\n         \"\"\"\n+\n         pass\n\n\n@@ -63,8 +81,7 @@ class JSONStorage(Storage):\n     Store the data in a JSON file.\n     \"\"\"\n\n-    def __init__(self, path: str, create_dirs=False, encoding=None,\n-        access_mode='r+', **kwargs):\n+    def __init__(self, path: str, create_dirs=False, encoding=None, access_mode='r+', **kwargs):\n         \"\"\"\n         Create a new instance.\n\n@@ -78,17 +95,67 @@ class JSONStorage(Storage):\n         :param access_mode: mode in which the file is opened (r, r+)\n         :type access_mode: str\n         \"\"\"\n+\n         super().__init__()\n+\n         self._mode = access_mode\n         self.kwargs = kwargs\n+\n         if access_mode not in ('r', 'rb', 'r+', 'rb+'):\n             warnings.warn(\n-                \"Using an `access_mode` other than 'r', 'rb', 'r+' or 'rb+' can cause data loss or corruption\"\n-                )\n-        if any([(character in self._mode) for character in ('+', 'w', 'a')]):\n+                'Using an `access_mode` other than \\'r\\', \\'rb\\', \\'r+\\' '\n+                'or \\'rb+\\' can cause data loss or corruption'\n+            )\n+\n+        # Create the file if it doesn't exist and creating is allowed by the\n+        # access mode\n+        if any([character in self._mode for character in ('+', 'w', 'a')]):  # any of the writing modes\n             touch(path, create_dirs=create_dirs)\n+\n+        # Open the file for reading/writing\n         self._handle = open(path, mode=self._mode, encoding=encoding)\n\n+    def close(self) -&gt; None:\n+        self._handle.close()\n+\n+    def read(self) -&gt; Optional[Dict[str, Dict[str, Any]]]:\n+        # Get the file size by moving the cursor to the file end and reading\n+        # its location\n+        self._handle.seek(0, os.SEEK_END)\n+        size = self._handle.tell()\n+\n+        if not size:\n+            # File is empty, so we return ``None`` so TinyDB can properly\n+            # initialize the database\n+            return None\n+        else:\n+            # Return the cursor to the beginning of the file\n+            self._handle.seek(0)\n+\n+            # Load the JSON contents of the file\n+            return json.load(self._handle)\n+\n+    def write(self, data: Dict[str, Dict[str, Any]]):\n+        # Move the cursor to the beginning of the file just in case\n+        self._handle.seek(0)\n+\n+        # Serialize the database state using the user-provided arguments\n+        serialized = json.dumps(data, **self.kwargs)\n+\n+        # Write the serialized data to the file\n+        try:\n+            self._handle.write(serialized)\n+        except io.UnsupportedOperation:\n+            raise IOError('Cannot write to the database. Access mode is \"{0}\"'.format(self._mode))\n+\n+        # Ensure the file has been written\n+        self._handle.flush()\n+        os.fsync(self._handle.fileno())\n+\n+        # Remove data that is behind the new cursor in case the file has\n+        # gotten shorter\n+        self._handle.truncate()\n+\n\n class MemoryStorage(Storage):\n     \"\"\"\n@@ -99,5 +166,12 @@ class MemoryStorage(Storage):\n         \"\"\"\n         Create a new instance.\n         \"\"\"\n+\n         super().__init__()\n         self.memory = None\n+\n+    def read(self) -&gt; Optional[Dict[str, Dict[str, Any]]]:\n+        return self.memory\n+\n+    def write(self, data: Dict[str, Dict[str, Any]]):\n+        self.memory = data\ndiff --git a/tinydb/table.py b/tinydb/table.py\nindex 48eea63..60a8798 100644\n--- a/tinydb/table.py\n+++ b/tinydb/table.py\n@@ -2,11 +2,25 @@\n This module implements tables, the central place for accessing and manipulating\n data in TinyDB.\n \"\"\"\n-from typing import Callable, Dict, Iterable, Iterator, List, Mapping, Optional, Union, cast, Tuple\n+\n+from typing import (\n+    Callable,\n+    Dict,\n+    Iterable,\n+    Iterator,\n+    List,\n+    Mapping,\n+    Optional,\n+    Union,\n+    cast,\n+    Tuple\n+)\n+\n from .queries import QueryLike\n from .storages import Storage\n from .utils import LRUCache\n-__all__ = 'Document', 'Table'\n+\n+__all__ = ('Document', 'Table')\n\n\n class Document(dict):\n@@ -59,79 +73,215 @@ class Table:\n     :param name: The table name\n     :param cache_size: Maximum capacity of query cache\n     \"\"\"\n+\n+    #: The class used to represent documents\n+    #:\n+    #: .. versionadded:: 4.0\n     document_class = Document\n+\n+    #: The class used to represent a document ID\n+    #:\n+    #: .. versionadded:: 4.0\n     document_id_class = int\n+\n+    #: The class used for caching query results\n+    #:\n+    #: .. versionadded:: 4.0\n     query_cache_class = LRUCache\n+\n+    #: The default capacity of the query cache\n+    #:\n+    #: .. versionadded:: 4.0\n     default_query_cache_capacity = 10\n\n-    def __init__(self, storage: Storage, name: str, cache_size: int=\n-        default_query_cache_capacity):\n+    def __init__(\n+        self,\n+        storage: Storage,\n+        name: str,\n+        cache_size: int = default_query_cache_capacity\n+    ):\n         \"\"\"\n         Create a table instance.\n         \"\"\"\n+\n         self._storage = storage\n         self._name = name\n-        self._query_cache: LRUCache[QueryLike, List[Document]\n-            ] = self.query_cache_class(capacity=cache_size)\n+        self._query_cache: LRUCache[QueryLike, List[Document]] \\\n+            = self.query_cache_class(capacity=cache_size)\n+\n         self._next_id = None\n\n     def __repr__(self):\n-        args = ['name={!r}'.format(self.name), 'total={}'.format(len(self)),\n-            'storage={}'.format(self._storage)]\n+        args = [\n+            'name={!r}'.format(self.name),\n+            'total={}'.format(len(self)),\n+            'storage={}'.format(self._storage),\n+        ]\n+\n         return '&lt;{} {}&gt;'.format(type(self).__name__, ', '.join(args))\n\n     @property\n-    def name(self) -&gt;str:\n+    def name(self) -&gt; str:\n         \"\"\"\n         Get the table name.\n         \"\"\"\n-        pass\n+        return self._name\n\n     @property\n-    def storage(self) -&gt;Storage:\n+    def storage(self) -&gt; Storage:\n         \"\"\"\n         Get the table storage instance.\n         \"\"\"\n-        pass\n+        return self._storage\n\n-    def insert(self, document: Mapping) -&gt;int:\n+    def insert(self, document: Mapping) -&gt; int:\n         \"\"\"\n         Insert a new document into the table.\n\n         :param document: the document to insert\n         :returns: the inserted document's ID\n         \"\"\"\n-        pass\n\n-    def insert_multiple(self, documents: Iterable[Mapping]) -&gt;List[int]:\n+        # Make sure the document implements the ``Mapping`` interface\n+        if not isinstance(document, Mapping):\n+            raise ValueError('Document is not a Mapping')\n+\n+        # First, we get the document ID for the new document\n+        if isinstance(document, Document):\n+            # For a `Document` object we use the specified ID\n+            doc_id = document.doc_id\n+\n+            # We also reset the stored next ID so the next insert won't\n+            # re-use document IDs by accident when storing an old value\n+            self._next_id = None\n+        else:\n+            # In all other cases we use the next free ID\n+            doc_id = self._get_next_id()\n+\n+        # Now, we update the table and add the document\n+        def updater(table: dict):\n+            if doc_id in table:\n+                raise ValueError(f'Document with ID {str(doc_id)} '\n+                                 f'already exists')\n+                \n+            # By calling ``dict(document)`` we convert the data we got to a\n+            # ``dict`` instance even if it was a different class that\n+            # implemented the ``Mapping`` interface\n+            table[doc_id] = dict(document)\n+\n+        # See below for details on ``Table._update``\n+        self._update_table(updater)\n+\n+        return doc_id\n+\n+    def insert_multiple(self, documents: Iterable[Mapping]) -&gt; List[int]:\n         \"\"\"\n         Insert multiple documents into the table.\n\n         :param documents: an Iterable of documents to insert\n         :returns: a list containing the inserted documents' IDs\n         \"\"\"\n-        pass\n+        doc_ids = []\n+\n+        def updater(table: dict):\n+            for document in documents:\n+\n+                # Make sure the document implements the ``Mapping`` interface\n+                if not isinstance(document, Mapping):\n+                    raise ValueError('Document is not a Mapping')\n+\n+                if isinstance(document, Document):\n+                    # Check if document does not override an existing document\n+                    if document.doc_id in table:\n+                        raise ValueError(\n+                            f'Document with ID {str(document.doc_id)} '\n+                            f'already exists'\n+                        )\n+\n+                    # Store the doc_id, so we can return all document IDs\n+                    # later. Then save the document with its doc_id and\n+                    # skip the rest of the current loop\n+                    doc_id = document.doc_id\n+                    doc_ids.append(doc_id)\n+                    table[doc_id] = dict(document)\n+                    continue\n+\n+                # Generate new document ID for this document\n+                # Store the doc_id, so we can return all document IDs\n+                # later, then save the document with the new doc_id\n+                doc_id = self._get_next_id()\n+                doc_ids.append(doc_id)\n+                table[doc_id] = dict(document)\n\n-    def all(self) -&gt;List[Document]:\n+        # See below for details on ``Table._update``\n+        self._update_table(updater)\n+\n+        return doc_ids\n+\n+    def all(self) -&gt; List[Document]:\n         \"\"\"\n         Get all documents stored in the table.\n\n         :returns: a list with all documents.\n         \"\"\"\n-        pass\n\n-    def search(self, cond: QueryLike) -&gt;List[Document]:\n+        # iter(self) (implemented in Table.__iter__ provides an iterator\n+        # that returns all documents in this table. We use it to get a list\n+        # of all documents by using the ``list`` constructor to perform the\n+        # conversion.\n+\n+        return list(iter(self))\n+\n+    def search(self, cond: QueryLike) -&gt; List[Document]:\n         \"\"\"\n         Search for all documents matching a 'where' cond.\n\n         :param cond: the condition to check against\n         :returns: list of matching documents\n         \"\"\"\n-        pass\n\n-    def get(self, cond: Optional[QueryLike]=None, doc_id: Optional[int]=\n-        None, doc_ids: Optional[List]=None) -&gt;Optional[Union[Document, List\n-        [Document]]]:\n+        # First, we check the query cache to see if it has results for this\n+        # query\n+        cached_results = self._query_cache.get(cond)\n+        if cached_results is not None:\n+            return cached_results[:]\n+\n+        # Perform the search by applying the query to all documents.\n+        # Then, only if the document matches the query, convert it\n+        # to the document class and document ID class.\n+        docs = [\n+            self.document_class(doc, self.document_id_class(doc_id))\n+            for doc_id, doc in self._read_table().items()\n+            if cond(doc)\n+        ]\n+\n+        # Only cache cacheable queries.\n+        #\n+        # This weird `getattr` dance is needed to make MyPy happy as\n+        # it doesn't know that a query might have a `is_cacheable` method\n+        # that is not declared in the `QueryLike` protocol due to it being\n+        # optional.\n+        # See: https://github.com/python/mypy/issues/1424\n+        #\n+        # Note also that by default we expect custom query objects to be\n+        # cacheable (which means they need to have a stable hash value).\n+        # This is to keep consistency with TinyDB's behavior before\n+        # `is_cacheable` was introduced which assumed that all queries\n+        # are cacheable.\n+        is_cacheable: Callable[[], bool] = getattr(cond, 'is_cacheable',\n+                                                   lambda: True)\n+        if is_cacheable():\n+            # Update the query cache\n+            self._query_cache[cond] = docs[:]\n+\n+        return docs\n+\n+    def get(\n+        self,\n+        cond: Optional[QueryLike] = None,\n+        doc_id: Optional[int] = None,\n+        doc_ids: Optional[List] = None\n+    ) -&gt; Optional[Union[Document, List[Document]]]:\n         \"\"\"\n         Get exactly one document specified by a query or a document ID.\n         However, if multiple document IDs are given then returns all\n@@ -145,10 +295,55 @@ class Table:\n\n         :returns: the document(s) or ``None``\n         \"\"\"\n-        pass\n+        table = self._read_table()\n+\n+        if doc_id is not None:\n+            # Retrieve a document specified by its ID\n+            raw_doc = table.get(str(doc_id), None)\n+\n+            if raw_doc is None:\n+                return None\n\n-    def contains(self, cond: Optional[QueryLike]=None, doc_id: Optional[int\n-        ]=None) -&gt;bool:\n+            # Convert the raw data to the document class\n+            return self.document_class(raw_doc, doc_id)\n+\n+        elif doc_ids is not None:\n+            # Filter the table by extracting out all those documents which\n+            # have doc id specified in the doc_id list.\n+\n+            # Since document IDs will be unique, we make it a set to ensure\n+            # constant time lookup\n+            doc_ids_set = set(str(doc_id) for doc_id in doc_ids)\n+\n+            # Now return the filtered documents in form of list\n+            return [\n+                self.document_class(doc, self.document_id_class(doc_id))\n+                for doc_id, doc in table.items()\n+                if doc_id in doc_ids_set\n+            ]\n+\n+        elif cond is not None:\n+            # Find a document specified by a query\n+            # The trailing underscore in doc_id_ is needed so MyPy\n+            # doesn't think that `doc_id_` (which is a string) needs\n+            # to have the same type as `doc_id` which is this function's\n+            # parameter and is an optional `int`.\n+            for doc_id_, doc in self._read_table().items():\n+                if cond(doc):\n+                    return self.document_class(\n+                        doc,\n+                        self.document_id_class(doc_id_)\n+                    )\n+\n+            return None\n+\n+        raise RuntimeError('You have to pass either cond or doc_id or doc_ids')\n+\n+    def contains(\n+        self,\n+        cond: Optional[QueryLike] = None,\n+        doc_id: Optional[int] = None\n+    ) -&gt; bool:\n         \"\"\"\n         Check whether the database contains a document matching a query or\n         an ID.\n@@ -158,11 +353,22 @@ class Table:\n         :param cond: the condition use\n         :param doc_id: the document ID to look for\n         \"\"\"\n-        pass\n+        if doc_id is not None:\n+            # Documents specified by ID\n+            return self.get(doc_id=doc_id) is not None\n\n-    def update(self, fields: Union[Mapping, Callable[[Mapping], None]],\n-        cond: Optional[QueryLike]=None, doc_ids: Optional[Iterable[int]]=None\n-        ) -&gt;List[int]:\n+        elif cond is not None:\n+            # Document specified by condition\n+            return self.get(cond) is not None\n+\n+        raise RuntimeError('You have to pass either cond or doc_id')\n+\n+    def update(\n+        self,\n+        fields: Union[Mapping, Callable[[Mapping], None]],\n+        cond: Optional[QueryLike] = None,\n+        doc_ids: Optional[Iterable[int]] = None,\n+    ) -&gt; List[int]:\n         \"\"\"\n         Update all matching documents to have a given set of fields.\n\n@@ -172,19 +378,135 @@ class Table:\n         :param doc_ids: a list of document IDs\n         :returns: a list containing the updated document's ID\n         \"\"\"\n-        pass\n\n-    def update_multiple(self, updates: Iterable[Tuple[Union[Mapping,\n-        Callable[[Mapping], None]], QueryLike]]) -&gt;List[int]:\n+        # Define the function that will perform the update\n+        if callable(fields):\n+            def perform_update(table, doc_id):\n+                # Update documents by calling the update function provided by\n+                # the user\n+                fields(table[doc_id])\n+        else:\n+            def perform_update(table, doc_id):\n+                # Update documents by setting all fields from the provided data\n+                table[doc_id].update(fields)\n+\n+        if doc_ids is not None:\n+            # Perform the update operation for documents specified by a list\n+            # of document IDs\n+\n+            updated_ids = list(doc_ids)\n+\n+            def updater(table: dict):\n+                # Call the processing callback with all document IDs\n+                for doc_id in updated_ids:\n+                    perform_update(table, doc_id)\n+\n+            # Perform the update operation (see _update_table for details)\n+            self._update_table(updater)\n+\n+            return updated_ids\n+\n+        elif cond is not None:\n+            # Perform the update operation for documents specified by a query\n+\n+            # Collect affected doc_ids\n+            updated_ids = []\n+\n+            def updater(table: dict):\n+                _cond = cast(QueryLike, cond)\n+\n+                # We need to convert the keys iterator to a list because\n+                # we may remove entries from the ``table`` dict during\n+                # iteration and doing this without the list conversion would\n+                # result in an exception (RuntimeError: dictionary changed size\n+                # during iteration)\n+                for doc_id in list(table.keys()):\n+                    # Pass through all documents to find documents matching the\n+                    # query. Call the processing callback with the document ID\n+                    if _cond(table[doc_id]):\n+                        # Add ID to list of updated documents\n+                        updated_ids.append(doc_id)\n+\n+                        # Perform the update (see above)\n+                        perform_update(table, doc_id)\n+\n+            # Perform the update operation (see _update_table for details)\n+            self._update_table(updater)\n+\n+            return updated_ids\n+\n+        else:\n+            # Update all documents unconditionally\n+\n+            updated_ids = []\n+\n+            def updater(table: dict):\n+                # Process all documents\n+                for doc_id in list(table.keys()):\n+                    # Add ID to list of updated documents\n+                    updated_ids.append(doc_id)\n+\n+                    # Perform the update (see above)\n+                    perform_update(table, doc_id)\n+\n+            # Perform the update operation (see _update_table for details)\n+            self._update_table(updater)\n+\n+            return updated_ids\n+\n+    def update_multiple(\n+        self,\n+        updates: Iterable[\n+            Tuple[Union[Mapping, Callable[[Mapping], None]], QueryLike]\n+        ],\n+    ) -&gt; List[int]:\n         \"\"\"\n         Update all matching documents to have a given set of fields.\n\n         :returns: a list containing the updated document's ID\n         \"\"\"\n-        pass\n\n-    def upsert(self, document: Mapping, cond: Optional[QueryLike]=None) -&gt;List[\n-        int]:\n+        # Define the function that will perform the update\n+        def perform_update(fields, table, doc_id):\n+            if callable(fields):\n+                # Update documents by calling the update function provided\n+                # by the user\n+                fields(table[doc_id])\n+            else:\n+                # Update documents by setting all fields from the provided\n+                # data\n+                table[doc_id].update(fields)\n+\n+        # Perform the update operation for documents specified by a query\n+\n+        # Collect affected doc_ids\n+        updated_ids = []\n+\n+        def updater(table: dict):\n+            # We need to convert the keys iterator to a list because\n+            # we may remove entries from the ``table`` dict during\n+            # iteration and doing this without the list conversion would\n+            # result in an exception (RuntimeError: dictionary changed size\n+            # during iteration)\n+            for doc_id in list(table.keys()):\n+                for fields, cond in updates:\n+                    _cond = cast(QueryLike, cond)\n+\n+                    # Pass through all documents to find documents matching the\n+                    # query. Call the processing callback with the document ID\n+                    if _cond(table[doc_id]):\n+                        # Add ID to list of updated documents\n+                        updated_ids.append(doc_id)\n+\n+                        # Perform the update (see above)\n+                        perform_update(fields, table, doc_id)\n+\n+        # Perform the update operation (see _update_table for details)\n+        self._update_table(updater)\n+\n+        return updated_ids\n+\n+    def upsert(self, document: Mapping, cond: Optional[QueryLike] = None) -&gt; List[int]:\n         \"\"\"\n         Update documents, if they exist, insert them otherwise.\n\n@@ -197,10 +519,39 @@ class Table:\n         Document with a doc_id\n         :returns: a list containing the updated documents' IDs\n         \"\"\"\n-        pass\n\n-    def remove(self, cond: Optional[QueryLike]=None, doc_ids: Optional[\n-        Iterable[int]]=None) -&gt;List[int]:\n+        # Extract doc_id\n+        if isinstance(document, Document) and hasattr(document, 'doc_id'):\n+            doc_ids: Optional[List[int]] = [document.doc_id]\n+        else:\n+            doc_ids = None\n+\n+        # Make sure we can actually find a matching document\n+        if doc_ids is None and cond is None:\n+            raise ValueError(\"If you don't specify a search query, you must \"\n+                             \"specify a doc_id. Hint: use a table.Document \"\n+                             \"object.\")\n+\n+        # Perform the update operation\n+        try:\n+            updated_docs: Optional[List[int]] = self.update(document, cond, doc_ids)\n+        except KeyError:\n+            # This happens when a doc_id is specified, but it's missing\n+            updated_docs = None\n+\n+        # If documents have been updated: return their IDs\n+        if updated_docs:\n+            return updated_docs\n+\n+        # There are no documents that match the specified query -&gt; insert the\n+        # data as a new document\n+        return [self.insert(document)]\n+\n+    def remove(\n+        self,\n+        cond: Optional[QueryLike] = None,\n+        doc_ids: Optional[Iterable[int]] = None,\n+    ) -&gt; List[int]:\n         \"\"\"\n         Remove all matching documents.\n\n@@ -208,50 +559,139 @@ class Table:\n         :param doc_ids: a list of document IDs\n         :returns: a list containing the removed documents' ID\n         \"\"\"\n-        pass\n+        if doc_ids is not None:\n+            # This function returns the list of IDs for the documents that have\n+            # been removed. When removing documents identified by a set of\n+            # document IDs, it's this list of document IDs we need to return\n+            # later.\n+            # We convert the document ID iterator into a list, so we can both\n+            # use the document IDs to remove the specified documents and\n+            # to return the list of affected document IDs\n+            removed_ids = list(doc_ids)\n+\n+            def updater(table: dict):\n+                for doc_id in removed_ids:\n+                    table.pop(doc_id)\n+\n+            # Perform the remove operation\n+            self._update_table(updater)\n+\n+            return removed_ids\n+\n+        if cond is not None:\n+            removed_ids = []\n+\n+            # This updater function will be called with the table data\n+            # as its first argument. See ``Table._update`` for details on this\n+            # operation\n+            def updater(table: dict):\n+                # We need to convince MyPy (the static type checker) that\n+                # the ``cond is not None`` invariant still holds true when\n+                # the updater function is called\n+                _cond = cast(QueryLike, cond)\n+\n+                # We need to convert the keys iterator to a list because\n+                # we may remove entries from the ``table`` dict during\n+                # iteration and doing this without the list conversion would\n+                # result in an exception (RuntimeError: dictionary changed size\n+                # during iteration)\n+                for doc_id in list(table.keys()):\n+                    if _cond(table[doc_id]):\n+                        # Add document ID to list of removed document IDs\n+                        removed_ids.append(doc_id)\n\n-    def truncate(self) -&gt;None:\n+                        # Remove document from the table\n+                        table.pop(doc_id)\n+\n+            # Perform the remove operation\n+            self._update_table(updater)\n+\n+            return removed_ids\n+\n+        raise RuntimeError('Use truncate() to remove all documents')\n+\n+    def truncate(self) -&gt; None:\n         \"\"\"\n         Truncate the table by removing all documents.\n         \"\"\"\n-        pass\n\n-    def count(self, cond: QueryLike) -&gt;int:\n+        # Update the table by resetting all data\n+        self._update_table(lambda table: table.clear())\n+\n+        # Reset document ID counter\n+        self._next_id = None\n+\n+    def count(self, cond: QueryLike) -&gt; int:\n         \"\"\"\n         Count the documents matching a query.\n\n         :param cond: the condition use\n         \"\"\"\n-        pass\n\n-    def clear_cache(self) -&gt;None:\n+        return len(self.search(cond))\n+\n+    def clear_cache(self) -&gt; None:\n         \"\"\"\n         Clear the query cache.\n         \"\"\"\n-        pass\n+\n+        self._query_cache.clear()\n\n     def __len__(self):\n         \"\"\"\n         Count the total number of documents in this table.\n         \"\"\"\n+\n         return len(self._read_table())\n\n-    def __iter__(self) -&gt;Iterator[Document]:\n+    def __iter__(self) -&gt; Iterator[Document]:\n         \"\"\"\n         Iterate over all documents stored in the table.\n\n         :returns: an iterator over all documents.\n         \"\"\"\n+\n+        # Iterate all documents and their IDs\n         for doc_id, doc in self._read_table().items():\n+            # Convert documents to the document class\n             yield self.document_class(doc, self.document_id_class(doc_id))\n\n     def _get_next_id(self):\n         \"\"\"\n         Return the ID for a newly inserted document.\n         \"\"\"\n-        pass\n\n-    def _read_table(self) -&gt;Dict[str, Mapping]:\n+        # If we already know the next ID\n+        if self._next_id is not None:\n+            next_id = self._next_id\n+            self._next_id = next_id + 1\n+\n+            return next_id\n+\n+        # Determine the next document ID by finding out the max ID value\n+        # of the current table documents\n+\n+        # Read the table documents\n+        table = self._read_table()\n+\n+        # If the table is empty, set the initial ID\n+        if not table:\n+            next_id = 1\n+            self._next_id = next_id + 1\n+\n+            return next_id\n+\n+        # Determine the next ID based on the maximum ID that's currently in use\n+        max_id = max(self.document_id_class(i) for i in table.keys())\n+        next_id = max_id + 1\n+\n+        # The next ID we will return AFTER this call needs to be larger than\n+        # the current next ID we calculated\n+        self._next_id = next_id + 1\n+\n+        return next_id\n+\n+    def _read_table(self) -&gt; Dict[str, Mapping]:\n         \"\"\"\n         Read the table data from the underlying storage.\n\n@@ -259,7 +699,22 @@ class Table:\n         we may not want to convert *all* documents when returning\n         only one document for example.\n         \"\"\"\n-        pass\n+\n+        # Retrieve the tables from the storage\n+        tables = self._storage.read()\n+\n+        if tables is None:\n+            # The database is empty\n+            return {}\n+\n+        # Retrieve the current table's data\n+        try:\n+            table = tables[self.name]\n+        except KeyError:\n+            # The table does not exist yet, so it is empty\n+            return {}\n+\n+        return table\n\n     def _update_table(self, updater: Callable[[Dict[int, Mapping]], None]):\n         \"\"\"\n@@ -274,4 +729,41 @@ class Table:\n         As a further optimization, we don't convert the documents into the\n         document class, as the table data will *not* be returned to the user.\n         \"\"\"\n-        pass\n+\n+        tables = self._storage.read()\n+\n+        if tables is None:\n+            # The database is empty\n+            tables = {}\n+\n+        try:\n+            raw_table = tables[self.name]\n+        except KeyError:\n+            # The table does not exist yet, so it is empty\n+            raw_table = {}\n+\n+        # Convert the document IDs to the document ID class.\n+        # This is required as the rest of TinyDB expects the document IDs\n+        # to be an instance of ``self.document_id_class`` but the storage\n+        # might convert dict keys to strings.\n+        table = {\n+            self.document_id_class(doc_id): doc\n+            for doc_id, doc in raw_table.items()\n+        }\n+\n+        # Perform the table update operation\n+        updater(table)\n+\n+        # Convert the document IDs back to strings.\n+        # This is required as some storages (most notably the JSON file format)\n+        # don't support IDs other than strings.\n+        tables[self.name] = {\n+            str(doc_id): doc\n+            for doc_id, doc in table.items()\n+        }\n+\n+        # Write the newly updated data back to the storage\n+        self._storage.write(tables)\n+\n+        # Clear the query cache, as the table contents have changed\n+        self.clear_cache()\ndiff --git a/tinydb/utils.py b/tinydb/utils.py\nindex 0721622..08430ba 100644\n--- a/tinydb/utils.py\n+++ b/tinydb/utils.py\n@@ -1,13 +1,17 @@\n \"\"\"\n Utility functions.\n \"\"\"\n+\n from collections import OrderedDict, abc\n-from typing import List, Iterator, TypeVar, Generic, Union, Optional, Type, TYPE_CHECKING\n+from typing import List, Iterator, TypeVar, Generic, Union, Optional, Type, \\\n+    TYPE_CHECKING\n+\n K = TypeVar('K')\n V = TypeVar('V')\n D = TypeVar('D')\n T = TypeVar('T')\n-__all__ = 'LRUCache', 'freeze', 'with_typehint'\n+\n+__all__ = ('LRUCache', 'freeze', 'with_typehint')\n\n\n def with_typehint(baseclass: Type[T]):\n@@ -23,7 +27,13 @@ def with_typehint(baseclass: Type[T]):\n     MyPy does not. For that reason TinyDB has a MyPy plugin in\n     ``mypy_plugin.py`` that adds support for this pattern.\n     \"\"\"\n-    pass\n+    if TYPE_CHECKING:\n+        # In the case of type checking: pretend that the target class inherits\n+        # from the specified base class\n+        return baseclass\n+\n+    # Otherwise: just inherit from `object` like a regular Python class\n+    return object\n\n\n class LRUCache(abc.MutableMapping, Generic[K, V]):\n@@ -40,31 +50,66 @@ class LRUCache(abc.MutableMapping, Generic[K, V]):\n     be discarded.\n     \"\"\"\n\n-    def __init__(self, capacity=None) -&gt;None:\n+    def __init__(self, capacity=None) -&gt; None:\n         self.capacity = capacity\n         self.cache: OrderedDict[K, V] = OrderedDict()\n\n-    def __len__(self) -&gt;int:\n+    @property\n+    def lru(self) -&gt; List[K]:\n+        return list(self.cache.keys())\n+\n+    @property\n+    def length(self) -&gt; int:\n+        return len(self.cache)\n+\n+    def clear(self) -&gt; None:\n+        self.cache.clear()\n+\n+    def __len__(self) -&gt; int:\n         return self.length\n\n-    def __contains__(self, key: object) -&gt;bool:\n+    def __contains__(self, key: object) -&gt; bool:\n         return key in self.cache\n\n-    def __setitem__(self, key: K, value: V) -&gt;None:\n+    def __setitem__(self, key: K, value: V) -&gt; None:\n         self.set(key, value)\n\n-    def __delitem__(self, key: K) -&gt;None:\n+    def __delitem__(self, key: K) -&gt; None:\n         del self.cache[key]\n\n-    def __getitem__(self, key) -&gt;V:\n+    def __getitem__(self, key) -&gt; V:\n         value = self.get(key)\n         if value is None:\n             raise KeyError(key)\n+\n         return value\n\n-    def __iter__(self) -&gt;Iterator[K]:\n+    def __iter__(self) -&gt; Iterator[K]:\n         return iter(self.cache)\n\n+    def get(self, key: K, default: Optional[D] = None) -&gt; Optional[Union[V, D]]:\n+        value = self.cache.get(key)\n+\n+        if value is not None:\n+            self.cache.move_to_end(key, last=True)\n+\n+            return value\n+\n+        return default\n+\n+    def set(self, key: K, value: V):\n+        if self.cache.get(key):\n+            self.cache.move_to_end(key, last=True)\n+\n+        else:\n+            self.cache[key] = value\n+\n+            # Check, if the cache is full and we have to remove old items\n+            # If the queue is of unlimited size, self.capacity is NaN and\n+            # x &gt; NaN is always False in Python and the cache won't be cleared.\n+            if self.capacity is not None and self.length &gt; self.capacity:\n+                self.cache.popitem(last=False)\n+\n\n class FrozenDict(dict):\n     \"\"\"\n@@ -76,16 +121,39 @@ class FrozenDict(dict):\n     \"\"\"\n\n     def __hash__(self):\n+        # Calculate the has by hashing a tuple of all dict items\n         return hash(tuple(sorted(self.items())))\n+\n+    def _immutable(self, *args, **kws):\n+        raise TypeError('object is immutable')\n+\n+    # Disable write access to the dict\n     __setitem__ = _immutable\n     __delitem__ = _immutable\n     clear = _immutable\n-    setdefault = _immutable\n+    setdefault = _immutable  # type: ignore\n     popitem = _immutable\n\n+    def update(self, e=None, **f):\n+        raise TypeError('object is immutable')\n+\n+    def pop(self, k, d=None):\n+        raise TypeError('object is immutable')\n+\n\n def freeze(obj):\n     \"\"\"\n     Freeze an object by making it immutable and thus hashable.\n     \"\"\"\n-    pass\n+    if isinstance(obj, dict):\n+        # Transform dicts into ``FrozenDict``s\n+        return FrozenDict((k, freeze(v)) for k, v in obj.items())\n+    elif isinstance(obj, list):\n+        # Transform lists into tuples\n+        return tuple(freeze(el) for el in obj)\n+    elif isinstance(obj, set):\n+        # Transform sets into ``frozenset``s\n+        return frozenset(obj)\n+    else:\n+        # Don't handle all other objects\n+        return obj\n</code></pre>"},{"location":"analysis_reference_voluptuous/","title":"Analysis reference voluptuous","text":"<p>back to reference summary</p>"},{"location":"analysis_reference_voluptuous/#submission-name-reference","title":"Submission Name: reference","text":""},{"location":"analysis_reference_voluptuous/#repository-voluptuous","title":"Repository: voluptuous","text":""},{"location":"analysis_reference_voluptuous/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count passed 149 total 149 collected 149"},{"location":"analysis_reference_voluptuous/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_reference_voluptuous/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/voluptuous/error.py b/voluptuous/error.py\nindex f72fbe7..9dab943 100644\n--- a/voluptuous/error.py\n+++ b/voluptuous/error.py\n@@ -1,5 +1,8 @@\n+# fmt: off\n import typing\n\n+# fmt: on\n+\n\n class Error(Exception):\n     \"\"\"Base validation exception.\"\"\"\n@@ -19,35 +22,70 @@ class Invalid(Error):\n\n     \"\"\"\n\n-    def __init__(self, message: str, path: typing.Optional[typing.List[\n-        typing.Hashable]]=None, error_message: typing.Optional[str]=None,\n-        error_type: typing.Optional[str]=None) -&gt;None:\n+    def __init__(\n+        self,\n+        message: str,\n+        path: typing.Optional[typing.List[typing.Hashable]] = None,\n+        error_message: typing.Optional[str] = None,\n+        error_type: typing.Optional[str] = None,\n+    ) -&gt; None:\n         Error.__init__(self, message)\n         self._path = path or []\n         self._error_message = error_message or message\n         self.error_type = error_type\n\n-    def __str__(self) -&gt;str:\n-        path = ' @ data[%s]' % ']['.join(map(repr, self.path)\n-            ) if self.path else ''\n+    @property\n+    def msg(self) -&gt; str:\n+        return self.args[0]\n+\n+    @property\n+    def path(self) -&gt; typing.List[typing.Hashable]:\n+        return self._path\n+\n+    @property\n+    def error_message(self) -&gt; str:\n+        return self._error_message\n+\n+    def __str__(self) -&gt; str:\n+        path = ' @ data[%s]' % ']['.join(map(repr, self.path)) if self.path else ''\n         output = Exception.__str__(self)\n         if self.error_type:\n             output += ' for ' + self.error_type\n         return output + path\n\n+    def prepend(self, path: typing.List[typing.Hashable]) -&gt; None:\n+        self._path = path + self.path\n\n-class MultipleInvalid(Invalid):\n\n-    def __init__(self, errors: typing.Optional[typing.List[Invalid]]=None\n-        ) -&gt;None:\n+class MultipleInvalid(Invalid):\n+    def __init__(self, errors: typing.Optional[typing.List[Invalid]] = None) -&gt; None:\n         self.errors = errors[:] if errors else []\n\n-    def __repr__(self) -&gt;str:\n+    def __repr__(self) -&gt; str:\n         return 'MultipleInvalid(%r)' % self.errors\n\n-    def __str__(self) -&gt;str:\n+    @property\n+    def msg(self) -&gt; str:\n+        return self.errors[0].msg\n+\n+    @property\n+    def path(self) -&gt; typing.List[typing.Hashable]:\n+        return self.errors[0].path\n+\n+    @property\n+    def error_message(self) -&gt; str:\n+        return self.errors[0].error_message\n+\n+    def add(self, error: Invalid) -&gt; None:\n+        self.errors.append(error)\n+\n+    def __str__(self) -&gt; str:\n         return str(self.errors[0])\n\n+    def prepend(self, path: typing.List[typing.Hashable]) -&gt; None:\n+        for error in self.errors:\n+            error.prepend(path)\n+\n\n class RequiredFieldInvalid(Invalid):\n     \"\"\"Required field was missing.\"\"\"\n@@ -171,9 +209,11 @@ class ExactSequenceInvalid(Invalid):\n\n class NotEnoughValid(Invalid):\n     \"\"\"The value did not pass enough validations.\"\"\"\n+\n     pass\n\n\n class TooManyValid(Invalid):\n     \"\"\"The value passed more than expected validations.\"\"\"\n+\n     pass\ndiff --git a/voluptuous/humanize.py b/voluptuous/humanize.py\nindex 2902871..eabfd02 100644\n--- a/voluptuous/humanize.py\n+++ b/voluptuous/humanize.py\n@@ -1,14 +1,57 @@\n+# fmt: off\n import typing\n+\n from voluptuous import Invalid, MultipleInvalid\n from voluptuous.error import Error\n from voluptuous.schema_builder import Schema\n+\n+# fmt: on\n+\n MAX_VALIDATION_ERROR_ITEM_LENGTH = 500\n\n\n-def humanize_error(data, validation_error: Invalid, max_sub_error_length:\n-    int=MAX_VALIDATION_ERROR_ITEM_LENGTH) -&gt;str:\n+def _nested_getitem(\n+    data: typing.Any, path: typing.List[typing.Hashable]\n+) -&gt; typing.Optional[typing.Any]:\n+    for item_index in path:\n+        try:\n+            data = data[item_index]\n+        except (KeyError, IndexError, TypeError):\n+            # The index is not present in the dictionary, list or other\n+            # indexable or data is not subscriptable\n+            return None\n+    return data\n+\n+\n+def humanize_error(\n+    data,\n+    validation_error: Invalid,\n+    max_sub_error_length: int = MAX_VALIDATION_ERROR_ITEM_LENGTH,\n+) -&gt; str:\n     \"\"\"Provide a more helpful + complete validation error message than that provided automatically\n     Invalid and MultipleInvalid do not include the offending value in error messages,\n     and MultipleInvalid.__str__ only provides the first error.\n     \"\"\"\n-    pass\n+    if isinstance(validation_error, MultipleInvalid):\n+        return '\\n'.join(\n+            sorted(\n+                humanize_error(data, sub_error, max_sub_error_length)\n+                for sub_error in validation_error.errors\n+            )\n+        )\n+    else:\n+        offending_item_summary = repr(_nested_getitem(data, validation_error.path))\n+        if len(offending_item_summary) &gt; max_sub_error_length:\n+            offending_item_summary = (\n+                offending_item_summary[: max_sub_error_length - 3] + '...'\n+            )\n+        return '%s. Got %s' % (validation_error, offending_item_summary)\n+\n+\n+def validate_with_humanized_errors(\n+    data, schema: Schema, max_sub_error_length: int = MAX_VALIDATION_ERROR_ITEM_LENGTH\n+) -&gt; typing.Any:\n+    try:\n+        return schema(data)\n+    except (Invalid, MultipleInvalid) as e:\n+        raise Error(humanize_error(data, e, max_sub_error_length))\ndiff --git a/voluptuous/schema_builder.py b/voluptuous/schema_builder.py\nindex de2b53c..cdeb514 100644\n--- a/voluptuous/schema_builder.py\n+++ b/voluptuous/schema_builder.py\n@@ -1,4 +1,6 @@\n+# fmt: off\n from __future__ import annotations\n+\n import collections\n import inspect\n import itertools\n@@ -8,15 +10,23 @@ import typing\n from collections.abc import Generator\n from contextlib import contextmanager\n from functools import cache, wraps\n+\n from voluptuous import error as er\n from voluptuous.error import Error\n-PREVENT_EXTRA = 0\n-ALLOW_EXTRA = 1\n-REMOVE_EXTRA = 2\n\n+# fmt: on\n\n-class Undefined(object):\n+# options for extra keys\n+PREVENT_EXTRA = 0  # any extra key not in schema will raise an error\n+ALLOW_EXTRA = 1  # extra keys not in schema will be included in output\n+REMOVE_EXTRA = 2  # extra keys not in schema will be excluded from output\n+\n+\n+def _isnamedtuple(obj):\n+    return isinstance(obj, tuple) and hasattr(obj, '_fields')\n\n+\n+class Undefined(object):\n     def __nonzero__(self):\n         return False\n\n@@ -25,19 +35,56 @@ class Undefined(object):\n\n\n UNDEFINED = Undefined()\n+\n+\n+def Self() -&gt; None:\n+    raise er.SchemaError('\"Self\" should never be called')\n+\n+\n DefaultFactory = typing.Union[Undefined, typing.Callable[[], typing.Any]]\n\n\n-def Extra(_) -&gt;None:\n+def default_factory(value) -&gt; DefaultFactory:\n+    if value is UNDEFINED or callable(value):\n+        return value\n+    return lambda: value\n+\n+\n+@contextmanager\n+def raises(\n+    exc, msg: typing.Optional[str] = None, regex: typing.Optional[re.Pattern] = None\n+) -&gt; Generator[None, None, None]:\n+    try:\n+        yield\n+    except exc as e:\n+        if msg is not None:\n+            assert str(e) == msg, '%r != %r' % (str(e), msg)\n+        if regex is not None:\n+            assert re.search(regex, str(e)), '%r does not match %r' % (str(e), regex)\n+    else:\n+        raise AssertionError(f\"Did not raise exception {exc.__name__}\")\n+\n+\n+def Extra(_) -&gt; None:\n     \"\"\"Allow keys in the data that are not present in the schema.\"\"\"\n-    pass\n+    raise er.SchemaError('\"Extra\" should never be called')\n\n\n+# As extra() is never called there's no way to catch references to the\n+# deprecated object, so we just leave an alias here instead.\n extra = Extra\n-primitive_types = bool, bytes, int, str, float, complex\n-Schemable = typing.Union['Schema', 'Object', collections.abc.Mapping, list,\n-    tuple, frozenset, set, bool, bytes, int, str, float, complex, type,\n-    object, dict, None, typing.Callable]\n+\n+primitive_types = (bool, bytes, int, str, float, complex)\n+\n+# fmt: off\n+Schemable = typing.Union[\n+    'Schema', 'Object',\n+    collections.abc.Mapping,\n+    list, tuple, frozenset, set,\n+    bool, bytes, int, str, float, complex,\n+    type, object, dict, None, typing.Callable\n+]\n+# fmt: on\n\n\n class Schema(object):\n@@ -61,11 +108,16 @@ class Schema(object):\n             &gt;&gt;&gt; assert v != v2\n\n     \"\"\"\n-    _extra_to_name = {REMOVE_EXTRA: 'REMOVE_EXTRA', ALLOW_EXTRA:\n-        'ALLOW_EXTRA', PREVENT_EXTRA: 'PREVENT_EXTRA'}\n\n-    def __init__(self, schema: Schemable, required: bool=False, extra: int=\n-        PREVENT_EXTRA) -&gt;None:\n+    _extra_to_name = {\n+        REMOVE_EXTRA: 'REMOVE_EXTRA',\n+        ALLOW_EXTRA: 'ALLOW_EXTRA',\n+        PREVENT_EXTRA: 'PREVENT_EXTRA',\n+    }\n+\n+    def __init__(\n+        self, schema: Schemable, required: bool = False, extra: int = PREVENT_EXTRA\n+    ) -&gt; None:\n         \"\"\"Create a new Schema.\n\n         :param schema: Validation schema. See :module:`voluptuous` for details.\n@@ -82,11 +134,11 @@ class Schema(object):\n         \"\"\"\n         self.schema: typing.Any = schema\n         self.required = required\n-        self.extra = int(extra)\n+        self.extra = int(extra)  # ensure the value is an integer\n         self._compiled = self._compile(schema)\n\n     @classmethod\n-    def infer(cls, data, **kwargs) -&gt;Schema:\n+    def infer(cls, data, **kwargs) -&gt; Schema:\n         \"\"\"Create a Schema from concrete data (e.g. an API response).\n\n         For example, this will take a dict like:\n@@ -113,7 +165,20 @@ class Schema(object):\n\n         Note: only very basic inference is supported.\n         \"\"\"\n-        pass\n+\n+        def value_to_schema_type(value):\n+            if isinstance(value, dict):\n+                if len(value) == 0:\n+                    return dict\n+                return {k: value_to_schema_type(v) for k, v in value.items()}\n+            if isinstance(value, list):\n+                if len(value) == 0:\n+                    return list\n+                else:\n+                    return [value_to_schema_type(v) for v in value]\n+            return type(value)\n+\n+        return cls(value_to_schema_type(data), **kwargs)\n\n     def __eq__(self, other):\n         if not isinstance(other, Schema):\n@@ -121,15 +186,18 @@ class Schema(object):\n         return other.schema == self.schema\n\n     def __ne__(self, other):\n-        return not self == other\n+        return not (self == other)\n\n     def __str__(self):\n         return str(self.schema)\n\n     def __repr__(self):\n-        return '&lt;Schema(%s, extra=%s, required=%s) object at 0x%x&gt;' % (self\n-            .schema, self._extra_to_name.get(self.extra, '??'), self.\n-            required, id(self))\n+        return \"&lt;Schema(%s, extra=%s, required=%s) object at 0x%x&gt;\" % (\n+            self.schema,\n+            self._extra_to_name.get(self.extra, '??'),\n+            self.required,\n+            id(self),\n+        )\n\n     def __call__(self, data):\n         \"\"\"Validate data against this schema.\"\"\"\n@@ -139,10 +207,183 @@ class Schema(object):\n             raise\n         except er.Invalid as e:\n             raise er.MultipleInvalid([e])\n+            # return self.validate([], self.schema, data)\n+\n+    def _compile(self, schema):\n+        if schema is Extra:\n+            return lambda _, v: v\n+        if schema is Self:\n+            return lambda p, v: self._compiled(p, v)\n+        elif hasattr(schema, \"__voluptuous_compile__\"):\n+            return schema.__voluptuous_compile__(self)\n+        if isinstance(schema, Object):\n+            return self._compile_object(schema)\n+        if isinstance(schema, collections.abc.Mapping):\n+            return self._compile_dict(schema)\n+        elif isinstance(schema, list):\n+            return self._compile_list(schema)\n+        elif isinstance(schema, tuple):\n+            return self._compile_tuple(schema)\n+        elif isinstance(schema, (frozenset, set)):\n+            return self._compile_set(schema)\n+        type_ = type(schema)\n+        if inspect.isclass(schema):\n+            type_ = schema\n+        if type_ in (*primitive_types, object, type(None)) or callable(schema):\n+            return _compile_scalar(schema)\n+        raise er.SchemaError('unsupported schema data type %r' % type(schema).__name__)\n\n     def _compile_mapping(self, schema, invalid_msg=None):\n         \"\"\"Create validator for given mapping.\"\"\"\n-        pass\n+        invalid_msg = invalid_msg or 'mapping value'\n+\n+        # Keys that may be required\n+        all_required_keys = set(\n+            key\n+            for key in schema\n+            if key is not Extra\n+            and (\n+                (self.required and not isinstance(key, (Optional, Remove)))\n+                or isinstance(key, Required)\n+            )\n+        )\n+\n+        # Keys that may have defaults\n+        all_default_keys = set(\n+            key\n+            for key in schema\n+            if isinstance(key, Required) or isinstance(key, Optional)\n+        )\n+\n+        _compiled_schema = {}\n+        for skey, svalue in schema.items():\n+            new_key = self._compile(skey)\n+            new_value = self._compile(svalue)\n+            _compiled_schema[skey] = (new_key, new_value)\n+\n+        candidates = list(_iterate_mapping_candidates(_compiled_schema))\n+\n+        # After we have the list of candidates in the correct order, we want to apply some optimization so that each\n+        # key in the data being validated will be matched against the relevant schema keys only.\n+        # No point in matching against different keys\n+        additional_candidates = []\n+        candidates_by_key = {}\n+        for skey, (ckey, cvalue) in candidates:\n+            if type(skey) in primitive_types:\n+                candidates_by_key.setdefault(skey, []).append((skey, (ckey, cvalue)))\n+            elif isinstance(skey, Marker) and type(skey.schema) in primitive_types:\n+                candidates_by_key.setdefault(skey.schema, []).append(\n+                    (skey, (ckey, cvalue))\n+                )\n+            else:\n+                # These are wildcards such as 'int', 'str', 'Remove' and others which should be applied to all keys\n+                additional_candidates.append((skey, (ckey, cvalue)))\n+\n+        def validate_mapping(path, iterable, out):\n+            required_keys = all_required_keys.copy()\n+\n+            # Build a map of all provided key-value pairs.\n+            # The type(out) is used to retain ordering in case a ordered\n+            # map type is provided as input.\n+            key_value_map = type(out)()\n+            for key, value in iterable:\n+                key_value_map[key] = value\n+\n+            # Insert default values for non-existing keys.\n+            for key in all_default_keys:\n+                if (\n+                    not isinstance(key.default, Undefined)\n+                    and key.schema not in key_value_map\n+                ):\n+                    # A default value has been specified for this missing\n+                    # key, insert it.\n+                    key_value_map[key.schema] = key.default()\n+\n+            errors = []\n+            for key, value in key_value_map.items():\n+                key_path = path + [key]\n+                remove_key = False\n+\n+                # Optimization. Validate against the matching key first, then fallback to the rest\n+                relevant_candidates = itertools.chain(\n+                    candidates_by_key.get(key, []), additional_candidates\n+                )\n+\n+                # compare each given key/value against all compiled key/values\n+                # schema key, (compiled key, compiled value)\n+                error = None\n+                for skey, (ckey, cvalue) in relevant_candidates:\n+                    try:\n+                        new_key = ckey(key_path, key)\n+                    except er.Invalid as e:\n+                        if len(e.path) &gt; len(key_path):\n+                            raise\n+                        if not error or len(e.path) &gt; len(error.path):\n+                            error = e\n+                        continue\n+                    # Backtracking is not performed once a key is selected, so if\n+                    # the value is invalid we immediately throw an exception.\n+                    exception_errors = []\n+                    # check if the key is marked for removal\n+                    is_remove = new_key is Remove\n+                    try:\n+                        cval = cvalue(key_path, value)\n+                        # include if it's not marked for removal\n+                        if not is_remove:\n+                            out[new_key] = cval\n+                        else:\n+                            remove_key = True\n+                            continue\n+                    except er.MultipleInvalid as e:\n+                        exception_errors.extend(e.errors)\n+                    except er.Invalid as e:\n+                        exception_errors.append(e)\n+\n+                    if exception_errors:\n+                        if is_remove or remove_key:\n+                            continue\n+                        for err in exception_errors:\n+                            if len(err.path) &lt;= len(key_path):\n+                                err.error_type = invalid_msg\n+                            errors.append(err)\n+                        # If there is a validation error for a required\n+                        # key, this means that the key was provided.\n+                        # Discard the required key so it does not\n+                        # create an additional, noisy exception.\n+                        required_keys.discard(skey)\n+                        break\n+\n+                    # Key and value okay, mark as found in case it was\n+                    # a Required() field.\n+                    required_keys.discard(skey)\n+\n+                    break\n+                else:\n+                    if remove_key:\n+                        # remove key\n+                        continue\n+                    elif self.extra == ALLOW_EXTRA:\n+                        out[key] = value\n+                    elif error:\n+                        errors.append(error)\n+                    elif self.extra != REMOVE_EXTRA:\n+                        errors.append(er.Invalid('extra keys not allowed', key_path))\n+                        # else REMOVE_EXTRA: ignore the key so it's removed from output\n+\n+            # for any required keys left that weren't found and don't have defaults:\n+            for key in required_keys:\n+                msg = (\n+                    key.msg\n+                    if hasattr(key, 'msg') and key.msg\n+                    else 'required key not provided'\n+                )\n+                errors.append(er.RequiredFieldInvalid(msg, path + [key]))\n+            if errors:\n+                raise er.MultipleInvalid(errors)\n+\n+            return out\n+\n+        return validate_mapping\n\n     def _compile_object(self, schema):\n         \"\"\"Validate an object.\n@@ -162,7 +403,17 @@ class Schema(object):\n             ...   validate(Structure(one='three'))\n\n         \"\"\"\n-        pass\n+        base_validate = self._compile_mapping(schema, invalid_msg='object value')\n+\n+        def validate_object(path, data):\n+            if schema.cls is not UNDEFINED and not isinstance(data, schema.cls):\n+                raise er.ObjectInvalid('expected a {0!r}'.format(schema.cls), path)\n+            iterable = _iterate_object(data)\n+            iterable = filter(lambda item: item[1] is not None, iterable)\n+            out = base_validate(path, iterable, {})\n+            return type(data)(**out)\n+\n+        return validate_object\n\n     def _compile_dict(self, schema):\n         \"\"\"Validate a dictionary.\n@@ -240,7 +491,64 @@ class Schema(object):\n          \"expected str for dictionary value @ data['adict']['strfield']\"]\n\n         \"\"\"\n-        pass\n+        base_validate = self._compile_mapping(schema, invalid_msg='dictionary value')\n+\n+        groups_of_exclusion = {}\n+        groups_of_inclusion = {}\n+        for node in schema:\n+            if isinstance(node, Exclusive):\n+                g = groups_of_exclusion.setdefault(node.group_of_exclusion, [])\n+                g.append(node)\n+            elif isinstance(node, Inclusive):\n+                g = groups_of_inclusion.setdefault(node.group_of_inclusion, [])\n+                g.append(node)\n+\n+        def validate_dict(path, data):\n+            if not isinstance(data, dict):\n+                raise er.DictInvalid('expected a dictionary', path)\n+\n+            errors = []\n+            for label, group in groups_of_exclusion.items():\n+                exists = False\n+                for exclusive in group:\n+                    if exclusive.schema in data:\n+                        if exists:\n+                            msg = (\n+                                exclusive.msg\n+                                if hasattr(exclusive, 'msg') and exclusive.msg\n+                                else \"two or more values in the same group of exclusion '%s'\"\n+                                % label\n+                            )\n+                            next_path = path + [VirtualPathComponent(label)]\n+                            errors.append(er.ExclusiveInvalid(msg, next_path))\n+                            break\n+                        exists = True\n+\n+            if errors:\n+                raise er.MultipleInvalid(errors)\n+\n+            for label, group in groups_of_inclusion.items():\n+                included = [node.schema in data for node in group]\n+                if any(included) and not all(included):\n+                    msg = (\n+                        \"some but not all values in the same group of inclusion '%s'\"\n+                        % label\n+                    )\n+                    for g in group:\n+                        if hasattr(g, 'msg') and g.msg:\n+                            msg = g.msg\n+                            break\n+                    next_path = path + [VirtualPathComponent(label)]\n+                    errors.append(er.InclusiveInvalid(msg, next_path))\n+                    break\n+\n+            if errors:\n+                raise er.MultipleInvalid(errors)\n+\n+            out = data.__class__()\n+            return base_validate(path, data.items(), out)\n+\n+        return validate_dict\n\n     def _compile_sequence(self, schema, seq_type):\n         \"\"\"Validate a sequence type.\n@@ -255,7 +563,49 @@ class Schema(object):\n         &gt;&gt;&gt; validator([1])\n         [1]\n         \"\"\"\n-        pass\n+        _compiled = [self._compile(s) for s in schema]\n+        seq_type_name = seq_type.__name__\n+\n+        def validate_sequence(path, data):\n+            if not isinstance(data, seq_type):\n+                raise er.SequenceTypeInvalid('expected a %s' % seq_type_name, path)\n+\n+            # Empty seq schema, reject any data.\n+            if not schema:\n+                if data:\n+                    raise er.MultipleInvalid(\n+                        [er.ValueInvalid('not a valid value', path if path else data)]\n+                    )\n+                return data\n+\n+            out = []\n+            invalid = None\n+            errors = []\n+            index_path = UNDEFINED\n+            for i, value in enumerate(data):\n+                index_path = path + [i]\n+                invalid = None\n+                for validate in _compiled:\n+                    try:\n+                        cval = validate(index_path, value)\n+                        if cval is not Remove:  # do not include Remove values\n+                            out.append(cval)\n+                        break\n+                    except er.Invalid as e:\n+                        if len(e.path) &gt; len(index_path):\n+                            raise\n+                        invalid = e\n+                else:\n+                    errors.append(invalid)\n+            if errors:\n+                raise er.MultipleInvalid(errors)\n+\n+            if _isnamedtuple(data):\n+                return type(data)(*out)\n+            else:\n+                return type(data)(out)\n+\n+        return validate_sequence\n\n     def _compile_tuple(self, schema):\n         \"\"\"Validate a tuple.\n@@ -270,7 +620,7 @@ class Schema(object):\n         &gt;&gt;&gt; validator((1,))\n         (1,)\n         \"\"\"\n-        pass\n+        return self._compile_sequence(schema, tuple)\n\n     def _compile_list(self, schema):\n         \"\"\"Validate a list.\n@@ -285,7 +635,7 @@ class Schema(object):\n         &gt;&gt;&gt; validator([1])\n         [1]\n         \"\"\"\n-        pass\n+        return self._compile_sequence(schema, list)\n\n     def _compile_set(self, schema):\n         \"\"\"Validate a set.\n@@ -300,10 +650,39 @@ class Schema(object):\n         &gt;&gt;&gt; with raises(er.MultipleInvalid, 'invalid value in set'):\n         ...   validator(set(['a']))\n         \"\"\"\n-        pass\n-\n-    def extend(self, schema: Schemable, required: typing.Optional[bool]=\n-        None, extra: typing.Optional[int]=None) -&gt;Schema:\n+        type_ = type(schema)\n+        type_name = type_.__name__\n+\n+        def validate_set(path, data):\n+            if not isinstance(data, type_):\n+                raise er.Invalid('expected a %s' % type_name, path)\n+\n+            _compiled = [self._compile(s) for s in schema]\n+            errors = []\n+            for value in data:\n+                for validate in _compiled:\n+                    try:\n+                        validate(path, value)\n+                        break\n+                    except er.Invalid:\n+                        pass\n+                else:\n+                    invalid = er.Invalid('invalid value in %s' % type_name, path)\n+                    errors.append(invalid)\n+\n+            if errors:\n+                raise er.MultipleInvalid(errors)\n+\n+            return data\n+\n+        return validate_set\n+\n+    def extend(\n+        self,\n+        schema: Schemable,\n+        required: typing.Optional[bool] = None,\n+        extra: typing.Optional[int] = None,\n+    ) -&gt; Schema:\n         \"\"\"Create a new `Schema` by merging this and the provided `schema`.\n\n         Neither this `Schema` nor the provided `schema` are modified. The\n@@ -316,7 +695,51 @@ class Schema(object):\n         :param required: if set, overrides `required` of this `Schema`\n         :param extra: if set, overrides `extra` of this `Schema`\n         \"\"\"\n-        pass\n+\n+        assert isinstance(self.schema, dict) and isinstance(\n+            schema, dict\n+        ), 'Both schemas must be dictionary-based'\n+\n+        result = self.schema.copy()\n+\n+        # returns the key that may have been passed as an argument to Marker constructor\n+        def key_literal(key):\n+            return key.schema if isinstance(key, Marker) else key\n+\n+        # build a map that takes the key literals to the needed objects\n+        # literal -&gt; Required|Optional|literal\n+        result_key_map = dict((key_literal(key), key) for key in result)\n+\n+        # for each item in the extension schema, replace duplicates\n+        # or add new keys\n+        for key, value in schema.items():\n+            # if the key is already in the dictionary, we need to replace it\n+            # transform key to literal before checking presence\n+            if key_literal(key) in result_key_map:\n+                result_key = result_key_map[key_literal(key)]\n+                result_value = result[result_key]\n+\n+                # if both are dictionaries, we need to extend recursively\n+                # create the new extended sub schema, then remove the old key and add the new one\n+                if isinstance(result_value, dict) and isinstance(value, dict):\n+                    new_value = Schema(result_value).extend(value).schema\n+                    del result[result_key]\n+                    result[key] = new_value\n+                # one or the other or both are not sub-schemas, simple replacement is fine\n+                # remove old key and add new one\n+                else:\n+                    del result[result_key]\n+                    result[key] = value\n+\n+            # key is new and can simply be added\n+            else:\n+                result[key] = value\n+\n+        # recompile and send old object\n+        result_cls = type(self)\n+        result_required = required if required is not None else self.required\n+        result_extra = extra if extra is not None else self.extra\n+        return result_cls(result, required=result_required, extra=result_extra)\n\n\n def _compile_scalar(schema):\n@@ -338,12 +761,78 @@ def _compile_scalar(schema):\n     &gt;&gt;&gt; with raises(er.Invalid, 'not a valid value'):\n     ...   _compile_scalar(lambda v: float(v))([], 'a')\n     \"\"\"\n-    pass\n+    if inspect.isclass(schema):\n+\n+        def validate_instance(path, data):\n+            if isinstance(data, schema):\n+                return data\n+            else:\n+                msg = 'expected %s' % schema.__name__\n+                raise er.TypeInvalid(msg, path)\n+\n+        return validate_instance\n+\n+    if callable(schema):\n+\n+        def validate_callable(path, data):\n+            try:\n+                return schema(data)\n+            except ValueError:\n+                raise er.ValueInvalid('not a valid value', path)\n+            except er.Invalid as e:\n+                e.prepend(path)\n+                raise\n+\n+        return validate_callable\n+\n+    def validate_value(path, data):\n+        if data != schema:\n+            raise er.ScalarInvalid('not a valid value', path)\n+        return data\n+\n+    return validate_value\n\n\n def _compile_itemsort():\n-    \"\"\"return sort function of mappings\"\"\"\n-    pass\n+    '''return sort function of mappings'''\n+\n+    def is_extra(key_):\n+        return key_ is Extra\n+\n+    def is_remove(key_):\n+        return isinstance(key_, Remove)\n+\n+    def is_marker(key_):\n+        return isinstance(key_, Marker)\n+\n+    def is_type(key_):\n+        return inspect.isclass(key_)\n+\n+    def is_callable(key_):\n+        return callable(key_)\n+\n+    # priority list for map sorting (in order of checking)\n+    # We want Extra to match last, because it's a catch-all. On the other hand,\n+    # Remove markers should match first (since invalid values will not\n+    # raise an Error, instead the validator will check if other schemas match\n+    # the same value).\n+    priority = [\n+        (1, is_remove),  # Remove highest priority after values\n+        (2, is_marker),  # then other Markers\n+        (4, is_type),  # types/classes lowest before Extra\n+        (3, is_callable),  # callables after markers\n+        (5, is_extra),  # Extra lowest priority\n+    ]\n+\n+    def item_priority(item_):\n+        key_ = item_[0]\n+        for i, check_ in priority:\n+            if check_(key_):\n+                return i\n+        # values have highest priorities\n+        return 0\n+\n+    return item_priority\n\n\n _sort_item = _compile_itemsort()\n@@ -351,7 +840,10 @@ _sort_item = _compile_itemsort()\n\n def _iterate_mapping_candidates(schema):\n     \"\"\"Iterate over schema in a meaningful order.\"\"\"\n-    pass\n+    # Without this, Extra might appear first in the iterator, and fail to\n+    # validate a key even though it's a Required that has its own validation,\n+    # generating a false positive.\n+    return sorted(schema.items(), key=_sort_item)\n\n\n def _iterate_object(obj):\n@@ -359,7 +851,23 @@ def _iterate_object(obj):\n     defined __slots__.\n\n     \"\"\"\n-    pass\n+    d = {}\n+    try:\n+        d = vars(obj)\n+    except TypeError:\n+        # maybe we have named tuple here?\n+        if hasattr(obj, '_asdict'):\n+            d = obj._asdict()\n+    for item in d.items():\n+        yield item\n+    try:\n+        slots = obj.__slots__\n+    except AttributeError:\n+        pass\n+    else:\n+        for key in slots:\n+            if key != '__dict__':\n+                yield (key, getattr(obj, key))\n\n\n class Msg(object):\n@@ -391,11 +899,16 @@ class Msg(object):\n     ...   assert isinstance(e.errors[0], er.RangeInvalid)\n     \"\"\"\n\n-    def __init__(self, schema: Schemable, msg: str, cls: typing.Optional[\n-        typing.Type[Error]]=None) -&gt;None:\n+    def __init__(\n+        self,\n+        schema: Schemable,\n+        msg: str,\n+        cls: typing.Optional[typing.Type[Error]] = None,\n+    ) -&gt; None:\n         if cls and not issubclass(cls, er.Invalid):\n             raise er.SchemaError(\n-                'Msg can only use subclases of Invalid as custom class')\n+                \"Msg can only use subclases of Invalid as custom class\"\n+            )\n         self._schema = schema\n         self.schema = Schema(schema)\n         self.msg = msg\n@@ -417,13 +930,12 @@ class Msg(object):\n class Object(dict):\n     \"\"\"Indicate that we should work with attributes, not keys.\"\"\"\n\n-    def __init__(self, schema: typing.Any, cls: object=UNDEFINED) -&gt;None:\n+    def __init__(self, schema: typing.Any, cls: object = UNDEFINED) -&gt; None:\n         self.cls = cls\n         super(Object, self).__init__(schema)\n\n\n class VirtualPathComponent(str):\n-\n     def __str__(self):\n         return '&lt;' + self + '&gt;'\n\n@@ -437,15 +949,20 @@ class Marker(object):\n     `description` is an optional field, unused by Voluptuous itself, but can be\n     introspected by any external tool, for example to generate schema documentation.\n     \"\"\"\n-    __slots__ = 'schema', '_schema', 'msg', 'description', '__hash__'\n\n-    def __init__(self, schema_: Schemable, msg: typing.Optional[str]=None,\n-        description: (typing.Any | None)=None) -&gt;None:\n+    __slots__ = ('schema', '_schema', 'msg', 'description', '__hash__')\n+\n+    def __init__(\n+        self,\n+        schema_: Schemable,\n+        msg: typing.Optional[str] = None,\n+        description: typing.Any | None = None,\n+    ) -&gt; None:\n         self.schema: typing.Any = schema_\n         self._schema = Schema(schema_)\n         self.msg = msg\n         self.description = description\n-        self.__hash__ = cache(lambda : hash(schema_))\n+        self.__hash__ = cache(lambda: hash(schema_))  # type: ignore[method-assign]\n\n     def __call__(self, v):\n         try:\n@@ -470,7 +987,7 @@ class Marker(object):\n         return self.schema == other\n\n     def __ne__(self, other):\n-        return not self.schema == other\n+        return not (self.schema == other)\n\n\n class Optional(Marker):\n@@ -496,11 +1013,14 @@ class Optional(Marker):\n     {'key2': 'value'}\n     \"\"\"\n\n-    def __init__(self, schema: Schemable, msg: typing.Optional[str]=None,\n-        default: typing.Any=UNDEFINED, description: (typing.Any | None)=None\n-        ) -&gt;None:\n-        super(Optional, self).__init__(schema, msg=msg, description=description\n-            )\n+    def __init__(\n+        self,\n+        schema: Schemable,\n+        msg: typing.Optional[str] = None,\n+        default: typing.Any = UNDEFINED,\n+        description: typing.Any | None = None,\n+    ) -&gt; None:\n+        super(Optional, self).__init__(schema, msg=msg, description=description)\n         self.default = default_factory(default)\n\n\n@@ -540,11 +1060,14 @@ class Exclusive(Optional):\n     ...             'social': {'social_network': 'barfoo', 'token': 'tEMp'}})\n     \"\"\"\n\n-    def __init__(self, schema: Schemable, group_of_exclusion: str, msg:\n-        typing.Optional[str]=None, description: (typing.Any | None)=None\n-        ) -&gt;None:\n-        super(Exclusive, self).__init__(schema, msg=msg, description=\n-            description)\n+    def __init__(\n+        self,\n+        schema: Schemable,\n+        group_of_exclusion: str,\n+        msg: typing.Optional[str] = None,\n+        description: typing.Any | None = None,\n+    ) -&gt; None:\n+        super(Exclusive, self).__init__(schema, msg=msg, description=description)\n         self.group_of_exclusion = group_of_exclusion\n\n\n@@ -590,11 +1113,17 @@ class Inclusive(Optional):\n     True\n     \"\"\"\n\n-    def __init__(self, schema: Schemable, group_of_inclusion: str, msg:\n-        typing.Optional[str]=None, description: (typing.Any | None)=None,\n-        default: typing.Any=UNDEFINED) -&gt;None:\n-        super(Inclusive, self).__init__(schema, msg=msg, default=default,\n-            description=description)\n+    def __init__(\n+        self,\n+        schema: Schemable,\n+        group_of_inclusion: str,\n+        msg: typing.Optional[str] = None,\n+        description: typing.Any | None = None,\n+        default: typing.Any = UNDEFINED,\n+    ) -&gt; None:\n+        super(Inclusive, self).__init__(\n+            schema, msg=msg, default=default, description=description\n+        )\n         self.group_of_inclusion = group_of_inclusion\n\n\n@@ -613,11 +1142,14 @@ class Required(Marker):\n     {'key': []}\n     \"\"\"\n\n-    def __init__(self, schema: Schemable, msg: typing.Optional[str]=None,\n-        default: typing.Any=UNDEFINED, description: (typing.Any | None)=None\n-        ) -&gt;None:\n-        super(Required, self).__init__(schema, msg=msg, description=description\n-            )\n+    def __init__(\n+        self,\n+        schema: Schemable,\n+        msg: typing.Optional[str] = None,\n+        default: typing.Any = UNDEFINED,\n+        description: typing.Any | None = None,\n+    ) -&gt; None:\n+        super(Required, self).__init__(schema, msg=msg, description=description)\n         self.default = default_factory(default)\n\n\n@@ -636,21 +1168,27 @@ class Remove(Marker):\n     [1, 2, 3, 5, '7']\n     \"\"\"\n\n-    def __init__(self, schema_: Schemable, msg: typing.Optional[str]=None,\n-        description: (typing.Any | None)=None) -&gt;None:\n+    def __init__(\n+        self,\n+        schema_: Schemable,\n+        msg: typing.Optional[str] = None,\n+        description: typing.Any | None = None,\n+    ) -&gt; None:\n         super().__init__(schema_, msg, description)\n-        self.__hash__ = cache(lambda : object.__hash__(self))\n+        self.__hash__ = cache(lambda: object.__hash__(self))  # type: ignore[method-assign]\n\n     def __call__(self, schema: Schemable):\n         super(Remove, self).__call__(schema)\n         return self.__class__\n\n     def __repr__(self):\n-        return 'Remove(%r)' % (self.schema,)\n+        return \"Remove(%r)\" % (self.schema,)\n\n\n-def message(default: typing.Optional[str]=None, cls: typing.Optional[typing\n-    .Type[Error]]=None) -&gt;typing.Callable:\n+def message(\n+    default: typing.Optional[str] = None,\n+    cls: typing.Optional[typing.Type[Error]] = None,\n+) -&gt; typing.Callable:\n     \"\"\"Convenience decorator to allow functions to provide a message.\n\n     Set a default message:\n@@ -678,20 +1216,56 @@ def message(default: typing.Optional[str]=None, cls: typing.Optional[typing\n         ... except er.MultipleInvalid as e:\n         ...   assert isinstance(e.errors[0], IntegerInvalid)\n     \"\"\"\n-    pass\n+    if cls and not issubclass(cls, er.Invalid):\n+        raise er.SchemaError(\n+            \"message can only use subclases of Invalid as custom class\"\n+        )\n+\n+    def decorator(f):\n+        @wraps(f)\n+        def check(msg=None, clsoverride=None):\n+            @wraps(f)\n+            def wrapper(*args, **kwargs):\n+                try:\n+                    return f(*args, **kwargs)\n+                except ValueError:\n+                    raise (clsoverride or cls or er.ValueInvalid)(\n+                        msg or default or 'invalid value'\n+                    )\n+\n+            return wrapper\n+\n+        return check\n+\n+    return decorator\n\n\n def _args_to_dict(func, args):\n     \"\"\"Returns argument names as values as key-value pairs.\"\"\"\n-    pass\n+    if sys.version_info &gt;= (3, 0):\n+        arg_count = func.__code__.co_argcount\n+        arg_names = func.__code__.co_varnames[:arg_count]\n+    else:\n+        arg_count = func.func_code.co_argcount\n+        arg_names = func.func_code.co_varnames[:arg_count]\n+\n+    arg_value_list = list(args)\n+    arguments = dict(\n+        (arg_name, arg_value_list[i])\n+        for i, arg_name in enumerate(arg_names)\n+        if i &lt; len(arg_value_list)\n+    )\n+    return arguments\n\n\n def _merge_args_with_kwargs(args_dict, kwargs_dict):\n     \"\"\"Merge args with kwargs.\"\"\"\n-    pass\n+    ret = args_dict.copy()\n+    ret.update(kwargs_dict)\n+    return ret\n\n\n-def validate(*a, **kw) -&gt;typing.Callable:\n+def validate(*a, **kw) -&gt; typing.Callable:\n     \"\"\"Decorator for validating arguments of a function against a given schema.\n\n     Set restrictions for arguments:\n@@ -707,4 +1281,35 @@ def validate(*a, **kw) -&gt;typing.Callable:\n         ...   return arg1 * 2\n\n     \"\"\"\n-    pass\n+    RETURNS_KEY = '__return__'\n+\n+    def validate_schema_decorator(func):\n+        returns_defined = False\n+        returns = None\n+\n+        schema_args_dict = _args_to_dict(func, a)\n+        schema_arguments = _merge_args_with_kwargs(schema_args_dict, kw)\n+\n+        if RETURNS_KEY in schema_arguments:\n+            returns_defined = True\n+            returns = schema_arguments[RETURNS_KEY]\n+            del schema_arguments[RETURNS_KEY]\n+\n+        input_schema = (\n+            Schema(schema_arguments, extra=ALLOW_EXTRA)\n+            if len(schema_arguments) != 0\n+            else lambda x: x\n+        )\n+        output_schema = Schema(returns) if returns_defined else lambda x: x\n+\n+        @wraps(func)\n+        def func_wrapper(*args, **kwargs):\n+            args_dict = _args_to_dict(func, args)\n+            arguments = _merge_args_with_kwargs(args_dict, kwargs)\n+            validated_arguments = input_schema(arguments)\n+            output = func(**validated_arguments)\n+            return output_schema(output)\n+\n+        return func_wrapper\n+\n+    return validate_schema_decorator\ndiff --git a/voluptuous/util.py b/voluptuous/util.py\nindex fe15b1a..0bf9302 100644\n--- a/voluptuous/util.py\n+++ b/voluptuous/util.py\n@@ -1,59 +1,65 @@\n+# F401: \"imported but unused\"\n+# fmt: off\n import typing\n-from voluptuous import validators\n-from voluptuous.error import Invalid, LiteralInvalid, TypeInvalid\n-from voluptuous.schema_builder import DefaultFactory\n-from voluptuous.schema_builder import Schema, default_factory, raises\n+\n+from voluptuous import validators  # noqa: F401\n+from voluptuous.error import Invalid, LiteralInvalid, TypeInvalid  # noqa: F401\n+from voluptuous.schema_builder import DefaultFactory  # noqa: F401\n+from voluptuous.schema_builder import Schema, default_factory, raises  # noqa: F401\n+\n+# fmt: on\n+\n __author__ = 'tusharmakkar08'\n\n\n-def Lower(v: str) -&gt;str:\n+def Lower(v: str) -&gt; str:\n     \"\"\"Transform a string to lower case.\n\n     &gt;&gt;&gt; s = Schema(Lower)\n     &gt;&gt;&gt; s('HI')\n     'hi'\n     \"\"\"\n-    pass\n+    return str(v).lower()\n\n\n-def Upper(v: str) -&gt;str:\n+def Upper(v: str) -&gt; str:\n     \"\"\"Transform a string to upper case.\n\n     &gt;&gt;&gt; s = Schema(Upper)\n     &gt;&gt;&gt; s('hi')\n     'HI'\n     \"\"\"\n-    pass\n+    return str(v).upper()\n\n\n-def Capitalize(v: str) -&gt;str:\n+def Capitalize(v: str) -&gt; str:\n     \"\"\"Capitalise a string.\n\n     &gt;&gt;&gt; s = Schema(Capitalize)\n     &gt;&gt;&gt; s('hello world')\n     'Hello world'\n     \"\"\"\n-    pass\n+    return str(v).capitalize()\n\n\n-def Title(v: str) -&gt;str:\n+def Title(v: str) -&gt; str:\n     \"\"\"Title case a string.\n\n     &gt;&gt;&gt; s = Schema(Title)\n     &gt;&gt;&gt; s('hello world')\n     'Hello World'\n     \"\"\"\n-    pass\n+    return str(v).title()\n\n\n-def Strip(v: str) -&gt;str:\n+def Strip(v: str) -&gt; str:\n     \"\"\"Strip whitespace from a string.\n\n     &gt;&gt;&gt; s = Schema(Strip)\n     &gt;&gt;&gt; s('  hello world  ')\n     'hello world'\n     \"\"\"\n-    pass\n+    return str(v).strip()\n\n\n class DefaultTo(object):\n@@ -67,7 +73,7 @@ class DefaultTo(object):\n     []\n     \"\"\"\n\n-    def __init__(self, default_value, msg: typing.Optional[str]=None) -&gt;None:\n+    def __init__(self, default_value, msg: typing.Optional[str] = None) -&gt; None:\n         self.default_value = default_factory(default_value)\n         self.msg = msg\n\n@@ -90,7 +96,7 @@ class SetTo(object):\n     42\n     \"\"\"\n\n-    def __init__(self, value) -&gt;None:\n+    def __init__(self, value) -&gt; None:\n         self.value = default_factory(value)\n\n     def __call__(self, v):\n@@ -112,15 +118,14 @@ class Set(object):\n     ...   s([set([1, 2]), set([3, 4])])\n     \"\"\"\n\n-    def __init__(self, msg: typing.Optional[str]=None) -&gt;None:\n+    def __init__(self, msg: typing.Optional[str] = None) -&gt; None:\n         self.msg = msg\n\n     def __call__(self, v):\n         try:\n             set_v = set(v)\n         except Exception as e:\n-            raise TypeInvalid(self.msg or 'cannot be presented as set: {0}'\n-                .format(e))\n+            raise TypeInvalid(self.msg or 'cannot be presented as set: {0}'.format(e))\n         return set_v\n\n     def __repr__(self):\n@@ -128,14 +133,12 @@ class Set(object):\n\n\n class Literal(object):\n-\n-    def __init__(self, lit) -&gt;None:\n+    def __init__(self, lit) -&gt; None:\n         self.lit = lit\n\n-    def __call__(self, value, msg: typing.Optional[str]=None):\n+    def __call__(self, value, msg: typing.Optional[str] = None):\n         if self.lit != value:\n-            raise LiteralInvalid(msg or '%s not match for %s' % (value,\n-                self.lit))\n+            raise LiteralInvalid(msg or '%s not match for %s' % (value, self.lit))\n         else:\n             return self.lit\n\ndiff --git a/voluptuous/validators.py b/voluptuous/validators.py\nindex 88b50f6..d385260 100644\n--- a/voluptuous/validators.py\n+++ b/voluptuous/validators.py\n@@ -1,4 +1,6 @@\n+# fmt: off\n from __future__ import annotations\n+\n import datetime\n import os\n import re\n@@ -6,30 +8,73 @@ import sys\n import typing\n from decimal import Decimal, InvalidOperation\n from functools import wraps\n-from voluptuous.error import AllInvalid, AnyInvalid, BooleanInvalid, CoerceInvalid, ContainsInvalid, DateInvalid, DatetimeInvalid, DirInvalid, EmailInvalid, ExactSequenceInvalid, FalseInvalid, FileInvalid, InInvalid, Invalid, LengthInvalid, MatchInvalid, MultipleInvalid, NotEnoughValid, NotInInvalid, PathInvalid, RangeInvalid, TooManyValid, TrueInvalid, TypeInvalid, UrlInvalid\n-from voluptuous.schema_builder import Schema, Schemable, message, raises\n+\n+from voluptuous.error import (\n+    AllInvalid, AnyInvalid, BooleanInvalid, CoerceInvalid, ContainsInvalid, DateInvalid,\n+    DatetimeInvalid, DirInvalid, EmailInvalid, ExactSequenceInvalid, FalseInvalid,\n+    FileInvalid, InInvalid, Invalid, LengthInvalid, MatchInvalid, MultipleInvalid,\n+    NotEnoughValid, NotInInvalid, PathInvalid, RangeInvalid, TooManyValid, TrueInvalid,\n+    TypeInvalid, UrlInvalid,\n+)\n+\n+# F401: flake8 complains about 'raises' not being used, but it is used in doctests\n+from voluptuous.schema_builder import Schema, Schemable, message, raises  # noqa: F401\n+\n if typing.TYPE_CHECKING:\n     from _typeshed import SupportsAllComparisons\n+\n+# fmt: on\n+\n+\n Enum: typing.Union[type, None]\n try:\n     from enum import Enum\n except ImportError:\n     Enum = None\n+\n+\n if sys.version_info &gt;= (3,):\n     import urllib.parse as urlparse\n+\n     basestring = str\n else:\n     import urlparse\n+\n+# Taken from https://github.com/kvesteri/validators/blob/master/validators/email.py\n+# fmt: off\n USER_REGEX = re.compile(\n-    '(?:(^[-!#$%&amp;\\'*+/=?^_`{}|~0-9A-Z]+(\\\\.[-!#$%&amp;\\'*+/=?^_`{}|~0-9A-Z]+)*$|^\"([\\\\001-\\\\010\\\\013\\\\014\\\\016-\\\\037!#-\\\\[\\\\]-\\\\177]|\\\\\\\\[\\\\001-\\\\011\\\\013\\\\014\\\\016-\\\\177])*\"$))\\\\Z'\n-    , re.IGNORECASE)\n+    # start anchor, because fullmatch is not available in python 2.7\n+    \"(?:\"\n+    # dot-atom\n+    r\"(^[-!#$%&amp;'*+/=?^_`{}|~0-9A-Z]+\"\n+    r\"(\\.[-!#$%&amp;'*+/=?^_`{}|~0-9A-Z]+)*$\"\n+    # quoted-string\n+    r'|^\"([\\001-\\010\\013\\014\\016-\\037!#-\\[\\]-\\177]|'\n+    r\"\"\"\\\\[\\001-\\011\\013\\014\\016-\\177])*\"$)\"\"\"\n+    # end anchor, because fullmatch is not available in python 2.7\n+    r\")\\Z\",\n+    re.IGNORECASE,\n+)\n DOMAIN_REGEX = re.compile(\n-    '(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\\\.)+(?:[A-Z]{2,6}\\\\.?|[A-Z0-9-]{2,}\\\\.?$)|^\\\\[(25[0-5]|2[0-4]\\\\d|[0-1]?\\\\d?\\\\d)(\\\\.(25[0-5]|2[0-4]\\\\d|[0-1]?\\\\d?\\\\d)){3}\\\\]$)\\\\Z'\n-    , re.IGNORECASE)\n+    # start anchor, because fullmatch is not available in python 2.7\n+    \"(?:\"\n+    # domain\n+    r'(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+'\n+    # tld\n+    r'(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?$)'\n+    # literal form, ipv4 address (SMTP 4.1.3)\n+    r'|^\\[(25[0-5]|2[0-4]\\d|[0-1]?\\d?\\d)'\n+    r'(\\.(25[0-5]|2[0-4]\\d|[0-1]?\\d?\\d)){3}\\]$'\n+    # end anchor, because fullmatch is not available in python 2.7\n+    r\")\\Z\",\n+    re.IGNORECASE,\n+)\n+# fmt: on\n+\n __author__ = 'tusharmakkar08'\n\n\n-def truth(f: typing.Callable) -&gt;typing.Callable:\n+def truth(f: typing.Callable) -&gt; typing.Callable:\n     \"\"\"Convenience decorator to convert truth functions into validators.\n\n     &gt;&gt;&gt; @truth\n@@ -41,7 +86,15 @@ def truth(f: typing.Callable) -&gt;typing.Callable:\n     &gt;&gt;&gt; with raises(MultipleInvalid, 'not a valid value'):\n     ...   validate('/notavaliddir')\n     \"\"\"\n-    pass\n+\n+    @wraps(f)\n+    def check(v):\n+        t = f(v)\n+        if not t:\n+            raise ValueError\n+        return v\n+\n+    return check\n\n\n class Coerce(object):\n@@ -65,8 +118,11 @@ class Coerce(object):\n         ...   validate('foo')\n     \"\"\"\n\n-    def __init__(self, type: typing.Union[type, typing.Callable], msg:\n-        typing.Optional[str]=None) -&gt;None:\n+    def __init__(\n+        self,\n+        type: typing.Union[type, typing.Callable],\n+        msg: typing.Optional[str] = None,\n+    ) -&gt; None:\n         self.type = type\n         self.msg = msg\n         self.type_name = type.__name__\n@@ -75,10 +131,9 @@ class Coerce(object):\n         try:\n             return self.type(v)\n         except (ValueError, TypeError, InvalidOperation):\n-            msg = self.msg or 'expected %s' % self.type_name\n+            msg = self.msg or ('expected %s' % self.type_name)\n             if not self.msg and Enum and issubclass(self.type, Enum):\n-                msg += ' or one of %s' % str([e.value for e in self.type])[1:-1\n-                    ]\n+                msg += \" or one of %s\" % str([e.value for e in self.type])[1:-1]\n             raise CoerceInvalid(msg)\n\n     def __repr__(self):\n@@ -109,7 +164,7 @@ def IsTrue(v):\n     ... except MultipleInvalid as e:\n     ...   assert isinstance(e.errors[0], TrueInvalid)\n     \"\"\"\n-    pass\n+    return v\n\n\n @message('value was not false', cls=FalseInvalid)\n@@ -129,7 +184,9 @@ def IsFalse(v):\n     ... except MultipleInvalid as e:\n     ...   assert isinstance(e.errors[0], FalseInvalid)\n     \"\"\"\n-    pass\n+    if v:\n+        raise ValueError\n+    return v\n\n\n @message('expected boolean', cls=BooleanInvalid)\n@@ -153,7 +210,14 @@ def Boolean(v):\n     ... except MultipleInvalid as e:\n     ...   assert isinstance(e.errors[0], BooleanInvalid)\n     \"\"\"\n-    pass\n+    if isinstance(v, basestring):\n+        v = v.lower()\n+        if v in ('1', 'true', 'yes', 'on', 'enable'):\n+            return True\n+        if v in ('0', 'false', 'no', 'off', 'disable'):\n+            return False\n+        raise ValueError\n+    return bool(v)\n\n\n class _WithSubValidators(object):\n@@ -164,14 +228,15 @@ class _WithSubValidators(object):\n     sub-validators are compiled by the parent `Schema`.\n     \"\"\"\n\n-    def __init__(self, *validators, msg=None, required=False, discriminant=\n-        None, **kwargs) -&gt;None:\n+    def __init__(\n+        self, *validators, msg=None, required=False, discriminant=None, **kwargs\n+    ) -&gt; None:\n         self.validators = validators\n         self.msg = msg\n         self.required = required\n         self.discriminant = discriminant\n\n-    def __voluptuous_compile__(self, schema: Schema) -&gt;typing.Callable:\n+    def __voluptuous_compile__(self, schema: Schema) -&gt; typing.Callable:\n         self._compiled = []\n         old_required = schema.required\n         self.schema = schema\n@@ -181,12 +246,32 @@ class _WithSubValidators(object):\n         schema.required = old_required\n         return self._run\n\n+    def _run(self, path: typing.List[typing.Hashable], value):\n+        if self.discriminant is not None:\n+            self._compiled = [\n+                self.schema._compile(v)\n+                for v in self.discriminant(value, self.validators)\n+            ]\n+\n+        return self._exec(self._compiled, value, path)\n+\n     def __call__(self, v):\n         return self._exec((Schema(val) for val in self.validators), v)\n\n     def __repr__(self):\n-        return '%s(%s, msg=%r)' % (self.__class__.__name__, ', '.join(repr(\n-            v) for v in self.validators), self.msg)\n+        return '%s(%s, msg=%r)' % (\n+            self.__class__.__name__,\n+            \", \".join(repr(v) for v in self.validators),\n+            self.msg,\n+        )\n+\n+    def _exec(\n+        self,\n+        funcs: typing.Iterable,\n+        v,\n+        path: typing.Optional[typing.List[typing.Hashable]] = None,\n+    ):\n+        raise NotImplementedError()\n\n\n class Any(_WithSubValidators):\n@@ -214,7 +299,24 @@ class Any(_WithSubValidators):\n     ...   validate(4)\n     \"\"\"\n\n+    def _exec(self, funcs, v, path=None):\n+        error = None\n+        for func in funcs:\n+            try:\n+                if path is None:\n+                    return func(v)\n+                else:\n+                    return func(path, v)\n+            except Invalid as e:\n+                if error is None or len(e.path) &gt; len(error.path):\n+                    error = e\n+        else:\n+            if error:\n+                raise error if self.msg is None else AnyInvalid(self.msg, path=path)\n+            raise AnyInvalid(self.msg or 'no valid value found', path=path)\n+\n\n+# Convenience alias\n Or = Any\n\n\n@@ -239,7 +341,24 @@ class Union(_WithSubValidators):\n     Without the discriminant, the exception would be \"extra keys not allowed @ data['b_val']\"\n     \"\"\"\n\n+    def _exec(self, funcs, v, path=None):\n+        error = None\n+        for func in funcs:\n+            try:\n+                if path is None:\n+                    return func(v)\n+                else:\n+                    return func(path, v)\n+            except Invalid as e:\n+                if error is None or len(e.path) &gt; len(error.path):\n+                    error = e\n+        else:\n+            if error:\n+                raise error if self.msg is None else AnyInvalid(self.msg, path=path)\n+            raise AnyInvalid(self.msg or 'no valid value found', path=path)\n+\n\n+# Convenience alias\n Switch = Union\n\n\n@@ -256,7 +375,19 @@ class All(_WithSubValidators):\n     10\n     \"\"\"\n\n+    def _exec(self, funcs, v, path=None):\n+        try:\n+            for func in funcs:\n+                if path is None:\n+                    v = func(v)\n+                else:\n+                    v = func(path, v)\n+        except Invalid as e:\n+            raise e if self.msg is None else AllInvalid(self.msg, path=path)\n+        return v\n\n+\n+# Convenience alias\n And = All\n\n\n@@ -279,8 +410,9 @@ class Match(object):\n     '0x123ef4'\n     \"\"\"\n\n-    def __init__(self, pattern: typing.Union[re.Pattern, str], msg: typing.\n-        Optional[str]=None) -&gt;None:\n+    def __init__(\n+        self, pattern: typing.Union[re.Pattern, str], msg: typing.Optional[str] = None\n+    ) -&gt; None:\n         if isinstance(pattern, basestring):\n             pattern = re.compile(pattern)\n         self.pattern = pattern\n@@ -290,11 +422,12 @@ class Match(object):\n         try:\n             match = self.pattern.match(v)\n         except TypeError:\n-            raise MatchInvalid('expected string or buffer')\n+            raise MatchInvalid(\"expected string or buffer\")\n         if not match:\n-            raise MatchInvalid(self.msg or\n-                'does not match regular expression {}'.format(self.pattern.\n-                pattern))\n+            raise MatchInvalid(\n+                self.msg\n+                or 'does not match regular expression {}'.format(self.pattern.pattern)\n+            )\n         return v\n\n     def __repr__(self):\n@@ -310,8 +443,12 @@ class Replace(object):\n     'I say goodbye'\n     \"\"\"\n\n-    def __init__(self, pattern: typing.Union[re.Pattern, str], substitution:\n-        str, msg: typing.Optional[str]=None) -&gt;None:\n+    def __init__(\n+        self,\n+        pattern: typing.Union[re.Pattern, str],\n+        substitution: str,\n+        msg: typing.Optional[str] = None,\n+    ) -&gt; None:\n         if isinstance(pattern, basestring):\n             pattern = re.compile(pattern)\n         self.pattern = pattern\n@@ -322,8 +459,18 @@ class Replace(object):\n         return self.pattern.sub(self.substitution, v)\n\n     def __repr__(self):\n-        return 'Replace(%r, %r, msg=%r)' % (self.pattern.pattern, self.\n-            substitution, self.msg)\n+        return 'Replace(%r, %r, msg=%r)' % (\n+            self.pattern.pattern,\n+            self.substitution,\n+            self.msg,\n+        )\n+\n+\n+def _url_validation(v: str) -&gt; urlparse.ParseResult:\n+    parsed = urlparse.urlparse(v)\n+    if not parsed.scheme or not parsed.netloc:\n+        raise UrlInvalid(\"must have a URL scheme and host\")\n+    return parsed\n\n\n @message('expected an email address', cls=EmailInvalid)\n@@ -340,7 +487,16 @@ def Email(v):\n     &gt;&gt;&gt; s('t@x.com')\n     't@x.com'\n     \"\"\"\n-    pass\n+    try:\n+        if not v or \"@\" not in v:\n+            raise EmailInvalid(\"Invalid email address\")\n+        user_part, domain_part = v.rsplit('@', 1)\n+\n+        if not (USER_REGEX.match(user_part) and DOMAIN_REGEX.match(domain_part)):\n+            raise EmailInvalid(\"Invalid email address\")\n+        return v\n+    except:  # noqa: E722\n+        raise ValueError\n\n\n @message('expected a fully qualified domain name URL', cls=UrlInvalid)\n@@ -353,7 +509,13 @@ def FqdnUrl(v):\n     &gt;&gt;&gt; s('http://w3.org')\n     'http://w3.org'\n     \"\"\"\n-    pass\n+    try:\n+        parsed_url = _url_validation(v)\n+        if \".\" not in parsed_url.netloc:\n+            raise UrlInvalid(\"must have a domain name in URL\")\n+        return v\n+    except:  # noqa: E722\n+        raise ValueError\n\n\n @message('expected a URL', cls=UrlInvalid)\n@@ -366,7 +528,11 @@ def Url(v):\n     &gt;&gt;&gt; s('http://w3.org')\n     'http://w3.org'\n     \"\"\"\n-    pass\n+    try:\n+        _url_validation(v)\n+        return v\n+    except:  # noqa: E722\n+        raise ValueError\n\n\n @message('Not a file', cls=FileInvalid)\n@@ -381,7 +547,14 @@ def IsFile(v):\n     &gt;&gt;&gt; with raises(FileInvalid, 'Not a file'):\n     ...   IsFile()(None)\n     \"\"\"\n-    pass\n+    try:\n+        if v:\n+            v = str(v)\n+            return os.path.isfile(v)\n+        else:\n+            raise FileInvalid('Not a file')\n+    except TypeError:\n+        raise FileInvalid('Not a file')\n\n\n @message('Not a directory', cls=DirInvalid)\n@@ -394,7 +567,14 @@ def IsDir(v):\n     &gt;&gt;&gt; with raises(DirInvalid, 'Not a directory'):\n     ...   IsDir()(None)\n     \"\"\"\n-    pass\n+    try:\n+        if v:\n+            v = str(v)\n+            return os.path.isdir(v)\n+        else:\n+            raise DirInvalid(\"Not a directory\")\n+    except TypeError:\n+        raise DirInvalid(\"Not a directory\")\n\n\n @message('path does not exist', cls=PathInvalid)\n@@ -409,10 +589,17 @@ def PathExists(v):\n     &gt;&gt;&gt; with raises(PathInvalid, 'Not a Path'):\n     ...   PathExists()(None)\n     \"\"\"\n-    pass\n+    try:\n+        if v:\n+            v = str(v)\n+            return os.path.exists(v)\n+        else:\n+            raise PathInvalid(\"Not a Path\")\n+    except TypeError:\n+        raise PathInvalid(\"Not a Path\")\n\n\n-def Maybe(validator: Schemable, msg: typing.Optional[str]=None):\n+def Maybe(validator: Schemable, msg: typing.Optional[str] = None):\n     \"\"\"Validate that the object matches given validator or is None.\n\n     :raises Invalid: If the value does not match the given validator and is not\n@@ -425,7 +612,7 @@ def Maybe(validator: Schemable, msg: typing.Optional[str]=None):\n     ...  s(\"string\")\n\n     \"\"\"\n-    pass\n+    return Any(None, validator, msg=msg)\n\n\n class Range(object):\n@@ -449,9 +636,14 @@ class Range(object):\n     ...   Schema(Range(max=10, max_included=False))(20)\n     \"\"\"\n\n-    def __init__(self, min: (SupportsAllComparisons | None)=None, max: (\n-        SupportsAllComparisons | None)=None, min_included: bool=True,\n-        max_included: bool=True, msg: typing.Optional[str]=None) -&gt;None:\n+    def __init__(\n+        self,\n+        min: SupportsAllComparisons | None = None,\n+        max: SupportsAllComparisons | None = None,\n+        min_included: bool = True,\n+        max_included: bool = True,\n+        msg: typing.Optional[str] = None,\n+    ) -&gt; None:\n         self.min = min\n         self.max = max\n         self.min_included = min_included\n@@ -462,28 +654,41 @@ class Range(object):\n         try:\n             if self.min_included:\n                 if self.min is not None and not v &gt;= self.min:\n-                    raise RangeInvalid(self.msg or \n-                        'value must be at least %s' % self.min)\n-            elif self.min is not None and not v &gt; self.min:\n-                raise RangeInvalid(self.msg or \n-                    'value must be higher than %s' % self.min)\n+                    raise RangeInvalid(\n+                        self.msg or 'value must be at least %s' % self.min\n+                    )\n+            else:\n+                if self.min is not None and not v &gt; self.min:\n+                    raise RangeInvalid(\n+                        self.msg or 'value must be higher than %s' % self.min\n+                    )\n             if self.max_included:\n                 if self.max is not None and not v &lt;= self.max:\n-                    raise RangeInvalid(self.msg or \n-                        'value must be at most %s' % self.max)\n-            elif self.max is not None and not v &lt; self.max:\n-                raise RangeInvalid(self.msg or \n-                    'value must be lower than %s' % self.max)\n+                    raise RangeInvalid(\n+                        self.msg or 'value must be at most %s' % self.max\n+                    )\n+            else:\n+                if self.max is not None and not v &lt; self.max:\n+                    raise RangeInvalid(\n+                        self.msg or 'value must be lower than %s' % self.max\n+                    )\n+\n             return v\n+\n+        # Objects that lack a partial ordering, e.g. None or strings will raise TypeError\n         except TypeError:\n-            raise RangeInvalid(self.msg or\n-                'invalid value or type (must have a partial ordering)')\n+            raise RangeInvalid(\n+                self.msg or 'invalid value or type (must have a partial ordering)'\n+            )\n\n     def __repr__(self):\n-        return (\n-            'Range(min=%r, max=%r, min_included=%r, max_included=%r, msg=%r)' %\n-            (self.min, self.max, self.min_included, self.max_included, self\n-            .msg))\n+        return 'Range(min=%r, max=%r, min_included=%r, max_included=%r, msg=%r)' % (\n+            self.min,\n+            self.max,\n+            self.min_included,\n+            self.max_included,\n+            self.msg,\n+        )\n\n\n class Clamp(object):\n@@ -500,9 +705,12 @@ class Clamp(object):\n     0\n     \"\"\"\n\n-    def __init__(self, min: (SupportsAllComparisons | None)=None, max: (\n-        SupportsAllComparisons | None)=None, msg: typing.Optional[str]=None\n-        ) -&gt;None:\n+    def __init__(\n+        self,\n+        min: SupportsAllComparisons | None = None,\n+        max: SupportsAllComparisons | None = None,\n+        msg: typing.Optional[str] = None,\n+    ) -&gt; None:\n         self.min = min\n         self.max = max\n         self.msg = msg\n@@ -514,9 +722,12 @@ class Clamp(object):\n             if self.max is not None and v &gt; self.max:\n                 v = self.max\n             return v\n+\n+        # Objects that lack a partial ordering, e.g. None or strings will raise TypeError\n         except TypeError:\n-            raise RangeInvalid(self.msg or\n-                'invalid value or type (must have a partial ordering)')\n+            raise RangeInvalid(\n+                self.msg or 'invalid value or type (must have a partial ordering)'\n+            )\n\n     def __repr__(self):\n         return 'Clamp(min=%s, max=%s)' % (self.min, self.max)\n@@ -525,9 +736,12 @@ class Clamp(object):\n class Length(object):\n     \"\"\"The length of a value must be in a certain range.\"\"\"\n\n-    def __init__(self, min: (SupportsAllComparisons | None)=None, max: (\n-        SupportsAllComparisons | None)=None, msg: typing.Optional[str]=None\n-        ) -&gt;None:\n+    def __init__(\n+        self,\n+        min: SupportsAllComparisons | None = None,\n+        max: SupportsAllComparisons | None = None,\n+        msg: typing.Optional[str] = None,\n+    ) -&gt; None:\n         self.min = min\n         self.max = max\n         self.msg = msg\n@@ -535,12 +749,16 @@ class Length(object):\n     def __call__(self, v):\n         try:\n             if self.min is not None and len(v) &lt; self.min:\n-                raise LengthInvalid(self.msg or \n-                    'length of value must be at least %s' % self.min)\n+                raise LengthInvalid(\n+                    self.msg or 'length of value must be at least %s' % self.min\n+                )\n             if self.max is not None and len(v) &gt; self.max:\n-                raise LengthInvalid(self.msg or \n-                    'length of value must be at most %s' % self.max)\n+                raise LengthInvalid(\n+                    self.msg or 'length of value must be at most %s' % self.max\n+                )\n             return v\n+\n+        # Objects that have no length e.g. None or strings will raise TypeError\n         except TypeError:\n             raise RangeInvalid(self.msg or 'invalid value or type')\n\n@@ -550,10 +768,12 @@ class Length(object):\n\n class Datetime(object):\n     \"\"\"Validate that the value matches the datetime format.\"\"\"\n+\n     DEFAULT_FORMAT = '%Y-%m-%dT%H:%M:%S.%fZ'\n\n-    def __init__(self, format: typing.Optional[str]=None, msg: typing.\n-        Optional[str]=None) -&gt;None:\n+    def __init__(\n+        self, format: typing.Optional[str] = None, msg: typing.Optional[str] = None\n+    ) -&gt; None:\n         self.format = format or self.DEFAULT_FORMAT\n         self.msg = msg\n\n@@ -561,8 +781,9 @@ class Datetime(object):\n         try:\n             datetime.datetime.strptime(v, self.format)\n         except (TypeError, ValueError):\n-            raise DatetimeInvalid(self.msg or \n-                'value does not match expected format %s' % self.format)\n+            raise DatetimeInvalid(\n+                self.msg or 'value does not match expected format %s' % self.format\n+            )\n         return v\n\n     def __repr__(self):\n@@ -571,14 +792,16 @@ class Datetime(object):\n\n class Date(Datetime):\n     \"\"\"Validate that the value matches the date format.\"\"\"\n+\n     DEFAULT_FORMAT = '%Y-%m-%d'\n\n     def __call__(self, v):\n         try:\n             datetime.datetime.strptime(v, self.format)\n         except (TypeError, ValueError):\n-            raise DateInvalid(self.msg or \n-                'value does not match expected format %s' % self.format)\n+            raise DateInvalid(\n+                self.msg or 'value does not match expected format %s' % self.format\n+            )\n         return v\n\n     def __repr__(self):\n@@ -588,8 +811,9 @@ class Date(Datetime):\n class In(object):\n     \"\"\"Validate that a value is in a collection.\"\"\"\n\n-    def __init__(self, container: typing.Container, msg: typing.Optional[\n-        str]=None) -&gt;None:\n+    def __init__(\n+        self, container: typing.Container, msg: typing.Optional[str] = None\n+    ) -&gt; None:\n         self.container = container\n         self.msg = msg\n\n@@ -600,11 +824,14 @@ class In(object):\n             check = True\n         if check:\n             try:\n-                raise InInvalid(self.msg or\n-                    f'value must be one of {sorted(self.container)}')\n+                raise InInvalid(\n+                    self.msg or f'value must be one of {sorted(self.container)}'\n+                )\n             except TypeError:\n-                raise InInvalid(self.msg or\n-                    f'value must be one of {sorted(self.container, key=str)}')\n+                raise InInvalid(\n+                    self.msg\n+                    or f'value must be one of {sorted(self.container, key=str)}'\n+                )\n         return v\n\n     def __repr__(self):\n@@ -614,8 +841,9 @@ class In(object):\n class NotIn(object):\n     \"\"\"Validate that a value is not in a collection.\"\"\"\n\n-    def __init__(self, container: typing.Iterable, msg: typing.Optional[str\n-        ]=None) -&gt;None:\n+    def __init__(\n+        self, container: typing.Iterable, msg: typing.Optional[str] = None\n+    ) -&gt; None:\n         self.container = container\n         self.msg = msg\n\n@@ -626,12 +854,14 @@ class NotIn(object):\n             check = True\n         if check:\n             try:\n-                raise NotInInvalid(self.msg or\n-                    f'value must not be one of {sorted(self.container)}')\n+                raise NotInInvalid(\n+                    self.msg or f'value must not be one of {sorted(self.container)}'\n+                )\n             except TypeError:\n-                raise NotInInvalid(self.msg or\n-                    f'value must not be one of {sorted(self.container, key=str)}'\n-                    )\n+                raise NotInInvalid(\n+                    self.msg\n+                    or f'value must not be one of {sorted(self.container, key=str)}'\n+                )\n         return v\n\n     def __repr__(self):\n@@ -648,7 +878,7 @@ class Contains(object):\n     ...   s([3, 2])\n     \"\"\"\n\n-    def __init__(self, item, msg: typing.Optional[str]=None) -&gt;None:\n+    def __init__(self, item, msg: typing.Optional[str] = None) -&gt; None:\n         self.item = item\n         self.msg = msg\n\n@@ -681,8 +911,12 @@ class ExactSequence(object):\n     ('hourly_report', 10, [], [])\n     \"\"\"\n\n-    def __init__(self, validators: typing.Iterable[Schemable], msg: typing.\n-        Optional[str]=None, **kwargs) -&gt;None:\n+    def __init__(\n+        self,\n+        validators: typing.Iterable[Schemable],\n+        msg: typing.Optional[str] = None,\n+        **kwargs,\n+    ) -&gt; None:\n         self.validators = validators\n         self.msg = msg\n         self._schemas = [Schema(val, **kwargs) for val in validators]\n@@ -693,12 +927,11 @@ class ExactSequence(object):\n         try:\n             v = type(v)(schema(x) for x, schema in zip(v, self._schemas))\n         except Invalid as e:\n-            raise (e if self.msg is None else ExactSequenceInvalid(self.msg))\n+            raise e if self.msg is None else ExactSequenceInvalid(self.msg)\n         return v\n\n     def __repr__(self):\n-        return 'ExactSequence([%s])' % ', '.join(repr(v) for v in self.\n-            validators)\n+        return 'ExactSequence([%s])' % \", \".join(repr(v) for v in self.validators)\n\n\n class Unique(object):\n@@ -727,20 +960,18 @@ class Unique(object):\n     ...   s('aabbc')\n     \"\"\"\n\n-    def __init__(self, msg: typing.Optional[str]=None) -&gt;None:\n+    def __init__(self, msg: typing.Optional[str] = None) -&gt; None:\n         self.msg = msg\n\n     def __call__(self, v):\n         try:\n             set_v = set(v)\n         except TypeError as e:\n-            raise TypeInvalid(self.msg or\n-                'contains unhashable elements: {0}'.format(e))\n+            raise TypeInvalid(self.msg or 'contains unhashable elements: {0}'.format(e))\n         if len(set_v) != len(v):\n             seen = set()\n             dupes = list(set(x for x in v if x in seen or seen.add(x)))\n-            raise Invalid(self.msg or 'contains duplicate items: {0}'.\n-                format(dupes))\n+            raise Invalid(self.msg or 'contains duplicate items: {0}'.format(dupes))\n         return v\n\n     def __repr__(self):\n@@ -763,15 +994,16 @@ class Equal(object):\n     ...     s('foo')\n     \"\"\"\n\n-    def __init__(self, target, msg: typing.Optional[str]=None) -&gt;None:\n+    def __init__(self, target, msg: typing.Optional[str] = None) -&gt; None:\n         self.target = target\n         self.msg = msg\n\n     def __call__(self, v):\n         if v != self.target:\n-            raise Invalid(self.msg or\n-                'Values are not equal: value:{} != target:{}'.format(v,\n-                self.target))\n+            raise Invalid(\n+                self.msg\n+                or 'Values are not equal: value:{} != target:{}'.format(v, self.target)\n+            )\n         return v\n\n     def __repr__(self):\n@@ -793,8 +1025,12 @@ class Unordered(object):\n     [1, 'foo']\n     \"\"\"\n\n-    def __init__(self, validators: typing.Iterable[Schemable], msg: typing.\n-        Optional[str]=None, **kwargs) -&gt;None:\n+    def __init__(\n+        self,\n+        validators: typing.Iterable[Schemable],\n+        msg: typing.Optional[str] = None,\n+        **kwargs,\n+    ) -&gt; None:\n         self.validators = validators\n         self.msg = msg\n         self._schemas = [Schema(val, **kwargs) for val in validators]\n@@ -802,10 +1038,15 @@ class Unordered(object):\n     def __call__(self, v):\n         if not isinstance(v, (list, tuple)):\n             raise Invalid(self.msg or 'Value {} is not sequence!'.format(v))\n+\n         if len(v) != len(self._schemas):\n-            raise Invalid(self.msg or\n-                'List lengths differ, value:{} != target:{}'.format(len(v),\n-                len(self._schemas)))\n+            raise Invalid(\n+                self.msg\n+                or 'List lengths differ, value:{} != target:{}'.format(\n+                    len(v), len(self._schemas)\n+                )\n+            )\n+\n         consumed = set()\n         missing = []\n         for index, value in enumerate(v):\n@@ -823,20 +1064,31 @@ class Unordered(object):\n                     break\n             if not found:\n                 missing.append((index, value))\n+\n         if len(missing) == 1:\n             el = missing[0]\n-            raise Invalid(self.msg or\n-                'Element #{} ({}) is not valid against any validator'.\n-                format(el[0], el[1]))\n+            raise Invalid(\n+                self.msg\n+                or 'Element #{} ({}) is not valid against any validator'.format(\n+                    el[0], el[1]\n+                )\n+            )\n         elif missing:\n-            raise MultipleInvalid([Invalid(self.msg or\n-                'Element #{} ({}) is not valid against any validator'.\n-                format(el[0], el[1])) for el in missing])\n+            raise MultipleInvalid(\n+                [\n+                    Invalid(\n+                        self.msg\n+                        or 'Element #{} ({}) is not valid against any validator'.format(\n+                            el[0], el[1]\n+                        )\n+                    )\n+                    for el in missing\n+                ]\n+            )\n         return v\n\n     def __repr__(self):\n-        return 'Unordered([{}])'.format(', '.join(repr(v) for v in self.\n-            validators))\n+        return 'Unordered([{}])'.format(\", \".join(repr(v) for v in self.validators))\n\n\n class Number(object):\n@@ -854,9 +1106,13 @@ class Number(object):\n     Decimal('1234.01')\n     \"\"\"\n\n-    def __init__(self, precision: typing.Optional[int]=None, scale: typing.\n-        Optional[int]=None, msg: typing.Optional[str]=None, yield_decimal:\n-        bool=False) -&gt;None:\n+    def __init__(\n+        self,\n+        precision: typing.Optional[int] = None,\n+        scale: typing.Optional[int] = None,\n+        msg: typing.Optional[str] = None,\n+        yield_decimal: bool = False,\n+    ) -&gt; None:\n         self.precision = precision\n         self.scale = scale\n         self.msg = msg\n@@ -868,33 +1124,56 @@ class Number(object):\n         :return: Decimal number\n         \"\"\"\n         precision, scale, decimal_num = self._get_precision_scale(v)\n-        if (self.precision is not None and self.scale is not None and \n-            precision != self.precision and scale != self.scale):\n-            raise Invalid(self.msg or \n-                'Precision must be equal to %s, and Scale must be equal to %s'\n-                 % (self.precision, self.scale))\n+\n+        if (\n+            self.precision is not None\n+            and self.scale is not None\n+            and precision != self.precision\n+            and scale != self.scale\n+        ):\n+            raise Invalid(\n+                self.msg\n+                or \"Precision must be equal to %s, and Scale must be equal to %s\"\n+                % (self.precision, self.scale)\n+            )\n         else:\n             if self.precision is not None and precision != self.precision:\n-                raise Invalid(self.msg or 'Precision must be equal to %s' %\n-                    self.precision)\n+                raise Invalid(\n+                    self.msg or \"Precision must be equal to %s\" % self.precision\n+                )\n+\n             if self.scale is not None and scale != self.scale:\n-                raise Invalid(self.msg or 'Scale must be equal to %s' %\n-                    self.scale)\n+                raise Invalid(self.msg or \"Scale must be equal to %s\" % self.scale)\n+\n         if self.yield_decimal:\n             return decimal_num\n         else:\n             return v\n\n     def __repr__(self):\n-        return 'Number(precision=%s, scale=%s, msg=%s)' % (self.precision,\n-            self.scale, self.msg)\n+        return 'Number(precision=%s, scale=%s, msg=%s)' % (\n+            self.precision,\n+            self.scale,\n+            self.msg,\n+        )\n\n-    def _get_precision_scale(self, number) -&gt;typing.Tuple[int, int, Decimal]:\n+    def _get_precision_scale(self, number) -&gt; typing.Tuple[int, int, Decimal]:\n         \"\"\"\n         :param number:\n         :return: tuple(precision, scale, decimal_number)\n         \"\"\"\n-        pass\n+        try:\n+            decimal_num = Decimal(number)\n+        except InvalidOperation:\n+            raise Invalid(self.msg or 'Value must be a number enclosed with string')\n+\n+        exp = decimal_num.as_tuple().exponent\n+        if isinstance(exp, int):\n+            return (len(decimal_num.as_tuple().digits), -exp, decimal_num)\n+        else:\n+            # TODO: handle infinity and NaN\n+            # raise Invalid(self.msg or 'Value has no precision')\n+            raise TypeError(\"infinity and NaN have no precision\")\n\n\n class SomeOf(_WithSubValidators):\n@@ -921,17 +1200,49 @@ class SomeOf(_WithSubValidators):\n     ...     validate(6.2)\n     \"\"\"\n\n-    def __init__(self, validators: typing.List[Schemable], min_valid:\n-        typing.Optional[int]=None, max_valid: typing.Optional[int]=None, **\n-        kwargs) -&gt;None:\n-        assert min_valid is not None or max_valid is not None, 'when using \"%s\" you should specify at least one of min_valid and max_valid' % (\n-            type(self).__name__,)\n+    def __init__(\n+        self,\n+        validators: typing.List[Schemable],\n+        min_valid: typing.Optional[int] = None,\n+        max_valid: typing.Optional[int] = None,\n+        **kwargs,\n+    ) -&gt; None:\n+        assert min_valid is not None or max_valid is not None, (\n+            'when using \"%s\" you should specify at least one of min_valid and max_valid'\n+            % (type(self).__name__,)\n+        )\n         self.min_valid = min_valid or 0\n         self.max_valid = max_valid or len(validators)\n         super(SomeOf, self).__init__(*validators, **kwargs)\n\n+    def _exec(self, funcs, v, path=None):\n+        errors = []\n+        funcs = list(funcs)\n+        for func in funcs:\n+            try:\n+                if path is None:\n+                    v = func(v)\n+                else:\n+                    v = func(path, v)\n+            except Invalid as e:\n+                errors.append(e)\n+\n+        passed_count = len(funcs) - len(errors)\n+        if self.min_valid &lt;= passed_count &lt;= self.max_valid:\n+            return v\n+\n+        msg = self.msg\n+        if not msg:\n+            msg = ', '.join(map(str, errors))\n+\n+        if passed_count &gt; self.max_valid:\n+            raise TooManyValid(msg)\n+        raise NotEnoughValid(msg)\n+\n     def __repr__(self):\n-        return (\n-            'SomeOf(min_valid=%s, validators=[%s], max_valid=%s, msg=%r)' %\n-            (self.min_valid, ', '.join(repr(v) for v in self.validators),\n-            self.max_valid, self.msg))\n+        return 'SomeOf(min_valid=%s, validators=[%s], max_valid=%s, msg=%r)' % (\n+            self.min_valid,\n+            \", \".join(repr(v) for v in self.validators),\n+            self.max_valid,\n+            self.msg,\n+        )\n</code></pre>"},{"location":"analysis_reference_wcwidth/","title":"Analysis reference wcwidth","text":"<p>back to reference summary</p>"},{"location":"analysis_reference_wcwidth/#submission-name-reference","title":"Submission Name: reference","text":""},{"location":"analysis_reference_wcwidth/#repository-wcwidth","title":"Repository: wcwidth","text":""},{"location":"analysis_reference_wcwidth/#pytest-summary-tests","title":"Pytest Summary: tests","text":"status count passed 38 skipped 1 total 39 collected 39"},{"location":"analysis_reference_wcwidth/#failed-pytest-outputs-tests","title":"Failed pytest outputs: tests","text":""},{"location":"analysis_reference_wcwidth/#test_table_integritypytest_verify_table_integrity","title":"test_table_integrity.py::test_verify_table_integrity","text":"<pre>test_table_integrity.py::test_verify_table_integrity</pre><pre>\n('/testbed/tests/test_table_integrity.py', 10, 'Skipped: Test only with a single version of python')\n</pre>"},{"location":"analysis_reference_wcwidth/#patch-diff","title":"Patch diff","text":"<pre><code>diff --git a/wcwidth/table_vs16.py b/wcwidth/table_vs16.py\nindex a064331..3249262 100644\n--- a/wcwidth/table_vs16.py\n+++ b/wcwidth/table_vs16.py\n@@ -3,29 +3,123 @@ Exports VS16_NARROW_TO_WIDE table keyed by supporting unicode version level.\n\n This code generated by wcwidth/bin/update-tables.py on 2023-11-07 16:43:49 UTC.\n \"\"\"\n-VS16_NARROW_TO_WIDE = {'9.0.0': ((35, 35), (42, 42), (48, 57), (169, 169),\n-    (174, 174), (8252, 8252), (8265, 8265), (8482, 8482), (8505, 8505), (\n-    8596, 8601), (8617, 8618), (9000, 9000), (9167, 9167), (9197, 9199), (\n-    9201, 9202), (9208, 9210), (9410, 9410), (9642, 9643), (9654, 9654), (\n-    9664, 9664), (9723, 9724), (9728, 9732), (9742, 9742), (9745, 9745), (\n-    9752, 9752), (9757, 9757), (9760, 9760), (9762, 9763), (9766, 9766), (\n-    9770, 9770), (9774, 9775), (9784, 9786), (9792, 9792), (9794, 9794), (\n-    9823, 9824), (9827, 9827), (9829, 9830), (9832, 9832), (9851, 9851), (\n-    9854, 9854), (9874, 9874), (9876, 9879), (9881, 9881), (9883, 9884), (\n-    9888, 9888), (9895, 9895), (9904, 9905), (9928, 9928), (9935, 9935), (\n-    9937, 9937), (9939, 9939), (9961, 9961), (9968, 9969), (9972, 9972), (\n-    9975, 9977), (9986, 9986), (9992, 9993), (9996, 9997), (9999, 9999), (\n-    10002, 10002), (10004, 10004), (10006, 10006), (10013, 10013), (10017, \n-    10017), (10035, 10036), (10052, 10052), (10055, 10055), (10083, 10084),\n-    (10145, 10145), (10548, 10549), (11013, 11015), (127344, 127345), (\n-    127358, 127359), (127777, 127777), (127780, 127788), (127798, 127798),\n-    (127869, 127869), (127894, 127895), (127897, 127899), (127902, 127903),\n-    (127947, 127950), (127956, 127967), (127987, 127987), (127989, 127989),\n-    (127991, 127991), (128063, 128063), (128065, 128065), (128253, 128253),\n-    (128329, 128330), (128367, 128368), (128371, 128377), (128391, 128391),\n-    (128394, 128397), (128400, 128400), (128421, 128421), (128424, 128424),\n-    (128433, 128434), (128444, 128444), (128450, 128452), (128465, 128467),\n-    (128476, 128478), (128481, 128481), (128483, 128483), (128488, 128488),\n-    (128495, 128495), (128499, 128499), (128506, 128506), (128715, 128715),\n-    (128717, 128719), (128736, 128741), (128745, 128745), (128752, 128752),\n-    (128755, 128755))}\n+VS16_NARROW_TO_WIDE = {\n+    '9.0.0': (\n+        # Source: 9.0.0\n+        # Date: 2023-02-01, 02:22:54 GMT\n+        #\n+        (0x00023, 0x00023,),  # Number Sign\n+        (0x0002a, 0x0002a,),  # Asterisk\n+        (0x00030, 0x00039,),  # Digit Zero              ..Digit Nine\n+        (0x000a9, 0x000a9,),  # Copyright Sign\n+        (0x000ae, 0x000ae,),  # Registered Sign\n+        (0x0203c, 0x0203c,),  # Double Exclamation Mark\n+        (0x02049, 0x02049,),  # Exclamation Question Mark\n+        (0x02122, 0x02122,),  # Trade Mark Sign\n+        (0x02139, 0x02139,),  # Information Source\n+        (0x02194, 0x02199,),  # Left Right Arrow        ..South West Arrow\n+        (0x021a9, 0x021aa,),  # Leftwards Arrow With Hoo..Rightwards Arrow With Ho\n+        (0x02328, 0x02328,),  # Keyboard\n+        (0x023cf, 0x023cf,),  # Eject Symbol\n+        (0x023ed, 0x023ef,),  # Black Right-pointing Dou..Black Right-pointing Tri\n+        (0x023f1, 0x023f2,),  # Stopwatch               ..Timer Clock\n+        (0x023f8, 0x023fa,),  # Double Vertical Bar     ..Black Circle For Record\n+        (0x024c2, 0x024c2,),  # Circled Latin Capital Letter M\n+        (0x025aa, 0x025ab,),  # Black Small Square      ..White Small Square\n+        (0x025b6, 0x025b6,),  # Black Right-pointing Triangle\n+        (0x025c0, 0x025c0,),  # Black Left-pointing Triangle\n+        (0x025fb, 0x025fc,),  # White Medium Square     ..Black Medium Square\n+        (0x02600, 0x02604,),  # Black Sun With Rays     ..Comet\n+        (0x0260e, 0x0260e,),  # Black Telephone\n+        (0x02611, 0x02611,),  # Ballot Box With Check\n+        (0x02618, 0x02618,),  # Shamrock\n+        (0x0261d, 0x0261d,),  # White Up Pointing Index\n+        (0x02620, 0x02620,),  # Skull And Crossbones\n+        (0x02622, 0x02623,),  # Radioactive Sign        ..Biohazard Sign\n+        (0x02626, 0x02626,),  # Orthodox Cross\n+        (0x0262a, 0x0262a,),  # Star And Crescent\n+        (0x0262e, 0x0262f,),  # Peace Symbol            ..Yin Yang\n+        (0x02638, 0x0263a,),  # Wheel Of Dharma         ..White Smiling Face\n+        (0x02640, 0x02640,),  # Female Sign\n+        (0x02642, 0x02642,),  # Male Sign\n+        (0x0265f, 0x02660,),  # Black Chess Pawn        ..Black Spade Suit\n+        (0x02663, 0x02663,),  # Black Club Suit\n+        (0x02665, 0x02666,),  # Black Heart Suit        ..Black Diamond Suit\n+        (0x02668, 0x02668,),  # Hot Springs\n+        (0x0267b, 0x0267b,),  # Black Universal Recycling Symbol\n+        (0x0267e, 0x0267e,),  # Permanent Paper Sign\n+        (0x02692, 0x02692,),  # Hammer And Pick\n+        (0x02694, 0x02697,),  # Crossed Swords          ..Alembic\n+        (0x02699, 0x02699,),  # Gear\n+        (0x0269b, 0x0269c,),  # Atom Symbol             ..Fleur-de-lis\n+        (0x026a0, 0x026a0,),  # Warning Sign\n+        (0x026a7, 0x026a7,),  # Male With Stroke And Male And Female Sign\n+        (0x026b0, 0x026b1,),  # Coffin                  ..Funeral Urn\n+        (0x026c8, 0x026c8,),  # Thunder Cloud And Rain\n+        (0x026cf, 0x026cf,),  # Pick\n+        (0x026d1, 0x026d1,),  # Helmet With White Cross\n+        (0x026d3, 0x026d3,),  # Chains\n+        (0x026e9, 0x026e9,),  # Shinto Shrine\n+        (0x026f0, 0x026f1,),  # Mountain                ..Umbrella On Ground\n+        (0x026f4, 0x026f4,),  # Ferry\n+        (0x026f7, 0x026f9,),  # Skier                   ..Person With Ball\n+        (0x02702, 0x02702,),  # Black Scissors\n+        (0x02708, 0x02709,),  # Airplane                ..Envelope\n+        (0x0270c, 0x0270d,),  # Victory Hand            ..Writing Hand\n+        (0x0270f, 0x0270f,),  # Pencil\n+        (0x02712, 0x02712,),  # Black Nib\n+        (0x02714, 0x02714,),  # Heavy Check Mark\n+        (0x02716, 0x02716,),  # Heavy Multiplication X\n+        (0x0271d, 0x0271d,),  # Latin Cross\n+        (0x02721, 0x02721,),  # Star Of David\n+        (0x02733, 0x02734,),  # Eight Spoked Asterisk   ..Eight Pointed Black Star\n+        (0x02744, 0x02744,),  # Snowflake\n+        (0x02747, 0x02747,),  # Sparkle\n+        (0x02763, 0x02764,),  # Heavy Heart Exclamation ..Heavy Black Heart\n+        (0x027a1, 0x027a1,),  # Black Rightwards Arrow\n+        (0x02934, 0x02935,),  # Arrow Pointing Rightward..Arrow Pointing Rightward\n+        (0x02b05, 0x02b07,),  # Leftwards Black Arrow   ..Downwards Black Arrow\n+        (0x1f170, 0x1f171,),  # Negative Squared Latin C..Negative Squared Latin C\n+        (0x1f17e, 0x1f17f,),  # Negative Squared Latin C..Negative Squared Latin C\n+        (0x1f321, 0x1f321,),  # Thermometer\n+        (0x1f324, 0x1f32c,),  # White Sun With Small Clo..Wind Blowing Face\n+        (0x1f336, 0x1f336,),  # Hot Pepper\n+        (0x1f37d, 0x1f37d,),  # Fork And Knife With Plate\n+        (0x1f396, 0x1f397,),  # Military Medal          ..Reminder Ribbon\n+        (0x1f399, 0x1f39b,),  # Studio Microphone       ..Control Knobs\n+        (0x1f39e, 0x1f39f,),  # Film Frames             ..Admission Tickets\n+        (0x1f3cb, 0x1f3ce,),  # Weight Lifter           ..Racing Car\n+        (0x1f3d4, 0x1f3df,),  # Snow Capped Mountain    ..Stadium\n+        (0x1f3f3, 0x1f3f3,),  # Waving White Flag\n+        (0x1f3f5, 0x1f3f5,),  # Rosette\n+        (0x1f3f7, 0x1f3f7,),  # Label\n+        (0x1f43f, 0x1f43f,),  # Chipmunk\n+        (0x1f441, 0x1f441,),  # Eye\n+        (0x1f4fd, 0x1f4fd,),  # Film Projector\n+        (0x1f549, 0x1f54a,),  # Om Symbol               ..Dove Of Peace\n+        (0x1f56f, 0x1f570,),  # Candle                  ..Mantelpiece Clock\n+        (0x1f573, 0x1f579,),  # Hole                    ..Joystick\n+        (0x1f587, 0x1f587,),  # Linked Paperclips\n+        (0x1f58a, 0x1f58d,),  # Lower Left Ballpoint Pen..Lower Left Crayon\n+        (0x1f590, 0x1f590,),  # Raised Hand With Fingers Splayed\n+        (0x1f5a5, 0x1f5a5,),  # Desktop Computer\n+        (0x1f5a8, 0x1f5a8,),  # Printer\n+        (0x1f5b1, 0x1f5b2,),  # Three Button Mouse      ..Trackball\n+        (0x1f5bc, 0x1f5bc,),  # Frame With Picture\n+        (0x1f5c2, 0x1f5c4,),  # Card Index Dividers     ..File Cabinet\n+        (0x1f5d1, 0x1f5d3,),  # Wastebasket             ..Spiral Calendar Pad\n+        (0x1f5dc, 0x1f5de,),  # Compression             ..Rolled-up Newspaper\n+        (0x1f5e1, 0x1f5e1,),  # Dagger Knife\n+        (0x1f5e3, 0x1f5e3,),  # Speaking Head In Silhouette\n+        (0x1f5e8, 0x1f5e8,),  # Left Speech Bubble\n+        (0x1f5ef, 0x1f5ef,),  # Right Anger Bubble\n+        (0x1f5f3, 0x1f5f3,),  # Ballot Box With Ballot\n+        (0x1f5fa, 0x1f5fa,),  # World Map\n+        (0x1f6cb, 0x1f6cb,),  # Couch And Lamp\n+        (0x1f6cd, 0x1f6cf,),  # Shopping Bags           ..Bed\n+        (0x1f6e0, 0x1f6e5,),  # Hammer And Wrench       ..Motor Boat\n+        (0x1f6e9, 0x1f6e9,),  # Small Airplane\n+        (0x1f6f0, 0x1f6f0,),  # Satellite\n+        (0x1f6f3, 0x1f6f3,),  # Passenger Ship\n+    ),\n+}\ndiff --git a/wcwidth/table_wide.py b/wcwidth/table_wide.py\nindex f36a027..bd6dfdd 100644\n--- a/wcwidth/table_wide.py\n+++ b/wcwidth/table_wide.py\n@@ -3,327 +3,1491 @@ Exports WIDE_EASTASIAN table keyed by supporting unicode version level.\n\n This code generated by wcwidth/bin/update-tables.py on 2024-01-06 01:39:49 UTC.\n \"\"\"\n-WIDE_EASTASIAN = {'4.1.0': ((4352, 4441), (4447, 4447), (9001, 9002), (\n-    11904, 11929), (11931, 12019), (12032, 12245), (12272, 12283), (12288, \n-    12329), (12336, 12350), (12353, 12438), (12443, 12543), (12549, 12588),\n-    (12593, 12686), (12688, 12727), (12736, 12751), (12784, 12830), (12832,\n-    12867), (12880, 13054), (13056, 19893), (19968, 40891), (40960, 42124),\n-    (42128, 42182), (44032, 55203), (63744, 64045), (64048, 64106), (64112,\n-    64217), (65040, 65049), (65072, 65106), (65108, 65126), (65128, 65131),\n-    (65281, 65376), (65504, 65510), (131072, 196605), (196608, 262141)),\n-    '5.0.0': ((4352, 4441), (4447, 4447), (9001, 9002), (11904, 11929), (\n-    11931, 12019), (12032, 12245), (12272, 12283), (12288, 12329), (12336, \n-    12350), (12353, 12438), (12443, 12543), (12549, 12588), (12593, 12686),\n-    (12688, 12727), (12736, 12751), (12784, 12830), (12832, 12867), (12880,\n-    13054), (13056, 19893), (19968, 40891), (40960, 42124), (42128, 42182),\n-    (44032, 55203), (63744, 64045), (64048, 64106), (64112, 64217), (65040,\n-    65049), (65072, 65106), (65108, 65126), (65128, 65131), (65281, 65376),\n-    (65504, 65510), (131072, 196605), (196608, 262141)), '5.1.0': ((4352, \n-    4441), (4447, 4447), (9001, 9002), (11904, 11929), (11931, 12019), (\n-    12032, 12245), (12272, 12283), (12288, 12329), (12336, 12350), (12353, \n-    12438), (12443, 12543), (12549, 12589), (12593, 12686), (12688, 12727),\n-    (12736, 12771), (12784, 12830), (12832, 12867), (12880, 13054), (13056,\n-    19893), (19968, 40899), (40960, 42124), (42128, 42182), (44032, 55203),\n-    (63744, 64045), (64048, 64106), (64112, 64217), (65040, 65049), (65072,\n-    65106), (65108, 65126), (65128, 65131), (65281, 65376), (65504, 65510),\n-    (131072, 196605), (196608, 262141)), '5.2.0': ((4352, 4447), (9001, \n-    9002), (11904, 11929), (11931, 12019), (12032, 12245), (12272, 12283),\n-    (12288, 12329), (12336, 12350), (12353, 12438), (12443, 12543), (12549,\n-    12589), (12593, 12686), (12688, 12727), (12736, 12771), (12784, 12830),\n-    (12832, 12871), (12880, 13054), (13056, 19903), (19968, 42124), (42128,\n-    42182), (43360, 43388), (44032, 55203), (63744, 64255), (65040, 65049),\n-    (65072, 65106), (65108, 65126), (65128, 65131), (65281, 65376), (65504,\n-    65510), (127488, 127488), (127504, 127537), (127552, 127560), (131072, \n-    196605), (196608, 262141)), '6.0.0': ((4352, 4447), (9001, 9002), (\n-    11904, 11929), (11931, 12019), (12032, 12245), (12272, 12283), (12288, \n-    12329), (12336, 12350), (12353, 12438), (12443, 12543), (12549, 12589),\n-    (12593, 12686), (12688, 12730), (12736, 12771), (12784, 12830), (12832,\n-    12871), (12880, 13054), (13056, 19903), (19968, 42124), (42128, 42182),\n-    (43360, 43388), (44032, 55203), (63744, 64255), (65040, 65049), (65072,\n-    65106), (65108, 65126), (65128, 65131), (65281, 65376), (65504, 65510),\n-    (110592, 110593), (127488, 127490), (127504, 127546), (127552, 127560),\n-    (127568, 127569), (131072, 196605), (196608, 262141)), '6.1.0': ((4352,\n-    4447), (9001, 9002), (11904, 11929), (11931, 12019), (12032, 12245), (\n-    12272, 12283), (12288, 12329), (12336, 12350), (12353, 12438), (12443, \n-    12543), (12549, 12589), (12593, 12686), (12688, 12730), (12736, 12771),\n-    (12784, 12830), (12832, 12871), (12880, 13054), (13056, 19903), (19968,\n-    42124), (42128, 42182), (43360, 43388), (44032, 55203), (63744, 64255),\n-    (65040, 65049), (65072, 65106), (65108, 65126), (65128, 65131), (65281,\n-    65376), (65504, 65510), (110592, 110593), (127488, 127490), (127504, \n-    127546), (127552, 127560), (127568, 127569), (131072, 196605), (196608,\n-    262141)), '6.2.0': ((4352, 4447), (9001, 9002), (11904, 11929), (11931,\n-    12019), (12032, 12245), (12272, 12283), (12288, 12329), (12336, 12350),\n-    (12353, 12438), (12443, 12543), (12549, 12589), (12593, 12686), (12688,\n-    12730), (12736, 12771), (12784, 12830), (12832, 12871), (12880, 13054),\n-    (13056, 19903), (19968, 42124), (42128, 42182), (43360, 43388), (44032,\n-    55203), (63744, 64255), (65040, 65049), (65072, 65106), (65108, 65126),\n-    (65128, 65131), (65281, 65376), (65504, 65510), (110592, 110593), (\n-    127488, 127490), (127504, 127546), (127552, 127560), (127568, 127569),\n-    (131072, 196605), (196608, 262141)), '6.3.0': ((4352, 4447), (9001, \n-    9002), (11904, 11929), (11931, 12019), (12032, 12245), (12272, 12283),\n-    (12288, 12329), (12336, 12350), (12353, 12438), (12443, 12543), (12549,\n-    12589), (12593, 12686), (12688, 12730), (12736, 12771), (12784, 12830),\n-    (12832, 12871), (12880, 13054), (13056, 19903), (19968, 42124), (42128,\n-    42182), (43360, 43388), (44032, 55203), (63744, 64255), (65040, 65049),\n-    (65072, 65106), (65108, 65126), (65128, 65131), (65281, 65376), (65504,\n-    65510), (110592, 110593), (127488, 127490), (127504, 127546), (127552, \n-    127560), (127568, 127569), (131072, 196605), (196608, 262141)), '7.0.0':\n-    ((4352, 4447), (9001, 9002), (11904, 11929), (11931, 12019), (12032, \n-    12245), (12272, 12283), (12288, 12329), (12336, 12350), (12353, 12438),\n-    (12443, 12543), (12549, 12589), (12593, 12686), (12688, 12730), (12736,\n-    12771), (12784, 12830), (12832, 12871), (12880, 13054), (13056, 19903),\n-    (19968, 42124), (42128, 42182), (43360, 43388), (44032, 55203), (63744,\n-    64255), (65040, 65049), (65072, 65106), (65108, 65126), (65128, 65131),\n-    (65281, 65376), (65504, 65510), (110592, 110593), (127488, 127490), (\n-    127504, 127546), (127552, 127560), (127568, 127569), (131072, 196605),\n-    (196608, 262141)), '8.0.0': ((4352, 4447), (9001, 9002), (11904, 11929),\n-    (11931, 12019), (12032, 12245), (12272, 12283), (12288, 12329), (12336,\n-    12350), (12353, 12438), (12443, 12543), (12549, 12589), (12593, 12686),\n-    (12688, 12730), (12736, 12771), (12784, 12830), (12832, 12871), (12880,\n-    13054), (13056, 19903), (19968, 42124), (42128, 42182), (43360, 43388),\n-    (44032, 55203), (63744, 64255), (65040, 65049), (65072, 65106), (65108,\n-    65126), (65128, 65131), (65281, 65376), (65504, 65510), (110592, 110593\n-    ), (127488, 127490), (127504, 127546), (127552, 127560), (127568, \n-    127569), (131072, 196605), (196608, 262141)), '9.0.0': ((4352, 4447), (\n-    8986, 8987), (9001, 9002), (9193, 9196), (9200, 9200), (9203, 9203), (\n-    9725, 9726), (9748, 9749), (9800, 9811), (9855, 9855), (9875, 9875), (\n-    9889, 9889), (9898, 9899), (9917, 9918), (9924, 9925), (9934, 9934), (\n-    9940, 9940), (9962, 9962), (9970, 9971), (9973, 9973), (9978, 9978), (\n-    9981, 9981), (9989, 9989), (9994, 9995), (10024, 10024), (10060, 10060),\n-    (10062, 10062), (10067, 10069), (10071, 10071), (10133, 10135), (10160,\n-    10160), (10175, 10175), (11035, 11036), (11088, 11088), (11093, 11093),\n-    (11904, 11929), (11931, 12019), (12032, 12245), (12272, 12283), (12288,\n-    12329), (12336, 12350), (12353, 12438), (12443, 12543), (12549, 12589),\n-    (12593, 12686), (12688, 12730), (12736, 12771), (12784, 12830), (12832,\n-    12871), (12880, 13054), (13056, 19903), (19968, 42124), (42128, 42182),\n-    (43360, 43388), (44032, 55203), (63744, 64255), (65040, 65049), (65072,\n-    65106), (65108, 65126), (65128, 65131), (65281, 65376), (65504, 65510),\n-    (94176, 94176), (94208, 100332), (100352, 101106), (110592, 110593), (\n-    126980, 126980), (127183, 127183), (127374, 127374), (127377, 127386),\n-    (127488, 127490), (127504, 127547), (127552, 127560), (127568, 127569),\n-    (127744, 127776), (127789, 127797), (127799, 127868), (127870, 127891),\n-    (127904, 127946), (127951, 127955), (127968, 127984), (127988, 127988),\n-    (127992, 127994), (128000, 128062), (128064, 128064), (128066, 128252),\n-    (128255, 128317), (128331, 128334), (128336, 128359), (128378, 128378),\n-    (128405, 128406), (128420, 128420), (128507, 128591), (128640, 128709),\n-    (128716, 128716), (128720, 128722), (128747, 128748), (128756, 128758),\n-    (129296, 129310), (129312, 129319), (129328, 129328), (129331, 129342),\n-    (129344, 129355), (129360, 129374), (129408, 129425), (129472, 129472),\n-    (131072, 196605), (196608, 262141)), '10.0.0': ((4352, 4447), (8986, \n-    8987), (9001, 9002), (9193, 9196), (9200, 9200), (9203, 9203), (9725, \n-    9726), (9748, 9749), (9800, 9811), (9855, 9855), (9875, 9875), (9889, \n-    9889), (9898, 9899), (9917, 9918), (9924, 9925), (9934, 9934), (9940, \n-    9940), (9962, 9962), (9970, 9971), (9973, 9973), (9978, 9978), (9981, \n-    9981), (9989, 9989), (9994, 9995), (10024, 10024), (10060, 10060), (\n-    10062, 10062), (10067, 10069), (10071, 10071), (10133, 10135), (10160, \n-    10160), (10175, 10175), (11035, 11036), (11088, 11088), (11093, 11093),\n-    (11904, 11929), (11931, 12019), (12032, 12245), (12272, 12283), (12288,\n-    12329), (12336, 12350), (12353, 12438), (12443, 12543), (12549, 12590),\n-    (12593, 12686), (12688, 12730), (12736, 12771), (12784, 12830), (12832,\n-    12871), (12880, 13054), (13056, 19903), (19968, 42124), (42128, 42182),\n-    (43360, 43388), (44032, 55203), (63744, 64255), (65040, 65049), (65072,\n-    65106), (65108, 65126), (65128, 65131), (65281, 65376), (65504, 65510),\n-    (94176, 94177), (94208, 100332), (100352, 101106), (110592, 110878), (\n-    110960, 111355), (126980, 126980), (127183, 127183), (127374, 127374),\n-    (127377, 127386), (127488, 127490), (127504, 127547), (127552, 127560),\n-    (127568, 127569), (127584, 127589), (127744, 127776), (127789, 127797),\n-    (127799, 127868), (127870, 127891), (127904, 127946), (127951, 127955),\n-    (127968, 127984), (127988, 127988), (127992, 127994), (128000, 128062),\n-    (128064, 128064), (128066, 128252), (128255, 128317), (128331, 128334),\n-    (128336, 128359), (128378, 128378), (128405, 128406), (128420, 128420),\n-    (128507, 128591), (128640, 128709), (128716, 128716), (128720, 128722),\n-    (128747, 128748), (128756, 128760), (129296, 129342), (129344, 129356),\n-    (129360, 129387), (129408, 129431), (129472, 129472), (129488, 129510),\n-    (131072, 196605), (196608, 262141)), '11.0.0': ((4352, 4447), (8986, \n-    8987), (9001, 9002), (9193, 9196), (9200, 9200), (9203, 9203), (9725, \n-    9726), (9748, 9749), (9800, 9811), (9855, 9855), (9875, 9875), (9889, \n-    9889), (9898, 9899), (9917, 9918), (9924, 9925), (9934, 9934), (9940, \n-    9940), (9962, 9962), (9970, 9971), (9973, 9973), (9978, 9978), (9981, \n-    9981), (9989, 9989), (9994, 9995), (10024, 10024), (10060, 10060), (\n-    10062, 10062), (10067, 10069), (10071, 10071), (10133, 10135), (10160, \n-    10160), (10175, 10175), (11035, 11036), (11088, 11088), (11093, 11093),\n-    (11904, 11929), (11931, 12019), (12032, 12245), (12272, 12283), (12288,\n-    12329), (12336, 12350), (12353, 12438), (12443, 12543), (12549, 12591),\n-    (12593, 12686), (12688, 12730), (12736, 12771), (12784, 12830), (12832,\n-    12871), (12880, 13054), (13056, 19903), (19968, 42124), (42128, 42182),\n-    (43360, 43388), (44032, 55203), (63744, 64255), (65040, 65049), (65072,\n-    65106), (65108, 65126), (65128, 65131), (65281, 65376), (65504, 65510),\n-    (94176, 94177), (94208, 100337), (100352, 101106), (110592, 110878), (\n-    110960, 111355), (126980, 126980), (127183, 127183), (127374, 127374),\n-    (127377, 127386), (127488, 127490), (127504, 127547), (127552, 127560),\n-    (127568, 127569), (127584, 127589), (127744, 127776), (127789, 127797),\n-    (127799, 127868), (127870, 127891), (127904, 127946), (127951, 127955),\n-    (127968, 127984), (127988, 127988), (127992, 127994), (128000, 128062),\n-    (128064, 128064), (128066, 128252), (128255, 128317), (128331, 128334),\n-    (128336, 128359), (128378, 128378), (128405, 128406), (128420, 128420),\n-    (128507, 128591), (128640, 128709), (128716, 128716), (128720, 128722),\n-    (128747, 128748), (128756, 128761), (129296, 129342), (129344, 129392),\n-    (129395, 129398), (129402, 129402), (129404, 129442), (129456, 129465),\n-    (129472, 129474), (129488, 129535), (131072, 196605), (196608, 262141)),\n-    '12.0.0': ((4352, 4447), (8986, 8987), (9001, 9002), (9193, 9196), (\n-    9200, 9200), (9203, 9203), (9725, 9726), (9748, 9749), (9800, 9811), (\n-    9855, 9855), (9875, 9875), (9889, 9889), (9898, 9899), (9917, 9918), (\n-    9924, 9925), (9934, 9934), (9940, 9940), (9962, 9962), (9970, 9971), (\n-    9973, 9973), (9978, 9978), (9981, 9981), (9989, 9989), (9994, 9995), (\n-    10024, 10024), (10060, 10060), (10062, 10062), (10067, 10069), (10071, \n-    10071), (10133, 10135), (10160, 10160), (10175, 10175), (11035, 11036),\n-    (11088, 11088), (11093, 11093), (11904, 11929), (11931, 12019), (12032,\n-    12245), (12272, 12283), (12288, 12329), (12336, 12350), (12353, 12438),\n-    (12443, 12543), (12549, 12591), (12593, 12686), (12688, 12730), (12736,\n-    12771), (12784, 12830), (12832, 12871), (12880, 13054), (13056, 19903),\n-    (19968, 42124), (42128, 42182), (43360, 43388), (44032, 55203), (63744,\n-    64255), (65040, 65049), (65072, 65106), (65108, 65126), (65128, 65131),\n-    (65281, 65376), (65504, 65510), (94176, 94179), (94208, 100343), (\n-    100352, 101106), (110592, 110878), (110928, 110930), (110948, 110951),\n-    (110960, 111355), (126980, 126980), (127183, 127183), (127374, 127374),\n-    (127377, 127386), (127488, 127490), (127504, 127547), (127552, 127560),\n-    (127568, 127569), (127584, 127589), (127744, 127776), (127789, 127797),\n-    (127799, 127868), (127870, 127891), (127904, 127946), (127951, 127955),\n-    (127968, 127984), (127988, 127988), (127992, 127994), (128000, 128062),\n-    (128064, 128064), (128066, 128252), (128255, 128317), (128331, 128334),\n-    (128336, 128359), (128378, 128378), (128405, 128406), (128420, 128420),\n-    (128507, 128591), (128640, 128709), (128716, 128716), (128720, 128722),\n-    (128725, 128725), (128747, 128748), (128756, 128762), (128992, 129003),\n-    (129293, 129393), (129395, 129398), (129402, 129442), (129445, 129450),\n-    (129454, 129482), (129485, 129535), (129648, 129651), (129656, 129658),\n-    (129664, 129666), (129680, 129685), (131072, 196605), (196608, 262141)),\n-    '12.1.0': ((4352, 4447), (8986, 8987), (9001, 9002), (9193, 9196), (\n-    9200, 9200), (9203, 9203), (9725, 9726), (9748, 9749), (9800, 9811), (\n-    9855, 9855), (9875, 9875), (9889, 9889), (9898, 9899), (9917, 9918), (\n-    9924, 9925), (9934, 9934), (9940, 9940), (9962, 9962), (9970, 9971), (\n-    9973, 9973), (9978, 9978), (9981, 9981), (9989, 9989), (9994, 9995), (\n-    10024, 10024), (10060, 10060), (10062, 10062), (10067, 10069), (10071, \n-    10071), (10133, 10135), (10160, 10160), (10175, 10175), (11035, 11036),\n-    (11088, 11088), (11093, 11093), (11904, 11929), (11931, 12019), (12032,\n-    12245), (12272, 12283), (12288, 12329), (12336, 12350), (12353, 12438),\n-    (12443, 12543), (12549, 12591), (12593, 12686), (12688, 12730), (12736,\n-    12771), (12784, 12830), (12832, 12871), (12880, 19903), (19968, 42124),\n-    (42128, 42182), (43360, 43388), (44032, 55203), (63744, 64255), (65040,\n-    65049), (65072, 65106), (65108, 65126), (65128, 65131), (65281, 65376),\n-    (65504, 65510), (94176, 94179), (94208, 100343), (100352, 101106), (\n-    110592, 110878), (110928, 110930), (110948, 110951), (110960, 111355),\n-    (126980, 126980), (127183, 127183), (127374, 127374), (127377, 127386),\n-    (127488, 127490), (127504, 127547), (127552, 127560), (127568, 127569),\n-    (127584, 127589), (127744, 127776), (127789, 127797), (127799, 127868),\n-    (127870, 127891), (127904, 127946), (127951, 127955), (127968, 127984),\n-    (127988, 127988), (127992, 127994), (128000, 128062), (128064, 128064),\n-    (128066, 128252), (128255, 128317), (128331, 128334), (128336, 128359),\n-    (128378, 128378), (128405, 128406), (128420, 128420), (128507, 128591),\n-    (128640, 128709), (128716, 128716), (128720, 128722), (128725, 128725),\n-    (128747, 128748), (128756, 128762), (128992, 129003), (129293, 129393),\n-    (129395, 129398), (129402, 129442), (129445, 129450), (129454, 129482),\n-    (129485, 129535), (129648, 129651), (129656, 129658), (129664, 129666),\n-    (129680, 129685), (131072, 196605), (196608, 262141)), '13.0.0': ((4352,\n-    4447), (8986, 8987), (9001, 9002), (9193, 9196), (9200, 9200), (9203, \n-    9203), (9725, 9726), (9748, 9749), (9800, 9811), (9855, 9855), (9875, \n-    9875), (9889, 9889), (9898, 9899), (9917, 9918), (9924, 9925), (9934, \n-    9934), (9940, 9940), (9962, 9962), (9970, 9971), (9973, 9973), (9978, \n-    9978), (9981, 9981), (9989, 9989), (9994, 9995), (10024, 10024), (10060,\n-    10060), (10062, 10062), (10067, 10069), (10071, 10071), (10133, 10135),\n-    (10160, 10160), (10175, 10175), (11035, 11036), (11088, 11088), (11093,\n-    11093), (11904, 11929), (11931, 12019), (12032, 12245), (12272, 12283),\n-    (12288, 12329), (12336, 12350), (12353, 12438), (12443, 12543), (12549,\n-    12591), (12593, 12686), (12688, 12771), (12784, 12830), (12832, 12871),\n-    (12880, 19903), (19968, 42124), (42128, 42182), (43360, 43388), (44032,\n-    55203), (63744, 64255), (65040, 65049), (65072, 65106), (65108, 65126),\n-    (65128, 65131), (65281, 65376), (65504, 65510), (94176, 94179), (94208,\n-    100343), (100352, 101589), (101632, 101640), (110592, 110878), (110928,\n-    110930), (110948, 110951), (110960, 111355), (126980, 126980), (127183,\n-    127183), (127374, 127374), (127377, 127386), (127488, 127490), (127504,\n-    127547), (127552, 127560), (127568, 127569), (127584, 127589), (127744,\n-    127776), (127789, 127797), (127799, 127868), (127870, 127891), (127904,\n-    127946), (127951, 127955), (127968, 127984), (127988, 127988), (127992,\n-    127994), (128000, 128062), (128064, 128064), (128066, 128252), (128255,\n-    128317), (128331, 128334), (128336, 128359), (128378, 128378), (128405,\n-    128406), (128420, 128420), (128507, 128591), (128640, 128709), (128716,\n-    128716), (128720, 128722), (128725, 128727), (128747, 128748), (128756,\n-    128764), (128992, 129003), (129292, 129338), (129340, 129349), (129351,\n-    129400), (129402, 129483), (129485, 129535), (129648, 129652), (129656,\n-    129658), (129664, 129670), (129680, 129704), (129712, 129718), (129728,\n-    129730), (129744, 129750), (131072, 196605), (196608, 262141)),\n-    '14.0.0': ((4352, 4447), (8986, 8987), (9001, 9002), (9193, 9196), (\n-    9200, 9200), (9203, 9203), (9725, 9726), (9748, 9749), (9800, 9811), (\n-    9855, 9855), (9875, 9875), (9889, 9889), (9898, 9899), (9917, 9918), (\n-    9924, 9925), (9934, 9934), (9940, 9940), (9962, 9962), (9970, 9971), (\n-    9973, 9973), (9978, 9978), (9981, 9981), (9989, 9989), (9994, 9995), (\n-    10024, 10024), (10060, 10060), (10062, 10062), (10067, 10069), (10071, \n-    10071), (10133, 10135), (10160, 10160), (10175, 10175), (11035, 11036),\n-    (11088, 11088), (11093, 11093), (11904, 11929), (11931, 12019), (12032,\n-    12245), (12272, 12283), (12288, 12329), (12336, 12350), (12353, 12438),\n-    (12443, 12543), (12549, 12591), (12593, 12686), (12688, 12771), (12784,\n-    12830), (12832, 12871), (12880, 19903), (19968, 42124), (42128, 42182),\n-    (43360, 43388), (44032, 55203), (63744, 64255), (65040, 65049), (65072,\n-    65106), (65108, 65126), (65128, 65131), (65281, 65376), (65504, 65510),\n-    (94176, 94179), (94208, 100343), (100352, 101589), (101632, 101640), (\n-    110576, 110579), (110581, 110587), (110589, 110590), (110592, 110882),\n-    (110928, 110930), (110948, 110951), (110960, 111355), (126980, 126980),\n-    (127183, 127183), (127374, 127374), (127377, 127386), (127488, 127490),\n-    (127504, 127547), (127552, 127560), (127568, 127569), (127584, 127589),\n-    (127744, 127776), (127789, 127797), (127799, 127868), (127870, 127891),\n-    (127904, 127946), (127951, 127955), (127968, 127984), (127988, 127988),\n-    (127992, 127994), (128000, 128062), (128064, 128064), (128066, 128252),\n-    (128255, 128317), (128331, 128334), (128336, 128359), (128378, 128378),\n-    (128405, 128406), (128420, 128420), (128507, 128591), (128640, 128709),\n-    (128716, 128716), (128720, 128722), (128725, 128727), (128733, 128735),\n-    (128747, 128748), (128756, 128764), (128992, 129003), (129008, 129008),\n-    (129292, 129338), (129340, 129349), (129351, 129535), (129648, 129652),\n-    (129656, 129660), (129664, 129670), (129680, 129708), (129712, 129722),\n-    (129728, 129733), (129744, 129753), (129760, 129767), (129776, 129782),\n-    (131072, 196605), (196608, 262141)), '15.0.0': ((4352, 4447), (8986, \n-    8987), (9001, 9002), (9193, 9196), (9200, 9200), (9203, 9203), (9725, \n-    9726), (9748, 9749), (9800, 9811), (9855, 9855), (9875, 9875), (9889, \n-    9889), (9898, 9899), (9917, 9918), (9924, 9925), (9934, 9934), (9940, \n-    9940), (9962, 9962), (9970, 9971), (9973, 9973), (9978, 9978), (9981, \n-    9981), (9989, 9989), (9994, 9995), (10024, 10024), (10060, 10060), (\n-    10062, 10062), (10067, 10069), (10071, 10071), (10133, 10135), (10160, \n-    10160), (10175, 10175), (11035, 11036), (11088, 11088), (11093, 11093),\n-    (11904, 11929), (11931, 12019), (12032, 12245), (12272, 12283), (12288,\n-    12329), (12336, 12350), (12353, 12438), (12443, 12543), (12549, 12591),\n-    (12593, 12686), (12688, 12771), (12784, 12830), (12832, 12871), (12880,\n-    19903), (19968, 42124), (42128, 42182), (43360, 43388), (44032, 55203),\n-    (63744, 64255), (65040, 65049), (65072, 65106), (65108, 65126), (65128,\n-    65131), (65281, 65376), (65504, 65510), (94176, 94179), (94208, 100343),\n-    (100352, 101589), (101632, 101640), (110576, 110579), (110581, 110587),\n-    (110589, 110590), (110592, 110882), (110898, 110898), (110928, 110930),\n-    (110933, 110933), (110948, 110951), (110960, 111355), (126980, 126980),\n-    (127183, 127183), (127374, 127374), (127377, 127386), (127488, 127490),\n-    (127504, 127547), (127552, 127560), (127568, 127569), (127584, 127589),\n-    (127744, 127776), (127789, 127797), (127799, 127868), (127870, 127891),\n-    (127904, 127946), (127951, 127955), (127968, 127984), (127988, 127988),\n-    (127992, 127994), (128000, 128062), (128064, 128064), (128066, 128252),\n-    (128255, 128317), (128331, 128334), (128336, 128359), (128378, 128378),\n-    (128405, 128406), (128420, 128420), (128507, 128591), (128640, 128709),\n-    (128716, 128716), (128720, 128722), (128725, 128727), (128732, 128735),\n-    (128747, 128748), (128756, 128764), (128992, 129003), (129008, 129008),\n-    (129292, 129338), (129340, 129349), (129351, 129535), (129648, 129660),\n-    (129664, 129672), (129680, 129725), (129727, 129733), (129742, 129755),\n-    (129760, 129768), (129776, 129784), (131072, 196605), (196608, 262141)),\n-    '15.1.0': ((4352, 4447), (8986, 8987), (9001, 9002), (9193, 9196), (\n-    9200, 9200), (9203, 9203), (9725, 9726), (9748, 9749), (9800, 9811), (\n-    9855, 9855), (9875, 9875), (9889, 9889), (9898, 9899), (9917, 9918), (\n-    9924, 9925), (9934, 9934), (9940, 9940), (9962, 9962), (9970, 9971), (\n-    9973, 9973), (9978, 9978), (9981, 9981), (9989, 9989), (9994, 9995), (\n-    10024, 10024), (10060, 10060), (10062, 10062), (10067, 10069), (10071, \n-    10071), (10133, 10135), (10160, 10160), (10175, 10175), (11035, 11036),\n-    (11088, 11088), (11093, 11093), (11904, 11929), (11931, 12019), (12032,\n-    12245), (12272, 12329), (12336, 12350), (12353, 12438), (12443, 12543),\n-    (12549, 12591), (12593, 12686), (12688, 12771), (12783, 12830), (12832,\n-    12871), (12880, 19903), (19968, 42124), (42128, 42182), (43360, 43388),\n-    (44032, 55203), (63744, 64255), (65040, 65049), (65072, 65106), (65108,\n-    65126), (65128, 65131), (65281, 65376), (65504, 65510), (94176, 94179),\n-    (94208, 100343), (100352, 101589), (101632, 101640), (110576, 110579),\n-    (110581, 110587), (110589, 110590), (110592, 110882), (110898, 110898),\n-    (110928, 110930), (110933, 110933), (110948, 110951), (110960, 111355),\n-    (126980, 126980), (127183, 127183), (127374, 127374), (127377, 127386),\n-    (127488, 127490), (127504, 127547), (127552, 127560), (127568, 127569),\n-    (127584, 127589), (127744, 127776), (127789, 127797), (127799, 127868),\n-    (127870, 127891), (127904, 127946), (127951, 127955), (127968, 127984),\n-    (127988, 127988), (127992, 127994), (128000, 128062), (128064, 128064),\n-    (128066, 128252), (128255, 128317), (128331, 128334), (128336, 128359),\n-    (128378, 128378), (128405, 128406), (128420, 128420), (128507, 128591),\n-    (128640, 128709), (128716, 128716), (128720, 128722), (128725, 128727),\n-    (128732, 128735), (128747, 128748), (128756, 128764), (128992, 129003),\n-    (129008, 129008), (129292, 129338), (129340, 129349), (129351, 129535),\n-    (129648, 129660), (129664, 129672), (129680, 129725), (129727, 129733),\n-    (129742, 129755), (129760, 129768), (129776, 129784), (131072, 196605),\n-    (196608, 262141))}\n+WIDE_EASTASIAN = {\n+    '4.1.0': (\n+        # Source: EastAsianWidth-4.1.0.txt\n+        # Date: 2005-03-17, 15:21:00 PST [KW]\n+        #\n+        (0x01100, 0x01159,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Yeorinhi\n+        (0x0115f, 0x0115f,),  # Hangul Choseong Filler\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312c,),  # Bopomofo Letter B       ..Bopomofo Letter Gn\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031b7,),  # Ideographic Annotation L..Bopomofo Final Letter H\n+        (0x031c0, 0x031cf,),  # Cjk Stroke T            ..Cjk Stroke N\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03243,),  # Parenthesized Ideograph ..Parenthesized Ideograph\n+        (0x03250, 0x032fe,),  # Partnership Sign        ..Circled Katakana Wo\n+        (0x03300, 0x04db5,),  # Square Apaato           ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x09fbb,),  # Cjk Unified Ideograph-4e..Cjk Unified Ideograph-9f\n+        (0x0a000, 0x0a48c,),  # Yi Syllable It          ..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0fa2d,),  # Cjk Compatibility Ideogr..Cjk Compatibility Ideogr\n+        (0x0fa30, 0x0fa6a,),  # Cjk Compatibility Ideogr..Cjk Compatibility Ideogr\n+        (0x0fa70, 0x0fad9,),  # Cjk Compatibility Ideogr..Cjk Compatibility Ideogr\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '5.0.0': (\n+        # Source: EastAsianWidth-5.0.0.txt\n+        # Date: 2006-02-15, 14:39:00 PST [KW]\n+        #\n+        (0x01100, 0x01159,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Yeorinhi\n+        (0x0115f, 0x0115f,),  # Hangul Choseong Filler\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312c,),  # Bopomofo Letter B       ..Bopomofo Letter Gn\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031b7,),  # Ideographic Annotation L..Bopomofo Final Letter H\n+        (0x031c0, 0x031cf,),  # Cjk Stroke T            ..Cjk Stroke N\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03243,),  # Parenthesized Ideograph ..Parenthesized Ideograph\n+        (0x03250, 0x032fe,),  # Partnership Sign        ..Circled Katakana Wo\n+        (0x03300, 0x04db5,),  # Square Apaato           ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x09fbb,),  # Cjk Unified Ideograph-4e..Cjk Unified Ideograph-9f\n+        (0x0a000, 0x0a48c,),  # Yi Syllable It          ..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0fa2d,),  # Cjk Compatibility Ideogr..Cjk Compatibility Ideogr\n+        (0x0fa30, 0x0fa6a,),  # Cjk Compatibility Ideogr..Cjk Compatibility Ideogr\n+        (0x0fa70, 0x0fad9,),  # Cjk Compatibility Ideogr..Cjk Compatibility Ideogr\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '5.1.0': (\n+        # Source: EastAsianWidth-5.1.0.txt\n+        # Date: 2008-03-20, 17:42:00 PDT [KW]\n+        #\n+        (0x01100, 0x01159,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Yeorinhi\n+        (0x0115f, 0x0115f,),  # Hangul Choseong Filler\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312d,),  # Bopomofo Letter B       ..Bopomofo Letter Ih\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031b7,),  # Ideographic Annotation L..Bopomofo Final Letter H\n+        (0x031c0, 0x031e3,),  # Cjk Stroke T            ..Cjk Stroke Q\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03243,),  # Parenthesized Ideograph ..Parenthesized Ideograph\n+        (0x03250, 0x032fe,),  # Partnership Sign        ..Circled Katakana Wo\n+        (0x03300, 0x04db5,),  # Square Apaato           ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x09fc3,),  # Cjk Unified Ideograph-4e..Cjk Unified Ideograph-9f\n+        (0x0a000, 0x0a48c,),  # Yi Syllable It          ..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0fa2d,),  # Cjk Compatibility Ideogr..Cjk Compatibility Ideogr\n+        (0x0fa30, 0x0fa6a,),  # Cjk Compatibility Ideogr..Cjk Compatibility Ideogr\n+        (0x0fa70, 0x0fad9,),  # Cjk Compatibility Ideogr..Cjk Compatibility Ideogr\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '5.2.0': (\n+        # Source: EastAsianWidth-5.2.0.txt\n+        # Date: 2009-06-09, 17:47:00 PDT [KW]\n+        #\n+        (0x01100, 0x0115f,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Filler\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312d,),  # Bopomofo Letter B       ..Bopomofo Letter Ih\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031b7,),  # Ideographic Annotation L..Bopomofo Final Letter H\n+        (0x031c0, 0x031e3,),  # Cjk Stroke T            ..Cjk Stroke Q\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03247,),  # Parenthesized Ideograph ..Circled Ideograph Koto\n+        (0x03250, 0x032fe,),  # Partnership Sign        ..Circled Katakana Wo\n+        (0x03300, 0x04dbf,),  # Square Apaato           ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x0a48c,),  # Cjk Unified Ideograph-4e..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0a960, 0x0a97c,),  # Hangul Choseong Tikeut-m..Hangul Choseong Ssangyeo\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0faff,),  # Cjk Compatibility Ideogr..(nil)\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x1f200, 0x1f200,),  # Square Hiragana Hoka\n+        (0x1f210, 0x1f231,),  # Squared Cjk Unified Ideo..Squared Cjk Unified Ideo\n+        (0x1f240, 0x1f248,),  # Tortoise Shell Bracketed..Tortoise Shell Bracketed\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '6.0.0': (\n+        # Source: EastAsianWidth-6.0.0.txt\n+        # Date: 2010-08-17, 12:17:00 PDT [KW]\n+        #\n+        (0x01100, 0x0115f,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Filler\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312d,),  # Bopomofo Letter B       ..Bopomofo Letter Ih\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031ba,),  # Ideographic Annotation L..Bopomofo Letter Zy\n+        (0x031c0, 0x031e3,),  # Cjk Stroke T            ..Cjk Stroke Q\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03247,),  # Parenthesized Ideograph ..Circled Ideograph Koto\n+        (0x03250, 0x032fe,),  # Partnership Sign        ..Circled Katakana Wo\n+        (0x03300, 0x04dbf,),  # Square Apaato           ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x0a48c,),  # Cjk Unified Ideograph-4e..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0a960, 0x0a97c,),  # Hangul Choseong Tikeut-m..Hangul Choseong Ssangyeo\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0faff,),  # Cjk Compatibility Ideogr..(nil)\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x1b000, 0x1b001,),  # Katakana Letter Archaic ..Hiragana Letter Archaic\n+        (0x1f200, 0x1f202,),  # Square Hiragana Hoka    ..Squared Katakana Sa\n+        (0x1f210, 0x1f23a,),  # Squared Cjk Unified Ideo..Squared Cjk Unified Ideo\n+        (0x1f240, 0x1f248,),  # Tortoise Shell Bracketed..Tortoise Shell Bracketed\n+        (0x1f250, 0x1f251,),  # Circled Ideograph Advant..Circled Ideograph Accept\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '6.1.0': (\n+        # Source: EastAsianWidth-6.1.0.txt\n+        # Date: 2011-09-19, 18:46:00 GMT [KW]\n+        #\n+        (0x01100, 0x0115f,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Filler\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312d,),  # Bopomofo Letter B       ..Bopomofo Letter Ih\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031ba,),  # Ideographic Annotation L..Bopomofo Letter Zy\n+        (0x031c0, 0x031e3,),  # Cjk Stroke T            ..Cjk Stroke Q\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03247,),  # Parenthesized Ideograph ..Circled Ideograph Koto\n+        (0x03250, 0x032fe,),  # Partnership Sign        ..Circled Katakana Wo\n+        (0x03300, 0x04dbf,),  # Square Apaato           ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x0a48c,),  # Cjk Unified Ideograph-4e..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0a960, 0x0a97c,),  # Hangul Choseong Tikeut-m..Hangul Choseong Ssangyeo\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0faff,),  # Cjk Compatibility Ideogr..(nil)\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x1b000, 0x1b001,),  # Katakana Letter Archaic ..Hiragana Letter Archaic\n+        (0x1f200, 0x1f202,),  # Square Hiragana Hoka    ..Squared Katakana Sa\n+        (0x1f210, 0x1f23a,),  # Squared Cjk Unified Ideo..Squared Cjk Unified Ideo\n+        (0x1f240, 0x1f248,),  # Tortoise Shell Bracketed..Tortoise Shell Bracketed\n+        (0x1f250, 0x1f251,),  # Circled Ideograph Advant..Circled Ideograph Accept\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '6.2.0': (\n+        # Source: EastAsianWidth-6.2.0.txt\n+        # Date: 2012-05-15, 18:30:00 GMT [KW]\n+        #\n+        (0x01100, 0x0115f,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Filler\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312d,),  # Bopomofo Letter B       ..Bopomofo Letter Ih\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031ba,),  # Ideographic Annotation L..Bopomofo Letter Zy\n+        (0x031c0, 0x031e3,),  # Cjk Stroke T            ..Cjk Stroke Q\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03247,),  # Parenthesized Ideograph ..Circled Ideograph Koto\n+        (0x03250, 0x032fe,),  # Partnership Sign        ..Circled Katakana Wo\n+        (0x03300, 0x04dbf,),  # Square Apaato           ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x0a48c,),  # Cjk Unified Ideograph-4e..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0a960, 0x0a97c,),  # Hangul Choseong Tikeut-m..Hangul Choseong Ssangyeo\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0faff,),  # Cjk Compatibility Ideogr..(nil)\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x1b000, 0x1b001,),  # Katakana Letter Archaic ..Hiragana Letter Archaic\n+        (0x1f200, 0x1f202,),  # Square Hiragana Hoka    ..Squared Katakana Sa\n+        (0x1f210, 0x1f23a,),  # Squared Cjk Unified Ideo..Squared Cjk Unified Ideo\n+        (0x1f240, 0x1f248,),  # Tortoise Shell Bracketed..Tortoise Shell Bracketed\n+        (0x1f250, 0x1f251,),  # Circled Ideograph Advant..Circled Ideograph Accept\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '6.3.0': (\n+        # Source: EastAsianWidth-6.3.0.txt\n+        # Date: 2013-02-05, 20:09:00 GMT [KW, LI]\n+        #\n+        (0x01100, 0x0115f,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Filler\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312d,),  # Bopomofo Letter B       ..Bopomofo Letter Ih\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031ba,),  # Ideographic Annotation L..Bopomofo Letter Zy\n+        (0x031c0, 0x031e3,),  # Cjk Stroke T            ..Cjk Stroke Q\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03247,),  # Parenthesized Ideograph ..Circled Ideograph Koto\n+        (0x03250, 0x032fe,),  # Partnership Sign        ..Circled Katakana Wo\n+        (0x03300, 0x04dbf,),  # Square Apaato           ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x0a48c,),  # Cjk Unified Ideograph-4e..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0a960, 0x0a97c,),  # Hangul Choseong Tikeut-m..Hangul Choseong Ssangyeo\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0faff,),  # Cjk Compatibility Ideogr..(nil)\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x1b000, 0x1b001,),  # Katakana Letter Archaic ..Hiragana Letter Archaic\n+        (0x1f200, 0x1f202,),  # Square Hiragana Hoka    ..Squared Katakana Sa\n+        (0x1f210, 0x1f23a,),  # Squared Cjk Unified Ideo..Squared Cjk Unified Ideo\n+        (0x1f240, 0x1f248,),  # Tortoise Shell Bracketed..Tortoise Shell Bracketed\n+        (0x1f250, 0x1f251,),  # Circled Ideograph Advant..Circled Ideograph Accept\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '7.0.0': (\n+        # Source: EastAsianWidth-7.0.0.txt\n+        # Date: 2014-02-28, 23:15:00 GMT [KW, LI]\n+        #\n+        (0x01100, 0x0115f,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Filler\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312d,),  # Bopomofo Letter B       ..Bopomofo Letter Ih\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031ba,),  # Ideographic Annotation L..Bopomofo Letter Zy\n+        (0x031c0, 0x031e3,),  # Cjk Stroke T            ..Cjk Stroke Q\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03247,),  # Parenthesized Ideograph ..Circled Ideograph Koto\n+        (0x03250, 0x032fe,),  # Partnership Sign        ..Circled Katakana Wo\n+        (0x03300, 0x04dbf,),  # Square Apaato           ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x0a48c,),  # Cjk Unified Ideograph-4e..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0a960, 0x0a97c,),  # Hangul Choseong Tikeut-m..Hangul Choseong Ssangyeo\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0faff,),  # Cjk Compatibility Ideogr..(nil)\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x1b000, 0x1b001,),  # Katakana Letter Archaic ..Hiragana Letter Archaic\n+        (0x1f200, 0x1f202,),  # Square Hiragana Hoka    ..Squared Katakana Sa\n+        (0x1f210, 0x1f23a,),  # Squared Cjk Unified Ideo..Squared Cjk Unified Ideo\n+        (0x1f240, 0x1f248,),  # Tortoise Shell Bracketed..Tortoise Shell Bracketed\n+        (0x1f250, 0x1f251,),  # Circled Ideograph Advant..Circled Ideograph Accept\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '8.0.0': (\n+        # Source: EastAsianWidth-8.0.0.txt\n+        # Date: 2015-02-10, 21:00:00 GMT [KW, LI]\n+        #\n+        (0x01100, 0x0115f,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Filler\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312d,),  # Bopomofo Letter B       ..Bopomofo Letter Ih\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031ba,),  # Ideographic Annotation L..Bopomofo Letter Zy\n+        (0x031c0, 0x031e3,),  # Cjk Stroke T            ..Cjk Stroke Q\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03247,),  # Parenthesized Ideograph ..Circled Ideograph Koto\n+        (0x03250, 0x032fe,),  # Partnership Sign        ..Circled Katakana Wo\n+        (0x03300, 0x04dbf,),  # Square Apaato           ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x0a48c,),  # Cjk Unified Ideograph-4e..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0a960, 0x0a97c,),  # Hangul Choseong Tikeut-m..Hangul Choseong Ssangyeo\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0faff,),  # Cjk Compatibility Ideogr..(nil)\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x1b000, 0x1b001,),  # Katakana Letter Archaic ..Hiragana Letter Archaic\n+        (0x1f200, 0x1f202,),  # Square Hiragana Hoka    ..Squared Katakana Sa\n+        (0x1f210, 0x1f23a,),  # Squared Cjk Unified Ideo..Squared Cjk Unified Ideo\n+        (0x1f240, 0x1f248,),  # Tortoise Shell Bracketed..Tortoise Shell Bracketed\n+        (0x1f250, 0x1f251,),  # Circled Ideograph Advant..Circled Ideograph Accept\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '9.0.0': (\n+        # Source: EastAsianWidth-9.0.0.txt\n+        # Date: 2016-05-27, 17:00:00 GMT [KW, LI]\n+        #\n+        (0x01100, 0x0115f,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Filler\n+        (0x0231a, 0x0231b,),  # Watch                   ..Hourglass\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x023e9, 0x023ec,),  # Black Right-pointing Dou..Black Down-pointing Doub\n+        (0x023f0, 0x023f0,),  # Alarm Clock\n+        (0x023f3, 0x023f3,),  # Hourglass With Flowing Sand\n+        (0x025fd, 0x025fe,),  # White Medium Small Squar..Black Medium Small Squar\n+        (0x02614, 0x02615,),  # Umbrella With Rain Drops..Hot Beverage\n+        (0x02648, 0x02653,),  # Aries                   ..Pisces\n+        (0x0267f, 0x0267f,),  # Wheelchair Symbol\n+        (0x02693, 0x02693,),  # Anchor\n+        (0x026a1, 0x026a1,),  # High Voltage Sign\n+        (0x026aa, 0x026ab,),  # Medium White Circle     ..Medium Black Circle\n+        (0x026bd, 0x026be,),  # Soccer Ball             ..Baseball\n+        (0x026c4, 0x026c5,),  # Snowman Without Snow    ..Sun Behind Cloud\n+        (0x026ce, 0x026ce,),  # Ophiuchus\n+        (0x026d4, 0x026d4,),  # No Entry\n+        (0x026ea, 0x026ea,),  # Church\n+        (0x026f2, 0x026f3,),  # Fountain                ..Flag In Hole\n+        (0x026f5, 0x026f5,),  # Sailboat\n+        (0x026fa, 0x026fa,),  # Tent\n+        (0x026fd, 0x026fd,),  # Fuel Pump\n+        (0x02705, 0x02705,),  # White Heavy Check Mark\n+        (0x0270a, 0x0270b,),  # Raised Fist             ..Raised Hand\n+        (0x02728, 0x02728,),  # Sparkles\n+        (0x0274c, 0x0274c,),  # Cross Mark\n+        (0x0274e, 0x0274e,),  # Negative Squared Cross Mark\n+        (0x02753, 0x02755,),  # Black Question Mark Orna..White Exclamation Mark O\n+        (0x02757, 0x02757,),  # Heavy Exclamation Mark Symbol\n+        (0x02795, 0x02797,),  # Heavy Plus Sign         ..Heavy Division Sign\n+        (0x027b0, 0x027b0,),  # Curly Loop\n+        (0x027bf, 0x027bf,),  # Double Curly Loop\n+        (0x02b1b, 0x02b1c,),  # Black Large Square      ..White Large Square\n+        (0x02b50, 0x02b50,),  # White Medium Star\n+        (0x02b55, 0x02b55,),  # Heavy Large Circle\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312d,),  # Bopomofo Letter B       ..Bopomofo Letter Ih\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031ba,),  # Ideographic Annotation L..Bopomofo Letter Zy\n+        (0x031c0, 0x031e3,),  # Cjk Stroke T            ..Cjk Stroke Q\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03247,),  # Parenthesized Ideograph ..Circled Ideograph Koto\n+        (0x03250, 0x032fe,),  # Partnership Sign        ..Circled Katakana Wo\n+        (0x03300, 0x04dbf,),  # Square Apaato           ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x0a48c,),  # Cjk Unified Ideograph-4e..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0a960, 0x0a97c,),  # Hangul Choseong Tikeut-m..Hangul Choseong Ssangyeo\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0faff,),  # Cjk Compatibility Ideogr..(nil)\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x16fe0, 0x16fe0,),  # Tangut Iteration Mark\n+        (0x17000, 0x187ec,),  # (nil)\n+        (0x18800, 0x18af2,),  # Tangut Component-001    ..Tangut Component-755\n+        (0x1b000, 0x1b001,),  # Katakana Letter Archaic ..Hiragana Letter Archaic\n+        (0x1f004, 0x1f004,),  # Mahjong Tile Red Dragon\n+        (0x1f0cf, 0x1f0cf,),  # Playing Card Black Joker\n+        (0x1f18e, 0x1f18e,),  # Negative Squared Ab\n+        (0x1f191, 0x1f19a,),  # Squared Cl              ..Squared Vs\n+        (0x1f200, 0x1f202,),  # Square Hiragana Hoka    ..Squared Katakana Sa\n+        (0x1f210, 0x1f23b,),  # Squared Cjk Unified Ideo..Squared Cjk Unified Ideo\n+        (0x1f240, 0x1f248,),  # Tortoise Shell Bracketed..Tortoise Shell Bracketed\n+        (0x1f250, 0x1f251,),  # Circled Ideograph Advant..Circled Ideograph Accept\n+        (0x1f300, 0x1f320,),  # Cyclone                 ..Shooting Star\n+        (0x1f32d, 0x1f335,),  # Hot Dog                 ..Cactus\n+        (0x1f337, 0x1f37c,),  # Tulip                   ..Baby Bottle\n+        (0x1f37e, 0x1f393,),  # Bottle With Popping Cork..Graduation Cap\n+        (0x1f3a0, 0x1f3ca,),  # Carousel Horse          ..Swimmer\n+        (0x1f3cf, 0x1f3d3,),  # Cricket Bat And Ball    ..Table Tennis Paddle And\n+        (0x1f3e0, 0x1f3f0,),  # House Building          ..European Castle\n+        (0x1f3f4, 0x1f3f4,),  # Waving Black Flag\n+        (0x1f3f8, 0x1f3fa,),  # Badminton Racquet And Sh..Amphora\n+        (0x1f400, 0x1f43e,),  # Rat                     ..Paw Prints\n+        (0x1f440, 0x1f440,),  # Eyes\n+        (0x1f442, 0x1f4fc,),  # Ear                     ..Videocassette\n+        (0x1f4ff, 0x1f53d,),  # Prayer Beads            ..Down-pointing Small Red\n+        (0x1f54b, 0x1f54e,),  # Kaaba                   ..Menorah With Nine Branch\n+        (0x1f550, 0x1f567,),  # Clock Face One Oclock   ..Clock Face Twelve-thirty\n+        (0x1f57a, 0x1f57a,),  # Man Dancing\n+        (0x1f595, 0x1f596,),  # Reversed Hand With Middl..Raised Hand With Part Be\n+        (0x1f5a4, 0x1f5a4,),  # Black Heart\n+        (0x1f5fb, 0x1f64f,),  # Mount Fuji              ..Person With Folded Hands\n+        (0x1f680, 0x1f6c5,),  # Rocket                  ..Left Luggage\n+        (0x1f6cc, 0x1f6cc,),  # Sleeping Accommodation\n+        (0x1f6d0, 0x1f6d2,),  # Place Of Worship        ..Shopping Trolley\n+        (0x1f6eb, 0x1f6ec,),  # Airplane Departure      ..Airplane Arriving\n+        (0x1f6f4, 0x1f6f6,),  # Scooter                 ..Canoe\n+        (0x1f910, 0x1f91e,),  # Zipper-mouth Face       ..Hand With Index And Midd\n+        (0x1f920, 0x1f927,),  # Face With Cowboy Hat    ..Sneezing Face\n+        (0x1f930, 0x1f930,),  # Pregnant Woman\n+        (0x1f933, 0x1f93e,),  # Selfie                  ..Handball\n+        (0x1f940, 0x1f94b,),  # Wilted Flower           ..Martial Arts Uniform\n+        (0x1f950, 0x1f95e,),  # Croissant               ..Pancakes\n+        (0x1f980, 0x1f991,),  # Crab                    ..Squid\n+        (0x1f9c0, 0x1f9c0,),  # Cheese Wedge\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '10.0.0': (\n+        # Source: EastAsianWidth-10.0.0.txt\n+        # Date: 2017-03-08, 02:00:00 GMT [KW, LI]\n+        #\n+        (0x01100, 0x0115f,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Filler\n+        (0x0231a, 0x0231b,),  # Watch                   ..Hourglass\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x023e9, 0x023ec,),  # Black Right-pointing Dou..Black Down-pointing Doub\n+        (0x023f0, 0x023f0,),  # Alarm Clock\n+        (0x023f3, 0x023f3,),  # Hourglass With Flowing Sand\n+        (0x025fd, 0x025fe,),  # White Medium Small Squar..Black Medium Small Squar\n+        (0x02614, 0x02615,),  # Umbrella With Rain Drops..Hot Beverage\n+        (0x02648, 0x02653,),  # Aries                   ..Pisces\n+        (0x0267f, 0x0267f,),  # Wheelchair Symbol\n+        (0x02693, 0x02693,),  # Anchor\n+        (0x026a1, 0x026a1,),  # High Voltage Sign\n+        (0x026aa, 0x026ab,),  # Medium White Circle     ..Medium Black Circle\n+        (0x026bd, 0x026be,),  # Soccer Ball             ..Baseball\n+        (0x026c4, 0x026c5,),  # Snowman Without Snow    ..Sun Behind Cloud\n+        (0x026ce, 0x026ce,),  # Ophiuchus\n+        (0x026d4, 0x026d4,),  # No Entry\n+        (0x026ea, 0x026ea,),  # Church\n+        (0x026f2, 0x026f3,),  # Fountain                ..Flag In Hole\n+        (0x026f5, 0x026f5,),  # Sailboat\n+        (0x026fa, 0x026fa,),  # Tent\n+        (0x026fd, 0x026fd,),  # Fuel Pump\n+        (0x02705, 0x02705,),  # White Heavy Check Mark\n+        (0x0270a, 0x0270b,),  # Raised Fist             ..Raised Hand\n+        (0x02728, 0x02728,),  # Sparkles\n+        (0x0274c, 0x0274c,),  # Cross Mark\n+        (0x0274e, 0x0274e,),  # Negative Squared Cross Mark\n+        (0x02753, 0x02755,),  # Black Question Mark Orna..White Exclamation Mark O\n+        (0x02757, 0x02757,),  # Heavy Exclamation Mark Symbol\n+        (0x02795, 0x02797,),  # Heavy Plus Sign         ..Heavy Division Sign\n+        (0x027b0, 0x027b0,),  # Curly Loop\n+        (0x027bf, 0x027bf,),  # Double Curly Loop\n+        (0x02b1b, 0x02b1c,),  # Black Large Square      ..White Large Square\n+        (0x02b50, 0x02b50,),  # White Medium Star\n+        (0x02b55, 0x02b55,),  # Heavy Large Circle\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312e,),  # Bopomofo Letter B       ..Bopomofo Letter O With D\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031ba,),  # Ideographic Annotation L..Bopomofo Letter Zy\n+        (0x031c0, 0x031e3,),  # Cjk Stroke T            ..Cjk Stroke Q\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03247,),  # Parenthesized Ideograph ..Circled Ideograph Koto\n+        (0x03250, 0x032fe,),  # Partnership Sign        ..Circled Katakana Wo\n+        (0x03300, 0x04dbf,),  # Square Apaato           ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x0a48c,),  # Cjk Unified Ideograph-4e..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0a960, 0x0a97c,),  # Hangul Choseong Tikeut-m..Hangul Choseong Ssangyeo\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0faff,),  # Cjk Compatibility Ideogr..(nil)\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x16fe0, 0x16fe1,),  # Tangut Iteration Mark   ..Nushu Iteration Mark\n+        (0x17000, 0x187ec,),  # (nil)\n+        (0x18800, 0x18af2,),  # Tangut Component-001    ..Tangut Component-755\n+        (0x1b000, 0x1b11e,),  # Katakana Letter Archaic ..Hentaigana Letter N-mu-m\n+        (0x1b170, 0x1b2fb,),  # Nushu Character-1b170   ..Nushu Character-1b2fb\n+        (0x1f004, 0x1f004,),  # Mahjong Tile Red Dragon\n+        (0x1f0cf, 0x1f0cf,),  # Playing Card Black Joker\n+        (0x1f18e, 0x1f18e,),  # Negative Squared Ab\n+        (0x1f191, 0x1f19a,),  # Squared Cl              ..Squared Vs\n+        (0x1f200, 0x1f202,),  # Square Hiragana Hoka    ..Squared Katakana Sa\n+        (0x1f210, 0x1f23b,),  # Squared Cjk Unified Ideo..Squared Cjk Unified Ideo\n+        (0x1f240, 0x1f248,),  # Tortoise Shell Bracketed..Tortoise Shell Bracketed\n+        (0x1f250, 0x1f251,),  # Circled Ideograph Advant..Circled Ideograph Accept\n+        (0x1f260, 0x1f265,),  # Rounded Symbol For Fu   ..Rounded Symbol For Cai\n+        (0x1f300, 0x1f320,),  # Cyclone                 ..Shooting Star\n+        (0x1f32d, 0x1f335,),  # Hot Dog                 ..Cactus\n+        (0x1f337, 0x1f37c,),  # Tulip                   ..Baby Bottle\n+        (0x1f37e, 0x1f393,),  # Bottle With Popping Cork..Graduation Cap\n+        (0x1f3a0, 0x1f3ca,),  # Carousel Horse          ..Swimmer\n+        (0x1f3cf, 0x1f3d3,),  # Cricket Bat And Ball    ..Table Tennis Paddle And\n+        (0x1f3e0, 0x1f3f0,),  # House Building          ..European Castle\n+        (0x1f3f4, 0x1f3f4,),  # Waving Black Flag\n+        (0x1f3f8, 0x1f3fa,),  # Badminton Racquet And Sh..Amphora\n+        (0x1f400, 0x1f43e,),  # Rat                     ..Paw Prints\n+        (0x1f440, 0x1f440,),  # Eyes\n+        (0x1f442, 0x1f4fc,),  # Ear                     ..Videocassette\n+        (0x1f4ff, 0x1f53d,),  # Prayer Beads            ..Down-pointing Small Red\n+        (0x1f54b, 0x1f54e,),  # Kaaba                   ..Menorah With Nine Branch\n+        (0x1f550, 0x1f567,),  # Clock Face One Oclock   ..Clock Face Twelve-thirty\n+        (0x1f57a, 0x1f57a,),  # Man Dancing\n+        (0x1f595, 0x1f596,),  # Reversed Hand With Middl..Raised Hand With Part Be\n+        (0x1f5a4, 0x1f5a4,),  # Black Heart\n+        (0x1f5fb, 0x1f64f,),  # Mount Fuji              ..Person With Folded Hands\n+        (0x1f680, 0x1f6c5,),  # Rocket                  ..Left Luggage\n+        (0x1f6cc, 0x1f6cc,),  # Sleeping Accommodation\n+        (0x1f6d0, 0x1f6d2,),  # Place Of Worship        ..Shopping Trolley\n+        (0x1f6eb, 0x1f6ec,),  # Airplane Departure      ..Airplane Arriving\n+        (0x1f6f4, 0x1f6f8,),  # Scooter                 ..Flying Saucer\n+        (0x1f910, 0x1f93e,),  # Zipper-mouth Face       ..Handball\n+        (0x1f940, 0x1f94c,),  # Wilted Flower           ..Curling Stone\n+        (0x1f950, 0x1f96b,),  # Croissant               ..Canned Food\n+        (0x1f980, 0x1f997,),  # Crab                    ..Cricket\n+        (0x1f9c0, 0x1f9c0,),  # Cheese Wedge\n+        (0x1f9d0, 0x1f9e6,),  # Face With Monocle       ..Socks\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '11.0.0': (\n+        # Source: EastAsianWidth-11.0.0.txt\n+        # Date: 2018-05-14, 09:41:59 GMT [KW, LI]\n+        #\n+        (0x01100, 0x0115f,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Filler\n+        (0x0231a, 0x0231b,),  # Watch                   ..Hourglass\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x023e9, 0x023ec,),  # Black Right-pointing Dou..Black Down-pointing Doub\n+        (0x023f0, 0x023f0,),  # Alarm Clock\n+        (0x023f3, 0x023f3,),  # Hourglass With Flowing Sand\n+        (0x025fd, 0x025fe,),  # White Medium Small Squar..Black Medium Small Squar\n+        (0x02614, 0x02615,),  # Umbrella With Rain Drops..Hot Beverage\n+        (0x02648, 0x02653,),  # Aries                   ..Pisces\n+        (0x0267f, 0x0267f,),  # Wheelchair Symbol\n+        (0x02693, 0x02693,),  # Anchor\n+        (0x026a1, 0x026a1,),  # High Voltage Sign\n+        (0x026aa, 0x026ab,),  # Medium White Circle     ..Medium Black Circle\n+        (0x026bd, 0x026be,),  # Soccer Ball             ..Baseball\n+        (0x026c4, 0x026c5,),  # Snowman Without Snow    ..Sun Behind Cloud\n+        (0x026ce, 0x026ce,),  # Ophiuchus\n+        (0x026d4, 0x026d4,),  # No Entry\n+        (0x026ea, 0x026ea,),  # Church\n+        (0x026f2, 0x026f3,),  # Fountain                ..Flag In Hole\n+        (0x026f5, 0x026f5,),  # Sailboat\n+        (0x026fa, 0x026fa,),  # Tent\n+        (0x026fd, 0x026fd,),  # Fuel Pump\n+        (0x02705, 0x02705,),  # White Heavy Check Mark\n+        (0x0270a, 0x0270b,),  # Raised Fist             ..Raised Hand\n+        (0x02728, 0x02728,),  # Sparkles\n+        (0x0274c, 0x0274c,),  # Cross Mark\n+        (0x0274e, 0x0274e,),  # Negative Squared Cross Mark\n+        (0x02753, 0x02755,),  # Black Question Mark Orna..White Exclamation Mark O\n+        (0x02757, 0x02757,),  # Heavy Exclamation Mark Symbol\n+        (0x02795, 0x02797,),  # Heavy Plus Sign         ..Heavy Division Sign\n+        (0x027b0, 0x027b0,),  # Curly Loop\n+        (0x027bf, 0x027bf,),  # Double Curly Loop\n+        (0x02b1b, 0x02b1c,),  # Black Large Square      ..White Large Square\n+        (0x02b50, 0x02b50,),  # White Medium Star\n+        (0x02b55, 0x02b55,),  # Heavy Large Circle\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312f,),  # Bopomofo Letter B       ..Bopomofo Letter Nn\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031ba,),  # Ideographic Annotation L..Bopomofo Letter Zy\n+        (0x031c0, 0x031e3,),  # Cjk Stroke T            ..Cjk Stroke Q\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03247,),  # Parenthesized Ideograph ..Circled Ideograph Koto\n+        (0x03250, 0x032fe,),  # Partnership Sign        ..Circled Katakana Wo\n+        (0x03300, 0x04dbf,),  # Square Apaato           ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x0a48c,),  # Cjk Unified Ideograph-4e..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0a960, 0x0a97c,),  # Hangul Choseong Tikeut-m..Hangul Choseong Ssangyeo\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0faff,),  # Cjk Compatibility Ideogr..(nil)\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x16fe0, 0x16fe1,),  # Tangut Iteration Mark   ..Nushu Iteration Mark\n+        (0x17000, 0x187f1,),  # (nil)\n+        (0x18800, 0x18af2,),  # Tangut Component-001    ..Tangut Component-755\n+        (0x1b000, 0x1b11e,),  # Katakana Letter Archaic ..Hentaigana Letter N-mu-m\n+        (0x1b170, 0x1b2fb,),  # Nushu Character-1b170   ..Nushu Character-1b2fb\n+        (0x1f004, 0x1f004,),  # Mahjong Tile Red Dragon\n+        (0x1f0cf, 0x1f0cf,),  # Playing Card Black Joker\n+        (0x1f18e, 0x1f18e,),  # Negative Squared Ab\n+        (0x1f191, 0x1f19a,),  # Squared Cl              ..Squared Vs\n+        (0x1f200, 0x1f202,),  # Square Hiragana Hoka    ..Squared Katakana Sa\n+        (0x1f210, 0x1f23b,),  # Squared Cjk Unified Ideo..Squared Cjk Unified Ideo\n+        (0x1f240, 0x1f248,),  # Tortoise Shell Bracketed..Tortoise Shell Bracketed\n+        (0x1f250, 0x1f251,),  # Circled Ideograph Advant..Circled Ideograph Accept\n+        (0x1f260, 0x1f265,),  # Rounded Symbol For Fu   ..Rounded Symbol For Cai\n+        (0x1f300, 0x1f320,),  # Cyclone                 ..Shooting Star\n+        (0x1f32d, 0x1f335,),  # Hot Dog                 ..Cactus\n+        (0x1f337, 0x1f37c,),  # Tulip                   ..Baby Bottle\n+        (0x1f37e, 0x1f393,),  # Bottle With Popping Cork..Graduation Cap\n+        (0x1f3a0, 0x1f3ca,),  # Carousel Horse          ..Swimmer\n+        (0x1f3cf, 0x1f3d3,),  # Cricket Bat And Ball    ..Table Tennis Paddle And\n+        (0x1f3e0, 0x1f3f0,),  # House Building          ..European Castle\n+        (0x1f3f4, 0x1f3f4,),  # Waving Black Flag\n+        (0x1f3f8, 0x1f3fa,),  # Badminton Racquet And Sh..Amphora\n+        (0x1f400, 0x1f43e,),  # Rat                     ..Paw Prints\n+        (0x1f440, 0x1f440,),  # Eyes\n+        (0x1f442, 0x1f4fc,),  # Ear                     ..Videocassette\n+        (0x1f4ff, 0x1f53d,),  # Prayer Beads            ..Down-pointing Small Red\n+        (0x1f54b, 0x1f54e,),  # Kaaba                   ..Menorah With Nine Branch\n+        (0x1f550, 0x1f567,),  # Clock Face One Oclock   ..Clock Face Twelve-thirty\n+        (0x1f57a, 0x1f57a,),  # Man Dancing\n+        (0x1f595, 0x1f596,),  # Reversed Hand With Middl..Raised Hand With Part Be\n+        (0x1f5a4, 0x1f5a4,),  # Black Heart\n+        (0x1f5fb, 0x1f64f,),  # Mount Fuji              ..Person With Folded Hands\n+        (0x1f680, 0x1f6c5,),  # Rocket                  ..Left Luggage\n+        (0x1f6cc, 0x1f6cc,),  # Sleeping Accommodation\n+        (0x1f6d0, 0x1f6d2,),  # Place Of Worship        ..Shopping Trolley\n+        (0x1f6eb, 0x1f6ec,),  # Airplane Departure      ..Airplane Arriving\n+        (0x1f6f4, 0x1f6f9,),  # Scooter                 ..Skateboard\n+        (0x1f910, 0x1f93e,),  # Zipper-mouth Face       ..Handball\n+        (0x1f940, 0x1f970,),  # Wilted Flower           ..Smiling Face With Smilin\n+        (0x1f973, 0x1f976,),  # Face With Party Horn And..Freezing Face\n+        (0x1f97a, 0x1f97a,),  # Face With Pleading Eyes\n+        (0x1f97c, 0x1f9a2,),  # Lab Coat                ..Swan\n+        (0x1f9b0, 0x1f9b9,),  # Emoji Component Red Hair..Supervillain\n+        (0x1f9c0, 0x1f9c2,),  # Cheese Wedge            ..Salt Shaker\n+        (0x1f9d0, 0x1f9ff,),  # Face With Monocle       ..Nazar Amulet\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '12.0.0': (\n+        # Source: EastAsianWidth-12.0.0.txt\n+        # Date: 2019-01-21, 14:12:58 GMT [KW, LI]\n+        #\n+        (0x01100, 0x0115f,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Filler\n+        (0x0231a, 0x0231b,),  # Watch                   ..Hourglass\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x023e9, 0x023ec,),  # Black Right-pointing Dou..Black Down-pointing Doub\n+        (0x023f0, 0x023f0,),  # Alarm Clock\n+        (0x023f3, 0x023f3,),  # Hourglass With Flowing Sand\n+        (0x025fd, 0x025fe,),  # White Medium Small Squar..Black Medium Small Squar\n+        (0x02614, 0x02615,),  # Umbrella With Rain Drops..Hot Beverage\n+        (0x02648, 0x02653,),  # Aries                   ..Pisces\n+        (0x0267f, 0x0267f,),  # Wheelchair Symbol\n+        (0x02693, 0x02693,),  # Anchor\n+        (0x026a1, 0x026a1,),  # High Voltage Sign\n+        (0x026aa, 0x026ab,),  # Medium White Circle     ..Medium Black Circle\n+        (0x026bd, 0x026be,),  # Soccer Ball             ..Baseball\n+        (0x026c4, 0x026c5,),  # Snowman Without Snow    ..Sun Behind Cloud\n+        (0x026ce, 0x026ce,),  # Ophiuchus\n+        (0x026d4, 0x026d4,),  # No Entry\n+        (0x026ea, 0x026ea,),  # Church\n+        (0x026f2, 0x026f3,),  # Fountain                ..Flag In Hole\n+        (0x026f5, 0x026f5,),  # Sailboat\n+        (0x026fa, 0x026fa,),  # Tent\n+        (0x026fd, 0x026fd,),  # Fuel Pump\n+        (0x02705, 0x02705,),  # White Heavy Check Mark\n+        (0x0270a, 0x0270b,),  # Raised Fist             ..Raised Hand\n+        (0x02728, 0x02728,),  # Sparkles\n+        (0x0274c, 0x0274c,),  # Cross Mark\n+        (0x0274e, 0x0274e,),  # Negative Squared Cross Mark\n+        (0x02753, 0x02755,),  # Black Question Mark Orna..White Exclamation Mark O\n+        (0x02757, 0x02757,),  # Heavy Exclamation Mark Symbol\n+        (0x02795, 0x02797,),  # Heavy Plus Sign         ..Heavy Division Sign\n+        (0x027b0, 0x027b0,),  # Curly Loop\n+        (0x027bf, 0x027bf,),  # Double Curly Loop\n+        (0x02b1b, 0x02b1c,),  # Black Large Square      ..White Large Square\n+        (0x02b50, 0x02b50,),  # White Medium Star\n+        (0x02b55, 0x02b55,),  # Heavy Large Circle\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312f,),  # Bopomofo Letter B       ..Bopomofo Letter Nn\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031ba,),  # Ideographic Annotation L..Bopomofo Letter Zy\n+        (0x031c0, 0x031e3,),  # Cjk Stroke T            ..Cjk Stroke Q\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03247,),  # Parenthesized Ideograph ..Circled Ideograph Koto\n+        (0x03250, 0x032fe,),  # Partnership Sign        ..Circled Katakana Wo\n+        (0x03300, 0x04dbf,),  # Square Apaato           ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x0a48c,),  # Cjk Unified Ideograph-4e..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0a960, 0x0a97c,),  # Hangul Choseong Tikeut-m..Hangul Choseong Ssangyeo\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0faff,),  # Cjk Compatibility Ideogr..(nil)\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x16fe0, 0x16fe3,),  # Tangut Iteration Mark   ..Old Chinese Iteration Ma\n+        (0x17000, 0x187f7,),  # (nil)\n+        (0x18800, 0x18af2,),  # Tangut Component-001    ..Tangut Component-755\n+        (0x1b000, 0x1b11e,),  # Katakana Letter Archaic ..Hentaigana Letter N-mu-m\n+        (0x1b150, 0x1b152,),  # Hiragana Letter Small Wi..Hiragana Letter Small Wo\n+        (0x1b164, 0x1b167,),  # Katakana Letter Small Wi..Katakana Letter Small N\n+        (0x1b170, 0x1b2fb,),  # Nushu Character-1b170   ..Nushu Character-1b2fb\n+        (0x1f004, 0x1f004,),  # Mahjong Tile Red Dragon\n+        (0x1f0cf, 0x1f0cf,),  # Playing Card Black Joker\n+        (0x1f18e, 0x1f18e,),  # Negative Squared Ab\n+        (0x1f191, 0x1f19a,),  # Squared Cl              ..Squared Vs\n+        (0x1f200, 0x1f202,),  # Square Hiragana Hoka    ..Squared Katakana Sa\n+        (0x1f210, 0x1f23b,),  # Squared Cjk Unified Ideo..Squared Cjk Unified Ideo\n+        (0x1f240, 0x1f248,),  # Tortoise Shell Bracketed..Tortoise Shell Bracketed\n+        (0x1f250, 0x1f251,),  # Circled Ideograph Advant..Circled Ideograph Accept\n+        (0x1f260, 0x1f265,),  # Rounded Symbol For Fu   ..Rounded Symbol For Cai\n+        (0x1f300, 0x1f320,),  # Cyclone                 ..Shooting Star\n+        (0x1f32d, 0x1f335,),  # Hot Dog                 ..Cactus\n+        (0x1f337, 0x1f37c,),  # Tulip                   ..Baby Bottle\n+        (0x1f37e, 0x1f393,),  # Bottle With Popping Cork..Graduation Cap\n+        (0x1f3a0, 0x1f3ca,),  # Carousel Horse          ..Swimmer\n+        (0x1f3cf, 0x1f3d3,),  # Cricket Bat And Ball    ..Table Tennis Paddle And\n+        (0x1f3e0, 0x1f3f0,),  # House Building          ..European Castle\n+        (0x1f3f4, 0x1f3f4,),  # Waving Black Flag\n+        (0x1f3f8, 0x1f3fa,),  # Badminton Racquet And Sh..Amphora\n+        (0x1f400, 0x1f43e,),  # Rat                     ..Paw Prints\n+        (0x1f440, 0x1f440,),  # Eyes\n+        (0x1f442, 0x1f4fc,),  # Ear                     ..Videocassette\n+        (0x1f4ff, 0x1f53d,),  # Prayer Beads            ..Down-pointing Small Red\n+        (0x1f54b, 0x1f54e,),  # Kaaba                   ..Menorah With Nine Branch\n+        (0x1f550, 0x1f567,),  # Clock Face One Oclock   ..Clock Face Twelve-thirty\n+        (0x1f57a, 0x1f57a,),  # Man Dancing\n+        (0x1f595, 0x1f596,),  # Reversed Hand With Middl..Raised Hand With Part Be\n+        (0x1f5a4, 0x1f5a4,),  # Black Heart\n+        (0x1f5fb, 0x1f64f,),  # Mount Fuji              ..Person With Folded Hands\n+        (0x1f680, 0x1f6c5,),  # Rocket                  ..Left Luggage\n+        (0x1f6cc, 0x1f6cc,),  # Sleeping Accommodation\n+        (0x1f6d0, 0x1f6d2,),  # Place Of Worship        ..Shopping Trolley\n+        (0x1f6d5, 0x1f6d5,),  # Hindu Temple\n+        (0x1f6eb, 0x1f6ec,),  # Airplane Departure      ..Airplane Arriving\n+        (0x1f6f4, 0x1f6fa,),  # Scooter                 ..Auto Rickshaw\n+        (0x1f7e0, 0x1f7eb,),  # Large Orange Circle     ..Large Brown Square\n+        (0x1f90d, 0x1f971,),  # White Heart             ..Yawning Face\n+        (0x1f973, 0x1f976,),  # Face With Party Horn And..Freezing Face\n+        (0x1f97a, 0x1f9a2,),  # Face With Pleading Eyes ..Swan\n+        (0x1f9a5, 0x1f9aa,),  # Sloth                   ..Oyster\n+        (0x1f9ae, 0x1f9ca,),  # Guide Dog               ..Ice Cube\n+        (0x1f9cd, 0x1f9ff,),  # Standing Person         ..Nazar Amulet\n+        (0x1fa70, 0x1fa73,),  # Ballet Shoes            ..Shorts\n+        (0x1fa78, 0x1fa7a,),  # Drop Of Blood           ..Stethoscope\n+        (0x1fa80, 0x1fa82,),  # Yo-yo                   ..Parachute\n+        (0x1fa90, 0x1fa95,),  # Ringed Planet           ..Banjo\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '12.1.0': (\n+        # Source: EastAsianWidth-12.1.0.txt\n+        # Date: 2019-03-31, 22:01:58 GMT [KW, LI]\n+        #\n+        (0x01100, 0x0115f,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Filler\n+        (0x0231a, 0x0231b,),  # Watch                   ..Hourglass\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x023e9, 0x023ec,),  # Black Right-pointing Dou..Black Down-pointing Doub\n+        (0x023f0, 0x023f0,),  # Alarm Clock\n+        (0x023f3, 0x023f3,),  # Hourglass With Flowing Sand\n+        (0x025fd, 0x025fe,),  # White Medium Small Squar..Black Medium Small Squar\n+        (0x02614, 0x02615,),  # Umbrella With Rain Drops..Hot Beverage\n+        (0x02648, 0x02653,),  # Aries                   ..Pisces\n+        (0x0267f, 0x0267f,),  # Wheelchair Symbol\n+        (0x02693, 0x02693,),  # Anchor\n+        (0x026a1, 0x026a1,),  # High Voltage Sign\n+        (0x026aa, 0x026ab,),  # Medium White Circle     ..Medium Black Circle\n+        (0x026bd, 0x026be,),  # Soccer Ball             ..Baseball\n+        (0x026c4, 0x026c5,),  # Snowman Without Snow    ..Sun Behind Cloud\n+        (0x026ce, 0x026ce,),  # Ophiuchus\n+        (0x026d4, 0x026d4,),  # No Entry\n+        (0x026ea, 0x026ea,),  # Church\n+        (0x026f2, 0x026f3,),  # Fountain                ..Flag In Hole\n+        (0x026f5, 0x026f5,),  # Sailboat\n+        (0x026fa, 0x026fa,),  # Tent\n+        (0x026fd, 0x026fd,),  # Fuel Pump\n+        (0x02705, 0x02705,),  # White Heavy Check Mark\n+        (0x0270a, 0x0270b,),  # Raised Fist             ..Raised Hand\n+        (0x02728, 0x02728,),  # Sparkles\n+        (0x0274c, 0x0274c,),  # Cross Mark\n+        (0x0274e, 0x0274e,),  # Negative Squared Cross Mark\n+        (0x02753, 0x02755,),  # Black Question Mark Orna..White Exclamation Mark O\n+        (0x02757, 0x02757,),  # Heavy Exclamation Mark Symbol\n+        (0x02795, 0x02797,),  # Heavy Plus Sign         ..Heavy Division Sign\n+        (0x027b0, 0x027b0,),  # Curly Loop\n+        (0x027bf, 0x027bf,),  # Double Curly Loop\n+        (0x02b1b, 0x02b1c,),  # Black Large Square      ..White Large Square\n+        (0x02b50, 0x02b50,),  # White Medium Star\n+        (0x02b55, 0x02b55,),  # Heavy Large Circle\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312f,),  # Bopomofo Letter B       ..Bopomofo Letter Nn\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031ba,),  # Ideographic Annotation L..Bopomofo Letter Zy\n+        (0x031c0, 0x031e3,),  # Cjk Stroke T            ..Cjk Stroke Q\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03247,),  # Parenthesized Ideograph ..Circled Ideograph Koto\n+        (0x03250, 0x04dbf,),  # Partnership Sign        ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x0a48c,),  # Cjk Unified Ideograph-4e..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0a960, 0x0a97c,),  # Hangul Choseong Tikeut-m..Hangul Choseong Ssangyeo\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0faff,),  # Cjk Compatibility Ideogr..(nil)\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x16fe0, 0x16fe3,),  # Tangut Iteration Mark   ..Old Chinese Iteration Ma\n+        (0x17000, 0x187f7,),  # (nil)\n+        (0x18800, 0x18af2,),  # Tangut Component-001    ..Tangut Component-755\n+        (0x1b000, 0x1b11e,),  # Katakana Letter Archaic ..Hentaigana Letter N-mu-m\n+        (0x1b150, 0x1b152,),  # Hiragana Letter Small Wi..Hiragana Letter Small Wo\n+        (0x1b164, 0x1b167,),  # Katakana Letter Small Wi..Katakana Letter Small N\n+        (0x1b170, 0x1b2fb,),  # Nushu Character-1b170   ..Nushu Character-1b2fb\n+        (0x1f004, 0x1f004,),  # Mahjong Tile Red Dragon\n+        (0x1f0cf, 0x1f0cf,),  # Playing Card Black Joker\n+        (0x1f18e, 0x1f18e,),  # Negative Squared Ab\n+        (0x1f191, 0x1f19a,),  # Squared Cl              ..Squared Vs\n+        (0x1f200, 0x1f202,),  # Square Hiragana Hoka    ..Squared Katakana Sa\n+        (0x1f210, 0x1f23b,),  # Squared Cjk Unified Ideo..Squared Cjk Unified Ideo\n+        (0x1f240, 0x1f248,),  # Tortoise Shell Bracketed..Tortoise Shell Bracketed\n+        (0x1f250, 0x1f251,),  # Circled Ideograph Advant..Circled Ideograph Accept\n+        (0x1f260, 0x1f265,),  # Rounded Symbol For Fu   ..Rounded Symbol For Cai\n+        (0x1f300, 0x1f320,),  # Cyclone                 ..Shooting Star\n+        (0x1f32d, 0x1f335,),  # Hot Dog                 ..Cactus\n+        (0x1f337, 0x1f37c,),  # Tulip                   ..Baby Bottle\n+        (0x1f37e, 0x1f393,),  # Bottle With Popping Cork..Graduation Cap\n+        (0x1f3a0, 0x1f3ca,),  # Carousel Horse          ..Swimmer\n+        (0x1f3cf, 0x1f3d3,),  # Cricket Bat And Ball    ..Table Tennis Paddle And\n+        (0x1f3e0, 0x1f3f0,),  # House Building          ..European Castle\n+        (0x1f3f4, 0x1f3f4,),  # Waving Black Flag\n+        (0x1f3f8, 0x1f3fa,),  # Badminton Racquet And Sh..Amphora\n+        (0x1f400, 0x1f43e,),  # Rat                     ..Paw Prints\n+        (0x1f440, 0x1f440,),  # Eyes\n+        (0x1f442, 0x1f4fc,),  # Ear                     ..Videocassette\n+        (0x1f4ff, 0x1f53d,),  # Prayer Beads            ..Down-pointing Small Red\n+        (0x1f54b, 0x1f54e,),  # Kaaba                   ..Menorah With Nine Branch\n+        (0x1f550, 0x1f567,),  # Clock Face One Oclock   ..Clock Face Twelve-thirty\n+        (0x1f57a, 0x1f57a,),  # Man Dancing\n+        (0x1f595, 0x1f596,),  # Reversed Hand With Middl..Raised Hand With Part Be\n+        (0x1f5a4, 0x1f5a4,),  # Black Heart\n+        (0x1f5fb, 0x1f64f,),  # Mount Fuji              ..Person With Folded Hands\n+        (0x1f680, 0x1f6c5,),  # Rocket                  ..Left Luggage\n+        (0x1f6cc, 0x1f6cc,),  # Sleeping Accommodation\n+        (0x1f6d0, 0x1f6d2,),  # Place Of Worship        ..Shopping Trolley\n+        (0x1f6d5, 0x1f6d5,),  # Hindu Temple\n+        (0x1f6eb, 0x1f6ec,),  # Airplane Departure      ..Airplane Arriving\n+        (0x1f6f4, 0x1f6fa,),  # Scooter                 ..Auto Rickshaw\n+        (0x1f7e0, 0x1f7eb,),  # Large Orange Circle     ..Large Brown Square\n+        (0x1f90d, 0x1f971,),  # White Heart             ..Yawning Face\n+        (0x1f973, 0x1f976,),  # Face With Party Horn And..Freezing Face\n+        (0x1f97a, 0x1f9a2,),  # Face With Pleading Eyes ..Swan\n+        (0x1f9a5, 0x1f9aa,),  # Sloth                   ..Oyster\n+        (0x1f9ae, 0x1f9ca,),  # Guide Dog               ..Ice Cube\n+        (0x1f9cd, 0x1f9ff,),  # Standing Person         ..Nazar Amulet\n+        (0x1fa70, 0x1fa73,),  # Ballet Shoes            ..Shorts\n+        (0x1fa78, 0x1fa7a,),  # Drop Of Blood           ..Stethoscope\n+        (0x1fa80, 0x1fa82,),  # Yo-yo                   ..Parachute\n+        (0x1fa90, 0x1fa95,),  # Ringed Planet           ..Banjo\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '13.0.0': (\n+        # Source: EastAsianWidth-13.0.0.txt\n+        # Date: 2029-01-21, 18:14:00 GMT [KW, LI]\n+        #\n+        (0x01100, 0x0115f,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Filler\n+        (0x0231a, 0x0231b,),  # Watch                   ..Hourglass\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x023e9, 0x023ec,),  # Black Right-pointing Dou..Black Down-pointing Doub\n+        (0x023f0, 0x023f0,),  # Alarm Clock\n+        (0x023f3, 0x023f3,),  # Hourglass With Flowing Sand\n+        (0x025fd, 0x025fe,),  # White Medium Small Squar..Black Medium Small Squar\n+        (0x02614, 0x02615,),  # Umbrella With Rain Drops..Hot Beverage\n+        (0x02648, 0x02653,),  # Aries                   ..Pisces\n+        (0x0267f, 0x0267f,),  # Wheelchair Symbol\n+        (0x02693, 0x02693,),  # Anchor\n+        (0x026a1, 0x026a1,),  # High Voltage Sign\n+        (0x026aa, 0x026ab,),  # Medium White Circle     ..Medium Black Circle\n+        (0x026bd, 0x026be,),  # Soccer Ball             ..Baseball\n+        (0x026c4, 0x026c5,),  # Snowman Without Snow    ..Sun Behind Cloud\n+        (0x026ce, 0x026ce,),  # Ophiuchus\n+        (0x026d4, 0x026d4,),  # No Entry\n+        (0x026ea, 0x026ea,),  # Church\n+        (0x026f2, 0x026f3,),  # Fountain                ..Flag In Hole\n+        (0x026f5, 0x026f5,),  # Sailboat\n+        (0x026fa, 0x026fa,),  # Tent\n+        (0x026fd, 0x026fd,),  # Fuel Pump\n+        (0x02705, 0x02705,),  # White Heavy Check Mark\n+        (0x0270a, 0x0270b,),  # Raised Fist             ..Raised Hand\n+        (0x02728, 0x02728,),  # Sparkles\n+        (0x0274c, 0x0274c,),  # Cross Mark\n+        (0x0274e, 0x0274e,),  # Negative Squared Cross Mark\n+        (0x02753, 0x02755,),  # Black Question Mark Orna..White Exclamation Mark O\n+        (0x02757, 0x02757,),  # Heavy Exclamation Mark Symbol\n+        (0x02795, 0x02797,),  # Heavy Plus Sign         ..Heavy Division Sign\n+        (0x027b0, 0x027b0,),  # Curly Loop\n+        (0x027bf, 0x027bf,),  # Double Curly Loop\n+        (0x02b1b, 0x02b1c,),  # Black Large Square      ..White Large Square\n+        (0x02b50, 0x02b50,),  # White Medium Star\n+        (0x02b55, 0x02b55,),  # Heavy Large Circle\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312f,),  # Bopomofo Letter B       ..Bopomofo Letter Nn\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031e3,),  # Ideographic Annotation L..Cjk Stroke Q\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03247,),  # Parenthesized Ideograph ..Circled Ideograph Koto\n+        (0x03250, 0x04dbf,),  # Partnership Sign        ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x0a48c,),  # Cjk Unified Ideograph-4e..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0a960, 0x0a97c,),  # Hangul Choseong Tikeut-m..Hangul Choseong Ssangyeo\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0faff,),  # Cjk Compatibility Ideogr..(nil)\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x16fe0, 0x16fe3,),  # Tangut Iteration Mark   ..Old Chinese Iteration Ma\n+        (0x17000, 0x187f7,),  # (nil)\n+        (0x18800, 0x18cd5,),  # Tangut Component-001    ..Khitan Small Script Char\n+        (0x18d00, 0x18d08,),  # (nil)\n+        (0x1b000, 0x1b11e,),  # Katakana Letter Archaic ..Hentaigana Letter N-mu-m\n+        (0x1b150, 0x1b152,),  # Hiragana Letter Small Wi..Hiragana Letter Small Wo\n+        (0x1b164, 0x1b167,),  # Katakana Letter Small Wi..Katakana Letter Small N\n+        (0x1b170, 0x1b2fb,),  # Nushu Character-1b170   ..Nushu Character-1b2fb\n+        (0x1f004, 0x1f004,),  # Mahjong Tile Red Dragon\n+        (0x1f0cf, 0x1f0cf,),  # Playing Card Black Joker\n+        (0x1f18e, 0x1f18e,),  # Negative Squared Ab\n+        (0x1f191, 0x1f19a,),  # Squared Cl              ..Squared Vs\n+        (0x1f200, 0x1f202,),  # Square Hiragana Hoka    ..Squared Katakana Sa\n+        (0x1f210, 0x1f23b,),  # Squared Cjk Unified Ideo..Squared Cjk Unified Ideo\n+        (0x1f240, 0x1f248,),  # Tortoise Shell Bracketed..Tortoise Shell Bracketed\n+        (0x1f250, 0x1f251,),  # Circled Ideograph Advant..Circled Ideograph Accept\n+        (0x1f260, 0x1f265,),  # Rounded Symbol For Fu   ..Rounded Symbol For Cai\n+        (0x1f300, 0x1f320,),  # Cyclone                 ..Shooting Star\n+        (0x1f32d, 0x1f335,),  # Hot Dog                 ..Cactus\n+        (0x1f337, 0x1f37c,),  # Tulip                   ..Baby Bottle\n+        (0x1f37e, 0x1f393,),  # Bottle With Popping Cork..Graduation Cap\n+        (0x1f3a0, 0x1f3ca,),  # Carousel Horse          ..Swimmer\n+        (0x1f3cf, 0x1f3d3,),  # Cricket Bat And Ball    ..Table Tennis Paddle And\n+        (0x1f3e0, 0x1f3f0,),  # House Building          ..European Castle\n+        (0x1f3f4, 0x1f3f4,),  # Waving Black Flag\n+        (0x1f3f8, 0x1f3fa,),  # Badminton Racquet And Sh..Amphora\n+        (0x1f400, 0x1f43e,),  # Rat                     ..Paw Prints\n+        (0x1f440, 0x1f440,),  # Eyes\n+        (0x1f442, 0x1f4fc,),  # Ear                     ..Videocassette\n+        (0x1f4ff, 0x1f53d,),  # Prayer Beads            ..Down-pointing Small Red\n+        (0x1f54b, 0x1f54e,),  # Kaaba                   ..Menorah With Nine Branch\n+        (0x1f550, 0x1f567,),  # Clock Face One Oclock   ..Clock Face Twelve-thirty\n+        (0x1f57a, 0x1f57a,),  # Man Dancing\n+        (0x1f595, 0x1f596,),  # Reversed Hand With Middl..Raised Hand With Part Be\n+        (0x1f5a4, 0x1f5a4,),  # Black Heart\n+        (0x1f5fb, 0x1f64f,),  # Mount Fuji              ..Person With Folded Hands\n+        (0x1f680, 0x1f6c5,),  # Rocket                  ..Left Luggage\n+        (0x1f6cc, 0x1f6cc,),  # Sleeping Accommodation\n+        (0x1f6d0, 0x1f6d2,),  # Place Of Worship        ..Shopping Trolley\n+        (0x1f6d5, 0x1f6d7,),  # Hindu Temple            ..Elevator\n+        (0x1f6eb, 0x1f6ec,),  # Airplane Departure      ..Airplane Arriving\n+        (0x1f6f4, 0x1f6fc,),  # Scooter                 ..Roller Skate\n+        (0x1f7e0, 0x1f7eb,),  # Large Orange Circle     ..Large Brown Square\n+        (0x1f90c, 0x1f93a,),  # Pinched Fingers         ..Fencer\n+        (0x1f93c, 0x1f945,),  # Wrestlers               ..Goal Net\n+        (0x1f947, 0x1f978,),  # First Place Medal       ..Disguised Face\n+        (0x1f97a, 0x1f9cb,),  # Face With Pleading Eyes ..Bubble Tea\n+        (0x1f9cd, 0x1f9ff,),  # Standing Person         ..Nazar Amulet\n+        (0x1fa70, 0x1fa74,),  # Ballet Shoes            ..Thong Sandal\n+        (0x1fa78, 0x1fa7a,),  # Drop Of Blood           ..Stethoscope\n+        (0x1fa80, 0x1fa86,),  # Yo-yo                   ..Nesting Dolls\n+        (0x1fa90, 0x1faa8,),  # Ringed Planet           ..Rock\n+        (0x1fab0, 0x1fab6,),  # Fly                     ..Feather\n+        (0x1fac0, 0x1fac2,),  # Anatomical Heart        ..People Hugging\n+        (0x1fad0, 0x1fad6,),  # Blueberries             ..Teapot\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '14.0.0': (\n+        # Source: EastAsianWidth-14.0.0.txt\n+        # Date: 2021-07-06, 09:58:53 GMT [KW, LI]\n+        #\n+        (0x01100, 0x0115f,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Filler\n+        (0x0231a, 0x0231b,),  # Watch                   ..Hourglass\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x023e9, 0x023ec,),  # Black Right-pointing Dou..Black Down-pointing Doub\n+        (0x023f0, 0x023f0,),  # Alarm Clock\n+        (0x023f3, 0x023f3,),  # Hourglass With Flowing Sand\n+        (0x025fd, 0x025fe,),  # White Medium Small Squar..Black Medium Small Squar\n+        (0x02614, 0x02615,),  # Umbrella With Rain Drops..Hot Beverage\n+        (0x02648, 0x02653,),  # Aries                   ..Pisces\n+        (0x0267f, 0x0267f,),  # Wheelchair Symbol\n+        (0x02693, 0x02693,),  # Anchor\n+        (0x026a1, 0x026a1,),  # High Voltage Sign\n+        (0x026aa, 0x026ab,),  # Medium White Circle     ..Medium Black Circle\n+        (0x026bd, 0x026be,),  # Soccer Ball             ..Baseball\n+        (0x026c4, 0x026c5,),  # Snowman Without Snow    ..Sun Behind Cloud\n+        (0x026ce, 0x026ce,),  # Ophiuchus\n+        (0x026d4, 0x026d4,),  # No Entry\n+        (0x026ea, 0x026ea,),  # Church\n+        (0x026f2, 0x026f3,),  # Fountain                ..Flag In Hole\n+        (0x026f5, 0x026f5,),  # Sailboat\n+        (0x026fa, 0x026fa,),  # Tent\n+        (0x026fd, 0x026fd,),  # Fuel Pump\n+        (0x02705, 0x02705,),  # White Heavy Check Mark\n+        (0x0270a, 0x0270b,),  # Raised Fist             ..Raised Hand\n+        (0x02728, 0x02728,),  # Sparkles\n+        (0x0274c, 0x0274c,),  # Cross Mark\n+        (0x0274e, 0x0274e,),  # Negative Squared Cross Mark\n+        (0x02753, 0x02755,),  # Black Question Mark Orna..White Exclamation Mark O\n+        (0x02757, 0x02757,),  # Heavy Exclamation Mark Symbol\n+        (0x02795, 0x02797,),  # Heavy Plus Sign         ..Heavy Division Sign\n+        (0x027b0, 0x027b0,),  # Curly Loop\n+        (0x027bf, 0x027bf,),  # Double Curly Loop\n+        (0x02b1b, 0x02b1c,),  # Black Large Square      ..White Large Square\n+        (0x02b50, 0x02b50,),  # White Medium Star\n+        (0x02b55, 0x02b55,),  # Heavy Large Circle\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312f,),  # Bopomofo Letter B       ..Bopomofo Letter Nn\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031e3,),  # Ideographic Annotation L..Cjk Stroke Q\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03247,),  # Parenthesized Ideograph ..Circled Ideograph Koto\n+        (0x03250, 0x04dbf,),  # Partnership Sign        ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x0a48c,),  # Cjk Unified Ideograph-4e..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0a960, 0x0a97c,),  # Hangul Choseong Tikeut-m..Hangul Choseong Ssangyeo\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0faff,),  # Cjk Compatibility Ideogr..(nil)\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x16fe0, 0x16fe3,),  # Tangut Iteration Mark   ..Old Chinese Iteration Ma\n+        (0x17000, 0x187f7,),  # (nil)\n+        (0x18800, 0x18cd5,),  # Tangut Component-001    ..Khitan Small Script Char\n+        (0x18d00, 0x18d08,),  # (nil)\n+        (0x1aff0, 0x1aff3,),  # Katakana Letter Minnan T..Katakana Letter Minnan T\n+        (0x1aff5, 0x1affb,),  # Katakana Letter Minnan T..Katakana Letter Minnan N\n+        (0x1affd, 0x1affe,),  # Katakana Letter Minnan N..Katakana Letter Minnan N\n+        (0x1b000, 0x1b122,),  # Katakana Letter Archaic ..Katakana Letter Archaic\n+        (0x1b150, 0x1b152,),  # Hiragana Letter Small Wi..Hiragana Letter Small Wo\n+        (0x1b164, 0x1b167,),  # Katakana Letter Small Wi..Katakana Letter Small N\n+        (0x1b170, 0x1b2fb,),  # Nushu Character-1b170   ..Nushu Character-1b2fb\n+        (0x1f004, 0x1f004,),  # Mahjong Tile Red Dragon\n+        (0x1f0cf, 0x1f0cf,),  # Playing Card Black Joker\n+        (0x1f18e, 0x1f18e,),  # Negative Squared Ab\n+        (0x1f191, 0x1f19a,),  # Squared Cl              ..Squared Vs\n+        (0x1f200, 0x1f202,),  # Square Hiragana Hoka    ..Squared Katakana Sa\n+        (0x1f210, 0x1f23b,),  # Squared Cjk Unified Ideo..Squared Cjk Unified Ideo\n+        (0x1f240, 0x1f248,),  # Tortoise Shell Bracketed..Tortoise Shell Bracketed\n+        (0x1f250, 0x1f251,),  # Circled Ideograph Advant..Circled Ideograph Accept\n+        (0x1f260, 0x1f265,),  # Rounded Symbol For Fu   ..Rounded Symbol For Cai\n+        (0x1f300, 0x1f320,),  # Cyclone                 ..Shooting Star\n+        (0x1f32d, 0x1f335,),  # Hot Dog                 ..Cactus\n+        (0x1f337, 0x1f37c,),  # Tulip                   ..Baby Bottle\n+        (0x1f37e, 0x1f393,),  # Bottle With Popping Cork..Graduation Cap\n+        (0x1f3a0, 0x1f3ca,),  # Carousel Horse          ..Swimmer\n+        (0x1f3cf, 0x1f3d3,),  # Cricket Bat And Ball    ..Table Tennis Paddle And\n+        (0x1f3e0, 0x1f3f0,),  # House Building          ..European Castle\n+        (0x1f3f4, 0x1f3f4,),  # Waving Black Flag\n+        (0x1f3f8, 0x1f3fa,),  # Badminton Racquet And Sh..Amphora\n+        (0x1f400, 0x1f43e,),  # Rat                     ..Paw Prints\n+        (0x1f440, 0x1f440,),  # Eyes\n+        (0x1f442, 0x1f4fc,),  # Ear                     ..Videocassette\n+        (0x1f4ff, 0x1f53d,),  # Prayer Beads            ..Down-pointing Small Red\n+        (0x1f54b, 0x1f54e,),  # Kaaba                   ..Menorah With Nine Branch\n+        (0x1f550, 0x1f567,),  # Clock Face One Oclock   ..Clock Face Twelve-thirty\n+        (0x1f57a, 0x1f57a,),  # Man Dancing\n+        (0x1f595, 0x1f596,),  # Reversed Hand With Middl..Raised Hand With Part Be\n+        (0x1f5a4, 0x1f5a4,),  # Black Heart\n+        (0x1f5fb, 0x1f64f,),  # Mount Fuji              ..Person With Folded Hands\n+        (0x1f680, 0x1f6c5,),  # Rocket                  ..Left Luggage\n+        (0x1f6cc, 0x1f6cc,),  # Sleeping Accommodation\n+        (0x1f6d0, 0x1f6d2,),  # Place Of Worship        ..Shopping Trolley\n+        (0x1f6d5, 0x1f6d7,),  # Hindu Temple            ..Elevator\n+        (0x1f6dd, 0x1f6df,),  # Playground Slide        ..Ring Buoy\n+        (0x1f6eb, 0x1f6ec,),  # Airplane Departure      ..Airplane Arriving\n+        (0x1f6f4, 0x1f6fc,),  # Scooter                 ..Roller Skate\n+        (0x1f7e0, 0x1f7eb,),  # Large Orange Circle     ..Large Brown Square\n+        (0x1f7f0, 0x1f7f0,),  # Heavy Equals Sign\n+        (0x1f90c, 0x1f93a,),  # Pinched Fingers         ..Fencer\n+        (0x1f93c, 0x1f945,),  # Wrestlers               ..Goal Net\n+        (0x1f947, 0x1f9ff,),  # First Place Medal       ..Nazar Amulet\n+        (0x1fa70, 0x1fa74,),  # Ballet Shoes            ..Thong Sandal\n+        (0x1fa78, 0x1fa7c,),  # Drop Of Blood           ..Crutch\n+        (0x1fa80, 0x1fa86,),  # Yo-yo                   ..Nesting Dolls\n+        (0x1fa90, 0x1faac,),  # Ringed Planet           ..Hamsa\n+        (0x1fab0, 0x1faba,),  # Fly                     ..Nest With Eggs\n+        (0x1fac0, 0x1fac5,),  # Anatomical Heart        ..Person With Crown\n+        (0x1fad0, 0x1fad9,),  # Blueberries             ..Jar\n+        (0x1fae0, 0x1fae7,),  # Melting Face            ..Bubbles\n+        (0x1faf0, 0x1faf6,),  # Hand With Index Finger A..Heart Hands\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '15.0.0': (\n+        # Source: EastAsianWidth-15.0.0.txt\n+        # Date: 2022-05-24, 17:40:20 GMT [KW, LI]\n+        #\n+        (0x01100, 0x0115f,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Filler\n+        (0x0231a, 0x0231b,),  # Watch                   ..Hourglass\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x023e9, 0x023ec,),  # Black Right-pointing Dou..Black Down-pointing Doub\n+        (0x023f0, 0x023f0,),  # Alarm Clock\n+        (0x023f3, 0x023f3,),  # Hourglass With Flowing Sand\n+        (0x025fd, 0x025fe,),  # White Medium Small Squar..Black Medium Small Squar\n+        (0x02614, 0x02615,),  # Umbrella With Rain Drops..Hot Beverage\n+        (0x02648, 0x02653,),  # Aries                   ..Pisces\n+        (0x0267f, 0x0267f,),  # Wheelchair Symbol\n+        (0x02693, 0x02693,),  # Anchor\n+        (0x026a1, 0x026a1,),  # High Voltage Sign\n+        (0x026aa, 0x026ab,),  # Medium White Circle     ..Medium Black Circle\n+        (0x026bd, 0x026be,),  # Soccer Ball             ..Baseball\n+        (0x026c4, 0x026c5,),  # Snowman Without Snow    ..Sun Behind Cloud\n+        (0x026ce, 0x026ce,),  # Ophiuchus\n+        (0x026d4, 0x026d4,),  # No Entry\n+        (0x026ea, 0x026ea,),  # Church\n+        (0x026f2, 0x026f3,),  # Fountain                ..Flag In Hole\n+        (0x026f5, 0x026f5,),  # Sailboat\n+        (0x026fa, 0x026fa,),  # Tent\n+        (0x026fd, 0x026fd,),  # Fuel Pump\n+        (0x02705, 0x02705,),  # White Heavy Check Mark\n+        (0x0270a, 0x0270b,),  # Raised Fist             ..Raised Hand\n+        (0x02728, 0x02728,),  # Sparkles\n+        (0x0274c, 0x0274c,),  # Cross Mark\n+        (0x0274e, 0x0274e,),  # Negative Squared Cross Mark\n+        (0x02753, 0x02755,),  # Black Question Mark Orna..White Exclamation Mark O\n+        (0x02757, 0x02757,),  # Heavy Exclamation Mark Symbol\n+        (0x02795, 0x02797,),  # Heavy Plus Sign         ..Heavy Division Sign\n+        (0x027b0, 0x027b0,),  # Curly Loop\n+        (0x027bf, 0x027bf,),  # Double Curly Loop\n+        (0x02b1b, 0x02b1c,),  # Black Large Square      ..White Large Square\n+        (0x02b50, 0x02b50,),  # White Medium Star\n+        (0x02b55, 0x02b55,),  # Heavy Large Circle\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x02ffb,),  # Ideographic Description ..Ideographic Description\n+        (0x03000, 0x03029,),  # Ideographic Space       ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312f,),  # Bopomofo Letter B       ..Bopomofo Letter Nn\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031e3,),  # Ideographic Annotation L..Cjk Stroke Q\n+        (0x031f0, 0x0321e,),  # Katakana Letter Small Ku..Parenthesized Korean Cha\n+        (0x03220, 0x03247,),  # Parenthesized Ideograph ..Circled Ideograph Koto\n+        (0x03250, 0x04dbf,),  # Partnership Sign        ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x0a48c,),  # Cjk Unified Ideograph-4e..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0a960, 0x0a97c,),  # Hangul Choseong Tikeut-m..Hangul Choseong Ssangyeo\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0faff,),  # Cjk Compatibility Ideogr..(nil)\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x16fe0, 0x16fe3,),  # Tangut Iteration Mark   ..Old Chinese Iteration Ma\n+        (0x17000, 0x187f7,),  # (nil)\n+        (0x18800, 0x18cd5,),  # Tangut Component-001    ..Khitan Small Script Char\n+        (0x18d00, 0x18d08,),  # (nil)\n+        (0x1aff0, 0x1aff3,),  # Katakana Letter Minnan T..Katakana Letter Minnan T\n+        (0x1aff5, 0x1affb,),  # Katakana Letter Minnan T..Katakana Letter Minnan N\n+        (0x1affd, 0x1affe,),  # Katakana Letter Minnan N..Katakana Letter Minnan N\n+        (0x1b000, 0x1b122,),  # Katakana Letter Archaic ..Katakana Letter Archaic\n+        (0x1b132, 0x1b132,),  # Hiragana Letter Small Ko\n+        (0x1b150, 0x1b152,),  # Hiragana Letter Small Wi..Hiragana Letter Small Wo\n+        (0x1b155, 0x1b155,),  # Katakana Letter Small Ko\n+        (0x1b164, 0x1b167,),  # Katakana Letter Small Wi..Katakana Letter Small N\n+        (0x1b170, 0x1b2fb,),  # Nushu Character-1b170   ..Nushu Character-1b2fb\n+        (0x1f004, 0x1f004,),  # Mahjong Tile Red Dragon\n+        (0x1f0cf, 0x1f0cf,),  # Playing Card Black Joker\n+        (0x1f18e, 0x1f18e,),  # Negative Squared Ab\n+        (0x1f191, 0x1f19a,),  # Squared Cl              ..Squared Vs\n+        (0x1f200, 0x1f202,),  # Square Hiragana Hoka    ..Squared Katakana Sa\n+        (0x1f210, 0x1f23b,),  # Squared Cjk Unified Ideo..Squared Cjk Unified Ideo\n+        (0x1f240, 0x1f248,),  # Tortoise Shell Bracketed..Tortoise Shell Bracketed\n+        (0x1f250, 0x1f251,),  # Circled Ideograph Advant..Circled Ideograph Accept\n+        (0x1f260, 0x1f265,),  # Rounded Symbol For Fu   ..Rounded Symbol For Cai\n+        (0x1f300, 0x1f320,),  # Cyclone                 ..Shooting Star\n+        (0x1f32d, 0x1f335,),  # Hot Dog                 ..Cactus\n+        (0x1f337, 0x1f37c,),  # Tulip                   ..Baby Bottle\n+        (0x1f37e, 0x1f393,),  # Bottle With Popping Cork..Graduation Cap\n+        (0x1f3a0, 0x1f3ca,),  # Carousel Horse          ..Swimmer\n+        (0x1f3cf, 0x1f3d3,),  # Cricket Bat And Ball    ..Table Tennis Paddle And\n+        (0x1f3e0, 0x1f3f0,),  # House Building          ..European Castle\n+        (0x1f3f4, 0x1f3f4,),  # Waving Black Flag\n+        (0x1f3f8, 0x1f3fa,),  # Badminton Racquet And Sh..Amphora\n+        (0x1f400, 0x1f43e,),  # Rat                     ..Paw Prints\n+        (0x1f440, 0x1f440,),  # Eyes\n+        (0x1f442, 0x1f4fc,),  # Ear                     ..Videocassette\n+        (0x1f4ff, 0x1f53d,),  # Prayer Beads            ..Down-pointing Small Red\n+        (0x1f54b, 0x1f54e,),  # Kaaba                   ..Menorah With Nine Branch\n+        (0x1f550, 0x1f567,),  # Clock Face One Oclock   ..Clock Face Twelve-thirty\n+        (0x1f57a, 0x1f57a,),  # Man Dancing\n+        (0x1f595, 0x1f596,),  # Reversed Hand With Middl..Raised Hand With Part Be\n+        (0x1f5a4, 0x1f5a4,),  # Black Heart\n+        (0x1f5fb, 0x1f64f,),  # Mount Fuji              ..Person With Folded Hands\n+        (0x1f680, 0x1f6c5,),  # Rocket                  ..Left Luggage\n+        (0x1f6cc, 0x1f6cc,),  # Sleeping Accommodation\n+        (0x1f6d0, 0x1f6d2,),  # Place Of Worship        ..Shopping Trolley\n+        (0x1f6d5, 0x1f6d7,),  # Hindu Temple            ..Elevator\n+        (0x1f6dc, 0x1f6df,),  # Wireless                ..Ring Buoy\n+        (0x1f6eb, 0x1f6ec,),  # Airplane Departure      ..Airplane Arriving\n+        (0x1f6f4, 0x1f6fc,),  # Scooter                 ..Roller Skate\n+        (0x1f7e0, 0x1f7eb,),  # Large Orange Circle     ..Large Brown Square\n+        (0x1f7f0, 0x1f7f0,),  # Heavy Equals Sign\n+        (0x1f90c, 0x1f93a,),  # Pinched Fingers         ..Fencer\n+        (0x1f93c, 0x1f945,),  # Wrestlers               ..Goal Net\n+        (0x1f947, 0x1f9ff,),  # First Place Medal       ..Nazar Amulet\n+        (0x1fa70, 0x1fa7c,),  # Ballet Shoes            ..Crutch\n+        (0x1fa80, 0x1fa88,),  # Yo-yo                   ..Flute\n+        (0x1fa90, 0x1fabd,),  # Ringed Planet           ..Wing\n+        (0x1fabf, 0x1fac5,),  # Goose                   ..Person With Crown\n+        (0x1face, 0x1fadb,),  # Moose                   ..Pea Pod\n+        (0x1fae0, 0x1fae8,),  # Melting Face            ..Shaking Face\n+        (0x1faf0, 0x1faf8,),  # Hand With Index Finger A..Rightwards Pushing Hand\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+    '15.1.0': (\n+        # Source: EastAsianWidth-15.1.0.txt\n+        # Date: 2023-07-28, 23:34:08 GMT\n+        #\n+        (0x01100, 0x0115f,),  # Hangul Choseong Kiyeok  ..Hangul Choseong Filler\n+        (0x0231a, 0x0231b,),  # Watch                   ..Hourglass\n+        (0x02329, 0x0232a,),  # Left-pointing Angle Brac..Right-pointing Angle Bra\n+        (0x023e9, 0x023ec,),  # Black Right-pointing Dou..Black Down-pointing Doub\n+        (0x023f0, 0x023f0,),  # Alarm Clock\n+        (0x023f3, 0x023f3,),  # Hourglass With Flowing Sand\n+        (0x025fd, 0x025fe,),  # White Medium Small Squar..Black Medium Small Squar\n+        (0x02614, 0x02615,),  # Umbrella With Rain Drops..Hot Beverage\n+        (0x02648, 0x02653,),  # Aries                   ..Pisces\n+        (0x0267f, 0x0267f,),  # Wheelchair Symbol\n+        (0x02693, 0x02693,),  # Anchor\n+        (0x026a1, 0x026a1,),  # High Voltage Sign\n+        (0x026aa, 0x026ab,),  # Medium White Circle     ..Medium Black Circle\n+        (0x026bd, 0x026be,),  # Soccer Ball             ..Baseball\n+        (0x026c4, 0x026c5,),  # Snowman Without Snow    ..Sun Behind Cloud\n+        (0x026ce, 0x026ce,),  # Ophiuchus\n+        (0x026d4, 0x026d4,),  # No Entry\n+        (0x026ea, 0x026ea,),  # Church\n+        (0x026f2, 0x026f3,),  # Fountain                ..Flag In Hole\n+        (0x026f5, 0x026f5,),  # Sailboat\n+        (0x026fa, 0x026fa,),  # Tent\n+        (0x026fd, 0x026fd,),  # Fuel Pump\n+        (0x02705, 0x02705,),  # White Heavy Check Mark\n+        (0x0270a, 0x0270b,),  # Raised Fist             ..Raised Hand\n+        (0x02728, 0x02728,),  # Sparkles\n+        (0x0274c, 0x0274c,),  # Cross Mark\n+        (0x0274e, 0x0274e,),  # Negative Squared Cross Mark\n+        (0x02753, 0x02755,),  # Black Question Mark Orna..White Exclamation Mark O\n+        (0x02757, 0x02757,),  # Heavy Exclamation Mark Symbol\n+        (0x02795, 0x02797,),  # Heavy Plus Sign         ..Heavy Division Sign\n+        (0x027b0, 0x027b0,),  # Curly Loop\n+        (0x027bf, 0x027bf,),  # Double Curly Loop\n+        (0x02b1b, 0x02b1c,),  # Black Large Square      ..White Large Square\n+        (0x02b50, 0x02b50,),  # White Medium Star\n+        (0x02b55, 0x02b55,),  # Heavy Large Circle\n+        (0x02e80, 0x02e99,),  # Cjk Radical Repeat      ..Cjk Radical Rap\n+        (0x02e9b, 0x02ef3,),  # Cjk Radical Choke       ..Cjk Radical C-simplified\n+        (0x02f00, 0x02fd5,),  # Kangxi Radical One      ..Kangxi Radical Flute\n+        (0x02ff0, 0x03029,),  # Ideographic Description ..Hangzhou Numeral Nine\n+        (0x03030, 0x0303e,),  # Wavy Dash               ..Ideographic Variation In\n+        (0x03041, 0x03096,),  # Hiragana Letter Small A ..Hiragana Letter Small Ke\n+        (0x0309b, 0x030ff,),  # Katakana-hiragana Voiced..Katakana Digraph Koto\n+        (0x03105, 0x0312f,),  # Bopomofo Letter B       ..Bopomofo Letter Nn\n+        (0x03131, 0x0318e,),  # Hangul Letter Kiyeok    ..Hangul Letter Araeae\n+        (0x03190, 0x031e3,),  # Ideographic Annotation L..Cjk Stroke Q\n+        (0x031ef, 0x0321e,),  # (nil)                   ..Parenthesized Korean Cha\n+        (0x03220, 0x03247,),  # Parenthesized Ideograph ..Circled Ideograph Koto\n+        (0x03250, 0x04dbf,),  # Partnership Sign        ..Cjk Unified Ideograph-4d\n+        (0x04e00, 0x0a48c,),  # Cjk Unified Ideograph-4e..Yi Syllable Yyr\n+        (0x0a490, 0x0a4c6,),  # Yi Radical Qot          ..Yi Radical Ke\n+        (0x0a960, 0x0a97c,),  # Hangul Choseong Tikeut-m..Hangul Choseong Ssangyeo\n+        (0x0ac00, 0x0d7a3,),  # Hangul Syllable Ga      ..Hangul Syllable Hih\n+        (0x0f900, 0x0faff,),  # Cjk Compatibility Ideogr..(nil)\n+        (0x0fe10, 0x0fe19,),  # Presentation Form For Ve..Presentation Form For Ve\n+        (0x0fe30, 0x0fe52,),  # Presentation Form For Ve..Small Full Stop\n+        (0x0fe54, 0x0fe66,),  # Small Semicolon         ..Small Equals Sign\n+        (0x0fe68, 0x0fe6b,),  # Small Reverse Solidus   ..Small Commercial At\n+        (0x0ff01, 0x0ff60,),  # Fullwidth Exclamation Ma..Fullwidth Right White Pa\n+        (0x0ffe0, 0x0ffe6,),  # Fullwidth Cent Sign     ..Fullwidth Won Sign\n+        (0x16fe0, 0x16fe3,),  # Tangut Iteration Mark   ..Old Chinese Iteration Ma\n+        (0x17000, 0x187f7,),  # (nil)\n+        (0x18800, 0x18cd5,),  # Tangut Component-001    ..Khitan Small Script Char\n+        (0x18d00, 0x18d08,),  # (nil)\n+        (0x1aff0, 0x1aff3,),  # Katakana Letter Minnan T..Katakana Letter Minnan T\n+        (0x1aff5, 0x1affb,),  # Katakana Letter Minnan T..Katakana Letter Minnan N\n+        (0x1affd, 0x1affe,),  # Katakana Letter Minnan N..Katakana Letter Minnan N\n+        (0x1b000, 0x1b122,),  # Katakana Letter Archaic ..Katakana Letter Archaic\n+        (0x1b132, 0x1b132,),  # Hiragana Letter Small Ko\n+        (0x1b150, 0x1b152,),  # Hiragana Letter Small Wi..Hiragana Letter Small Wo\n+        (0x1b155, 0x1b155,),  # Katakana Letter Small Ko\n+        (0x1b164, 0x1b167,),  # Katakana Letter Small Wi..Katakana Letter Small N\n+        (0x1b170, 0x1b2fb,),  # Nushu Character-1b170   ..Nushu Character-1b2fb\n+        (0x1f004, 0x1f004,),  # Mahjong Tile Red Dragon\n+        (0x1f0cf, 0x1f0cf,),  # Playing Card Black Joker\n+        (0x1f18e, 0x1f18e,),  # Negative Squared Ab\n+        (0x1f191, 0x1f19a,),  # Squared Cl              ..Squared Vs\n+        (0x1f200, 0x1f202,),  # Square Hiragana Hoka    ..Squared Katakana Sa\n+        (0x1f210, 0x1f23b,),  # Squared Cjk Unified Ideo..Squared Cjk Unified Ideo\n+        (0x1f240, 0x1f248,),  # Tortoise Shell Bracketed..Tortoise Shell Bracketed\n+        (0x1f250, 0x1f251,),  # Circled Ideograph Advant..Circled Ideograph Accept\n+        (0x1f260, 0x1f265,),  # Rounded Symbol For Fu   ..Rounded Symbol For Cai\n+        (0x1f300, 0x1f320,),  # Cyclone                 ..Shooting Star\n+        (0x1f32d, 0x1f335,),  # Hot Dog                 ..Cactus\n+        (0x1f337, 0x1f37c,),  # Tulip                   ..Baby Bottle\n+        (0x1f37e, 0x1f393,),  # Bottle With Popping Cork..Graduation Cap\n+        (0x1f3a0, 0x1f3ca,),  # Carousel Horse          ..Swimmer\n+        (0x1f3cf, 0x1f3d3,),  # Cricket Bat And Ball    ..Table Tennis Paddle And\n+        (0x1f3e0, 0x1f3f0,),  # House Building          ..European Castle\n+        (0x1f3f4, 0x1f3f4,),  # Waving Black Flag\n+        (0x1f3f8, 0x1f3fa,),  # Badminton Racquet And Sh..Amphora\n+        (0x1f400, 0x1f43e,),  # Rat                     ..Paw Prints\n+        (0x1f440, 0x1f440,),  # Eyes\n+        (0x1f442, 0x1f4fc,),  # Ear                     ..Videocassette\n+        (0x1f4ff, 0x1f53d,),  # Prayer Beads            ..Down-pointing Small Red\n+        (0x1f54b, 0x1f54e,),  # Kaaba                   ..Menorah With Nine Branch\n+        (0x1f550, 0x1f567,),  # Clock Face One Oclock   ..Clock Face Twelve-thirty\n+        (0x1f57a, 0x1f57a,),  # Man Dancing\n+        (0x1f595, 0x1f596,),  # Reversed Hand With Middl..Raised Hand With Part Be\n+        (0x1f5a4, 0x1f5a4,),  # Black Heart\n+        (0x1f5fb, 0x1f64f,),  # Mount Fuji              ..Person With Folded Hands\n+        (0x1f680, 0x1f6c5,),  # Rocket                  ..Left Luggage\n+        (0x1f6cc, 0x1f6cc,),  # Sleeping Accommodation\n+        (0x1f6d0, 0x1f6d2,),  # Place Of Worship        ..Shopping Trolley\n+        (0x1f6d5, 0x1f6d7,),  # Hindu Temple            ..Elevator\n+        (0x1f6dc, 0x1f6df,),  # Wireless                ..Ring Buoy\n+        (0x1f6eb, 0x1f6ec,),  # Airplane Departure      ..Airplane Arriving\n+        (0x1f6f4, 0x1f6fc,),  # Scooter                 ..Roller Skate\n+        (0x1f7e0, 0x1f7eb,),  # Large Orange Circle     ..Large Brown Square\n+        (0x1f7f0, 0x1f7f0,),  # Heavy Equals Sign\n+        (0x1f90c, 0x1f93a,),  # Pinched Fingers         ..Fencer\n+        (0x1f93c, 0x1f945,),  # Wrestlers               ..Goal Net\n+        (0x1f947, 0x1f9ff,),  # First Place Medal       ..Nazar Amulet\n+        (0x1fa70, 0x1fa7c,),  # Ballet Shoes            ..Crutch\n+        (0x1fa80, 0x1fa88,),  # Yo-yo                   ..Flute\n+        (0x1fa90, 0x1fabd,),  # Ringed Planet           ..Wing\n+        (0x1fabf, 0x1fac5,),  # Goose                   ..Person With Crown\n+        (0x1face, 0x1fadb,),  # Moose                   ..Pea Pod\n+        (0x1fae0, 0x1fae8,),  # Melting Face            ..Shaking Face\n+        (0x1faf0, 0x1faf8,),  # Hand With Index Finger A..Rightwards Pushing Hand\n+        (0x20000, 0x2fffd,),  # Cjk Unified Ideograph-20..(nil)\n+        (0x30000, 0x3fffd,),  # Cjk Unified Ideograph-30..(nil)\n+    ),\n+}\ndiff --git a/wcwidth/table_zero.py b/wcwidth/table_zero.py\nindex d7d64b3..dd42291 100644\n--- a/wcwidth/table_zero.py\n+++ b/wcwidth/table_zero.py\n@@ -3,1004 +3,4841 @@ Exports ZERO_WIDTH table keyed by supporting unicode version level.\n\n This code generated by wcwidth/bin/update-tables.py on 2024-01-04 07:14:52 UTC.\n \"\"\"\n-ZERO_WIDTH = {'4.1.0': ((0, 0), (173, 173), (768, 879), (1155, 1158), (1160,\n-    1161), (1425, 1465), (1467, 1469), (1471, 1471), (1473, 1474), (1476, \n-    1477), (1479, 1479), (1536, 1539), (1552, 1557), (1611, 1630), (1648, \n-    1648), (1750, 1764), (1767, 1768), (1770, 1773), (1807, 1807), (1809, \n-    1809), (1840, 1866), (1958, 1968), (2305, 2307), (2364, 2364), (2366, \n-    2381), (2385, 2388), (2402, 2403), (2433, 2435), (2492, 2492), (2494, \n-    2500), (2503, 2504), (2507, 2509), (2519, 2519), (2530, 2531), (2561, \n-    2563), (2620, 2620), (2622, 2626), (2631, 2632), (2635, 2637), (2672, \n-    2673), (2689, 2691), (2748, 2748), (2750, 2757), (2759, 2761), (2763, \n-    2765), (2786, 2787), (2817, 2819), (2876, 2876), (2878, 2883), (2887, \n-    2888), (2891, 2893), (2902, 2903), (2946, 2946), (3006, 3010), (3014, \n-    3016), (3018, 3021), (3031, 3031), (3073, 3075), (3134, 3140), (3142, \n-    3144), (3146, 3149), (3157, 3158), (3202, 3203), (3260, 3260), (3262, \n-    3268), (3270, 3272), (3274, 3277), (3285, 3286), (3330, 3331), (3390, \n-    3395), (3398, 3400), (3402, 3405), (3415, 3415), (3458, 3459), (3530, \n-    3530), (3535, 3540), (3542, 3542), (3544, 3551), (3570, 3571), (3633, \n-    3633), (3636, 3642), (3655, 3662), (3761, 3761), (3764, 3769), (3771, \n-    3772), (3784, 3789), (3864, 3865), (3893, 3893), (3895, 3895), (3897, \n-    3897), (3902, 3903), (3953, 3972), (3974, 3975), (3984, 3991), (3993, \n-    4028), (4038, 4038), (4140, 4146), (4150, 4153), (4182, 4185), (4448, \n-    4607), (4959, 4959), (5906, 5908), (5938, 5940), (5970, 5971), (6002, \n-    6003), (6068, 6099), (6109, 6109), (6155, 6157), (6313, 6313), (6432, \n-    6443), (6448, 6459), (6576, 6592), (6600, 6601), (6679, 6683), (7616, \n-    7619), (8203, 8207), (8232, 8238), (8288, 8291), (8298, 8303), (8400, \n-    8427), (12330, 12335), (12441, 12442), (43010, 43010), (43014, 43014),\n-    (43019, 43019), (43043, 43047), (55216, 55295), (64286, 64286), (65024,\n-    65039), (65056, 65059), (65279, 65279), (65529, 65531), (68097, 68099),\n-    (68101, 68102), (68108, 68111), (68152, 68154), (68159, 68159), (119141,\n-    119145), (119149, 119170), (119173, 119179), (119210, 119213), (119362,\n-    119364), (917505, 917505), (917536, 917631), (917760, 917999)), '5.0.0':\n-    ((0, 0), (173, 173), (768, 879), (1155, 1158), (1160, 1161), (1425, \n-    1469), (1471, 1471), (1473, 1474), (1476, 1477), (1479, 1479), (1536, \n-    1539), (1552, 1557), (1611, 1630), (1648, 1648), (1750, 1764), (1767, \n-    1768), (1770, 1773), (1807, 1807), (1809, 1809), (1840, 1866), (1958, \n-    1968), (2027, 2035), (2305, 2307), (2364, 2364), (2366, 2381), (2385, \n-    2388), (2402, 2403), (2433, 2435), (2492, 2492), (2494, 2500), (2503, \n-    2504), (2507, 2509), (2519, 2519), (2530, 2531), (2561, 2563), (2620, \n-    2620), (2622, 2626), (2631, 2632), (2635, 2637), (2672, 2673), (2689, \n-    2691), (2748, 2748), (2750, 2757), (2759, 2761), (2763, 2765), (2786, \n-    2787), (2817, 2819), (2876, 2876), (2878, 2883), (2887, 2888), (2891, \n-    2893), (2902, 2903), (2946, 2946), (3006, 3010), (3014, 3016), (3018, \n-    3021), (3031, 3031), (3073, 3075), (3134, 3140), (3142, 3144), (3146, \n-    3149), (3157, 3158), (3202, 3203), (3260, 3260), (3262, 3268), (3270, \n-    3272), (3274, 3277), (3285, 3286), (3298, 3299), (3330, 3331), (3390, \n-    3395), (3398, 3400), (3402, 3405), (3415, 3415), (3458, 3459), (3530, \n-    3530), (3535, 3540), (3542, 3542), (3544, 3551), (3570, 3571), (3633, \n-    3633), (3636, 3642), (3655, 3662), (3761, 3761), (3764, 3769), (3771, \n-    3772), (3784, 3789), (3864, 3865), (3893, 3893), (3895, 3895), (3897, \n-    3897), (3902, 3903), (3953, 3972), (3974, 3975), (3984, 3991), (3993, \n-    4028), (4038, 4038), (4140, 4146), (4150, 4153), (4182, 4185), (4448, \n-    4607), (4959, 4959), (5906, 5908), (5938, 5940), (5970, 5971), (6002, \n-    6003), (6068, 6099), (6109, 6109), (6155, 6157), (6313, 6313), (6432, \n-    6443), (6448, 6459), (6576, 6592), (6600, 6601), (6679, 6683), (6912, \n-    6916), (6964, 6980), (7019, 7027), (7616, 7626), (7678, 7679), (8203, \n-    8207), (8232, 8238), (8288, 8291), (8298, 8303), (8400, 8431), (12330, \n-    12335), (12441, 12442), (43010, 43010), (43014, 43014), (43019, 43019),\n-    (43043, 43047), (55216, 55295), (64286, 64286), (65024, 65039), (65056,\n-    65059), (65279, 65279), (65529, 65531), (68097, 68099), (68101, 68102),\n-    (68108, 68111), (68152, 68154), (68159, 68159), (119141, 119145), (\n-    119149, 119170), (119173, 119179), (119210, 119213), (119362, 119364),\n-    (917505, 917505), (917536, 917631), (917760, 917999)), '5.1.0': ((0, 0),\n-    (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), (1473,\n-    1474), (1476, 1477), (1479, 1479), (1536, 1539), (1552, 1562), (1611, \n-    1630), (1648, 1648), (1750, 1764), (1767, 1768), (1770, 1773), (1807, \n-    1807), (1809, 1809), (1840, 1866), (1958, 1968), (2027, 2035), (2305, \n-    2307), (2364, 2364), (2366, 2381), (2385, 2388), (2402, 2403), (2433, \n-    2435), (2492, 2492), (2494, 2500), (2503, 2504), (2507, 2509), (2519, \n-    2519), (2530, 2531), (2561, 2563), (2620, 2620), (2622, 2626), (2631, \n-    2632), (2635, 2637), (2641, 2641), (2672, 2673), (2677, 2677), (2689, \n-    2691), (2748, 2748), (2750, 2757), (2759, 2761), (2763, 2765), (2786, \n-    2787), (2817, 2819), (2876, 2876), (2878, 2884), (2887, 2888), (2891, \n-    2893), (2902, 2903), (2914, 2915), (2946, 2946), (3006, 3010), (3014, \n-    3016), (3018, 3021), (3031, 3031), (3073, 3075), (3134, 3140), (3142, \n-    3144), (3146, 3149), (3157, 3158), (3170, 3171), (3202, 3203), (3260, \n-    3260), (3262, 3268), (3270, 3272), (3274, 3277), (3285, 3286), (3298, \n-    3299), (3330, 3331), (3390, 3396), (3398, 3400), (3402, 3405), (3415, \n-    3415), (3426, 3427), (3458, 3459), (3530, 3530), (3535, 3540), (3542, \n-    3542), (3544, 3551), (3570, 3571), (3633, 3633), (3636, 3642), (3655, \n-    3662), (3761, 3761), (3764, 3769), (3771, 3772), (3784, 3789), (3864, \n-    3865), (3893, 3893), (3895, 3895), (3897, 3897), (3902, 3903), (3953, \n-    3972), (3974, 3975), (3984, 3991), (3993, 4028), (4038, 4038), (4139, \n-    4158), (4182, 4185), (4190, 4192), (4194, 4196), (4199, 4205), (4209, \n-    4212), (4226, 4237), (4239, 4239), (4448, 4607), (4959, 4959), (5906, \n-    5908), (5938, 5940), (5970, 5971), (6002, 6003), (6068, 6099), (6109, \n-    6109), (6155, 6157), (6313, 6313), (6432, 6443), (6448, 6459), (6576, \n-    6592), (6600, 6601), (6679, 6683), (6912, 6916), (6964, 6980), (7019, \n-    7027), (7040, 7042), (7073, 7082), (7204, 7223), (7616, 7654), (7678, \n-    7679), (8203, 8207), (8232, 8238), (8288, 8292), (8298, 8303), (8400, \n-    8432), (11744, 11775), (12330, 12335), (12441, 12442), (42607, 42610),\n-    (42620, 42621), (43010, 43010), (43014, 43014), (43019, 43019), (43043,\n-    43047), (43136, 43137), (43188, 43204), (43302, 43309), (43335, 43347),\n-    (43561, 43574), (43587, 43587), (43596, 43597), (55216, 55295), (64286,\n-    64286), (65024, 65039), (65056, 65062), (65279, 65279), (65529, 65531),\n-    (66045, 66045), (68097, 68099), (68101, 68102), (68108, 68111), (68152,\n-    68154), (68159, 68159), (119141, 119145), (119149, 119170), (119173, \n-    119179), (119210, 119213), (119362, 119364), (917505, 917505), (917536,\n-    917631), (917760, 917999)), '5.2.0': ((0, 0), (173, 173), (768, 879), (\n-    1155, 1161), (1425, 1469), (1471, 1471), (1473, 1474), (1476, 1477), (\n-    1479, 1479), (1536, 1539), (1552, 1562), (1611, 1630), (1648, 1648), (\n-    1750, 1764), (1767, 1768), (1770, 1773), (1807, 1807), (1809, 1809), (\n-    1840, 1866), (1958, 1968), (2027, 2035), (2070, 2073), (2075, 2083), (\n-    2085, 2087), (2089, 2093), (2304, 2307), (2364, 2364), (2366, 2382), (\n-    2385, 2389), (2402, 2403), (2433, 2435), (2492, 2492), (2494, 2500), (\n-    2503, 2504), (2507, 2509), (2519, 2519), (2530, 2531), (2561, 2563), (\n-    2620, 2620), (2622, 2626), (2631, 2632), (2635, 2637), (2641, 2641), (\n-    2672, 2673), (2677, 2677), (2689, 2691), (2748, 2748), (2750, 2757), (\n-    2759, 2761), (2763, 2765), (2786, 2787), (2817, 2819), (2876, 2876), (\n-    2878, 2884), (2887, 2888), (2891, 2893), (2902, 2903), (2914, 2915), (\n-    2946, 2946), (3006, 3010), (3014, 3016), (3018, 3021), (3031, 3031), (\n-    3073, 3075), (3134, 3140), (3142, 3144), (3146, 3149), (3157, 3158), (\n-    3170, 3171), (3202, 3203), (3260, 3260), (3262, 3268), (3270, 3272), (\n-    3274, 3277), (3285, 3286), (3298, 3299), (3330, 3331), (3390, 3396), (\n-    3398, 3400), (3402, 3405), (3415, 3415), (3426, 3427), (3458, 3459), (\n-    3530, 3530), (3535, 3540), (3542, 3542), (3544, 3551), (3570, 3571), (\n-    3633, 3633), (3636, 3642), (3655, 3662), (3761, 3761), (3764, 3769), (\n-    3771, 3772), (3784, 3789), (3864, 3865), (3893, 3893), (3895, 3895), (\n-    3897, 3897), (3902, 3903), (3953, 3972), (3974, 3975), (3984, 3991), (\n-    3993, 4028), (4038, 4038), (4139, 4158), (4182, 4185), (4190, 4192), (\n-    4194, 4196), (4199, 4205), (4209, 4212), (4226, 4237), (4239, 4239), (\n-    4250, 4253), (4448, 4607), (4959, 4959), (5906, 5908), (5938, 5940), (\n-    5970, 5971), (6002, 6003), (6068, 6099), (6109, 6109), (6155, 6157), (\n-    6313, 6313), (6432, 6443), (6448, 6459), (6576, 6592), (6600, 6601), (\n-    6679, 6683), (6741, 6750), (6752, 6780), (6783, 6783), (6912, 6916), (\n-    6964, 6980), (7019, 7027), (7040, 7042), (7073, 7082), (7204, 7223), (\n-    7376, 7378), (7380, 7400), (7405, 7405), (7410, 7410), (7616, 7654), (\n-    7677, 7679), (8203, 8207), (8232, 8238), (8288, 8292), (8298, 8303), (\n-    8400, 8432), (11503, 11505), (11744, 11775), (12330, 12335), (12441, \n-    12442), (42607, 42610), (42620, 42621), (42736, 42737), (43010, 43010),\n-    (43014, 43014), (43019, 43019), (43043, 43047), (43136, 43137), (43188,\n-    43204), (43232, 43249), (43302, 43309), (43335, 43347), (43392, 43395),\n-    (43443, 43456), (43561, 43574), (43587, 43587), (43596, 43597), (43643,\n-    43643), (43696, 43696), (43698, 43700), (43703, 43704), (43710, 43711),\n-    (43713, 43713), (44003, 44010), (44012, 44013), (55216, 55295), (64286,\n-    64286), (65024, 65039), (65056, 65062), (65279, 65279), (65529, 65531),\n-    (66045, 66045), (68097, 68099), (68101, 68102), (68108, 68111), (68152,\n-    68154), (68159, 68159), (69760, 69762), (69808, 69818), (69821, 69821),\n-    (119141, 119145), (119149, 119170), (119173, 119179), (119210, 119213),\n-    (119362, 119364), (917505, 917505), (917536, 917631), (917760, 917999)),\n-    '6.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (\n-    1471, 1471), (1473, 1474), (1476, 1477), (1479, 1479), (1536, 1539), (\n-    1552, 1562), (1611, 1631), (1648, 1648), (1750, 1757), (1759, 1764), (\n-    1767, 1768), (1770, 1773), (1807, 1807), (1809, 1809), (1840, 1866), (\n-    1958, 1968), (2027, 2035), (2070, 2073), (2075, 2083), (2085, 2087), (\n-    2089, 2093), (2137, 2139), (2304, 2307), (2362, 2364), (2366, 2383), (\n-    2385, 2391), (2402, 2403), (2433, 2435), (2492, 2492), (2494, 2500), (\n-    2503, 2504), (2507, 2509), (2519, 2519), (2530, 2531), (2561, 2563), (\n-    2620, 2620), (2622, 2626), (2631, 2632), (2635, 2637), (2641, 2641), (\n-    2672, 2673), (2677, 2677), (2689, 2691), (2748, 2748), (2750, 2757), (\n-    2759, 2761), (2763, 2765), (2786, 2787), (2817, 2819), (2876, 2876), (\n-    2878, 2884), (2887, 2888), (2891, 2893), (2902, 2903), (2914, 2915), (\n-    2946, 2946), (3006, 3010), (3014, 3016), (3018, 3021), (3031, 3031), (\n-    3073, 3075), (3134, 3140), (3142, 3144), (3146, 3149), (3157, 3158), (\n-    3170, 3171), (3202, 3203), (3260, 3260), (3262, 3268), (3270, 3272), (\n-    3274, 3277), (3285, 3286), (3298, 3299), (3330, 3331), (3390, 3396), (\n-    3398, 3400), (3402, 3405), (3415, 3415), (3426, 3427), (3458, 3459), (\n-    3530, 3530), (3535, 3540), (3542, 3542), (3544, 3551), (3570, 3571), (\n-    3633, 3633), (3636, 3642), (3655, 3662), (3761, 3761), (3764, 3769), (\n-    3771, 3772), (3784, 3789), (3864, 3865), (3893, 3893), (3895, 3895), (\n-    3897, 3897), (3902, 3903), (3953, 3972), (3974, 3975), (3981, 3991), (\n-    3993, 4028), (4038, 4038), (4139, 4158), (4182, 4185), (4190, 4192), (\n-    4194, 4196), (4199, 4205), (4209, 4212), (4226, 4237), (4239, 4239), (\n-    4250, 4253), (4448, 4607), (4957, 4959), (5906, 5908), (5938, 5940), (\n-    5970, 5971), (6002, 6003), (6068, 6099), (6109, 6109), (6155, 6157), (\n-    6313, 6313), (6432, 6443), (6448, 6459), (6576, 6592), (6600, 6601), (\n-    6679, 6683), (6741, 6750), (6752, 6780), (6783, 6783), (6912, 6916), (\n-    6964, 6980), (7019, 7027), (7040, 7042), (7073, 7082), (7142, 7155), (\n-    7204, 7223), (7376, 7378), (7380, 7400), (7405, 7405), (7410, 7410), (\n-    7616, 7654), (7676, 7679), (8203, 8207), (8232, 8238), (8288, 8292), (\n-    8298, 8303), (8400, 8432), (11503, 11505), (11647, 11647), (11744, \n-    11775), (12330, 12335), (12441, 12442), (42607, 42610), (42620, 42621),\n-    (42736, 42737), (43010, 43010), (43014, 43014), (43019, 43019), (43043,\n-    43047), (43136, 43137), (43188, 43204), (43232, 43249), (43302, 43309),\n-    (43335, 43347), (43392, 43395), (43443, 43456), (43561, 43574), (43587,\n-    43587), (43596, 43597), (43643, 43643), (43696, 43696), (43698, 43700),\n-    (43703, 43704), (43710, 43711), (43713, 43713), (44003, 44010), (44012,\n-    44013), (55216, 55295), (64286, 64286), (65024, 65039), (65056, 65062),\n-    (65279, 65279), (65529, 65531), (66045, 66045), (68097, 68099), (68101,\n-    68102), (68108, 68111), (68152, 68154), (68159, 68159), (69632, 69634),\n-    (69688, 69702), (69760, 69762), (69808, 69818), (69821, 69821), (119141,\n-    119145), (119149, 119170), (119173, 119179), (119210, 119213), (119362,\n-    119364), (917505, 917505), (917536, 917631), (917760, 917999)), '6.1.0':\n-    ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, \n-    1471), (1473, 1474), (1476, 1477), (1479, 1479), (1536, 1540), (1552, \n-    1562), (1611, 1631), (1648, 1648), (1750, 1757), (1759, 1764), (1767, \n-    1768), (1770, 1773), (1807, 1807), (1809, 1809), (1840, 1866), (1958, \n-    1968), (2027, 2035), (2070, 2073), (2075, 2083), (2085, 2087), (2089, \n-    2093), (2137, 2139), (2276, 2302), (2304, 2307), (2362, 2364), (2366, \n-    2383), (2385, 2391), (2402, 2403), (2433, 2435), (2492, 2492), (2494, \n-    2500), (2503, 2504), (2507, 2509), (2519, 2519), (2530, 2531), (2561, \n-    2563), (2620, 2620), (2622, 2626), (2631, 2632), (2635, 2637), (2641, \n-    2641), (2672, 2673), (2677, 2677), (2689, 2691), (2748, 2748), (2750, \n-    2757), (2759, 2761), (2763, 2765), (2786, 2787), (2817, 2819), (2876, \n-    2876), (2878, 2884), (2887, 2888), (2891, 2893), (2902, 2903), (2914, \n-    2915), (2946, 2946), (3006, 3010), (3014, 3016), (3018, 3021), (3031, \n-    3031), (3073, 3075), (3134, 3140), (3142, 3144), (3146, 3149), (3157, \n-    3158), (3170, 3171), (3202, 3203), (3260, 3260), (3262, 3268), (3270, \n-    3272), (3274, 3277), (3285, 3286), (3298, 3299), (3330, 3331), (3390, \n-    3396), (3398, 3400), (3402, 3405), (3415, 3415), (3426, 3427), (3458, \n-    3459), (3530, 3530), (3535, 3540), (3542, 3542), (3544, 3551), (3570, \n-    3571), (3633, 3633), (3636, 3642), (3655, 3662), (3761, 3761), (3764, \n-    3769), (3771, 3772), (3784, 3789), (3864, 3865), (3893, 3893), (3895, \n-    3895), (3897, 3897), (3902, 3903), (3953, 3972), (3974, 3975), (3981, \n-    3991), (3993, 4028), (4038, 4038), (4139, 4158), (4182, 4185), (4190, \n-    4192), (4194, 4196), (4199, 4205), (4209, 4212), (4226, 4237), (4239, \n-    4239), (4250, 4253), (4448, 4607), (4957, 4959), (5906, 5908), (5938, \n-    5940), (5970, 5971), (6002, 6003), (6068, 6099), (6109, 6109), (6155, \n-    6157), (6313, 6313), (6432, 6443), (6448, 6459), (6576, 6592), (6600, \n-    6601), (6679, 6683), (6741, 6750), (6752, 6780), (6783, 6783), (6912, \n-    6916), (6964, 6980), (7019, 7027), (7040, 7042), (7073, 7085), (7142, \n-    7155), (7204, 7223), (7376, 7378), (7380, 7400), (7405, 7405), (7410, \n-    7412), (7616, 7654), (7676, 7679), (8203, 8207), (8232, 8238), (8288, \n-    8292), (8298, 8303), (8400, 8432), (11503, 11505), (11647, 11647), (\n-    11744, 11775), (12330, 12335), (12441, 12442), (42607, 42610), (42612, \n-    42621), (42655, 42655), (42736, 42737), (43010, 43010), (43014, 43014),\n-    (43019, 43019), (43043, 43047), (43136, 43137), (43188, 43204), (43232,\n-    43249), (43302, 43309), (43335, 43347), (43392, 43395), (43443, 43456),\n-    (43561, 43574), (43587, 43587), (43596, 43597), (43643, 43643), (43696,\n-    43696), (43698, 43700), (43703, 43704), (43710, 43711), (43713, 43713),\n-    (43755, 43759), (43765, 43766), (44003, 44010), (44012, 44013), (55216,\n-    55295), (64286, 64286), (65024, 65039), (65056, 65062), (65279, 65279),\n-    (65529, 65531), (66045, 66045), (68097, 68099), (68101, 68102), (68108,\n-    68111), (68152, 68154), (68159, 68159), (69632, 69634), (69688, 69702),\n-    (69760, 69762), (69808, 69818), (69821, 69821), (69888, 69890), (69927,\n-    69940), (70016, 70018), (70067, 70080), (71339, 71351), (94033, 94078),\n-    (94095, 94098), (119141, 119145), (119149, 119170), (119173, 119179), (\n-    119210, 119213), (119362, 119364), (917505, 917505), (917536, 917631),\n-    (917760, 917999)), '6.2.0': ((0, 0), (173, 173), (768, 879), (1155, \n-    1161), (1425, 1469), (1471, 1471), (1473, 1474), (1476, 1477), (1479, \n-    1479), (1536, 1540), (1552, 1562), (1611, 1631), (1648, 1648), (1750, \n-    1757), (1759, 1764), (1767, 1768), (1770, 1773), (1807, 1807), (1809, \n-    1809), (1840, 1866), (1958, 1968), (2027, 2035), (2070, 2073), (2075, \n-    2083), (2085, 2087), (2089, 2093), (2137, 2139), (2276, 2302), (2304, \n-    2307), (2362, 2364), (2366, 2383), (2385, 2391), (2402, 2403), (2433, \n-    2435), (2492, 2492), (2494, 2500), (2503, 2504), (2507, 2509), (2519, \n-    2519), (2530, 2531), (2561, 2563), (2620, 2620), (2622, 2626), (2631, \n-    2632), (2635, 2637), (2641, 2641), (2672, 2673), (2677, 2677), (2689, \n-    2691), (2748, 2748), (2750, 2757), (2759, 2761), (2763, 2765), (2786, \n-    2787), (2817, 2819), (2876, 2876), (2878, 2884), (2887, 2888), (2891, \n-    2893), (2902, 2903), (2914, 2915), (2946, 2946), (3006, 3010), (3014, \n-    3016), (3018, 3021), (3031, 3031), (3073, 3075), (3134, 3140), (3142, \n-    3144), (3146, 3149), (3157, 3158), (3170, 3171), (3202, 3203), (3260, \n-    3260), (3262, 3268), (3270, 3272), (3274, 3277), (3285, 3286), (3298, \n-    3299), (3330, 3331), (3390, 3396), (3398, 3400), (3402, 3405), (3415, \n-    3415), (3426, 3427), (3458, 3459), (3530, 3530), (3535, 3540), (3542, \n-    3542), (3544, 3551), (3570, 3571), (3633, 3633), (3636, 3642), (3655, \n-    3662), (3761, 3761), (3764, 3769), (3771, 3772), (3784, 3789), (3864, \n-    3865), (3893, 3893), (3895, 3895), (3897, 3897), (3902, 3903), (3953, \n-    3972), (3974, 3975), (3981, 3991), (3993, 4028), (4038, 4038), (4139, \n-    4158), (4182, 4185), (4190, 4192), (4194, 4196), (4199, 4205), (4209, \n-    4212), (4226, 4237), (4239, 4239), (4250, 4253), (4448, 4607), (4957, \n-    4959), (5906, 5908), (5938, 5940), (5970, 5971), (6002, 6003), (6068, \n-    6099), (6109, 6109), (6155, 6157), (6313, 6313), (6432, 6443), (6448, \n-    6459), (6576, 6592), (6600, 6601), (6679, 6683), (6741, 6750), (6752, \n-    6780), (6783, 6783), (6912, 6916), (6964, 6980), (7019, 7027), (7040, \n-    7042), (7073, 7085), (7142, 7155), (7204, 7223), (7376, 7378), (7380, \n-    7400), (7405, 7405), (7410, 7412), (7616, 7654), (7676, 7679), (8203, \n-    8207), (8232, 8238), (8288, 8292), (8298, 8303), (8400, 8432), (11503, \n-    11505), (11647, 11647), (11744, 11775), (12330, 12335), (12441, 12442),\n-    (42607, 42610), (42612, 42621), (42655, 42655), (42736, 42737), (43010,\n-    43010), (43014, 43014), (43019, 43019), (43043, 43047), (43136, 43137),\n-    (43188, 43204), (43232, 43249), (43302, 43309), (43335, 43347), (43392,\n-    43395), (43443, 43456), (43561, 43574), (43587, 43587), (43596, 43597),\n-    (43643, 43643), (43696, 43696), (43698, 43700), (43703, 43704), (43710,\n-    43711), (43713, 43713), (43755, 43759), (43765, 43766), (44003, 44010),\n-    (44012, 44013), (55216, 55295), (64286, 64286), (65024, 65039), (65056,\n-    65062), (65279, 65279), (65529, 65531), (66045, 66045), (68097, 68099),\n-    (68101, 68102), (68108, 68111), (68152, 68154), (68159, 68159), (69632,\n-    69634), (69688, 69702), (69760, 69762), (69808, 69818), (69821, 69821),\n-    (69888, 69890), (69927, 69940), (70016, 70018), (70067, 70080), (71339,\n-    71351), (94033, 94078), (94095, 94098), (119141, 119145), (119149, \n-    119170), (119173, 119179), (119210, 119213), (119362, 119364), (917505,\n-    917505), (917536, 917631), (917760, 917999)), '6.3.0': ((0, 0), (173, \n-    173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), (1473, 1474\n-    ), (1476, 1477), (1479, 1479), (1536, 1540), (1552, 1562), (1564, 1564),\n-    (1611, 1631), (1648, 1648), (1750, 1757), (1759, 1764), (1767, 1768), (\n-    1770, 1773), (1807, 1807), (1809, 1809), (1840, 1866), (1958, 1968), (\n-    2027, 2035), (2070, 2073), (2075, 2083), (2085, 2087), (2089, 2093), (\n-    2137, 2139), (2276, 2302), (2304, 2307), (2362, 2364), (2366, 2383), (\n-    2385, 2391), (2402, 2403), (2433, 2435), (2492, 2492), (2494, 2500), (\n-    2503, 2504), (2507, 2509), (2519, 2519), (2530, 2531), (2561, 2563), (\n-    2620, 2620), (2622, 2626), (2631, 2632), (2635, 2637), (2641, 2641), (\n-    2672, 2673), (2677, 2677), (2689, 2691), (2748, 2748), (2750, 2757), (\n-    2759, 2761), (2763, 2765), (2786, 2787), (2817, 2819), (2876, 2876), (\n-    2878, 2884), (2887, 2888), (2891, 2893), (2902, 2903), (2914, 2915), (\n-    2946, 2946), (3006, 3010), (3014, 3016), (3018, 3021), (3031, 3031), (\n-    3073, 3075), (3134, 3140), (3142, 3144), (3146, 3149), (3157, 3158), (\n-    3170, 3171), (3202, 3203), (3260, 3260), (3262, 3268), (3270, 3272), (\n-    3274, 3277), (3285, 3286), (3298, 3299), (3330, 3331), (3390, 3396), (\n-    3398, 3400), (3402, 3405), (3415, 3415), (3426, 3427), (3458, 3459), (\n-    3530, 3530), (3535, 3540), (3542, 3542), (3544, 3551), (3570, 3571), (\n-    3633, 3633), (3636, 3642), (3655, 3662), (3761, 3761), (3764, 3769), (\n-    3771, 3772), (3784, 3789), (3864, 3865), (3893, 3893), (3895, 3895), (\n-    3897, 3897), (3902, 3903), (3953, 3972), (3974, 3975), (3981, 3991), (\n-    3993, 4028), (4038, 4038), (4139, 4158), (4182, 4185), (4190, 4192), (\n-    4194, 4196), (4199, 4205), (4209, 4212), (4226, 4237), (4239, 4239), (\n-    4250, 4253), (4448, 4607), (4957, 4959), (5906, 5908), (5938, 5940), (\n-    5970, 5971), (6002, 6003), (6068, 6099), (6109, 6109), (6155, 6158), (\n-    6313, 6313), (6432, 6443), (6448, 6459), (6576, 6592), (6600, 6601), (\n-    6679, 6683), (6741, 6750), (6752, 6780), (6783, 6783), (6912, 6916), (\n-    6964, 6980), (7019, 7027), (7040, 7042), (7073, 7085), (7142, 7155), (\n-    7204, 7223), (7376, 7378), (7380, 7400), (7405, 7405), (7410, 7412), (\n-    7616, 7654), (7676, 7679), (8203, 8207), (8232, 8238), (8288, 8292), (\n-    8294, 8303), (8400, 8432), (11503, 11505), (11647, 11647), (11744, \n-    11775), (12330, 12335), (12441, 12442), (42607, 42610), (42612, 42621),\n-    (42655, 42655), (42736, 42737), (43010, 43010), (43014, 43014), (43019,\n-    43019), (43043, 43047), (43136, 43137), (43188, 43204), (43232, 43249),\n-    (43302, 43309), (43335, 43347), (43392, 43395), (43443, 43456), (43561,\n-    43574), (43587, 43587), (43596, 43597), (43643, 43643), (43696, 43696),\n-    (43698, 43700), (43703, 43704), (43710, 43711), (43713, 43713), (43755,\n-    43759), (43765, 43766), (44003, 44010), (44012, 44013), (55216, 55295),\n-    (64286, 64286), (65024, 65039), (65056, 65062), (65279, 65279), (65529,\n-    65531), (66045, 66045), (68097, 68099), (68101, 68102), (68108, 68111),\n-    (68152, 68154), (68159, 68159), (69632, 69634), (69688, 69702), (69760,\n-    69762), (69808, 69818), (69821, 69821), (69888, 69890), (69927, 69940),\n-    (70016, 70018), (70067, 70080), (71339, 71351), (94033, 94078), (94095,\n-    94098), (119141, 119145), (119149, 119170), (119173, 119179), (119210, \n-    119213), (119362, 119364), (917505, 917505), (917536, 917631), (917760,\n-    917999)), '7.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425,\n-    1469), (1471, 1471), (1473, 1474), (1476, 1477), (1479, 1479), (1536, \n-    1541), (1552, 1562), (1564, 1564), (1611, 1631), (1648, 1648), (1750, \n-    1757), (1759, 1764), (1767, 1768), (1770, 1773), (1807, 1807), (1809, \n-    1809), (1840, 1866), (1958, 1968), (2027, 2035), (2070, 2073), (2075, \n-    2083), (2085, 2087), (2089, 2093), (2137, 2139), (2276, 2307), (2362, \n-    2364), (2366, 2383), (2385, 2391), (2402, 2403), (2433, 2435), (2492, \n-    2492), (2494, 2500), (2503, 2504), (2507, 2509), (2519, 2519), (2530, \n-    2531), (2561, 2563), (2620, 2620), (2622, 2626), (2631, 2632), (2635, \n-    2637), (2641, 2641), (2672, 2673), (2677, 2677), (2689, 2691), (2748, \n-    2748), (2750, 2757), (2759, 2761), (2763, 2765), (2786, 2787), (2817, \n-    2819), (2876, 2876), (2878, 2884), (2887, 2888), (2891, 2893), (2902, \n-    2903), (2914, 2915), (2946, 2946), (3006, 3010), (3014, 3016), (3018, \n-    3021), (3031, 3031), (3072, 3075), (3134, 3140), (3142, 3144), (3146, \n-    3149), (3157, 3158), (3170, 3171), (3201, 3203), (3260, 3260), (3262, \n-    3268), (3270, 3272), (3274, 3277), (3285, 3286), (3298, 3299), (3329, \n-    3331), (3390, 3396), (3398, 3400), (3402, 3405), (3415, 3415), (3426, \n-    3427), (3458, 3459), (3530, 3530), (3535, 3540), (3542, 3542), (3544, \n-    3551), (3570, 3571), (3633, 3633), (3636, 3642), (3655, 3662), (3761, \n-    3761), (3764, 3769), (3771, 3772), (3784, 3789), (3864, 3865), (3893, \n-    3893), (3895, 3895), (3897, 3897), (3902, 3903), (3953, 3972), (3974, \n-    3975), (3981, 3991), (3993, 4028), (4038, 4038), (4139, 4158), (4182, \n-    4185), (4190, 4192), (4194, 4196), (4199, 4205), (4209, 4212), (4226, \n-    4237), (4239, 4239), (4250, 4253), (4448, 4607), (4957, 4959), (5906, \n-    5908), (5938, 5940), (5970, 5971), (6002, 6003), (6068, 6099), (6109, \n-    6109), (6155, 6158), (6313, 6313), (6432, 6443), (6448, 6459), (6576, \n-    6592), (6600, 6601), (6679, 6683), (6741, 6750), (6752, 6780), (6783, \n-    6783), (6832, 6846), (6912, 6916), (6964, 6980), (7019, 7027), (7040, \n-    7042), (7073, 7085), (7142, 7155), (7204, 7223), (7376, 7378), (7380, \n-    7400), (7405, 7405), (7410, 7412), (7416, 7417), (7616, 7669), (7676, \n-    7679), (8203, 8207), (8232, 8238), (8288, 8292), (8294, 8303), (8400, \n-    8432), (11503, 11505), (11647, 11647), (11744, 11775), (12330, 12335),\n-    (12441, 12442), (42607, 42610), (42612, 42621), (42655, 42655), (42736,\n-    42737), (43010, 43010), (43014, 43014), (43019, 43019), (43043, 43047),\n-    (43136, 43137), (43188, 43204), (43232, 43249), (43302, 43309), (43335,\n-    43347), (43392, 43395), (43443, 43456), (43493, 43493), (43561, 43574),\n-    (43587, 43587), (43596, 43597), (43643, 43645), (43696, 43696), (43698,\n-    43700), (43703, 43704), (43710, 43711), (43713, 43713), (43755, 43759),\n-    (43765, 43766), (44003, 44010), (44012, 44013), (55216, 55295), (64286,\n-    64286), (65024, 65039), (65056, 65069), (65279, 65279), (65529, 65531),\n-    (66045, 66045), (66272, 66272), (66422, 66426), (68097, 68099), (68101,\n-    68102), (68108, 68111), (68152, 68154), (68159, 68159), (68325, 68326),\n-    (69632, 69634), (69688, 69702), (69759, 69762), (69808, 69818), (69821,\n-    69821), (69888, 69890), (69927, 69940), (70003, 70003), (70016, 70018),\n-    (70067, 70080), (70188, 70199), (70367, 70378), (70401, 70403), (70460,\n-    70460), (70462, 70468), (70471, 70472), (70475, 70477), (70487, 70487),\n-    (70498, 70499), (70502, 70508), (70512, 70516), (70832, 70851), (71087,\n-    71093), (71096, 71104), (71216, 71232), (71339, 71351), (92912, 92916),\n-    (92976, 92982), (94033, 94078), (94095, 94098), (113821, 113822), (\n-    113824, 113827), (119141, 119145), (119149, 119170), (119173, 119179),\n-    (119210, 119213), (119362, 119364), (125136, 125142), (917505, 917505),\n-    (917536, 917631), (917760, 917999)), '8.0.0': ((0, 0), (173, 173), (768,\n-    879), (1155, 1161), (1425, 1469), (1471, 1471), (1473, 1474), (1476, \n-    1477), (1479, 1479), (1536, 1541), (1552, 1562), (1564, 1564), (1611, \n-    1631), (1648, 1648), (1750, 1757), (1759, 1764), (1767, 1768), (1770, \n-    1773), (1807, 1807), (1809, 1809), (1840, 1866), (1958, 1968), (2027, \n-    2035), (2070, 2073), (2075, 2083), (2085, 2087), (2089, 2093), (2137, \n-    2139), (2275, 2307), (2362, 2364), (2366, 2383), (2385, 2391), (2402, \n-    2403), (2433, 2435), (2492, 2492), (2494, 2500), (2503, 2504), (2507, \n-    2509), (2519, 2519), (2530, 2531), (2561, 2563), (2620, 2620), (2622, \n-    2626), (2631, 2632), (2635, 2637), (2641, 2641), (2672, 2673), (2677, \n-    2677), (2689, 2691), (2748, 2748), (2750, 2757), (2759, 2761), (2763, \n-    2765), (2786, 2787), (2817, 2819), (2876, 2876), (2878, 2884), (2887, \n-    2888), (2891, 2893), (2902, 2903), (2914, 2915), (2946, 2946), (3006, \n-    3010), (3014, 3016), (3018, 3021), (3031, 3031), (3072, 3075), (3134, \n-    3140), (3142, 3144), (3146, 3149), (3157, 3158), (3170, 3171), (3201, \n-    3203), (3260, 3260), (3262, 3268), (3270, 3272), (3274, 3277), (3285, \n-    3286), (3298, 3299), (3329, 3331), (3390, 3396), (3398, 3400), (3402, \n-    3405), (3415, 3415), (3426, 3427), (3458, 3459), (3530, 3530), (3535, \n-    3540), (3542, 3542), (3544, 3551), (3570, 3571), (3633, 3633), (3636, \n-    3642), (3655, 3662), (3761, 3761), (3764, 3769), (3771, 3772), (3784, \n-    3789), (3864, 3865), (3893, 3893), (3895, 3895), (3897, 3897), (3902, \n-    3903), (3953, 3972), (3974, 3975), (3981, 3991), (3993, 4028), (4038, \n-    4038), (4139, 4158), (4182, 4185), (4190, 4192), (4194, 4196), (4199, \n-    4205), (4209, 4212), (4226, 4237), (4239, 4239), (4250, 4253), (4448, \n-    4607), (4957, 4959), (5906, 5908), (5938, 5940), (5970, 5971), (6002, \n-    6003), (6068, 6099), (6109, 6109), (6155, 6158), (6313, 6313), (6432, \n-    6443), (6448, 6459), (6679, 6683), (6741, 6750), (6752, 6780), (6783, \n-    6783), (6832, 6846), (6912, 6916), (6964, 6980), (7019, 7027), (7040, \n-    7042), (7073, 7085), (7142, 7155), (7204, 7223), (7376, 7378), (7380, \n-    7400), (7405, 7405), (7410, 7412), (7416, 7417), (7616, 7669), (7676, \n-    7679), (8203, 8207), (8232, 8238), (8288, 8292), (8294, 8303), (8400, \n-    8432), (11503, 11505), (11647, 11647), (11744, 11775), (12330, 12335),\n-    (12441, 12442), (42607, 42610), (42612, 42621), (42654, 42655), (42736,\n-    42737), (43010, 43010), (43014, 43014), (43019, 43019), (43043, 43047),\n-    (43136, 43137), (43188, 43204), (43232, 43249), (43302, 43309), (43335,\n-    43347), (43392, 43395), (43443, 43456), (43493, 43493), (43561, 43574),\n-    (43587, 43587), (43596, 43597), (43643, 43645), (43696, 43696), (43698,\n-    43700), (43703, 43704), (43710, 43711), (43713, 43713), (43755, 43759),\n-    (43765, 43766), (44003, 44010), (44012, 44013), (55216, 55295), (64286,\n-    64286), (65024, 65039), (65056, 65071), (65279, 65279), (65529, 65531),\n-    (66045, 66045), (66272, 66272), (66422, 66426), (68097, 68099), (68101,\n-    68102), (68108, 68111), (68152, 68154), (68159, 68159), (68325, 68326),\n-    (69632, 69634), (69688, 69702), (69759, 69762), (69808, 69818), (69821,\n-    69821), (69888, 69890), (69927, 69940), (70003, 70003), (70016, 70018),\n-    (70067, 70080), (70090, 70092), (70188, 70199), (70367, 70378), (70400,\n-    70403), (70460, 70460), (70462, 70468), (70471, 70472), (70475, 70477),\n-    (70487, 70487), (70498, 70499), (70502, 70508), (70512, 70516), (70832,\n-    70851), (71087, 71093), (71096, 71104), (71132, 71133), (71216, 71232),\n-    (71339, 71351), (71453, 71467), (92912, 92916), (92976, 92982), (94033,\n-    94078), (94095, 94098), (113821, 113822), (113824, 113827), (119141, \n-    119145), (119149, 119170), (119173, 119179), (119210, 119213), (119362,\n-    119364), (121344, 121398), (121403, 121452), (121461, 121461), (121476,\n-    121476), (121499, 121503), (121505, 121519), (125136, 125142), (127995,\n-    127999), (917505, 917505), (917536, 917631), (917760, 917999)), '9.0.0':\n-    ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, \n-    1471), (1473, 1474), (1476, 1477), (1479, 1479), (1536, 1541), (1552, \n-    1562), (1564, 1564), (1611, 1631), (1648, 1648), (1750, 1757), (1759, \n-    1764), (1767, 1768), (1770, 1773), (1807, 1807), (1809, 1809), (1840, \n-    1866), (1958, 1968), (2027, 2035), (2070, 2073), (2075, 2083), (2085, \n-    2087), (2089, 2093), (2137, 2139), (2260, 2307), (2362, 2364), (2366, \n-    2383), (2385, 2391), (2402, 2403), (2433, 2435), (2492, 2492), (2494, \n-    2500), (2503, 2504), (2507, 2509), (2519, 2519), (2530, 2531), (2561, \n-    2563), (2620, 2620), (2622, 2626), (2631, 2632), (2635, 2637), (2641, \n-    2641), (2672, 2673), (2677, 2677), (2689, 2691), (2748, 2748), (2750, \n-    2757), (2759, 2761), (2763, 2765), (2786, 2787), (2817, 2819), (2876, \n-    2876), (2878, 2884), (2887, 2888), (2891, 2893), (2902, 2903), (2914, \n-    2915), (2946, 2946), (3006, 3010), (3014, 3016), (3018, 3021), (3031, \n-    3031), (3072, 3075), (3134, 3140), (3142, 3144), (3146, 3149), (3157, \n-    3158), (3170, 3171), (3201, 3203), (3260, 3260), (3262, 3268), (3270, \n-    3272), (3274, 3277), (3285, 3286), (3298, 3299), (3329, 3331), (3390, \n-    3396), (3398, 3400), (3402, 3405), (3415, 3415), (3426, 3427), (3458, \n-    3459), (3530, 3530), (3535, 3540), (3542, 3542), (3544, 3551), (3570, \n-    3571), (3633, 3633), (3636, 3642), (3655, 3662), (3761, 3761), (3764, \n-    3769), (3771, 3772), (3784, 3789), (3864, 3865), (3893, 3893), (3895, \n-    3895), (3897, 3897), (3902, 3903), (3953, 3972), (3974, 3975), (3981, \n-    3991), (3993, 4028), (4038, 4038), (4139, 4158), (4182, 4185), (4190, \n-    4192), (4194, 4196), (4199, 4205), (4209, 4212), (4226, 4237), (4239, \n-    4239), (4250, 4253), (4448, 4607), (4957, 4959), (5906, 5908), (5938, \n-    5940), (5970, 5971), (6002, 6003), (6068, 6099), (6109, 6109), (6155, \n-    6158), (6277, 6278), (6313, 6313), (6432, 6443), (6448, 6459), (6679, \n-    6683), (6741, 6750), (6752, 6780), (6783, 6783), (6832, 6846), (6912, \n-    6916), (6964, 6980), (7019, 7027), (7040, 7042), (7073, 7085), (7142, \n-    7155), (7204, 7223), (7376, 7378), (7380, 7400), (7405, 7405), (7410, \n-    7412), (7416, 7417), (7616, 7669), (7675, 7679), (8203, 8207), (8232, \n-    8238), (8288, 8292), (8294, 8303), (8400, 8432), (11503, 11505), (11647,\n-    11647), (11744, 11775), (12330, 12335), (12441, 12442), (42607, 42610),\n-    (42612, 42621), (42654, 42655), (42736, 42737), (43010, 43010), (43014,\n-    43014), (43019, 43019), (43043, 43047), (43136, 43137), (43188, 43205),\n-    (43232, 43249), (43302, 43309), (43335, 43347), (43392, 43395), (43443,\n-    43456), (43493, 43493), (43561, 43574), (43587, 43587), (43596, 43597),\n-    (43643, 43645), (43696, 43696), (43698, 43700), (43703, 43704), (43710,\n-    43711), (43713, 43713), (43755, 43759), (43765, 43766), (44003, 44010),\n-    (44012, 44013), (55216, 55295), (64286, 64286), (65024, 65039), (65056,\n-    65071), (65279, 65279), (65529, 65531), (66045, 66045), (66272, 66272),\n-    (66422, 66426), (68097, 68099), (68101, 68102), (68108, 68111), (68152,\n-    68154), (68159, 68159), (68325, 68326), (69632, 69634), (69688, 69702),\n-    (69759, 69762), (69808, 69818), (69821, 69821), (69888, 69890), (69927,\n-    69940), (70003, 70003), (70016, 70018), (70067, 70080), (70090, 70092),\n-    (70188, 70199), (70206, 70206), (70367, 70378), (70400, 70403), (70460,\n-    70460), (70462, 70468), (70471, 70472), (70475, 70477), (70487, 70487),\n-    (70498, 70499), (70502, 70508), (70512, 70516), (70709, 70726), (70832,\n-    70851), (71087, 71093), (71096, 71104), (71132, 71133), (71216, 71232),\n-    (71339, 71351), (71453, 71467), (72751, 72758), (72760, 72767), (72850,\n-    72871), (72873, 72886), (92912, 92916), (92976, 92982), (94033, 94078),\n-    (94095, 94098), (113821, 113822), (113824, 113827), (119141, 119145), (\n-    119149, 119170), (119173, 119179), (119210, 119213), (119362, 119364),\n-    (121344, 121398), (121403, 121452), (121461, 121461), (121476, 121476),\n-    (121499, 121503), (121505, 121519), (122880, 122886), (122888, 122904),\n-    (122907, 122913), (122915, 122916), (122918, 122922), (125136, 125142),\n-    (125252, 125258), (127995, 127999), (917505, 917505), (917536, 917631),\n-    (917760, 917999)), '10.0.0': ((0, 0), (173, 173), (768, 879), (1155, \n-    1161), (1425, 1469), (1471, 1471), (1473, 1474), (1476, 1477), (1479, \n-    1479), (1536, 1541), (1552, 1562), (1564, 1564), (1611, 1631), (1648, \n-    1648), (1750, 1757), (1759, 1764), (1767, 1768), (1770, 1773), (1807, \n-    1807), (1809, 1809), (1840, 1866), (1958, 1968), (2027, 2035), (2070, \n-    2073), (2075, 2083), (2085, 2087), (2089, 2093), (2137, 2139), (2260, \n-    2307), (2362, 2364), (2366, 2383), (2385, 2391), (2402, 2403), (2433, \n-    2435), (2492, 2492), (2494, 2500), (2503, 2504), (2507, 2509), (2519, \n-    2519), (2530, 2531), (2561, 2563), (2620, 2620), (2622, 2626), (2631, \n-    2632), (2635, 2637), (2641, 2641), (2672, 2673), (2677, 2677), (2689, \n-    2691), (2748, 2748), (2750, 2757), (2759, 2761), (2763, 2765), (2786, \n-    2787), (2810, 2815), (2817, 2819), (2876, 2876), (2878, 2884), (2887, \n-    2888), (2891, 2893), (2902, 2903), (2914, 2915), (2946, 2946), (3006, \n-    3010), (3014, 3016), (3018, 3021), (3031, 3031), (3072, 3075), (3134, \n-    3140), (3142, 3144), (3146, 3149), (3157, 3158), (3170, 3171), (3201, \n-    3203), (3260, 3260), (3262, 3268), (3270, 3272), (3274, 3277), (3285, \n-    3286), (3298, 3299), (3328, 3331), (3387, 3388), (3390, 3396), (3398, \n-    3400), (3402, 3405), (3415, 3415), (3426, 3427), (3458, 3459), (3530, \n-    3530), (3535, 3540), (3542, 3542), (3544, 3551), (3570, 3571), (3633, \n-    3633), (3636, 3642), (3655, 3662), (3761, 3761), (3764, 3769), (3771, \n-    3772), (3784, 3789), (3864, 3865), (3893, 3893), (3895, 3895), (3897, \n-    3897), (3902, 3903), (3953, 3972), (3974, 3975), (3981, 3991), (3993, \n-    4028), (4038, 4038), (4139, 4158), (4182, 4185), (4190, 4192), (4194, \n-    4196), (4199, 4205), (4209, 4212), (4226, 4237), (4239, 4239), (4250, \n-    4253), (4448, 4607), (4957, 4959), (5906, 5908), (5938, 5940), (5970, \n-    5971), (6002, 6003), (6068, 6099), (6109, 6109), (6155, 6158), (6277, \n-    6278), (6313, 6313), (6432, 6443), (6448, 6459), (6679, 6683), (6741, \n-    6750), (6752, 6780), (6783, 6783), (6832, 6846), (6912, 6916), (6964, \n-    6980), (7019, 7027), (7040, 7042), (7073, 7085), (7142, 7155), (7204, \n-    7223), (7376, 7378), (7380, 7400), (7405, 7405), (7410, 7412), (7415, \n-    7417), (7616, 7673), (7675, 7679), (8203, 8207), (8232, 8238), (8288, \n-    8292), (8294, 8303), (8400, 8432), (11503, 11505), (11647, 11647), (\n-    11744, 11775), (12330, 12335), (12441, 12442), (42607, 42610), (42612, \n-    42621), (42654, 42655), (42736, 42737), (43010, 43010), (43014, 43014),\n-    (43019, 43019), (43043, 43047), (43136, 43137), (43188, 43205), (43232,\n-    43249), (43302, 43309), (43335, 43347), (43392, 43395), (43443, 43456),\n-    (43493, 43493), (43561, 43574), (43587, 43587), (43596, 43597), (43643,\n-    43645), (43696, 43696), (43698, 43700), (43703, 43704), (43710, 43711),\n-    (43713, 43713), (43755, 43759), (43765, 43766), (44003, 44010), (44012,\n-    44013), (55216, 55295), (64286, 64286), (65024, 65039), (65056, 65071),\n-    (65279, 65279), (65529, 65531), (66045, 66045), (66272, 66272), (66422,\n-    66426), (68097, 68099), (68101, 68102), (68108, 68111), (68152, 68154),\n-    (68159, 68159), (68325, 68326), (69632, 69634), (69688, 69702), (69759,\n-    69762), (69808, 69818), (69821, 69821), (69888, 69890), (69927, 69940),\n-    (70003, 70003), (70016, 70018), (70067, 70080), (70090, 70092), (70188,\n-    70199), (70206, 70206), (70367, 70378), (70400, 70403), (70460, 70460),\n-    (70462, 70468), (70471, 70472), (70475, 70477), (70487, 70487), (70498,\n-    70499), (70502, 70508), (70512, 70516), (70709, 70726), (70832, 70851),\n-    (71087, 71093), (71096, 71104), (71132, 71133), (71216, 71232), (71339,\n-    71351), (71453, 71467), (72193, 72202), (72243, 72249), (72251, 72254),\n-    (72263, 72263), (72273, 72283), (72330, 72345), (72751, 72758), (72760,\n-    72767), (72850, 72871), (72873, 72886), (73009, 73014), (73018, 73018),\n-    (73020, 73021), (73023, 73029), (73031, 73031), (92912, 92916), (92976,\n-    92982), (94033, 94078), (94095, 94098), (113821, 113822), (113824, \n-    113827), (119141, 119145), (119149, 119170), (119173, 119179), (119210,\n-    119213), (119362, 119364), (121344, 121398), (121403, 121452), (121461,\n-    121461), (121476, 121476), (121499, 121503), (121505, 121519), (122880,\n-    122886), (122888, 122904), (122907, 122913), (122915, 122916), (122918,\n-    122922), (125136, 125142), (125252, 125258), (127995, 127999), (917505,\n-    917505), (917536, 917631), (917760, 917999)), '11.0.0': ((0, 0), (173, \n-    173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), (1473, 1474\n-    ), (1476, 1477), (1479, 1479), (1536, 1541), (1552, 1562), (1564, 1564),\n-    (1611, 1631), (1648, 1648), (1750, 1757), (1759, 1764), (1767, 1768), (\n-    1770, 1773), (1807, 1807), (1809, 1809), (1840, 1866), (1958, 1968), (\n-    2027, 2035), (2045, 2045), (2070, 2073), (2075, 2083), (2085, 2087), (\n-    2089, 2093), (2137, 2139), (2259, 2307), (2362, 2364), (2366, 2383), (\n-    2385, 2391), (2402, 2403), (2433, 2435), (2492, 2492), (2494, 2500), (\n-    2503, 2504), (2507, 2509), (2519, 2519), (2530, 2531), (2558, 2558), (\n-    2561, 2563), (2620, 2620), (2622, 2626), (2631, 2632), (2635, 2637), (\n-    2641, 2641), (2672, 2673), (2677, 2677), (2689, 2691), (2748, 2748), (\n-    2750, 2757), (2759, 2761), (2763, 2765), (2786, 2787), (2810, 2815), (\n-    2817, 2819), (2876, 2876), (2878, 2884), (2887, 2888), (2891, 2893), (\n-    2902, 2903), (2914, 2915), (2946, 2946), (3006, 3010), (3014, 3016), (\n-    3018, 3021), (3031, 3031), (3072, 3076), (3134, 3140), (3142, 3144), (\n-    3146, 3149), (3157, 3158), (3170, 3171), (3201, 3203), (3260, 3260), (\n-    3262, 3268), (3270, 3272), (3274, 3277), (3285, 3286), (3298, 3299), (\n-    3328, 3331), (3387, 3388), (3390, 3396), (3398, 3400), (3402, 3405), (\n-    3415, 3415), (3426, 3427), (3458, 3459), (3530, 3530), (3535, 3540), (\n-    3542, 3542), (3544, 3551), (3570, 3571), (3633, 3633), (3636, 3642), (\n-    3655, 3662), (3761, 3761), (3764, 3769), (3771, 3772), (3784, 3789), (\n-    3864, 3865), (3893, 3893), (3895, 3895), (3897, 3897), (3902, 3903), (\n-    3953, 3972), (3974, 3975), (3981, 3991), (3993, 4028), (4038, 4038), (\n-    4139, 4158), (4182, 4185), (4190, 4192), (4194, 4196), (4199, 4205), (\n-    4209, 4212), (4226, 4237), (4239, 4239), (4250, 4253), (4448, 4607), (\n-    4957, 4959), (5906, 5908), (5938, 5940), (5970, 5971), (6002, 6003), (\n-    6068, 6099), (6109, 6109), (6155, 6158), (6277, 6278), (6313, 6313), (\n-    6432, 6443), (6448, 6459), (6679, 6683), (6741, 6750), (6752, 6780), (\n-    6783, 6783), (6832, 6846), (6912, 6916), (6964, 6980), (7019, 7027), (\n-    7040, 7042), (7073, 7085), (7142, 7155), (7204, 7223), (7376, 7378), (\n-    7380, 7400), (7405, 7405), (7410, 7412), (7415, 7417), (7616, 7673), (\n-    7675, 7679), (8203, 8207), (8232, 8238), (8288, 8292), (8294, 8303), (\n-    8400, 8432), (11503, 11505), (11647, 11647), (11744, 11775), (12330, \n-    12335), (12441, 12442), (42607, 42610), (42612, 42621), (42654, 42655),\n-    (42736, 42737), (43010, 43010), (43014, 43014), (43019, 43019), (43043,\n-    43047), (43136, 43137), (43188, 43205), (43232, 43249), (43263, 43263),\n-    (43302, 43309), (43335, 43347), (43392, 43395), (43443, 43456), (43493,\n-    43493), (43561, 43574), (43587, 43587), (43596, 43597), (43643, 43645),\n-    (43696, 43696), (43698, 43700), (43703, 43704), (43710, 43711), (43713,\n-    43713), (43755, 43759), (43765, 43766), (44003, 44010), (44012, 44013),\n-    (55216, 55295), (64286, 64286), (65024, 65039), (65056, 65071), (65279,\n-    65279), (65529, 65531), (66045, 66045), (66272, 66272), (66422, 66426),\n-    (68097, 68099), (68101, 68102), (68108, 68111), (68152, 68154), (68159,\n-    68159), (68325, 68326), (68900, 68903), (69446, 69456), (69632, 69634),\n-    (69688, 69702), (69759, 69762), (69808, 69818), (69821, 69821), (69837,\n-    69837), (69888, 69890), (69927, 69940), (69957, 69958), (70003, 70003),\n-    (70016, 70018), (70067, 70080), (70089, 70092), (70188, 70199), (70206,\n-    70206), (70367, 70378), (70400, 70403), (70459, 70460), (70462, 70468),\n-    (70471, 70472), (70475, 70477), (70487, 70487), (70498, 70499), (70502,\n-    70508), (70512, 70516), (70709, 70726), (70750, 70750), (70832, 70851),\n-    (71087, 71093), (71096, 71104), (71132, 71133), (71216, 71232), (71339,\n-    71351), (71453, 71467), (71724, 71738), (72193, 72202), (72243, 72249),\n-    (72251, 72254), (72263, 72263), (72273, 72283), (72330, 72345), (72751,\n-    72758), (72760, 72767), (72850, 72871), (72873, 72886), (73009, 73014),\n-    (73018, 73018), (73020, 73021), (73023, 73029), (73031, 73031), (73098,\n-    73102), (73104, 73105), (73107, 73111), (73459, 73462), (92912, 92916),\n-    (92976, 92982), (94033, 94078), (94095, 94098), (113821, 113822), (\n-    113824, 113827), (119141, 119145), (119149, 119170), (119173, 119179),\n-    (119210, 119213), (119362, 119364), (121344, 121398), (121403, 121452),\n-    (121461, 121461), (121476, 121476), (121499, 121503), (121505, 121519),\n-    (122880, 122886), (122888, 122904), (122907, 122913), (122915, 122916),\n-    (122918, 122922), (125136, 125142), (125252, 125258), (127995, 127999),\n-    (917505, 917505), (917536, 917631), (917760, 917999)), '12.0.0': ((0, 0\n-    ), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), (\n-    1473, 1474), (1476, 1477), (1479, 1479), (1536, 1541), (1552, 1562), (\n-    1564, 1564), (1611, 1631), (1648, 1648), (1750, 1757), (1759, 1764), (\n-    1767, 1768), (1770, 1773), (1807, 1807), (1809, 1809), (1840, 1866), (\n-    1958, 1968), (2027, 2035), (2045, 2045), (2070, 2073), (2075, 2083), (\n-    2085, 2087), (2089, 2093), (2137, 2139), (2259, 2307), (2362, 2364), (\n-    2366, 2383), (2385, 2391), (2402, 2403), (2433, 2435), (2492, 2492), (\n-    2494, 2500), (2503, 2504), (2507, 2509), (2519, 2519), (2530, 2531), (\n-    2558, 2558), (2561, 2563), (2620, 2620), (2622, 2626), (2631, 2632), (\n-    2635, 2637), (2641, 2641), (2672, 2673), (2677, 2677), (2689, 2691), (\n-    2748, 2748), (2750, 2757), (2759, 2761), (2763, 2765), (2786, 2787), (\n-    2810, 2815), (2817, 2819), (2876, 2876), (2878, 2884), (2887, 2888), (\n-    2891, 2893), (2902, 2903), (2914, 2915), (2946, 2946), (3006, 3010), (\n-    3014, 3016), (3018, 3021), (3031, 3031), (3072, 3076), (3134, 3140), (\n-    3142, 3144), (3146, 3149), (3157, 3158), (3170, 3171), (3201, 3203), (\n-    3260, 3260), (3262, 3268), (3270, 3272), (3274, 3277), (3285, 3286), (\n-    3298, 3299), (3328, 3331), (3387, 3388), (3390, 3396), (3398, 3400), (\n-    3402, 3405), (3415, 3415), (3426, 3427), (3458, 3459), (3530, 3530), (\n-    3535, 3540), (3542, 3542), (3544, 3551), (3570, 3571), (3633, 3633), (\n-    3636, 3642), (3655, 3662), (3761, 3761), (3764, 3772), (3784, 3789), (\n-    3864, 3865), (3893, 3893), (3895, 3895), (3897, 3897), (3902, 3903), (\n-    3953, 3972), (3974, 3975), (3981, 3991), (3993, 4028), (4038, 4038), (\n-    4139, 4158), (4182, 4185), (4190, 4192), (4194, 4196), (4199, 4205), (\n-    4209, 4212), (4226, 4237), (4239, 4239), (4250, 4253), (4448, 4607), (\n-    4957, 4959), (5906, 5908), (5938, 5940), (5970, 5971), (6002, 6003), (\n-    6068, 6099), (6109, 6109), (6155, 6158), (6277, 6278), (6313, 6313), (\n-    6432, 6443), (6448, 6459), (6679, 6683), (6741, 6750), (6752, 6780), (\n-    6783, 6783), (6832, 6846), (6912, 6916), (6964, 6980), (7019, 7027), (\n-    7040, 7042), (7073, 7085), (7142, 7155), (7204, 7223), (7376, 7378), (\n-    7380, 7400), (7405, 7405), (7412, 7412), (7415, 7417), (7616, 7673), (\n-    7675, 7679), (8203, 8207), (8232, 8238), (8288, 8292), (8294, 8303), (\n-    8400, 8432), (11503, 11505), (11647, 11647), (11744, 11775), (12330, \n-    12335), (12441, 12442), (42607, 42610), (42612, 42621), (42654, 42655),\n-    (42736, 42737), (43010, 43010), (43014, 43014), (43019, 43019), (43043,\n-    43047), (43136, 43137), (43188, 43205), (43232, 43249), (43263, 43263),\n-    (43302, 43309), (43335, 43347), (43392, 43395), (43443, 43456), (43493,\n-    43493), (43561, 43574), (43587, 43587), (43596, 43597), (43643, 43645),\n-    (43696, 43696), (43698, 43700), (43703, 43704), (43710, 43711), (43713,\n-    43713), (43755, 43759), (43765, 43766), (44003, 44010), (44012, 44013),\n-    (55216, 55295), (64286, 64286), (65024, 65039), (65056, 65071), (65279,\n-    65279), (65529, 65531), (66045, 66045), (66272, 66272), (66422, 66426),\n-    (68097, 68099), (68101, 68102), (68108, 68111), (68152, 68154), (68159,\n-    68159), (68325, 68326), (68900, 68903), (69446, 69456), (69632, 69634),\n-    (69688, 69702), (69759, 69762), (69808, 69818), (69821, 69821), (69837,\n-    69837), (69888, 69890), (69927, 69940), (69957, 69958), (70003, 70003),\n-    (70016, 70018), (70067, 70080), (70089, 70092), (70188, 70199), (70206,\n-    70206), (70367, 70378), (70400, 70403), (70459, 70460), (70462, 70468),\n-    (70471, 70472), (70475, 70477), (70487, 70487), (70498, 70499), (70502,\n-    70508), (70512, 70516), (70709, 70726), (70750, 70750), (70832, 70851),\n-    (71087, 71093), (71096, 71104), (71132, 71133), (71216, 71232), (71339,\n-    71351), (71453, 71467), (71724, 71738), (72145, 72151), (72154, 72160),\n-    (72164, 72164), (72193, 72202), (72243, 72249), (72251, 72254), (72263,\n-    72263), (72273, 72283), (72330, 72345), (72751, 72758), (72760, 72767),\n-    (72850, 72871), (72873, 72886), (73009, 73014), (73018, 73018), (73020,\n-    73021), (73023, 73029), (73031, 73031), (73098, 73102), (73104, 73105),\n-    (73107, 73111), (73459, 73462), (78896, 78904), (92912, 92916), (92976,\n-    92982), (94031, 94031), (94033, 94087), (94095, 94098), (113821, 113822\n-    ), (113824, 113827), (119141, 119145), (119149, 119170), (119173, \n-    119179), (119210, 119213), (119362, 119364), (121344, 121398), (121403,\n-    121452), (121461, 121461), (121476, 121476), (121499, 121503), (121505,\n-    121519), (122880, 122886), (122888, 122904), (122907, 122913), (122915,\n-    122916), (122918, 122922), (123184, 123190), (123628, 123631), (125136,\n-    125142), (125252, 125258), (127995, 127999), (917505, 917505), (917536,\n-    917631), (917760, 917999)), '12.1.0': ((0, 0), (173, 173), (768, 879),\n-    (1155, 1161), (1425, 1469), (1471, 1471), (1473, 1474), (1476, 1477), (\n-    1479, 1479), (1536, 1541), (1552, 1562), (1564, 1564), (1611, 1631), (\n-    1648, 1648), (1750, 1757), (1759, 1764), (1767, 1768), (1770, 1773), (\n-    1807, 1807), (1809, 1809), (1840, 1866), (1958, 1968), (2027, 2035), (\n-    2045, 2045), (2070, 2073), (2075, 2083), (2085, 2087), (2089, 2093), (\n-    2137, 2139), (2259, 2307), (2362, 2364), (2366, 2383), (2385, 2391), (\n-    2402, 2403), (2433, 2435), (2492, 2492), (2494, 2500), (2503, 2504), (\n-    2507, 2509), (2519, 2519), (2530, 2531), (2558, 2558), (2561, 2563), (\n-    2620, 2620), (2622, 2626), (2631, 2632), (2635, 2637), (2641, 2641), (\n-    2672, 2673), (2677, 2677), (2689, 2691), (2748, 2748), (2750, 2757), (\n-    2759, 2761), (2763, 2765), (2786, 2787), (2810, 2815), (2817, 2819), (\n-    2876, 2876), (2878, 2884), (2887, 2888), (2891, 2893), (2902, 2903), (\n-    2914, 2915), (2946, 2946), (3006, 3010), (3014, 3016), (3018, 3021), (\n-    3031, 3031), (3072, 3076), (3134, 3140), (3142, 3144), (3146, 3149), (\n-    3157, 3158), (3170, 3171), (3201, 3203), (3260, 3260), (3262, 3268), (\n-    3270, 3272), (3274, 3277), (3285, 3286), (3298, 3299), (3328, 3331), (\n-    3387, 3388), (3390, 3396), (3398, 3400), (3402, 3405), (3415, 3415), (\n-    3426, 3427), (3458, 3459), (3530, 3530), (3535, 3540), (3542, 3542), (\n-    3544, 3551), (3570, 3571), (3633, 3633), (3636, 3642), (3655, 3662), (\n-    3761, 3761), (3764, 3772), (3784, 3789), (3864, 3865), (3893, 3893), (\n-    3895, 3895), (3897, 3897), (3902, 3903), (3953, 3972), (3974, 3975), (\n-    3981, 3991), (3993, 4028), (4038, 4038), (4139, 4158), (4182, 4185), (\n-    4190, 4192), (4194, 4196), (4199, 4205), (4209, 4212), (4226, 4237), (\n-    4239, 4239), (4250, 4253), (4448, 4607), (4957, 4959), (5906, 5908), (\n-    5938, 5940), (5970, 5971), (6002, 6003), (6068, 6099), (6109, 6109), (\n-    6155, 6158), (6277, 6278), (6313, 6313), (6432, 6443), (6448, 6459), (\n-    6679, 6683), (6741, 6750), (6752, 6780), (6783, 6783), (6832, 6846), (\n-    6912, 6916), (6964, 6980), (7019, 7027), (7040, 7042), (7073, 7085), (\n-    7142, 7155), (7204, 7223), (7376, 7378), (7380, 7400), (7405, 7405), (\n-    7412, 7412), (7415, 7417), (7616, 7673), (7675, 7679), (8203, 8207), (\n-    8232, 8238), (8288, 8292), (8294, 8303), (8400, 8432), (11503, 11505),\n-    (11647, 11647), (11744, 11775), (12330, 12335), (12441, 12442), (42607,\n-    42610), (42612, 42621), (42654, 42655), (42736, 42737), (43010, 43010),\n-    (43014, 43014), (43019, 43019), (43043, 43047), (43136, 43137), (43188,\n-    43205), (43232, 43249), (43263, 43263), (43302, 43309), (43335, 43347),\n-    (43392, 43395), (43443, 43456), (43493, 43493), (43561, 43574), (43587,\n-    43587), (43596, 43597), (43643, 43645), (43696, 43696), (43698, 43700),\n-    (43703, 43704), (43710, 43711), (43713, 43713), (43755, 43759), (43765,\n-    43766), (44003, 44010), (44012, 44013), (55216, 55295), (64286, 64286),\n-    (65024, 65039), (65056, 65071), (65279, 65279), (65529, 65531), (66045,\n-    66045), (66272, 66272), (66422, 66426), (68097, 68099), (68101, 68102),\n-    (68108, 68111), (68152, 68154), (68159, 68159), (68325, 68326), (68900,\n-    68903), (69446, 69456), (69632, 69634), (69688, 69702), (69759, 69762),\n-    (69808, 69818), (69821, 69821), (69837, 69837), (69888, 69890), (69927,\n-    69940), (69957, 69958), (70003, 70003), (70016, 70018), (70067, 70080),\n-    (70089, 70092), (70188, 70199), (70206, 70206), (70367, 70378), (70400,\n-    70403), (70459, 70460), (70462, 70468), (70471, 70472), (70475, 70477),\n-    (70487, 70487), (70498, 70499), (70502, 70508), (70512, 70516), (70709,\n-    70726), (70750, 70750), (70832, 70851), (71087, 71093), (71096, 71104),\n-    (71132, 71133), (71216, 71232), (71339, 71351), (71453, 71467), (71724,\n-    71738), (72145, 72151), (72154, 72160), (72164, 72164), (72193, 72202),\n-    (72243, 72249), (72251, 72254), (72263, 72263), (72273, 72283), (72330,\n-    72345), (72751, 72758), (72760, 72767), (72850, 72871), (72873, 72886),\n-    (73009, 73014), (73018, 73018), (73020, 73021), (73023, 73029), (73031,\n-    73031), (73098, 73102), (73104, 73105), (73107, 73111), (73459, 73462),\n-    (78896, 78904), (92912, 92916), (92976, 92982), (94031, 94031), (94033,\n-    94087), (94095, 94098), (113821, 113822), (113824, 113827), (119141, \n-    119145), (119149, 119170), (119173, 119179), (119210, 119213), (119362,\n-    119364), (121344, 121398), (121403, 121452), (121461, 121461), (121476,\n-    121476), (121499, 121503), (121505, 121519), (122880, 122886), (122888,\n-    122904), (122907, 122913), (122915, 122916), (122918, 122922), (123184,\n-    123190), (123628, 123631), (125136, 125142), (125252, 125258), (127995,\n-    127999), (917505, 917505), (917536, 917631), (917760, 917999)),\n-    '13.0.0': ((0, 0), (173, 173), (768, 879), (1155, 1161), (1425, 1469),\n-    (1471, 1471), (1473, 1474), (1476, 1477), (1479, 1479), (1536, 1541), (\n-    1552, 1562), (1564, 1564), (1611, 1631), (1648, 1648), (1750, 1757), (\n-    1759, 1764), (1767, 1768), (1770, 1773), (1807, 1807), (1809, 1809), (\n-    1840, 1866), (1958, 1968), (2027, 2035), (2045, 2045), (2070, 2073), (\n-    2075, 2083), (2085, 2087), (2089, 2093), (2137, 2139), (2259, 2307), (\n-    2362, 2364), (2366, 2383), (2385, 2391), (2402, 2403), (2433, 2435), (\n-    2492, 2492), (2494, 2500), (2503, 2504), (2507, 2509), (2519, 2519), (\n-    2530, 2531), (2558, 2558), (2561, 2563), (2620, 2620), (2622, 2626), (\n-    2631, 2632), (2635, 2637), (2641, 2641), (2672, 2673), (2677, 2677), (\n-    2689, 2691), (2748, 2748), (2750, 2757), (2759, 2761), (2763, 2765), (\n-    2786, 2787), (2810, 2815), (2817, 2819), (2876, 2876), (2878, 2884), (\n-    2887, 2888), (2891, 2893), (2901, 2903), (2914, 2915), (2946, 2946), (\n-    3006, 3010), (3014, 3016), (3018, 3021), (3031, 3031), (3072, 3076), (\n-    3134, 3140), (3142, 3144), (3146, 3149), (3157, 3158), (3170, 3171), (\n-    3201, 3203), (3260, 3260), (3262, 3268), (3270, 3272), (3274, 3277), (\n-    3285, 3286), (3298, 3299), (3328, 3331), (3387, 3388), (3390, 3396), (\n-    3398, 3400), (3402, 3405), (3415, 3415), (3426, 3427), (3457, 3459), (\n-    3530, 3530), (3535, 3540), (3542, 3542), (3544, 3551), (3570, 3571), (\n-    3633, 3633), (3636, 3642), (3655, 3662), (3761, 3761), (3764, 3772), (\n-    3784, 3789), (3864, 3865), (3893, 3893), (3895, 3895), (3897, 3897), (\n-    3902, 3903), (3953, 3972), (3974, 3975), (3981, 3991), (3993, 4028), (\n-    4038, 4038), (4139, 4158), (4182, 4185), (4190, 4192), (4194, 4196), (\n-    4199, 4205), (4209, 4212), (4226, 4237), (4239, 4239), (4250, 4253), (\n-    4448, 4607), (4957, 4959), (5906, 5908), (5938, 5940), (5970, 5971), (\n-    6002, 6003), (6068, 6099), (6109, 6109), (6155, 6158), (6277, 6278), (\n-    6313, 6313), (6432, 6443), (6448, 6459), (6679, 6683), (6741, 6750), (\n-    6752, 6780), (6783, 6783), (6832, 6848), (6912, 6916), (6964, 6980), (\n-    7019, 7027), (7040, 7042), (7073, 7085), (7142, 7155), (7204, 7223), (\n-    7376, 7378), (7380, 7400), (7405, 7405), (7412, 7412), (7415, 7417), (\n-    7616, 7673), (7675, 7679), (8203, 8207), (8232, 8238), (8288, 8292), (\n-    8294, 8303), (8400, 8432), (11503, 11505), (11647, 11647), (11744, \n-    11775), (12330, 12335), (12441, 12442), (42607, 42610), (42612, 42621),\n-    (42654, 42655), (42736, 42737), (43010, 43010), (43014, 43014), (43019,\n-    43019), (43043, 43047), (43052, 43052), (43136, 43137), (43188, 43205),\n-    (43232, 43249), (43263, 43263), (43302, 43309), (43335, 43347), (43392,\n-    43395), (43443, 43456), (43493, 43493), (43561, 43574), (43587, 43587),\n-    (43596, 43597), (43643, 43645), (43696, 43696), (43698, 43700), (43703,\n-    43704), (43710, 43711), (43713, 43713), (43755, 43759), (43765, 43766),\n-    (44003, 44010), (44012, 44013), (55216, 55295), (64286, 64286), (65024,\n-    65039), (65056, 65071), (65279, 65279), (65529, 65531), (66045, 66045),\n-    (66272, 66272), (66422, 66426), (68097, 68099), (68101, 68102), (68108,\n-    68111), (68152, 68154), (68159, 68159), (68325, 68326), (68900, 68903),\n-    (69291, 69292), (69446, 69456), (69632, 69634), (69688, 69702), (69759,\n-    69762), (69808, 69818), (69821, 69821), (69837, 69837), (69888, 69890),\n-    (69927, 69940), (69957, 69958), (70003, 70003), (70016, 70018), (70067,\n-    70080), (70089, 70092), (70094, 70095), (70188, 70199), (70206, 70206),\n-    (70367, 70378), (70400, 70403), (70459, 70460), (70462, 70468), (70471,\n-    70472), (70475, 70477), (70487, 70487), (70498, 70499), (70502, 70508),\n-    (70512, 70516), (70709, 70726), (70750, 70750), (70832, 70851), (71087,\n-    71093), (71096, 71104), (71132, 71133), (71216, 71232), (71339, 71351),\n-    (71453, 71467), (71724, 71738), (71984, 71989), (71991, 71992), (71995,\n-    71998), (72000, 72000), (72002, 72003), (72145, 72151), (72154, 72160),\n-    (72164, 72164), (72193, 72202), (72243, 72249), (72251, 72254), (72263,\n-    72263), (72273, 72283), (72330, 72345), (72751, 72758), (72760, 72767),\n-    (72850, 72871), (72873, 72886), (73009, 73014), (73018, 73018), (73020,\n-    73021), (73023, 73029), (73031, 73031), (73098, 73102), (73104, 73105),\n-    (73107, 73111), (73459, 73462), (78896, 78904), (92912, 92916), (92976,\n-    92982), (94031, 94031), (94033, 94087), (94095, 94098), (94180, 94180),\n-    (94192, 94193), (113821, 113822), (113824, 113827), (119141, 119145), (\n-    119149, 119170), (119173, 119179), (119210, 119213), (119362, 119364),\n-    (121344, 121398), (121403, 121452), (121461, 121461), (121476, 121476),\n-    (121499, 121503), (121505, 121519), (122880, 122886), (122888, 122904),\n-    (122907, 122913), (122915, 122916), (122918, 122922), (123184, 123190),\n-    (123628, 123631), (125136, 125142), (125252, 125258), (127995, 127999),\n-    (917505, 917505), (917536, 917631), (917760, 917999)), '14.0.0': ((0, 0\n-    ), (173, 173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), (\n-    1473, 1474), (1476, 1477), (1479, 1479), (1536, 1541), (1552, 1562), (\n-    1564, 1564), (1611, 1631), (1648, 1648), (1750, 1757), (1759, 1764), (\n-    1767, 1768), (1770, 1773), (1807, 1807), (1809, 1809), (1840, 1866), (\n-    1958, 1968), (2027, 2035), (2045, 2045), (2070, 2073), (2075, 2083), (\n-    2085, 2087), (2089, 2093), (2137, 2139), (2192, 2193), (2200, 2207), (\n-    2250, 2307), (2362, 2364), (2366, 2383), (2385, 2391), (2402, 2403), (\n-    2433, 2435), (2492, 2492), (2494, 2500), (2503, 2504), (2507, 2509), (\n-    2519, 2519), (2530, 2531), (2558, 2558), (2561, 2563), (2620, 2620), (\n-    2622, 2626), (2631, 2632), (2635, 2637), (2641, 2641), (2672, 2673), (\n-    2677, 2677), (2689, 2691), (2748, 2748), (2750, 2757), (2759, 2761), (\n-    2763, 2765), (2786, 2787), (2810, 2815), (2817, 2819), (2876, 2876), (\n-    2878, 2884), (2887, 2888), (2891, 2893), (2901, 2903), (2914, 2915), (\n-    2946, 2946), (3006, 3010), (3014, 3016), (3018, 3021), (3031, 3031), (\n-    3072, 3076), (3132, 3132), (3134, 3140), (3142, 3144), (3146, 3149), (\n-    3157, 3158), (3170, 3171), (3201, 3203), (3260, 3260), (3262, 3268), (\n-    3270, 3272), (3274, 3277), (3285, 3286), (3298, 3299), (3328, 3331), (\n-    3387, 3388), (3390, 3396), (3398, 3400), (3402, 3405), (3415, 3415), (\n-    3426, 3427), (3457, 3459), (3530, 3530), (3535, 3540), (3542, 3542), (\n-    3544, 3551), (3570, 3571), (3633, 3633), (3636, 3642), (3655, 3662), (\n-    3761, 3761), (3764, 3772), (3784, 3789), (3864, 3865), (3893, 3893), (\n-    3895, 3895), (3897, 3897), (3902, 3903), (3953, 3972), (3974, 3975), (\n-    3981, 3991), (3993, 4028), (4038, 4038), (4139, 4158), (4182, 4185), (\n-    4190, 4192), (4194, 4196), (4199, 4205), (4209, 4212), (4226, 4237), (\n-    4239, 4239), (4250, 4253), (4448, 4607), (4957, 4959), (5906, 5909), (\n-    5938, 5940), (5970, 5971), (6002, 6003), (6068, 6099), (6109, 6109), (\n-    6155, 6159), (6277, 6278), (6313, 6313), (6432, 6443), (6448, 6459), (\n-    6679, 6683), (6741, 6750), (6752, 6780), (6783, 6783), (6832, 6862), (\n-    6912, 6916), (6964, 6980), (7019, 7027), (7040, 7042), (7073, 7085), (\n-    7142, 7155), (7204, 7223), (7376, 7378), (7380, 7400), (7405, 7405), (\n-    7412, 7412), (7415, 7417), (7616, 7679), (8203, 8207), (8232, 8238), (\n-    8288, 8292), (8294, 8303), (8400, 8432), (11503, 11505), (11647, 11647),\n-    (11744, 11775), (12330, 12335), (12441, 12442), (42607, 42610), (42612,\n-    42621), (42654, 42655), (42736, 42737), (43010, 43010), (43014, 43014),\n-    (43019, 43019), (43043, 43047), (43052, 43052), (43136, 43137), (43188,\n-    43205), (43232, 43249), (43263, 43263), (43302, 43309), (43335, 43347),\n-    (43392, 43395), (43443, 43456), (43493, 43493), (43561, 43574), (43587,\n-    43587), (43596, 43597), (43643, 43645), (43696, 43696), (43698, 43700),\n-    (43703, 43704), (43710, 43711), (43713, 43713), (43755, 43759), (43765,\n-    43766), (44003, 44010), (44012, 44013), (55216, 55295), (64286, 64286),\n-    (65024, 65039), (65056, 65071), (65279, 65279), (65529, 65531), (66045,\n-    66045), (66272, 66272), (66422, 66426), (68097, 68099), (68101, 68102),\n-    (68108, 68111), (68152, 68154), (68159, 68159), (68325, 68326), (68900,\n-    68903), (69291, 69292), (69446, 69456), (69506, 69509), (69632, 69634),\n-    (69688, 69702), (69744, 69744), (69747, 69748), (69759, 69762), (69808,\n-    69818), (69821, 69821), (69826, 69826), (69837, 69837), (69888, 69890),\n-    (69927, 69940), (69957, 69958), (70003, 70003), (70016, 70018), (70067,\n-    70080), (70089, 70092), (70094, 70095), (70188, 70199), (70206, 70206),\n-    (70367, 70378), (70400, 70403), (70459, 70460), (70462, 70468), (70471,\n-    70472), (70475, 70477), (70487, 70487), (70498, 70499), (70502, 70508),\n-    (70512, 70516), (70709, 70726), (70750, 70750), (70832, 70851), (71087,\n-    71093), (71096, 71104), (71132, 71133), (71216, 71232), (71339, 71351),\n-    (71453, 71467), (71724, 71738), (71984, 71989), (71991, 71992), (71995,\n-    71998), (72000, 72000), (72002, 72003), (72145, 72151), (72154, 72160),\n-    (72164, 72164), (72193, 72202), (72243, 72249), (72251, 72254), (72263,\n-    72263), (72273, 72283), (72330, 72345), (72751, 72758), (72760, 72767),\n-    (72850, 72871), (72873, 72886), (73009, 73014), (73018, 73018), (73020,\n-    73021), (73023, 73029), (73031, 73031), (73098, 73102), (73104, 73105),\n-    (73107, 73111), (73459, 73462), (78896, 78904), (92912, 92916), (92976,\n-    92982), (94031, 94031), (94033, 94087), (94095, 94098), (94180, 94180),\n-    (94192, 94193), (113821, 113822), (113824, 113827), (118528, 118573), (\n-    118576, 118598), (119141, 119145), (119149, 119170), (119173, 119179),\n-    (119210, 119213), (119362, 119364), (121344, 121398), (121403, 121452),\n-    (121461, 121461), (121476, 121476), (121499, 121503), (121505, 121519),\n-    (122880, 122886), (122888, 122904), (122907, 122913), (122915, 122916),\n-    (122918, 122922), (123184, 123190), (123566, 123566), (123628, 123631),\n-    (125136, 125142), (125252, 125258), (127995, 127999), (917505, 917505),\n-    (917536, 917631), (917760, 917999)), '15.0.0': ((0, 0), (173, 173), (\n-    768, 879), (1155, 1161), (1425, 1469), (1471, 1471), (1473, 1474), (\n-    1476, 1477), (1479, 1479), (1536, 1541), (1552, 1562), (1564, 1564), (\n-    1611, 1631), (1648, 1648), (1750, 1757), (1759, 1764), (1767, 1768), (\n-    1770, 1773), (1807, 1807), (1809, 1809), (1840, 1866), (1958, 1968), (\n-    2027, 2035), (2045, 2045), (2070, 2073), (2075, 2083), (2085, 2087), (\n-    2089, 2093), (2137, 2139), (2192, 2193), (2200, 2207), (2250, 2307), (\n-    2362, 2364), (2366, 2383), (2385, 2391), (2402, 2403), (2433, 2435), (\n-    2492, 2492), (2494, 2500), (2503, 2504), (2507, 2509), (2519, 2519), (\n-    2530, 2531), (2558, 2558), (2561, 2563), (2620, 2620), (2622, 2626), (\n-    2631, 2632), (2635, 2637), (2641, 2641), (2672, 2673), (2677, 2677), (\n-    2689, 2691), (2748, 2748), (2750, 2757), (2759, 2761), (2763, 2765), (\n-    2786, 2787), (2810, 2815), (2817, 2819), (2876, 2876), (2878, 2884), (\n-    2887, 2888), (2891, 2893), (2901, 2903), (2914, 2915), (2946, 2946), (\n-    3006, 3010), (3014, 3016), (3018, 3021), (3031, 3031), (3072, 3076), (\n-    3132, 3132), (3134, 3140), (3142, 3144), (3146, 3149), (3157, 3158), (\n-    3170, 3171), (3201, 3203), (3260, 3260), (3262, 3268), (3270, 3272), (\n-    3274, 3277), (3285, 3286), (3298, 3299), (3315, 3315), (3328, 3331), (\n-    3387, 3388), (3390, 3396), (3398, 3400), (3402, 3405), (3415, 3415), (\n-    3426, 3427), (3457, 3459), (3530, 3530), (3535, 3540), (3542, 3542), (\n-    3544, 3551), (3570, 3571), (3633, 3633), (3636, 3642), (3655, 3662), (\n-    3761, 3761), (3764, 3772), (3784, 3790), (3864, 3865), (3893, 3893), (\n-    3895, 3895), (3897, 3897), (3902, 3903), (3953, 3972), (3974, 3975), (\n-    3981, 3991), (3993, 4028), (4038, 4038), (4139, 4158), (4182, 4185), (\n-    4190, 4192), (4194, 4196), (4199, 4205), (4209, 4212), (4226, 4237), (\n-    4239, 4239), (4250, 4253), (4448, 4607), (4957, 4959), (5906, 5909), (\n-    5938, 5940), (5970, 5971), (6002, 6003), (6068, 6099), (6109, 6109), (\n-    6155, 6159), (6277, 6278), (6313, 6313), (6432, 6443), (6448, 6459), (\n-    6679, 6683), (6741, 6750), (6752, 6780), (6783, 6783), (6832, 6862), (\n-    6912, 6916), (6964, 6980), (7019, 7027), (7040, 7042), (7073, 7085), (\n-    7142, 7155), (7204, 7223), (7376, 7378), (7380, 7400), (7405, 7405), (\n-    7412, 7412), (7415, 7417), (7616, 7679), (8203, 8207), (8232, 8238), (\n-    8288, 8292), (8294, 8303), (8400, 8432), (11503, 11505), (11647, 11647),\n-    (11744, 11775), (12330, 12335), (12441, 12442), (42607, 42610), (42612,\n-    42621), (42654, 42655), (42736, 42737), (43010, 43010), (43014, 43014),\n-    (43019, 43019), (43043, 43047), (43052, 43052), (43136, 43137), (43188,\n-    43205), (43232, 43249), (43263, 43263), (43302, 43309), (43335, 43347),\n-    (43392, 43395), (43443, 43456), (43493, 43493), (43561, 43574), (43587,\n-    43587), (43596, 43597), (43643, 43645), (43696, 43696), (43698, 43700),\n-    (43703, 43704), (43710, 43711), (43713, 43713), (43755, 43759), (43765,\n-    43766), (44003, 44010), (44012, 44013), (55216, 55295), (64286, 64286),\n-    (65024, 65039), (65056, 65071), (65279, 65279), (65529, 65531), (66045,\n-    66045), (66272, 66272), (66422, 66426), (68097, 68099), (68101, 68102),\n-    (68108, 68111), (68152, 68154), (68159, 68159), (68325, 68326), (68900,\n-    68903), (69291, 69292), (69373, 69375), (69446, 69456), (69506, 69509),\n-    (69632, 69634), (69688, 69702), (69744, 69744), (69747, 69748), (69759,\n-    69762), (69808, 69818), (69821, 69821), (69826, 69826), (69837, 69837),\n-    (69888, 69890), (69927, 69940), (69957, 69958), (70003, 70003), (70016,\n-    70018), (70067, 70080), (70089, 70092), (70094, 70095), (70188, 70199),\n-    (70206, 70206), (70209, 70209), (70367, 70378), (70400, 70403), (70459,\n-    70460), (70462, 70468), (70471, 70472), (70475, 70477), (70487, 70487),\n-    (70498, 70499), (70502, 70508), (70512, 70516), (70709, 70726), (70750,\n-    70750), (70832, 70851), (71087, 71093), (71096, 71104), (71132, 71133),\n-    (71216, 71232), (71339, 71351), (71453, 71467), (71724, 71738), (71984,\n-    71989), (71991, 71992), (71995, 71998), (72000, 72000), (72002, 72003),\n-    (72145, 72151), (72154, 72160), (72164, 72164), (72193, 72202), (72243,\n-    72249), (72251, 72254), (72263, 72263), (72273, 72283), (72330, 72345),\n-    (72751, 72758), (72760, 72767), (72850, 72871), (72873, 72886), (73009,\n-    73014), (73018, 73018), (73020, 73021), (73023, 73029), (73031, 73031),\n-    (73098, 73102), (73104, 73105), (73107, 73111), (73459, 73462), (73472,\n-    73473), (73475, 73475), (73524, 73530), (73534, 73538), (78896, 78912),\n-    (78919, 78933), (92912, 92916), (92976, 92982), (94031, 94031), (94033,\n-    94087), (94095, 94098), (94180, 94180), (94192, 94193), (113821, 113822\n-    ), (113824, 113827), (118528, 118573), (118576, 118598), (119141, \n-    119145), (119149, 119170), (119173, 119179), (119210, 119213), (119362,\n-    119364), (121344, 121398), (121403, 121452), (121461, 121461), (121476,\n-    121476), (121499, 121503), (121505, 121519), (122880, 122886), (122888,\n-    122904), (122907, 122913), (122915, 122916), (122918, 122922), (123023,\n-    123023), (123184, 123190), (123566, 123566), (123628, 123631), (124140,\n-    124143), (125136, 125142), (125252, 125258), (127995, 127999), (917505,\n-    917505), (917536, 917631), (917760, 917999)), '15.1.0': ((0, 0), (173, \n-    173), (768, 879), (1155, 1161), (1425, 1469), (1471, 1471), (1473, 1474\n-    ), (1476, 1477), (1479, 1479), (1536, 1541), (1552, 1562), (1564, 1564),\n-    (1611, 1631), (1648, 1648), (1750, 1757), (1759, 1764), (1767, 1768), (\n-    1770, 1773), (1807, 1807), (1809, 1809), (1840, 1866), (1958, 1968), (\n-    2027, 2035), (2045, 2045), (2070, 2073), (2075, 2083), (2085, 2087), (\n-    2089, 2093), (2137, 2139), (2192, 2193), (2200, 2207), (2250, 2307), (\n-    2362, 2364), (2366, 2383), (2385, 2391), (2402, 2403), (2433, 2435), (\n-    2492, 2492), (2494, 2500), (2503, 2504), (2507, 2509), (2519, 2519), (\n-    2530, 2531), (2558, 2558), (2561, 2563), (2620, 2620), (2622, 2626), (\n-    2631, 2632), (2635, 2637), (2641, 2641), (2672, 2673), (2677, 2677), (\n-    2689, 2691), (2748, 2748), (2750, 2757), (2759, 2761), (2763, 2765), (\n-    2786, 2787), (2810, 2815), (2817, 2819), (2876, 2876), (2878, 2884), (\n-    2887, 2888), (2891, 2893), (2901, 2903), (2914, 2915), (2946, 2946), (\n-    3006, 3010), (3014, 3016), (3018, 3021), (3031, 3031), (3072, 3076), (\n-    3132, 3132), (3134, 3140), (3142, 3144), (3146, 3149), (3157, 3158), (\n-    3170, 3171), (3201, 3203), (3260, 3260), (3262, 3268), (3270, 3272), (\n-    3274, 3277), (3285, 3286), (3298, 3299), (3315, 3315), (3328, 3331), (\n-    3387, 3388), (3390, 3396), (3398, 3400), (3402, 3405), (3415, 3415), (\n-    3426, 3427), (3457, 3459), (3530, 3530), (3535, 3540), (3542, 3542), (\n-    3544, 3551), (3570, 3571), (3633, 3633), (3636, 3642), (3655, 3662), (\n-    3761, 3761), (3764, 3772), (3784, 3790), (3864, 3865), (3893, 3893), (\n-    3895, 3895), (3897, 3897), (3902, 3903), (3953, 3972), (3974, 3975), (\n-    3981, 3991), (3993, 4028), (4038, 4038), (4139, 4158), (4182, 4185), (\n-    4190, 4192), (4194, 4196), (4199, 4205), (4209, 4212), (4226, 4237), (\n-    4239, 4239), (4250, 4253), (4448, 4607), (4957, 4959), (5906, 5909), (\n-    5938, 5940), (5970, 5971), (6002, 6003), (6068, 6099), (6109, 6109), (\n-    6155, 6159), (6277, 6278), (6313, 6313), (6432, 6443), (6448, 6459), (\n-    6679, 6683), (6741, 6750), (6752, 6780), (6783, 6783), (6832, 6862), (\n-    6912, 6916), (6964, 6980), (7019, 7027), (7040, 7042), (7073, 7085), (\n-    7142, 7155), (7204, 7223), (7376, 7378), (7380, 7400), (7405, 7405), (\n-    7412, 7412), (7415, 7417), (7616, 7679), (8203, 8207), (8232, 8238), (\n-    8288, 8292), (8294, 8303), (8400, 8432), (11503, 11505), (11647, 11647),\n-    (11744, 11775), (12330, 12335), (12441, 12442), (42607, 42610), (42612,\n-    42621), (42654, 42655), (42736, 42737), (43010, 43010), (43014, 43014),\n-    (43019, 43019), (43043, 43047), (43052, 43052), (43136, 43137), (43188,\n-    43205), (43232, 43249), (43263, 43263), (43302, 43309), (43335, 43347),\n-    (43392, 43395), (43443, 43456), (43493, 43493), (43561, 43574), (43587,\n-    43587), (43596, 43597), (43643, 43645), (43696, 43696), (43698, 43700),\n-    (43703, 43704), (43710, 43711), (43713, 43713), (43755, 43759), (43765,\n-    43766), (44003, 44010), (44012, 44013), (55216, 55295), (64286, 64286),\n-    (65024, 65039), (65056, 65071), (65279, 65279), (65529, 65531), (66045,\n-    66045), (66272, 66272), (66422, 66426), (68097, 68099), (68101, 68102),\n-    (68108, 68111), (68152, 68154), (68159, 68159), (68325, 68326), (68900,\n-    68903), (69291, 69292), (69373, 69375), (69446, 69456), (69506, 69509),\n-    (69632, 69634), (69688, 69702), (69744, 69744), (69747, 69748), (69759,\n-    69762), (69808, 69818), (69821, 69821), (69826, 69826), (69837, 69837),\n-    (69888, 69890), (69927, 69940), (69957, 69958), (70003, 70003), (70016,\n-    70018), (70067, 70080), (70089, 70092), (70094, 70095), (70188, 70199),\n-    (70206, 70206), (70209, 70209), (70367, 70378), (70400, 70403), (70459,\n-    70460), (70462, 70468), (70471, 70472), (70475, 70477), (70487, 70487),\n-    (70498, 70499), (70502, 70508), (70512, 70516), (70709, 70726), (70750,\n-    70750), (70832, 70851), (71087, 71093), (71096, 71104), (71132, 71133),\n-    (71216, 71232), (71339, 71351), (71453, 71467), (71724, 71738), (71984,\n-    71989), (71991, 71992), (71995, 71998), (72000, 72000), (72002, 72003),\n-    (72145, 72151), (72154, 72160), (72164, 72164), (72193, 72202), (72243,\n-    72249), (72251, 72254), (72263, 72263), (72273, 72283), (72330, 72345),\n-    (72751, 72758), (72760, 72767), (72850, 72871), (72873, 72886), (73009,\n-    73014), (73018, 73018), (73020, 73021), (73023, 73029), (73031, 73031),\n-    (73098, 73102), (73104, 73105), (73107, 73111), (73459, 73462), (73472,\n-    73473), (73475, 73475), (73524, 73530), (73534, 73538), (78896, 78912),\n-    (78919, 78933), (92912, 92916), (92976, 92982), (94031, 94031), (94033,\n-    94087), (94095, 94098), (94180, 94180), (94192, 94193), (113821, 113822\n-    ), (113824, 113827), (118528, 118573), (118576, 118598), (119141, \n-    119145), (119149, 119170), (119173, 119179), (119210, 119213), (119362,\n-    119364), (121344, 121398), (121403, 121452), (121461, 121461), (121476,\n-    121476), (121499, 121503), (121505, 121519), (122880, 122886), (122888,\n-    122904), (122907, 122913), (122915, 122916), (122918, 122922), (123023,\n-    123023), (123184, 123190), (123566, 123566), (123628, 123631), (124140,\n-    124143), (125136, 125142), (125252, 125258), (127995, 127999), (917505,\n-    917505), (917536, 917631), (917760, 917999))}\n+ZERO_WIDTH = {\n+    '4.1.0': (\n+        # Source: DerivedGeneralCategory-4.1.0.txt\n+        # Date: 2005-02-26, 02:35:50 GMT [MD]\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00486,),  # Combining Cyrillic Titlo..Combining Cyrillic Psili\n+        (0x00488, 0x00489,),  # Combining Cyrillic Hundr..Combining Cyrillic Milli\n+        (0x00591, 0x005b9,),  # Hebrew Accent Etnahta   ..Hebrew Point Holam\n+        (0x005bb, 0x005bd,),  # Hebrew Point Qubuts     ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00603,),  # Arabic Number Sign      ..Arabic Sign Safha\n+        (0x00610, 0x00615,),  # Arabic Sign Sallallahou ..Arabic Small High Tah\n+        (0x0064b, 0x0065e,),  # Arabic Fathatan         ..Arabic Fatha With Two Do\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006e4,),  # Arabic Small High Ligatu..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x00901, 0x00903,),  # Devanagari Sign Candrabi..Devanagari Sign Visarga\n+        (0x0093c, 0x0093c,),  # Devanagari Sign Nukta\n+        (0x0093e, 0x0094d,),  # Devanagari Vowel Sign Aa..Devanagari Sign Virama\n+        (0x00951, 0x00954,),  # Devanagari Stress Sign U..Devanagari Acute Accent\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b43,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b56, 0x00b57,),  # Oriya Ai Length Mark    ..Oriya Au Length Mark\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c01, 0x00c03,),  # Telugu Sign Candrabindu ..Telugu Sign Visarga\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c82, 0x00c83,),  # Kannada Sign Anusvara   ..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00d02, 0x00d03,),  # Malayalam Sign Anusvara ..Malayalam Sign Visarga\n+        (0x00d3e, 0x00d43,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d82, 0x00d83,),  # Sinhala Sign Anusvaraya ..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00eb9,),  # Lao Vowel Sign I        ..Lao Vowel Sign Uu\n+        (0x00ebb, 0x00ebc,),  # Lao Vowel Sign Mai Kon  ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f90, 0x00f97,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102c, 0x01032,),  # Myanmar Vowel Sign Aa   ..Myanmar Vowel Sign Ai\n+        (0x01036, 0x01039,),  # Myanmar Sign Anusvara   ..Myanmar Sign Virama\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135f, 0x0135f,),  # Ethiopic Combining Gemination Mark\n+        (0x01712, 0x01714,),  # Tagalog Vowel Sign I    ..Tagalog Sign Virama\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180d,),  # Mongolian Free Variation..Mongolian Free Variation\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x019b0, 0x019c0,),  # New Tai Lue Vowel Sign V..New Tai Lue Vowel Sign I\n+        (0x019c8, 0x019c9,),  # New Tai Lue Tone Mark-1 ..New Tai Lue Tone Mark-2\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01dc0, 0x01dc3,),  # Combining Dotted Grave A..Combining Suspension Mar\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02063,),  # Word Joiner             ..Invisible Separator\n+        (0x0206a, 0x0206f,),  # Inhibit Symmetric Swappi..Nominal Digit Shapes\n+        (0x020d0, 0x020eb,),  # Combining Left Harpoon A..Combining Long Double So\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe23,),  # Combining Ligature Left ..Combining Double Tilde R\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '5.0.0': (\n+        # Source: DerivedGeneralCategory-5.0.0.txt\n+        # Date: 2006-02-27, 23:41:27 GMT [MD]\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00486,),  # Combining Cyrillic Titlo..Combining Cyrillic Psili\n+        (0x00488, 0x00489,),  # Combining Cyrillic Hundr..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00603,),  # Arabic Number Sign      ..Arabic Sign Safha\n+        (0x00610, 0x00615,),  # Arabic Sign Sallallahou ..Arabic Small High Tah\n+        (0x0064b, 0x0065e,),  # Arabic Fathatan         ..Arabic Fatha With Two Do\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006e4,),  # Arabic Small High Ligatu..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x00901, 0x00903,),  # Devanagari Sign Candrabi..Devanagari Sign Visarga\n+        (0x0093c, 0x0093c,),  # Devanagari Sign Nukta\n+        (0x0093e, 0x0094d,),  # Devanagari Vowel Sign Aa..Devanagari Sign Virama\n+        (0x00951, 0x00954,),  # Devanagari Stress Sign U..Devanagari Acute Accent\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b43,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b56, 0x00b57,),  # Oriya Ai Length Mark    ..Oriya Au Length Mark\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c01, 0x00c03,),  # Telugu Sign Candrabindu ..Telugu Sign Visarga\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c82, 0x00c83,),  # Kannada Sign Anusvara   ..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00d02, 0x00d03,),  # Malayalam Sign Anusvara ..Malayalam Sign Visarga\n+        (0x00d3e, 0x00d43,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d82, 0x00d83,),  # Sinhala Sign Anusvaraya ..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00eb9,),  # Lao Vowel Sign I        ..Lao Vowel Sign Uu\n+        (0x00ebb, 0x00ebc,),  # Lao Vowel Sign Mai Kon  ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f90, 0x00f97,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102c, 0x01032,),  # Myanmar Vowel Sign Aa   ..Myanmar Vowel Sign Ai\n+        (0x01036, 0x01039,),  # Myanmar Sign Anusvara   ..Myanmar Sign Virama\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135f, 0x0135f,),  # Ethiopic Combining Gemination Mark\n+        (0x01712, 0x01714,),  # Tagalog Vowel Sign I    ..Tagalog Sign Virama\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180d,),  # Mongolian Free Variation..Mongolian Free Variation\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x019b0, 0x019c0,),  # New Tai Lue Vowel Sign V..New Tai Lue Vowel Sign I\n+        (0x019c8, 0x019c9,),  # New Tai Lue Tone Mark-1 ..New Tai Lue Tone Mark-2\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01dc0, 0x01dca,),  # Combining Dotted Grave A..Combining Latin Small Le\n+        (0x01dfe, 0x01dff,),  # Combining Left Arrowhead..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02063,),  # Word Joiner             ..Invisible Separator\n+        (0x0206a, 0x0206f,),  # Inhibit Symmetric Swappi..Nominal Digit Shapes\n+        (0x020d0, 0x020ef,),  # Combining Left Harpoon A..Combining Right Arrow Be\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe23,),  # Combining Ligature Left ..Combining Double Tilde R\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '5.1.0': (\n+        # Source: DerivedGeneralCategory-5.1.0.txt\n+        # Date: 2008-03-20, 17:54:57 GMT [MD]\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00603,),  # Arabic Number Sign      ..Arabic Sign Safha\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0064b, 0x0065e,),  # Arabic Fathatan         ..Arabic Fatha With Two Do\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006e4,),  # Arabic Small High Ligatu..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x00901, 0x00903,),  # Devanagari Sign Candrabi..Devanagari Sign Visarga\n+        (0x0093c, 0x0093c,),  # Devanagari Sign Nukta\n+        (0x0093e, 0x0094d,),  # Devanagari Vowel Sign Aa..Devanagari Sign Virama\n+        (0x00951, 0x00954,),  # Devanagari Stress Sign U..Devanagari Acute Accent\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b56, 0x00b57,),  # Oriya Ai Length Mark    ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c01, 0x00c03,),  # Telugu Sign Candrabindu ..Telugu Sign Visarga\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c82, 0x00c83,),  # Kannada Sign Anusvara   ..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00d02, 0x00d03,),  # Malayalam Sign Anusvara ..Malayalam Sign Visarga\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d82, 0x00d83,),  # Sinhala Sign Anusvaraya ..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00eb9,),  # Lao Vowel Sign I        ..Lao Vowel Sign Uu\n+        (0x00ebb, 0x00ebc,),  # Lao Vowel Sign Mai Kon  ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f90, 0x00f97,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135f, 0x0135f,),  # Ethiopic Combining Gemination Mark\n+        (0x01712, 0x01714,),  # Tagalog Vowel Sign I    ..Tagalog Sign Virama\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180d,),  # Mongolian Free Variation..Mongolian Free Variation\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x019b0, 0x019c0,),  # New Tai Lue Vowel Sign V..New Tai Lue Vowel Sign I\n+        (0x019c8, 0x019c9,),  # New Tai Lue Tone Mark-1 ..New Tai Lue Tone Mark-2\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01baa,),  # Sundanese Consonant Sign..Sundanese Sign Pamaaeh\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01dc0, 0x01de6,),  # Combining Dotted Grave A..Combining Latin Small Le\n+        (0x01dfe, 0x01dff,),  # Combining Left Arrowhead..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x0206a, 0x0206f,),  # Inhibit Symmetric Swappi..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a67c, 0x0a67d,),  # Combining Cyrillic Kavyk..Combining Cyrillic Payer\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c4,),  # Saurashtra Consonant Sig..Saurashtra Sign Virama\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe26,),  # Combining Ligature Left ..Combining Conjoining Mac\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '5.2.0': (\n+        # Source: DerivedGeneralCategory-5.2.0.txt\n+        # Date: 2009-08-22, 04:58:21 GMT [MD]\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00603,),  # Arabic Number Sign      ..Arabic Sign Safha\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0064b, 0x0065e,),  # Arabic Fathatan         ..Arabic Fatha With Two Do\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006e4,),  # Arabic Small High Ligatu..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x00816, 0x00819,),  # Samaritan Mark In       ..Samaritan Mark Dagesh\n+        (0x0081b, 0x00823,),  # Samaritan Mark Epentheti..Samaritan Vowel Sign A\n+        (0x00825, 0x00827,),  # Samaritan Vowel Sign Sho..Samaritan Vowel Sign U\n+        (0x00829, 0x0082d,),  # Samaritan Vowel Sign Lon..Samaritan Mark Nequdaa\n+        (0x00900, 0x00903,),  # Devanagari Sign Inverted..Devanagari Sign Visarga\n+        (0x0093c, 0x0093c,),  # Devanagari Sign Nukta\n+        (0x0093e, 0x0094e,),  # Devanagari Vowel Sign Aa..Devanagari Vowel Sign Pr\n+        (0x00951, 0x00955,),  # Devanagari Stress Sign U..Devanagari Vowel Sign Ca\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b56, 0x00b57,),  # Oriya Ai Length Mark    ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c01, 0x00c03,),  # Telugu Sign Candrabindu ..Telugu Sign Visarga\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c82, 0x00c83,),  # Kannada Sign Anusvara   ..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00d02, 0x00d03,),  # Malayalam Sign Anusvara ..Malayalam Sign Visarga\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d82, 0x00d83,),  # Sinhala Sign Anusvaraya ..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00eb9,),  # Lao Vowel Sign I        ..Lao Vowel Sign Uu\n+        (0x00ebb, 0x00ebc,),  # Lao Vowel Sign Mai Kon  ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f90, 0x00f97,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x0109a, 0x0109d,),  # Myanmar Sign Khamti Tone..Myanmar Vowel Sign Aiton\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135f, 0x0135f,),  # Ethiopic Combining Gemination Mark\n+        (0x01712, 0x01714,),  # Tagalog Vowel Sign I    ..Tagalog Sign Virama\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180d,),  # Mongolian Free Variation..Mongolian Free Variation\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x019b0, 0x019c0,),  # New Tai Lue Vowel Sign V..New Tai Lue Vowel Sign I\n+        (0x019c8, 0x019c9,),  # New Tai Lue Tone Mark-1 ..New Tai Lue Tone Mark-2\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01a55, 0x01a5e,),  # Tai Tham Consonant Sign ..Tai Tham Consonant Sign\n+        (0x01a60, 0x01a7c,),  # Tai Tham Sign Sakot     ..Tai Tham Sign Khuen-lue\n+        (0x01a7f, 0x01a7f,),  # Tai Tham Combining Cryptogrammic Dot\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01baa,),  # Sundanese Consonant Sign..Sundanese Sign Pamaaeh\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01cd0, 0x01cd2,),  # Vedic Tone Karshana     ..Vedic Tone Prenkha\n+        (0x01cd4, 0x01ce8,),  # Vedic Sign Yajurvedic Mi..Vedic Sign Visarga Anuda\n+        (0x01ced, 0x01ced,),  # Vedic Sign Tiryak\n+        (0x01cf2, 0x01cf2,),  # Vedic Sign Ardhavisarga\n+        (0x01dc0, 0x01de6,),  # Combining Dotted Grave A..Combining Latin Small Le\n+        (0x01dfd, 0x01dff,),  # Combining Almost Equal T..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x0206a, 0x0206f,),  # Inhibit Symmetric Swappi..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02cef, 0x02cf1,),  # Coptic Combining Ni Abov..Coptic Combining Spiritu\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a67c, 0x0a67d,),  # Combining Cyrillic Kavyk..Combining Cyrillic Payer\n+        (0x0a6f0, 0x0a6f1,),  # Bamum Combining Mark Koq..Bamum Combining Mark Tuk\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c4,),  # Saurashtra Consonant Sig..Saurashtra Sign Virama\n+        (0x0a8e0, 0x0a8f1,),  # Combining Devanagari Dig..Combining Devanagari Sig\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0a980, 0x0a983,),  # Javanese Sign Panyangga ..Javanese Sign Wignyan\n+        (0x0a9b3, 0x0a9c0,),  # Javanese Sign Cecak Telu..Javanese Pangkon\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0aa7b, 0x0aa7b,),  # Myanmar Sign Pao Karen Tone\n+        (0x0aab0, 0x0aab0,),  # Tai Viet Mai Kang\n+        (0x0aab2, 0x0aab4,),  # Tai Viet Vowel I        ..Tai Viet Vowel U\n+        (0x0aab7, 0x0aab8,),  # Tai Viet Mai Khit       ..Tai Viet Vowel Ia\n+        (0x0aabe, 0x0aabf,),  # Tai Viet Vowel Am       ..Tai Viet Tone Mai Ek\n+        (0x0aac1, 0x0aac1,),  # Tai Viet Tone Mai Tho\n+        (0x0abe3, 0x0abea,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0abec, 0x0abed,),  # Meetei Mayek Lum Iyek   ..Meetei Mayek Apun Iyek\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe26,),  # Combining Ligature Left ..Combining Conjoining Mac\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x11080, 0x11082,),  # Kaithi Sign Candrabindu ..Kaithi Sign Visarga\n+        (0x110b0, 0x110ba,),  # Kaithi Vowel Sign Aa    ..Kaithi Sign Nukta\n+        (0x110bd, 0x110bd,),  # Kaithi Number Sign\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '6.0.0': (\n+        # Source: DerivedGeneralCategory-6.0.0.txt\n+        # Date: 2010-08-19, 00:48:09 GMT [MD]\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00603,),  # Arabic Number Sign      ..Arabic Sign Safha\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0064b, 0x0065f,),  # Arabic Fathatan         ..Arabic Wavy Hamza Below\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006dd,),  # Arabic Small High Ligatu..Arabic End Of Ayah\n+        (0x006df, 0x006e4,),  # Arabic Small High Rounde..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x00816, 0x00819,),  # Samaritan Mark In       ..Samaritan Mark Dagesh\n+        (0x0081b, 0x00823,),  # Samaritan Mark Epentheti..Samaritan Vowel Sign A\n+        (0x00825, 0x00827,),  # Samaritan Vowel Sign Sho..Samaritan Vowel Sign U\n+        (0x00829, 0x0082d,),  # Samaritan Vowel Sign Lon..Samaritan Mark Nequdaa\n+        (0x00859, 0x0085b,),  # Mandaic Affrication Mark..Mandaic Gemination Mark\n+        (0x00900, 0x00903,),  # Devanagari Sign Inverted..Devanagari Sign Visarga\n+        (0x0093a, 0x0093c,),  # Devanagari Vowel Sign Oe..Devanagari Sign Nukta\n+        (0x0093e, 0x0094f,),  # Devanagari Vowel Sign Aa..Devanagari Vowel Sign Aw\n+        (0x00951, 0x00957,),  # Devanagari Stress Sign U..Devanagari Vowel Sign Uu\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b56, 0x00b57,),  # Oriya Ai Length Mark    ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c01, 0x00c03,),  # Telugu Sign Candrabindu ..Telugu Sign Visarga\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c82, 0x00c83,),  # Kannada Sign Anusvara   ..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00d02, 0x00d03,),  # Malayalam Sign Anusvara ..Malayalam Sign Visarga\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d82, 0x00d83,),  # Sinhala Sign Anusvaraya ..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00eb9,),  # Lao Vowel Sign I        ..Lao Vowel Sign Uu\n+        (0x00ebb, 0x00ebc,),  # Lao Vowel Sign Mai Kon  ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f8d, 0x00f97,),  # Tibetan Subjoined Sign L..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x0109a, 0x0109d,),  # Myanmar Sign Khamti Tone..Myanmar Vowel Sign Aiton\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135d, 0x0135f,),  # Ethiopic Combining Gemin..Ethiopic Combining Gemin\n+        (0x01712, 0x01714,),  # Tagalog Vowel Sign I    ..Tagalog Sign Virama\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180d,),  # Mongolian Free Variation..Mongolian Free Variation\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x019b0, 0x019c0,),  # New Tai Lue Vowel Sign V..New Tai Lue Vowel Sign I\n+        (0x019c8, 0x019c9,),  # New Tai Lue Tone Mark-1 ..New Tai Lue Tone Mark-2\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01a55, 0x01a5e,),  # Tai Tham Consonant Sign ..Tai Tham Consonant Sign\n+        (0x01a60, 0x01a7c,),  # Tai Tham Sign Sakot     ..Tai Tham Sign Khuen-lue\n+        (0x01a7f, 0x01a7f,),  # Tai Tham Combining Cryptogrammic Dot\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01baa,),  # Sundanese Consonant Sign..Sundanese Sign Pamaaeh\n+        (0x01be6, 0x01bf3,),  # Batak Sign Tompi        ..Batak Panongonan\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01cd0, 0x01cd2,),  # Vedic Tone Karshana     ..Vedic Tone Prenkha\n+        (0x01cd4, 0x01ce8,),  # Vedic Sign Yajurvedic Mi..Vedic Sign Visarga Anuda\n+        (0x01ced, 0x01ced,),  # Vedic Sign Tiryak\n+        (0x01cf2, 0x01cf2,),  # Vedic Sign Ardhavisarga\n+        (0x01dc0, 0x01de6,),  # Combining Dotted Grave A..Combining Latin Small Le\n+        (0x01dfc, 0x01dff,),  # Combining Double Inverte..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x0206a, 0x0206f,),  # Inhibit Symmetric Swappi..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02cef, 0x02cf1,),  # Coptic Combining Ni Abov..Coptic Combining Spiritu\n+        (0x02d7f, 0x02d7f,),  # Tifinagh Consonant Joiner\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a67c, 0x0a67d,),  # Combining Cyrillic Kavyk..Combining Cyrillic Payer\n+        (0x0a6f0, 0x0a6f1,),  # Bamum Combining Mark Koq..Bamum Combining Mark Tuk\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c4,),  # Saurashtra Consonant Sig..Saurashtra Sign Virama\n+        (0x0a8e0, 0x0a8f1,),  # Combining Devanagari Dig..Combining Devanagari Sig\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0a980, 0x0a983,),  # Javanese Sign Panyangga ..Javanese Sign Wignyan\n+        (0x0a9b3, 0x0a9c0,),  # Javanese Sign Cecak Telu..Javanese Pangkon\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0aa7b, 0x0aa7b,),  # Myanmar Sign Pao Karen Tone\n+        (0x0aab0, 0x0aab0,),  # Tai Viet Mai Kang\n+        (0x0aab2, 0x0aab4,),  # Tai Viet Vowel I        ..Tai Viet Vowel U\n+        (0x0aab7, 0x0aab8,),  # Tai Viet Mai Khit       ..Tai Viet Vowel Ia\n+        (0x0aabe, 0x0aabf,),  # Tai Viet Vowel Am       ..Tai Viet Tone Mai Ek\n+        (0x0aac1, 0x0aac1,),  # Tai Viet Tone Mai Tho\n+        (0x0abe3, 0x0abea,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0abec, 0x0abed,),  # Meetei Mayek Lum Iyek   ..Meetei Mayek Apun Iyek\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe26,),  # Combining Ligature Left ..Combining Conjoining Mac\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x11000, 0x11002,),  # Brahmi Sign Candrabindu ..Brahmi Sign Visarga\n+        (0x11038, 0x11046,),  # Brahmi Vowel Sign Aa    ..Brahmi Virama\n+        (0x11080, 0x11082,),  # Kaithi Sign Candrabindu ..Kaithi Sign Visarga\n+        (0x110b0, 0x110ba,),  # Kaithi Vowel Sign Aa    ..Kaithi Sign Nukta\n+        (0x110bd, 0x110bd,),  # Kaithi Number Sign\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '6.1.0': (\n+        # Source: DerivedGeneralCategory-6.1.0.txt\n+        # Date: 2011-11-27, 05:10:22 GMT [MD]\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00604,),  # Arabic Number Sign      ..Arabic Sign Samvat\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0064b, 0x0065f,),  # Arabic Fathatan         ..Arabic Wavy Hamza Below\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006dd,),  # Arabic Small High Ligatu..Arabic End Of Ayah\n+        (0x006df, 0x006e4,),  # Arabic Small High Rounde..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x00816, 0x00819,),  # Samaritan Mark In       ..Samaritan Mark Dagesh\n+        (0x0081b, 0x00823,),  # Samaritan Mark Epentheti..Samaritan Vowel Sign A\n+        (0x00825, 0x00827,),  # Samaritan Vowel Sign Sho..Samaritan Vowel Sign U\n+        (0x00829, 0x0082d,),  # Samaritan Vowel Sign Lon..Samaritan Mark Nequdaa\n+        (0x00859, 0x0085b,),  # Mandaic Affrication Mark..Mandaic Gemination Mark\n+        (0x008e4, 0x008fe,),  # Arabic Curly Fatha      ..Arabic Damma With Dot\n+        (0x00900, 0x00903,),  # Devanagari Sign Inverted..Devanagari Sign Visarga\n+        (0x0093a, 0x0093c,),  # Devanagari Vowel Sign Oe..Devanagari Sign Nukta\n+        (0x0093e, 0x0094f,),  # Devanagari Vowel Sign Aa..Devanagari Vowel Sign Aw\n+        (0x00951, 0x00957,),  # Devanagari Stress Sign U..Devanagari Vowel Sign Uu\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b56, 0x00b57,),  # Oriya Ai Length Mark    ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c01, 0x00c03,),  # Telugu Sign Candrabindu ..Telugu Sign Visarga\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c82, 0x00c83,),  # Kannada Sign Anusvara   ..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00d02, 0x00d03,),  # Malayalam Sign Anusvara ..Malayalam Sign Visarga\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d82, 0x00d83,),  # Sinhala Sign Anusvaraya ..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00eb9,),  # Lao Vowel Sign I        ..Lao Vowel Sign Uu\n+        (0x00ebb, 0x00ebc,),  # Lao Vowel Sign Mai Kon  ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f8d, 0x00f97,),  # Tibetan Subjoined Sign L..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x0109a, 0x0109d,),  # Myanmar Sign Khamti Tone..Myanmar Vowel Sign Aiton\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135d, 0x0135f,),  # Ethiopic Combining Gemin..Ethiopic Combining Gemin\n+        (0x01712, 0x01714,),  # Tagalog Vowel Sign I    ..Tagalog Sign Virama\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180d,),  # Mongolian Free Variation..Mongolian Free Variation\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x019b0, 0x019c0,),  # New Tai Lue Vowel Sign V..New Tai Lue Vowel Sign I\n+        (0x019c8, 0x019c9,),  # New Tai Lue Tone Mark-1 ..New Tai Lue Tone Mark-2\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01a55, 0x01a5e,),  # Tai Tham Consonant Sign ..Tai Tham Consonant Sign\n+        (0x01a60, 0x01a7c,),  # Tai Tham Sign Sakot     ..Tai Tham Sign Khuen-lue\n+        (0x01a7f, 0x01a7f,),  # Tai Tham Combining Cryptogrammic Dot\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01bad,),  # Sundanese Consonant Sign..Sundanese Consonant Sign\n+        (0x01be6, 0x01bf3,),  # Batak Sign Tompi        ..Batak Panongonan\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01cd0, 0x01cd2,),  # Vedic Tone Karshana     ..Vedic Tone Prenkha\n+        (0x01cd4, 0x01ce8,),  # Vedic Sign Yajurvedic Mi..Vedic Sign Visarga Anuda\n+        (0x01ced, 0x01ced,),  # Vedic Sign Tiryak\n+        (0x01cf2, 0x01cf4,),  # Vedic Sign Ardhavisarga ..Vedic Tone Candra Above\n+        (0x01dc0, 0x01de6,),  # Combining Dotted Grave A..Combining Latin Small Le\n+        (0x01dfc, 0x01dff,),  # Combining Double Inverte..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x0206a, 0x0206f,),  # Inhibit Symmetric Swappi..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02cef, 0x02cf1,),  # Coptic Combining Ni Abov..Coptic Combining Spiritu\n+        (0x02d7f, 0x02d7f,),  # Tifinagh Consonant Joiner\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a674, 0x0a67d,),  # Combining Cyrillic Lette..Combining Cyrillic Payer\n+        (0x0a69f, 0x0a69f,),  # Combining Cyrillic Letter Iotified E\n+        (0x0a6f0, 0x0a6f1,),  # Bamum Combining Mark Koq..Bamum Combining Mark Tuk\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c4,),  # Saurashtra Consonant Sig..Saurashtra Sign Virama\n+        (0x0a8e0, 0x0a8f1,),  # Combining Devanagari Dig..Combining Devanagari Sig\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0a980, 0x0a983,),  # Javanese Sign Panyangga ..Javanese Sign Wignyan\n+        (0x0a9b3, 0x0a9c0,),  # Javanese Sign Cecak Telu..Javanese Pangkon\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0aa7b, 0x0aa7b,),  # Myanmar Sign Pao Karen Tone\n+        (0x0aab0, 0x0aab0,),  # Tai Viet Mai Kang\n+        (0x0aab2, 0x0aab4,),  # Tai Viet Vowel I        ..Tai Viet Vowel U\n+        (0x0aab7, 0x0aab8,),  # Tai Viet Mai Khit       ..Tai Viet Vowel Ia\n+        (0x0aabe, 0x0aabf,),  # Tai Viet Vowel Am       ..Tai Viet Tone Mai Ek\n+        (0x0aac1, 0x0aac1,),  # Tai Viet Tone Mai Tho\n+        (0x0aaeb, 0x0aaef,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0aaf5, 0x0aaf6,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Virama\n+        (0x0abe3, 0x0abea,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0abec, 0x0abed,),  # Meetei Mayek Lum Iyek   ..Meetei Mayek Apun Iyek\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe26,),  # Combining Ligature Left ..Combining Conjoining Mac\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x11000, 0x11002,),  # Brahmi Sign Candrabindu ..Brahmi Sign Visarga\n+        (0x11038, 0x11046,),  # Brahmi Vowel Sign Aa    ..Brahmi Virama\n+        (0x11080, 0x11082,),  # Kaithi Sign Candrabindu ..Kaithi Sign Visarga\n+        (0x110b0, 0x110ba,),  # Kaithi Vowel Sign Aa    ..Kaithi Sign Nukta\n+        (0x110bd, 0x110bd,),  # Kaithi Number Sign\n+        (0x11100, 0x11102,),  # Chakma Sign Candrabindu ..Chakma Sign Visarga\n+        (0x11127, 0x11134,),  # Chakma Vowel Sign A     ..Chakma Maayyaa\n+        (0x11180, 0x11182,),  # Sharada Sign Candrabindu..Sharada Sign Visarga\n+        (0x111b3, 0x111c0,),  # Sharada Vowel Sign Aa   ..Sharada Sign Virama\n+        (0x116ab, 0x116b7,),  # Takri Sign Anusvara     ..Takri Sign Nukta\n+        (0x16f51, 0x16f7e,),  # Miao Sign Aspiration    ..Miao Vowel Sign Ng\n+        (0x16f8f, 0x16f92,),  # Miao Tone Right         ..Miao Tone Below\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '6.2.0': (\n+        # Source: DerivedGeneralCategory-6.2.0.txt\n+        # Date: 2012-05-20, 00:42:34 GMT [MD]\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00604,),  # Arabic Number Sign      ..Arabic Sign Samvat\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0064b, 0x0065f,),  # Arabic Fathatan         ..Arabic Wavy Hamza Below\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006dd,),  # Arabic Small High Ligatu..Arabic End Of Ayah\n+        (0x006df, 0x006e4,),  # Arabic Small High Rounde..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x00816, 0x00819,),  # Samaritan Mark In       ..Samaritan Mark Dagesh\n+        (0x0081b, 0x00823,),  # Samaritan Mark Epentheti..Samaritan Vowel Sign A\n+        (0x00825, 0x00827,),  # Samaritan Vowel Sign Sho..Samaritan Vowel Sign U\n+        (0x00829, 0x0082d,),  # Samaritan Vowel Sign Lon..Samaritan Mark Nequdaa\n+        (0x00859, 0x0085b,),  # Mandaic Affrication Mark..Mandaic Gemination Mark\n+        (0x008e4, 0x008fe,),  # Arabic Curly Fatha      ..Arabic Damma With Dot\n+        (0x00900, 0x00903,),  # Devanagari Sign Inverted..Devanagari Sign Visarga\n+        (0x0093a, 0x0093c,),  # Devanagari Vowel Sign Oe..Devanagari Sign Nukta\n+        (0x0093e, 0x0094f,),  # Devanagari Vowel Sign Aa..Devanagari Vowel Sign Aw\n+        (0x00951, 0x00957,),  # Devanagari Stress Sign U..Devanagari Vowel Sign Uu\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b56, 0x00b57,),  # Oriya Ai Length Mark    ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c01, 0x00c03,),  # Telugu Sign Candrabindu ..Telugu Sign Visarga\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c82, 0x00c83,),  # Kannada Sign Anusvara   ..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00d02, 0x00d03,),  # Malayalam Sign Anusvara ..Malayalam Sign Visarga\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d82, 0x00d83,),  # Sinhala Sign Anusvaraya ..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00eb9,),  # Lao Vowel Sign I        ..Lao Vowel Sign Uu\n+        (0x00ebb, 0x00ebc,),  # Lao Vowel Sign Mai Kon  ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f8d, 0x00f97,),  # Tibetan Subjoined Sign L..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x0109a, 0x0109d,),  # Myanmar Sign Khamti Tone..Myanmar Vowel Sign Aiton\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135d, 0x0135f,),  # Ethiopic Combining Gemin..Ethiopic Combining Gemin\n+        (0x01712, 0x01714,),  # Tagalog Vowel Sign I    ..Tagalog Sign Virama\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180d,),  # Mongolian Free Variation..Mongolian Free Variation\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x019b0, 0x019c0,),  # New Tai Lue Vowel Sign V..New Tai Lue Vowel Sign I\n+        (0x019c8, 0x019c9,),  # New Tai Lue Tone Mark-1 ..New Tai Lue Tone Mark-2\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01a55, 0x01a5e,),  # Tai Tham Consonant Sign ..Tai Tham Consonant Sign\n+        (0x01a60, 0x01a7c,),  # Tai Tham Sign Sakot     ..Tai Tham Sign Khuen-lue\n+        (0x01a7f, 0x01a7f,),  # Tai Tham Combining Cryptogrammic Dot\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01bad,),  # Sundanese Consonant Sign..Sundanese Consonant Sign\n+        (0x01be6, 0x01bf3,),  # Batak Sign Tompi        ..Batak Panongonan\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01cd0, 0x01cd2,),  # Vedic Tone Karshana     ..Vedic Tone Prenkha\n+        (0x01cd4, 0x01ce8,),  # Vedic Sign Yajurvedic Mi..Vedic Sign Visarga Anuda\n+        (0x01ced, 0x01ced,),  # Vedic Sign Tiryak\n+        (0x01cf2, 0x01cf4,),  # Vedic Sign Ardhavisarga ..Vedic Tone Candra Above\n+        (0x01dc0, 0x01de6,),  # Combining Dotted Grave A..Combining Latin Small Le\n+        (0x01dfc, 0x01dff,),  # Combining Double Inverte..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x0206a, 0x0206f,),  # Inhibit Symmetric Swappi..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02cef, 0x02cf1,),  # Coptic Combining Ni Abov..Coptic Combining Spiritu\n+        (0x02d7f, 0x02d7f,),  # Tifinagh Consonant Joiner\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a674, 0x0a67d,),  # Combining Cyrillic Lette..Combining Cyrillic Payer\n+        (0x0a69f, 0x0a69f,),  # Combining Cyrillic Letter Iotified E\n+        (0x0a6f0, 0x0a6f1,),  # Bamum Combining Mark Koq..Bamum Combining Mark Tuk\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c4,),  # Saurashtra Consonant Sig..Saurashtra Sign Virama\n+        (0x0a8e0, 0x0a8f1,),  # Combining Devanagari Dig..Combining Devanagari Sig\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0a980, 0x0a983,),  # Javanese Sign Panyangga ..Javanese Sign Wignyan\n+        (0x0a9b3, 0x0a9c0,),  # Javanese Sign Cecak Telu..Javanese Pangkon\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0aa7b, 0x0aa7b,),  # Myanmar Sign Pao Karen Tone\n+        (0x0aab0, 0x0aab0,),  # Tai Viet Mai Kang\n+        (0x0aab2, 0x0aab4,),  # Tai Viet Vowel I        ..Tai Viet Vowel U\n+        (0x0aab7, 0x0aab8,),  # Tai Viet Mai Khit       ..Tai Viet Vowel Ia\n+        (0x0aabe, 0x0aabf,),  # Tai Viet Vowel Am       ..Tai Viet Tone Mai Ek\n+        (0x0aac1, 0x0aac1,),  # Tai Viet Tone Mai Tho\n+        (0x0aaeb, 0x0aaef,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0aaf5, 0x0aaf6,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Virama\n+        (0x0abe3, 0x0abea,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0abec, 0x0abed,),  # Meetei Mayek Lum Iyek   ..Meetei Mayek Apun Iyek\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe26,),  # Combining Ligature Left ..Combining Conjoining Mac\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x11000, 0x11002,),  # Brahmi Sign Candrabindu ..Brahmi Sign Visarga\n+        (0x11038, 0x11046,),  # Brahmi Vowel Sign Aa    ..Brahmi Virama\n+        (0x11080, 0x11082,),  # Kaithi Sign Candrabindu ..Kaithi Sign Visarga\n+        (0x110b0, 0x110ba,),  # Kaithi Vowel Sign Aa    ..Kaithi Sign Nukta\n+        (0x110bd, 0x110bd,),  # Kaithi Number Sign\n+        (0x11100, 0x11102,),  # Chakma Sign Candrabindu ..Chakma Sign Visarga\n+        (0x11127, 0x11134,),  # Chakma Vowel Sign A     ..Chakma Maayyaa\n+        (0x11180, 0x11182,),  # Sharada Sign Candrabindu..Sharada Sign Visarga\n+        (0x111b3, 0x111c0,),  # Sharada Vowel Sign Aa   ..Sharada Sign Virama\n+        (0x116ab, 0x116b7,),  # Takri Sign Anusvara     ..Takri Sign Nukta\n+        (0x16f51, 0x16f7e,),  # Miao Sign Aspiration    ..Miao Vowel Sign Ng\n+        (0x16f8f, 0x16f92,),  # Miao Tone Right         ..Miao Tone Below\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '6.3.0': (\n+        # Source: DerivedGeneralCategory-6.3.0.txt\n+        # Date: 2013-07-05, 14:08:45 GMT [MD]\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00604,),  # Arabic Number Sign      ..Arabic Sign Samvat\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0061c, 0x0061c,),  # Arabic Letter Mark\n+        (0x0064b, 0x0065f,),  # Arabic Fathatan         ..Arabic Wavy Hamza Below\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006dd,),  # Arabic Small High Ligatu..Arabic End Of Ayah\n+        (0x006df, 0x006e4,),  # Arabic Small High Rounde..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x00816, 0x00819,),  # Samaritan Mark In       ..Samaritan Mark Dagesh\n+        (0x0081b, 0x00823,),  # Samaritan Mark Epentheti..Samaritan Vowel Sign A\n+        (0x00825, 0x00827,),  # Samaritan Vowel Sign Sho..Samaritan Vowel Sign U\n+        (0x00829, 0x0082d,),  # Samaritan Vowel Sign Lon..Samaritan Mark Nequdaa\n+        (0x00859, 0x0085b,),  # Mandaic Affrication Mark..Mandaic Gemination Mark\n+        (0x008e4, 0x008fe,),  # Arabic Curly Fatha      ..Arabic Damma With Dot\n+        (0x00900, 0x00903,),  # Devanagari Sign Inverted..Devanagari Sign Visarga\n+        (0x0093a, 0x0093c,),  # Devanagari Vowel Sign Oe..Devanagari Sign Nukta\n+        (0x0093e, 0x0094f,),  # Devanagari Vowel Sign Aa..Devanagari Vowel Sign Aw\n+        (0x00951, 0x00957,),  # Devanagari Stress Sign U..Devanagari Vowel Sign Uu\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b56, 0x00b57,),  # Oriya Ai Length Mark    ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c01, 0x00c03,),  # Telugu Sign Candrabindu ..Telugu Sign Visarga\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c82, 0x00c83,),  # Kannada Sign Anusvara   ..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00d02, 0x00d03,),  # Malayalam Sign Anusvara ..Malayalam Sign Visarga\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d82, 0x00d83,),  # Sinhala Sign Anusvaraya ..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00eb9,),  # Lao Vowel Sign I        ..Lao Vowel Sign Uu\n+        (0x00ebb, 0x00ebc,),  # Lao Vowel Sign Mai Kon  ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f8d, 0x00f97,),  # Tibetan Subjoined Sign L..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x0109a, 0x0109d,),  # Myanmar Sign Khamti Tone..Myanmar Vowel Sign Aiton\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135d, 0x0135f,),  # Ethiopic Combining Gemin..Ethiopic Combining Gemin\n+        (0x01712, 0x01714,),  # Tagalog Vowel Sign I    ..Tagalog Sign Virama\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180e,),  # Mongolian Free Variation..Mongolian Vowel Separato\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x019b0, 0x019c0,),  # New Tai Lue Vowel Sign V..New Tai Lue Vowel Sign I\n+        (0x019c8, 0x019c9,),  # New Tai Lue Tone Mark-1 ..New Tai Lue Tone Mark-2\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01a55, 0x01a5e,),  # Tai Tham Consonant Sign ..Tai Tham Consonant Sign\n+        (0x01a60, 0x01a7c,),  # Tai Tham Sign Sakot     ..Tai Tham Sign Khuen-lue\n+        (0x01a7f, 0x01a7f,),  # Tai Tham Combining Cryptogrammic Dot\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01bad,),  # Sundanese Consonant Sign..Sundanese Consonant Sign\n+        (0x01be6, 0x01bf3,),  # Batak Sign Tompi        ..Batak Panongonan\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01cd0, 0x01cd2,),  # Vedic Tone Karshana     ..Vedic Tone Prenkha\n+        (0x01cd4, 0x01ce8,),  # Vedic Sign Yajurvedic Mi..Vedic Sign Visarga Anuda\n+        (0x01ced, 0x01ced,),  # Vedic Sign Tiryak\n+        (0x01cf2, 0x01cf4,),  # Vedic Sign Ardhavisarga ..Vedic Tone Candra Above\n+        (0x01dc0, 0x01de6,),  # Combining Dotted Grave A..Combining Latin Small Le\n+        (0x01dfc, 0x01dff,),  # Combining Double Inverte..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x02066, 0x0206f,),  # Left-to-right Isolate   ..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02cef, 0x02cf1,),  # Coptic Combining Ni Abov..Coptic Combining Spiritu\n+        (0x02d7f, 0x02d7f,),  # Tifinagh Consonant Joiner\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a674, 0x0a67d,),  # Combining Cyrillic Lette..Combining Cyrillic Payer\n+        (0x0a69f, 0x0a69f,),  # Combining Cyrillic Letter Iotified E\n+        (0x0a6f0, 0x0a6f1,),  # Bamum Combining Mark Koq..Bamum Combining Mark Tuk\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c4,),  # Saurashtra Consonant Sig..Saurashtra Sign Virama\n+        (0x0a8e0, 0x0a8f1,),  # Combining Devanagari Dig..Combining Devanagari Sig\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0a980, 0x0a983,),  # Javanese Sign Panyangga ..Javanese Sign Wignyan\n+        (0x0a9b3, 0x0a9c0,),  # Javanese Sign Cecak Telu..Javanese Pangkon\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0aa7b, 0x0aa7b,),  # Myanmar Sign Pao Karen Tone\n+        (0x0aab0, 0x0aab0,),  # Tai Viet Mai Kang\n+        (0x0aab2, 0x0aab4,),  # Tai Viet Vowel I        ..Tai Viet Vowel U\n+        (0x0aab7, 0x0aab8,),  # Tai Viet Mai Khit       ..Tai Viet Vowel Ia\n+        (0x0aabe, 0x0aabf,),  # Tai Viet Vowel Am       ..Tai Viet Tone Mai Ek\n+        (0x0aac1, 0x0aac1,),  # Tai Viet Tone Mai Tho\n+        (0x0aaeb, 0x0aaef,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0aaf5, 0x0aaf6,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Virama\n+        (0x0abe3, 0x0abea,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0abec, 0x0abed,),  # Meetei Mayek Lum Iyek   ..Meetei Mayek Apun Iyek\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe26,),  # Combining Ligature Left ..Combining Conjoining Mac\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x11000, 0x11002,),  # Brahmi Sign Candrabindu ..Brahmi Sign Visarga\n+        (0x11038, 0x11046,),  # Brahmi Vowel Sign Aa    ..Brahmi Virama\n+        (0x11080, 0x11082,),  # Kaithi Sign Candrabindu ..Kaithi Sign Visarga\n+        (0x110b0, 0x110ba,),  # Kaithi Vowel Sign Aa    ..Kaithi Sign Nukta\n+        (0x110bd, 0x110bd,),  # Kaithi Number Sign\n+        (0x11100, 0x11102,),  # Chakma Sign Candrabindu ..Chakma Sign Visarga\n+        (0x11127, 0x11134,),  # Chakma Vowel Sign A     ..Chakma Maayyaa\n+        (0x11180, 0x11182,),  # Sharada Sign Candrabindu..Sharada Sign Visarga\n+        (0x111b3, 0x111c0,),  # Sharada Vowel Sign Aa   ..Sharada Sign Virama\n+        (0x116ab, 0x116b7,),  # Takri Sign Anusvara     ..Takri Sign Nukta\n+        (0x16f51, 0x16f7e,),  # Miao Sign Aspiration    ..Miao Vowel Sign Ng\n+        (0x16f8f, 0x16f92,),  # Miao Tone Right         ..Miao Tone Below\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '7.0.0': (\n+        # Source: DerivedGeneralCategory-7.0.0.txt\n+        # Date: 2014-02-07, 18:42:12 GMT [MD]\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00605,),  # Arabic Number Sign      ..Arabic Number Mark Above\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0061c, 0x0061c,),  # Arabic Letter Mark\n+        (0x0064b, 0x0065f,),  # Arabic Fathatan         ..Arabic Wavy Hamza Below\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006dd,),  # Arabic Small High Ligatu..Arabic End Of Ayah\n+        (0x006df, 0x006e4,),  # Arabic Small High Rounde..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x00816, 0x00819,),  # Samaritan Mark In       ..Samaritan Mark Dagesh\n+        (0x0081b, 0x00823,),  # Samaritan Mark Epentheti..Samaritan Vowel Sign A\n+        (0x00825, 0x00827,),  # Samaritan Vowel Sign Sho..Samaritan Vowel Sign U\n+        (0x00829, 0x0082d,),  # Samaritan Vowel Sign Lon..Samaritan Mark Nequdaa\n+        (0x00859, 0x0085b,),  # Mandaic Affrication Mark..Mandaic Gemination Mark\n+        (0x008e4, 0x00903,),  # Arabic Curly Fatha      ..Devanagari Sign Visarga\n+        (0x0093a, 0x0093c,),  # Devanagari Vowel Sign Oe..Devanagari Sign Nukta\n+        (0x0093e, 0x0094f,),  # Devanagari Vowel Sign Aa..Devanagari Vowel Sign Aw\n+        (0x00951, 0x00957,),  # Devanagari Stress Sign U..Devanagari Vowel Sign Uu\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b56, 0x00b57,),  # Oriya Ai Length Mark    ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c00, 0x00c03,),  # Telugu Sign Combining Ca..Telugu Sign Visarga\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c81, 0x00c83,),  # Kannada Sign Candrabindu..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00d01, 0x00d03,),  # Malayalam Sign Candrabin..Malayalam Sign Visarga\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d82, 0x00d83,),  # Sinhala Sign Anusvaraya ..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00eb9,),  # Lao Vowel Sign I        ..Lao Vowel Sign Uu\n+        (0x00ebb, 0x00ebc,),  # Lao Vowel Sign Mai Kon  ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f8d, 0x00f97,),  # Tibetan Subjoined Sign L..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x0109a, 0x0109d,),  # Myanmar Sign Khamti Tone..Myanmar Vowel Sign Aiton\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135d, 0x0135f,),  # Ethiopic Combining Gemin..Ethiopic Combining Gemin\n+        (0x01712, 0x01714,),  # Tagalog Vowel Sign I    ..Tagalog Sign Virama\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180e,),  # Mongolian Free Variation..Mongolian Vowel Separato\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x019b0, 0x019c0,),  # New Tai Lue Vowel Sign V..New Tai Lue Vowel Sign I\n+        (0x019c8, 0x019c9,),  # New Tai Lue Tone Mark-1 ..New Tai Lue Tone Mark-2\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01a55, 0x01a5e,),  # Tai Tham Consonant Sign ..Tai Tham Consonant Sign\n+        (0x01a60, 0x01a7c,),  # Tai Tham Sign Sakot     ..Tai Tham Sign Khuen-lue\n+        (0x01a7f, 0x01a7f,),  # Tai Tham Combining Cryptogrammic Dot\n+        (0x01ab0, 0x01abe,),  # Combining Doubled Circum..Combining Parentheses Ov\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01bad,),  # Sundanese Consonant Sign..Sundanese Consonant Sign\n+        (0x01be6, 0x01bf3,),  # Batak Sign Tompi        ..Batak Panongonan\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01cd0, 0x01cd2,),  # Vedic Tone Karshana     ..Vedic Tone Prenkha\n+        (0x01cd4, 0x01ce8,),  # Vedic Sign Yajurvedic Mi..Vedic Sign Visarga Anuda\n+        (0x01ced, 0x01ced,),  # Vedic Sign Tiryak\n+        (0x01cf2, 0x01cf4,),  # Vedic Sign Ardhavisarga ..Vedic Tone Candra Above\n+        (0x01cf8, 0x01cf9,),  # Vedic Tone Ring Above   ..Vedic Tone Double Ring A\n+        (0x01dc0, 0x01df5,),  # Combining Dotted Grave A..Combining Up Tack Above\n+        (0x01dfc, 0x01dff,),  # Combining Double Inverte..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x02066, 0x0206f,),  # Left-to-right Isolate   ..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02cef, 0x02cf1,),  # Coptic Combining Ni Abov..Coptic Combining Spiritu\n+        (0x02d7f, 0x02d7f,),  # Tifinagh Consonant Joiner\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a674, 0x0a67d,),  # Combining Cyrillic Lette..Combining Cyrillic Payer\n+        (0x0a69f, 0x0a69f,),  # Combining Cyrillic Letter Iotified E\n+        (0x0a6f0, 0x0a6f1,),  # Bamum Combining Mark Koq..Bamum Combining Mark Tuk\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c4,),  # Saurashtra Consonant Sig..Saurashtra Sign Virama\n+        (0x0a8e0, 0x0a8f1,),  # Combining Devanagari Dig..Combining Devanagari Sig\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0a980, 0x0a983,),  # Javanese Sign Panyangga ..Javanese Sign Wignyan\n+        (0x0a9b3, 0x0a9c0,),  # Javanese Sign Cecak Telu..Javanese Pangkon\n+        (0x0a9e5, 0x0a9e5,),  # Myanmar Sign Shan Saw\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0aa7b, 0x0aa7d,),  # Myanmar Sign Pao Karen T..Myanmar Sign Tai Laing T\n+        (0x0aab0, 0x0aab0,),  # Tai Viet Mai Kang\n+        (0x0aab2, 0x0aab4,),  # Tai Viet Vowel I        ..Tai Viet Vowel U\n+        (0x0aab7, 0x0aab8,),  # Tai Viet Mai Khit       ..Tai Viet Vowel Ia\n+        (0x0aabe, 0x0aabf,),  # Tai Viet Vowel Am       ..Tai Viet Tone Mai Ek\n+        (0x0aac1, 0x0aac1,),  # Tai Viet Tone Mai Tho\n+        (0x0aaeb, 0x0aaef,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0aaf5, 0x0aaf6,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Virama\n+        (0x0abe3, 0x0abea,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0abec, 0x0abed,),  # Meetei Mayek Lum Iyek   ..Meetei Mayek Apun Iyek\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe2d,),  # Combining Ligature Left ..Combining Conjoining Mac\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x102e0, 0x102e0,),  # Coptic Epact Thousands Mark\n+        (0x10376, 0x1037a,),  # Combining Old Permic Let..Combining Old Permic Let\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x10ae5, 0x10ae6,),  # Manichaean Abbreviation ..Manichaean Abbreviation\n+        (0x11000, 0x11002,),  # Brahmi Sign Candrabindu ..Brahmi Sign Visarga\n+        (0x11038, 0x11046,),  # Brahmi Vowel Sign Aa    ..Brahmi Virama\n+        (0x1107f, 0x11082,),  # Brahmi Number Joiner    ..Kaithi Sign Visarga\n+        (0x110b0, 0x110ba,),  # Kaithi Vowel Sign Aa    ..Kaithi Sign Nukta\n+        (0x110bd, 0x110bd,),  # Kaithi Number Sign\n+        (0x11100, 0x11102,),  # Chakma Sign Candrabindu ..Chakma Sign Visarga\n+        (0x11127, 0x11134,),  # Chakma Vowel Sign A     ..Chakma Maayyaa\n+        (0x11173, 0x11173,),  # Mahajani Sign Nukta\n+        (0x11180, 0x11182,),  # Sharada Sign Candrabindu..Sharada Sign Visarga\n+        (0x111b3, 0x111c0,),  # Sharada Vowel Sign Aa   ..Sharada Sign Virama\n+        (0x1122c, 0x11237,),  # Khojki Vowel Sign Aa    ..Khojki Sign Shadda\n+        (0x112df, 0x112ea,),  # Khudawadi Sign Anusvara ..Khudawadi Sign Virama\n+        (0x11301, 0x11303,),  # Grantha Sign Candrabindu..Grantha Sign Visarga\n+        (0x1133c, 0x1133c,),  # Grantha Sign Nukta\n+        (0x1133e, 0x11344,),  # Grantha Vowel Sign Aa   ..Grantha Vowel Sign Vocal\n+        (0x11347, 0x11348,),  # Grantha Vowel Sign Ee   ..Grantha Vowel Sign Ai\n+        (0x1134b, 0x1134d,),  # Grantha Vowel Sign Oo   ..Grantha Sign Virama\n+        (0x11357, 0x11357,),  # Grantha Au Length Mark\n+        (0x11362, 0x11363,),  # Grantha Vowel Sign Vocal..Grantha Vowel Sign Vocal\n+        (0x11366, 0x1136c,),  # Combining Grantha Digit ..Combining Grantha Digit\n+        (0x11370, 0x11374,),  # Combining Grantha Letter..Combining Grantha Letter\n+        (0x114b0, 0x114c3,),  # Tirhuta Vowel Sign Aa   ..Tirhuta Sign Nukta\n+        (0x115af, 0x115b5,),  # Siddham Vowel Sign Aa   ..Siddham Vowel Sign Vocal\n+        (0x115b8, 0x115c0,),  # Siddham Vowel Sign E    ..Siddham Sign Nukta\n+        (0x11630, 0x11640,),  # Modi Vowel Sign Aa      ..Modi Sign Ardhacandra\n+        (0x116ab, 0x116b7,),  # Takri Sign Anusvara     ..Takri Sign Nukta\n+        (0x16af0, 0x16af4,),  # Bassa Vah Combining High..Bassa Vah Combining High\n+        (0x16b30, 0x16b36,),  # Pahawh Hmong Mark Cim Tu..Pahawh Hmong Mark Cim Ta\n+        (0x16f51, 0x16f7e,),  # Miao Sign Aspiration    ..Miao Vowel Sign Ng\n+        (0x16f8f, 0x16f92,),  # Miao Tone Right         ..Miao Tone Below\n+        (0x1bc9d, 0x1bc9e,),  # Duployan Thick Letter Se..Duployan Double Mark\n+        (0x1bca0, 0x1bca3,),  # Shorthand Format Letter ..Shorthand Format Up Step\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0x1e8d0, 0x1e8d6,),  # Mende Kikakui Combining ..Mende Kikakui Combining\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '8.0.0': (\n+        # Source: DerivedGeneralCategory-8.0.0.txt\n+        # Date: 2015-02-13, 13:47:11 GMT [MD]\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00605,),  # Arabic Number Sign      ..Arabic Number Mark Above\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0061c, 0x0061c,),  # Arabic Letter Mark\n+        (0x0064b, 0x0065f,),  # Arabic Fathatan         ..Arabic Wavy Hamza Below\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006dd,),  # Arabic Small High Ligatu..Arabic End Of Ayah\n+        (0x006df, 0x006e4,),  # Arabic Small High Rounde..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x00816, 0x00819,),  # Samaritan Mark In       ..Samaritan Mark Dagesh\n+        (0x0081b, 0x00823,),  # Samaritan Mark Epentheti..Samaritan Vowel Sign A\n+        (0x00825, 0x00827,),  # Samaritan Vowel Sign Sho..Samaritan Vowel Sign U\n+        (0x00829, 0x0082d,),  # Samaritan Vowel Sign Lon..Samaritan Mark Nequdaa\n+        (0x00859, 0x0085b,),  # Mandaic Affrication Mark..Mandaic Gemination Mark\n+        (0x008e3, 0x00903,),  # Arabic Turned Damma Belo..Devanagari Sign Visarga\n+        (0x0093a, 0x0093c,),  # Devanagari Vowel Sign Oe..Devanagari Sign Nukta\n+        (0x0093e, 0x0094f,),  # Devanagari Vowel Sign Aa..Devanagari Vowel Sign Aw\n+        (0x00951, 0x00957,),  # Devanagari Stress Sign U..Devanagari Vowel Sign Uu\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b56, 0x00b57,),  # Oriya Ai Length Mark    ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c00, 0x00c03,),  # Telugu Sign Combining Ca..Telugu Sign Visarga\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c81, 0x00c83,),  # Kannada Sign Candrabindu..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00d01, 0x00d03,),  # Malayalam Sign Candrabin..Malayalam Sign Visarga\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d82, 0x00d83,),  # Sinhala Sign Anusvaraya ..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00eb9,),  # Lao Vowel Sign I        ..Lao Vowel Sign Uu\n+        (0x00ebb, 0x00ebc,),  # Lao Vowel Sign Mai Kon  ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f8d, 0x00f97,),  # Tibetan Subjoined Sign L..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x0109a, 0x0109d,),  # Myanmar Sign Khamti Tone..Myanmar Vowel Sign Aiton\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135d, 0x0135f,),  # Ethiopic Combining Gemin..Ethiopic Combining Gemin\n+        (0x01712, 0x01714,),  # Tagalog Vowel Sign I    ..Tagalog Sign Virama\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180e,),  # Mongolian Free Variation..Mongolian Vowel Separato\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01a55, 0x01a5e,),  # Tai Tham Consonant Sign ..Tai Tham Consonant Sign\n+        (0x01a60, 0x01a7c,),  # Tai Tham Sign Sakot     ..Tai Tham Sign Khuen-lue\n+        (0x01a7f, 0x01a7f,),  # Tai Tham Combining Cryptogrammic Dot\n+        (0x01ab0, 0x01abe,),  # Combining Doubled Circum..Combining Parentheses Ov\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01bad,),  # Sundanese Consonant Sign..Sundanese Consonant Sign\n+        (0x01be6, 0x01bf3,),  # Batak Sign Tompi        ..Batak Panongonan\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01cd0, 0x01cd2,),  # Vedic Tone Karshana     ..Vedic Tone Prenkha\n+        (0x01cd4, 0x01ce8,),  # Vedic Sign Yajurvedic Mi..Vedic Sign Visarga Anuda\n+        (0x01ced, 0x01ced,),  # Vedic Sign Tiryak\n+        (0x01cf2, 0x01cf4,),  # Vedic Sign Ardhavisarga ..Vedic Tone Candra Above\n+        (0x01cf8, 0x01cf9,),  # Vedic Tone Ring Above   ..Vedic Tone Double Ring A\n+        (0x01dc0, 0x01df5,),  # Combining Dotted Grave A..Combining Up Tack Above\n+        (0x01dfc, 0x01dff,),  # Combining Double Inverte..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x02066, 0x0206f,),  # Left-to-right Isolate   ..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02cef, 0x02cf1,),  # Coptic Combining Ni Abov..Coptic Combining Spiritu\n+        (0x02d7f, 0x02d7f,),  # Tifinagh Consonant Joiner\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a674, 0x0a67d,),  # Combining Cyrillic Lette..Combining Cyrillic Payer\n+        (0x0a69e, 0x0a69f,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0a6f0, 0x0a6f1,),  # Bamum Combining Mark Koq..Bamum Combining Mark Tuk\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c4,),  # Saurashtra Consonant Sig..Saurashtra Sign Virama\n+        (0x0a8e0, 0x0a8f1,),  # Combining Devanagari Dig..Combining Devanagari Sig\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0a980, 0x0a983,),  # Javanese Sign Panyangga ..Javanese Sign Wignyan\n+        (0x0a9b3, 0x0a9c0,),  # Javanese Sign Cecak Telu..Javanese Pangkon\n+        (0x0a9e5, 0x0a9e5,),  # Myanmar Sign Shan Saw\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0aa7b, 0x0aa7d,),  # Myanmar Sign Pao Karen T..Myanmar Sign Tai Laing T\n+        (0x0aab0, 0x0aab0,),  # Tai Viet Mai Kang\n+        (0x0aab2, 0x0aab4,),  # Tai Viet Vowel I        ..Tai Viet Vowel U\n+        (0x0aab7, 0x0aab8,),  # Tai Viet Mai Khit       ..Tai Viet Vowel Ia\n+        (0x0aabe, 0x0aabf,),  # Tai Viet Vowel Am       ..Tai Viet Tone Mai Ek\n+        (0x0aac1, 0x0aac1,),  # Tai Viet Tone Mai Tho\n+        (0x0aaeb, 0x0aaef,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0aaf5, 0x0aaf6,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Virama\n+        (0x0abe3, 0x0abea,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0abec, 0x0abed,),  # Meetei Mayek Lum Iyek   ..Meetei Mayek Apun Iyek\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe2f,),  # Combining Ligature Left ..Combining Cyrillic Titlo\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x102e0, 0x102e0,),  # Coptic Epact Thousands Mark\n+        (0x10376, 0x1037a,),  # Combining Old Permic Let..Combining Old Permic Let\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x10ae5, 0x10ae6,),  # Manichaean Abbreviation ..Manichaean Abbreviation\n+        (0x11000, 0x11002,),  # Brahmi Sign Candrabindu ..Brahmi Sign Visarga\n+        (0x11038, 0x11046,),  # Brahmi Vowel Sign Aa    ..Brahmi Virama\n+        (0x1107f, 0x11082,),  # Brahmi Number Joiner    ..Kaithi Sign Visarga\n+        (0x110b0, 0x110ba,),  # Kaithi Vowel Sign Aa    ..Kaithi Sign Nukta\n+        (0x110bd, 0x110bd,),  # Kaithi Number Sign\n+        (0x11100, 0x11102,),  # Chakma Sign Candrabindu ..Chakma Sign Visarga\n+        (0x11127, 0x11134,),  # Chakma Vowel Sign A     ..Chakma Maayyaa\n+        (0x11173, 0x11173,),  # Mahajani Sign Nukta\n+        (0x11180, 0x11182,),  # Sharada Sign Candrabindu..Sharada Sign Visarga\n+        (0x111b3, 0x111c0,),  # Sharada Vowel Sign Aa   ..Sharada Sign Virama\n+        (0x111ca, 0x111cc,),  # Sharada Sign Nukta      ..Sharada Extra Short Vowe\n+        (0x1122c, 0x11237,),  # Khojki Vowel Sign Aa    ..Khojki Sign Shadda\n+        (0x112df, 0x112ea,),  # Khudawadi Sign Anusvara ..Khudawadi Sign Virama\n+        (0x11300, 0x11303,),  # Grantha Sign Combining A..Grantha Sign Visarga\n+        (0x1133c, 0x1133c,),  # Grantha Sign Nukta\n+        (0x1133e, 0x11344,),  # Grantha Vowel Sign Aa   ..Grantha Vowel Sign Vocal\n+        (0x11347, 0x11348,),  # Grantha Vowel Sign Ee   ..Grantha Vowel Sign Ai\n+        (0x1134b, 0x1134d,),  # Grantha Vowel Sign Oo   ..Grantha Sign Virama\n+        (0x11357, 0x11357,),  # Grantha Au Length Mark\n+        (0x11362, 0x11363,),  # Grantha Vowel Sign Vocal..Grantha Vowel Sign Vocal\n+        (0x11366, 0x1136c,),  # Combining Grantha Digit ..Combining Grantha Digit\n+        (0x11370, 0x11374,),  # Combining Grantha Letter..Combining Grantha Letter\n+        (0x114b0, 0x114c3,),  # Tirhuta Vowel Sign Aa   ..Tirhuta Sign Nukta\n+        (0x115af, 0x115b5,),  # Siddham Vowel Sign Aa   ..Siddham Vowel Sign Vocal\n+        (0x115b8, 0x115c0,),  # Siddham Vowel Sign E    ..Siddham Sign Nukta\n+        (0x115dc, 0x115dd,),  # Siddham Vowel Sign Alter..Siddham Vowel Sign Alter\n+        (0x11630, 0x11640,),  # Modi Vowel Sign Aa      ..Modi Sign Ardhacandra\n+        (0x116ab, 0x116b7,),  # Takri Sign Anusvara     ..Takri Sign Nukta\n+        (0x1171d, 0x1172b,),  # Ahom Consonant Sign Medi..Ahom Sign Killer\n+        (0x16af0, 0x16af4,),  # Bassa Vah Combining High..Bassa Vah Combining High\n+        (0x16b30, 0x16b36,),  # Pahawh Hmong Mark Cim Tu..Pahawh Hmong Mark Cim Ta\n+        (0x16f51, 0x16f7e,),  # Miao Sign Aspiration    ..Miao Vowel Sign Ng\n+        (0x16f8f, 0x16f92,),  # Miao Tone Right         ..Miao Tone Below\n+        (0x1bc9d, 0x1bc9e,),  # Duployan Thick Letter Se..Duployan Double Mark\n+        (0x1bca0, 0x1bca3,),  # Shorthand Format Letter ..Shorthand Format Up Step\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0x1da00, 0x1da36,),  # Signwriting Head Rim    ..Signwriting Air Sucking\n+        (0x1da3b, 0x1da6c,),  # Signwriting Mouth Closed..Signwriting Excitement\n+        (0x1da75, 0x1da75,),  # Signwriting Upper Body Tilting From Hip Joints\n+        (0x1da84, 0x1da84,),  # Signwriting Location Head Neck\n+        (0x1da9b, 0x1da9f,),  # Signwriting Fill Modifie..Signwriting Fill Modifie\n+        (0x1daa1, 0x1daaf,),  # Signwriting Rotation Mod..Signwriting Rotation Mod\n+        (0x1e8d0, 0x1e8d6,),  # Mende Kikakui Combining ..Mende Kikakui Combining\n+        (0x1f3fb, 0x1f3ff,),  # Emoji Modifier Fitzpatri..Emoji Modifier Fitzpatri\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '9.0.0': (\n+        # Source: DerivedGeneralCategory-9.0.0.txt\n+        # Date: 2016-06-01, 10:34:26 GMT\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00605,),  # Arabic Number Sign      ..Arabic Number Mark Above\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0061c, 0x0061c,),  # Arabic Letter Mark\n+        (0x0064b, 0x0065f,),  # Arabic Fathatan         ..Arabic Wavy Hamza Below\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006dd,),  # Arabic Small High Ligatu..Arabic End Of Ayah\n+        (0x006df, 0x006e4,),  # Arabic Small High Rounde..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x00816, 0x00819,),  # Samaritan Mark In       ..Samaritan Mark Dagesh\n+        (0x0081b, 0x00823,),  # Samaritan Mark Epentheti..Samaritan Vowel Sign A\n+        (0x00825, 0x00827,),  # Samaritan Vowel Sign Sho..Samaritan Vowel Sign U\n+        (0x00829, 0x0082d,),  # Samaritan Vowel Sign Lon..Samaritan Mark Nequdaa\n+        (0x00859, 0x0085b,),  # Mandaic Affrication Mark..Mandaic Gemination Mark\n+        (0x008d4, 0x00903,),  # Arabic Small High Word A..Devanagari Sign Visarga\n+        (0x0093a, 0x0093c,),  # Devanagari Vowel Sign Oe..Devanagari Sign Nukta\n+        (0x0093e, 0x0094f,),  # Devanagari Vowel Sign Aa..Devanagari Vowel Sign Aw\n+        (0x00951, 0x00957,),  # Devanagari Stress Sign U..Devanagari Vowel Sign Uu\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b56, 0x00b57,),  # Oriya Ai Length Mark    ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c00, 0x00c03,),  # Telugu Sign Combining Ca..Telugu Sign Visarga\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c81, 0x00c83,),  # Kannada Sign Candrabindu..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00d01, 0x00d03,),  # Malayalam Sign Candrabin..Malayalam Sign Visarga\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d82, 0x00d83,),  # Sinhala Sign Anusvaraya ..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00eb9,),  # Lao Vowel Sign I        ..Lao Vowel Sign Uu\n+        (0x00ebb, 0x00ebc,),  # Lao Vowel Sign Mai Kon  ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f8d, 0x00f97,),  # Tibetan Subjoined Sign L..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x0109a, 0x0109d,),  # Myanmar Sign Khamti Tone..Myanmar Vowel Sign Aiton\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135d, 0x0135f,),  # Ethiopic Combining Gemin..Ethiopic Combining Gemin\n+        (0x01712, 0x01714,),  # Tagalog Vowel Sign I    ..Tagalog Sign Virama\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180e,),  # Mongolian Free Variation..Mongolian Vowel Separato\n+        (0x01885, 0x01886,),  # Mongolian Letter Ali Gal..Mongolian Letter Ali Gal\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01a55, 0x01a5e,),  # Tai Tham Consonant Sign ..Tai Tham Consonant Sign\n+        (0x01a60, 0x01a7c,),  # Tai Tham Sign Sakot     ..Tai Tham Sign Khuen-lue\n+        (0x01a7f, 0x01a7f,),  # Tai Tham Combining Cryptogrammic Dot\n+        (0x01ab0, 0x01abe,),  # Combining Doubled Circum..Combining Parentheses Ov\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01bad,),  # Sundanese Consonant Sign..Sundanese Consonant Sign\n+        (0x01be6, 0x01bf3,),  # Batak Sign Tompi        ..Batak Panongonan\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01cd0, 0x01cd2,),  # Vedic Tone Karshana     ..Vedic Tone Prenkha\n+        (0x01cd4, 0x01ce8,),  # Vedic Sign Yajurvedic Mi..Vedic Sign Visarga Anuda\n+        (0x01ced, 0x01ced,),  # Vedic Sign Tiryak\n+        (0x01cf2, 0x01cf4,),  # Vedic Sign Ardhavisarga ..Vedic Tone Candra Above\n+        (0x01cf8, 0x01cf9,),  # Vedic Tone Ring Above   ..Vedic Tone Double Ring A\n+        (0x01dc0, 0x01df5,),  # Combining Dotted Grave A..Combining Up Tack Above\n+        (0x01dfb, 0x01dff,),  # Combining Deletion Mark ..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x02066, 0x0206f,),  # Left-to-right Isolate   ..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02cef, 0x02cf1,),  # Coptic Combining Ni Abov..Coptic Combining Spiritu\n+        (0x02d7f, 0x02d7f,),  # Tifinagh Consonant Joiner\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a674, 0x0a67d,),  # Combining Cyrillic Lette..Combining Cyrillic Payer\n+        (0x0a69e, 0x0a69f,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0a6f0, 0x0a6f1,),  # Bamum Combining Mark Koq..Bamum Combining Mark Tuk\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c5,),  # Saurashtra Consonant Sig..Saurashtra Sign Candrabi\n+        (0x0a8e0, 0x0a8f1,),  # Combining Devanagari Dig..Combining Devanagari Sig\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0a980, 0x0a983,),  # Javanese Sign Panyangga ..Javanese Sign Wignyan\n+        (0x0a9b3, 0x0a9c0,),  # Javanese Sign Cecak Telu..Javanese Pangkon\n+        (0x0a9e5, 0x0a9e5,),  # Myanmar Sign Shan Saw\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0aa7b, 0x0aa7d,),  # Myanmar Sign Pao Karen T..Myanmar Sign Tai Laing T\n+        (0x0aab0, 0x0aab0,),  # Tai Viet Mai Kang\n+        (0x0aab2, 0x0aab4,),  # Tai Viet Vowel I        ..Tai Viet Vowel U\n+        (0x0aab7, 0x0aab8,),  # Tai Viet Mai Khit       ..Tai Viet Vowel Ia\n+        (0x0aabe, 0x0aabf,),  # Tai Viet Vowel Am       ..Tai Viet Tone Mai Ek\n+        (0x0aac1, 0x0aac1,),  # Tai Viet Tone Mai Tho\n+        (0x0aaeb, 0x0aaef,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0aaf5, 0x0aaf6,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Virama\n+        (0x0abe3, 0x0abea,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0abec, 0x0abed,),  # Meetei Mayek Lum Iyek   ..Meetei Mayek Apun Iyek\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe2f,),  # Combining Ligature Left ..Combining Cyrillic Titlo\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x102e0, 0x102e0,),  # Coptic Epact Thousands Mark\n+        (0x10376, 0x1037a,),  # Combining Old Permic Let..Combining Old Permic Let\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x10ae5, 0x10ae6,),  # Manichaean Abbreviation ..Manichaean Abbreviation\n+        (0x11000, 0x11002,),  # Brahmi Sign Candrabindu ..Brahmi Sign Visarga\n+        (0x11038, 0x11046,),  # Brahmi Vowel Sign Aa    ..Brahmi Virama\n+        (0x1107f, 0x11082,),  # Brahmi Number Joiner    ..Kaithi Sign Visarga\n+        (0x110b0, 0x110ba,),  # Kaithi Vowel Sign Aa    ..Kaithi Sign Nukta\n+        (0x110bd, 0x110bd,),  # Kaithi Number Sign\n+        (0x11100, 0x11102,),  # Chakma Sign Candrabindu ..Chakma Sign Visarga\n+        (0x11127, 0x11134,),  # Chakma Vowel Sign A     ..Chakma Maayyaa\n+        (0x11173, 0x11173,),  # Mahajani Sign Nukta\n+        (0x11180, 0x11182,),  # Sharada Sign Candrabindu..Sharada Sign Visarga\n+        (0x111b3, 0x111c0,),  # Sharada Vowel Sign Aa   ..Sharada Sign Virama\n+        (0x111ca, 0x111cc,),  # Sharada Sign Nukta      ..Sharada Extra Short Vowe\n+        (0x1122c, 0x11237,),  # Khojki Vowel Sign Aa    ..Khojki Sign Shadda\n+        (0x1123e, 0x1123e,),  # Khojki Sign Sukun\n+        (0x112df, 0x112ea,),  # Khudawadi Sign Anusvara ..Khudawadi Sign Virama\n+        (0x11300, 0x11303,),  # Grantha Sign Combining A..Grantha Sign Visarga\n+        (0x1133c, 0x1133c,),  # Grantha Sign Nukta\n+        (0x1133e, 0x11344,),  # Grantha Vowel Sign Aa   ..Grantha Vowel Sign Vocal\n+        (0x11347, 0x11348,),  # Grantha Vowel Sign Ee   ..Grantha Vowel Sign Ai\n+        (0x1134b, 0x1134d,),  # Grantha Vowel Sign Oo   ..Grantha Sign Virama\n+        (0x11357, 0x11357,),  # Grantha Au Length Mark\n+        (0x11362, 0x11363,),  # Grantha Vowel Sign Vocal..Grantha Vowel Sign Vocal\n+        (0x11366, 0x1136c,),  # Combining Grantha Digit ..Combining Grantha Digit\n+        (0x11370, 0x11374,),  # Combining Grantha Letter..Combining Grantha Letter\n+        (0x11435, 0x11446,),  # Newa Vowel Sign Aa      ..Newa Sign Nukta\n+        (0x114b0, 0x114c3,),  # Tirhuta Vowel Sign Aa   ..Tirhuta Sign Nukta\n+        (0x115af, 0x115b5,),  # Siddham Vowel Sign Aa   ..Siddham Vowel Sign Vocal\n+        (0x115b8, 0x115c0,),  # Siddham Vowel Sign E    ..Siddham Sign Nukta\n+        (0x115dc, 0x115dd,),  # Siddham Vowel Sign Alter..Siddham Vowel Sign Alter\n+        (0x11630, 0x11640,),  # Modi Vowel Sign Aa      ..Modi Sign Ardhacandra\n+        (0x116ab, 0x116b7,),  # Takri Sign Anusvara     ..Takri Sign Nukta\n+        (0x1171d, 0x1172b,),  # Ahom Consonant Sign Medi..Ahom Sign Killer\n+        (0x11c2f, 0x11c36,),  # Bhaiksuki Vowel Sign Aa ..Bhaiksuki Vowel Sign Voc\n+        (0x11c38, 0x11c3f,),  # Bhaiksuki Vowel Sign E  ..Bhaiksuki Sign Virama\n+        (0x11c92, 0x11ca7,),  # Marchen Subjoined Letter..Marchen Subjoined Letter\n+        (0x11ca9, 0x11cb6,),  # Marchen Subjoined Letter..Marchen Sign Candrabindu\n+        (0x16af0, 0x16af4,),  # Bassa Vah Combining High..Bassa Vah Combining High\n+        (0x16b30, 0x16b36,),  # Pahawh Hmong Mark Cim Tu..Pahawh Hmong Mark Cim Ta\n+        (0x16f51, 0x16f7e,),  # Miao Sign Aspiration    ..Miao Vowel Sign Ng\n+        (0x16f8f, 0x16f92,),  # Miao Tone Right         ..Miao Tone Below\n+        (0x1bc9d, 0x1bc9e,),  # Duployan Thick Letter Se..Duployan Double Mark\n+        (0x1bca0, 0x1bca3,),  # Shorthand Format Letter ..Shorthand Format Up Step\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0x1da00, 0x1da36,),  # Signwriting Head Rim    ..Signwriting Air Sucking\n+        (0x1da3b, 0x1da6c,),  # Signwriting Mouth Closed..Signwriting Excitement\n+        (0x1da75, 0x1da75,),  # Signwriting Upper Body Tilting From Hip Joints\n+        (0x1da84, 0x1da84,),  # Signwriting Location Head Neck\n+        (0x1da9b, 0x1da9f,),  # Signwriting Fill Modifie..Signwriting Fill Modifie\n+        (0x1daa1, 0x1daaf,),  # Signwriting Rotation Mod..Signwriting Rotation Mod\n+        (0x1e000, 0x1e006,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e008, 0x1e018,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e01b, 0x1e021,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e023, 0x1e024,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e026, 0x1e02a,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e8d0, 0x1e8d6,),  # Mende Kikakui Combining ..Mende Kikakui Combining\n+        (0x1e944, 0x1e94a,),  # Adlam Alif Lengthener   ..Adlam Nukta\n+        (0x1f3fb, 0x1f3ff,),  # Emoji Modifier Fitzpatri..Emoji Modifier Fitzpatri\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '10.0.0': (\n+        # Source: DerivedGeneralCategory-10.0.0.txt\n+        # Date: 2017-03-08, 08:41:49 GMT\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00605,),  # Arabic Number Sign      ..Arabic Number Mark Above\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0061c, 0x0061c,),  # Arabic Letter Mark\n+        (0x0064b, 0x0065f,),  # Arabic Fathatan         ..Arabic Wavy Hamza Below\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006dd,),  # Arabic Small High Ligatu..Arabic End Of Ayah\n+        (0x006df, 0x006e4,),  # Arabic Small High Rounde..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x00816, 0x00819,),  # Samaritan Mark In       ..Samaritan Mark Dagesh\n+        (0x0081b, 0x00823,),  # Samaritan Mark Epentheti..Samaritan Vowel Sign A\n+        (0x00825, 0x00827,),  # Samaritan Vowel Sign Sho..Samaritan Vowel Sign U\n+        (0x00829, 0x0082d,),  # Samaritan Vowel Sign Lon..Samaritan Mark Nequdaa\n+        (0x00859, 0x0085b,),  # Mandaic Affrication Mark..Mandaic Gemination Mark\n+        (0x008d4, 0x00903,),  # Arabic Small High Word A..Devanagari Sign Visarga\n+        (0x0093a, 0x0093c,),  # Devanagari Vowel Sign Oe..Devanagari Sign Nukta\n+        (0x0093e, 0x0094f,),  # Devanagari Vowel Sign Aa..Devanagari Vowel Sign Aw\n+        (0x00951, 0x00957,),  # Devanagari Stress Sign U..Devanagari Vowel Sign Uu\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00afa, 0x00aff,),  # Gujarati Sign Sukun     ..Gujarati Sign Two-circle\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b56, 0x00b57,),  # Oriya Ai Length Mark    ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c00, 0x00c03,),  # Telugu Sign Combining Ca..Telugu Sign Visarga\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c81, 0x00c83,),  # Kannada Sign Candrabindu..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00d00, 0x00d03,),  # Malayalam Sign Combining..Malayalam Sign Visarga\n+        (0x00d3b, 0x00d3c,),  # Malayalam Sign Vertical ..Malayalam Sign Circular\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d82, 0x00d83,),  # Sinhala Sign Anusvaraya ..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00eb9,),  # Lao Vowel Sign I        ..Lao Vowel Sign Uu\n+        (0x00ebb, 0x00ebc,),  # Lao Vowel Sign Mai Kon  ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f8d, 0x00f97,),  # Tibetan Subjoined Sign L..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x0109a, 0x0109d,),  # Myanmar Sign Khamti Tone..Myanmar Vowel Sign Aiton\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135d, 0x0135f,),  # Ethiopic Combining Gemin..Ethiopic Combining Gemin\n+        (0x01712, 0x01714,),  # Tagalog Vowel Sign I    ..Tagalog Sign Virama\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180e,),  # Mongolian Free Variation..Mongolian Vowel Separato\n+        (0x01885, 0x01886,),  # Mongolian Letter Ali Gal..Mongolian Letter Ali Gal\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01a55, 0x01a5e,),  # Tai Tham Consonant Sign ..Tai Tham Consonant Sign\n+        (0x01a60, 0x01a7c,),  # Tai Tham Sign Sakot     ..Tai Tham Sign Khuen-lue\n+        (0x01a7f, 0x01a7f,),  # Tai Tham Combining Cryptogrammic Dot\n+        (0x01ab0, 0x01abe,),  # Combining Doubled Circum..Combining Parentheses Ov\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01bad,),  # Sundanese Consonant Sign..Sundanese Consonant Sign\n+        (0x01be6, 0x01bf3,),  # Batak Sign Tompi        ..Batak Panongonan\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01cd0, 0x01cd2,),  # Vedic Tone Karshana     ..Vedic Tone Prenkha\n+        (0x01cd4, 0x01ce8,),  # Vedic Sign Yajurvedic Mi..Vedic Sign Visarga Anuda\n+        (0x01ced, 0x01ced,),  # Vedic Sign Tiryak\n+        (0x01cf2, 0x01cf4,),  # Vedic Sign Ardhavisarga ..Vedic Tone Candra Above\n+        (0x01cf7, 0x01cf9,),  # Vedic Sign Atikrama     ..Vedic Tone Double Ring A\n+        (0x01dc0, 0x01df9,),  # Combining Dotted Grave A..Combining Wide Inverted\n+        (0x01dfb, 0x01dff,),  # Combining Deletion Mark ..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x02066, 0x0206f,),  # Left-to-right Isolate   ..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02cef, 0x02cf1,),  # Coptic Combining Ni Abov..Coptic Combining Spiritu\n+        (0x02d7f, 0x02d7f,),  # Tifinagh Consonant Joiner\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a674, 0x0a67d,),  # Combining Cyrillic Lette..Combining Cyrillic Payer\n+        (0x0a69e, 0x0a69f,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0a6f0, 0x0a6f1,),  # Bamum Combining Mark Koq..Bamum Combining Mark Tuk\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c5,),  # Saurashtra Consonant Sig..Saurashtra Sign Candrabi\n+        (0x0a8e0, 0x0a8f1,),  # Combining Devanagari Dig..Combining Devanagari Sig\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0a980, 0x0a983,),  # Javanese Sign Panyangga ..Javanese Sign Wignyan\n+        (0x0a9b3, 0x0a9c0,),  # Javanese Sign Cecak Telu..Javanese Pangkon\n+        (0x0a9e5, 0x0a9e5,),  # Myanmar Sign Shan Saw\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0aa7b, 0x0aa7d,),  # Myanmar Sign Pao Karen T..Myanmar Sign Tai Laing T\n+        (0x0aab0, 0x0aab0,),  # Tai Viet Mai Kang\n+        (0x0aab2, 0x0aab4,),  # Tai Viet Vowel I        ..Tai Viet Vowel U\n+        (0x0aab7, 0x0aab8,),  # Tai Viet Mai Khit       ..Tai Viet Vowel Ia\n+        (0x0aabe, 0x0aabf,),  # Tai Viet Vowel Am       ..Tai Viet Tone Mai Ek\n+        (0x0aac1, 0x0aac1,),  # Tai Viet Tone Mai Tho\n+        (0x0aaeb, 0x0aaef,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0aaf5, 0x0aaf6,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Virama\n+        (0x0abe3, 0x0abea,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0abec, 0x0abed,),  # Meetei Mayek Lum Iyek   ..Meetei Mayek Apun Iyek\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe2f,),  # Combining Ligature Left ..Combining Cyrillic Titlo\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x102e0, 0x102e0,),  # Coptic Epact Thousands Mark\n+        (0x10376, 0x1037a,),  # Combining Old Permic Let..Combining Old Permic Let\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x10ae5, 0x10ae6,),  # Manichaean Abbreviation ..Manichaean Abbreviation\n+        (0x11000, 0x11002,),  # Brahmi Sign Candrabindu ..Brahmi Sign Visarga\n+        (0x11038, 0x11046,),  # Brahmi Vowel Sign Aa    ..Brahmi Virama\n+        (0x1107f, 0x11082,),  # Brahmi Number Joiner    ..Kaithi Sign Visarga\n+        (0x110b0, 0x110ba,),  # Kaithi Vowel Sign Aa    ..Kaithi Sign Nukta\n+        (0x110bd, 0x110bd,),  # Kaithi Number Sign\n+        (0x11100, 0x11102,),  # Chakma Sign Candrabindu ..Chakma Sign Visarga\n+        (0x11127, 0x11134,),  # Chakma Vowel Sign A     ..Chakma Maayyaa\n+        (0x11173, 0x11173,),  # Mahajani Sign Nukta\n+        (0x11180, 0x11182,),  # Sharada Sign Candrabindu..Sharada Sign Visarga\n+        (0x111b3, 0x111c0,),  # Sharada Vowel Sign Aa   ..Sharada Sign Virama\n+        (0x111ca, 0x111cc,),  # Sharada Sign Nukta      ..Sharada Extra Short Vowe\n+        (0x1122c, 0x11237,),  # Khojki Vowel Sign Aa    ..Khojki Sign Shadda\n+        (0x1123e, 0x1123e,),  # Khojki Sign Sukun\n+        (0x112df, 0x112ea,),  # Khudawadi Sign Anusvara ..Khudawadi Sign Virama\n+        (0x11300, 0x11303,),  # Grantha Sign Combining A..Grantha Sign Visarga\n+        (0x1133c, 0x1133c,),  # Grantha Sign Nukta\n+        (0x1133e, 0x11344,),  # Grantha Vowel Sign Aa   ..Grantha Vowel Sign Vocal\n+        (0x11347, 0x11348,),  # Grantha Vowel Sign Ee   ..Grantha Vowel Sign Ai\n+        (0x1134b, 0x1134d,),  # Grantha Vowel Sign Oo   ..Grantha Sign Virama\n+        (0x11357, 0x11357,),  # Grantha Au Length Mark\n+        (0x11362, 0x11363,),  # Grantha Vowel Sign Vocal..Grantha Vowel Sign Vocal\n+        (0x11366, 0x1136c,),  # Combining Grantha Digit ..Combining Grantha Digit\n+        (0x11370, 0x11374,),  # Combining Grantha Letter..Combining Grantha Letter\n+        (0x11435, 0x11446,),  # Newa Vowel Sign Aa      ..Newa Sign Nukta\n+        (0x114b0, 0x114c3,),  # Tirhuta Vowel Sign Aa   ..Tirhuta Sign Nukta\n+        (0x115af, 0x115b5,),  # Siddham Vowel Sign Aa   ..Siddham Vowel Sign Vocal\n+        (0x115b8, 0x115c0,),  # Siddham Vowel Sign E    ..Siddham Sign Nukta\n+        (0x115dc, 0x115dd,),  # Siddham Vowel Sign Alter..Siddham Vowel Sign Alter\n+        (0x11630, 0x11640,),  # Modi Vowel Sign Aa      ..Modi Sign Ardhacandra\n+        (0x116ab, 0x116b7,),  # Takri Sign Anusvara     ..Takri Sign Nukta\n+        (0x1171d, 0x1172b,),  # Ahom Consonant Sign Medi..Ahom Sign Killer\n+        (0x11a01, 0x11a0a,),  # Zanabazar Square Vowel S..Zanabazar Square Vowel L\n+        (0x11a33, 0x11a39,),  # Zanabazar Square Final C..Zanabazar Square Sign Vi\n+        (0x11a3b, 0x11a3e,),  # Zanabazar Square Cluster..Zanabazar Square Cluster\n+        (0x11a47, 0x11a47,),  # Zanabazar Square Subjoiner\n+        (0x11a51, 0x11a5b,),  # Soyombo Vowel Sign I    ..Soyombo Vowel Length Mar\n+        (0x11a8a, 0x11a99,),  # Soyombo Final Consonant ..Soyombo Subjoiner\n+        (0x11c2f, 0x11c36,),  # Bhaiksuki Vowel Sign Aa ..Bhaiksuki Vowel Sign Voc\n+        (0x11c38, 0x11c3f,),  # Bhaiksuki Vowel Sign E  ..Bhaiksuki Sign Virama\n+        (0x11c92, 0x11ca7,),  # Marchen Subjoined Letter..Marchen Subjoined Letter\n+        (0x11ca9, 0x11cb6,),  # Marchen Subjoined Letter..Marchen Sign Candrabindu\n+        (0x11d31, 0x11d36,),  # Masaram Gondi Vowel Sign..Masaram Gondi Vowel Sign\n+        (0x11d3a, 0x11d3a,),  # Masaram Gondi Vowel Sign E\n+        (0x11d3c, 0x11d3d,),  # Masaram Gondi Vowel Sign..Masaram Gondi Vowel Sign\n+        (0x11d3f, 0x11d45,),  # Masaram Gondi Vowel Sign..Masaram Gondi Virama\n+        (0x11d47, 0x11d47,),  # Masaram Gondi Ra-kara\n+        (0x16af0, 0x16af4,),  # Bassa Vah Combining High..Bassa Vah Combining High\n+        (0x16b30, 0x16b36,),  # Pahawh Hmong Mark Cim Tu..Pahawh Hmong Mark Cim Ta\n+        (0x16f51, 0x16f7e,),  # Miao Sign Aspiration    ..Miao Vowel Sign Ng\n+        (0x16f8f, 0x16f92,),  # Miao Tone Right         ..Miao Tone Below\n+        (0x1bc9d, 0x1bc9e,),  # Duployan Thick Letter Se..Duployan Double Mark\n+        (0x1bca0, 0x1bca3,),  # Shorthand Format Letter ..Shorthand Format Up Step\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0x1da00, 0x1da36,),  # Signwriting Head Rim    ..Signwriting Air Sucking\n+        (0x1da3b, 0x1da6c,),  # Signwriting Mouth Closed..Signwriting Excitement\n+        (0x1da75, 0x1da75,),  # Signwriting Upper Body Tilting From Hip Joints\n+        (0x1da84, 0x1da84,),  # Signwriting Location Head Neck\n+        (0x1da9b, 0x1da9f,),  # Signwriting Fill Modifie..Signwriting Fill Modifie\n+        (0x1daa1, 0x1daaf,),  # Signwriting Rotation Mod..Signwriting Rotation Mod\n+        (0x1e000, 0x1e006,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e008, 0x1e018,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e01b, 0x1e021,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e023, 0x1e024,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e026, 0x1e02a,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e8d0, 0x1e8d6,),  # Mende Kikakui Combining ..Mende Kikakui Combining\n+        (0x1e944, 0x1e94a,),  # Adlam Alif Lengthener   ..Adlam Nukta\n+        (0x1f3fb, 0x1f3ff,),  # Emoji Modifier Fitzpatri..Emoji Modifier Fitzpatri\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '11.0.0': (\n+        # Source: DerivedGeneralCategory-11.0.0.txt\n+        # Date: 2018-02-21, 05:34:04 GMT\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00605,),  # Arabic Number Sign      ..Arabic Number Mark Above\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0061c, 0x0061c,),  # Arabic Letter Mark\n+        (0x0064b, 0x0065f,),  # Arabic Fathatan         ..Arabic Wavy Hamza Below\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006dd,),  # Arabic Small High Ligatu..Arabic End Of Ayah\n+        (0x006df, 0x006e4,),  # Arabic Small High Rounde..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x007fd, 0x007fd,),  # Nko Dantayalan\n+        (0x00816, 0x00819,),  # Samaritan Mark In       ..Samaritan Mark Dagesh\n+        (0x0081b, 0x00823,),  # Samaritan Mark Epentheti..Samaritan Vowel Sign A\n+        (0x00825, 0x00827,),  # Samaritan Vowel Sign Sho..Samaritan Vowel Sign U\n+        (0x00829, 0x0082d,),  # Samaritan Vowel Sign Lon..Samaritan Mark Nequdaa\n+        (0x00859, 0x0085b,),  # Mandaic Affrication Mark..Mandaic Gemination Mark\n+        (0x008d3, 0x00903,),  # Arabic Small Low Waw    ..Devanagari Sign Visarga\n+        (0x0093a, 0x0093c,),  # Devanagari Vowel Sign Oe..Devanagari Sign Nukta\n+        (0x0093e, 0x0094f,),  # Devanagari Vowel Sign Aa..Devanagari Vowel Sign Aw\n+        (0x00951, 0x00957,),  # Devanagari Stress Sign U..Devanagari Vowel Sign Uu\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x009fe, 0x009fe,),  # Bengali Sandhi Mark\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00afa, 0x00aff,),  # Gujarati Sign Sukun     ..Gujarati Sign Two-circle\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b56, 0x00b57,),  # Oriya Ai Length Mark    ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c00, 0x00c04,),  # Telugu Sign Combining Ca..Telugu Sign Combining An\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c81, 0x00c83,),  # Kannada Sign Candrabindu..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00d00, 0x00d03,),  # Malayalam Sign Combining..Malayalam Sign Visarga\n+        (0x00d3b, 0x00d3c,),  # Malayalam Sign Vertical ..Malayalam Sign Circular\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d82, 0x00d83,),  # Sinhala Sign Anusvaraya ..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00eb9,),  # Lao Vowel Sign I        ..Lao Vowel Sign Uu\n+        (0x00ebb, 0x00ebc,),  # Lao Vowel Sign Mai Kon  ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f8d, 0x00f97,),  # Tibetan Subjoined Sign L..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x0109a, 0x0109d,),  # Myanmar Sign Khamti Tone..Myanmar Vowel Sign Aiton\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135d, 0x0135f,),  # Ethiopic Combining Gemin..Ethiopic Combining Gemin\n+        (0x01712, 0x01714,),  # Tagalog Vowel Sign I    ..Tagalog Sign Virama\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180e,),  # Mongolian Free Variation..Mongolian Vowel Separato\n+        (0x01885, 0x01886,),  # Mongolian Letter Ali Gal..Mongolian Letter Ali Gal\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01a55, 0x01a5e,),  # Tai Tham Consonant Sign ..Tai Tham Consonant Sign\n+        (0x01a60, 0x01a7c,),  # Tai Tham Sign Sakot     ..Tai Tham Sign Khuen-lue\n+        (0x01a7f, 0x01a7f,),  # Tai Tham Combining Cryptogrammic Dot\n+        (0x01ab0, 0x01abe,),  # Combining Doubled Circum..Combining Parentheses Ov\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01bad,),  # Sundanese Consonant Sign..Sundanese Consonant Sign\n+        (0x01be6, 0x01bf3,),  # Batak Sign Tompi        ..Batak Panongonan\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01cd0, 0x01cd2,),  # Vedic Tone Karshana     ..Vedic Tone Prenkha\n+        (0x01cd4, 0x01ce8,),  # Vedic Sign Yajurvedic Mi..Vedic Sign Visarga Anuda\n+        (0x01ced, 0x01ced,),  # Vedic Sign Tiryak\n+        (0x01cf2, 0x01cf4,),  # Vedic Sign Ardhavisarga ..Vedic Tone Candra Above\n+        (0x01cf7, 0x01cf9,),  # Vedic Sign Atikrama     ..Vedic Tone Double Ring A\n+        (0x01dc0, 0x01df9,),  # Combining Dotted Grave A..Combining Wide Inverted\n+        (0x01dfb, 0x01dff,),  # Combining Deletion Mark ..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x02066, 0x0206f,),  # Left-to-right Isolate   ..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02cef, 0x02cf1,),  # Coptic Combining Ni Abov..Coptic Combining Spiritu\n+        (0x02d7f, 0x02d7f,),  # Tifinagh Consonant Joiner\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a674, 0x0a67d,),  # Combining Cyrillic Lette..Combining Cyrillic Payer\n+        (0x0a69e, 0x0a69f,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0a6f0, 0x0a6f1,),  # Bamum Combining Mark Koq..Bamum Combining Mark Tuk\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c5,),  # Saurashtra Consonant Sig..Saurashtra Sign Candrabi\n+        (0x0a8e0, 0x0a8f1,),  # Combining Devanagari Dig..Combining Devanagari Sig\n+        (0x0a8ff, 0x0a8ff,),  # Devanagari Vowel Sign Ay\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0a980, 0x0a983,),  # Javanese Sign Panyangga ..Javanese Sign Wignyan\n+        (0x0a9b3, 0x0a9c0,),  # Javanese Sign Cecak Telu..Javanese Pangkon\n+        (0x0a9e5, 0x0a9e5,),  # Myanmar Sign Shan Saw\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0aa7b, 0x0aa7d,),  # Myanmar Sign Pao Karen T..Myanmar Sign Tai Laing T\n+        (0x0aab0, 0x0aab0,),  # Tai Viet Mai Kang\n+        (0x0aab2, 0x0aab4,),  # Tai Viet Vowel I        ..Tai Viet Vowel U\n+        (0x0aab7, 0x0aab8,),  # Tai Viet Mai Khit       ..Tai Viet Vowel Ia\n+        (0x0aabe, 0x0aabf,),  # Tai Viet Vowel Am       ..Tai Viet Tone Mai Ek\n+        (0x0aac1, 0x0aac1,),  # Tai Viet Tone Mai Tho\n+        (0x0aaeb, 0x0aaef,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0aaf5, 0x0aaf6,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Virama\n+        (0x0abe3, 0x0abea,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0abec, 0x0abed,),  # Meetei Mayek Lum Iyek   ..Meetei Mayek Apun Iyek\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe2f,),  # Combining Ligature Left ..Combining Cyrillic Titlo\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x102e0, 0x102e0,),  # Coptic Epact Thousands Mark\n+        (0x10376, 0x1037a,),  # Combining Old Permic Let..Combining Old Permic Let\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x10ae5, 0x10ae6,),  # Manichaean Abbreviation ..Manichaean Abbreviation\n+        (0x10d24, 0x10d27,),  # Hanifi Rohingya Sign Har..Hanifi Rohingya Sign Tas\n+        (0x10f46, 0x10f50,),  # Sogdian Combining Dot Be..Sogdian Combining Stroke\n+        (0x11000, 0x11002,),  # Brahmi Sign Candrabindu ..Brahmi Sign Visarga\n+        (0x11038, 0x11046,),  # Brahmi Vowel Sign Aa    ..Brahmi Virama\n+        (0x1107f, 0x11082,),  # Brahmi Number Joiner    ..Kaithi Sign Visarga\n+        (0x110b0, 0x110ba,),  # Kaithi Vowel Sign Aa    ..Kaithi Sign Nukta\n+        (0x110bd, 0x110bd,),  # Kaithi Number Sign\n+        (0x110cd, 0x110cd,),  # Kaithi Number Sign Above\n+        (0x11100, 0x11102,),  # Chakma Sign Candrabindu ..Chakma Sign Visarga\n+        (0x11127, 0x11134,),  # Chakma Vowel Sign A     ..Chakma Maayyaa\n+        (0x11145, 0x11146,),  # Chakma Vowel Sign Aa    ..Chakma Vowel Sign Ei\n+        (0x11173, 0x11173,),  # Mahajani Sign Nukta\n+        (0x11180, 0x11182,),  # Sharada Sign Candrabindu..Sharada Sign Visarga\n+        (0x111b3, 0x111c0,),  # Sharada Vowel Sign Aa   ..Sharada Sign Virama\n+        (0x111c9, 0x111cc,),  # Sharada Sandhi Mark     ..Sharada Extra Short Vowe\n+        (0x1122c, 0x11237,),  # Khojki Vowel Sign Aa    ..Khojki Sign Shadda\n+        (0x1123e, 0x1123e,),  # Khojki Sign Sukun\n+        (0x112df, 0x112ea,),  # Khudawadi Sign Anusvara ..Khudawadi Sign Virama\n+        (0x11300, 0x11303,),  # Grantha Sign Combining A..Grantha Sign Visarga\n+        (0x1133b, 0x1133c,),  # Combining Bindu Below   ..Grantha Sign Nukta\n+        (0x1133e, 0x11344,),  # Grantha Vowel Sign Aa   ..Grantha Vowel Sign Vocal\n+        (0x11347, 0x11348,),  # Grantha Vowel Sign Ee   ..Grantha Vowel Sign Ai\n+        (0x1134b, 0x1134d,),  # Grantha Vowel Sign Oo   ..Grantha Sign Virama\n+        (0x11357, 0x11357,),  # Grantha Au Length Mark\n+        (0x11362, 0x11363,),  # Grantha Vowel Sign Vocal..Grantha Vowel Sign Vocal\n+        (0x11366, 0x1136c,),  # Combining Grantha Digit ..Combining Grantha Digit\n+        (0x11370, 0x11374,),  # Combining Grantha Letter..Combining Grantha Letter\n+        (0x11435, 0x11446,),  # Newa Vowel Sign Aa      ..Newa Sign Nukta\n+        (0x1145e, 0x1145e,),  # Newa Sandhi Mark\n+        (0x114b0, 0x114c3,),  # Tirhuta Vowel Sign Aa   ..Tirhuta Sign Nukta\n+        (0x115af, 0x115b5,),  # Siddham Vowel Sign Aa   ..Siddham Vowel Sign Vocal\n+        (0x115b8, 0x115c0,),  # Siddham Vowel Sign E    ..Siddham Sign Nukta\n+        (0x115dc, 0x115dd,),  # Siddham Vowel Sign Alter..Siddham Vowel Sign Alter\n+        (0x11630, 0x11640,),  # Modi Vowel Sign Aa      ..Modi Sign Ardhacandra\n+        (0x116ab, 0x116b7,),  # Takri Sign Anusvara     ..Takri Sign Nukta\n+        (0x1171d, 0x1172b,),  # Ahom Consonant Sign Medi..Ahom Sign Killer\n+        (0x1182c, 0x1183a,),  # Dogra Vowel Sign Aa     ..Dogra Sign Nukta\n+        (0x11a01, 0x11a0a,),  # Zanabazar Square Vowel S..Zanabazar Square Vowel L\n+        (0x11a33, 0x11a39,),  # Zanabazar Square Final C..Zanabazar Square Sign Vi\n+        (0x11a3b, 0x11a3e,),  # Zanabazar Square Cluster..Zanabazar Square Cluster\n+        (0x11a47, 0x11a47,),  # Zanabazar Square Subjoiner\n+        (0x11a51, 0x11a5b,),  # Soyombo Vowel Sign I    ..Soyombo Vowel Length Mar\n+        (0x11a8a, 0x11a99,),  # Soyombo Final Consonant ..Soyombo Subjoiner\n+        (0x11c2f, 0x11c36,),  # Bhaiksuki Vowel Sign Aa ..Bhaiksuki Vowel Sign Voc\n+        (0x11c38, 0x11c3f,),  # Bhaiksuki Vowel Sign E  ..Bhaiksuki Sign Virama\n+        (0x11c92, 0x11ca7,),  # Marchen Subjoined Letter..Marchen Subjoined Letter\n+        (0x11ca9, 0x11cb6,),  # Marchen Subjoined Letter..Marchen Sign Candrabindu\n+        (0x11d31, 0x11d36,),  # Masaram Gondi Vowel Sign..Masaram Gondi Vowel Sign\n+        (0x11d3a, 0x11d3a,),  # Masaram Gondi Vowel Sign E\n+        (0x11d3c, 0x11d3d,),  # Masaram Gondi Vowel Sign..Masaram Gondi Vowel Sign\n+        (0x11d3f, 0x11d45,),  # Masaram Gondi Vowel Sign..Masaram Gondi Virama\n+        (0x11d47, 0x11d47,),  # Masaram Gondi Ra-kara\n+        (0x11d8a, 0x11d8e,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Vowel Sign\n+        (0x11d90, 0x11d91,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Vowel Sign\n+        (0x11d93, 0x11d97,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Virama\n+        (0x11ef3, 0x11ef6,),  # Makasar Vowel Sign I    ..Makasar Vowel Sign O\n+        (0x16af0, 0x16af4,),  # Bassa Vah Combining High..Bassa Vah Combining High\n+        (0x16b30, 0x16b36,),  # Pahawh Hmong Mark Cim Tu..Pahawh Hmong Mark Cim Ta\n+        (0x16f51, 0x16f7e,),  # Miao Sign Aspiration    ..Miao Vowel Sign Ng\n+        (0x16f8f, 0x16f92,),  # Miao Tone Right         ..Miao Tone Below\n+        (0x1bc9d, 0x1bc9e,),  # Duployan Thick Letter Se..Duployan Double Mark\n+        (0x1bca0, 0x1bca3,),  # Shorthand Format Letter ..Shorthand Format Up Step\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0x1da00, 0x1da36,),  # Signwriting Head Rim    ..Signwriting Air Sucking\n+        (0x1da3b, 0x1da6c,),  # Signwriting Mouth Closed..Signwriting Excitement\n+        (0x1da75, 0x1da75,),  # Signwriting Upper Body Tilting From Hip Joints\n+        (0x1da84, 0x1da84,),  # Signwriting Location Head Neck\n+        (0x1da9b, 0x1da9f,),  # Signwriting Fill Modifie..Signwriting Fill Modifie\n+        (0x1daa1, 0x1daaf,),  # Signwriting Rotation Mod..Signwriting Rotation Mod\n+        (0x1e000, 0x1e006,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e008, 0x1e018,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e01b, 0x1e021,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e023, 0x1e024,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e026, 0x1e02a,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e8d0, 0x1e8d6,),  # Mende Kikakui Combining ..Mende Kikakui Combining\n+        (0x1e944, 0x1e94a,),  # Adlam Alif Lengthener   ..Adlam Nukta\n+        (0x1f3fb, 0x1f3ff,),  # Emoji Modifier Fitzpatri..Emoji Modifier Fitzpatri\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '12.0.0': (\n+        # Source: DerivedGeneralCategory-12.0.0.txt\n+        # Date: 2019-01-22, 08:18:28 GMT\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00605,),  # Arabic Number Sign      ..Arabic Number Mark Above\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0061c, 0x0061c,),  # Arabic Letter Mark\n+        (0x0064b, 0x0065f,),  # Arabic Fathatan         ..Arabic Wavy Hamza Below\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006dd,),  # Arabic Small High Ligatu..Arabic End Of Ayah\n+        (0x006df, 0x006e4,),  # Arabic Small High Rounde..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x007fd, 0x007fd,),  # Nko Dantayalan\n+        (0x00816, 0x00819,),  # Samaritan Mark In       ..Samaritan Mark Dagesh\n+        (0x0081b, 0x00823,),  # Samaritan Mark Epentheti..Samaritan Vowel Sign A\n+        (0x00825, 0x00827,),  # Samaritan Vowel Sign Sho..Samaritan Vowel Sign U\n+        (0x00829, 0x0082d,),  # Samaritan Vowel Sign Lon..Samaritan Mark Nequdaa\n+        (0x00859, 0x0085b,),  # Mandaic Affrication Mark..Mandaic Gemination Mark\n+        (0x008d3, 0x00903,),  # Arabic Small Low Waw    ..Devanagari Sign Visarga\n+        (0x0093a, 0x0093c,),  # Devanagari Vowel Sign Oe..Devanagari Sign Nukta\n+        (0x0093e, 0x0094f,),  # Devanagari Vowel Sign Aa..Devanagari Vowel Sign Aw\n+        (0x00951, 0x00957,),  # Devanagari Stress Sign U..Devanagari Vowel Sign Uu\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x009fe, 0x009fe,),  # Bengali Sandhi Mark\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00afa, 0x00aff,),  # Gujarati Sign Sukun     ..Gujarati Sign Two-circle\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b56, 0x00b57,),  # Oriya Ai Length Mark    ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c00, 0x00c04,),  # Telugu Sign Combining Ca..Telugu Sign Combining An\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c81, 0x00c83,),  # Kannada Sign Candrabindu..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00d00, 0x00d03,),  # Malayalam Sign Combining..Malayalam Sign Visarga\n+        (0x00d3b, 0x00d3c,),  # Malayalam Sign Vertical ..Malayalam Sign Circular\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d82, 0x00d83,),  # Sinhala Sign Anusvaraya ..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00ebc,),  # Lao Vowel Sign I        ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f8d, 0x00f97,),  # Tibetan Subjoined Sign L..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x0109a, 0x0109d,),  # Myanmar Sign Khamti Tone..Myanmar Vowel Sign Aiton\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135d, 0x0135f,),  # Ethiopic Combining Gemin..Ethiopic Combining Gemin\n+        (0x01712, 0x01714,),  # Tagalog Vowel Sign I    ..Tagalog Sign Virama\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180e,),  # Mongolian Free Variation..Mongolian Vowel Separato\n+        (0x01885, 0x01886,),  # Mongolian Letter Ali Gal..Mongolian Letter Ali Gal\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01a55, 0x01a5e,),  # Tai Tham Consonant Sign ..Tai Tham Consonant Sign\n+        (0x01a60, 0x01a7c,),  # Tai Tham Sign Sakot     ..Tai Tham Sign Khuen-lue\n+        (0x01a7f, 0x01a7f,),  # Tai Tham Combining Cryptogrammic Dot\n+        (0x01ab0, 0x01abe,),  # Combining Doubled Circum..Combining Parentheses Ov\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01bad,),  # Sundanese Consonant Sign..Sundanese Consonant Sign\n+        (0x01be6, 0x01bf3,),  # Batak Sign Tompi        ..Batak Panongonan\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01cd0, 0x01cd2,),  # Vedic Tone Karshana     ..Vedic Tone Prenkha\n+        (0x01cd4, 0x01ce8,),  # Vedic Sign Yajurvedic Mi..Vedic Sign Visarga Anuda\n+        (0x01ced, 0x01ced,),  # Vedic Sign Tiryak\n+        (0x01cf4, 0x01cf4,),  # Vedic Tone Candra Above\n+        (0x01cf7, 0x01cf9,),  # Vedic Sign Atikrama     ..Vedic Tone Double Ring A\n+        (0x01dc0, 0x01df9,),  # Combining Dotted Grave A..Combining Wide Inverted\n+        (0x01dfb, 0x01dff,),  # Combining Deletion Mark ..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x02066, 0x0206f,),  # Left-to-right Isolate   ..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02cef, 0x02cf1,),  # Coptic Combining Ni Abov..Coptic Combining Spiritu\n+        (0x02d7f, 0x02d7f,),  # Tifinagh Consonant Joiner\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a674, 0x0a67d,),  # Combining Cyrillic Lette..Combining Cyrillic Payer\n+        (0x0a69e, 0x0a69f,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0a6f0, 0x0a6f1,),  # Bamum Combining Mark Koq..Bamum Combining Mark Tuk\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c5,),  # Saurashtra Consonant Sig..Saurashtra Sign Candrabi\n+        (0x0a8e0, 0x0a8f1,),  # Combining Devanagari Dig..Combining Devanagari Sig\n+        (0x0a8ff, 0x0a8ff,),  # Devanagari Vowel Sign Ay\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0a980, 0x0a983,),  # Javanese Sign Panyangga ..Javanese Sign Wignyan\n+        (0x0a9b3, 0x0a9c0,),  # Javanese Sign Cecak Telu..Javanese Pangkon\n+        (0x0a9e5, 0x0a9e5,),  # Myanmar Sign Shan Saw\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0aa7b, 0x0aa7d,),  # Myanmar Sign Pao Karen T..Myanmar Sign Tai Laing T\n+        (0x0aab0, 0x0aab0,),  # Tai Viet Mai Kang\n+        (0x0aab2, 0x0aab4,),  # Tai Viet Vowel I        ..Tai Viet Vowel U\n+        (0x0aab7, 0x0aab8,),  # Tai Viet Mai Khit       ..Tai Viet Vowel Ia\n+        (0x0aabe, 0x0aabf,),  # Tai Viet Vowel Am       ..Tai Viet Tone Mai Ek\n+        (0x0aac1, 0x0aac1,),  # Tai Viet Tone Mai Tho\n+        (0x0aaeb, 0x0aaef,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0aaf5, 0x0aaf6,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Virama\n+        (0x0abe3, 0x0abea,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0abec, 0x0abed,),  # Meetei Mayek Lum Iyek   ..Meetei Mayek Apun Iyek\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe2f,),  # Combining Ligature Left ..Combining Cyrillic Titlo\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x102e0, 0x102e0,),  # Coptic Epact Thousands Mark\n+        (0x10376, 0x1037a,),  # Combining Old Permic Let..Combining Old Permic Let\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x10ae5, 0x10ae6,),  # Manichaean Abbreviation ..Manichaean Abbreviation\n+        (0x10d24, 0x10d27,),  # Hanifi Rohingya Sign Har..Hanifi Rohingya Sign Tas\n+        (0x10f46, 0x10f50,),  # Sogdian Combining Dot Be..Sogdian Combining Stroke\n+        (0x11000, 0x11002,),  # Brahmi Sign Candrabindu ..Brahmi Sign Visarga\n+        (0x11038, 0x11046,),  # Brahmi Vowel Sign Aa    ..Brahmi Virama\n+        (0x1107f, 0x11082,),  # Brahmi Number Joiner    ..Kaithi Sign Visarga\n+        (0x110b0, 0x110ba,),  # Kaithi Vowel Sign Aa    ..Kaithi Sign Nukta\n+        (0x110bd, 0x110bd,),  # Kaithi Number Sign\n+        (0x110cd, 0x110cd,),  # Kaithi Number Sign Above\n+        (0x11100, 0x11102,),  # Chakma Sign Candrabindu ..Chakma Sign Visarga\n+        (0x11127, 0x11134,),  # Chakma Vowel Sign A     ..Chakma Maayyaa\n+        (0x11145, 0x11146,),  # Chakma Vowel Sign Aa    ..Chakma Vowel Sign Ei\n+        (0x11173, 0x11173,),  # Mahajani Sign Nukta\n+        (0x11180, 0x11182,),  # Sharada Sign Candrabindu..Sharada Sign Visarga\n+        (0x111b3, 0x111c0,),  # Sharada Vowel Sign Aa   ..Sharada Sign Virama\n+        (0x111c9, 0x111cc,),  # Sharada Sandhi Mark     ..Sharada Extra Short Vowe\n+        (0x1122c, 0x11237,),  # Khojki Vowel Sign Aa    ..Khojki Sign Shadda\n+        (0x1123e, 0x1123e,),  # Khojki Sign Sukun\n+        (0x112df, 0x112ea,),  # Khudawadi Sign Anusvara ..Khudawadi Sign Virama\n+        (0x11300, 0x11303,),  # Grantha Sign Combining A..Grantha Sign Visarga\n+        (0x1133b, 0x1133c,),  # Combining Bindu Below   ..Grantha Sign Nukta\n+        (0x1133e, 0x11344,),  # Grantha Vowel Sign Aa   ..Grantha Vowel Sign Vocal\n+        (0x11347, 0x11348,),  # Grantha Vowel Sign Ee   ..Grantha Vowel Sign Ai\n+        (0x1134b, 0x1134d,),  # Grantha Vowel Sign Oo   ..Grantha Sign Virama\n+        (0x11357, 0x11357,),  # Grantha Au Length Mark\n+        (0x11362, 0x11363,),  # Grantha Vowel Sign Vocal..Grantha Vowel Sign Vocal\n+        (0x11366, 0x1136c,),  # Combining Grantha Digit ..Combining Grantha Digit\n+        (0x11370, 0x11374,),  # Combining Grantha Letter..Combining Grantha Letter\n+        (0x11435, 0x11446,),  # Newa Vowel Sign Aa      ..Newa Sign Nukta\n+        (0x1145e, 0x1145e,),  # Newa Sandhi Mark\n+        (0x114b0, 0x114c3,),  # Tirhuta Vowel Sign Aa   ..Tirhuta Sign Nukta\n+        (0x115af, 0x115b5,),  # Siddham Vowel Sign Aa   ..Siddham Vowel Sign Vocal\n+        (0x115b8, 0x115c0,),  # Siddham Vowel Sign E    ..Siddham Sign Nukta\n+        (0x115dc, 0x115dd,),  # Siddham Vowel Sign Alter..Siddham Vowel Sign Alter\n+        (0x11630, 0x11640,),  # Modi Vowel Sign Aa      ..Modi Sign Ardhacandra\n+        (0x116ab, 0x116b7,),  # Takri Sign Anusvara     ..Takri Sign Nukta\n+        (0x1171d, 0x1172b,),  # Ahom Consonant Sign Medi..Ahom Sign Killer\n+        (0x1182c, 0x1183a,),  # Dogra Vowel Sign Aa     ..Dogra Sign Nukta\n+        (0x119d1, 0x119d7,),  # Nandinagari Vowel Sign A..Nandinagari Vowel Sign V\n+        (0x119da, 0x119e0,),  # Nandinagari Vowel Sign E..Nandinagari Sign Virama\n+        (0x119e4, 0x119e4,),  # Nandinagari Vowel Sign Prishthamatra E\n+        (0x11a01, 0x11a0a,),  # Zanabazar Square Vowel S..Zanabazar Square Vowel L\n+        (0x11a33, 0x11a39,),  # Zanabazar Square Final C..Zanabazar Square Sign Vi\n+        (0x11a3b, 0x11a3e,),  # Zanabazar Square Cluster..Zanabazar Square Cluster\n+        (0x11a47, 0x11a47,),  # Zanabazar Square Subjoiner\n+        (0x11a51, 0x11a5b,),  # Soyombo Vowel Sign I    ..Soyombo Vowel Length Mar\n+        (0x11a8a, 0x11a99,),  # Soyombo Final Consonant ..Soyombo Subjoiner\n+        (0x11c2f, 0x11c36,),  # Bhaiksuki Vowel Sign Aa ..Bhaiksuki Vowel Sign Voc\n+        (0x11c38, 0x11c3f,),  # Bhaiksuki Vowel Sign E  ..Bhaiksuki Sign Virama\n+        (0x11c92, 0x11ca7,),  # Marchen Subjoined Letter..Marchen Subjoined Letter\n+        (0x11ca9, 0x11cb6,),  # Marchen Subjoined Letter..Marchen Sign Candrabindu\n+        (0x11d31, 0x11d36,),  # Masaram Gondi Vowel Sign..Masaram Gondi Vowel Sign\n+        (0x11d3a, 0x11d3a,),  # Masaram Gondi Vowel Sign E\n+        (0x11d3c, 0x11d3d,),  # Masaram Gondi Vowel Sign..Masaram Gondi Vowel Sign\n+        (0x11d3f, 0x11d45,),  # Masaram Gondi Vowel Sign..Masaram Gondi Virama\n+        (0x11d47, 0x11d47,),  # Masaram Gondi Ra-kara\n+        (0x11d8a, 0x11d8e,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Vowel Sign\n+        (0x11d90, 0x11d91,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Vowel Sign\n+        (0x11d93, 0x11d97,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Virama\n+        (0x11ef3, 0x11ef6,),  # Makasar Vowel Sign I    ..Makasar Vowel Sign O\n+        (0x13430, 0x13438,),  # Egyptian Hieroglyph Vert..Egyptian Hieroglyph End\n+        (0x16af0, 0x16af4,),  # Bassa Vah Combining High..Bassa Vah Combining High\n+        (0x16b30, 0x16b36,),  # Pahawh Hmong Mark Cim Tu..Pahawh Hmong Mark Cim Ta\n+        (0x16f4f, 0x16f4f,),  # Miao Sign Consonant Modifier Bar\n+        (0x16f51, 0x16f87,),  # Miao Sign Aspiration    ..Miao Vowel Sign Ui\n+        (0x16f8f, 0x16f92,),  # Miao Tone Right         ..Miao Tone Below\n+        (0x1bc9d, 0x1bc9e,),  # Duployan Thick Letter Se..Duployan Double Mark\n+        (0x1bca0, 0x1bca3,),  # Shorthand Format Letter ..Shorthand Format Up Step\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0x1da00, 0x1da36,),  # Signwriting Head Rim    ..Signwriting Air Sucking\n+        (0x1da3b, 0x1da6c,),  # Signwriting Mouth Closed..Signwriting Excitement\n+        (0x1da75, 0x1da75,),  # Signwriting Upper Body Tilting From Hip Joints\n+        (0x1da84, 0x1da84,),  # Signwriting Location Head Neck\n+        (0x1da9b, 0x1da9f,),  # Signwriting Fill Modifie..Signwriting Fill Modifie\n+        (0x1daa1, 0x1daaf,),  # Signwriting Rotation Mod..Signwriting Rotation Mod\n+        (0x1e000, 0x1e006,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e008, 0x1e018,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e01b, 0x1e021,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e023, 0x1e024,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e026, 0x1e02a,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e130, 0x1e136,),  # Nyiakeng Puachue Hmong T..Nyiakeng Puachue Hmong T\n+        (0x1e2ec, 0x1e2ef,),  # Wancho Tone Tup         ..Wancho Tone Koini\n+        (0x1e8d0, 0x1e8d6,),  # Mende Kikakui Combining ..Mende Kikakui Combining\n+        (0x1e944, 0x1e94a,),  # Adlam Alif Lengthener   ..Adlam Nukta\n+        (0x1f3fb, 0x1f3ff,),  # Emoji Modifier Fitzpatri..Emoji Modifier Fitzpatri\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '12.1.0': (\n+        # Source: DerivedGeneralCategory-12.1.0.txt\n+        # Date: 2019-03-10, 10:53:08 GMT\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00605,),  # Arabic Number Sign      ..Arabic Number Mark Above\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0061c, 0x0061c,),  # Arabic Letter Mark\n+        (0x0064b, 0x0065f,),  # Arabic Fathatan         ..Arabic Wavy Hamza Below\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006dd,),  # Arabic Small High Ligatu..Arabic End Of Ayah\n+        (0x006df, 0x006e4,),  # Arabic Small High Rounde..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x007fd, 0x007fd,),  # Nko Dantayalan\n+        (0x00816, 0x00819,),  # Samaritan Mark In       ..Samaritan Mark Dagesh\n+        (0x0081b, 0x00823,),  # Samaritan Mark Epentheti..Samaritan Vowel Sign A\n+        (0x00825, 0x00827,),  # Samaritan Vowel Sign Sho..Samaritan Vowel Sign U\n+        (0x00829, 0x0082d,),  # Samaritan Vowel Sign Lon..Samaritan Mark Nequdaa\n+        (0x00859, 0x0085b,),  # Mandaic Affrication Mark..Mandaic Gemination Mark\n+        (0x008d3, 0x00903,),  # Arabic Small Low Waw    ..Devanagari Sign Visarga\n+        (0x0093a, 0x0093c,),  # Devanagari Vowel Sign Oe..Devanagari Sign Nukta\n+        (0x0093e, 0x0094f,),  # Devanagari Vowel Sign Aa..Devanagari Vowel Sign Aw\n+        (0x00951, 0x00957,),  # Devanagari Stress Sign U..Devanagari Vowel Sign Uu\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x009fe, 0x009fe,),  # Bengali Sandhi Mark\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00afa, 0x00aff,),  # Gujarati Sign Sukun     ..Gujarati Sign Two-circle\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b56, 0x00b57,),  # Oriya Ai Length Mark    ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c00, 0x00c04,),  # Telugu Sign Combining Ca..Telugu Sign Combining An\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c81, 0x00c83,),  # Kannada Sign Candrabindu..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00d00, 0x00d03,),  # Malayalam Sign Combining..Malayalam Sign Visarga\n+        (0x00d3b, 0x00d3c,),  # Malayalam Sign Vertical ..Malayalam Sign Circular\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d82, 0x00d83,),  # Sinhala Sign Anusvaraya ..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00ebc,),  # Lao Vowel Sign I        ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f8d, 0x00f97,),  # Tibetan Subjoined Sign L..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x0109a, 0x0109d,),  # Myanmar Sign Khamti Tone..Myanmar Vowel Sign Aiton\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135d, 0x0135f,),  # Ethiopic Combining Gemin..Ethiopic Combining Gemin\n+        (0x01712, 0x01714,),  # Tagalog Vowel Sign I    ..Tagalog Sign Virama\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180e,),  # Mongolian Free Variation..Mongolian Vowel Separato\n+        (0x01885, 0x01886,),  # Mongolian Letter Ali Gal..Mongolian Letter Ali Gal\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01a55, 0x01a5e,),  # Tai Tham Consonant Sign ..Tai Tham Consonant Sign\n+        (0x01a60, 0x01a7c,),  # Tai Tham Sign Sakot     ..Tai Tham Sign Khuen-lue\n+        (0x01a7f, 0x01a7f,),  # Tai Tham Combining Cryptogrammic Dot\n+        (0x01ab0, 0x01abe,),  # Combining Doubled Circum..Combining Parentheses Ov\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01bad,),  # Sundanese Consonant Sign..Sundanese Consonant Sign\n+        (0x01be6, 0x01bf3,),  # Batak Sign Tompi        ..Batak Panongonan\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01cd0, 0x01cd2,),  # Vedic Tone Karshana     ..Vedic Tone Prenkha\n+        (0x01cd4, 0x01ce8,),  # Vedic Sign Yajurvedic Mi..Vedic Sign Visarga Anuda\n+        (0x01ced, 0x01ced,),  # Vedic Sign Tiryak\n+        (0x01cf4, 0x01cf4,),  # Vedic Tone Candra Above\n+        (0x01cf7, 0x01cf9,),  # Vedic Sign Atikrama     ..Vedic Tone Double Ring A\n+        (0x01dc0, 0x01df9,),  # Combining Dotted Grave A..Combining Wide Inverted\n+        (0x01dfb, 0x01dff,),  # Combining Deletion Mark ..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x02066, 0x0206f,),  # Left-to-right Isolate   ..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02cef, 0x02cf1,),  # Coptic Combining Ni Abov..Coptic Combining Spiritu\n+        (0x02d7f, 0x02d7f,),  # Tifinagh Consonant Joiner\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a674, 0x0a67d,),  # Combining Cyrillic Lette..Combining Cyrillic Payer\n+        (0x0a69e, 0x0a69f,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0a6f0, 0x0a6f1,),  # Bamum Combining Mark Koq..Bamum Combining Mark Tuk\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c5,),  # Saurashtra Consonant Sig..Saurashtra Sign Candrabi\n+        (0x0a8e0, 0x0a8f1,),  # Combining Devanagari Dig..Combining Devanagari Sig\n+        (0x0a8ff, 0x0a8ff,),  # Devanagari Vowel Sign Ay\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0a980, 0x0a983,),  # Javanese Sign Panyangga ..Javanese Sign Wignyan\n+        (0x0a9b3, 0x0a9c0,),  # Javanese Sign Cecak Telu..Javanese Pangkon\n+        (0x0a9e5, 0x0a9e5,),  # Myanmar Sign Shan Saw\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0aa7b, 0x0aa7d,),  # Myanmar Sign Pao Karen T..Myanmar Sign Tai Laing T\n+        (0x0aab0, 0x0aab0,),  # Tai Viet Mai Kang\n+        (0x0aab2, 0x0aab4,),  # Tai Viet Vowel I        ..Tai Viet Vowel U\n+        (0x0aab7, 0x0aab8,),  # Tai Viet Mai Khit       ..Tai Viet Vowel Ia\n+        (0x0aabe, 0x0aabf,),  # Tai Viet Vowel Am       ..Tai Viet Tone Mai Ek\n+        (0x0aac1, 0x0aac1,),  # Tai Viet Tone Mai Tho\n+        (0x0aaeb, 0x0aaef,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0aaf5, 0x0aaf6,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Virama\n+        (0x0abe3, 0x0abea,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0abec, 0x0abed,),  # Meetei Mayek Lum Iyek   ..Meetei Mayek Apun Iyek\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe2f,),  # Combining Ligature Left ..Combining Cyrillic Titlo\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x102e0, 0x102e0,),  # Coptic Epact Thousands Mark\n+        (0x10376, 0x1037a,),  # Combining Old Permic Let..Combining Old Permic Let\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x10ae5, 0x10ae6,),  # Manichaean Abbreviation ..Manichaean Abbreviation\n+        (0x10d24, 0x10d27,),  # Hanifi Rohingya Sign Har..Hanifi Rohingya Sign Tas\n+        (0x10f46, 0x10f50,),  # Sogdian Combining Dot Be..Sogdian Combining Stroke\n+        (0x11000, 0x11002,),  # Brahmi Sign Candrabindu ..Brahmi Sign Visarga\n+        (0x11038, 0x11046,),  # Brahmi Vowel Sign Aa    ..Brahmi Virama\n+        (0x1107f, 0x11082,),  # Brahmi Number Joiner    ..Kaithi Sign Visarga\n+        (0x110b0, 0x110ba,),  # Kaithi Vowel Sign Aa    ..Kaithi Sign Nukta\n+        (0x110bd, 0x110bd,),  # Kaithi Number Sign\n+        (0x110cd, 0x110cd,),  # Kaithi Number Sign Above\n+        (0x11100, 0x11102,),  # Chakma Sign Candrabindu ..Chakma Sign Visarga\n+        (0x11127, 0x11134,),  # Chakma Vowel Sign A     ..Chakma Maayyaa\n+        (0x11145, 0x11146,),  # Chakma Vowel Sign Aa    ..Chakma Vowel Sign Ei\n+        (0x11173, 0x11173,),  # Mahajani Sign Nukta\n+        (0x11180, 0x11182,),  # Sharada Sign Candrabindu..Sharada Sign Visarga\n+        (0x111b3, 0x111c0,),  # Sharada Vowel Sign Aa   ..Sharada Sign Virama\n+        (0x111c9, 0x111cc,),  # Sharada Sandhi Mark     ..Sharada Extra Short Vowe\n+        (0x1122c, 0x11237,),  # Khojki Vowel Sign Aa    ..Khojki Sign Shadda\n+        (0x1123e, 0x1123e,),  # Khojki Sign Sukun\n+        (0x112df, 0x112ea,),  # Khudawadi Sign Anusvara ..Khudawadi Sign Virama\n+        (0x11300, 0x11303,),  # Grantha Sign Combining A..Grantha Sign Visarga\n+        (0x1133b, 0x1133c,),  # Combining Bindu Below   ..Grantha Sign Nukta\n+        (0x1133e, 0x11344,),  # Grantha Vowel Sign Aa   ..Grantha Vowel Sign Vocal\n+        (0x11347, 0x11348,),  # Grantha Vowel Sign Ee   ..Grantha Vowel Sign Ai\n+        (0x1134b, 0x1134d,),  # Grantha Vowel Sign Oo   ..Grantha Sign Virama\n+        (0x11357, 0x11357,),  # Grantha Au Length Mark\n+        (0x11362, 0x11363,),  # Grantha Vowel Sign Vocal..Grantha Vowel Sign Vocal\n+        (0x11366, 0x1136c,),  # Combining Grantha Digit ..Combining Grantha Digit\n+        (0x11370, 0x11374,),  # Combining Grantha Letter..Combining Grantha Letter\n+        (0x11435, 0x11446,),  # Newa Vowel Sign Aa      ..Newa Sign Nukta\n+        (0x1145e, 0x1145e,),  # Newa Sandhi Mark\n+        (0x114b0, 0x114c3,),  # Tirhuta Vowel Sign Aa   ..Tirhuta Sign Nukta\n+        (0x115af, 0x115b5,),  # Siddham Vowel Sign Aa   ..Siddham Vowel Sign Vocal\n+        (0x115b8, 0x115c0,),  # Siddham Vowel Sign E    ..Siddham Sign Nukta\n+        (0x115dc, 0x115dd,),  # Siddham Vowel Sign Alter..Siddham Vowel Sign Alter\n+        (0x11630, 0x11640,),  # Modi Vowel Sign Aa      ..Modi Sign Ardhacandra\n+        (0x116ab, 0x116b7,),  # Takri Sign Anusvara     ..Takri Sign Nukta\n+        (0x1171d, 0x1172b,),  # Ahom Consonant Sign Medi..Ahom Sign Killer\n+        (0x1182c, 0x1183a,),  # Dogra Vowel Sign Aa     ..Dogra Sign Nukta\n+        (0x119d1, 0x119d7,),  # Nandinagari Vowel Sign A..Nandinagari Vowel Sign V\n+        (0x119da, 0x119e0,),  # Nandinagari Vowel Sign E..Nandinagari Sign Virama\n+        (0x119e4, 0x119e4,),  # Nandinagari Vowel Sign Prishthamatra E\n+        (0x11a01, 0x11a0a,),  # Zanabazar Square Vowel S..Zanabazar Square Vowel L\n+        (0x11a33, 0x11a39,),  # Zanabazar Square Final C..Zanabazar Square Sign Vi\n+        (0x11a3b, 0x11a3e,),  # Zanabazar Square Cluster..Zanabazar Square Cluster\n+        (0x11a47, 0x11a47,),  # Zanabazar Square Subjoiner\n+        (0x11a51, 0x11a5b,),  # Soyombo Vowel Sign I    ..Soyombo Vowel Length Mar\n+        (0x11a8a, 0x11a99,),  # Soyombo Final Consonant ..Soyombo Subjoiner\n+        (0x11c2f, 0x11c36,),  # Bhaiksuki Vowel Sign Aa ..Bhaiksuki Vowel Sign Voc\n+        (0x11c38, 0x11c3f,),  # Bhaiksuki Vowel Sign E  ..Bhaiksuki Sign Virama\n+        (0x11c92, 0x11ca7,),  # Marchen Subjoined Letter..Marchen Subjoined Letter\n+        (0x11ca9, 0x11cb6,),  # Marchen Subjoined Letter..Marchen Sign Candrabindu\n+        (0x11d31, 0x11d36,),  # Masaram Gondi Vowel Sign..Masaram Gondi Vowel Sign\n+        (0x11d3a, 0x11d3a,),  # Masaram Gondi Vowel Sign E\n+        (0x11d3c, 0x11d3d,),  # Masaram Gondi Vowel Sign..Masaram Gondi Vowel Sign\n+        (0x11d3f, 0x11d45,),  # Masaram Gondi Vowel Sign..Masaram Gondi Virama\n+        (0x11d47, 0x11d47,),  # Masaram Gondi Ra-kara\n+        (0x11d8a, 0x11d8e,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Vowel Sign\n+        (0x11d90, 0x11d91,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Vowel Sign\n+        (0x11d93, 0x11d97,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Virama\n+        (0x11ef3, 0x11ef6,),  # Makasar Vowel Sign I    ..Makasar Vowel Sign O\n+        (0x13430, 0x13438,),  # Egyptian Hieroglyph Vert..Egyptian Hieroglyph End\n+        (0x16af0, 0x16af4,),  # Bassa Vah Combining High..Bassa Vah Combining High\n+        (0x16b30, 0x16b36,),  # Pahawh Hmong Mark Cim Tu..Pahawh Hmong Mark Cim Ta\n+        (0x16f4f, 0x16f4f,),  # Miao Sign Consonant Modifier Bar\n+        (0x16f51, 0x16f87,),  # Miao Sign Aspiration    ..Miao Vowel Sign Ui\n+        (0x16f8f, 0x16f92,),  # Miao Tone Right         ..Miao Tone Below\n+        (0x1bc9d, 0x1bc9e,),  # Duployan Thick Letter Se..Duployan Double Mark\n+        (0x1bca0, 0x1bca3,),  # Shorthand Format Letter ..Shorthand Format Up Step\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0x1da00, 0x1da36,),  # Signwriting Head Rim    ..Signwriting Air Sucking\n+        (0x1da3b, 0x1da6c,),  # Signwriting Mouth Closed..Signwriting Excitement\n+        (0x1da75, 0x1da75,),  # Signwriting Upper Body Tilting From Hip Joints\n+        (0x1da84, 0x1da84,),  # Signwriting Location Head Neck\n+        (0x1da9b, 0x1da9f,),  # Signwriting Fill Modifie..Signwriting Fill Modifie\n+        (0x1daa1, 0x1daaf,),  # Signwriting Rotation Mod..Signwriting Rotation Mod\n+        (0x1e000, 0x1e006,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e008, 0x1e018,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e01b, 0x1e021,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e023, 0x1e024,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e026, 0x1e02a,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e130, 0x1e136,),  # Nyiakeng Puachue Hmong T..Nyiakeng Puachue Hmong T\n+        (0x1e2ec, 0x1e2ef,),  # Wancho Tone Tup         ..Wancho Tone Koini\n+        (0x1e8d0, 0x1e8d6,),  # Mende Kikakui Combining ..Mende Kikakui Combining\n+        (0x1e944, 0x1e94a,),  # Adlam Alif Lengthener   ..Adlam Nukta\n+        (0x1f3fb, 0x1f3ff,),  # Emoji Modifier Fitzpatri..Emoji Modifier Fitzpatri\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '13.0.0': (\n+        # Source: DerivedGeneralCategory-13.0.0.txt\n+        # Date: 2019-10-21, 14:30:32 GMT\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00605,),  # Arabic Number Sign      ..Arabic Number Mark Above\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0061c, 0x0061c,),  # Arabic Letter Mark\n+        (0x0064b, 0x0065f,),  # Arabic Fathatan         ..Arabic Wavy Hamza Below\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006dd,),  # Arabic Small High Ligatu..Arabic End Of Ayah\n+        (0x006df, 0x006e4,),  # Arabic Small High Rounde..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x007fd, 0x007fd,),  # Nko Dantayalan\n+        (0x00816, 0x00819,),  # Samaritan Mark In       ..Samaritan Mark Dagesh\n+        (0x0081b, 0x00823,),  # Samaritan Mark Epentheti..Samaritan Vowel Sign A\n+        (0x00825, 0x00827,),  # Samaritan Vowel Sign Sho..Samaritan Vowel Sign U\n+        (0x00829, 0x0082d,),  # Samaritan Vowel Sign Lon..Samaritan Mark Nequdaa\n+        (0x00859, 0x0085b,),  # Mandaic Affrication Mark..Mandaic Gemination Mark\n+        (0x008d3, 0x00903,),  # Arabic Small Low Waw    ..Devanagari Sign Visarga\n+        (0x0093a, 0x0093c,),  # Devanagari Vowel Sign Oe..Devanagari Sign Nukta\n+        (0x0093e, 0x0094f,),  # Devanagari Vowel Sign Aa..Devanagari Vowel Sign Aw\n+        (0x00951, 0x00957,),  # Devanagari Stress Sign U..Devanagari Vowel Sign Uu\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x009fe, 0x009fe,),  # Bengali Sandhi Mark\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00afa, 0x00aff,),  # Gujarati Sign Sukun     ..Gujarati Sign Two-circle\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b55, 0x00b57,),  # Oriya Sign Overline     ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c00, 0x00c04,),  # Telugu Sign Combining Ca..Telugu Sign Combining An\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c81, 0x00c83,),  # Kannada Sign Candrabindu..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00d00, 0x00d03,),  # Malayalam Sign Combining..Malayalam Sign Visarga\n+        (0x00d3b, 0x00d3c,),  # Malayalam Sign Vertical ..Malayalam Sign Circular\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d81, 0x00d83,),  # Sinhala Sign Candrabindu..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00ebc,),  # Lao Vowel Sign I        ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f8d, 0x00f97,),  # Tibetan Subjoined Sign L..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x0109a, 0x0109d,),  # Myanmar Sign Khamti Tone..Myanmar Vowel Sign Aiton\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135d, 0x0135f,),  # Ethiopic Combining Gemin..Ethiopic Combining Gemin\n+        (0x01712, 0x01714,),  # Tagalog Vowel Sign I    ..Tagalog Sign Virama\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180e,),  # Mongolian Free Variation..Mongolian Vowel Separato\n+        (0x01885, 0x01886,),  # Mongolian Letter Ali Gal..Mongolian Letter Ali Gal\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01a55, 0x01a5e,),  # Tai Tham Consonant Sign ..Tai Tham Consonant Sign\n+        (0x01a60, 0x01a7c,),  # Tai Tham Sign Sakot     ..Tai Tham Sign Khuen-lue\n+        (0x01a7f, 0x01a7f,),  # Tai Tham Combining Cryptogrammic Dot\n+        (0x01ab0, 0x01ac0,),  # Combining Doubled Circum..Combining Latin Small Le\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01bad,),  # Sundanese Consonant Sign..Sundanese Consonant Sign\n+        (0x01be6, 0x01bf3,),  # Batak Sign Tompi        ..Batak Panongonan\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01cd0, 0x01cd2,),  # Vedic Tone Karshana     ..Vedic Tone Prenkha\n+        (0x01cd4, 0x01ce8,),  # Vedic Sign Yajurvedic Mi..Vedic Sign Visarga Anuda\n+        (0x01ced, 0x01ced,),  # Vedic Sign Tiryak\n+        (0x01cf4, 0x01cf4,),  # Vedic Tone Candra Above\n+        (0x01cf7, 0x01cf9,),  # Vedic Sign Atikrama     ..Vedic Tone Double Ring A\n+        (0x01dc0, 0x01df9,),  # Combining Dotted Grave A..Combining Wide Inverted\n+        (0x01dfb, 0x01dff,),  # Combining Deletion Mark ..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x02066, 0x0206f,),  # Left-to-right Isolate   ..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02cef, 0x02cf1,),  # Coptic Combining Ni Abov..Coptic Combining Spiritu\n+        (0x02d7f, 0x02d7f,),  # Tifinagh Consonant Joiner\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a674, 0x0a67d,),  # Combining Cyrillic Lette..Combining Cyrillic Payer\n+        (0x0a69e, 0x0a69f,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0a6f0, 0x0a6f1,),  # Bamum Combining Mark Koq..Bamum Combining Mark Tuk\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a82c, 0x0a82c,),  # Syloti Nagri Sign Alternate Hasanta\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c5,),  # Saurashtra Consonant Sig..Saurashtra Sign Candrabi\n+        (0x0a8e0, 0x0a8f1,),  # Combining Devanagari Dig..Combining Devanagari Sig\n+        (0x0a8ff, 0x0a8ff,),  # Devanagari Vowel Sign Ay\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0a980, 0x0a983,),  # Javanese Sign Panyangga ..Javanese Sign Wignyan\n+        (0x0a9b3, 0x0a9c0,),  # Javanese Sign Cecak Telu..Javanese Pangkon\n+        (0x0a9e5, 0x0a9e5,),  # Myanmar Sign Shan Saw\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0aa7b, 0x0aa7d,),  # Myanmar Sign Pao Karen T..Myanmar Sign Tai Laing T\n+        (0x0aab0, 0x0aab0,),  # Tai Viet Mai Kang\n+        (0x0aab2, 0x0aab4,),  # Tai Viet Vowel I        ..Tai Viet Vowel U\n+        (0x0aab7, 0x0aab8,),  # Tai Viet Mai Khit       ..Tai Viet Vowel Ia\n+        (0x0aabe, 0x0aabf,),  # Tai Viet Vowel Am       ..Tai Viet Tone Mai Ek\n+        (0x0aac1, 0x0aac1,),  # Tai Viet Tone Mai Tho\n+        (0x0aaeb, 0x0aaef,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0aaf5, 0x0aaf6,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Virama\n+        (0x0abe3, 0x0abea,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0abec, 0x0abed,),  # Meetei Mayek Lum Iyek   ..Meetei Mayek Apun Iyek\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe2f,),  # Combining Ligature Left ..Combining Cyrillic Titlo\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x102e0, 0x102e0,),  # Coptic Epact Thousands Mark\n+        (0x10376, 0x1037a,),  # Combining Old Permic Let..Combining Old Permic Let\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x10ae5, 0x10ae6,),  # Manichaean Abbreviation ..Manichaean Abbreviation\n+        (0x10d24, 0x10d27,),  # Hanifi Rohingya Sign Har..Hanifi Rohingya Sign Tas\n+        (0x10eab, 0x10eac,),  # Yezidi Combining Hamza M..Yezidi Combining Madda M\n+        (0x10f46, 0x10f50,),  # Sogdian Combining Dot Be..Sogdian Combining Stroke\n+        (0x11000, 0x11002,),  # Brahmi Sign Candrabindu ..Brahmi Sign Visarga\n+        (0x11038, 0x11046,),  # Brahmi Vowel Sign Aa    ..Brahmi Virama\n+        (0x1107f, 0x11082,),  # Brahmi Number Joiner    ..Kaithi Sign Visarga\n+        (0x110b0, 0x110ba,),  # Kaithi Vowel Sign Aa    ..Kaithi Sign Nukta\n+        (0x110bd, 0x110bd,),  # Kaithi Number Sign\n+        (0x110cd, 0x110cd,),  # Kaithi Number Sign Above\n+        (0x11100, 0x11102,),  # Chakma Sign Candrabindu ..Chakma Sign Visarga\n+        (0x11127, 0x11134,),  # Chakma Vowel Sign A     ..Chakma Maayyaa\n+        (0x11145, 0x11146,),  # Chakma Vowel Sign Aa    ..Chakma Vowel Sign Ei\n+        (0x11173, 0x11173,),  # Mahajani Sign Nukta\n+        (0x11180, 0x11182,),  # Sharada Sign Candrabindu..Sharada Sign Visarga\n+        (0x111b3, 0x111c0,),  # Sharada Vowel Sign Aa   ..Sharada Sign Virama\n+        (0x111c9, 0x111cc,),  # Sharada Sandhi Mark     ..Sharada Extra Short Vowe\n+        (0x111ce, 0x111cf,),  # Sharada Vowel Sign Prish..Sharada Sign Inverted Ca\n+        (0x1122c, 0x11237,),  # Khojki Vowel Sign Aa    ..Khojki Sign Shadda\n+        (0x1123e, 0x1123e,),  # Khojki Sign Sukun\n+        (0x112df, 0x112ea,),  # Khudawadi Sign Anusvara ..Khudawadi Sign Virama\n+        (0x11300, 0x11303,),  # Grantha Sign Combining A..Grantha Sign Visarga\n+        (0x1133b, 0x1133c,),  # Combining Bindu Below   ..Grantha Sign Nukta\n+        (0x1133e, 0x11344,),  # Grantha Vowel Sign Aa   ..Grantha Vowel Sign Vocal\n+        (0x11347, 0x11348,),  # Grantha Vowel Sign Ee   ..Grantha Vowel Sign Ai\n+        (0x1134b, 0x1134d,),  # Grantha Vowel Sign Oo   ..Grantha Sign Virama\n+        (0x11357, 0x11357,),  # Grantha Au Length Mark\n+        (0x11362, 0x11363,),  # Grantha Vowel Sign Vocal..Grantha Vowel Sign Vocal\n+        (0x11366, 0x1136c,),  # Combining Grantha Digit ..Combining Grantha Digit\n+        (0x11370, 0x11374,),  # Combining Grantha Letter..Combining Grantha Letter\n+        (0x11435, 0x11446,),  # Newa Vowel Sign Aa      ..Newa Sign Nukta\n+        (0x1145e, 0x1145e,),  # Newa Sandhi Mark\n+        (0x114b0, 0x114c3,),  # Tirhuta Vowel Sign Aa   ..Tirhuta Sign Nukta\n+        (0x115af, 0x115b5,),  # Siddham Vowel Sign Aa   ..Siddham Vowel Sign Vocal\n+        (0x115b8, 0x115c0,),  # Siddham Vowel Sign E    ..Siddham Sign Nukta\n+        (0x115dc, 0x115dd,),  # Siddham Vowel Sign Alter..Siddham Vowel Sign Alter\n+        (0x11630, 0x11640,),  # Modi Vowel Sign Aa      ..Modi Sign Ardhacandra\n+        (0x116ab, 0x116b7,),  # Takri Sign Anusvara     ..Takri Sign Nukta\n+        (0x1171d, 0x1172b,),  # Ahom Consonant Sign Medi..Ahom Sign Killer\n+        (0x1182c, 0x1183a,),  # Dogra Vowel Sign Aa     ..Dogra Sign Nukta\n+        (0x11930, 0x11935,),  # Dives Akuru Vowel Sign A..Dives Akuru Vowel Sign E\n+        (0x11937, 0x11938,),  # Dives Akuru Vowel Sign A..Dives Akuru Vowel Sign O\n+        (0x1193b, 0x1193e,),  # Dives Akuru Sign Anusvar..Dives Akuru Virama\n+        (0x11940, 0x11940,),  # Dives Akuru Medial Ya\n+        (0x11942, 0x11943,),  # Dives Akuru Medial Ra   ..Dives Akuru Sign Nukta\n+        (0x119d1, 0x119d7,),  # Nandinagari Vowel Sign A..Nandinagari Vowel Sign V\n+        (0x119da, 0x119e0,),  # Nandinagari Vowel Sign E..Nandinagari Sign Virama\n+        (0x119e4, 0x119e4,),  # Nandinagari Vowel Sign Prishthamatra E\n+        (0x11a01, 0x11a0a,),  # Zanabazar Square Vowel S..Zanabazar Square Vowel L\n+        (0x11a33, 0x11a39,),  # Zanabazar Square Final C..Zanabazar Square Sign Vi\n+        (0x11a3b, 0x11a3e,),  # Zanabazar Square Cluster..Zanabazar Square Cluster\n+        (0x11a47, 0x11a47,),  # Zanabazar Square Subjoiner\n+        (0x11a51, 0x11a5b,),  # Soyombo Vowel Sign I    ..Soyombo Vowel Length Mar\n+        (0x11a8a, 0x11a99,),  # Soyombo Final Consonant ..Soyombo Subjoiner\n+        (0x11c2f, 0x11c36,),  # Bhaiksuki Vowel Sign Aa ..Bhaiksuki Vowel Sign Voc\n+        (0x11c38, 0x11c3f,),  # Bhaiksuki Vowel Sign E  ..Bhaiksuki Sign Virama\n+        (0x11c92, 0x11ca7,),  # Marchen Subjoined Letter..Marchen Subjoined Letter\n+        (0x11ca9, 0x11cb6,),  # Marchen Subjoined Letter..Marchen Sign Candrabindu\n+        (0x11d31, 0x11d36,),  # Masaram Gondi Vowel Sign..Masaram Gondi Vowel Sign\n+        (0x11d3a, 0x11d3a,),  # Masaram Gondi Vowel Sign E\n+        (0x11d3c, 0x11d3d,),  # Masaram Gondi Vowel Sign..Masaram Gondi Vowel Sign\n+        (0x11d3f, 0x11d45,),  # Masaram Gondi Vowel Sign..Masaram Gondi Virama\n+        (0x11d47, 0x11d47,),  # Masaram Gondi Ra-kara\n+        (0x11d8a, 0x11d8e,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Vowel Sign\n+        (0x11d90, 0x11d91,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Vowel Sign\n+        (0x11d93, 0x11d97,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Virama\n+        (0x11ef3, 0x11ef6,),  # Makasar Vowel Sign I    ..Makasar Vowel Sign O\n+        (0x13430, 0x13438,),  # Egyptian Hieroglyph Vert..Egyptian Hieroglyph End\n+        (0x16af0, 0x16af4,),  # Bassa Vah Combining High..Bassa Vah Combining High\n+        (0x16b30, 0x16b36,),  # Pahawh Hmong Mark Cim Tu..Pahawh Hmong Mark Cim Ta\n+        (0x16f4f, 0x16f4f,),  # Miao Sign Consonant Modifier Bar\n+        (0x16f51, 0x16f87,),  # Miao Sign Aspiration    ..Miao Vowel Sign Ui\n+        (0x16f8f, 0x16f92,),  # Miao Tone Right         ..Miao Tone Below\n+        (0x16fe4, 0x16fe4,),  # Khitan Small Script Filler\n+        (0x16ff0, 0x16ff1,),  # Vietnamese Alternate Rea..Vietnamese Alternate Rea\n+        (0x1bc9d, 0x1bc9e,),  # Duployan Thick Letter Se..Duployan Double Mark\n+        (0x1bca0, 0x1bca3,),  # Shorthand Format Letter ..Shorthand Format Up Step\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0x1da00, 0x1da36,),  # Signwriting Head Rim    ..Signwriting Air Sucking\n+        (0x1da3b, 0x1da6c,),  # Signwriting Mouth Closed..Signwriting Excitement\n+        (0x1da75, 0x1da75,),  # Signwriting Upper Body Tilting From Hip Joints\n+        (0x1da84, 0x1da84,),  # Signwriting Location Head Neck\n+        (0x1da9b, 0x1da9f,),  # Signwriting Fill Modifie..Signwriting Fill Modifie\n+        (0x1daa1, 0x1daaf,),  # Signwriting Rotation Mod..Signwriting Rotation Mod\n+        (0x1e000, 0x1e006,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e008, 0x1e018,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e01b, 0x1e021,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e023, 0x1e024,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e026, 0x1e02a,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e130, 0x1e136,),  # Nyiakeng Puachue Hmong T..Nyiakeng Puachue Hmong T\n+        (0x1e2ec, 0x1e2ef,),  # Wancho Tone Tup         ..Wancho Tone Koini\n+        (0x1e8d0, 0x1e8d6,),  # Mende Kikakui Combining ..Mende Kikakui Combining\n+        (0x1e944, 0x1e94a,),  # Adlam Alif Lengthener   ..Adlam Nukta\n+        (0x1f3fb, 0x1f3ff,),  # Emoji Modifier Fitzpatri..Emoji Modifier Fitzpatri\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '14.0.0': (\n+        # Source: DerivedGeneralCategory-14.0.0.txt\n+        # Date: 2021-07-10, 00:35:08 GMT\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00605,),  # Arabic Number Sign      ..Arabic Number Mark Above\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0061c, 0x0061c,),  # Arabic Letter Mark\n+        (0x0064b, 0x0065f,),  # Arabic Fathatan         ..Arabic Wavy Hamza Below\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006dd,),  # Arabic Small High Ligatu..Arabic End Of Ayah\n+        (0x006df, 0x006e4,),  # Arabic Small High Rounde..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x007fd, 0x007fd,),  # Nko Dantayalan\n+        (0x00816, 0x00819,),  # Samaritan Mark In       ..Samaritan Mark Dagesh\n+        (0x0081b, 0x00823,),  # Samaritan Mark Epentheti..Samaritan Vowel Sign A\n+        (0x00825, 0x00827,),  # Samaritan Vowel Sign Sho..Samaritan Vowel Sign U\n+        (0x00829, 0x0082d,),  # Samaritan Vowel Sign Lon..Samaritan Mark Nequdaa\n+        (0x00859, 0x0085b,),  # Mandaic Affrication Mark..Mandaic Gemination Mark\n+        (0x00890, 0x00891,),  # Arabic Pound Mark Above ..Arabic Piastre Mark Abov\n+        (0x00898, 0x0089f,),  # Arabic Small High Word A..Arabic Half Madda Over M\n+        (0x008ca, 0x00903,),  # Arabic Small High Farsi ..Devanagari Sign Visarga\n+        (0x0093a, 0x0093c,),  # Devanagari Vowel Sign Oe..Devanagari Sign Nukta\n+        (0x0093e, 0x0094f,),  # Devanagari Vowel Sign Aa..Devanagari Vowel Sign Aw\n+        (0x00951, 0x00957,),  # Devanagari Stress Sign U..Devanagari Vowel Sign Uu\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x009fe, 0x009fe,),  # Bengali Sandhi Mark\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00afa, 0x00aff,),  # Gujarati Sign Sukun     ..Gujarati Sign Two-circle\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b55, 0x00b57,),  # Oriya Sign Overline     ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c00, 0x00c04,),  # Telugu Sign Combining Ca..Telugu Sign Combining An\n+        (0x00c3c, 0x00c3c,),  # Telugu Sign Nukta\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c81, 0x00c83,),  # Kannada Sign Candrabindu..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00d00, 0x00d03,),  # Malayalam Sign Combining..Malayalam Sign Visarga\n+        (0x00d3b, 0x00d3c,),  # Malayalam Sign Vertical ..Malayalam Sign Circular\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d81, 0x00d83,),  # Sinhala Sign Candrabindu..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00ebc,),  # Lao Vowel Sign I        ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ecd,),  # Lao Tone Mai Ek         ..Lao Niggahita\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f8d, 0x00f97,),  # Tibetan Subjoined Sign L..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x0109a, 0x0109d,),  # Myanmar Sign Khamti Tone..Myanmar Vowel Sign Aiton\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135d, 0x0135f,),  # Ethiopic Combining Gemin..Ethiopic Combining Gemin\n+        (0x01712, 0x01715,),  # Tagalog Vowel Sign I    ..Tagalog Sign Pamudpod\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180f,),  # Mongolian Free Variation..Mongolian Free Variation\n+        (0x01885, 0x01886,),  # Mongolian Letter Ali Gal..Mongolian Letter Ali Gal\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01a55, 0x01a5e,),  # Tai Tham Consonant Sign ..Tai Tham Consonant Sign\n+        (0x01a60, 0x01a7c,),  # Tai Tham Sign Sakot     ..Tai Tham Sign Khuen-lue\n+        (0x01a7f, 0x01a7f,),  # Tai Tham Combining Cryptogrammic Dot\n+        (0x01ab0, 0x01ace,),  # Combining Doubled Circum..Combining Latin Small Le\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01bad,),  # Sundanese Consonant Sign..Sundanese Consonant Sign\n+        (0x01be6, 0x01bf3,),  # Batak Sign Tompi        ..Batak Panongonan\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01cd0, 0x01cd2,),  # Vedic Tone Karshana     ..Vedic Tone Prenkha\n+        (0x01cd4, 0x01ce8,),  # Vedic Sign Yajurvedic Mi..Vedic Sign Visarga Anuda\n+        (0x01ced, 0x01ced,),  # Vedic Sign Tiryak\n+        (0x01cf4, 0x01cf4,),  # Vedic Tone Candra Above\n+        (0x01cf7, 0x01cf9,),  # Vedic Sign Atikrama     ..Vedic Tone Double Ring A\n+        (0x01dc0, 0x01dff,),  # Combining Dotted Grave A..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x02066, 0x0206f,),  # Left-to-right Isolate   ..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02cef, 0x02cf1,),  # Coptic Combining Ni Abov..Coptic Combining Spiritu\n+        (0x02d7f, 0x02d7f,),  # Tifinagh Consonant Joiner\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a674, 0x0a67d,),  # Combining Cyrillic Lette..Combining Cyrillic Payer\n+        (0x0a69e, 0x0a69f,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0a6f0, 0x0a6f1,),  # Bamum Combining Mark Koq..Bamum Combining Mark Tuk\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a82c, 0x0a82c,),  # Syloti Nagri Sign Alternate Hasanta\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c5,),  # Saurashtra Consonant Sig..Saurashtra Sign Candrabi\n+        (0x0a8e0, 0x0a8f1,),  # Combining Devanagari Dig..Combining Devanagari Sig\n+        (0x0a8ff, 0x0a8ff,),  # Devanagari Vowel Sign Ay\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0a980, 0x0a983,),  # Javanese Sign Panyangga ..Javanese Sign Wignyan\n+        (0x0a9b3, 0x0a9c0,),  # Javanese Sign Cecak Telu..Javanese Pangkon\n+        (0x0a9e5, 0x0a9e5,),  # Myanmar Sign Shan Saw\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0aa7b, 0x0aa7d,),  # Myanmar Sign Pao Karen T..Myanmar Sign Tai Laing T\n+        (0x0aab0, 0x0aab0,),  # Tai Viet Mai Kang\n+        (0x0aab2, 0x0aab4,),  # Tai Viet Vowel I        ..Tai Viet Vowel U\n+        (0x0aab7, 0x0aab8,),  # Tai Viet Mai Khit       ..Tai Viet Vowel Ia\n+        (0x0aabe, 0x0aabf,),  # Tai Viet Vowel Am       ..Tai Viet Tone Mai Ek\n+        (0x0aac1, 0x0aac1,),  # Tai Viet Tone Mai Tho\n+        (0x0aaeb, 0x0aaef,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0aaf5, 0x0aaf6,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Virama\n+        (0x0abe3, 0x0abea,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0abec, 0x0abed,),  # Meetei Mayek Lum Iyek   ..Meetei Mayek Apun Iyek\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe2f,),  # Combining Ligature Left ..Combining Cyrillic Titlo\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x102e0, 0x102e0,),  # Coptic Epact Thousands Mark\n+        (0x10376, 0x1037a,),  # Combining Old Permic Let..Combining Old Permic Let\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x10ae5, 0x10ae6,),  # Manichaean Abbreviation ..Manichaean Abbreviation\n+        (0x10d24, 0x10d27,),  # Hanifi Rohingya Sign Har..Hanifi Rohingya Sign Tas\n+        (0x10eab, 0x10eac,),  # Yezidi Combining Hamza M..Yezidi Combining Madda M\n+        (0x10f46, 0x10f50,),  # Sogdian Combining Dot Be..Sogdian Combining Stroke\n+        (0x10f82, 0x10f85,),  # Old Uyghur Combining Dot..Old Uyghur Combining Two\n+        (0x11000, 0x11002,),  # Brahmi Sign Candrabindu ..Brahmi Sign Visarga\n+        (0x11038, 0x11046,),  # Brahmi Vowel Sign Aa    ..Brahmi Virama\n+        (0x11070, 0x11070,),  # Brahmi Sign Old Tamil Virama\n+        (0x11073, 0x11074,),  # Brahmi Vowel Sign Old Ta..Brahmi Vowel Sign Old Ta\n+        (0x1107f, 0x11082,),  # Brahmi Number Joiner    ..Kaithi Sign Visarga\n+        (0x110b0, 0x110ba,),  # Kaithi Vowel Sign Aa    ..Kaithi Sign Nukta\n+        (0x110bd, 0x110bd,),  # Kaithi Number Sign\n+        (0x110c2, 0x110c2,),  # Kaithi Vowel Sign Vocalic R\n+        (0x110cd, 0x110cd,),  # Kaithi Number Sign Above\n+        (0x11100, 0x11102,),  # Chakma Sign Candrabindu ..Chakma Sign Visarga\n+        (0x11127, 0x11134,),  # Chakma Vowel Sign A     ..Chakma Maayyaa\n+        (0x11145, 0x11146,),  # Chakma Vowel Sign Aa    ..Chakma Vowel Sign Ei\n+        (0x11173, 0x11173,),  # Mahajani Sign Nukta\n+        (0x11180, 0x11182,),  # Sharada Sign Candrabindu..Sharada Sign Visarga\n+        (0x111b3, 0x111c0,),  # Sharada Vowel Sign Aa   ..Sharada Sign Virama\n+        (0x111c9, 0x111cc,),  # Sharada Sandhi Mark     ..Sharada Extra Short Vowe\n+        (0x111ce, 0x111cf,),  # Sharada Vowel Sign Prish..Sharada Sign Inverted Ca\n+        (0x1122c, 0x11237,),  # Khojki Vowel Sign Aa    ..Khojki Sign Shadda\n+        (0x1123e, 0x1123e,),  # Khojki Sign Sukun\n+        (0x112df, 0x112ea,),  # Khudawadi Sign Anusvara ..Khudawadi Sign Virama\n+        (0x11300, 0x11303,),  # Grantha Sign Combining A..Grantha Sign Visarga\n+        (0x1133b, 0x1133c,),  # Combining Bindu Below   ..Grantha Sign Nukta\n+        (0x1133e, 0x11344,),  # Grantha Vowel Sign Aa   ..Grantha Vowel Sign Vocal\n+        (0x11347, 0x11348,),  # Grantha Vowel Sign Ee   ..Grantha Vowel Sign Ai\n+        (0x1134b, 0x1134d,),  # Grantha Vowel Sign Oo   ..Grantha Sign Virama\n+        (0x11357, 0x11357,),  # Grantha Au Length Mark\n+        (0x11362, 0x11363,),  # Grantha Vowel Sign Vocal..Grantha Vowel Sign Vocal\n+        (0x11366, 0x1136c,),  # Combining Grantha Digit ..Combining Grantha Digit\n+        (0x11370, 0x11374,),  # Combining Grantha Letter..Combining Grantha Letter\n+        (0x11435, 0x11446,),  # Newa Vowel Sign Aa      ..Newa Sign Nukta\n+        (0x1145e, 0x1145e,),  # Newa Sandhi Mark\n+        (0x114b0, 0x114c3,),  # Tirhuta Vowel Sign Aa   ..Tirhuta Sign Nukta\n+        (0x115af, 0x115b5,),  # Siddham Vowel Sign Aa   ..Siddham Vowel Sign Vocal\n+        (0x115b8, 0x115c0,),  # Siddham Vowel Sign E    ..Siddham Sign Nukta\n+        (0x115dc, 0x115dd,),  # Siddham Vowel Sign Alter..Siddham Vowel Sign Alter\n+        (0x11630, 0x11640,),  # Modi Vowel Sign Aa      ..Modi Sign Ardhacandra\n+        (0x116ab, 0x116b7,),  # Takri Sign Anusvara     ..Takri Sign Nukta\n+        (0x1171d, 0x1172b,),  # Ahom Consonant Sign Medi..Ahom Sign Killer\n+        (0x1182c, 0x1183a,),  # Dogra Vowel Sign Aa     ..Dogra Sign Nukta\n+        (0x11930, 0x11935,),  # Dives Akuru Vowel Sign A..Dives Akuru Vowel Sign E\n+        (0x11937, 0x11938,),  # Dives Akuru Vowel Sign A..Dives Akuru Vowel Sign O\n+        (0x1193b, 0x1193e,),  # Dives Akuru Sign Anusvar..Dives Akuru Virama\n+        (0x11940, 0x11940,),  # Dives Akuru Medial Ya\n+        (0x11942, 0x11943,),  # Dives Akuru Medial Ra   ..Dives Akuru Sign Nukta\n+        (0x119d1, 0x119d7,),  # Nandinagari Vowel Sign A..Nandinagari Vowel Sign V\n+        (0x119da, 0x119e0,),  # Nandinagari Vowel Sign E..Nandinagari Sign Virama\n+        (0x119e4, 0x119e4,),  # Nandinagari Vowel Sign Prishthamatra E\n+        (0x11a01, 0x11a0a,),  # Zanabazar Square Vowel S..Zanabazar Square Vowel L\n+        (0x11a33, 0x11a39,),  # Zanabazar Square Final C..Zanabazar Square Sign Vi\n+        (0x11a3b, 0x11a3e,),  # Zanabazar Square Cluster..Zanabazar Square Cluster\n+        (0x11a47, 0x11a47,),  # Zanabazar Square Subjoiner\n+        (0x11a51, 0x11a5b,),  # Soyombo Vowel Sign I    ..Soyombo Vowel Length Mar\n+        (0x11a8a, 0x11a99,),  # Soyombo Final Consonant ..Soyombo Subjoiner\n+        (0x11c2f, 0x11c36,),  # Bhaiksuki Vowel Sign Aa ..Bhaiksuki Vowel Sign Voc\n+        (0x11c38, 0x11c3f,),  # Bhaiksuki Vowel Sign E  ..Bhaiksuki Sign Virama\n+        (0x11c92, 0x11ca7,),  # Marchen Subjoined Letter..Marchen Subjoined Letter\n+        (0x11ca9, 0x11cb6,),  # Marchen Subjoined Letter..Marchen Sign Candrabindu\n+        (0x11d31, 0x11d36,),  # Masaram Gondi Vowel Sign..Masaram Gondi Vowel Sign\n+        (0x11d3a, 0x11d3a,),  # Masaram Gondi Vowel Sign E\n+        (0x11d3c, 0x11d3d,),  # Masaram Gondi Vowel Sign..Masaram Gondi Vowel Sign\n+        (0x11d3f, 0x11d45,),  # Masaram Gondi Vowel Sign..Masaram Gondi Virama\n+        (0x11d47, 0x11d47,),  # Masaram Gondi Ra-kara\n+        (0x11d8a, 0x11d8e,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Vowel Sign\n+        (0x11d90, 0x11d91,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Vowel Sign\n+        (0x11d93, 0x11d97,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Virama\n+        (0x11ef3, 0x11ef6,),  # Makasar Vowel Sign I    ..Makasar Vowel Sign O\n+        (0x13430, 0x13438,),  # Egyptian Hieroglyph Vert..Egyptian Hieroglyph End\n+        (0x16af0, 0x16af4,),  # Bassa Vah Combining High..Bassa Vah Combining High\n+        (0x16b30, 0x16b36,),  # Pahawh Hmong Mark Cim Tu..Pahawh Hmong Mark Cim Ta\n+        (0x16f4f, 0x16f4f,),  # Miao Sign Consonant Modifier Bar\n+        (0x16f51, 0x16f87,),  # Miao Sign Aspiration    ..Miao Vowel Sign Ui\n+        (0x16f8f, 0x16f92,),  # Miao Tone Right         ..Miao Tone Below\n+        (0x16fe4, 0x16fe4,),  # Khitan Small Script Filler\n+        (0x16ff0, 0x16ff1,),  # Vietnamese Alternate Rea..Vietnamese Alternate Rea\n+        (0x1bc9d, 0x1bc9e,),  # Duployan Thick Letter Se..Duployan Double Mark\n+        (0x1bca0, 0x1bca3,),  # Shorthand Format Letter ..Shorthand Format Up Step\n+        (0x1cf00, 0x1cf2d,),  # Znamenny Combining Mark ..Znamenny Combining Mark\n+        (0x1cf30, 0x1cf46,),  # Znamenny Combining Tonal..Znamenny Priznak Modifie\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0x1da00, 0x1da36,),  # Signwriting Head Rim    ..Signwriting Air Sucking\n+        (0x1da3b, 0x1da6c,),  # Signwriting Mouth Closed..Signwriting Excitement\n+        (0x1da75, 0x1da75,),  # Signwriting Upper Body Tilting From Hip Joints\n+        (0x1da84, 0x1da84,),  # Signwriting Location Head Neck\n+        (0x1da9b, 0x1da9f,),  # Signwriting Fill Modifie..Signwriting Fill Modifie\n+        (0x1daa1, 0x1daaf,),  # Signwriting Rotation Mod..Signwriting Rotation Mod\n+        (0x1e000, 0x1e006,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e008, 0x1e018,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e01b, 0x1e021,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e023, 0x1e024,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e026, 0x1e02a,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e130, 0x1e136,),  # Nyiakeng Puachue Hmong T..Nyiakeng Puachue Hmong T\n+        (0x1e2ae, 0x1e2ae,),  # Toto Sign Rising Tone\n+        (0x1e2ec, 0x1e2ef,),  # Wancho Tone Tup         ..Wancho Tone Koini\n+        (0x1e8d0, 0x1e8d6,),  # Mende Kikakui Combining ..Mende Kikakui Combining\n+        (0x1e944, 0x1e94a,),  # Adlam Alif Lengthener   ..Adlam Nukta\n+        (0x1f3fb, 0x1f3ff,),  # Emoji Modifier Fitzpatri..Emoji Modifier Fitzpatri\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '15.0.0': (\n+        # Source: DerivedGeneralCategory-15.0.0.txt\n+        # Date: 2022-04-26, 23:14:35 GMT\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00605,),  # Arabic Number Sign      ..Arabic Number Mark Above\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0061c, 0x0061c,),  # Arabic Letter Mark\n+        (0x0064b, 0x0065f,),  # Arabic Fathatan         ..Arabic Wavy Hamza Below\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006dd,),  # Arabic Small High Ligatu..Arabic End Of Ayah\n+        (0x006df, 0x006e4,),  # Arabic Small High Rounde..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x007fd, 0x007fd,),  # Nko Dantayalan\n+        (0x00816, 0x00819,),  # Samaritan Mark In       ..Samaritan Mark Dagesh\n+        (0x0081b, 0x00823,),  # Samaritan Mark Epentheti..Samaritan Vowel Sign A\n+        (0x00825, 0x00827,),  # Samaritan Vowel Sign Sho..Samaritan Vowel Sign U\n+        (0x00829, 0x0082d,),  # Samaritan Vowel Sign Lon..Samaritan Mark Nequdaa\n+        (0x00859, 0x0085b,),  # Mandaic Affrication Mark..Mandaic Gemination Mark\n+        (0x00890, 0x00891,),  # Arabic Pound Mark Above ..Arabic Piastre Mark Abov\n+        (0x00898, 0x0089f,),  # Arabic Small High Word A..Arabic Half Madda Over M\n+        (0x008ca, 0x00903,),  # Arabic Small High Farsi ..Devanagari Sign Visarga\n+        (0x0093a, 0x0093c,),  # Devanagari Vowel Sign Oe..Devanagari Sign Nukta\n+        (0x0093e, 0x0094f,),  # Devanagari Vowel Sign Aa..Devanagari Vowel Sign Aw\n+        (0x00951, 0x00957,),  # Devanagari Stress Sign U..Devanagari Vowel Sign Uu\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x009fe, 0x009fe,),  # Bengali Sandhi Mark\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00afa, 0x00aff,),  # Gujarati Sign Sukun     ..Gujarati Sign Two-circle\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b55, 0x00b57,),  # Oriya Sign Overline     ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c00, 0x00c04,),  # Telugu Sign Combining Ca..Telugu Sign Combining An\n+        (0x00c3c, 0x00c3c,),  # Telugu Sign Nukta\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c81, 0x00c83,),  # Kannada Sign Candrabindu..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00cf3, 0x00cf3,),  # Kannada Sign Combining Anusvara Above Right\n+        (0x00d00, 0x00d03,),  # Malayalam Sign Combining..Malayalam Sign Visarga\n+        (0x00d3b, 0x00d3c,),  # Malayalam Sign Vertical ..Malayalam Sign Circular\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d81, 0x00d83,),  # Sinhala Sign Candrabindu..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00ebc,),  # Lao Vowel Sign I        ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ece,),  # Lao Tone Mai Ek         ..Lao Yamakkan\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f8d, 0x00f97,),  # Tibetan Subjoined Sign L..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x0109a, 0x0109d,),  # Myanmar Sign Khamti Tone..Myanmar Vowel Sign Aiton\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135d, 0x0135f,),  # Ethiopic Combining Gemin..Ethiopic Combining Gemin\n+        (0x01712, 0x01715,),  # Tagalog Vowel Sign I    ..Tagalog Sign Pamudpod\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180f,),  # Mongolian Free Variation..Mongolian Free Variation\n+        (0x01885, 0x01886,),  # Mongolian Letter Ali Gal..Mongolian Letter Ali Gal\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01a55, 0x01a5e,),  # Tai Tham Consonant Sign ..Tai Tham Consonant Sign\n+        (0x01a60, 0x01a7c,),  # Tai Tham Sign Sakot     ..Tai Tham Sign Khuen-lue\n+        (0x01a7f, 0x01a7f,),  # Tai Tham Combining Cryptogrammic Dot\n+        (0x01ab0, 0x01ace,),  # Combining Doubled Circum..Combining Latin Small Le\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01bad,),  # Sundanese Consonant Sign..Sundanese Consonant Sign\n+        (0x01be6, 0x01bf3,),  # Batak Sign Tompi        ..Batak Panongonan\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01cd0, 0x01cd2,),  # Vedic Tone Karshana     ..Vedic Tone Prenkha\n+        (0x01cd4, 0x01ce8,),  # Vedic Sign Yajurvedic Mi..Vedic Sign Visarga Anuda\n+        (0x01ced, 0x01ced,),  # Vedic Sign Tiryak\n+        (0x01cf4, 0x01cf4,),  # Vedic Tone Candra Above\n+        (0x01cf7, 0x01cf9,),  # Vedic Sign Atikrama     ..Vedic Tone Double Ring A\n+        (0x01dc0, 0x01dff,),  # Combining Dotted Grave A..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x02066, 0x0206f,),  # Left-to-right Isolate   ..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02cef, 0x02cf1,),  # Coptic Combining Ni Abov..Coptic Combining Spiritu\n+        (0x02d7f, 0x02d7f,),  # Tifinagh Consonant Joiner\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a674, 0x0a67d,),  # Combining Cyrillic Lette..Combining Cyrillic Payer\n+        (0x0a69e, 0x0a69f,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0a6f0, 0x0a6f1,),  # Bamum Combining Mark Koq..Bamum Combining Mark Tuk\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a82c, 0x0a82c,),  # Syloti Nagri Sign Alternate Hasanta\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c5,),  # Saurashtra Consonant Sig..Saurashtra Sign Candrabi\n+        (0x0a8e0, 0x0a8f1,),  # Combining Devanagari Dig..Combining Devanagari Sig\n+        (0x0a8ff, 0x0a8ff,),  # Devanagari Vowel Sign Ay\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0a980, 0x0a983,),  # Javanese Sign Panyangga ..Javanese Sign Wignyan\n+        (0x0a9b3, 0x0a9c0,),  # Javanese Sign Cecak Telu..Javanese Pangkon\n+        (0x0a9e5, 0x0a9e5,),  # Myanmar Sign Shan Saw\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0aa7b, 0x0aa7d,),  # Myanmar Sign Pao Karen T..Myanmar Sign Tai Laing T\n+        (0x0aab0, 0x0aab0,),  # Tai Viet Mai Kang\n+        (0x0aab2, 0x0aab4,),  # Tai Viet Vowel I        ..Tai Viet Vowel U\n+        (0x0aab7, 0x0aab8,),  # Tai Viet Mai Khit       ..Tai Viet Vowel Ia\n+        (0x0aabe, 0x0aabf,),  # Tai Viet Vowel Am       ..Tai Viet Tone Mai Ek\n+        (0x0aac1, 0x0aac1,),  # Tai Viet Tone Mai Tho\n+        (0x0aaeb, 0x0aaef,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0aaf5, 0x0aaf6,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Virama\n+        (0x0abe3, 0x0abea,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0abec, 0x0abed,),  # Meetei Mayek Lum Iyek   ..Meetei Mayek Apun Iyek\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe2f,),  # Combining Ligature Left ..Combining Cyrillic Titlo\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x102e0, 0x102e0,),  # Coptic Epact Thousands Mark\n+        (0x10376, 0x1037a,),  # Combining Old Permic Let..Combining Old Permic Let\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x10ae5, 0x10ae6,),  # Manichaean Abbreviation ..Manichaean Abbreviation\n+        (0x10d24, 0x10d27,),  # Hanifi Rohingya Sign Har..Hanifi Rohingya Sign Tas\n+        (0x10eab, 0x10eac,),  # Yezidi Combining Hamza M..Yezidi Combining Madda M\n+        (0x10efd, 0x10eff,),  # Arabic Small Low Word Sa..Arabic Small Low Word Ma\n+        (0x10f46, 0x10f50,),  # Sogdian Combining Dot Be..Sogdian Combining Stroke\n+        (0x10f82, 0x10f85,),  # Old Uyghur Combining Dot..Old Uyghur Combining Two\n+        (0x11000, 0x11002,),  # Brahmi Sign Candrabindu ..Brahmi Sign Visarga\n+        (0x11038, 0x11046,),  # Brahmi Vowel Sign Aa    ..Brahmi Virama\n+        (0x11070, 0x11070,),  # Brahmi Sign Old Tamil Virama\n+        (0x11073, 0x11074,),  # Brahmi Vowel Sign Old Ta..Brahmi Vowel Sign Old Ta\n+        (0x1107f, 0x11082,),  # Brahmi Number Joiner    ..Kaithi Sign Visarga\n+        (0x110b0, 0x110ba,),  # Kaithi Vowel Sign Aa    ..Kaithi Sign Nukta\n+        (0x110bd, 0x110bd,),  # Kaithi Number Sign\n+        (0x110c2, 0x110c2,),  # Kaithi Vowel Sign Vocalic R\n+        (0x110cd, 0x110cd,),  # Kaithi Number Sign Above\n+        (0x11100, 0x11102,),  # Chakma Sign Candrabindu ..Chakma Sign Visarga\n+        (0x11127, 0x11134,),  # Chakma Vowel Sign A     ..Chakma Maayyaa\n+        (0x11145, 0x11146,),  # Chakma Vowel Sign Aa    ..Chakma Vowel Sign Ei\n+        (0x11173, 0x11173,),  # Mahajani Sign Nukta\n+        (0x11180, 0x11182,),  # Sharada Sign Candrabindu..Sharada Sign Visarga\n+        (0x111b3, 0x111c0,),  # Sharada Vowel Sign Aa   ..Sharada Sign Virama\n+        (0x111c9, 0x111cc,),  # Sharada Sandhi Mark     ..Sharada Extra Short Vowe\n+        (0x111ce, 0x111cf,),  # Sharada Vowel Sign Prish..Sharada Sign Inverted Ca\n+        (0x1122c, 0x11237,),  # Khojki Vowel Sign Aa    ..Khojki Sign Shadda\n+        (0x1123e, 0x1123e,),  # Khojki Sign Sukun\n+        (0x11241, 0x11241,),  # Khojki Vowel Sign Vocalic R\n+        (0x112df, 0x112ea,),  # Khudawadi Sign Anusvara ..Khudawadi Sign Virama\n+        (0x11300, 0x11303,),  # Grantha Sign Combining A..Grantha Sign Visarga\n+        (0x1133b, 0x1133c,),  # Combining Bindu Below   ..Grantha Sign Nukta\n+        (0x1133e, 0x11344,),  # Grantha Vowel Sign Aa   ..Grantha Vowel Sign Vocal\n+        (0x11347, 0x11348,),  # Grantha Vowel Sign Ee   ..Grantha Vowel Sign Ai\n+        (0x1134b, 0x1134d,),  # Grantha Vowel Sign Oo   ..Grantha Sign Virama\n+        (0x11357, 0x11357,),  # Grantha Au Length Mark\n+        (0x11362, 0x11363,),  # Grantha Vowel Sign Vocal..Grantha Vowel Sign Vocal\n+        (0x11366, 0x1136c,),  # Combining Grantha Digit ..Combining Grantha Digit\n+        (0x11370, 0x11374,),  # Combining Grantha Letter..Combining Grantha Letter\n+        (0x11435, 0x11446,),  # Newa Vowel Sign Aa      ..Newa Sign Nukta\n+        (0x1145e, 0x1145e,),  # Newa Sandhi Mark\n+        (0x114b0, 0x114c3,),  # Tirhuta Vowel Sign Aa   ..Tirhuta Sign Nukta\n+        (0x115af, 0x115b5,),  # Siddham Vowel Sign Aa   ..Siddham Vowel Sign Vocal\n+        (0x115b8, 0x115c0,),  # Siddham Vowel Sign E    ..Siddham Sign Nukta\n+        (0x115dc, 0x115dd,),  # Siddham Vowel Sign Alter..Siddham Vowel Sign Alter\n+        (0x11630, 0x11640,),  # Modi Vowel Sign Aa      ..Modi Sign Ardhacandra\n+        (0x116ab, 0x116b7,),  # Takri Sign Anusvara     ..Takri Sign Nukta\n+        (0x1171d, 0x1172b,),  # Ahom Consonant Sign Medi..Ahom Sign Killer\n+        (0x1182c, 0x1183a,),  # Dogra Vowel Sign Aa     ..Dogra Sign Nukta\n+        (0x11930, 0x11935,),  # Dives Akuru Vowel Sign A..Dives Akuru Vowel Sign E\n+        (0x11937, 0x11938,),  # Dives Akuru Vowel Sign A..Dives Akuru Vowel Sign O\n+        (0x1193b, 0x1193e,),  # Dives Akuru Sign Anusvar..Dives Akuru Virama\n+        (0x11940, 0x11940,),  # Dives Akuru Medial Ya\n+        (0x11942, 0x11943,),  # Dives Akuru Medial Ra   ..Dives Akuru Sign Nukta\n+        (0x119d1, 0x119d7,),  # Nandinagari Vowel Sign A..Nandinagari Vowel Sign V\n+        (0x119da, 0x119e0,),  # Nandinagari Vowel Sign E..Nandinagari Sign Virama\n+        (0x119e4, 0x119e4,),  # Nandinagari Vowel Sign Prishthamatra E\n+        (0x11a01, 0x11a0a,),  # Zanabazar Square Vowel S..Zanabazar Square Vowel L\n+        (0x11a33, 0x11a39,),  # Zanabazar Square Final C..Zanabazar Square Sign Vi\n+        (0x11a3b, 0x11a3e,),  # Zanabazar Square Cluster..Zanabazar Square Cluster\n+        (0x11a47, 0x11a47,),  # Zanabazar Square Subjoiner\n+        (0x11a51, 0x11a5b,),  # Soyombo Vowel Sign I    ..Soyombo Vowel Length Mar\n+        (0x11a8a, 0x11a99,),  # Soyombo Final Consonant ..Soyombo Subjoiner\n+        (0x11c2f, 0x11c36,),  # Bhaiksuki Vowel Sign Aa ..Bhaiksuki Vowel Sign Voc\n+        (0x11c38, 0x11c3f,),  # Bhaiksuki Vowel Sign E  ..Bhaiksuki Sign Virama\n+        (0x11c92, 0x11ca7,),  # Marchen Subjoined Letter..Marchen Subjoined Letter\n+        (0x11ca9, 0x11cb6,),  # Marchen Subjoined Letter..Marchen Sign Candrabindu\n+        (0x11d31, 0x11d36,),  # Masaram Gondi Vowel Sign..Masaram Gondi Vowel Sign\n+        (0x11d3a, 0x11d3a,),  # Masaram Gondi Vowel Sign E\n+        (0x11d3c, 0x11d3d,),  # Masaram Gondi Vowel Sign..Masaram Gondi Vowel Sign\n+        (0x11d3f, 0x11d45,),  # Masaram Gondi Vowel Sign..Masaram Gondi Virama\n+        (0x11d47, 0x11d47,),  # Masaram Gondi Ra-kara\n+        (0x11d8a, 0x11d8e,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Vowel Sign\n+        (0x11d90, 0x11d91,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Vowel Sign\n+        (0x11d93, 0x11d97,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Virama\n+        (0x11ef3, 0x11ef6,),  # Makasar Vowel Sign I    ..Makasar Vowel Sign O\n+        (0x11f00, 0x11f01,),  # Kawi Sign Candrabindu   ..Kawi Sign Anusvara\n+        (0x11f03, 0x11f03,),  # Kawi Sign Visarga\n+        (0x11f34, 0x11f3a,),  # Kawi Vowel Sign Aa      ..Kawi Vowel Sign Vocalic\n+        (0x11f3e, 0x11f42,),  # Kawi Vowel Sign E       ..Kawi Conjoiner\n+        (0x13430, 0x13440,),  # Egyptian Hieroglyph Vert..Egyptian Hieroglyph Mirr\n+        (0x13447, 0x13455,),  # Egyptian Hieroglyph Modi..Egyptian Hieroglyph Modi\n+        (0x16af0, 0x16af4,),  # Bassa Vah Combining High..Bassa Vah Combining High\n+        (0x16b30, 0x16b36,),  # Pahawh Hmong Mark Cim Tu..Pahawh Hmong Mark Cim Ta\n+        (0x16f4f, 0x16f4f,),  # Miao Sign Consonant Modifier Bar\n+        (0x16f51, 0x16f87,),  # Miao Sign Aspiration    ..Miao Vowel Sign Ui\n+        (0x16f8f, 0x16f92,),  # Miao Tone Right         ..Miao Tone Below\n+        (0x16fe4, 0x16fe4,),  # Khitan Small Script Filler\n+        (0x16ff0, 0x16ff1,),  # Vietnamese Alternate Rea..Vietnamese Alternate Rea\n+        (0x1bc9d, 0x1bc9e,),  # Duployan Thick Letter Se..Duployan Double Mark\n+        (0x1bca0, 0x1bca3,),  # Shorthand Format Letter ..Shorthand Format Up Step\n+        (0x1cf00, 0x1cf2d,),  # Znamenny Combining Mark ..Znamenny Combining Mark\n+        (0x1cf30, 0x1cf46,),  # Znamenny Combining Tonal..Znamenny Priznak Modifie\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0x1da00, 0x1da36,),  # Signwriting Head Rim    ..Signwriting Air Sucking\n+        (0x1da3b, 0x1da6c,),  # Signwriting Mouth Closed..Signwriting Excitement\n+        (0x1da75, 0x1da75,),  # Signwriting Upper Body Tilting From Hip Joints\n+        (0x1da84, 0x1da84,),  # Signwriting Location Head Neck\n+        (0x1da9b, 0x1da9f,),  # Signwriting Fill Modifie..Signwriting Fill Modifie\n+        (0x1daa1, 0x1daaf,),  # Signwriting Rotation Mod..Signwriting Rotation Mod\n+        (0x1e000, 0x1e006,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e008, 0x1e018,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e01b, 0x1e021,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e023, 0x1e024,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e026, 0x1e02a,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e08f, 0x1e08f,),  # Combining Cyrillic Small Letter Byelorussian-ukr\n+        (0x1e130, 0x1e136,),  # Nyiakeng Puachue Hmong T..Nyiakeng Puachue Hmong T\n+        (0x1e2ae, 0x1e2ae,),  # Toto Sign Rising Tone\n+        (0x1e2ec, 0x1e2ef,),  # Wancho Tone Tup         ..Wancho Tone Koini\n+        (0x1e4ec, 0x1e4ef,),  # Nag Mundari Sign Muhor  ..Nag Mundari Sign Sutuh\n+        (0x1e8d0, 0x1e8d6,),  # Mende Kikakui Combining ..Mende Kikakui Combining\n+        (0x1e944, 0x1e94a,),  # Adlam Alif Lengthener   ..Adlam Nukta\n+        (0x1f3fb, 0x1f3ff,),  # Emoji Modifier Fitzpatri..Emoji Modifier Fitzpatri\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+    '15.1.0': (\n+        # Source: DerivedGeneralCategory-15.1.0.txt\n+        # Date: 2023-07-28, 23:34:02 GMT\n+        #\n+        (0x00000, 0x00000,),  # (nil)\n+        (0x000ad, 0x000ad,),  # Soft Hyphen\n+        (0x00300, 0x0036f,),  # Combining Grave Accent  ..Combining Latin Small Le\n+        (0x00483, 0x00489,),  # Combining Cyrillic Titlo..Combining Cyrillic Milli\n+        (0x00591, 0x005bd,),  # Hebrew Accent Etnahta   ..Hebrew Point Meteg\n+        (0x005bf, 0x005bf,),  # Hebrew Point Rafe\n+        (0x005c1, 0x005c2,),  # Hebrew Point Shin Dot   ..Hebrew Point Sin Dot\n+        (0x005c4, 0x005c5,),  # Hebrew Mark Upper Dot   ..Hebrew Mark Lower Dot\n+        (0x005c7, 0x005c7,),  # Hebrew Point Qamats Qatan\n+        (0x00600, 0x00605,),  # Arabic Number Sign      ..Arabic Number Mark Above\n+        (0x00610, 0x0061a,),  # Arabic Sign Sallallahou ..Arabic Small Kasra\n+        (0x0061c, 0x0061c,),  # Arabic Letter Mark\n+        (0x0064b, 0x0065f,),  # Arabic Fathatan         ..Arabic Wavy Hamza Below\n+        (0x00670, 0x00670,),  # Arabic Letter Superscript Alef\n+        (0x006d6, 0x006dd,),  # Arabic Small High Ligatu..Arabic End Of Ayah\n+        (0x006df, 0x006e4,),  # Arabic Small High Rounde..Arabic Small High Madda\n+        (0x006e7, 0x006e8,),  # Arabic Small High Yeh   ..Arabic Small High Noon\n+        (0x006ea, 0x006ed,),  # Arabic Empty Centre Low ..Arabic Small Low Meem\n+        (0x0070f, 0x0070f,),  # Syriac Abbreviation Mark\n+        (0x00711, 0x00711,),  # Syriac Letter Superscript Alaph\n+        (0x00730, 0x0074a,),  # Syriac Pthaha Above     ..Syriac Barrekh\n+        (0x007a6, 0x007b0,),  # Thaana Abafili          ..Thaana Sukun\n+        (0x007eb, 0x007f3,),  # Nko Combining Short High..Nko Combining Double Dot\n+        (0x007fd, 0x007fd,),  # Nko Dantayalan\n+        (0x00816, 0x00819,),  # Samaritan Mark In       ..Samaritan Mark Dagesh\n+        (0x0081b, 0x00823,),  # Samaritan Mark Epentheti..Samaritan Vowel Sign A\n+        (0x00825, 0x00827,),  # Samaritan Vowel Sign Sho..Samaritan Vowel Sign U\n+        (0x00829, 0x0082d,),  # Samaritan Vowel Sign Lon..Samaritan Mark Nequdaa\n+        (0x00859, 0x0085b,),  # Mandaic Affrication Mark..Mandaic Gemination Mark\n+        (0x00890, 0x00891,),  # Arabic Pound Mark Above ..Arabic Piastre Mark Abov\n+        (0x00898, 0x0089f,),  # Arabic Small High Word A..Arabic Half Madda Over M\n+        (0x008ca, 0x00903,),  # Arabic Small High Farsi ..Devanagari Sign Visarga\n+        (0x0093a, 0x0093c,),  # Devanagari Vowel Sign Oe..Devanagari Sign Nukta\n+        (0x0093e, 0x0094f,),  # Devanagari Vowel Sign Aa..Devanagari Vowel Sign Aw\n+        (0x00951, 0x00957,),  # Devanagari Stress Sign U..Devanagari Vowel Sign Uu\n+        (0x00962, 0x00963,),  # Devanagari Vowel Sign Vo..Devanagari Vowel Sign Vo\n+        (0x00981, 0x00983,),  # Bengali Sign Candrabindu..Bengali Sign Visarga\n+        (0x009bc, 0x009bc,),  # Bengali Sign Nukta\n+        (0x009be, 0x009c4,),  # Bengali Vowel Sign Aa   ..Bengali Vowel Sign Vocal\n+        (0x009c7, 0x009c8,),  # Bengali Vowel Sign E    ..Bengali Vowel Sign Ai\n+        (0x009cb, 0x009cd,),  # Bengali Vowel Sign O    ..Bengali Sign Virama\n+        (0x009d7, 0x009d7,),  # Bengali Au Length Mark\n+        (0x009e2, 0x009e3,),  # Bengali Vowel Sign Vocal..Bengali Vowel Sign Vocal\n+        (0x009fe, 0x009fe,),  # Bengali Sandhi Mark\n+        (0x00a01, 0x00a03,),  # Gurmukhi Sign Adak Bindi..Gurmukhi Sign Visarga\n+        (0x00a3c, 0x00a3c,),  # Gurmukhi Sign Nukta\n+        (0x00a3e, 0x00a42,),  # Gurmukhi Vowel Sign Aa  ..Gurmukhi Vowel Sign Uu\n+        (0x00a47, 0x00a48,),  # Gurmukhi Vowel Sign Ee  ..Gurmukhi Vowel Sign Ai\n+        (0x00a4b, 0x00a4d,),  # Gurmukhi Vowel Sign Oo  ..Gurmukhi Sign Virama\n+        (0x00a51, 0x00a51,),  # Gurmukhi Sign Udaat\n+        (0x00a70, 0x00a71,),  # Gurmukhi Tippi          ..Gurmukhi Addak\n+        (0x00a75, 0x00a75,),  # Gurmukhi Sign Yakash\n+        (0x00a81, 0x00a83,),  # Gujarati Sign Candrabind..Gujarati Sign Visarga\n+        (0x00abc, 0x00abc,),  # Gujarati Sign Nukta\n+        (0x00abe, 0x00ac5,),  # Gujarati Vowel Sign Aa  ..Gujarati Vowel Sign Cand\n+        (0x00ac7, 0x00ac9,),  # Gujarati Vowel Sign E   ..Gujarati Vowel Sign Cand\n+        (0x00acb, 0x00acd,),  # Gujarati Vowel Sign O   ..Gujarati Sign Virama\n+        (0x00ae2, 0x00ae3,),  # Gujarati Vowel Sign Voca..Gujarati Vowel Sign Voca\n+        (0x00afa, 0x00aff,),  # Gujarati Sign Sukun     ..Gujarati Sign Two-circle\n+        (0x00b01, 0x00b03,),  # Oriya Sign Candrabindu  ..Oriya Sign Visarga\n+        (0x00b3c, 0x00b3c,),  # Oriya Sign Nukta\n+        (0x00b3e, 0x00b44,),  # Oriya Vowel Sign Aa     ..Oriya Vowel Sign Vocalic\n+        (0x00b47, 0x00b48,),  # Oriya Vowel Sign E      ..Oriya Vowel Sign Ai\n+        (0x00b4b, 0x00b4d,),  # Oriya Vowel Sign O      ..Oriya Sign Virama\n+        (0x00b55, 0x00b57,),  # Oriya Sign Overline     ..Oriya Au Length Mark\n+        (0x00b62, 0x00b63,),  # Oriya Vowel Sign Vocalic..Oriya Vowel Sign Vocalic\n+        (0x00b82, 0x00b82,),  # Tamil Sign Anusvara\n+        (0x00bbe, 0x00bc2,),  # Tamil Vowel Sign Aa     ..Tamil Vowel Sign Uu\n+        (0x00bc6, 0x00bc8,),  # Tamil Vowel Sign E      ..Tamil Vowel Sign Ai\n+        (0x00bca, 0x00bcd,),  # Tamil Vowel Sign O      ..Tamil Sign Virama\n+        (0x00bd7, 0x00bd7,),  # Tamil Au Length Mark\n+        (0x00c00, 0x00c04,),  # Telugu Sign Combining Ca..Telugu Sign Combining An\n+        (0x00c3c, 0x00c3c,),  # Telugu Sign Nukta\n+        (0x00c3e, 0x00c44,),  # Telugu Vowel Sign Aa    ..Telugu Vowel Sign Vocali\n+        (0x00c46, 0x00c48,),  # Telugu Vowel Sign E     ..Telugu Vowel Sign Ai\n+        (0x00c4a, 0x00c4d,),  # Telugu Vowel Sign O     ..Telugu Sign Virama\n+        (0x00c55, 0x00c56,),  # Telugu Length Mark      ..Telugu Ai Length Mark\n+        (0x00c62, 0x00c63,),  # Telugu Vowel Sign Vocali..Telugu Vowel Sign Vocali\n+        (0x00c81, 0x00c83,),  # Kannada Sign Candrabindu..Kannada Sign Visarga\n+        (0x00cbc, 0x00cbc,),  # Kannada Sign Nukta\n+        (0x00cbe, 0x00cc4,),  # Kannada Vowel Sign Aa   ..Kannada Vowel Sign Vocal\n+        (0x00cc6, 0x00cc8,),  # Kannada Vowel Sign E    ..Kannada Vowel Sign Ai\n+        (0x00cca, 0x00ccd,),  # Kannada Vowel Sign O    ..Kannada Sign Virama\n+        (0x00cd5, 0x00cd6,),  # Kannada Length Mark     ..Kannada Ai Length Mark\n+        (0x00ce2, 0x00ce3,),  # Kannada Vowel Sign Vocal..Kannada Vowel Sign Vocal\n+        (0x00cf3, 0x00cf3,),  # Kannada Sign Combining Anusvara Above Right\n+        (0x00d00, 0x00d03,),  # Malayalam Sign Combining..Malayalam Sign Visarga\n+        (0x00d3b, 0x00d3c,),  # Malayalam Sign Vertical ..Malayalam Sign Circular\n+        (0x00d3e, 0x00d44,),  # Malayalam Vowel Sign Aa ..Malayalam Vowel Sign Voc\n+        (0x00d46, 0x00d48,),  # Malayalam Vowel Sign E  ..Malayalam Vowel Sign Ai\n+        (0x00d4a, 0x00d4d,),  # Malayalam Vowel Sign O  ..Malayalam Sign Virama\n+        (0x00d57, 0x00d57,),  # Malayalam Au Length Mark\n+        (0x00d62, 0x00d63,),  # Malayalam Vowel Sign Voc..Malayalam Vowel Sign Voc\n+        (0x00d81, 0x00d83,),  # Sinhala Sign Candrabindu..Sinhala Sign Visargaya\n+        (0x00dca, 0x00dca,),  # Sinhala Sign Al-lakuna\n+        (0x00dcf, 0x00dd4,),  # Sinhala Vowel Sign Aela-..Sinhala Vowel Sign Ketti\n+        (0x00dd6, 0x00dd6,),  # Sinhala Vowel Sign Diga Paa-pilla\n+        (0x00dd8, 0x00ddf,),  # Sinhala Vowel Sign Gaett..Sinhala Vowel Sign Gayan\n+        (0x00df2, 0x00df3,),  # Sinhala Vowel Sign Diga ..Sinhala Vowel Sign Diga\n+        (0x00e31, 0x00e31,),  # Thai Character Mai Han-akat\n+        (0x00e34, 0x00e3a,),  # Thai Character Sara I   ..Thai Character Phinthu\n+        (0x00e47, 0x00e4e,),  # Thai Character Maitaikhu..Thai Character Yamakkan\n+        (0x00eb1, 0x00eb1,),  # Lao Vowel Sign Mai Kan\n+        (0x00eb4, 0x00ebc,),  # Lao Vowel Sign I        ..Lao Semivowel Sign Lo\n+        (0x00ec8, 0x00ece,),  # Lao Tone Mai Ek         ..Lao Yamakkan\n+        (0x00f18, 0x00f19,),  # Tibetan Astrological Sig..Tibetan Astrological Sig\n+        (0x00f35, 0x00f35,),  # Tibetan Mark Ngas Bzung Nyi Zla\n+        (0x00f37, 0x00f37,),  # Tibetan Mark Ngas Bzung Sgor Rtags\n+        (0x00f39, 0x00f39,),  # Tibetan Mark Tsa -phru\n+        (0x00f3e, 0x00f3f,),  # Tibetan Sign Yar Tshes  ..Tibetan Sign Mar Tshes\n+        (0x00f71, 0x00f84,),  # Tibetan Vowel Sign Aa   ..Tibetan Mark Halanta\n+        (0x00f86, 0x00f87,),  # Tibetan Sign Lci Rtags  ..Tibetan Sign Yang Rtags\n+        (0x00f8d, 0x00f97,),  # Tibetan Subjoined Sign L..Tibetan Subjoined Letter\n+        (0x00f99, 0x00fbc,),  # Tibetan Subjoined Letter..Tibetan Subjoined Letter\n+        (0x00fc6, 0x00fc6,),  # Tibetan Symbol Padma Gdan\n+        (0x0102b, 0x0103e,),  # Myanmar Vowel Sign Tall ..Myanmar Consonant Sign M\n+        (0x01056, 0x01059,),  # Myanmar Vowel Sign Vocal..Myanmar Vowel Sign Vocal\n+        (0x0105e, 0x01060,),  # Myanmar Consonant Sign M..Myanmar Consonant Sign M\n+        (0x01062, 0x01064,),  # Myanmar Vowel Sign Sgaw ..Myanmar Tone Mark Sgaw K\n+        (0x01067, 0x0106d,),  # Myanmar Vowel Sign Weste..Myanmar Sign Western Pwo\n+        (0x01071, 0x01074,),  # Myanmar Vowel Sign Geba ..Myanmar Vowel Sign Kayah\n+        (0x01082, 0x0108d,),  # Myanmar Consonant Sign S..Myanmar Sign Shan Counci\n+        (0x0108f, 0x0108f,),  # Myanmar Sign Rumai Palaung Tone-5\n+        (0x0109a, 0x0109d,),  # Myanmar Sign Khamti Tone..Myanmar Vowel Sign Aiton\n+        (0x01160, 0x011ff,),  # Hangul Jungseong Filler ..Hangul Jongseong Ssangni\n+        (0x0135d, 0x0135f,),  # Ethiopic Combining Gemin..Ethiopic Combining Gemin\n+        (0x01712, 0x01715,),  # Tagalog Vowel Sign I    ..Tagalog Sign Pamudpod\n+        (0x01732, 0x01734,),  # Hanunoo Vowel Sign I    ..Hanunoo Sign Pamudpod\n+        (0x01752, 0x01753,),  # Buhid Vowel Sign I      ..Buhid Vowel Sign U\n+        (0x01772, 0x01773,),  # Tagbanwa Vowel Sign I   ..Tagbanwa Vowel Sign U\n+        (0x017b4, 0x017d3,),  # Khmer Vowel Inherent Aq ..Khmer Sign Bathamasat\n+        (0x017dd, 0x017dd,),  # Khmer Sign Atthacan\n+        (0x0180b, 0x0180f,),  # Mongolian Free Variation..Mongolian Free Variation\n+        (0x01885, 0x01886,),  # Mongolian Letter Ali Gal..Mongolian Letter Ali Gal\n+        (0x018a9, 0x018a9,),  # Mongolian Letter Ali Gali Dagalga\n+        (0x01920, 0x0192b,),  # Limbu Vowel Sign A      ..Limbu Subjoined Letter W\n+        (0x01930, 0x0193b,),  # Limbu Small Letter Ka   ..Limbu Sign Sa-i\n+        (0x01a17, 0x01a1b,),  # Buginese Vowel Sign I   ..Buginese Vowel Sign Ae\n+        (0x01a55, 0x01a5e,),  # Tai Tham Consonant Sign ..Tai Tham Consonant Sign\n+        (0x01a60, 0x01a7c,),  # Tai Tham Sign Sakot     ..Tai Tham Sign Khuen-lue\n+        (0x01a7f, 0x01a7f,),  # Tai Tham Combining Cryptogrammic Dot\n+        (0x01ab0, 0x01ace,),  # Combining Doubled Circum..Combining Latin Small Le\n+        (0x01b00, 0x01b04,),  # Balinese Sign Ulu Ricem ..Balinese Sign Bisah\n+        (0x01b34, 0x01b44,),  # Balinese Sign Rerekan   ..Balinese Adeg Adeg\n+        (0x01b6b, 0x01b73,),  # Balinese Musical Symbol ..Balinese Musical Symbol\n+        (0x01b80, 0x01b82,),  # Sundanese Sign Panyecek ..Sundanese Sign Pangwisad\n+        (0x01ba1, 0x01bad,),  # Sundanese Consonant Sign..Sundanese Consonant Sign\n+        (0x01be6, 0x01bf3,),  # Batak Sign Tompi        ..Batak Panongonan\n+        (0x01c24, 0x01c37,),  # Lepcha Subjoined Letter ..Lepcha Sign Nukta\n+        (0x01cd0, 0x01cd2,),  # Vedic Tone Karshana     ..Vedic Tone Prenkha\n+        (0x01cd4, 0x01ce8,),  # Vedic Sign Yajurvedic Mi..Vedic Sign Visarga Anuda\n+        (0x01ced, 0x01ced,),  # Vedic Sign Tiryak\n+        (0x01cf4, 0x01cf4,),  # Vedic Tone Candra Above\n+        (0x01cf7, 0x01cf9,),  # Vedic Sign Atikrama     ..Vedic Tone Double Ring A\n+        (0x01dc0, 0x01dff,),  # Combining Dotted Grave A..Combining Right Arrowhea\n+        (0x0200b, 0x0200f,),  # Zero Width Space        ..Right-to-left Mark\n+        (0x02028, 0x0202e,),  # Line Separator          ..Right-to-left Override\n+        (0x02060, 0x02064,),  # Word Joiner             ..Invisible Plus\n+        (0x02066, 0x0206f,),  # Left-to-right Isolate   ..Nominal Digit Shapes\n+        (0x020d0, 0x020f0,),  # Combining Left Harpoon A..Combining Asterisk Above\n+        (0x02cef, 0x02cf1,),  # Coptic Combining Ni Abov..Coptic Combining Spiritu\n+        (0x02d7f, 0x02d7f,),  # Tifinagh Consonant Joiner\n+        (0x02de0, 0x02dff,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0302a, 0x0302f,),  # Ideographic Level Tone M..Hangul Double Dot Tone M\n+        (0x03099, 0x0309a,),  # Combining Katakana-hirag..Combining Katakana-hirag\n+        (0x0a66f, 0x0a672,),  # Combining Cyrillic Vzmet..Combining Cyrillic Thous\n+        (0x0a674, 0x0a67d,),  # Combining Cyrillic Lette..Combining Cyrillic Payer\n+        (0x0a69e, 0x0a69f,),  # Combining Cyrillic Lette..Combining Cyrillic Lette\n+        (0x0a6f0, 0x0a6f1,),  # Bamum Combining Mark Koq..Bamum Combining Mark Tuk\n+        (0x0a802, 0x0a802,),  # Syloti Nagri Sign Dvisvara\n+        (0x0a806, 0x0a806,),  # Syloti Nagri Sign Hasanta\n+        (0x0a80b, 0x0a80b,),  # Syloti Nagri Sign Anusvara\n+        (0x0a823, 0x0a827,),  # Syloti Nagri Vowel Sign ..Syloti Nagri Vowel Sign\n+        (0x0a82c, 0x0a82c,),  # Syloti Nagri Sign Alternate Hasanta\n+        (0x0a880, 0x0a881,),  # Saurashtra Sign Anusvara..Saurashtra Sign Visarga\n+        (0x0a8b4, 0x0a8c5,),  # Saurashtra Consonant Sig..Saurashtra Sign Candrabi\n+        (0x0a8e0, 0x0a8f1,),  # Combining Devanagari Dig..Combining Devanagari Sig\n+        (0x0a8ff, 0x0a8ff,),  # Devanagari Vowel Sign Ay\n+        (0x0a926, 0x0a92d,),  # Kayah Li Vowel Ue       ..Kayah Li Tone Calya Plop\n+        (0x0a947, 0x0a953,),  # Rejang Vowel Sign I     ..Rejang Virama\n+        (0x0a980, 0x0a983,),  # Javanese Sign Panyangga ..Javanese Sign Wignyan\n+        (0x0a9b3, 0x0a9c0,),  # Javanese Sign Cecak Telu..Javanese Pangkon\n+        (0x0a9e5, 0x0a9e5,),  # Myanmar Sign Shan Saw\n+        (0x0aa29, 0x0aa36,),  # Cham Vowel Sign Aa      ..Cham Consonant Sign Wa\n+        (0x0aa43, 0x0aa43,),  # Cham Consonant Sign Final Ng\n+        (0x0aa4c, 0x0aa4d,),  # Cham Consonant Sign Fina..Cham Consonant Sign Fina\n+        (0x0aa7b, 0x0aa7d,),  # Myanmar Sign Pao Karen T..Myanmar Sign Tai Laing T\n+        (0x0aab0, 0x0aab0,),  # Tai Viet Mai Kang\n+        (0x0aab2, 0x0aab4,),  # Tai Viet Vowel I        ..Tai Viet Vowel U\n+        (0x0aab7, 0x0aab8,),  # Tai Viet Mai Khit       ..Tai Viet Vowel Ia\n+        (0x0aabe, 0x0aabf,),  # Tai Viet Vowel Am       ..Tai Viet Tone Mai Ek\n+        (0x0aac1, 0x0aac1,),  # Tai Viet Tone Mai Tho\n+        (0x0aaeb, 0x0aaef,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0aaf5, 0x0aaf6,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Virama\n+        (0x0abe3, 0x0abea,),  # Meetei Mayek Vowel Sign ..Meetei Mayek Vowel Sign\n+        (0x0abec, 0x0abed,),  # Meetei Mayek Lum Iyek   ..Meetei Mayek Apun Iyek\n+        (0x0d7b0, 0x0d7ff,),  # Hangul Jungseong O-yeo  ..(nil)\n+        (0x0fb1e, 0x0fb1e,),  # Hebrew Point Judeo-spanish Varika\n+        (0x0fe00, 0x0fe0f,),  # Variation Selector-1    ..Variation Selector-16\n+        (0x0fe20, 0x0fe2f,),  # Combining Ligature Left ..Combining Cyrillic Titlo\n+        (0x0feff, 0x0feff,),  # Zero Width No-break Space\n+        (0x0fff9, 0x0fffb,),  # Interlinear Annotation A..Interlinear Annotation T\n+        (0x101fd, 0x101fd,),  # Phaistos Disc Sign Combining Oblique Stroke\n+        (0x102e0, 0x102e0,),  # Coptic Epact Thousands Mark\n+        (0x10376, 0x1037a,),  # Combining Old Permic Let..Combining Old Permic Let\n+        (0x10a01, 0x10a03,),  # Kharoshthi Vowel Sign I ..Kharoshthi Vowel Sign Vo\n+        (0x10a05, 0x10a06,),  # Kharoshthi Vowel Sign E ..Kharoshthi Vowel Sign O\n+        (0x10a0c, 0x10a0f,),  # Kharoshthi Vowel Length ..Kharoshthi Sign Visarga\n+        (0x10a38, 0x10a3a,),  # Kharoshthi Sign Bar Abov..Kharoshthi Sign Dot Belo\n+        (0x10a3f, 0x10a3f,),  # Kharoshthi Virama\n+        (0x10ae5, 0x10ae6,),  # Manichaean Abbreviation ..Manichaean Abbreviation\n+        (0x10d24, 0x10d27,),  # Hanifi Rohingya Sign Har..Hanifi Rohingya Sign Tas\n+        (0x10eab, 0x10eac,),  # Yezidi Combining Hamza M..Yezidi Combining Madda M\n+        (0x10efd, 0x10eff,),  # Arabic Small Low Word Sa..Arabic Small Low Word Ma\n+        (0x10f46, 0x10f50,),  # Sogdian Combining Dot Be..Sogdian Combining Stroke\n+        (0x10f82, 0x10f85,),  # Old Uyghur Combining Dot..Old Uyghur Combining Two\n+        (0x11000, 0x11002,),  # Brahmi Sign Candrabindu ..Brahmi Sign Visarga\n+        (0x11038, 0x11046,),  # Brahmi Vowel Sign Aa    ..Brahmi Virama\n+        (0x11070, 0x11070,),  # Brahmi Sign Old Tamil Virama\n+        (0x11073, 0x11074,),  # Brahmi Vowel Sign Old Ta..Brahmi Vowel Sign Old Ta\n+        (0x1107f, 0x11082,),  # Brahmi Number Joiner    ..Kaithi Sign Visarga\n+        (0x110b0, 0x110ba,),  # Kaithi Vowel Sign Aa    ..Kaithi Sign Nukta\n+        (0x110bd, 0x110bd,),  # Kaithi Number Sign\n+        (0x110c2, 0x110c2,),  # Kaithi Vowel Sign Vocalic R\n+        (0x110cd, 0x110cd,),  # Kaithi Number Sign Above\n+        (0x11100, 0x11102,),  # Chakma Sign Candrabindu ..Chakma Sign Visarga\n+        (0x11127, 0x11134,),  # Chakma Vowel Sign A     ..Chakma Maayyaa\n+        (0x11145, 0x11146,),  # Chakma Vowel Sign Aa    ..Chakma Vowel Sign Ei\n+        (0x11173, 0x11173,),  # Mahajani Sign Nukta\n+        (0x11180, 0x11182,),  # Sharada Sign Candrabindu..Sharada Sign Visarga\n+        (0x111b3, 0x111c0,),  # Sharada Vowel Sign Aa   ..Sharada Sign Virama\n+        (0x111c9, 0x111cc,),  # Sharada Sandhi Mark     ..Sharada Extra Short Vowe\n+        (0x111ce, 0x111cf,),  # Sharada Vowel Sign Prish..Sharada Sign Inverted Ca\n+        (0x1122c, 0x11237,),  # Khojki Vowel Sign Aa    ..Khojki Sign Shadda\n+        (0x1123e, 0x1123e,),  # Khojki Sign Sukun\n+        (0x11241, 0x11241,),  # Khojki Vowel Sign Vocalic R\n+        (0x112df, 0x112ea,),  # Khudawadi Sign Anusvara ..Khudawadi Sign Virama\n+        (0x11300, 0x11303,),  # Grantha Sign Combining A..Grantha Sign Visarga\n+        (0x1133b, 0x1133c,),  # Combining Bindu Below   ..Grantha Sign Nukta\n+        (0x1133e, 0x11344,),  # Grantha Vowel Sign Aa   ..Grantha Vowel Sign Vocal\n+        (0x11347, 0x11348,),  # Grantha Vowel Sign Ee   ..Grantha Vowel Sign Ai\n+        (0x1134b, 0x1134d,),  # Grantha Vowel Sign Oo   ..Grantha Sign Virama\n+        (0x11357, 0x11357,),  # Grantha Au Length Mark\n+        (0x11362, 0x11363,),  # Grantha Vowel Sign Vocal..Grantha Vowel Sign Vocal\n+        (0x11366, 0x1136c,),  # Combining Grantha Digit ..Combining Grantha Digit\n+        (0x11370, 0x11374,),  # Combining Grantha Letter..Combining Grantha Letter\n+        (0x11435, 0x11446,),  # Newa Vowel Sign Aa      ..Newa Sign Nukta\n+        (0x1145e, 0x1145e,),  # Newa Sandhi Mark\n+        (0x114b0, 0x114c3,),  # Tirhuta Vowel Sign Aa   ..Tirhuta Sign Nukta\n+        (0x115af, 0x115b5,),  # Siddham Vowel Sign Aa   ..Siddham Vowel Sign Vocal\n+        (0x115b8, 0x115c0,),  # Siddham Vowel Sign E    ..Siddham Sign Nukta\n+        (0x115dc, 0x115dd,),  # Siddham Vowel Sign Alter..Siddham Vowel Sign Alter\n+        (0x11630, 0x11640,),  # Modi Vowel Sign Aa      ..Modi Sign Ardhacandra\n+        (0x116ab, 0x116b7,),  # Takri Sign Anusvara     ..Takri Sign Nukta\n+        (0x1171d, 0x1172b,),  # Ahom Consonant Sign Medi..Ahom Sign Killer\n+        (0x1182c, 0x1183a,),  # Dogra Vowel Sign Aa     ..Dogra Sign Nukta\n+        (0x11930, 0x11935,),  # Dives Akuru Vowel Sign A..Dives Akuru Vowel Sign E\n+        (0x11937, 0x11938,),  # Dives Akuru Vowel Sign A..Dives Akuru Vowel Sign O\n+        (0x1193b, 0x1193e,),  # Dives Akuru Sign Anusvar..Dives Akuru Virama\n+        (0x11940, 0x11940,),  # Dives Akuru Medial Ya\n+        (0x11942, 0x11943,),  # Dives Akuru Medial Ra   ..Dives Akuru Sign Nukta\n+        (0x119d1, 0x119d7,),  # Nandinagari Vowel Sign A..Nandinagari Vowel Sign V\n+        (0x119da, 0x119e0,),  # Nandinagari Vowel Sign E..Nandinagari Sign Virama\n+        (0x119e4, 0x119e4,),  # Nandinagari Vowel Sign Prishthamatra E\n+        (0x11a01, 0x11a0a,),  # Zanabazar Square Vowel S..Zanabazar Square Vowel L\n+        (0x11a33, 0x11a39,),  # Zanabazar Square Final C..Zanabazar Square Sign Vi\n+        (0x11a3b, 0x11a3e,),  # Zanabazar Square Cluster..Zanabazar Square Cluster\n+        (0x11a47, 0x11a47,),  # Zanabazar Square Subjoiner\n+        (0x11a51, 0x11a5b,),  # Soyombo Vowel Sign I    ..Soyombo Vowel Length Mar\n+        (0x11a8a, 0x11a99,),  # Soyombo Final Consonant ..Soyombo Subjoiner\n+        (0x11c2f, 0x11c36,),  # Bhaiksuki Vowel Sign Aa ..Bhaiksuki Vowel Sign Voc\n+        (0x11c38, 0x11c3f,),  # Bhaiksuki Vowel Sign E  ..Bhaiksuki Sign Virama\n+        (0x11c92, 0x11ca7,),  # Marchen Subjoined Letter..Marchen Subjoined Letter\n+        (0x11ca9, 0x11cb6,),  # Marchen Subjoined Letter..Marchen Sign Candrabindu\n+        (0x11d31, 0x11d36,),  # Masaram Gondi Vowel Sign..Masaram Gondi Vowel Sign\n+        (0x11d3a, 0x11d3a,),  # Masaram Gondi Vowel Sign E\n+        (0x11d3c, 0x11d3d,),  # Masaram Gondi Vowel Sign..Masaram Gondi Vowel Sign\n+        (0x11d3f, 0x11d45,),  # Masaram Gondi Vowel Sign..Masaram Gondi Virama\n+        (0x11d47, 0x11d47,),  # Masaram Gondi Ra-kara\n+        (0x11d8a, 0x11d8e,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Vowel Sign\n+        (0x11d90, 0x11d91,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Vowel Sign\n+        (0x11d93, 0x11d97,),  # Gunjala Gondi Vowel Sign..Gunjala Gondi Virama\n+        (0x11ef3, 0x11ef6,),  # Makasar Vowel Sign I    ..Makasar Vowel Sign O\n+        (0x11f00, 0x11f01,),  # Kawi Sign Candrabindu   ..Kawi Sign Anusvara\n+        (0x11f03, 0x11f03,),  # Kawi Sign Visarga\n+        (0x11f34, 0x11f3a,),  # Kawi Vowel Sign Aa      ..Kawi Vowel Sign Vocalic\n+        (0x11f3e, 0x11f42,),  # Kawi Vowel Sign E       ..Kawi Conjoiner\n+        (0x13430, 0x13440,),  # Egyptian Hieroglyph Vert..Egyptian Hieroglyph Mirr\n+        (0x13447, 0x13455,),  # Egyptian Hieroglyph Modi..Egyptian Hieroglyph Modi\n+        (0x16af0, 0x16af4,),  # Bassa Vah Combining High..Bassa Vah Combining High\n+        (0x16b30, 0x16b36,),  # Pahawh Hmong Mark Cim Tu..Pahawh Hmong Mark Cim Ta\n+        (0x16f4f, 0x16f4f,),  # Miao Sign Consonant Modifier Bar\n+        (0x16f51, 0x16f87,),  # Miao Sign Aspiration    ..Miao Vowel Sign Ui\n+        (0x16f8f, 0x16f92,),  # Miao Tone Right         ..Miao Tone Below\n+        (0x16fe4, 0x16fe4,),  # Khitan Small Script Filler\n+        (0x16ff0, 0x16ff1,),  # Vietnamese Alternate Rea..Vietnamese Alternate Rea\n+        (0x1bc9d, 0x1bc9e,),  # Duployan Thick Letter Se..Duployan Double Mark\n+        (0x1bca0, 0x1bca3,),  # Shorthand Format Letter ..Shorthand Format Up Step\n+        (0x1cf00, 0x1cf2d,),  # Znamenny Combining Mark ..Znamenny Combining Mark\n+        (0x1cf30, 0x1cf46,),  # Znamenny Combining Tonal..Znamenny Priznak Modifie\n+        (0x1d165, 0x1d169,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d16d, 0x1d182,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d185, 0x1d18b,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d1aa, 0x1d1ad,),  # Musical Symbol Combining..Musical Symbol Combining\n+        (0x1d242, 0x1d244,),  # Combining Greek Musical ..Combining Greek Musical\n+        (0x1da00, 0x1da36,),  # Signwriting Head Rim    ..Signwriting Air Sucking\n+        (0x1da3b, 0x1da6c,),  # Signwriting Mouth Closed..Signwriting Excitement\n+        (0x1da75, 0x1da75,),  # Signwriting Upper Body Tilting From Hip Joints\n+        (0x1da84, 0x1da84,),  # Signwriting Location Head Neck\n+        (0x1da9b, 0x1da9f,),  # Signwriting Fill Modifie..Signwriting Fill Modifie\n+        (0x1daa1, 0x1daaf,),  # Signwriting Rotation Mod..Signwriting Rotation Mod\n+        (0x1e000, 0x1e006,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e008, 0x1e018,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e01b, 0x1e021,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e023, 0x1e024,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e026, 0x1e02a,),  # Combining Glagolitic Let..Combining Glagolitic Let\n+        (0x1e08f, 0x1e08f,),  # Combining Cyrillic Small Letter Byelorussian-ukr\n+        (0x1e130, 0x1e136,),  # Nyiakeng Puachue Hmong T..Nyiakeng Puachue Hmong T\n+        (0x1e2ae, 0x1e2ae,),  # Toto Sign Rising Tone\n+        (0x1e2ec, 0x1e2ef,),  # Wancho Tone Tup         ..Wancho Tone Koini\n+        (0x1e4ec, 0x1e4ef,),  # Nag Mundari Sign Muhor  ..Nag Mundari Sign Sutuh\n+        (0x1e8d0, 0x1e8d6,),  # Mende Kikakui Combining ..Mende Kikakui Combining\n+        (0x1e944, 0x1e94a,),  # Adlam Alif Lengthener   ..Adlam Nukta\n+        (0x1f3fb, 0x1f3ff,),  # Emoji Modifier Fitzpatri..Emoji Modifier Fitzpatri\n+        (0xe0001, 0xe0001,),  # Language Tag\n+        (0xe0020, 0xe007f,),  # Tag Space               ..Cancel Tag\n+        (0xe0100, 0xe01ef,),  # Variation Selector-17   ..Variation Selector-256\n+    ),\n+}\ndiff --git a/wcwidth/unicode_versions.py b/wcwidth/unicode_versions.py\nindex cc437d7..4e9ccbf 100644\n--- a/wcwidth/unicode_versions.py\n+++ b/wcwidth/unicode_versions.py\n@@ -15,4 +15,24 @@ def list_versions():\n     :returns: Supported Unicode version numbers in ascending sorted order.\n     :rtype: list[str]\n     \"\"\"\n-    pass\n+    return (\n+        \"4.1.0\",\n+        \"5.0.0\",\n+        \"5.1.0\",\n+        \"5.2.0\",\n+        \"6.0.0\",\n+        \"6.1.0\",\n+        \"6.2.0\",\n+        \"6.3.0\",\n+        \"7.0.0\",\n+        \"8.0.0\",\n+        \"9.0.0\",\n+        \"10.0.0\",\n+        \"11.0.0\",\n+        \"12.0.0\",\n+        \"12.1.0\",\n+        \"13.0.0\",\n+        \"14.0.0\",\n+        \"15.0.0\",\n+        \"15.1.0\",\n+    )\ndiff --git a/wcwidth/wcwidth.py b/wcwidth/wcwidth.py\nindex 6d93a59..e924020 100644\n--- a/wcwidth/wcwidth.py\n+++ b/wcwidth/wcwidth.py\n@@ -61,17 +61,27 @@ http://www.unicode.org/unicode/reports/tr11/\n Latest version: http://www.cl.cam.ac.uk/~mgk25/ucs/wcwidth.c\n \"\"\"\n from __future__ import division\n+\n+# std imports\n import os\n import sys\n import warnings\n+\n+# local\n from .table_vs16 import VS16_NARROW_TO_WIDE\n from .table_wide import WIDE_EASTASIAN\n from .table_zero import ZERO_WIDTH\n from .unicode_versions import list_versions\n+\n try:\n+    # std imports\n     from functools import lru_cache\n except ImportError:\n+    # lru_cache was added in Python 3.2\n+    # 3rd party\n     from backports.functools_lru_cache import lru_cache\n+\n+# global cache\n _PY3 = sys.version_info[0] &gt;= 3\n\n\n@@ -85,12 +95,26 @@ def _bisearch(ucs, table):\n     :rtype: int\n     :returns: 1 if ordinal value ucs is found within lookup table, else 0.\n     \"\"\"\n-    pass\n+    lbound = 0\n+    ubound = len(table) - 1\n+\n+    if ucs &lt; table[0][0] or ucs &gt; table[ubound][1]:\n+        return 0\n+    while ubound &gt;= lbound:\n+        mid = (lbound + ubound) // 2\n+        if ucs &gt; table[mid][1]:\n+            lbound = mid + 1\n+        elif ucs &lt; table[mid][0]:\n+            ubound = mid - 1\n+        else:\n+            return 1\n+\n+    return 0\n\n\n @lru_cache(maxsize=1000)\n def wcwidth(wc, unicode_version='auto'):\n-    \"\"\"\n+    r\"\"\"\n     Given one Unicode character, return its printable length on a terminal.\n\n     :param str wc: A single Unicode character.\n@@ -103,7 +127,7 @@ def wcwidth(wc, unicode_version='auto'):\n         highest Unicode version level is used.\n     :return: The width, in cells, necessary to display the character of\n         Unicode string character, ``wc``.  Returns 0 if the ``wc`` argument has\n-        no printable effect on a terminal (such as NUL '\\\\0'), -1 if ``wc`` is\n+        no printable effect on a terminal (such as NUL '\\0'), -1 if ``wc`` is\n         not printable, or has an indeterminate effect on the terminal, such as\n         a control character.  Otherwise, the number of column positions the\n         character occupies on a graphic terminal (1 or 2) is returned.\n@@ -111,7 +135,26 @@ def wcwidth(wc, unicode_version='auto'):\n\n     See :ref:`Specification` for details of cell measurement.\n     \"\"\"\n-    pass\n+    ucs = ord(wc) if wc else 0\n+\n+    # small optimization: early return of 1 for printable ASCII, this provides\n+    # approximately 40% performance improvement for mostly-ascii documents, with\n+    # less than 1% impact to others.\n+    if 32 &lt;= ucs &lt; 0x7f:\n+        return 1\n+\n+    # C0/C1 control characters are -1 for compatibility with POSIX-like calls\n+    if ucs and ucs &lt; 32 or 0x07F &lt;= ucs &lt; 0x0A0:\n+        return -1\n+\n+    _unicode_version = _wcmatch_version(unicode_version)\n+\n+    # Zero width\n+    if _bisearch(ucs, ZERO_WIDTH[_unicode_version]):\n+        return 0\n+\n+    # 1 or 2 width\n+    return 1 + _bisearch(ucs, WIDE_EASTASIAN[_unicode_version])\n\n\n def wcswidth(pwcs, n=None, unicode_version='auto'):\n@@ -135,7 +178,41 @@ def wcswidth(pwcs, n=None, unicode_version='auto'):\n\n     See :ref:`Specification` for details of cell measurement.\n     \"\"\"\n-    pass\n+    # this 'n' argument is a holdover for POSIX function\n+    _unicode_version = None\n+    end = len(pwcs) if n is None else n\n+    width = 0\n+    idx = 0\n+    last_measured_char = None\n+    while idx &lt; end:\n+        char = pwcs[idx]\n+        if char == u'\\u200D':\n+            # Zero Width Joiner, do not measure this or next character\n+            idx += 2\n+            continue\n+        if char == u'\\uFE0F' and last_measured_char:\n+            # on variation selector 16 (VS16) following another character,\n+            # conditionally add '1' to the measured width if that character is\n+            # known to be converted from narrow to wide by the VS16 character.\n+            if _unicode_version is None:\n+                _unicode_version = _wcversion_value(_wcmatch_version(unicode_version))\n+            if _unicode_version &gt;= (9, 0, 0):\n+                width += _bisearch(ord(last_measured_char), VS16_NARROW_TO_WIDE[\"9.0.0\"])\n+                last_measured_char = None\n+            idx += 1\n+            continue\n+        # measure character at current index\n+        wcw = wcwidth(char, unicode_version)\n+        if wcw &lt; 0:\n+            # early return -1 on C0 and C1 control characters\n+            return wcw\n+        if wcw &gt; 0:\n+            # track last character measured to contain a cell, so that\n+            # subsequent VS-16 modifiers may be understood\n+            last_measured_char = char\n+        width += wcw\n+        idx += 1\n+    return width\n\n\n @lru_cache(maxsize=128)\n@@ -147,7 +224,8 @@ def _wcversion_value(ver_string):\n     :rtype: tuple(int)\n     :returns: tuple of digit tuples, ``tuple(int, [...])``.\n     \"\"\"\n-    pass\n+    retval = tuple(map(int, (ver_string.split('.'))))\n+    return retval\n\n\n @lru_cache(maxsize=8)\n@@ -175,4 +253,93 @@ def _wcmatch_version(given_version):\n     :returns: unicode string, or non-unicode ``str`` type for python 2\n         when given ``version`` is also type ``str``.\n     \"\"\"\n-    pass\n+    # Design note: the choice to return the same type that is given certainly\n+    # complicates it for python 2 str-type, but allows us to define an api that\n+    # uses 'string-type' for unicode version level definitions, so all of our\n+    # example code works with all versions of python.\n+    #\n+    # That, along with the string-to-numeric and comparisons of earliest,\n+    # latest, matching, or nearest, greatly complicates this function.\n+    # Performance is somewhat curbed by memoization.\n+    _return_str = not _PY3 and isinstance(given_version, str)\n+\n+    if _return_str:\n+        # avoid list-comprehension to work around a coverage issue:\n+        # https://github.com/nedbat/coveragepy/issues/753\n+        unicode_versions = list(map(lambda ucs: ucs.encode(), list_versions()))\n+    else:\n+        unicode_versions = list_versions()\n+    latest_version = unicode_versions[-1]\n+\n+    if given_version in (u'auto', 'auto'):\n+        given_version = os.environ.get(\n+            'UNICODE_VERSION',\n+            'latest' if not _return_str else latest_version.encode())\n+\n+    if given_version in (u'latest', 'latest'):\n+        # default match, when given as 'latest', use the most latest unicode\n+        # version specification level supported.\n+        return latest_version if not _return_str else latest_version.encode()\n+\n+    if given_version in unicode_versions:\n+        # exact match, downstream has specified an explicit matching version\n+        # matching any value of list_versions().\n+        return given_version if not _return_str else given_version.encode()\n+\n+    # The user's version is not supported by ours. We return the newest unicode\n+    # version level that we support below their given value.\n+    try:\n+        cmp_given = _wcversion_value(given_version)\n+\n+    except ValueError:\n+        # submitted value raises ValueError in int(), warn and use latest.\n+        warnings.warn(\"UNICODE_VERSION value, {given_version!r}, is invalid. \"\n+                      \"Value should be in form of `integer[.]+', the latest \"\n+                      \"supported unicode version {latest_version!r} has been \"\n+                      \"inferred.\".format(given_version=given_version,\n+                                         latest_version=latest_version))\n+        return latest_version if not _return_str else latest_version.encode()\n+\n+    # given version is less than any available version, return earliest\n+    # version.\n+    earliest_version = unicode_versions[0]\n+    cmp_earliest_version = _wcversion_value(earliest_version)\n+\n+    if cmp_given &lt;= cmp_earliest_version:\n+        # this probably isn't what you wanted, the oldest wcwidth.c you will\n+        # find in the wild is likely version 5 or 6, which we both support,\n+        # but it's better than not saying anything at all.\n+        warnings.warn(\"UNICODE_VERSION value, {given_version!r}, is lower \"\n+                      \"than any available unicode version. Returning lowest \"\n+                      \"version level, {earliest_version!r}\".format(\n+                          given_version=given_version,\n+                          earliest_version=earliest_version))\n+        return earliest_version if not _return_str else earliest_version.encode()\n+\n+    # create list of versions which are less than our equal to given version,\n+    # and return the tail value, which is the highest level we may support,\n+    # or the latest value we support, when completely unmatched or higher\n+    # than any supported version.\n+    #\n+    # function will never complete, always returns.\n+    for idx, unicode_version in enumerate(unicode_versions):\n+        # look ahead to next value\n+        try:\n+            cmp_next_version = _wcversion_value(unicode_versions[idx + 1])\n+        except IndexError:\n+            # at end of list, return latest version\n+            return latest_version if not _return_str else latest_version.encode()\n+\n+        # Maybe our given version has less parts, as in tuple(8, 0), than the\n+        # next compare version tuple(8, 0, 0). Test for an exact match by\n+        # comparison of only the leading dotted piece(s): (8, 0) == (8, 0).\n+        if cmp_given == cmp_next_version[:len(cmp_given)]:\n+            return unicode_versions[idx + 1]\n+\n+        # Or, if any next value is greater than our given support level\n+        # version, return the current value in index.  Even though it must\n+        # be less than the given value, its our closest possible match. That\n+        # is, 4.1 is returned for given 4.9.9, where 4.1 and 5.0 are available.\n+        if cmp_next_version &gt; cmp_given:\n+            return unicode_version\n+    assert False, (\"Code path unreachable\", given_version, unicode_versions)  # pragma: no cover\n</code></pre>"},{"location":"api/","title":"API","text":""},{"location":"api/#commit0","title":"Commit0","text":"<p>Commit0 provides several commands to facilitate the process of cloning, building, testing, and evaluating repositories. Here's an overview of the available commands:</p>"},{"location":"api/#setup","title":"Setup","text":"<p>Use <code>commit0 setup [OPTIONS] REPO_SPLIT</code> to clone a repository split. Available options include:</p> Argument Type Description Default <code>repo_split</code> str Split of repositories to clone <code>--dataset-name</code> str Name of the Huggingface dataset <code>wentingzhao/commit0_combined</code> <code>--dataset-split</code> str Split of the Huggingface dataset <code>test</code> <code>--base-dir</code> str Base directory to clone repos to <code>repos/</code> <code>--commit0-dot-file-path</code> str Storing path for stateful commit0 configs <code>.commit0.yaml</code>"},{"location":"api/#build","title":"Build","text":"<p>Use <code>commit0 build [OPTIONS]</code> to build the Commit0 split chosen in the Setup stage. Available options include:</p> Argument Type Description Default <code>--num-workers</code> int Number of workers <code>8</code> <code>--commit0-dot-file-path</code> str Path to the commit0 dot file <code>.commit0.yaml</code> <code>--verbose</code> int Verbosity level (1 or 2) <code>1</code>"},{"location":"api/#get-tests","title":"Get Tests","text":"<p>Use <code>commit0 get-tests REPO_NAME</code> to get tests for a Commit0 repository.</p> Argument Type Description Default <code>repo_name</code> str Name of the repository to get tests for"},{"location":"api/#test","title":"Test","text":"<p>Use <code>commit0 test [OPTIONS] REPO_OR_REPO_PATH [TEST_IDS]</code> to run tests on a Commit0 repository. Available options include:</p> Argument Type Description Default <code>repo_or_repo_path</code> str Directory of the repository to test <code>test_ids</code> str Test IDs to run <code>--branch</code> str Branch to test <code>--backend</code> str Backend to use for testing <code>modal</code> <code>--timeout</code> int Timeout for tests in seconds <code>1800</code> <code>--num-cpus</code> int Number of CPUs to use <code>1</code> <code>--reference</code> bool Test the reference commit <code>False</code> <code>--coverage</code> bool Get coverage information <code>False</code> <code>--rebuild</code> bool Rebuild an image <code>False</code> <code>--commit0-dot-file-path</code> str Path to the commit0 dot file <code>.commit0.yaml</code> <code>--verbose</code> int Verbosity level (1 or 2) <code>1</code> <code>--stdin</code> bool Read test names from stdin <code>False</code>"},{"location":"api/#evaluate","title":"Evaluate","text":"<p>Use <code>commit0 evaluate [OPTIONS]</code> to evaluate the Commit0 split chosen in the Setup stage. Available options include:</p> Argument Type Description Default <code>--branch</code> str Branch to evaluate <code>--backend</code> str Backend to use for evaluation <code>modal</code> <code>--timeout</code> int Timeout for evaluation in seconds <code>1800</code> <code>--num-cpus</code> int Number of CPUs to use <code>1</code> <code>--num-workers</code> int Number of workers to use <code>8</code> <code>--reference</code> bool Evaluate the reference commit <code>False</code> <code>--coverage</code> bool Get coverage information <code>False</code> <code>--commit0-dot-file-path</code> str Path to the commit0 dot file <code>.commit0.yaml</code> <code>--rebuild</code> bool Rebuild images <code>False</code>"},{"location":"api/#lint","title":"Lint","text":"<p>Use <code>commit0 lint [OPTIONS] REPO_OR_REPO_DIR</code> to lint files in a repository. Available options include:</p> Argument Type Description Default <code>repo_or_repo_dir</code> str Directory of the repository to test <code>--files</code> List[Path] Files to lint (optional) <code>--commit0-dot-file-path</code> str Path to the commit0 dot file <code>.commit0.yaml</code> <code>--verbose</code> int Verbosity level (1 or 2) <code>1</code>"},{"location":"api/#save","title":"Save","text":"<p>Use <code>commit0 save [OPTIONS] OWNER BRANCH</code> to save the Commit0 split to GitHub. Available options include:</p> Argument Type Description Default <code>owner</code> str Owner of the repository <code>branch</code> str Branch to save <code>--github-token</code> str GitHub token for authentication <code>--commit0-dot-file-path</code> str Path to the commit0 dot file <code>.commit0.yaml</code>"},{"location":"api/#agent","title":"Agent","text":""},{"location":"api/#config","title":"Config","text":"<p>Use <code>agent config [OPTIONS] AGENT_NAME</code> to set up the configuration for an agent. Available options include:</p> Argument Type Description Default <code>agent_name</code> str Agent to use, we only support aider for now. <code>aider</code> <code>--model-name</code> str LLM model to use, check here for all supported models. <code>claude-3-5-sonnet-20240620</code> <code>--use-user-prompt</code> bool Use a custom prompt instead of the default prompt. <code>False</code> <code>--user-prompt</code> str The prompt sent to agent. See code for details. <code>--run-tests</code> bool Run tests after code modifications for feedback. You need to set up <code>docker</code> or <code>modal</code> before running tests, refer to commit0 docs. <code>False</code> <code>--max-iteration</code> int Maximum number of agent iterations. <code>3</code> <code>--use-repo-info</code> bool Include the repository information. <code>False</code> <code>--max-repo-info-length</code> int Maximum length of the repository information to use. <code>10000</code> <code>--use-unit-tests-info</code> bool Include the unit tests information. <code>False</code> <code>--max-unit-tests-info-length</code> int Maximum length of the unit tests information to use. <code>10000</code> <code>--use-spec-info</code> bool Include the spec information. <code>False</code> <code>--max-spec-info-length</code> int Maximum length of the spec information to use. <code>10000</code> <code>--use-lint-info</code> bool Include the lint information. <code>False</code> <code>--max-lint-info-length</code> int Maximum length of the lint information to use. <code>10000</code> <code>--pre-commit-config-path</code> str Path to the pre-commit config file. This is needed for running <code>lint</code>. <code>.pre-commit-config.yaml</code> <code>--agent-config-file</code> str Path to write the agent config. <code>.agent.yaml</code>"},{"location":"api/#running","title":"Running","text":"<p>Use <code>agent run [OPTIONS] BRANCH</code> to execute an agent on a specific branch. Available options include:</p> Argument Type Description Default <code>branch</code> str Branch to run the agent on, you can specific the name of the branch <code>--backend</code> str Test backend to run the agent on, ignore this option if you are not adding <code>run_tests</code> option to agent. <code>modal</code> <code>--log-dir</code> str Log directory to store the logs. <code>logs/aider</code> <code>--max-parallel-repos</code> int Maximum number of repositories for agent to run in parallel. Running in sequential if set to 1. <code>1</code> <code>--display-repo-progress-num</code> int Number of repo progress displayed when running. <code>5</code>"},{"location":"baseline/","title":"Baseline","text":"<p>Commit0 contains a baseline system based on the Aider code generation system.</p> <p>...</p>"},{"location":"distributed/","title":"Distributed","text":"<p>One of the main advantages of <code>commit0</code> is that it can run a range of unit tests in distributed environments.</p> <p>By default, the library is configured to work with modal.</p> <pre><code>pip install modal\nmodal token new\n</code></pre>"},{"location":"distributed/#modal-setup","title":"Modal Setup","text":"<p>To enable distributed run, first create a file called <code>distributed.yaml</code></p> <pre><code>backend: modal\nbase_dir: repos.dist/\n</code></pre> <p>You can pass this configuration file as an argumnet to clone.</p> <pre><code>commit0 clone lite --cfg=distributed\n</code></pre> <p>Next to run tests you can run the standard test command.</p> <pre><code>commit0 test simpy master tests/test_event.py::test_succeed --cfg=distributed\n</code></pre>"},{"location":"repos/","title":"Repos","text":"<p>Directions for how to add new repositories.</p>"},{"location":"setupdist/","title":"Commit0","text":""},{"location":"setupdist/#distributed-mode","title":"Distributed Mode","text":"<p>Commit0 is a command-line tool that allows you to run unit-tests on a variety of libraries in isolated environments.</p> <p>The defaul tool uses modal as a distributed test runner.</p> <pre><code>pip install modal\nmodal token new\n</code></pre> <p>To get started, run the <code>setup</code> command with the dataset split that youare interested in working with. We'll start with the <code>lite</code> split.</p> <pre><code>commit0 setup lite\n</code></pre> <p>This will clone a set of skeleton libraries in your <code>repos/</code> directory. Commiting changes to branches in this directory is how you send changes to the test runner.</p> <p>Next to run tests you can run the standard test command. This command will run a reference unit test for the <code>simpy</code> repo.</p> <pre><code>commit0 test simpy tests/test_event.py::test_succeed --reference\n</code></pre> <p>To run a test in your codebase you can run with no args. This one will fail.</p> <pre><code>commit0 test simpy tests/test_event.py::test_succeed\n</code></pre> <p>To run a test in your codebase with a specific branch you can commit to the branch and call with the --branch command.</p> <pre><code>commit0 test simpy tests/test_event.py::test_succeed --branch my_branch\n</code></pre>"},{"location":"setupdist/#local-mode","title":"Local Mode","text":"<p>To run in local mode you first be sure that you have docker tools installed. On Debian systems:</p> <pre><code>apt install docker\n</code></pre> <p>To get started, run the <code>setup</code> command with the dataset split that you are interested in working with. We'll start with the <code>lite</code> split.</p> <pre><code>commit0 setup lite\n</code></pre> <p>This will install a clone the code for subset of libraries to your <code>repos/</code> directory.</p> <p>Next run the <code>build</code> command which will configure Docker containers for each of the libraries with isolated virtual environments. The command uses the uv library for efficient builds.</p> <pre><code>commit0 build\n</code></pre> <p>The main operation you can do with these enviroments is to run tests. Here we run a test in the <code>simpy</code> library.</p> <pre><code>commit0 test simpy tests/test_event.py::test_succeed\n</code></pre> <p>See distributed setup for more commands.</p>"},{"location":"setuplocal/","title":"Setuplocal","text":""},{"location":"setuplocal/#local-mode","title":"Local Mode","text":"<p>To run in local mode you first be sure that you have docker tools installed. On Debian systems:</p> <pre><code>apt install docker\n</code></pre> <p>To get started, run the <code>setup</code> command with the dataset split that you are interested in working with. We'll start with the <code>lite</code> split.</p> <pre><code>commit0 setup lite\n</code></pre> <p>This will install a clone the code for subset of libraries to your <code>repos/</code> directory.</p> <p>Next run the <code>build</code> command which will configure Docker containers for each of the libraries with isolated virtual environments. The command uses the uv library for efficient builds.</p> <pre><code>commit0 build\n</code></pre> <p>The main operation you can do with these enviroments is to run tests. Here we run a test in the <code>simpy</code> library.</p> <pre><code>commit0 test simpy tests/test_event.py::test_succeed\n</code></pre> <p>See distributed setup for more commands.</p>"},{"location":"table/","title":"Table","text":"Name Repo Commit0 Tests minitorch [orig] [commit0] 230 simpy [orig] [commit0] 140 bitstring [orig] [commit0] 834 tinydb [orig] [commit0] 201 marshmallow [orig] [commit0] 1229 python-prompt-toolkit [orig] [commit0] 151 parsel [orig] [commit0] 343 pyjwt pyjwt [orig] [commit0] 259 networkx [orig] [commit0] 5440 graphene [orig] [commit0] 447 tlslite-ng tlslite-ng [orig] [commit0] 1653 wcwidth wcwidth [orig] [commit0] 38 chardet chardet [orig] [commit0] 376 dnspython dnspython [orig] [commit0] 1304 imapclient imapclient [orig] [commit0] 267 virtualenv [orig] [commit0] 284 pexpect pexpect [orig] [commit0] 255 web3.py [orig] [commit0] 40433 babel [orig] [commit0] 5663 geopandas [orig] [commit0] 2196 dulwich dulwich [orig] [commit0] 1522 flask [orig] [commit0] 477 voluptuous voluptuous [orig] [commit0] 149 jinja [orig] [commit0] 851 seaborn [orig] [commit0] 2362 requests requests [orig] [commit0] 590 scrapy [orig] [commit0] 2904 fastapi [orig] [commit0] 2013 click [orig] [commit0] 589 python-rsa [orig] [commit0] 86 statsmodels [orig] [commit0] 17669 more-itertools more-itertools [orig] [commit0] 662 moviepy [orig] [commit0] 109 deprecated deprecated [orig] [commit0] 171 pydantic [orig] [commit0] 5091 loguru [orig] [commit0] 1461 pypdf [orig] [commit0] 911 attrs [orig] [commit0] 1414 mimesis [orig] [commit0] 6159 cookiecutter [orig] [commit0] 367 tornado [orig] [commit0] 1150 imbalanced-learn [orig] [commit0] 2310 python-progressbar [orig] [commit0] 385 pylint [orig] [commit0] 1878 sphinx [orig] [commit0] 2187 joblib [orig] [commit0] 1450 xarray [orig] [commit0] 15643 cachetools cachetools [orig] [commit0] 215 paramiko paramiko [orig] [commit0] 557 fabric [orig] [commit0] 353 filesystem_spec [orig] [commit0] 698 jedi jedi [orig] [commit0] 3854 sqlparse sqlparse [orig] [commit0] 461 portalocker [orig] [commit0] 38"}]}