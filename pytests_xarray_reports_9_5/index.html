
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.34">
    
    
      
        <title>Select repository - spec2repo</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.35f28582.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#select-repository" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="spec2repo" class="md-header__button md-logo" aria-label="spec2repo" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            spec2repo
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Select repository
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="spec2repo" class="md-nav__button md-logo" aria-label="spec2repo" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    spec2repo
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../setup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Setup
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../repos/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Extending
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Leaderboard
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytests/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Submission Pytests
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Submission Analysis
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pytest-summary" class="md-nav__link">
    <span class="md-ellipsis">
      Pytest Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#failed-pytest-tests" class="md-nav__link">
    <span class="md-ellipsis">
      Failed Pytest Tests
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="select-repository">Select repository</h1>
<p><a class="md-button" href="/pytests_sphinx_reports_9_5">sphinx_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_parsel_reports_9_5">parsel_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_tinydb_reports_9_5">tinydb_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_more-itertools_reports_9_5">more-itertools_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_marshmallow_reports_9_5">marshmallow_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_sqlparse_reports_9_5">sqlparse_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_cachetools_reports_9_5">cachetools_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_mimesis_reports_9_5">mimesis_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_moviepy_reports_9_5">moviepy_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_scrapy_reports_9_5">scrapy_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_filesystem_spec_reports_9_5">filesystem_spec_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_python-progressbar_reports_9_5">python-progressbar_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_pytest_reports_9_5">pytest_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_web3.py_reports_9_5">web3.py_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_xarray_reports_9_5">xarray_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_deprecated_reports_9_5">deprecated_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_graphene_reports_9_5">graphene_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_flask_reports_9_5">flask_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_wcwidth_reports_9_5">wcwidth_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_dulwich_reports_9_5">dulwich_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_chardet_reports_9_5">chardet_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_seaborn_reports_9_5">seaborn_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_loguru_reports_9_5">loguru_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_statsmodels_reports_9_5">statsmodels_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_jinja_reports_9_5">jinja_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_virtualenv_reports_9_5">virtualenv_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_pylint_reports_9_5">pylint_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_python-rsa_reports_9_5">python-rsa_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_cookiecutter_reports_9_5">cookiecutter_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_tornado_reports_9_5">tornado_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_fastapi_reports_9_5">fastapi_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_dnspython_reports_9_5">dnspython_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_fabric_reports_9_5">fabric_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_geopandas_reports_9_5">geopandas_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_bitstring_reports_9_5">bitstring_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_requests_reports_9_5">requests_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_imapclient_reports_9_5">imapclient_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_minitorch_reports_9_5">minitorch_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_pydantic_reports_9_5">pydantic_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_jedi_reports_9_5">jedi_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_simpy_reports_9_5">simpy_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_tlslite-ng_reports_9_5">tlslite-ng_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_attrs_reports_9_5">attrs_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_click_reports_9_5">click_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_paramiko_reports_9_5">paramiko_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_voluptuous_reports_9_5">voluptuous_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_networkx_reports_9_5">networkx_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_PyBoy_reports_9_5">PyBoy_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_joblib_reports_9_5">joblib_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_pexpect_reports_9_5">pexpect_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_babel_reports_9_5">babel_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_portalocker_reports_9_5">portalocker_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_pypdf_reports_9_5">pypdf_reports_9_5</a></p>
<p><a class="md-button" href="/pytests_python-prompt-toolkit_reports_9_5">python-prompt-toolkit_reports_9_5</a></p>
<h2 id="pytest-summary">Pytest Summary</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">category</th>
<th style="text-align: center;">count</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">failed</td>
<td style="text-align: center;">300</td>
</tr>
<tr>
<td style="text-align: left;">passed</td>
<td style="text-align: center;">15633</td>
</tr>
<tr>
<td style="text-align: left;">xfailed</td>
<td style="text-align: center;">67</td>
</tr>
<tr>
<td style="text-align: left;">skipped</td>
<td style="text-align: center;">1098</td>
</tr>
<tr>
<td style="text-align: left;">xpassed</td>
<td style="text-align: center;">10</td>
</tr>
<tr>
<td style="text-align: left;">total</td>
<td style="text-align: center;">17108</td>
</tr>
<tr>
<td style="text-align: left;">collected</td>
<td style="text-align: center;">17108</td>
</tr>
<tr>
<td style="text-align: left;">duration</td>
<td style="text-align: center;">346.51s</td>
</tr>
</tbody>
</table>
<h2 id="failed-pytest-tests">Failed Pytest Tests</h2>
<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_explicitly_omit_fill_value_via_encoding_kwarg</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a1bd60>

    def test_explicitly_omit_fill_value_via_encoding_kwarg(self) -> None:
        ds = Dataset({"x": ("y", [np.pi, -np.pi])})
        kwargs = dict(encoding={"x": {"_FillValue": None}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_explicitly_omit_fill_value_in_coord</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a1afe0>

    def test_explicitly_omit_fill_value_in_coord(self) -> None:
        ds = Dataset({"x": ("y", [np.pi, -np.pi])}, coords={"y": [0.0, 1.0]})
        ds.y.encoding["_FillValue"] = None
>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1229: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_explicitly_omit_fill_value_in_coord_via_encoding_kwarg</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a1a0e0>

    def test_explicitly_omit_fill_value_in_coord_via_encoding_kwarg(self) -> None:
        ds = Dataset({"x": ("y", [np.pi, -np.pi])}, coords={"y": [0.0, 1.0]})
        kwargs = dict(encoding={"y": {"_FillValue": None}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1235: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_encoding_same_dtype</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a1bee0>

    def test_encoding_same_dtype(self) -> None:
        ds = Dataset({"x": ("y", np.arange(10.0, dtype="f4"))})
        kwargs = dict(encoding={"x": {"dtype": "f4"}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1242: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_append_write</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b7410190>

    def test_append_write(self) -> None:
        # regression for GH1215
        data = create_test_data()
>       with self.roundtrip_append(data) as actual:

/testbed/xarray/tests/test_backends.py:1251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:330: in roundtrip_append
    self.save(data[[key]], path, mode=mode, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_append_overwrite_values</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b7410400>

    def test_append_overwrite_values(self) -> None:
        # regression for GH1215
        data = create_test_data()
        with create_tmp_file(allow_cleanup_failure=False) as tmp_file:
>           self.save(data, tmp_file, mode="w")

/testbed/xarray/tests/test_backends.py:1258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_append_with_invalid_dim_raises</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b7410670>

    def test_append_with_invalid_dim_raises(self) -> None:
        data = create_test_data()
        with create_tmp_file(allow_cleanup_failure=False) as tmp_file:
>           self.save(data, tmp_file, mode="w")

/testbed/xarray/tests/test_backends.py:1268: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_multiindex_not_implemented</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b74108e0>

    def test_multiindex_not_implemented(self) -> None:
        ds = Dataset(coords={"y": ("x", [1, 2]), "z": ("x", ["a", "b"])}).set_index(
            x=["y", "z"]
        )
        with pytest.raises(NotImplementedError, match=r"MultiIndex"):
            with self.roundtrip(ds):
                pass

        # regression GH8628 (can serialize reset multi-index level coordinates)
        ds_reset = ds.reset_index("x")
>       with self.roundtrip(ds_reset) as actual:

/testbed/xarray/tests/test_backends.py:1286: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_refresh_from_disk</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a19630>

    @pytest.mark.skipif(
        ON_WINDOWS, reason="Windows does not allow modifying open files"
    )
    def test_refresh_from_disk(self) -> None:
        # regression test for https://github.com/pydata/xarray/issues/4862

        with create_tmp_file() as example_1_path:
            with create_tmp_file() as example_1_modified_path:
                with open_example_dataset("example_1.nc") as example_1:
>                   self.save(example_1, example_1_path)

/testbed/xarray/tests/test_backends.py:1302: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:257: in set_dimension
    self.ds.dimensions[name] = None
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_open_group</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a21b70>

    def test_open_group(self) -> None:
        # Create a netCDF file with a dataset stored within a group
        with create_tmp_file() as tmp_file:
            with nc4.Dataset(tmp_file, "w") as rootgrp:
                foogrp = rootgrp.createGroup("foo")
                ds = foogrp
                ds.createDimension("time", size=10)
                x = np.arange(10)
                ds.createVariable("x", np.int32, dimensions=("time",))
                ds.variables["x"][:] = x

            expected = Dataset()
            expected["x"] = ("time", x)

            # check equivalent ways to specify group
            for group in "foo", "/foo", "foo/", "/foo/":
>               with self.open(tmp_file, group=group) as actual:

/testbed/xarray/tests/test_backends.py:1374: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:342: in open
    with open_dataset(path, engine=self.engine, **kwargs) as ds:
/testbed/xarray/backends/api.py:588: in open_dataset
    backend_ds = backend.open_dataset(
/testbed/xarray/backends/h5netcdf_.py:418: in open_dataset
    ds = store_entrypoint.open_dataset(
/testbed/xarray/backends/store.py:43: in open_dataset
    vars, attrs = filename_or_obj.load()
/testbed/xarray/backends/common.py:221: in load
    (_decode_variable_name(k), v) for k, v in self.get_variables().items()
/testbed/xarray/backends/h5netcdf_.py:237: in get_variables
    return FrozenDict(
/testbed/xarray/core/utils.py:436: in FrozenDict
    return Frozen(dict(*args, **kwargs))
/testbed/xarray/backends/h5netcdf_.py:238: in <genexpr>
    (k, self.open_store_variable(k, v)) for k, v in self.ds.variables.items()
/testbed/xarray/backends/h5netcdf_.py:200: in open_store_variable
    dimensions = var.dimensions
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:260: in dimensions
    self._dimensions = self._lookup_dimensions()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:154: in _lookup_dimensions
    if _unlabeled_dimension_mix(self._h5ds) == "labeled":
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in _unlabeled_dimension_mix
    dimset = set([len(j) for j in dimlist])
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in <listcomp>
    dimset = set([len(j) for j in dimlist])
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
/testbed/.venv/lib/python3.10/site-packages/h5py/_hl/dims.py:60: in __len__
    return h5ds.get_num_scales(self._id, self._dimension)
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:72: in h5py.h5ds.get_num_scales
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSget_num_scales (return value <0)

h5py/defs.pyx:4461: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_open_subgroup</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a21de0>

    def test_open_subgroup(self) -> None:
        # Create a netCDF file with a dataset stored within a group within a
        # group
        with create_tmp_file() as tmp_file:
            rootgrp = nc4.Dataset(tmp_file, "w")
            foogrp = rootgrp.createGroup("foo")
            bargrp = foogrp.createGroup("bar")
            ds = bargrp
            ds.createDimension("time", size=10)
            x = np.arange(10)
            ds.createVariable("x", np.int32, dimensions=("time",))
            ds.variables["x"][:] = x
            rootgrp.close()

            expected = Dataset()
            expected["x"] = ("time", x)

            # check equivalent ways to specify group
            for group in "foo/bar", "/foo/bar", "foo/bar/", "/foo/bar/":
>               with self.open(tmp_file, group=group) as actual:

/testbed/xarray/tests/test_backends.py:1402: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:342: in open
    with open_dataset(path, engine=self.engine, **kwargs) as ds:
/testbed/xarray/backends/api.py:588: in open_dataset
    backend_ds = backend.open_dataset(
/testbed/xarray/backends/h5netcdf_.py:418: in open_dataset
    ds = store_entrypoint.open_dataset(
/testbed/xarray/backends/store.py:43: in open_dataset
    vars, attrs = filename_or_obj.load()
/testbed/xarray/backends/common.py:221: in load
    (_decode_variable_name(k), v) for k, v in self.get_variables().items()
/testbed/xarray/backends/h5netcdf_.py:237: in get_variables
    return FrozenDict(
/testbed/xarray/core/utils.py:436: in FrozenDict
    return Frozen(dict(*args, **kwargs))
/testbed/xarray/backends/h5netcdf_.py:238: in <genexpr>
    (k, self.open_store_variable(k, v)) for k, v in self.ds.variables.items()
/testbed/xarray/backends/h5netcdf_.py:200: in open_store_variable
    dimensions = var.dimensions
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:260: in dimensions
    self._dimensions = self._lookup_dimensions()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:154: in _lookup_dimensions
    if _unlabeled_dimension_mix(self._h5ds) == "labeled":
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in _unlabeled_dimension_mix
    dimset = set([len(j) for j in dimlist])
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in <listcomp>
    dimset = set([len(j) for j in dimlist])
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
/testbed/.venv/lib/python3.10/site-packages/h5py/_hl/dims.py:60: in __len__
    return h5ds.get_num_scales(self._id, self._dimension)
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:72: in h5py.h5ds.get_num_scales
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSget_num_scales (return value <0)

h5py/defs.pyx:4461: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_write_groups</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a22050>

    def test_write_groups(self) -> None:
        data1 = create_test_data()
        data2 = data1 * 2
        with create_tmp_file() as tmp_file:
>           self.save(data1, tmp_file, group="data/1")

/testbed/xarray/tests/test_backends.py:1409: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_encoding_kwarg_vlen_string[input_strings0-True]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a22320>
input_strings = [b'foo', b'bar', b'baz'], is_bytes = True

    @pytest.mark.parametrize(
        "input_strings, is_bytes",
        [
            ([b"foo", b"bar", b"baz"], True),
            (["foo", "bar", "baz"], False),
            (["foó", "bár", "baź"], False),
        ],
    )
    def test_encoding_kwarg_vlen_string(
        self, input_strings: list[str], is_bytes: bool
    ) -> None:
        original = Dataset({"x": input_strings})

        expected_string = ["foo", "bar", "baz"] if is_bytes else input_strings
        expected = Dataset({"x": expected_string})
        kwargs = dict(encoding={"x": {"dtype": str}})
>       with self.roundtrip(original, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1432: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_encoding_kwarg_vlen_string[input_strings1-False]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a22440>
input_strings = ['foo', 'bar', 'baz'], is_bytes = False

    @pytest.mark.parametrize(
        "input_strings, is_bytes",
        [
            ([b"foo", b"bar", b"baz"], True),
            (["foo", "bar", "baz"], False),
            (["foó", "bár", "baź"], False),
        ],
    )
    def test_encoding_kwarg_vlen_string(
        self, input_strings: list[str], is_bytes: bool
    ) -> None:
        original = Dataset({"x": input_strings})

        expected_string = ["foo", "bar", "baz"] if is_bytes else input_strings
        expected = Dataset({"x": expected_string})
        kwargs = dict(encoding={"x": {"dtype": str}})
>       with self.roundtrip(original, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1432: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_encoding_kwarg_vlen_string[input_strings2-False]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a22620>
input_strings = ['foó', 'bár', 'baź'], is_bytes = False

    @pytest.mark.parametrize(
        "input_strings, is_bytes",
        [
            ([b"foo", b"bar", b"baz"], True),
            (["foo", "bar", "baz"], False),
            (["foó", "bár", "baź"], False),
        ],
    )
    def test_encoding_kwarg_vlen_string(
        self, input_strings: list[str], is_bytes: bool
    ) -> None:
        original = Dataset({"x": input_strings})

        expected_string = ["foo", "bar", "baz"] if is_bytes else input_strings
        expected = Dataset({"x": expected_string})
        kwargs = dict(encoding={"x": {"dtype": str}})
>       with self.roundtrip(original, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1432: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_string_with_fill_value_vlen[XXX]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a228c0>
fill_value = 'XXX'

    @pytest.mark.parametrize("fill_value", ["XXX", "", "bár"])
    def test_roundtrip_string_with_fill_value_vlen(self, fill_value: str) -> None:
        values = np.array(["ab", "cdef", np.nan], dtype=object)
        expected = Dataset({"x": ("t", values)})

        original = Dataset({"x": ("t", values, {}, {"_FillValue": fill_value})})
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:1443: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_string_with_fill_value_vlen[]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a22950>
fill_value = ''

    @pytest.mark.parametrize("fill_value", ["XXX", "", "bár"])
    def test_roundtrip_string_with_fill_value_vlen(self, fill_value: str) -> None:
        values = np.array(["ab", "cdef", np.nan], dtype=object)
        expected = Dataset({"x": ("t", values)})

        original = Dataset({"x": ("t", values, {}, {"_FillValue": fill_value})})
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:1443: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_string_with_fill_value_vlen[b\xe1r]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a22b60>
fill_value = 'bár'

    @pytest.mark.parametrize("fill_value", ["XXX", "", "bár"])
    def test_roundtrip_string_with_fill_value_vlen(self, fill_value: str) -> None:
        values = np.array(["ab", "cdef", np.nan], dtype=object)
        expected = Dataset({"x": ("t", values)})

        original = Dataset({"x": ("t", values, {}, {"_FillValue": fill_value})})
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:1443: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestNetCDF4Data::test_compression_encoding[zstd]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestNetCDF4Data object at 0x79d78cb6c610>
compression = 'zstd'

    @pytest.mark.parametrize(
        "compression",
        [
            None,
            "zlib",
            "szip",
            "zstd",
            "blosc_lz",
            "blosc_lz4",
            "blosc_lz4hc",
            "blosc_zlib",
            "blosc_zstd",
        ],
    )
    @requires_netCDF4_1_6_2_or_above
    @pytest.mark.xfail(ON_WINDOWS, reason="new compression not yet implemented")
    def test_compression_encoding(self, compression: str | None) -> None:
        data = create_test_data(dim_sizes=(20, 80, 10))
        encoding_params: dict[str, Any] = dict(compression=compression, blosc_shuffle=1)
        data["var2"].encoding.update(encoding_params)
        data["var2"].encoding.update(
            {
                "chunksizes": (20, 40),
                "original_shape": data.var2.shape,
                "blosc_shuffle": 1,
                "fletcher32": False,
            }
        )
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1957: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:367: in store
    self.set_variables(
/testbed/xarray/backends/common.py:405: in set_variables
    target, source = self.prepare_variable(
/testbed/xarray/backends/netCDF4_.py:538: in prepare_variable
    nc4_var = self.ds.createVariable(**default_args)
src/netCDF4/_netCDF4.pyx:2956: in netCDF4._netCDF4.Dataset.createVariable
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   netCDF4._netCDF4.NetCDF4MissingFeatureException: compression='zstd' requires netCDF lib >= 4.9.0 (using 4.9.3-development). To enable, rebuild netcdf4-python using netCDF 4.9.0 or higher (and possibly enable compression='zstd')

src/netCDF4/_netCDF4.pyx:4230: NetCDF4MissingFeatureException
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_character_array</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a22da0>

    def test_roundtrip_character_array(self) -> None:
        with create_tmp_file() as tmp_file:
            values = np.array([["a", "b", "c"], ["d", "e", "f"]], dtype="S")

            with nc4.Dataset(tmp_file, mode="w") as nc:
                nc.createDimension("x", 2)
                nc.createDimension("string3", 3)
                v = nc.createVariable("x", np.dtype("S1"), ("x", "string3"))
                v[:] = values

            values = np.array(["abc", "def"], dtype="S")
            expected = Dataset({"x": ("x", values)})
            with open_dataset(tmp_file) as actual:
                assert_identical(expected, actual)
                # regression test for #157
>               with self.roundtrip(actual) as roundtripped:

/testbed/xarray/tests/test_backends.py:1465: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestNetCDF4Data::test_compression_encoding[blosc_lz]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestNetCDF4Data object at 0x79d78cb6eb60>
compression = 'blosc_lz'

    @pytest.mark.parametrize(
        "compression",
        [
            None,
            "zlib",
            "szip",
            "zstd",
            "blosc_lz",
            "blosc_lz4",
            "blosc_lz4hc",
            "blosc_zlib",
            "blosc_zstd",
        ],
    )
    @requires_netCDF4_1_6_2_or_above
    @pytest.mark.xfail(ON_WINDOWS, reason="new compression not yet implemented")
    def test_compression_encoding(self, compression: str | None) -> None:
        data = create_test_data(dim_sizes=(20, 80, 10))
        encoding_params: dict[str, Any] = dict(compression=compression, blosc_shuffle=1)
        data["var2"].encoding.update(encoding_params)
        data["var2"].encoding.update(
            {
                "chunksizes": (20, 40),
                "original_shape": data.var2.shape,
                "blosc_shuffle": 1,
                "fletcher32": False,
            }
        )
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1957: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:367: in store
    self.set_variables(
/testbed/xarray/backends/common.py:405: in set_variables
    target, source = self.prepare_variable(
/testbed/xarray/backends/netCDF4_.py:538: in prepare_variable
    nc4_var = self.ds.createVariable(**default_args)
src/netCDF4/_netCDF4.pyx:2956: in netCDF4._netCDF4.Dataset.createVariable
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   netCDF4._netCDF4.NetCDF4MissingFeatureException: compression='blosc_*' requires netCDF lib >= 4.9.0 (using 4.9.3-development). To enable, rebuild netcdf4-python using netCDF 4.9.0 or higher (and possibly enable compression='blosc_*')

src/netCDF4/_netCDF4.pyx:4254: NetCDF4MissingFeatureException
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_default_to_char_arrays</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a23010>

    def test_default_to_char_arrays(self) -> None:
        data = Dataset({"x": np.array(["foo", "zzzz"], dtype="S")})
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1470: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestNetCDF4Data::test_compression_encoding[blosc_lz4]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestNetCDF4Data object at 0x79d78cb6e320>
compression = 'blosc_lz4'

    @pytest.mark.parametrize(
        "compression",
        [
            None,
            "zlib",
            "szip",
            "zstd",
            "blosc_lz",
            "blosc_lz4",
            "blosc_lz4hc",
            "blosc_zlib",
            "blosc_zstd",
        ],
    )
    @requires_netCDF4_1_6_2_or_above
    @pytest.mark.xfail(ON_WINDOWS, reason="new compression not yet implemented")
    def test_compression_encoding(self, compression: str | None) -> None:
        data = create_test_data(dim_sizes=(20, 80, 10))
        encoding_params: dict[str, Any] = dict(compression=compression, blosc_shuffle=1)
        data["var2"].encoding.update(encoding_params)
        data["var2"].encoding.update(
            {
                "chunksizes": (20, 40),
                "original_shape": data.var2.shape,
                "blosc_shuffle": 1,
                "fletcher32": False,
            }
        )
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1957: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:367: in store
    self.set_variables(
/testbed/xarray/backends/common.py:405: in set_variables
    target, source = self.prepare_variable(
/testbed/xarray/backends/netCDF4_.py:538: in prepare_variable
    nc4_var = self.ds.createVariable(**default_args)
src/netCDF4/_netCDF4.pyx:2956: in netCDF4._netCDF4.Dataset.createVariable
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   netCDF4._netCDF4.NetCDF4MissingFeatureException: compression='blosc_*' requires netCDF lib >= 4.9.0 (using 4.9.3-development). To enable, rebuild netcdf4-python using netCDF 4.9.0 or higher (and possibly enable compression='blosc_*')

src/netCDF4/_netCDF4.pyx:4254: NetCDF4MissingFeatureException
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_dump_encodings</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a21f30>

    def test_dump_encodings(self) -> None:
        # regression test for #709
        ds = Dataset({"x": ("y", np.arange(10.0))})
        kwargs = dict(encoding={"x": {"zlib": True}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1505: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestNetCDF4Data::test_compression_encoding[blosc_lz4hc]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestNetCDF4Data object at 0x79d78cb6e680>
compression = 'blosc_lz4hc'

    @pytest.mark.parametrize(
        "compression",
        [
            None,
            "zlib",
            "szip",
            "zstd",
            "blosc_lz",
            "blosc_lz4",
            "blosc_lz4hc",
            "blosc_zlib",
            "blosc_zstd",
        ],
    )
    @requires_netCDF4_1_6_2_or_above
    @pytest.mark.xfail(ON_WINDOWS, reason="new compression not yet implemented")
    def test_compression_encoding(self, compression: str | None) -> None:
        data = create_test_data(dim_sizes=(20, 80, 10))
        encoding_params: dict[str, Any] = dict(compression=compression, blosc_shuffle=1)
        data["var2"].encoding.update(encoding_params)
        data["var2"].encoding.update(
            {
                "chunksizes": (20, 40),
                "original_shape": data.var2.shape,
                "blosc_shuffle": 1,
                "fletcher32": False,
            }
        )
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1957: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:367: in store
    self.set_variables(
/testbed/xarray/backends/common.py:405: in set_variables
    target, source = self.prepare_variable(
/testbed/xarray/backends/netCDF4_.py:538: in prepare_variable
    nc4_var = self.ds.createVariable(**default_args)
src/netCDF4/_netCDF4.pyx:2956: in netCDF4._netCDF4.Dataset.createVariable
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   netCDF4._netCDF4.NetCDF4MissingFeatureException: compression='blosc_*' requires netCDF lib >= 4.9.0 (using 4.9.3-development). To enable, rebuild netcdf4-python using netCDF 4.9.0 or higher (and possibly enable compression='blosc_*')

src/netCDF4/_netCDF4.pyx:4254: NetCDF4MissingFeatureException
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_compression_encoding_legacy</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a20a90>

    def test_compression_encoding_legacy(self) -> None:
        data = create_test_data()
        data["var2"].encoding.update(
            {
                "zlib": True,
                "chunksizes": (5, 5),
                "fletcher32": True,
                "shuffle": True,
                "original_shape": data.var2.shape,
            }
        )
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1538: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestNetCDF4Data::test_compression_encoding[blosc_zlib]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestNetCDF4Data object at 0x79d78cb6f0d0>
compression = 'blosc_zlib'

    @pytest.mark.parametrize(
        "compression",
        [
            None,
            "zlib",
            "szip",
            "zstd",
            "blosc_lz",
            "blosc_lz4",
            "blosc_lz4hc",
            "blosc_zlib",
            "blosc_zstd",
        ],
    )
    @requires_netCDF4_1_6_2_or_above
    @pytest.mark.xfail(ON_WINDOWS, reason="new compression not yet implemented")
    def test_compression_encoding(self, compression: str | None) -> None:
        data = create_test_data(dim_sizes=(20, 80, 10))
        encoding_params: dict[str, Any] = dict(compression=compression, blosc_shuffle=1)
        data["var2"].encoding.update(encoding_params)
        data["var2"].encoding.update(
            {
                "chunksizes": (20, 40),
                "original_shape": data.var2.shape,
                "blosc_shuffle": 1,
                "fletcher32": False,
            }
        )
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1957: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:367: in store
    self.set_variables(
/testbed/xarray/backends/common.py:405: in set_variables
    target, source = self.prepare_variable(
/testbed/xarray/backends/netCDF4_.py:538: in prepare_variable
    nc4_var = self.ds.createVariable(**default_args)
src/netCDF4/_netCDF4.pyx:2956: in netCDF4._netCDF4.Dataset.createVariable
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   netCDF4._netCDF4.NetCDF4MissingFeatureException: compression='blosc_*' requires netCDF lib >= 4.9.0 (using 4.9.3-development). To enable, rebuild netcdf4-python using netCDF 4.9.0 or higher (and possibly enable compression='blosc_*')

src/netCDF4/_netCDF4.pyx:4254: NetCDF4MissingFeatureException
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestNetCDF4Data::test_compression_encoding[blosc_zstd]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestNetCDF4Data object at 0x79d78cb6e9e0>
compression = 'blosc_zstd'

    @pytest.mark.parametrize(
        "compression",
        [
            None,
            "zlib",
            "szip",
            "zstd",
            "blosc_lz",
            "blosc_lz4",
            "blosc_lz4hc",
            "blosc_zlib",
            "blosc_zstd",
        ],
    )
    @requires_netCDF4_1_6_2_or_above
    @pytest.mark.xfail(ON_WINDOWS, reason="new compression not yet implemented")
    def test_compression_encoding(self, compression: str | None) -> None:
        data = create_test_data(dim_sizes=(20, 80, 10))
        encoding_params: dict[str, Any] = dict(compression=compression, blosc_shuffle=1)
        data["var2"].encoding.update(encoding_params)
        data["var2"].encoding.update(
            {
                "chunksizes": (20, 40),
                "original_shape": data.var2.shape,
                "blosc_shuffle": 1,
                "fletcher32": False,
            }
        )
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1957: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:367: in store
    self.set_variables(
/testbed/xarray/backends/common.py:405: in set_variables
    target, source = self.prepare_variable(
/testbed/xarray/backends/netCDF4_.py:538: in prepare_variable
    nc4_var = self.ds.createVariable(**default_args)
src/netCDF4/_netCDF4.pyx:2956: in netCDF4._netCDF4.Dataset.createVariable
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   netCDF4._netCDF4.NetCDF4MissingFeatureException: compression='blosc_*' requires netCDF lib >= 4.9.0 (using 4.9.3-development). To enable, rebuild netcdf4-python using netCDF 4.9.0 or higher (and possibly enable compression='blosc_*')

src/netCDF4/_netCDF4.pyx:4254: NetCDF4MissingFeatureException
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_encoding_kwarg_compression</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a233d0>

    def test_encoding_kwarg_compression(self) -> None:
        ds = Dataset({"x": np.arange(10.0)})
        encoding = dict(
            dtype="f4",
            zlib=True,
            complevel=9,
            fletcher32=True,
            chunksizes=(5,),
            shuffle=True,
        )
        kwargs = dict(encoding=dict(x=encoding))

>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_keep_chunksizes_if_no_original_shape</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a23640>

    def test_keep_chunksizes_if_no_original_shape(self) -> None:
        ds = Dataset({"x": [1, 2, 3]})
        chunksizes = (2,)
        ds.variables["x"].encoding = {"chunksizes": chunksizes}

>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1575: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_preferred_chunks_is_present</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a238b0>

    def test_preferred_chunks_is_present(self) -> None:
        ds = Dataset({"x": [1, 2, 3]})
        chunksizes = (2,)
        ds.variables["x"].encoding = {"chunksizes": chunksizes}

>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1586: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_auto_chunking_is_based_on_disk_chunk_sizes</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a23b20>

    @requires_dask
    def test_auto_chunking_is_based_on_disk_chunk_sizes(self) -> None:
        x_size = y_size = 1000
        y_chunksize = y_size
        x_chunksize = 10

        with dask.config.set({"array.chunk-size": "100KiB"}):
>           with self.chunked_roundtrip(
                (1, y_size, x_size),
                (1, y_chunksize, x_chunksize),
                open_kwargs={"chunks": "auto"},
            ) as ds:

/testbed/xarray/tests/test_backends.py:1596: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:1641: in chunked_roundtrip
    with self.roundtrip(dataset, open_kwargs=open_kwargs) as ds:
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_base_chunking_uses_disk_chunk_sizes</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a23d90>

    @requires_dask
    def test_base_chunking_uses_disk_chunk_sizes(self) -> None:
        x_size = y_size = 1000
        y_chunksize = y_size
        x_chunksize = 10

>       with self.chunked_roundtrip(
            (1, y_size, x_size),
            (1, y_chunksize, x_chunksize),
            open_kwargs={"chunks": {}},
        ) as ds:

/testbed/xarray/tests/test_backends.py:1612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:1641: in chunked_roundtrip
    with self.roundtrip(dataset, open_kwargs=open_kwargs) as ds:
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_preferred_chunks_are_disk_chunk_sizes</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a18040>

    def test_preferred_chunks_are_disk_chunk_sizes(self) -> None:
        x_size = y_size = 1000
        y_chunksize = y_size
        x_chunksize = 10

>       with self.chunked_roundtrip(
            (1, y_size, x_size), (1, y_chunksize, x_chunksize)
        ) as ds:

/testbed/xarray/tests/test_backends.py:1649: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:1641: in chunked_roundtrip
    with self.roundtrip(dataset, open_kwargs=open_kwargs) as ds:
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_encoding_chunksizes_unlimited</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a182b0>

    def test_encoding_chunksizes_unlimited(self) -> None:
        # regression test for GH1225
        ds = Dataset({"x": [1, 2, 3], "y": ("x", [2, 3, 4])})
        ds.variables["x"].encoding = {
            "zlib": False,
            "shuffle": False,
            "complevel": 0,
            "fletcher32": False,
            "contiguous": False,
            "chunksizes": (2**20,),
            "original_shape": (3,),
        }
>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1670: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_raise_on_forward_slashes_in_names</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a18c70>

    def test_raise_on_forward_slashes_in_names(self) -> None:
        # test for forward slash in variable names and dimensions
        # see GH 7943
        data_vars: list[dict[str, Any]] = [
            {"PASS/FAIL": (["PASSFAIL"], np.array([0]))},
            {"PASS/FAIL": np.array([0])},
            {"PASSFAIL": (["PASS/FAIL"], np.array([0]))},
        ]
        for dv in data_vars:
            ds = Dataset(data_vars=dv)
            with pytest.raises(ValueError, match="Forward slashes '/' are not allowed"):
>               with self.roundtrip(ds):

/testbed/xarray/tests/test_backends.py:1746: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_encoding_enum__no_fill_value</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a18ee0>

    @requires_netCDF4
    def test_encoding_enum__no_fill_value(self):
        with create_tmp_file() as tmp_file:
            cloud_type_dict = {"clear": 0, "cloudy": 1}
            with nc4.Dataset(tmp_file, mode="w") as nc:
                nc.createDimension("time", size=2)
                cloud_type = nc.createEnumType("u1", "cloud_type", cloud_type_dict)
                v = nc.createVariable(
                    "clouds",
                    cloud_type,
                    "time",
                    fill_value=None,
                )
                v[:] = 1
            with open_dataset(tmp_file) as original:
                save_kwargs = {}
                if self.engine == "h5netcdf":
                    save_kwargs["invalid_netcdf"] = True
>               with self.roundtrip(original, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1767: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_encoding_enum__multiple_variable_with_enum</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a19150>

    @requires_netCDF4
    def test_encoding_enum__multiple_variable_with_enum(self):
        with create_tmp_file() as tmp_file:
            cloud_type_dict = {"clear": 0, "cloudy": 1, "missing": 255}
            with nc4.Dataset(tmp_file, mode="w") as nc:
                nc.createDimension("time", size=2)
                cloud_type = nc.createEnumType("u1", "cloud_type", cloud_type_dict)
                nc.createVariable(
                    "clouds",
                    cloud_type,
                    "time",
                    fill_value=255,
                )
                nc.createVariable(
                    "tifa",
                    cloud_type,
                    "time",
                    fill_value=255,
                )
            with open_dataset(tmp_file) as original:
                save_kwargs = {}
                if self.engine == "h5netcdf":
                    save_kwargs["invalid_netcdf"] = True
>               with self.roundtrip(original, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1803: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_complex</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a20c10>

    def test_complex(self) -> None:
        expected = Dataset({"x": ("y", np.ones(5) + 1j * np.ones(5))})
        save_kwargs = {"invalid_netcdf": True}
        with pytest.warns(UserWarning, match="You are writing invalid netcdf features"):
>           with self.roundtrip(expected, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:3599: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_complex_error[None]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b69fb400>
invalid_netcdf = None

    @pytest.mark.parametrize("invalid_netcdf", [None, False])
    def test_complex_error(self, invalid_netcdf) -> None:
        import h5netcdf

        expected = Dataset({"x": ("y", np.ones(5) + 1j * np.ones(5))})
        save_kwargs = {"invalid_netcdf": invalid_netcdf}
        with pytest.raises(
            h5netcdf.CompatibilityError, match="are not a supported NetCDF feature"
        ):
>           with self.roundtrip(expected, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:3611: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestNetCDF4ViaDaskData::test_compression_encoding[zstd]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestNetCDF4ViaDaskData object at 0x79d78d91da80>
compression = 'zstd'

    @pytest.mark.parametrize(
        "compression",
        [
            None,
            "zlib",
            "szip",
            "zstd",
            "blosc_lz",
            "blosc_lz4",
            "blosc_lz4hc",
            "blosc_zlib",
            "blosc_zstd",
        ],
    )
    @requires_netCDF4_1_6_2_or_above
    @pytest.mark.xfail(ON_WINDOWS, reason="new compression not yet implemented")
    def test_compression_encoding(self, compression: str | None) -> None:
        data = create_test_data(dim_sizes=(20, 80, 10))
        encoding_params: dict[str, Any] = dict(compression=compression, blosc_shuffle=1)
        data["var2"].encoding.update(encoding_params)
        data["var2"].encoding.update(
            {
                "chunksizes": (20, 40),
                "original_shape": data.var2.shape,
                "blosc_shuffle": 1,
                "fletcher32": False,
            }
        )
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1957: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:2068: in roundtrip
    with TestNetCDF4Data.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:367: in store
    self.set_variables(
/testbed/xarray/backends/common.py:405: in set_variables
    target, source = self.prepare_variable(
/testbed/xarray/backends/netCDF4_.py:538: in prepare_variable
    nc4_var = self.ds.createVariable(**default_args)
src/netCDF4/_netCDF4.pyx:2956: in netCDF4._netCDF4.Dataset.createVariable
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   netCDF4._netCDF4.NetCDF4MissingFeatureException: compression='zstd' requires netCDF lib >= 4.9.0 (using 4.9.3-development). To enable, rebuild netcdf4-python using netCDF 4.9.0 or higher (and possibly enable compression='zstd')

src/netCDF4/_netCDF4.pyx:4230: NetCDF4MissingFeatureException
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_complex_error[False]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b69fb070>
invalid_netcdf = False

    @pytest.mark.parametrize("invalid_netcdf", [None, False])
    def test_complex_error(self, invalid_netcdf) -> None:
        import h5netcdf

        expected = Dataset({"x": ("y", np.ones(5) + 1j * np.ones(5))})
        save_kwargs = {"invalid_netcdf": invalid_netcdf}
        with pytest.raises(
            h5netcdf.CompatibilityError, match="are not a supported NetCDF feature"
        ):
>           with self.roundtrip(expected, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:3611: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestNetCDF4ViaDaskData::test_compression_encoding[blosc_lz]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestNetCDF4ViaDaskData object at 0x79d78d91d870>
compression = 'blosc_lz'

    @pytest.mark.parametrize(
        "compression",
        [
            None,
            "zlib",
            "szip",
            "zstd",
            "blosc_lz",
            "blosc_lz4",
            "blosc_lz4hc",
            "blosc_zlib",
            "blosc_zstd",
        ],
    )
    @requires_netCDF4_1_6_2_or_above
    @pytest.mark.xfail(ON_WINDOWS, reason="new compression not yet implemented")
    def test_compression_encoding(self, compression: str | None) -> None:
        data = create_test_data(dim_sizes=(20, 80, 10))
        encoding_params: dict[str, Any] = dict(compression=compression, blosc_shuffle=1)
        data["var2"].encoding.update(encoding_params)
        data["var2"].encoding.update(
            {
                "chunksizes": (20, 40),
                "original_shape": data.var2.shape,
                "blosc_shuffle": 1,
                "fletcher32": False,
            }
        )
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1957: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:2068: in roundtrip
    with TestNetCDF4Data.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:367: in store
    self.set_variables(
/testbed/xarray/backends/common.py:405: in set_variables
    target, source = self.prepare_variable(
/testbed/xarray/backends/netCDF4_.py:538: in prepare_variable
    nc4_var = self.ds.createVariable(**default_args)
src/netCDF4/_netCDF4.pyx:2956: in netCDF4._netCDF4.Dataset.createVariable
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   netCDF4._netCDF4.NetCDF4MissingFeatureException: compression='blosc_*' requires netCDF lib >= 4.9.0 (using 4.9.3-development). To enable, rebuild netcdf4-python using netCDF 4.9.0 or higher (and possibly enable compression='blosc_*')

src/netCDF4/_netCDF4.pyx:4254: NetCDF4MissingFeatureException
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_numpy_bool_</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b69f8f40>

    def test_numpy_bool_(self) -> None:
        # h5netcdf loads booleans as numpy.bool_, this type needs to be supported
        # when writing invalid_netcdf datasets in order to support a roundtrip
        expected = Dataset({"x": ("y", np.ones(5), {"numpy_bool": np.bool_(True)})})
        save_kwargs = {"invalid_netcdf": True}
        with pytest.warns(UserWarning, match="You are writing invalid netcdf features"):
>           with self.roundtrip(expected, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:3620: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_cross_engine_read_write_netcdf4</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a20d30>

    def test_cross_engine_read_write_netcdf4(self) -> None:
        # Drop dim3, because its labels include strings. These appear to be
        # not properly read with python-netCDF4, which converts them into
        # unicode instead of leaving them as bytes.
        data = create_test_data().drop_vars("dim3")
        data.attrs["foo"] = "bar"
        valid_engines: list[T_NetcdfEngine] = ["netcdf4", "h5netcdf"]
        for write_engine in valid_engines:
            with create_tmp_file() as tmp_file:
                data.to_netcdf(tmp_file, engine=write_engine)
                for read_engine in valid_engines:
>                   with open_dataset(tmp_file, engine=read_engine) as actual:

/testbed/xarray/tests/test_backends.py:3634: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/backends/api.py:588: in open_dataset
    backend_ds = backend.open_dataset(
/testbed/xarray/backends/h5netcdf_.py:418: in open_dataset
    ds = store_entrypoint.open_dataset(
/testbed/xarray/backends/store.py:43: in open_dataset
    vars, attrs = filename_or_obj.load()
/testbed/xarray/backends/common.py:221: in load
    (_decode_variable_name(k), v) for k, v in self.get_variables().items()
/testbed/xarray/backends/h5netcdf_.py:237: in get_variables
    return FrozenDict(
/testbed/xarray/core/utils.py:436: in FrozenDict
    return Frozen(dict(*args, **kwargs))
/testbed/xarray/backends/h5netcdf_.py:238: in <genexpr>
    (k, self.open_store_variable(k, v)) for k, v in self.ds.variables.items()
/testbed/xarray/backends/h5netcdf_.py:200: in open_store_variable
    dimensions = var.dimensions
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:260: in dimensions
    self._dimensions = self._lookup_dimensions()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:154: in _lookup_dimensions
    if _unlabeled_dimension_mix(self._h5ds) == "labeled":
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in _unlabeled_dimension_mix
    dimset = set([len(j) for j in dimlist])
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in <listcomp>
    dimset = set([len(j) for j in dimlist])
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
/testbed/.venv/lib/python3.10/site-packages/h5py/_hl/dims.py:60: in __len__
    return h5ds.get_num_scales(self._id, self._dimension)
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:72: in h5py.h5ds.get_num_scales
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSget_num_scales (return value <0)

h5py/defs.pyx:4461: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestNetCDF4ViaDaskData::test_compression_encoding[blosc_lz4]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestNetCDF4ViaDaskData object at 0x79d78d91fe50>
compression = 'blosc_lz4'

    @pytest.mark.parametrize(
        "compression",
        [
            None,
            "zlib",
            "szip",
            "zstd",
            "blosc_lz",
            "blosc_lz4",
            "blosc_lz4hc",
            "blosc_zlib",
            "blosc_zstd",
        ],
    )
    @requires_netCDF4_1_6_2_or_above
    @pytest.mark.xfail(ON_WINDOWS, reason="new compression not yet implemented")
    def test_compression_encoding(self, compression: str | None) -> None:
        data = create_test_data(dim_sizes=(20, 80, 10))
        encoding_params: dict[str, Any] = dict(compression=compression, blosc_shuffle=1)
        data["var2"].encoding.update(encoding_params)
        data["var2"].encoding.update(
            {
                "chunksizes": (20, 40),
                "original_shape": data.var2.shape,
                "blosc_shuffle": 1,
                "fletcher32": False,
            }
        )
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1957: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:2068: in roundtrip
    with TestNetCDF4Data.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:367: in store
    self.set_variables(
/testbed/xarray/backends/common.py:405: in set_variables
    target, source = self.prepare_variable(
/testbed/xarray/backends/netCDF4_.py:538: in prepare_variable
    nc4_var = self.ds.createVariable(**default_args)
src/netCDF4/_netCDF4.pyx:2956: in netCDF4._netCDF4.Dataset.createVariable
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   netCDF4._netCDF4.NetCDF4MissingFeatureException: compression='blosc_*' requires netCDF lib >= 4.9.0 (using 4.9.3-development). To enable, rebuild netcdf4-python using netCDF 4.9.0 or higher (and possibly enable compression='blosc_*')

src/netCDF4/_netCDF4.pyx:4254: NetCDF4MissingFeatureException
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_encoding_unlimited_dims</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a20f40>

    def test_encoding_unlimited_dims(self) -> None:
        ds = Dataset({"x": ("y", np.arange(10.0))})
>       with self.roundtrip(ds, save_kwargs=dict(unlimited_dims=["y"])) as actual:

/testbed/xarray/tests/test_backends.py:3647: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:257: in set_dimension
    self.ds.dimensions[name] = None
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestNetCDF4ViaDaskData::test_compression_encoding[blosc_lz4hc]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestNetCDF4ViaDaskData object at 0x79d78d91fd30>
compression = 'blosc_lz4hc'

    @pytest.mark.parametrize(
        "compression",
        [
            None,
            "zlib",
            "szip",
            "zstd",
            "blosc_lz",
            "blosc_lz4",
            "blosc_lz4hc",
            "blosc_zlib",
            "blosc_zstd",
        ],
    )
    @requires_netCDF4_1_6_2_or_above
    @pytest.mark.xfail(ON_WINDOWS, reason="new compression not yet implemented")
    def test_compression_encoding(self, compression: str | None) -> None:
        data = create_test_data(dim_sizes=(20, 80, 10))
        encoding_params: dict[str, Any] = dict(compression=compression, blosc_shuffle=1)
        data["var2"].encoding.update(encoding_params)
        data["var2"].encoding.update(
            {
                "chunksizes": (20, 40),
                "original_shape": data.var2.shape,
                "blosc_shuffle": 1,
                "fletcher32": False,
            }
        )
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1957: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:2068: in roundtrip
    with TestNetCDF4Data.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:367: in store
    self.set_variables(
/testbed/xarray/backends/common.py:405: in set_variables
    target, source = self.prepare_variable(
/testbed/xarray/backends/netCDF4_.py:538: in prepare_variable
    nc4_var = self.ds.createVariable(**default_args)
src/netCDF4/_netCDF4.pyx:2956: in netCDF4._netCDF4.Dataset.createVariable
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   netCDF4._netCDF4.NetCDF4MissingFeatureException: compression='blosc_*' requires netCDF lib >= 4.9.0 (using 4.9.3-development). To enable, rebuild netcdf4-python using netCDF 4.9.0 or higher (and possibly enable compression='blosc_*')

src/netCDF4/_netCDF4.pyx:4254: NetCDF4MissingFeatureException
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_compression_encoding_h5py</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a211b0>

    def test_compression_encoding_h5py(self) -> None:
        ENCODINGS: tuple[tuple[dict[str, Any], dict[str, Any]], ...] = (
            # h5py style compression with gzip codec will be converted to
            # NetCDF4-Python style on round-trip
            (
                {"compression": "gzip", "compression_opts": 9},
                {"zlib": True, "complevel": 9},
            ),
            # What can't be expressed in NetCDF4-Python style is
            # round-tripped unaltered
            (
                {"compression": "lzf", "compression_opts": None},
                {"compression": "lzf", "compression_opts": None},
            ),
            # If both styles are used together, h5py format takes precedence
            (
                {
                    "compression": "lzf",
                    "compression_opts": None,
                    "zlib": True,
                    "complevel": 9,
                },
                {"compression": "lzf", "compression_opts": None},
            ),
        )

        for compr_in, compr_out in ENCODINGS:
            data = create_test_data()
            compr_common = {
                "chunksizes": (5, 5),
                "fletcher32": True,
                "shuffle": True,
                "original_shape": data.var2.shape,
            }
            data["var2"].encoding.update(compr_in)
            data["var2"].encoding.update(compr_common)
            compr_out.update(compr_common)
            data["scalar"] = ("scalar_dim", np.array([2.0]))
            data["scalar"] = data["scalar"][0]
>           with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:3694: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestNetCDF4ViaDaskData::test_compression_encoding[blosc_zlib]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestNetCDF4ViaDaskData object at 0x79d78d91f580>
compression = 'blosc_zlib'

    @pytest.mark.parametrize(
        "compression",
        [
            None,
            "zlib",
            "szip",
            "zstd",
            "blosc_lz",
            "blosc_lz4",
            "blosc_lz4hc",
            "blosc_zlib",
            "blosc_zstd",
        ],
    )
    @requires_netCDF4_1_6_2_or_above
    @pytest.mark.xfail(ON_WINDOWS, reason="new compression not yet implemented")
    def test_compression_encoding(self, compression: str | None) -> None:
        data = create_test_data(dim_sizes=(20, 80, 10))
        encoding_params: dict[str, Any] = dict(compression=compression, blosc_shuffle=1)
        data["var2"].encoding.update(encoding_params)
        data["var2"].encoding.update(
            {
                "chunksizes": (20, 40),
                "original_shape": data.var2.shape,
                "blosc_shuffle": 1,
                "fletcher32": False,
            }
        )
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1957: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:2068: in roundtrip
    with TestNetCDF4Data.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:367: in store
    self.set_variables(
/testbed/xarray/backends/common.py:405: in set_variables
    target, source = self.prepare_variable(
/testbed/xarray/backends/netCDF4_.py:538: in prepare_variable
    nc4_var = self.ds.createVariable(**default_args)
src/netCDF4/_netCDF4.pyx:2956: in netCDF4._netCDF4.Dataset.createVariable
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   netCDF4._netCDF4.NetCDF4MissingFeatureException: compression='blosc_*' requires netCDF lib >= 4.9.0 (using 4.9.3-development). To enable, rebuild netcdf4-python using netCDF 4.9.0 or higher (and possibly enable compression='blosc_*')

src/netCDF4/_netCDF4.pyx:4254: NetCDF4MissingFeatureException
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_compression_check_encoding_h5py</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a21420>

    def test_compression_check_encoding_h5py(self) -> None:
        """When mismatched h5py and NetCDF4-Python encodings are expressed
        in to_netcdf(encoding=...), must raise ValueError
        """
        data = Dataset({"x": ("y", np.arange(10.0))})
        # Compatible encodings are graciously supported
        with create_tmp_file() as tmp_file:
>           data.to_netcdf(
                tmp_file,
                engine="h5netcdf",
                encoding={
                    "x": {
                        "compression": "gzip",
                        "zlib": True,
                        "compression_opts": 6,
                        "complevel": 6,
                    }
                },
            )

/testbed/xarray/tests/test_backends.py:3705: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_dump_encodings_h5py</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x7f42b6a21690>

    def test_dump_encodings_h5py(self) -> None:
        # regression test for #709
        ds = Dataset({"x": ("y", np.arange(10.0))})

        kwargs = {"encoding": {"x": {"compression": "gzip", "compression_opts": 9}}}
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:3754: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestNetCDF4ViaDaskData::test_compression_encoding[blosc_zstd]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestNetCDF4ViaDaskData object at 0x79d78d91df60>
compression = 'blosc_zstd'

    @pytest.mark.parametrize(
        "compression",
        [
            None,
            "zlib",
            "szip",
            "zstd",
            "blosc_lz",
            "blosc_lz4",
            "blosc_lz4hc",
            "blosc_zlib",
            "blosc_zstd",
        ],
    )
    @requires_netCDF4_1_6_2_or_above
    @pytest.mark.xfail(ON_WINDOWS, reason="new compression not yet implemented")
    def test_compression_encoding(self, compression: str | None) -> None:
        data = create_test_data(dim_sizes=(20, 80, 10))
        encoding_params: dict[str, Any] = dict(compression=compression, blosc_shuffle=1)
        data["var2"].encoding.update(encoding_params)
        data["var2"].encoding.update(
            {
                "chunksizes": (20, 40),
                "original_shape": data.var2.shape,
                "blosc_shuffle": 1,
                "fletcher32": False,
            }
        )
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1957: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:2068: in roundtrip
    with TestNetCDF4Data.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:367: in store
    self.set_variables(
/testbed/xarray/backends/common.py:405: in set_variables
    target, source = self.prepare_variable(
/testbed/xarray/backends/netCDF4_.py:538: in prepare_variable
    nc4_var = self.ds.createVariable(**default_args)
src/netCDF4/_netCDF4.pyx:2956: in netCDF4._netCDF4.Dataset.createVariable
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   netCDF4._netCDF4.NetCDF4MissingFeatureException: compression='blosc_*' requires netCDF lib >= 4.9.0 (using 4.9.3-development). To enable, rebuild netcdf4-python using netCDF 4.9.0 or higher (and possibly enable compression='blosc_*')

src/netCDF4/_netCDF4.pyx:4254: NetCDF4MissingFeatureException
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_zero_dimensional_variable</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409acc10>

    def test_zero_dimensional_variable(self) -> None:
        expected = create_test_data()
        expected["float_var"] = ([], 1.0e9, {"units": "units of awesome"})
        expected["bytes_var"] = ([], b"foobar")
        expected["string_var"] = ([], "foobar")
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:350: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFAlreadyOpen::test_deepcopy</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFAlreadyOpen object at 0x7f42b6877010>

    def test_deepcopy(self) -> None:
        import h5netcdf

        with create_tmp_file() as tmp_file:
            with nc4.Dataset(tmp_file, mode="w") as nc:
                nc.createDimension("x", 10)
                v = nc.createVariable("y", np.int32, ("x",))
                v[:] = np.arange(10)

            kwargs = {"decode_vlen_strings": True}

            h5 = h5netcdf.File(tmp_file, mode="r", **kwargs)
            store = backends.H5NetCDFStore(h5)
>           with open_dataset(store) as ds:

/testbed/xarray/tests/test_backends.py:3813: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/backends/api.py:588: in open_dataset
    backend_ds = backend.open_dataset(
/testbed/xarray/backends/store.py:43: in open_dataset
    vars, attrs = filename_or_obj.load()
/testbed/xarray/backends/common.py:221: in load
    (_decode_variable_name(k), v) for k, v in self.get_variables().items()
/testbed/xarray/backends/h5netcdf_.py:237: in get_variables
    return FrozenDict(
/testbed/xarray/core/utils.py:436: in FrozenDict
    return Frozen(dict(*args, **kwargs))
/testbed/xarray/backends/h5netcdf_.py:238: in <genexpr>
    (k, self.open_store_variable(k, v)) for k, v in self.ds.variables.items()
/testbed/xarray/backends/h5netcdf_.py:200: in open_store_variable
    dimensions = var.dimensions
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:260: in dimensions
    self._dimensions = self._lookup_dimensions()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:154: in _lookup_dimensions
    if _unlabeled_dimension_mix(self._h5ds) == "labeled":
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in _unlabeled_dimension_mix
    dimset = set([len(j) for j in dimlist])
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in <listcomp>
    dimset = set([len(j) for j in dimlist])
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
/testbed/.venv/lib/python3.10/site-packages/h5py/_hl/dims.py:60: in __len__
    return h5ds.get_num_scales(self._id, self._dimension)
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:72: in h5py.h5ds.get_num_scales
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSget_num_scales (return value <0)

h5py/defs.pyx:4461: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_write_store</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409ace80>

    def test_write_store(self) -> None:
        expected = create_test_data()
        with self.create_store() as store:
>           expected.dump_to_store(store)

/testbed/xarray/tests/test_backends.py:356: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/core/dataset.py:2170: in dump_to_store
    dump_to_store(self, store, **kwargs)
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_zero_dimensional_variable</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6902ad0>

    def test_zero_dimensional_variable(self) -> None:
        expected = create_test_data()
        expected["float_var"] = ([], 1.0e9, {"units": "units of awesome"})
        expected["bytes_var"] = ([], b"foobar")
        expected["string_var"] = ([], "foobar")
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:350: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_test_data</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409ad0f0>

    def test_roundtrip_test_data(self) -> None:
        expected = create_test_data()
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:383: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_write_store</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6901c30>

    def test_write_store(self) -> None:
        expected = create_test_data()
        with self.create_store() as store:
>           expected.dump_to_store(store)

/testbed/xarray/tests/test_backends.py:356: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/core/dataset.py:2170: in dump_to_store
    dump_to_store(self, store, **kwargs)
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_load</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409ad360>

    def test_load(self) -> None:
        expected = create_test_data()

        @contextlib.contextmanager
        def assert_loads(vars=None):
            if vars is None:
                vars = expected
            with self.roundtrip(expected) as actual:
                for k, v in actual.variables.items():
                    # IndexVariables are eagerly loaded into memory
                    assert v._in_memory == (k in actual.dims)
                yield actual
                for k, v in actual.variables.items():
                    if k in vars:
                        assert v._in_memory
                assert_identical(expected, actual)

        with pytest.raises(AssertionError):
            # make sure the contextmanager works!
>           with assert_loads() as ds:

/testbed/xarray/tests/test_backends.py:406: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:394: in assert_loads
    with self.roundtrip(expected) as actual:
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_test_data</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6900fd0>

    def test_roundtrip_test_data(self) -> None:
        expected = create_test_data()
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:383: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_dataset_compute</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409ad5d0>

    def test_dataset_compute(self) -> None:
        expected = create_test_data()

>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:423: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_load</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69000a0>

    def test_load(self) -> None:
        expected = create_test_data()

        @contextlib.contextmanager
        def assert_loads(vars=None):
            if vars is None:
                vars = expected
            with self.roundtrip(expected) as actual:
                for k, v in actual.variables.items():
                    # IndexVariables are eagerly loaded into memory
                    assert v._in_memory == (k in actual.dims)
                yield actual
                for k, v in actual.variables.items():
                    if k in vars:
                        assert v._in_memory
                assert_identical(expected, actual)

        with pytest.raises(AssertionError):
            # make sure the contextmanager works!
>           with assert_loads() as ds:

/testbed/xarray/tests/test_backends.py:406: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:394: in assert_loads
    with self.roundtrip(expected) as actual:
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_pickle</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409ad840>

    def test_pickle(self) -> None:
        expected = Dataset({"foo": ("x", [42])})
>       with self.roundtrip(expected, allow_cleanup_failure=ON_WINDOWS) as roundtripped:

/testbed/xarray/tests/test_backends.py:441: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_dataset_compute</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6902c50>

    def test_dataset_compute(self) -> None:
        expected = create_test_data()

>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:423: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_pickle_dataarray</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409adab0>

    @pytest.mark.filterwarnings("ignore:deallocating CachingFileManager")
    def test_pickle_dataarray(self) -> None:
        expected = Dataset({"foo": ("x", [42])})
>       with self.roundtrip(expected, allow_cleanup_failure=ON_WINDOWS) as roundtripped:

/testbed/xarray/tests/test_backends.py:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_pickle</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6903010>

    def test_pickle(self) -> None:
        expected = Dataset({"foo": ("x", [42])})
>       with self.roundtrip(expected, allow_cleanup_failure=ON_WINDOWS) as roundtripped:

/testbed/xarray/tests/test_backends.py:441: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_dataset_caching</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409add20>

    def test_dataset_caching(self) -> None:
        expected = Dataset({"foo": ("x", [5, 6, 7])})
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:461: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_None_variable</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409adf90>

    @pytest.mark.filterwarnings("ignore:deallocating CachingFileManager")
    def test_roundtrip_None_variable(self) -> None:
        expected = Dataset({None: (("x", "y"), [[0, 1], [2, 3]])})
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:476: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_pickle_dataarray</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69033d0>

    @pytest.mark.filterwarnings("ignore:deallocating CachingFileManager")
    def test_pickle_dataarray(self) -> None:
        expected = Dataset({"foo": ("x", [42])})
>       with self.roundtrip(expected, allow_cleanup_failure=ON_WINDOWS) as roundtripped:

/testbed/xarray/tests/test_backends.py:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_object_dtype</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409ae200>

    def test_roundtrip_object_dtype(self) -> None:
        floats = np.array([0.0, 0.0, 1.0, 2.0, 3.0], dtype=object)
        floats_nans = np.array([np.nan, np.nan, 1.0, 2.0, 3.0], dtype=object)
        bytes_ = np.array([b"ab", b"cdef", b"g"], dtype=object)
        bytes_nans = np.array([b"ab", b"cdef", np.nan], dtype=object)
        strings = np.array(["ab", "cdef", "g"], dtype=object)
        strings_nans = np.array(["ab", "cdef", np.nan], dtype=object)
        all_nans = np.array([np.nan, np.nan], dtype=object)
        original = Dataset(
            {
                "floats": ("a", floats),
                "floats_nans": ("a", floats_nans),
                "bytes": ("b", bytes_),
                "bytes_nans": ("b", bytes_nans),
                "strings": ("b", strings),
                "strings_nans": ("b", strings_nans),
                "all_nans": ("c", all_nans),
                "nan": ([], np.nan),
            }
        )
        expected = original.copy(deep=True)
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:500: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_dataset_caching</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69036d0>

    def test_dataset_caching(self) -> None:
        expected = Dataset({"foo": ("x", [5, 6, 7])})
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:461: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_string_data</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408ac280>

    def test_roundtrip_string_data(self) -> None:
        expected = Dataset({"x": ("t", ["ab", "cdef"])})
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:516: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_None_variable</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69039d0>

    @pytest.mark.filterwarnings("ignore:deallocating CachingFileManager")
    def test_roundtrip_None_variable(self) -> None:
        expected = Dataset({None: (("x", "y"), [[0, 1], [2, 3]])})
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:476: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_string_encoded_characters</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408ac4c0>

    def test_roundtrip_string_encoded_characters(self) -> None:
        expected = Dataset({"x": ("t", ["ab", "cdef"])})
        expected["x"].encoding["dtype"] = "S1"
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:522: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_object_dtype</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6903d60>

    def test_roundtrip_object_dtype(self) -> None:
        floats = np.array([0.0, 0.0, 1.0, 2.0, 3.0], dtype=object)
        floats_nans = np.array([np.nan, np.nan, 1.0, 2.0, 3.0], dtype=object)
        bytes_ = np.array([b"ab", b"cdef", b"g"], dtype=object)
        bytes_nans = np.array([b"ab", b"cdef", np.nan], dtype=object)
        strings = np.array(["ab", "cdef", "g"], dtype=object)
        strings_nans = np.array(["ab", "cdef", np.nan], dtype=object)
        all_nans = np.array([np.nan, np.nan], dtype=object)
        original = Dataset(
            {
                "floats": ("a", floats),
                "floats_nans": ("a", floats_nans),
                "bytes": ("b", bytes_),
                "bytes_nans": ("b", bytes_nans),
                "strings": ("b", strings),
                "strings_nans": ("b", strings_nans),
                "all_nans": ("c", all_nans),
                "nan": ([], np.nan),
            }
        )
        expected = original.copy(deep=True)
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:500: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_string_data</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69300d0>

    def test_roundtrip_string_data(self) -> None:
        expected = Dataset({"x": ("t", ["ab", "cdef"])})
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:516: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_numpy_datetime_data</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408ac790>

    def test_roundtrip_numpy_datetime_data(self) -> None:
        times = pd.to_datetime(["2000-01-01", "2000-01-02", "NaT"], unit="ns")
        expected = Dataset({"t": ("t", times), "t0": times[0]})
        kwargs = {"encoding": {"t0": {"units": "days since 1950-01-01"}}}
>       with self.roundtrip(expected, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:535: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_cftime_datetime_data</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408aca00>

    @requires_cftime
    def test_roundtrip_cftime_datetime_data(self) -> None:
        from xarray.tests.test_coding_times import _all_cftime_date_types

        date_types = _all_cftime_date_types()
        for date_type in date_types.values():
            times = [date_type(1, 1, 1), date_type(1, 1, 2)]
            expected = Dataset({"t": ("t", times), "t0": times[0]})
            kwargs = {"encoding": {"t0": {"units": "days since 0001-01-01"}}}
            expected_decoded_t = np.array(times)
            expected_decoded_t0 = np.array([date_type(1, 1, 1)])
            expected_calendar = times[0].calendar

            with warnings.catch_warnings():
                if expected_calendar in {"proleptic_gregorian", "standard"}:
                    warnings.filterwarnings("ignore", "Unable to decode time axis")

>               with self.roundtrip(expected, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:556: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_string_encoded_characters</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6930520>

    def test_roundtrip_string_encoded_characters(self) -> None:
        expected = Dataset({"x": ("t", ["ab", "cdef"])})
        expected["x"].encoding["dtype"] = "S1"
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:522: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_timedelta_data</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408accd0>

    def test_roundtrip_timedelta_data(self) -> None:
        time_deltas = pd.to_timedelta(["1h", "2h", "NaT"])  # type: ignore[arg-type]  #https://github.com/pandas-dev/pandas-stubs/issues/956
        expected = Dataset({"td": ("td", time_deltas), "td0": time_deltas[0]})
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:573: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_numpy_datetime_data</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69cd930>

    def test_roundtrip_numpy_datetime_data(self) -> None:
        times = pd.to_datetime(["2000-01-01", "2000-01-02", "NaT"], unit="ns")
        expected = Dataset({"t": ("t", times), "t0": times[0]})
        kwargs = {"encoding": {"t0": {"units": "days since 1950-01-01"}}}
>       with self.roundtrip(expected, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:535: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_float64_data</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408acf40>

    def test_roundtrip_float64_data(self) -> None:
        expected = Dataset({"x": ("y", np.array([1.0, 2.0, np.pi], dtype="float64"))})
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:578: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_cftime_datetime_data</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69cde10>

    @requires_cftime
    def test_roundtrip_cftime_datetime_data(self) -> None:
        from xarray.tests.test_coding_times import _all_cftime_date_types

        date_types = _all_cftime_date_types()
        for date_type in date_types.values():
            times = [date_type(1, 1, 1), date_type(1, 1, 2)]
            expected = Dataset({"t": ("t", times), "t0": times[0]})
            kwargs = {"encoding": {"t0": {"units": "days since 0001-01-01"}}}
            expected_decoded_t = np.array(times)
            expected_decoded_t0 = np.array([date_type(1, 1, 1)])
            expected_calendar = times[0].calendar

            with warnings.catch_warnings():
                if expected_calendar in {"proleptic_gregorian", "standard"}:
                    warnings.filterwarnings("ignore", "Unable to decode time axis")

>               with self.roundtrip(expected, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:556: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_example_1_netcdf</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408ad360>

    def test_roundtrip_example_1_netcdf(self) -> None:
        with open_example_dataset("example_1.nc") as expected:
>           with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:583: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:257: in set_dimension
    self.ds.dimensions[name] = None
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_timedelta_data</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69ce230>

    def test_roundtrip_timedelta_data(self) -> None:
        time_deltas = pd.to_timedelta(["1h", "2h", "NaT"])  # type: ignore[arg-type]  #https://github.com/pandas-dev/pandas-stubs/issues/956
        expected = Dataset({"td": ("td", time_deltas), "td0": time_deltas[0]})
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:573: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_coordinates</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408ad570>

    def test_roundtrip_coordinates(self) -> None:
        original = Dataset(
            {"foo": ("x", [0, 1])}, {"x": [2, 3], "y": ("a", [42]), "z": ("x", [4, 5])}
        )

>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:595: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_float64_data</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69ce9e0>

    def test_roundtrip_float64_data(self) -> None:
        expected = Dataset({"x": ("y", np.array([1.0, 2.0, np.pi], dtype="float64"))})
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:578: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_global_coordinates</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408ad900>

    def test_roundtrip_global_coordinates(self) -> None:
        original = Dataset(
            {"foo": ("x", [0, 1])}, {"x": [2, 3], "y": ("a", [42]), "z": ("x", [4, 5])}
        )
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:610: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_boolean_dtype</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408ade40>

    def test_roundtrip_boolean_dtype(self) -> None:
        original = create_boolean_data()
        assert original["x"].dtype == "bool"
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_example_1_netcdf</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69cec20>

    def test_roundtrip_example_1_netcdf(self) -> None:
        with open_example_dataset("example_1.nc") as expected:
>           with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:583: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:257: in set_dimension
    self.ds.dimensions[name] = None
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_coordinates</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69cf010>

    def test_roundtrip_coordinates(self) -> None:
        original = Dataset(
            {"foo": ("x", [0, 1])}, {"x": [2, 3], "y": ("a", [42]), "z": ("x", [4, 5])}
        )

>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:595: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_orthogonal_indexing</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408ae200>

    def test_orthogonal_indexing(self) -> None:
        in_memory = create_test_data()
>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_global_coordinates</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69cf370>

    def test_roundtrip_global_coordinates(self) -> None:
        original = Dataset(
            {"foo": ("x", [0, 1])}, {"x": [2, 3], "y": ("a", [42]), "z": ("x", [4, 5])}
        )
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:610: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_vectorized_indexing</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408ae380>

    def test_vectorized_indexing(self) -> None:
        in_memory = create_test_data()
>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:658: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_boolean_dtype</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6903130>

    def test_roundtrip_boolean_dtype(self) -> None:
        original = create_boolean_data()
        assert original["x"].dtype == "bool"
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_vectorized_indexing_negative_step</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408ae6e0>

    def test_vectorized_indexing_negative_step(self) -> None:
        # use dask explicitly when present
        open_kwargs: dict[str, Any] | None
        if has_dask:
            open_kwargs = {"chunks": {}}
        else:
            open_kwargs = None
        in_memory = create_test_data()

        def multiple_indexing(indexers):
            # make sure a sequence of lazy indexings certainly works.
            with self.roundtrip(in_memory, open_kwargs=open_kwargs) as on_disk:
                actual = on_disk["var3"]
                expected = in_memory["var3"]
                for ind in indexers:
                    actual = actual.isel(ind)
                    expected = expected.isel(ind)
                    # make sure the array is not yet loaded into memory
                    assert not actual.variable._in_memory
                assert_identical(expected, actual.load())

        # with negative step slice.
        indexers = [
            {
                "dim1": DataArray([[0, 7], [2, 6], [3, 5]], dims=["a", "b"]),
                "dim3": slice(-1, 1, -1),
            }
        ]
>       multiple_indexing(indexers)

/testbed/xarray/tests/test_backends.py:748: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/tests/test_backends.py:731: in multiple_indexing
    with self.roundtrip(in_memory, open_kwargs=open_kwargs) as on_disk:
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_orthogonal_indexing</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6902200>

    def test_orthogonal_indexing(self) -> None:
        in_memory = create_test_data()
>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_outer_indexing_reversed</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408ae890>

    def test_outer_indexing_reversed(self) -> None:
        # regression test for GH6560
        ds = xr.Dataset(
            {"z": (("t", "p", "y", "x"), np.ones((1, 1, 31, 40)))},
        )

>       with self.roundtrip(ds) as on_disk:

/testbed/xarray/tests/test_backends.py:765: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_vectorized_indexing</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69ceec0>

    def test_vectorized_indexing(self) -> None:
        in_memory = create_test_data()
>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:658: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_isel_dataarray</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408aeb90>

    def test_isel_dataarray(self) -> None:
        # Make sure isel works lazily. GH:issue:1688
        in_memory = create_test_data()
>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:772: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_array_type_after_indexing</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408ae590>

    def test_array_type_after_indexing(self) -> None:
        in_memory = create_test_data()
>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:799: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_vectorized_indexing_negative_step</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69cd990>

    def test_vectorized_indexing_negative_step(self) -> None:
        # use dask explicitly when present
        open_kwargs: dict[str, Any] | None
        if has_dask:
            open_kwargs = {"chunks": {}}
        else:
            open_kwargs = None
        in_memory = create_test_data()

        def multiple_indexing(indexers):
            # make sure a sequence of lazy indexings certainly works.
            with self.roundtrip(in_memory, open_kwargs=open_kwargs) as on_disk:
                actual = on_disk["var3"]
                expected = in_memory["var3"]
                for ind in indexers:
                    actual = actual.isel(ind)
                    expected = expected.isel(ind)
                    # make sure the array is not yet loaded into memory
                    assert not actual.variable._in_memory
                assert_identical(expected, actual.load())

        # with negative step slice.
        indexers = [
            {
                "dim1": DataArray([[0, 7], [2, 6], [3, 5]], dims=["a", "b"]),
                "dim3": slice(-1, 1, -1),
            }
        ]
>       multiple_indexing(indexers)

/testbed/xarray/tests/test_backends.py:748: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/tests/test_backends.py:731: in multiple_indexing
    with self.roundtrip(in_memory, open_kwargs=open_kwargs) as on_disk:
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_outer_indexing_reversed</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69cf820>

    def test_outer_indexing_reversed(self) -> None:
        # regression test for GH6560
        ds = xr.Dataset(
            {"z": (("t", "p", "y", "x"), np.ones((1, 1, 31, 40)))},
        )

>       with self.roundtrip(ds) as on_disk:

/testbed/xarray/tests/test_backends.py:765: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_dropna</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408adcc0>

    def test_dropna(self) -> None:
        # regression test for GH:issue:1694
        a = np.random.randn(4, 3)
        a[1, 1] = np.nan
        in_memory = xr.Dataset(
            {"a": (("y", "x"), a)}, coords={"y": np.arange(4), "x": np.arange(3)}
        )

        assert_identical(
            in_memory.dropna(dim="x"), in_memory.isel(x=slice(None, None, 2))
        )

>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:824: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_isel_dataarray</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69cfb80>

    def test_isel_dataarray(self) -> None:
        # Make sure isel works lazily. GH:issue:1688
        in_memory = create_test_data()
>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:772: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_ondisk_after_print</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4408ad000>

    def test_ondisk_after_print(self) -> None:
        """Make sure print does not load file into memory"""
        in_memory = create_test_data()
>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:833: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_bytes_with_fill_value</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409dd960>

    def test_roundtrip_bytes_with_fill_value(self) -> None:
        values = np.array([b"ab", b"cdef", np.nan], dtype=object)
        encoding = {"_FillValue": b"X", "dtype": "S1"}
        original = Dataset({"x": ("t", values, {}, encoding)})
        expected = original.copy(deep=True)
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:844: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_array_type_after_indexing</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69cfe50>

    def test_array_type_after_indexing(self) -> None:
        in_memory = create_test_data()
>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:799: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_dropna</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69cd840>

    def test_dropna(self) -> None:
        # regression test for GH:issue:1694
        a = np.random.randn(4, 3)
        a[1, 1] = np.nan
        in_memory = xr.Dataset(
            {"a": (("y", "x"), a)}, coords={"y": np.arange(4), "x": np.arange(3)}
        )

        assert_identical(
            in_memory.dropna(dim="x"), in_memory.isel(x=slice(None, None, 2))
        )

>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:824: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_empty_vlen_string_array</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409d6c20>

    def test_roundtrip_empty_vlen_string_array(self) -> None:
        # checks preserving vlen dtype for empty arrays GH7862
        dtype = create_vlen_dtype(str)
        original = Dataset({"a": np.array([], dtype=dtype)})
        assert check_vlen_dtype(original["a"].dtype) is str
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:867: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_mask_and_scale[dtype0-create_unsigned_masked_scaled_data-create_encoded_unsigned_masked_scaled_data]</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409dcc10>
decoded_fn = <function create_unsigned_masked_scaled_data at 0x77d441682c20>
encoded_fn = <function create_encoded_unsigned_masked_scaled_data at 0x77d441682cb0>
dtype = dtype('float64')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_ondisk_after_print</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69cd4e0>

    def test_ondisk_after_print(self) -> None:
        """Make sure print does not load file into memory"""
        in_memory = create_test_data()
>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:833: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_bytes_with_fill_value</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68c9a20>

    def test_roundtrip_bytes_with_fill_value(self) -> None:
        values = np.array([b"ab", b"cdef", np.nan], dtype=object)
        encoding = {"_FillValue": b"X", "dtype": "S1"}
        original = Dataset({"x": ("t", values, {}, encoding)})
        expected = original.copy(deep=True)
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:844: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_mask_and_scale[dtype0-create_signed_masked_scaled_data-create_encoded_signed_masked_scaled_data]</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409ddba0>
decoded_fn = <function create_signed_masked_scaled_data at 0x77d441682e60>
encoded_fn = <function create_encoded_signed_masked_scaled_data at 0x77d441682ef0>
dtype = dtype('float64')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_empty_vlen_string_array</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68c9ea0>

    def test_roundtrip_empty_vlen_string_array(self) -> None:
        # checks preserving vlen dtype for empty arrays GH7862
        dtype = create_vlen_dtype(str)
        original = Dataset({"a": np.array([], dtype=dtype)})
        assert check_vlen_dtype(original["a"].dtype) is str
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:867: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_mask_and_scale[dtype0-create_masked_and_scaled_data-create_encoded_masked_and_scaled_data]</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409ddc60>
decoded_fn = <function create_masked_and_scaled_data at 0x77d441682b00>
encoded_fn = <function create_encoded_masked_and_scaled_data at 0x77d441682b90>
dtype = dtype('float64')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_mask_and_scale[dtype0-create_unsigned_masked_scaled_data-create_encoded_unsigned_masked_scaled_data]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68ca3e0>
decoded_fn = <function create_unsigned_masked_scaled_data at 0x7f42b692ac20>
encoded_fn = <function create_encoded_unsigned_masked_scaled_data at 0x7f42b692acb0>
dtype = dtype('float64')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_mask_and_scale[dtype1-create_unsigned_masked_scaled_data-create_encoded_unsigned_masked_scaled_data]</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409ddd20>
decoded_fn = <function create_unsigned_masked_scaled_data at 0x77d441682c20>
encoded_fn = <function create_encoded_unsigned_masked_scaled_data at 0x77d441682cb0>
dtype = dtype('float32')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_mask_and_scale[dtype0-create_signed_masked_scaled_data-create_encoded_signed_masked_scaled_data]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68ca8c0>
decoded_fn = <function create_signed_masked_scaled_data at 0x7f42b692ae60>
encoded_fn = <function create_encoded_signed_masked_scaled_data at 0x7f42b692aef0>
dtype = dtype('float64')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_mask_and_scale[dtype1-create_signed_masked_scaled_data-create_encoded_signed_masked_scaled_data]</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409ddea0>
decoded_fn = <function create_signed_masked_scaled_data at 0x77d441682e60>
encoded_fn = <function create_encoded_signed_masked_scaled_data at 0x77d441682ef0>
dtype = dtype('float32')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_mask_and_scale[dtype0-create_masked_and_scaled_data-create_encoded_masked_and_scaled_data]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68ca800>
decoded_fn = <function create_masked_and_scaled_data at 0x7f42b692ab00>
encoded_fn = <function create_encoded_masked_and_scaled_data at 0x7f42b692ab90>
dtype = dtype('float64')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_mask_and_scale[dtype1-create_masked_and_scaled_data-create_encoded_masked_and_scaled_data]</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409ddf60>
decoded_fn = <function create_masked_and_scaled_data at 0x77d441682b00>
encoded_fn = <function create_encoded_masked_and_scaled_data at 0x77d441682b90>
dtype = dtype('float32')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_mask_and_scale[dtype1-create_unsigned_masked_scaled_data-create_encoded_unsigned_masked_scaled_data]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68caad0>
decoded_fn = <function create_unsigned_masked_scaled_data at 0x7f42b692ac20>
encoded_fn = <function create_encoded_unsigned_masked_scaled_data at 0x7f42b692acb0>
dtype = dtype('float32')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_unsigned[fillvalue0]</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409de200>
fillvalue = np.int8(-1)

    @pytest.mark.parametrize("fillvalue", [np.int8(-1), np.uint8(255), -1, 255])
    def test_roundtrip_unsigned(self, fillvalue):
        # regression/numpy2 test for
        encoding = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
            "dtype": "i1",
        }
        x = np.array([0, 1, 127, 128, 254, np.nan], dtype=np.float32)
        decoded = Dataset({"x": ("t", x, {}, encoding)})

        attributes = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
        }
        # Create unsigned data corresponding to [0, 1, 127, 128, 255] unsigned
        sb = np.asarray([0, 1, 127, -128, -2, -1], dtype="i1")
        encoded = Dataset({"x": ("t", sb, attributes)})

>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:947: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_mask_and_scale[dtype1-create_signed_masked_scaled_data-create_encoded_signed_masked_scaled_data]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68cac20>
decoded_fn = <function create_signed_masked_scaled_data at 0x7f42b692ae60>
encoded_fn = <function create_encoded_signed_masked_scaled_data at 0x7f42b692aef0>
dtype = dtype('float32')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_unsigned[fillvalue1]</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409de2c0>
fillvalue = np.uint8(255)

    @pytest.mark.parametrize("fillvalue", [np.int8(-1), np.uint8(255), -1, 255])
    def test_roundtrip_unsigned(self, fillvalue):
        # regression/numpy2 test for
        encoding = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
            "dtype": "i1",
        }
        x = np.array([0, 1, 127, 128, 254, np.nan], dtype=np.float32)
        decoded = Dataset({"x": ("t", x, {}, encoding)})

        attributes = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
        }
        # Create unsigned data corresponding to [0, 1, 127, 128, 255] unsigned
        sb = np.asarray([0, 1, 127, -128, -2, -1], dtype="i1")
        encoded = Dataset({"x": ("t", sb, attributes)})

>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:947: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_unsigned[-1]</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409de500>
fillvalue = -1

    @pytest.mark.parametrize("fillvalue", [np.int8(-1), np.uint8(255), -1, 255])
    def test_roundtrip_unsigned(self, fillvalue):
        # regression/numpy2 test for
        encoding = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
            "dtype": "i1",
        }
        x = np.array([0, 1, 127, 128, 254, np.nan], dtype=np.float32)
        decoded = Dataset({"x": ("t", x, {}, encoding)})

        attributes = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
        }
        # Create unsigned data corresponding to [0, 1, 127, 128, 255] unsigned
        sb = np.asarray([0, 1, 127, -128, -2, -1], dtype="i1")
        encoded = Dataset({"x": ("t", sb, attributes)})

>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:947: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_mask_and_scale[dtype1-create_masked_and_scaled_data-create_encoded_masked_and_scaled_data]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68cae90>
decoded_fn = <function create_masked_and_scaled_data at 0x7f42b692ab00>
encoded_fn = <function create_encoded_masked_and_scaled_data at 0x7f42b692ab90>
dtype = dtype('float32')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_unsigned[255]</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409de5c0>
fillvalue = 255

    @pytest.mark.parametrize("fillvalue", [np.int8(-1), np.uint8(255), -1, 255])
    def test_roundtrip_unsigned(self, fillvalue):
        # regression/numpy2 test for
        encoding = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
            "dtype": "i1",
        }
        x = np.array([0, 1, 127, 128, 254, np.nan], dtype=np.float32)
        decoded = Dataset({"x": ("t", x, {}, encoding)})

        attributes = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
        }
        # Create unsigned data corresponding to [0, 1, 127, 128, 255] unsigned
        sb = np.asarray([0, 1, 127, -128, -2, -1], dtype="i1")
        encoded = Dataset({"x": ("t", sb, attributes)})

>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:947: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_unsigned[fillvalue0]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68cb0a0>
fillvalue = np.int8(-1)

    @pytest.mark.parametrize("fillvalue", [np.int8(-1), np.uint8(255), -1, 255])
    def test_roundtrip_unsigned(self, fillvalue):
        # regression/numpy2 test for
        encoding = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
            "dtype": "i1",
        }
        x = np.array([0, 1, 127, 128, 254, np.nan], dtype=np.float32)
        decoded = Dataset({"x": ("t", x, {}, encoding)})

        attributes = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
        }
        # Create unsigned data corresponding to [0, 1, 127, 128, 255] unsigned
        sb = np.asarray([0, 1, 127, -128, -2, -1], dtype="i1")
        encoded = Dataset({"x": ("t", sb, attributes)})

>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:947: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_unsigned[fillvalue1]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68cb1f0>
fillvalue = np.uint8(255)

    @pytest.mark.parametrize("fillvalue", [np.int8(-1), np.uint8(255), -1, 255])
    def test_roundtrip_unsigned(self, fillvalue):
        # regression/numpy2 test for
        encoding = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
            "dtype": "i1",
        }
        x = np.array([0, 1, 127, 128, 254, np.nan], dtype=np.float32)
        decoded = Dataset({"x": ("t", x, {}, encoding)})

        attributes = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
        }
        # Create unsigned data corresponding to [0, 1, 127, 128, 255] unsigned
        sb = np.asarray([0, 1, 127, -128, -2, -1], dtype="i1")
        encoded = Dataset({"x": ("t", sb, attributes)})

>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:947: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_coordinate_variables_after_dataset_roundtrip</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409dea70>

    def test_coordinate_variables_after_dataset_roundtrip(self) -> None:
        original = self._create_cf_dataset()
>       with self.roundtrip(original, open_kwargs={"decode_coords": "all"}) as actual:

/testbed/xarray/tests/test_backends.py:1023: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_grid_mapping_and_bounds_are_coordinates_after_dataarray_roundtrip</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409dece0>

    def test_grid_mapping_and_bounds_are_coordinates_after_dataarray_roundtrip(
        self,
    ) -> None:
        original = self._create_cf_dataset()
        # The DataArray roundtrip should have the same warnings as the
        # Dataset, but we already tested for those, so just go for the
        # new warnings.  It would appear that there is no way to tell
        # pytest "This warning and also this warning should both be
        # present".
        # xarray/tests/test_conventions.py::TestCFEncodedDataStore
        # needs the to_dataset. The other backends should be fine
        # without it.
        with pytest.warns(
            UserWarning,
            match=(
                r"Variable\(s\) referenced in bounds not in variables: "
                r"\['l(at|ong)itude_bnds'\]"
            ),
        ):
>           with self.roundtrip(
                original["variable"].to_dataset(), open_kwargs={"decode_coords": "all"}
            ) as actual:

/testbed/xarray/tests/test_backends.py:1055: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError

During handling of the above exception, another exception occurred:

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409dece0>

    def test_grid_mapping_and_bounds_are_coordinates_after_dataarray_roundtrip(
        self,
    ) -> None:
        original = self._create_cf_dataset()
        # The DataArray roundtrip should have the same warnings as the
        # Dataset, but we already tested for those, so just go for the
        # new warnings.  It would appear that there is no way to tell
        # pytest "This warning and also this warning should both be
        # present".
        # xarray/tests/test_conventions.py::TestCFEncodedDataStore
        # needs the to_dataset. The other backends should be fine
        # without it.
>       with pytest.warns(
            UserWarning,
            match=(
                r"Variable\(s\) referenced in bounds not in variables: "
                r"\['l(at|ong)itude_bnds'\]"
            ),
        ):
E       Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.
E        Emitted warnings: [].

/testbed/xarray/tests/test_backends.py:1048: Failed
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_unsigned[-1]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68cb370>
fillvalue = -1

    @pytest.mark.parametrize("fillvalue", [np.int8(-1), np.uint8(255), -1, 255])
    def test_roundtrip_unsigned(self, fillvalue):
        # regression/numpy2 test for
        encoding = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
            "dtype": "i1",
        }
        x = np.array([0, 1, 127, 128, 254, np.nan], dtype=np.float32)
        decoded = Dataset({"x": ("t", x, {}, encoding)})

        attributes = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
        }
        # Create unsigned data corresponding to [0, 1, 127, 128, 255] unsigned
        sb = np.asarray([0, 1, 127, -128, -2, -1], dtype="i1")
        encoded = Dataset({"x": ("t", sb, attributes)})

>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:947: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_coordinates_encoding</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409df1c0>

    def test_coordinates_encoding(self) -> None:
        def equals_latlon(obj):
            return obj == "lat lon" or obj == "lon lat"

        original = Dataset(
            {"temp": ("x", [0, 1]), "precip": ("x", [0, -1])},
            {"lat": ("x", [2, 3]), "lon": ("x", [4, 5])},
        )
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:1079: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_unsigned[255]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6877280>
fillvalue = 255

    @pytest.mark.parametrize("fillvalue", [np.int8(-1), np.uint8(255), -1, 255])
    def test_roundtrip_unsigned(self, fillvalue):
        # regression/numpy2 test for
        encoding = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
            "dtype": "i1",
        }
        x = np.array([0, 1, 127, 128, 254, np.nan], dtype=np.float32)
        decoded = Dataset({"x": ("t", x, {}, encoding)})

        attributes = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
        }
        # Create unsigned data corresponding to [0, 1, 127, 128, 255] unsigned
        sb = np.asarray([0, 1, 127, -128, -2, -1], dtype="i1")
        encoded = Dataset({"x": ("t", sb, attributes)})

>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:947: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_roundtrip_endian</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409df430>

    def test_roundtrip_endian(self) -> None:
        ds = Dataset(
            {
                "x": np.arange(3, 10, dtype=">i2"),
                "y": np.arange(3, 20, dtype="<i4"),
                "z": np.arange(3, 30, dtype="=i8"),
                "w": ("x", np.arange(3, 10, dtype=float)),
            }
        )

>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_coordinate_variables_after_dataset_roundtrip</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68c9090>

    def test_coordinate_variables_after_dataset_roundtrip(self) -> None:
        original = self._create_cf_dataset()
>       with self.roundtrip(original, open_kwargs={"decode_coords": "all"}) as actual:

/testbed/xarray/tests/test_backends.py:1023: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_encoding_kwarg</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409df910>

    def test_encoding_kwarg(self) -> None:
        ds = Dataset({"x": ("y", np.arange(10.0))})

        kwargs: dict[str, Any] = dict(encoding={"x": {"dtype": "f4"}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1152: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_grid_mapping_and_bounds_are_coordinates_after_dataarray_roundtrip</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68cb580>

    def test_grid_mapping_and_bounds_are_coordinates_after_dataarray_roundtrip(
        self,
    ) -> None:
        original = self._create_cf_dataset()
        # The DataArray roundtrip should have the same warnings as the
        # Dataset, but we already tested for those, so just go for the
        # new warnings.  It would appear that there is no way to tell
        # pytest "This warning and also this warning should both be
        # present".
        # xarray/tests/test_conventions.py::TestCFEncodedDataStore
        # needs the to_dataset. The other backends should be fine
        # without it.
        with pytest.warns(
            UserWarning,
            match=(
                r"Variable\(s\) referenced in bounds not in variables: "
                r"\['l(at|ong)itude_bnds'\]"
            ),
        ):
>           with self.roundtrip(
                original["variable"].to_dataset(), open_kwargs={"decode_coords": "all"}
            ) as actual:

/testbed/xarray/tests/test_backends.py:1055: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError

During handling of the above exception, another exception occurred:

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68cb580>

    def test_grid_mapping_and_bounds_are_coordinates_after_dataarray_roundtrip(
        self,
    ) -> None:
        original = self._create_cf_dataset()
        # The DataArray roundtrip should have the same warnings as the
        # Dataset, but we already tested for those, so just go for the
        # new warnings.  It would appear that there is no way to tell
        # pytest "This warning and also this warning should both be
        # present".
        # xarray/tests/test_conventions.py::TestCFEncodedDataStore
        # needs the to_dataset. The other backends should be fine
        # without it.
>       with pytest.warns(
            UserWarning,
            match=(
                r"Variable\(s\) referenced in bounds not in variables: "
                r"\['l(at|ong)itude_bnds'\]"
            ),
        ):
E       Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.
E        Emitted warnings: [].

/testbed/xarray/tests/test_backends.py:1048: Failed
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_encoding_kwarg_dates</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409dfb80>

    def test_encoding_kwarg_dates(self) -> None:
        ds = Dataset({"t": pd.date_range("2000-01-01", periods=3)})
        units = "days since 1900-01-01"
        kwargs = dict(encoding={"t": {"units": units}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_coordinates_encoding</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68cbc40>

    def test_coordinates_encoding(self) -> None:
        def equals_latlon(obj):
            return obj == "lat lon" or obj == "lon lat"

        original = Dataset(
            {"temp": ("x", [0, 1]), "precip": ("x", [0, -1])},
            {"lat": ("x", [2, 3]), "lon": ("x", [4, 5])},
        )
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:1079: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_encoding_kwarg_fixed_width_string</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4409dfdf0>

    def test_encoding_kwarg_fixed_width_string(self) -> None:
        # regression test for GH2149
        for strings in [[b"foo", b"bar", b"baz"], ["foo", "bar", "baz"]]:
            ds = Dataset({"x": strings})
            kwargs = dict(encoding={"x": {"dtype": "S1"}})
>           with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1186: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_endian</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68cbf40>

    def test_roundtrip_endian(self) -> None:
        ds = Dataset(
            {
                "x": np.arange(3, 10, dtype=">i2"),
                "y": np.arange(3, 20, dtype="<i4"),
                "z": np.arange(3, 30, dtype="=i8"),
                "w": ("x", np.arange(3, 10, dtype=float)),
            }
        )

>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_default_fill_value</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d4414b71f0>

    def test_default_fill_value(self) -> None:
        # Test default encoding for float:
        ds = Dataset({"x": ("y", np.arange(10.0))})
        kwargs = dict(encoding={"x": {"dtype": "f4"}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1194: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_encoding_kwarg</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6900550>

    def test_encoding_kwarg(self) -> None:
        ds = Dataset({"x": ("y", np.arange(10.0))})

        kwargs: dict[str, Any] = dict(encoding={"x": {"dtype": "f4"}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1152: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFData::test_explicitly_omit_fill_value</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFData object at 0x77d44144fb20>

    def test_explicitly_omit_fill_value(self) -> None:
        ds = Dataset({"x": ("y", [np.pi, -np.pi])})
        ds.x.encoding["_FillValue"] = None
>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1216: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_encoding_kwarg_dates</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6900a00>

    def test_encoding_kwarg_dates(self) -> None:
        ds = Dataset({"t": pd.date_range("2000-01-01", periods=3)})
        units = "days since 1900-01-01"
        kwargs = dict(encoding={"t": {"units": units}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_encoding_kwarg_fixed_width_string</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6900cd0>

    def test_encoding_kwarg_fixed_width_string(self) -> None:
        # regression test for GH2149
        for strings in [[b"foo", b"bar", b"baz"], ["foo", "bar", "baz"]]:
            ds = Dataset({"x": strings})
            kwargs = dict(encoding={"x": {"dtype": "S1"}})
>           with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1186: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_default_fill_value</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6901180>

    def test_default_fill_value(self) -> None:
        # Test default encoding for float:
        ds = Dataset({"x": ("y", np.arange(10.0))})
        kwargs = dict(encoding={"x": {"dtype": "f4"}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1194: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_explicitly_omit_fill_value</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6901420>

    def test_explicitly_omit_fill_value(self) -> None:
        ds = Dataset({"x": ("y", [np.pi, -np.pi])})
        ds.x.encoding["_FillValue"] = None
>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1216: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_explicitly_omit_fill_value_via_encoding_kwarg</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69017b0>

    def test_explicitly_omit_fill_value_via_encoding_kwarg(self) -> None:
        ds = Dataset({"x": ("y", [np.pi, -np.pi])})
        kwargs = dict(encoding={"x": {"_FillValue": None}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_explicitly_omit_fill_value_in_coord</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6901900>

    def test_explicitly_omit_fill_value_in_coord(self) -> None:
        ds = Dataset({"x": ("y", [np.pi, -np.pi])}, coords={"y": [0.0, 1.0]})
        ds.y.encoding["_FillValue"] = None
>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1229: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_explicitly_omit_fill_value_in_coord_via_encoding_kwarg</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6901e70>

    def test_explicitly_omit_fill_value_in_coord_via_encoding_kwarg(self) -> None:
        ds = Dataset({"x": ("y", [np.pi, -np.pi])}, coords={"y": [0.0, 1.0]})
        kwargs = dict(encoding={"y": {"_FillValue": None}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1235: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_encoding_same_dtype</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6901f90>

    def test_encoding_same_dtype(self) -> None:
        ds = Dataset({"x": ("y", np.arange(10.0, dtype="f4"))})
        kwargs = dict(encoding={"x": {"dtype": "f4"}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1242: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_append_write</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69022f0>

    def test_append_write(self) -> None:
        # regression for GH1215
        data = create_test_data()
>       with self.roundtrip_append(data) as actual:

/testbed/xarray/tests/test_backends.py:1251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:330: in roundtrip_append
    self.save(data[[key]], path, mode=mode, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_append_overwrite_values</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6902650>

    def test_append_overwrite_values(self) -> None:
        # regression for GH1215
        data = create_test_data()
        with create_tmp_file(allow_cleanup_failure=False) as tmp_file:
>           self.save(data, tmp_file, mode="w")

/testbed/xarray/tests/test_backends.py:1258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_append_with_invalid_dim_raises</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b69028f0>

    def test_append_with_invalid_dim_raises(self) -> None:
        data = create_test_data()
        with create_tmp_file(allow_cleanup_failure=False) as tmp_file:
>           self.save(data, tmp_file, mode="w")

/testbed/xarray/tests/test_backends.py:1268: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_multiindex_not_implemented</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68c9210>

    def test_multiindex_not_implemented(self) -> None:
        ds = Dataset(coords={"y": ("x", [1, 2]), "z": ("x", ["a", "b"])}).set_index(
            x=["y", "z"]
        )
        with pytest.raises(NotImplementedError, match=r"MultiIndex"):
            with self.roundtrip(ds):
                pass

        # regression GH8628 (can serialize reset multi-index level coordinates)
        ds_reset = ds.reset_index("x")
>       with self.roundtrip(ds_reset) as actual:

/testbed/xarray/tests/test_backends.py:1286: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_refresh_from_disk</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68c9660>

    @pytest.mark.skipif(
        ON_WINDOWS, reason="Windows does not allow modifying open files"
    )
    def test_refresh_from_disk(self) -> None:
        # regression test for https://github.com/pydata/xarray/issues/4862

        with create_tmp_file() as example_1_path:
            with create_tmp_file() as example_1_modified_path:
                with open_example_dataset("example_1.nc") as example_1:
>                   self.save(example_1, example_1_path)

/testbed/xarray/tests/test_backends.py:1302: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:257: in set_dimension
    self.ds.dimensions[name] = None
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_open_group</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6877f40>

    def test_open_group(self) -> None:
        # Create a netCDF file with a dataset stored within a group
        with create_tmp_file() as tmp_file:
            with nc4.Dataset(tmp_file, "w") as rootgrp:
                foogrp = rootgrp.createGroup("foo")
                ds = foogrp
                ds.createDimension("time", size=10)
                x = np.arange(10)
                ds.createVariable("x", np.int32, dimensions=("time",))
                ds.variables["x"][:] = x

            expected = Dataset()
            expected["x"] = ("time", x)

            # check equivalent ways to specify group
            for group in "foo", "/foo", "foo/", "/foo/":
>               with self.open(tmp_file, group=group) as actual:

/testbed/xarray/tests/test_backends.py:1374: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:342: in open
    with open_dataset(path, engine=self.engine, **kwargs) as ds:
/testbed/xarray/backends/api.py:588: in open_dataset
    backend_ds = backend.open_dataset(
/testbed/xarray/backends/h5netcdf_.py:418: in open_dataset
    ds = store_entrypoint.open_dataset(
/testbed/xarray/backends/store.py:43: in open_dataset
    vars, attrs = filename_or_obj.load()
/testbed/xarray/backends/common.py:221: in load
    (_decode_variable_name(k), v) for k, v in self.get_variables().items()
/testbed/xarray/backends/h5netcdf_.py:237: in get_variables
    return FrozenDict(
/testbed/xarray/core/utils.py:436: in FrozenDict
    return Frozen(dict(*args, **kwargs))
/testbed/xarray/backends/h5netcdf_.py:238: in <genexpr>
    (k, self.open_store_variable(k, v)) for k, v in self.ds.variables.items()
/testbed/xarray/backends/h5netcdf_.py:200: in open_store_variable
    dimensions = var.dimensions
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:260: in dimensions
    self._dimensions = self._lookup_dimensions()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:154: in _lookup_dimensions
    if _unlabeled_dimension_mix(self._h5ds) == "labeled":
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in _unlabeled_dimension_mix
    dimset = set([len(j) for j in dimlist])
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in <listcomp>
    dimset = set([len(j) for j in dimlist])
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
/testbed/.venv/lib/python3.10/site-packages/h5py/_hl/dims.py:60: in __len__
    return h5ds.get_num_scales(self._id, self._dimension)
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:72: in h5py.h5ds.get_num_scales
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSget_num_scales (return value <0)

h5py/defs.pyx:4461: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_open_subgroup</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6877220>

    def test_open_subgroup(self) -> None:
        # Create a netCDF file with a dataset stored within a group within a
        # group
        with create_tmp_file() as tmp_file:
            rootgrp = nc4.Dataset(tmp_file, "w")
            foogrp = rootgrp.createGroup("foo")
            bargrp = foogrp.createGroup("bar")
            ds = bargrp
            ds.createDimension("time", size=10)
            x = np.arange(10)
            ds.createVariable("x", np.int32, dimensions=("time",))
            ds.variables["x"][:] = x
            rootgrp.close()

            expected = Dataset()
            expected["x"] = ("time", x)

            # check equivalent ways to specify group
            for group in "foo/bar", "/foo/bar", "foo/bar/", "/foo/bar/":
>               with self.open(tmp_file, group=group) as actual:

/testbed/xarray/tests/test_backends.py:1402: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:342: in open
    with open_dataset(path, engine=self.engine, **kwargs) as ds:
/testbed/xarray/backends/api.py:588: in open_dataset
    backend_ds = backend.open_dataset(
/testbed/xarray/backends/h5netcdf_.py:418: in open_dataset
    ds = store_entrypoint.open_dataset(
/testbed/xarray/backends/store.py:43: in open_dataset
    vars, attrs = filename_or_obj.load()
/testbed/xarray/backends/common.py:221: in load
    (_decode_variable_name(k), v) for k, v in self.get_variables().items()
/testbed/xarray/backends/h5netcdf_.py:237: in get_variables
    return FrozenDict(
/testbed/xarray/core/utils.py:436: in FrozenDict
    return Frozen(dict(*args, **kwargs))
/testbed/xarray/backends/h5netcdf_.py:238: in <genexpr>
    (k, self.open_store_variable(k, v)) for k, v in self.ds.variables.items()
/testbed/xarray/backends/h5netcdf_.py:200: in open_store_variable
    dimensions = var.dimensions
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:260: in dimensions
    self._dimensions = self._lookup_dimensions()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:154: in _lookup_dimensions
    if _unlabeled_dimension_mix(self._h5ds) == "labeled":
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in _unlabeled_dimension_mix
    dimset = set([len(j) for j in dimlist])
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in <listcomp>
    dimset = set([len(j) for j in dimlist])
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
/testbed/.venv/lib/python3.10/site-packages/h5py/_hl/dims.py:60: in __len__
    return h5ds.get_num_scales(self._id, self._dimension)
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:72: in h5py.h5ds.get_num_scales
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSget_num_scales (return value <0)

h5py/defs.pyx:4461: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_write_groups</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6885c30>

    def test_write_groups(self) -> None:
        data1 = create_test_data()
        data2 = data1 * 2
        with create_tmp_file() as tmp_file:
>           self.save(data1, tmp_file, group="data/1")

/testbed/xarray/tests/test_backends.py:1409: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_encoding_kwarg_vlen_string[input_strings0-True]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6884dc0>
input_strings = [b'foo', b'bar', b'baz'], is_bytes = True

    @pytest.mark.parametrize(
        "input_strings, is_bytes",
        [
            ([b"foo", b"bar", b"baz"], True),
            (["foo", "bar", "baz"], False),
            (["foó", "bár", "baź"], False),
        ],
    )
    def test_encoding_kwarg_vlen_string(
        self, input_strings: list[str], is_bytes: bool
    ) -> None:
        original = Dataset({"x": input_strings})

        expected_string = ["foo", "bar", "baz"] if is_bytes else input_strings
        expected = Dataset({"x": expected_string})
        kwargs = dict(encoding={"x": {"dtype": str}})
>       with self.roundtrip(original, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1432: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_encoding_kwarg_vlen_string[input_strings1-False]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68848e0>
input_strings = ['foo', 'bar', 'baz'], is_bytes = False

    @pytest.mark.parametrize(
        "input_strings, is_bytes",
        [
            ([b"foo", b"bar", b"baz"], True),
            (["foo", "bar", "baz"], False),
            (["foó", "bár", "baź"], False),
        ],
    )
    def test_encoding_kwarg_vlen_string(
        self, input_strings: list[str], is_bytes: bool
    ) -> None:
        original = Dataset({"x": input_strings})

        expected_string = ["foo", "bar", "baz"] if is_bytes else input_strings
        expected = Dataset({"x": expected_string})
        kwargs = dict(encoding={"x": {"dtype": str}})
>       with self.roundtrip(original, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1432: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_encoding_kwarg_vlen_string[input_strings2-False]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6885e70>
input_strings = ['foó', 'bár', 'baź'], is_bytes = False

    @pytest.mark.parametrize(
        "input_strings, is_bytes",
        [
            ([b"foo", b"bar", b"baz"], True),
            (["foo", "bar", "baz"], False),
            (["foó", "bár", "baź"], False),
        ],
    )
    def test_encoding_kwarg_vlen_string(
        self, input_strings: list[str], is_bytes: bool
    ) -> None:
        original = Dataset({"x": input_strings})

        expected_string = ["foo", "bar", "baz"] if is_bytes else input_strings
        expected = Dataset({"x": expected_string})
        kwargs = dict(encoding={"x": {"dtype": str}})
>       with self.roundtrip(original, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1432: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_string_with_fill_value_vlen[XXX]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68861a0>
fill_value = 'XXX'

    @pytest.mark.parametrize("fill_value", ["XXX", "", "bár"])
    def test_roundtrip_string_with_fill_value_vlen(self, fill_value: str) -> None:
        values = np.array(["ab", "cdef", np.nan], dtype=object)
        expected = Dataset({"x": ("t", values)})

        original = Dataset({"x": ("t", values, {}, {"_FillValue": fill_value})})
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:1443: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_string_with_fill_value_vlen[]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6886320>
fill_value = ''

    @pytest.mark.parametrize("fill_value", ["XXX", "", "bár"])
    def test_roundtrip_string_with_fill_value_vlen(self, fill_value: str) -> None:
        values = np.array(["ab", "cdef", np.nan], dtype=object)
        expected = Dataset({"x": ("t", values)})

        original = Dataset({"x": ("t", values, {}, {"_FillValue": fill_value})})
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:1443: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_string_with_fill_value_vlen[b\xe1r]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68864d0>
fill_value = 'bár'

    @pytest.mark.parametrize("fill_value", ["XXX", "", "bár"])
    def test_roundtrip_string_with_fill_value_vlen(self, fill_value: str) -> None:
        values = np.array(["ab", "cdef", np.nan], dtype=object)
        expected = Dataset({"x": ("t", values)})

        original = Dataset({"x": ("t", values, {}, {"_FillValue": fill_value})})
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:1443: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_roundtrip_character_array</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6886770>

    def test_roundtrip_character_array(self) -> None:
        with create_tmp_file() as tmp_file:
            values = np.array([["a", "b", "c"], ["d", "e", "f"]], dtype="S")

            with nc4.Dataset(tmp_file, mode="w") as nc:
                nc.createDimension("x", 2)
                nc.createDimension("string3", 3)
                v = nc.createVariable("x", np.dtype("S1"), ("x", "string3"))
                v[:] = values

            values = np.array(["abc", "def"], dtype="S")
            expected = Dataset({"x": ("x", values)})
            with open_dataset(tmp_file) as actual:
                assert_identical(expected, actual)
                # regression test for #157
>               with self.roundtrip(actual) as roundtripped:

/testbed/xarray/tests/test_backends.py:1465: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_default_to_char_arrays</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6886a40>

    def test_default_to_char_arrays(self) -> None:
        data = Dataset({"x": np.array(["foo", "zzzz"], dtype="S")})
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1470: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_dump_encodings</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6886ec0>

    def test_dump_encodings(self) -> None:
        # regression test for #709
        ds = Dataset({"x": ("y", np.arange(10.0))})
        kwargs = dict(encoding={"x": {"zlib": True}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1505: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_compression_encoding_legacy</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6887670>

    def test_compression_encoding_legacy(self) -> None:
        data = create_test_data()
        data["var2"].encoding.update(
            {
                "zlib": True,
                "chunksizes": (5, 5),
                "fletcher32": True,
                "shuffle": True,
                "original_shape": data.var2.shape,
            }
        )
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1538: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_encoding_kwarg_compression</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68878b0>

    def test_encoding_kwarg_compression(self) -> None:
        ds = Dataset({"x": np.arange(10.0)})
        encoding = dict(
            dtype="f4",
            zlib=True,
            complevel=9,
            fletcher32=True,
            chunksizes=(5,),
            shuffle=True,
        )
        kwargs = dict(encoding=dict(x=encoding))

>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_keep_chunksizes_if_no_original_shape</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6887a30>

    def test_keep_chunksizes_if_no_original_shape(self) -> None:
        ds = Dataset({"x": [1, 2, 3]})
        chunksizes = (2,)
        ds.variables["x"].encoding = {"chunksizes": chunksizes}

>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1575: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_preferred_chunks_is_present</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6887d60>

    def test_preferred_chunks_is_present(self) -> None:
        ds = Dataset({"x": [1, 2, 3]})
        chunksizes = (2,)
        ds.variables["x"].encoding = {"chunksizes": chunksizes}

>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1586: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_auto_chunking_is_based_on_disk_chunk_sizes</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68c8040>

    @requires_dask
    def test_auto_chunking_is_based_on_disk_chunk_sizes(self) -> None:
        x_size = y_size = 1000
        y_chunksize = y_size
        x_chunksize = 10

        with dask.config.set({"array.chunk-size": "100KiB"}):
>           with self.chunked_roundtrip(
                (1, y_size, x_size),
                (1, y_chunksize, x_chunksize),
                open_kwargs={"chunks": "auto"},
            ) as ds:

/testbed/xarray/tests/test_backends.py:1596: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:1641: in chunked_roundtrip
    with self.roundtrip(dataset, open_kwargs=open_kwargs) as ds:
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_base_chunking_uses_disk_chunk_sizes</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68c8340>

    @requires_dask
    def test_base_chunking_uses_disk_chunk_sizes(self) -> None:
        x_size = y_size = 1000
        y_chunksize = y_size
        x_chunksize = 10

>       with self.chunked_roundtrip(
            (1, y_size, x_size),
            (1, y_chunksize, x_chunksize),
            open_kwargs={"chunks": {}},
        ) as ds:

/testbed/xarray/tests/test_backends.py:1612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:1641: in chunked_roundtrip
    with self.roundtrip(dataset, open_kwargs=open_kwargs) as ds:
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_preferred_chunks_are_disk_chunk_sizes</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68c8730>

    def test_preferred_chunks_are_disk_chunk_sizes(self) -> None:
        x_size = y_size = 1000
        y_chunksize = y_size
        x_chunksize = 10

>       with self.chunked_roundtrip(
            (1, y_size, x_size), (1, y_chunksize, x_chunksize)
        ) as ds:

/testbed/xarray/tests/test_backends.py:1649: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:1641: in chunked_roundtrip
    with self.roundtrip(dataset, open_kwargs=open_kwargs) as ds:
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_encoding_chunksizes_unlimited</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6887cd0>

    def test_encoding_chunksizes_unlimited(self) -> None:
        # regression test for GH1225
        ds = Dataset({"x": [1, 2, 3], "y": ("x", [2, 3, 4])})
        ds.variables["x"].encoding = {
            "zlib": False,
            "shuffle": False,
            "complevel": 0,
            "fletcher32": False,
            "contiguous": False,
            "chunksizes": (2**20,),
            "original_shape": (3,),
        }
>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1670: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_raise_on_forward_slashes_in_names</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68c8b20>

    def test_raise_on_forward_slashes_in_names(self) -> None:
        # test for forward slash in variable names and dimensions
        # see GH 7943
        data_vars: list[dict[str, Any]] = [
            {"PASS/FAIL": (["PASSFAIL"], np.array([0]))},
            {"PASS/FAIL": np.array([0])},
            {"PASSFAIL": (["PASS/FAIL"], np.array([0]))},
        ]
        for dv in data_vars:
            ds = Dataset(data_vars=dv)
            with pytest.raises(ValueError, match="Forward slashes '/' are not allowed"):
>               with self.roundtrip(ds):

/testbed/xarray/tests/test_backends.py:1746: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_encoding_enum__no_fill_value</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68c8fd0>

    @requires_netCDF4
    def test_encoding_enum__no_fill_value(self):
        with create_tmp_file() as tmp_file:
            cloud_type_dict = {"clear": 0, "cloudy": 1}
            with nc4.Dataset(tmp_file, mode="w") as nc:
                nc.createDimension("time", size=2)
                cloud_type = nc.createEnumType("u1", "cloud_type", cloud_type_dict)
                v = nc.createVariable(
                    "clouds",
                    cloud_type,
                    "time",
                    fill_value=None,
                )
                v[:] = 1
            with open_dataset(tmp_file) as original:
                save_kwargs = {}
                if self.engine == "h5netcdf":
                    save_kwargs["invalid_netcdf"] = True
>               with self.roundtrip(original, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1767: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_encoding_enum__multiple_variable_with_enum</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68c90c0>

    @requires_netCDF4
    def test_encoding_enum__multiple_variable_with_enum(self):
        with create_tmp_file() as tmp_file:
            cloud_type_dict = {"clear": 0, "cloudy": 1, "missing": 255}
            with nc4.Dataset(tmp_file, mode="w") as nc:
                nc.createDimension("time", size=2)
                cloud_type = nc.createEnumType("u1", "cloud_type", cloud_type_dict)
                nc.createVariable(
                    "clouds",
                    cloud_type,
                    "time",
                    fill_value=255,
                )
                nc.createVariable(
                    "tifa",
                    cloud_type,
                    "time",
                    fill_value=255,
                )
            with open_dataset(tmp_file) as original:
                save_kwargs = {}
                if self.engine == "h5netcdf":
                    save_kwargs["invalid_netcdf"] = True
>               with self.roundtrip(original, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1803: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_complex</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6877d90>

    def test_complex(self) -> None:
        expected = Dataset({"x": ("y", np.ones(5) + 1j * np.ones(5))})
        save_kwargs = {"invalid_netcdf": True}
        with pytest.warns(UserWarning, match="You are writing invalid netcdf features"):
>           with self.roundtrip(expected, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:3599: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_complex_error[None]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68841c0>
invalid_netcdf = None

    @pytest.mark.parametrize("invalid_netcdf", [None, False])
    def test_complex_error(self, invalid_netcdf) -> None:
        import h5netcdf

        expected = Dataset({"x": ("y", np.ones(5) + 1j * np.ones(5))})
        save_kwargs = {"invalid_netcdf": invalid_netcdf}
        with pytest.raises(
            h5netcdf.CompatibilityError, match="are not a supported NetCDF feature"
        ):
>           with self.roundtrip(expected, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:3611: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_complex_error[False]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68842e0>
invalid_netcdf = False

    @pytest.mark.parametrize("invalid_netcdf", [None, False])
    def test_complex_error(self, invalid_netcdf) -> None:
        import h5netcdf

        expected = Dataset({"x": ("y", np.ones(5) + 1j * np.ones(5))})
        save_kwargs = {"invalid_netcdf": invalid_netcdf}
        with pytest.raises(
            h5netcdf.CompatibilityError, match="are not a supported NetCDF feature"
        ):
>           with self.roundtrip(expected, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:3611: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_numpy_bool_</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6884760>

    def test_numpy_bool_(self) -> None:
        # h5netcdf loads booleans as numpy.bool_, this type needs to be supported
        # when writing invalid_netcdf datasets in order to support a roundtrip
        expected = Dataset({"x": ("y", np.ones(5), {"numpy_bool": np.bool_(True)})})
        save_kwargs = {"invalid_netcdf": True}
        with pytest.warns(UserWarning, match="You are writing invalid netcdf features"):
>           with self.roundtrip(expected, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:3620: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_cross_engine_read_write_netcdf4</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6884a30>

    def test_cross_engine_read_write_netcdf4(self) -> None:
        # Drop dim3, because its labels include strings. These appear to be
        # not properly read with python-netCDF4, which converts them into
        # unicode instead of leaving them as bytes.
        data = create_test_data().drop_vars("dim3")
        data.attrs["foo"] = "bar"
        valid_engines: list[T_NetcdfEngine] = ["netcdf4", "h5netcdf"]
        for write_engine in valid_engines:
            with create_tmp_file() as tmp_file:
                data.to_netcdf(tmp_file, engine=write_engine)
                for read_engine in valid_engines:
>                   with open_dataset(tmp_file, engine=read_engine) as actual:

/testbed/xarray/tests/test_backends.py:3634: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/backends/api.py:588: in open_dataset
    backend_ds = backend.open_dataset(
/testbed/xarray/backends/h5netcdf_.py:418: in open_dataset
    ds = store_entrypoint.open_dataset(
/testbed/xarray/backends/store.py:43: in open_dataset
    vars, attrs = filename_or_obj.load()
/testbed/xarray/backends/common.py:221: in load
    (_decode_variable_name(k), v) for k, v in self.get_variables().items()
/testbed/xarray/backends/h5netcdf_.py:237: in get_variables
    return FrozenDict(
/testbed/xarray/core/utils.py:436: in FrozenDict
    return Frozen(dict(*args, **kwargs))
/testbed/xarray/backends/h5netcdf_.py:238: in <genexpr>
    (k, self.open_store_variable(k, v)) for k, v in self.ds.variables.items()
/testbed/xarray/backends/h5netcdf_.py:200: in open_store_variable
    dimensions = var.dimensions
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:260: in dimensions
    self._dimensions = self._lookup_dimensions()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:154: in _lookup_dimensions
    if _unlabeled_dimension_mix(self._h5ds) == "labeled":
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in _unlabeled_dimension_mix
    dimset = set([len(j) for j in dimlist])
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in <listcomp>
    dimset = set([len(j) for j in dimlist])
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
/testbed/.venv/lib/python3.10/site-packages/h5py/_hl/dims.py:60: in __len__
    return h5ds.get_num_scales(self._id, self._dimension)
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:72: in h5py.h5ds.get_num_scales
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSget_num_scales (return value <0)

h5py/defs.pyx:4461: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_encoding_unlimited_dims</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6884f70>

    def test_encoding_unlimited_dims(self) -> None:
        ds = Dataset({"x": ("y", np.arange(10.0))})
>       with self.roundtrip(ds, save_kwargs=dict(unlimited_dims=["y"])) as actual:

/testbed/xarray/tests/test_backends.py:3647: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:257: in set_dimension
    self.ds.dimensions[name] = None
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_dask.py::test_map_blocks_da_ds_with_template[obj0]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

obj = <xarray.DataArray 'a' (x: 10, y: 20)> Size: 2kB
dask.array<xarray-<this-array>, shape=(10, 20), dtype=float64, chunksi...=np.ndarray>
    cxy      (x, y) int64 2kB dask.array<chunksize=(4, 5), meta=np.ndarray>
Attributes:
    test:     test

    @pytest.mark.parametrize("obj", [make_da(), make_ds()])
    def test_map_blocks_da_ds_with_template(obj):
        func = lambda x: x.isel(x=[1])
        template = obj.isel(x=[1, 5, 9])
        with raise_if_dask_computes():
>           actual = xr.map_blocks(func, obj, template=template)

/testbed/xarray/tests/test_dask.py:1369: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

func = <function test_map_blocks_da_ds_with_template.<locals>.<lambda> at 0x79d75a179360>
obj = <xarray.DataArray 'a' (x: 10, y: 20)> Size: 2kB
dask.array<xarray-<this-array>, shape=(10, 20), dtype=float64, chunksi...=np.ndarray>
    cxy      (x, y) int64 2kB dask.array<chunksize=(4, 5), meta=np.ndarray>
Attributes:
    test:     test
args = (), kwargs = {}
template = <xarray.DataArray 'a' (x: 3, y: 20)> Size: 480B
dask.array<getitem, shape=(3, 20), dtype=float64, chunksize=(3, 5), ch...np.ndarray>
    cxy      (x, y) int64 480B dask.array<chunksize=(3, 5), meta=np.ndarray>
Attributes:
    test:     test

    def map_blocks(
        func: Callable[..., T_Xarray],
        obj: DataArray | Dataset,
        args: Sequence[Any] = (),
        kwargs: Mapping[str, Any] | None = None,
        template: DataArray | Dataset | None = None,
    ) -> T_Xarray:
        """Apply a function to each block of a DataArray or Dataset.

        .. warning::
            This function is experimental and its signature may change.

        Parameters
        ----------
        func : callable
            User-provided function that accepts a DataArray or Dataset as its first
            parameter ``obj``. The function will receive a subset or 'block' of ``obj`` (see below),
            corresponding to one chunk along each chunked dimension. ``func`` will be
            executed as ``func(subset_obj, *subset_args, **kwargs)``.

            This function must return either a single DataArray or a single Dataset.

            This function cannot add a new chunked dimension.
        obj : DataArray, Dataset
            Passed to the function as its first argument, one block at a time.
        args : sequence
            Passed to func after unpacking and subsetting any xarray objects by blocks.
            xarray objects in args must be aligned with obj, otherwise an error is raised.
        kwargs : mapping
            Passed verbatim to func after unpacking. xarray objects, if any, will not be
            subset to blocks. Passing dask collections in kwargs is not allowed.
        template : DataArray or Dataset, optional
            xarray object representing the final result after compute is called. If not provided,
            the function will be first run on mocked-up data, that looks like ``obj`` but
            has sizes 0, to determine properties of the returned object such as dtype,
            variable names, attributes, new dimensions and new indexes (if any).
            ``template`` must be provided if the function changes the size of existing dimensions.
            When provided, ``attrs`` on variables in `template` are copied over to the result. Any
            ``attrs`` set by ``func`` will be ignored.

        Returns
        -------
        obj : same as obj
            A single DataArray or Dataset with dask backend, reassembled from the outputs of the
            function.

        Notes
        -----
        This function is designed for when ``func`` needs to manipulate a whole xarray object
        subset to each block. Each block is loaded into memory. In the more common case where
        ``func`` can work on numpy arrays, it is recommended to use ``apply_ufunc``.

        If none of the variables in ``obj`` is backed by dask arrays, calling this function is
        equivalent to calling ``func(obj, *args, **kwargs)``.

        See Also
        --------
        dask.array.map_blocks, xarray.apply_ufunc, xarray.Dataset.map_blocks
        xarray.DataArray.map_blocks

        Examples
        --------
        Calculate an anomaly from climatology using ``.groupby()``. Using
        ``xr.map_blocks()`` allows for parallel operations with knowledge of ``xarray``,
        its indices, and its methods like ``.groupby()``.

        >>> def calculate_anomaly(da, groupby_type="time.month"):
        ...     gb = da.groupby(groupby_type)
        ...     clim = gb.mean(dim="time")
        ...     return gb - clim
        ...
        >>> time = xr.cftime_range("1990-01", "1992-01", freq="ME")
        >>> month = xr.DataArray(time.month, coords={"time": time}, dims=["time"])
        >>> np.random.seed(123)
        >>> array = xr.DataArray(
        ...     np.random.rand(len(time)),
        ...     dims=["time"],
        ...     coords={"time": time, "month": month},
        ... ).chunk()
        >>> array.map_blocks(calculate_anomaly, template=array).compute()
        <xarray.DataArray (time: 24)> Size: 192B
        array([ 0.12894847,  0.11323072, -0.0855964 , -0.09334032,  0.26848862,
                0.12382735,  0.22460641,  0.07650108, -0.07673453, -0.22865714,
               -0.19063865,  0.0590131 , -0.12894847, -0.11323072,  0.0855964 ,
                0.09334032, -0.26848862, -0.12382735, -0.22460641, -0.07650108,
                0.07673453,  0.22865714,  0.19063865, -0.0590131 ])
        Coordinates:
          * time     (time) object 192B 1990-01-31 00:00:00 ... 1991-12-31 00:00:00
            month    (time) int64 192B 1 2 3 4 5 6 7 8 9 10 ... 3 4 5 6 7 8 9 10 11 12

        Note that one must explicitly use ``args=[]`` and ``kwargs={}`` to pass arguments
        to the function being applied in ``xr.map_blocks()``:

        >>> array.map_blocks(
        ...     calculate_anomaly,
        ...     kwargs={"groupby_type": "time.year"},
        ...     template=array,
        ... )  # doctest: +ELLIPSIS
        <xarray.DataArray (time: 24)> Size: 192B
        dask.array<<this-array>-calculate_anomaly, shape=(24,), dtype=float64, chunksize=(24,), chunktype=numpy.ndarray>
        Coordinates:
          * time     (time) object 192B 1990-01-31 00:00:00 ... 1991-12-31 00:00:00
            month    (time) int64 192B dask.array<chunksize=(24,), meta=np.ndarray>
        """

        def _wrapper(
            func: Callable,
            args: list,
            kwargs: dict,
            arg_is_array: Iterable[bool],
            expected: ExpectedDict,
        ):
            """
            Wrapper function that receives datasets in args; converts to dataarrays when necessary;
            passes these to the user function `func` and checks returned objects for expected shapes/sizes/etc.
            """

            converted_args = [
                dataset_to_dataarray(arg) if is_array else arg
                for is_array, arg in zip(arg_is_array, args)
            ]

            result = func(*converted_args, **kwargs)

            merged_coordinates = merge(
                [arg.coords for arg in args if isinstance(arg, (Dataset, DataArray))]
            ).coords

            # check all dims are present
            missing_dimensions = set(expected["shapes"]) - set(result.sizes)
            if missing_dimensions:
                raise ValueError(
                    f"Dimensions {missing_dimensions} missing on returned object."
                )

            # check that index lengths and values are as expected
            for name, index in result._indexes.items():
                if name in expected["shapes"]:
                    if result.sizes[name] != expected["shapes"][name]:
                        raise ValueError(
                            f"Received dimension {name!r} of length {result.sizes[name]}. "
                            f"Expected length {expected['shapes'][name]}."
                        )

                # ChainMap wants MutableMapping, but xindexes is Mapping
                merged_indexes = collections.ChainMap(
                    expected["indexes"], merged_coordinates.xindexes  # type: ignore[arg-type]
                )
                expected_index = merged_indexes.get(name, None)
                if expected_index is not None and not index.equals(expected_index):
                    raise ValueError(
                        f"Expected index {name!r} to be {expected_index!r}. Received {index!r} instead."
                    )

            # check that all expected variables were returned
            check_result_variables(result, expected, "coords")
            if isinstance(result, Dataset):
                check_result_variables(result, expected, "data_vars")

            return make_dict(result)

        if template is not None and not isinstance(template, (DataArray, Dataset)):
            raise TypeError(
                f"template must be a DataArray or Dataset. Received {type(template).__name__} instead."
            )
        if not isinstance(args, Sequence):
            raise TypeError("args must be a sequence (for example, a list or tuple).")
        if kwargs is None:
            kwargs = {}
        elif not isinstance(kwargs, Mapping):
            raise TypeError("kwargs must be a mapping (for example, a dict)")

        for value in kwargs.values():
            if is_dask_collection(value):
                raise TypeError(
                    "Cannot pass dask collections in kwargs yet. Please compute or "
                    "load values before passing to map_blocks."
                )

        if not is_dask_collection(obj):
            return func(obj, *args, **kwargs)

        try:
            import dask
            import dask.array
            from dask.highlevelgraph import HighLevelGraph

        except ImportError:
            pass

        all_args = [obj] + list(args)
        is_xarray = [isinstance(arg, (Dataset, DataArray)) for arg in all_args]
        is_array = [isinstance(arg, DataArray) for arg in all_args]

        # there should be a better way to group this. partition?
        xarray_indices, xarray_objs = unzip(
            (index, arg) for index, arg in enumerate(all_args) if is_xarray[index]
        )
        others = [
            (index, arg) for index, arg in enumerate(all_args) if not is_xarray[index]
        ]

        # all xarray objects must be aligned. This is consistent with apply_ufunc.
        aligned = align(*xarray_objs, join="exact")
        xarray_objs = tuple(
            dataarray_to_dataset(arg) if isinstance(arg, DataArray) else arg
            for arg in aligned
        )
        # rechunk any numpy variables appropriately
        xarray_objs = tuple(arg.chunk(arg.chunksizes) for arg in xarray_objs)

        merged_coordinates = merge([arg.coords for arg in aligned]).coords

        _, npargs = unzip(
            sorted(list(zip(xarray_indices, xarray_objs)) + others, key=lambda x: x[0])
        )

        # check that chunk sizes are compatible
        input_chunks = dict(npargs[0].chunks)
        for arg in xarray_objs[1:]:
            assert_chunks_compatible(npargs[0], arg)
            input_chunks.update(arg.chunks)

        coordinates: Coordinates
        if template is None:
            # infer template by providing zero-shaped arrays
            template = infer_template(func, aligned[0], *args, **kwargs)
            template_coords = set(template.coords)
            preserved_coord_vars = template_coords & set(merged_coordinates)
            new_coord_vars = template_coords - set(merged_coordinates)

            preserved_coords = merged_coordinates.to_dataset()[preserved_coord_vars]
            # preserved_coords contains all coordinates variables that share a dimension
            # with any index variable in preserved_indexes
            # Drop any unneeded vars in a second pass, this is required for e.g.
            # if the mapped function were to drop a non-dimension coordinate variable.
            preserved_coords = preserved_coords.drop_vars(
                tuple(k for k in preserved_coords.variables if k not in template_coords)
            )

            coordinates = merge(
                (preserved_coords, template.coords.to_dataset()[new_coord_vars])
            ).coords
            output_chunks: Mapping[Hashable, tuple[int, ...]] = {
                dim: input_chunks[dim] for dim in template.dims if dim in input_chunks
            }

        else:
            # template xarray object has been provided with proper sizes and chunk shapes
            coordinates = template.coords
            output_chunks = template.chunksizes
            if not output_chunks:
                raise ValueError(
                    "Provided template has no dask arrays. "
                    " Please construct a template with appropriately chunked dask arrays."
                )

        new_indexes = set(template.xindexes) - set(merged_coordinates)
        modified_indexes = set(
            name
            for name, xindex in coordinates.xindexes.items()
            if not xindex.equals(merged_coordinates.xindexes.get(name, None))
        )

        for dim in output_chunks:
            if dim in input_chunks and len(input_chunks[dim]) != len(output_chunks[dim]):
>               raise ValueError(
                    "map_blocks requires that one block of the input maps to one block of output. "
                    f"Expected number of output chunks along dimension {dim!r} to be {len(input_chunks[dim])}. "
                    f"Received {len(output_chunks[dim])} instead. Please provide template if not provided, or "
                    "fix the provided template."
                )
E               ValueError: map_blocks requires that one block of the input maps to one block of output. Expected number of output chunks along dimension 'x' to be 3. Received 1 instead. Please provide template if not provided, or fix the provided template.

/testbed/xarray/core/parallel.py:495: ValueError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_dask.py::test_map_blocks_da_ds_with_template[obj1]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

obj = <xarray.Dataset> Size: 9kB
Dimensions:  (x: 10, y: 20, z: 4)
Coordinates:
  * x        (x) int64 80B 0 1 2 3 4 5 6 7 8...2B 1 1 1 1
    e        (x, y) int64 2kB 100 101 102 103 104 105 ... 124 125 126 127 128
Attributes:
    test:     test

    @pytest.mark.parametrize("obj", [make_da(), make_ds()])
    def test_map_blocks_da_ds_with_template(obj):
        func = lambda x: x.isel(x=[1])
        template = obj.isel(x=[1, 5, 9])
        with raise_if_dask_computes():
>           actual = xr.map_blocks(func, obj, template=template)

/testbed/xarray/tests/test_dask.py:1369: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

func = <function test_map_blocks_da_ds_with_template.<locals>.<lambda> at 0x79d75e5ea170>
obj = <xarray.Dataset> Size: 9kB
Dimensions:  (x: 10, y: 20, z: 4)
Coordinates:
  * x        (x) int64 80B 0 1 2 3 4 5 6 7 8...2B 1 1 1 1
    e        (x, y) int64 2kB 100 101 102 103 104 105 ... 124 125 126 127 128
Attributes:
    test:     test
args = (), kwargs = {}
template = <xarray.Dataset> Size: 3kB
Dimensions:  (x: 3, y: 20, z: 4)
Coordinates:
  * x        (x) int64 24B 1 5 9
  * y       ...B 1 1 1 1
    e        (x, y) int64 480B 101 102 103 104 105 106 ... 124 125 126 127 128
Attributes:
    test:     test

    def map_blocks(
        func: Callable[..., T_Xarray],
        obj: DataArray | Dataset,
        args: Sequence[Any] = (),
        kwargs: Mapping[str, Any] | None = None,
        template: DataArray | Dataset | None = None,
    ) -> T_Xarray:
        """Apply a function to each block of a DataArray or Dataset.

        .. warning::
            This function is experimental and its signature may change.

        Parameters
        ----------
        func : callable
            User-provided function that accepts a DataArray or Dataset as its first
            parameter ``obj``. The function will receive a subset or 'block' of ``obj`` (see below),
            corresponding to one chunk along each chunked dimension. ``func`` will be
            executed as ``func(subset_obj, *subset_args, **kwargs)``.

            This function must return either a single DataArray or a single Dataset.

            This function cannot add a new chunked dimension.
        obj : DataArray, Dataset
            Passed to the function as its first argument, one block at a time.
        args : sequence
            Passed to func after unpacking and subsetting any xarray objects by blocks.
            xarray objects in args must be aligned with obj, otherwise an error is raised.
        kwargs : mapping
            Passed verbatim to func after unpacking. xarray objects, if any, will not be
            subset to blocks. Passing dask collections in kwargs is not allowed.
        template : DataArray or Dataset, optional
            xarray object representing the final result after compute is called. If not provided,
            the function will be first run on mocked-up data, that looks like ``obj`` but
            has sizes 0, to determine properties of the returned object such as dtype,
            variable names, attributes, new dimensions and new indexes (if any).
            ``template`` must be provided if the function changes the size of existing dimensions.
            When provided, ``attrs`` on variables in `template` are copied over to the result. Any
            ``attrs`` set by ``func`` will be ignored.

        Returns
        -------
        obj : same as obj
            A single DataArray or Dataset with dask backend, reassembled from the outputs of the
            function.

        Notes
        -----
        This function is designed for when ``func`` needs to manipulate a whole xarray object
        subset to each block. Each block is loaded into memory. In the more common case where
        ``func`` can work on numpy arrays, it is recommended to use ``apply_ufunc``.

        If none of the variables in ``obj`` is backed by dask arrays, calling this function is
        equivalent to calling ``func(obj, *args, **kwargs)``.

        See Also
        --------
        dask.array.map_blocks, xarray.apply_ufunc, xarray.Dataset.map_blocks
        xarray.DataArray.map_blocks

        Examples
        --------
        Calculate an anomaly from climatology using ``.groupby()``. Using
        ``xr.map_blocks()`` allows for parallel operations with knowledge of ``xarray``,
        its indices, and its methods like ``.groupby()``.

        >>> def calculate_anomaly(da, groupby_type="time.month"):
        ...     gb = da.groupby(groupby_type)
        ...     clim = gb.mean(dim="time")
        ...     return gb - clim
        ...
        >>> time = xr.cftime_range("1990-01", "1992-01", freq="ME")
        >>> month = xr.DataArray(time.month, coords={"time": time}, dims=["time"])
        >>> np.random.seed(123)
        >>> array = xr.DataArray(
        ...     np.random.rand(len(time)),
        ...     dims=["time"],
        ...     coords={"time": time, "month": month},
        ... ).chunk()
        >>> array.map_blocks(calculate_anomaly, template=array).compute()
        <xarray.DataArray (time: 24)> Size: 192B
        array([ 0.12894847,  0.11323072, -0.0855964 , -0.09334032,  0.26848862,
                0.12382735,  0.22460641,  0.07650108, -0.07673453, -0.22865714,
               -0.19063865,  0.0590131 , -0.12894847, -0.11323072,  0.0855964 ,
                0.09334032, -0.26848862, -0.12382735, -0.22460641, -0.07650108,
                0.07673453,  0.22865714,  0.19063865, -0.0590131 ])
        Coordinates:
          * time     (time) object 192B 1990-01-31 00:00:00 ... 1991-12-31 00:00:00
            month    (time) int64 192B 1 2 3 4 5 6 7 8 9 10 ... 3 4 5 6 7 8 9 10 11 12

        Note that one must explicitly use ``args=[]`` and ``kwargs={}`` to pass arguments
        to the function being applied in ``xr.map_blocks()``:

        >>> array.map_blocks(
        ...     calculate_anomaly,
        ...     kwargs={"groupby_type": "time.year"},
        ...     template=array,
        ... )  # doctest: +ELLIPSIS
        <xarray.DataArray (time: 24)> Size: 192B
        dask.array<<this-array>-calculate_anomaly, shape=(24,), dtype=float64, chunksize=(24,), chunktype=numpy.ndarray>
        Coordinates:
          * time     (time) object 192B 1990-01-31 00:00:00 ... 1991-12-31 00:00:00
            month    (time) int64 192B dask.array<chunksize=(24,), meta=np.ndarray>
        """

        def _wrapper(
            func: Callable,
            args: list,
            kwargs: dict,
            arg_is_array: Iterable[bool],
            expected: ExpectedDict,
        ):
            """
            Wrapper function that receives datasets in args; converts to dataarrays when necessary;
            passes these to the user function `func` and checks returned objects for expected shapes/sizes/etc.
            """

            converted_args = [
                dataset_to_dataarray(arg) if is_array else arg
                for is_array, arg in zip(arg_is_array, args)
            ]

            result = func(*converted_args, **kwargs)

            merged_coordinates = merge(
                [arg.coords for arg in args if isinstance(arg, (Dataset, DataArray))]
            ).coords

            # check all dims are present
            missing_dimensions = set(expected["shapes"]) - set(result.sizes)
            if missing_dimensions:
                raise ValueError(
                    f"Dimensions {missing_dimensions} missing on returned object."
                )

            # check that index lengths and values are as expected
            for name, index in result._indexes.items():
                if name in expected["shapes"]:
                    if result.sizes[name] != expected["shapes"][name]:
                        raise ValueError(
                            f"Received dimension {name!r} of length {result.sizes[name]}. "
                            f"Expected length {expected['shapes'][name]}."
                        )

                # ChainMap wants MutableMapping, but xindexes is Mapping
                merged_indexes = collections.ChainMap(
                    expected["indexes"], merged_coordinates.xindexes  # type: ignore[arg-type]
                )
                expected_index = merged_indexes.get(name, None)
                if expected_index is not None and not index.equals(expected_index):
                    raise ValueError(
                        f"Expected index {name!r} to be {expected_index!r}. Received {index!r} instead."
                    )

            # check that all expected variables were returned
            check_result_variables(result, expected, "coords")
            if isinstance(result, Dataset):
                check_result_variables(result, expected, "data_vars")

            return make_dict(result)

        if template is not None and not isinstance(template, (DataArray, Dataset)):
            raise TypeError(
                f"template must be a DataArray or Dataset. Received {type(template).__name__} instead."
            )
        if not isinstance(args, Sequence):
            raise TypeError("args must be a sequence (for example, a list or tuple).")
        if kwargs is None:
            kwargs = {}
        elif not isinstance(kwargs, Mapping):
            raise TypeError("kwargs must be a mapping (for example, a dict)")

        for value in kwargs.values():
            if is_dask_collection(value):
                raise TypeError(
                    "Cannot pass dask collections in kwargs yet. Please compute or "
                    "load values before passing to map_blocks."
                )

        if not is_dask_collection(obj):
            return func(obj, *args, **kwargs)

        try:
            import dask
            import dask.array
            from dask.highlevelgraph import HighLevelGraph

        except ImportError:
            pass

        all_args = [obj] + list(args)
        is_xarray = [isinstance(arg, (Dataset, DataArray)) for arg in all_args]
        is_array = [isinstance(arg, DataArray) for arg in all_args]

        # there should be a better way to group this. partition?
        xarray_indices, xarray_objs = unzip(
            (index, arg) for index, arg in enumerate(all_args) if is_xarray[index]
        )
        others = [
            (index, arg) for index, arg in enumerate(all_args) if not is_xarray[index]
        ]

        # all xarray objects must be aligned. This is consistent with apply_ufunc.
        aligned = align(*xarray_objs, join="exact")
        xarray_objs = tuple(
            dataarray_to_dataset(arg) if isinstance(arg, DataArray) else arg
            for arg in aligned
        )
        # rechunk any numpy variables appropriately
        xarray_objs = tuple(arg.chunk(arg.chunksizes) for arg in xarray_objs)

        merged_coordinates = merge([arg.coords for arg in aligned]).coords

        _, npargs = unzip(
            sorted(list(zip(xarray_indices, xarray_objs)) + others, key=lambda x: x[0])
        )

        # check that chunk sizes are compatible
        input_chunks = dict(npargs[0].chunks)
        for arg in xarray_objs[1:]:
            assert_chunks_compatible(npargs[0], arg)
            input_chunks.update(arg.chunks)

        coordinates: Coordinates
        if template is None:
            # infer template by providing zero-shaped arrays
            template = infer_template(func, aligned[0], *args, **kwargs)
            template_coords = set(template.coords)
            preserved_coord_vars = template_coords & set(merged_coordinates)
            new_coord_vars = template_coords - set(merged_coordinates)

            preserved_coords = merged_coordinates.to_dataset()[preserved_coord_vars]
            # preserved_coords contains all coordinates variables that share a dimension
            # with any index variable in preserved_indexes
            # Drop any unneeded vars in a second pass, this is required for e.g.
            # if the mapped function were to drop a non-dimension coordinate variable.
            preserved_coords = preserved_coords.drop_vars(
                tuple(k for k in preserved_coords.variables if k not in template_coords)
            )

            coordinates = merge(
                (preserved_coords, template.coords.to_dataset()[new_coord_vars])
            ).coords
            output_chunks: Mapping[Hashable, tuple[int, ...]] = {
                dim: input_chunks[dim] for dim in template.dims if dim in input_chunks
            }

        else:
            # template xarray object has been provided with proper sizes and chunk shapes
            coordinates = template.coords
            output_chunks = template.chunksizes
            if not output_chunks:
                raise ValueError(
                    "Provided template has no dask arrays. "
                    " Please construct a template with appropriately chunked dask arrays."
                )

        new_indexes = set(template.xindexes) - set(merged_coordinates)
        modified_indexes = set(
            name
            for name, xindex in coordinates.xindexes.items()
            if not xindex.equals(merged_coordinates.xindexes.get(name, None))
        )

        for dim in output_chunks:
            if dim in input_chunks and len(input_chunks[dim]) != len(output_chunks[dim]):
>               raise ValueError(
                    "map_blocks requires that one block of the input maps to one block of output. "
                    f"Expected number of output chunks along dimension {dim!r} to be {len(input_chunks[dim])}. "
                    f"Received {len(output_chunks[dim])} instead. Please provide template if not provided, or "
                    "fix the provided template."
                )
E               ValueError: map_blocks requires that one block of the input maps to one block of output. Expected number of output chunks along dimension 'x' to be 3. Received 1 instead. Please provide template if not provided, or fix the provided template.

/testbed/xarray/core/parallel.py:495: ValueError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_dask.py::test_map_blocks_template_convert_object</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

    def test_map_blocks_template_convert_object():
        da = make_da()
        func = lambda x: x.to_dataset().isel(x=[1])
        template = da.to_dataset().isel(x=[1, 5, 9])
        with raise_if_dask_computes():
>           actual = xr.map_blocks(func, da, template=template)

/testbed/xarray/tests/test_dask.py:1401: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

func = <function test_map_blocks_template_convert_object.<locals>.<lambda> at 0x79d75e5e92d0>
obj = <xarray.DataArray 'a' (x: 10, y: 20)> Size: 2kB
dask.array<xarray-<this-array>, shape=(10, 20), dtype=float64, chunksi...=np.ndarray>
    cxy      (x, y) int64 2kB dask.array<chunksize=(4, 5), meta=np.ndarray>
Attributes:
    test:     test
args = (), kwargs = {}
template = <xarray.Dataset> Size: 1kB
Dimensions:  (x: 3, y: 20)
Coordinates:
  * x        (x) int64 24B 1 5 9
  * y        (y) i...(3, 5), meta=np.ndarray>
Data variables:
    a        (x, y) float64 480B dask.array<chunksize=(3, 5), meta=np.ndarray>

    def map_blocks(
        func: Callable[..., T_Xarray],
        obj: DataArray | Dataset,
        args: Sequence[Any] = (),
        kwargs: Mapping[str, Any] | None = None,
        template: DataArray | Dataset | None = None,
    ) -> T_Xarray:
        """Apply a function to each block of a DataArray or Dataset.

        .. warning::
            This function is experimental and its signature may change.

        Parameters
        ----------
        func : callable
            User-provided function that accepts a DataArray or Dataset as its first
            parameter ``obj``. The function will receive a subset or 'block' of ``obj`` (see below),
            corresponding to one chunk along each chunked dimension. ``func`` will be
            executed as ``func(subset_obj, *subset_args, **kwargs)``.

            This function must return either a single DataArray or a single Dataset.

            This function cannot add a new chunked dimension.
        obj : DataArray, Dataset
            Passed to the function as its first argument, one block at a time.
        args : sequence
            Passed to func after unpacking and subsetting any xarray objects by blocks.
            xarray objects in args must be aligned with obj, otherwise an error is raised.
        kwargs : mapping
            Passed verbatim to func after unpacking. xarray objects, if any, will not be
            subset to blocks. Passing dask collections in kwargs is not allowed.
        template : DataArray or Dataset, optional
            xarray object representing the final result after compute is called. If not provided,
            the function will be first run on mocked-up data, that looks like ``obj`` but
            has sizes 0, to determine properties of the returned object such as dtype,
            variable names, attributes, new dimensions and new indexes (if any).
            ``template`` must be provided if the function changes the size of existing dimensions.
            When provided, ``attrs`` on variables in `template` are copied over to the result. Any
            ``attrs`` set by ``func`` will be ignored.

        Returns
        -------
        obj : same as obj
            A single DataArray or Dataset with dask backend, reassembled from the outputs of the
            function.

        Notes
        -----
        This function is designed for when ``func`` needs to manipulate a whole xarray object
        subset to each block. Each block is loaded into memory. In the more common case where
        ``func`` can work on numpy arrays, it is recommended to use ``apply_ufunc``.

        If none of the variables in ``obj`` is backed by dask arrays, calling this function is
        equivalent to calling ``func(obj, *args, **kwargs)``.

        See Also
        --------
        dask.array.map_blocks, xarray.apply_ufunc, xarray.Dataset.map_blocks
        xarray.DataArray.map_blocks

        Examples
        --------
        Calculate an anomaly from climatology using ``.groupby()``. Using
        ``xr.map_blocks()`` allows for parallel operations with knowledge of ``xarray``,
        its indices, and its methods like ``.groupby()``.

        >>> def calculate_anomaly(da, groupby_type="time.month"):
        ...     gb = da.groupby(groupby_type)
        ...     clim = gb.mean(dim="time")
        ...     return gb - clim
        ...
        >>> time = xr.cftime_range("1990-01", "1992-01", freq="ME")
        >>> month = xr.DataArray(time.month, coords={"time": time}, dims=["time"])
        >>> np.random.seed(123)
        >>> array = xr.DataArray(
        ...     np.random.rand(len(time)),
        ...     dims=["time"],
        ...     coords={"time": time, "month": month},
        ... ).chunk()
        >>> array.map_blocks(calculate_anomaly, template=array).compute()
        <xarray.DataArray (time: 24)> Size: 192B
        array([ 0.12894847,  0.11323072, -0.0855964 , -0.09334032,  0.26848862,
                0.12382735,  0.22460641,  0.07650108, -0.07673453, -0.22865714,
               -0.19063865,  0.0590131 , -0.12894847, -0.11323072,  0.0855964 ,
                0.09334032, -0.26848862, -0.12382735, -0.22460641, -0.07650108,
                0.07673453,  0.22865714,  0.19063865, -0.0590131 ])
        Coordinates:
          * time     (time) object 192B 1990-01-31 00:00:00 ... 1991-12-31 00:00:00
            month    (time) int64 192B 1 2 3 4 5 6 7 8 9 10 ... 3 4 5 6 7 8 9 10 11 12

        Note that one must explicitly use ``args=[]`` and ``kwargs={}`` to pass arguments
        to the function being applied in ``xr.map_blocks()``:

        >>> array.map_blocks(
        ...     calculate_anomaly,
        ...     kwargs={"groupby_type": "time.year"},
        ...     template=array,
        ... )  # doctest: +ELLIPSIS
        <xarray.DataArray (time: 24)> Size: 192B
        dask.array<<this-array>-calculate_anomaly, shape=(24,), dtype=float64, chunksize=(24,), chunktype=numpy.ndarray>
        Coordinates:
          * time     (time) object 192B 1990-01-31 00:00:00 ... 1991-12-31 00:00:00
            month    (time) int64 192B dask.array<chunksize=(24,), meta=np.ndarray>
        """

        def _wrapper(
            func: Callable,
            args: list,
            kwargs: dict,
            arg_is_array: Iterable[bool],
            expected: ExpectedDict,
        ):
            """
            Wrapper function that receives datasets in args; converts to dataarrays when necessary;
            passes these to the user function `func` and checks returned objects for expected shapes/sizes/etc.
            """

            converted_args = [
                dataset_to_dataarray(arg) if is_array else arg
                for is_array, arg in zip(arg_is_array, args)
            ]

            result = func(*converted_args, **kwargs)

            merged_coordinates = merge(
                [arg.coords for arg in args if isinstance(arg, (Dataset, DataArray))]
            ).coords

            # check all dims are present
            missing_dimensions = set(expected["shapes"]) - set(result.sizes)
            if missing_dimensions:
                raise ValueError(
                    f"Dimensions {missing_dimensions} missing on returned object."
                )

            # check that index lengths and values are as expected
            for name, index in result._indexes.items():
                if name in expected["shapes"]:
                    if result.sizes[name] != expected["shapes"][name]:
                        raise ValueError(
                            f"Received dimension {name!r} of length {result.sizes[name]}. "
                            f"Expected length {expected['shapes'][name]}."
                        )

                # ChainMap wants MutableMapping, but xindexes is Mapping
                merged_indexes = collections.ChainMap(
                    expected["indexes"], merged_coordinates.xindexes  # type: ignore[arg-type]
                )
                expected_index = merged_indexes.get(name, None)
                if expected_index is not None and not index.equals(expected_index):
                    raise ValueError(
                        f"Expected index {name!r} to be {expected_index!r}. Received {index!r} instead."
                    )

            # check that all expected variables were returned
            check_result_variables(result, expected, "coords")
            if isinstance(result, Dataset):
                check_result_variables(result, expected, "data_vars")

            return make_dict(result)

        if template is not None and not isinstance(template, (DataArray, Dataset)):
            raise TypeError(
                f"template must be a DataArray or Dataset. Received {type(template).__name__} instead."
            )
        if not isinstance(args, Sequence):
            raise TypeError("args must be a sequence (for example, a list or tuple).")
        if kwargs is None:
            kwargs = {}
        elif not isinstance(kwargs, Mapping):
            raise TypeError("kwargs must be a mapping (for example, a dict)")

        for value in kwargs.values():
            if is_dask_collection(value):
                raise TypeError(
                    "Cannot pass dask collections in kwargs yet. Please compute or "
                    "load values before passing to map_blocks."
                )

        if not is_dask_collection(obj):
            return func(obj, *args, **kwargs)

        try:
            import dask
            import dask.array
            from dask.highlevelgraph import HighLevelGraph

        except ImportError:
            pass

        all_args = [obj] + list(args)
        is_xarray = [isinstance(arg, (Dataset, DataArray)) for arg in all_args]
        is_array = [isinstance(arg, DataArray) for arg in all_args]

        # there should be a better way to group this. partition?
        xarray_indices, xarray_objs = unzip(
            (index, arg) for index, arg in enumerate(all_args) if is_xarray[index]
        )
        others = [
            (index, arg) for index, arg in enumerate(all_args) if not is_xarray[index]
        ]

        # all xarray objects must be aligned. This is consistent with apply_ufunc.
        aligned = align(*xarray_objs, join="exact")
        xarray_objs = tuple(
            dataarray_to_dataset(arg) if isinstance(arg, DataArray) else arg
            for arg in aligned
        )
        # rechunk any numpy variables appropriately
        xarray_objs = tuple(arg.chunk(arg.chunksizes) for arg in xarray_objs)

        merged_coordinates = merge([arg.coords for arg in aligned]).coords

        _, npargs = unzip(
            sorted(list(zip(xarray_indices, xarray_objs)) + others, key=lambda x: x[0])
        )

        # check that chunk sizes are compatible
        input_chunks = dict(npargs[0].chunks)
        for arg in xarray_objs[1:]:
            assert_chunks_compatible(npargs[0], arg)
            input_chunks.update(arg.chunks)

        coordinates: Coordinates
        if template is None:
            # infer template by providing zero-shaped arrays
            template = infer_template(func, aligned[0], *args, **kwargs)
            template_coords = set(template.coords)
            preserved_coord_vars = template_coords & set(merged_coordinates)
            new_coord_vars = template_coords - set(merged_coordinates)

            preserved_coords = merged_coordinates.to_dataset()[preserved_coord_vars]
            # preserved_coords contains all coordinates variables that share a dimension
            # with any index variable in preserved_indexes
            # Drop any unneeded vars in a second pass, this is required for e.g.
            # if the mapped function were to drop a non-dimension coordinate variable.
            preserved_coords = preserved_coords.drop_vars(
                tuple(k for k in preserved_coords.variables if k not in template_coords)
            )

            coordinates = merge(
                (preserved_coords, template.coords.to_dataset()[new_coord_vars])
            ).coords
            output_chunks: Mapping[Hashable, tuple[int, ...]] = {
                dim: input_chunks[dim] for dim in template.dims if dim in input_chunks
            }

        else:
            # template xarray object has been provided with proper sizes and chunk shapes
            coordinates = template.coords
            output_chunks = template.chunksizes
            if not output_chunks:
                raise ValueError(
                    "Provided template has no dask arrays. "
                    " Please construct a template with appropriately chunked dask arrays."
                )

        new_indexes = set(template.xindexes) - set(merged_coordinates)
        modified_indexes = set(
            name
            for name, xindex in coordinates.xindexes.items()
            if not xindex.equals(merged_coordinates.xindexes.get(name, None))
        )

        for dim in output_chunks:
            if dim in input_chunks and len(input_chunks[dim]) != len(output_chunks[dim]):
>               raise ValueError(
                    "map_blocks requires that one block of the input maps to one block of output. "
                    f"Expected number of output chunks along dimension {dim!r} to be {len(input_chunks[dim])}. "
                    f"Received {len(output_chunks[dim])} instead. Please provide template if not provided, or "
                    "fix the provided template."
                )
E               ValueError: map_blocks requires that one block of the input maps to one block of output. Expected number of output chunks along dimension 'x' to be 3. Received 1 instead. Please provide template if not provided, or fix the provided template.

/testbed/xarray/core/parallel.py:495: ValueError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_compression_encoding_h5py</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68852d0>

    def test_compression_encoding_h5py(self) -> None:
        ENCODINGS: tuple[tuple[dict[str, Any], dict[str, Any]], ...] = (
            # h5py style compression with gzip codec will be converted to
            # NetCDF4-Python style on round-trip
            (
                {"compression": "gzip", "compression_opts": 9},
                {"zlib": True, "complevel": 9},
            ),
            # What can't be expressed in NetCDF4-Python style is
            # round-tripped unaltered
            (
                {"compression": "lzf", "compression_opts": None},
                {"compression": "lzf", "compression_opts": None},
            ),
            # If both styles are used together, h5py format takes precedence
            (
                {
                    "compression": "lzf",
                    "compression_opts": None,
                    "zlib": True,
                    "complevel": 9,
                },
                {"compression": "lzf", "compression_opts": None},
            ),
        )

        for compr_in, compr_out in ENCODINGS:
            data = create_test_data()
            compr_common = {
                "chunksizes": (5, 5),
                "fletcher32": True,
                "shuffle": True,
                "original_shape": data.var2.shape,
            }
            data["var2"].encoding.update(compr_in)
            data["var2"].encoding.update(compr_common)
            compr_out.update(compr_common)
            data["scalar"] = ("scalar_dim", np.array([2.0]))
            data["scalar"] = data["scalar"][0]
>           with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:3694: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_dask.py::test_map_blocks_errors_bad_template[obj0]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

obj = <xarray.DataArray 'a' (x: 10, y: 20)> Size: 2kB
dask.array<xarray-<this-array>, shape=(10, 20), dtype=float64, chunksi...=np.ndarray>
    cxy      (x, y) int64 2kB dask.array<chunksize=(4, 5), meta=np.ndarray>
Attributes:
    test:     test

    @pytest.mark.parametrize("obj", [make_da(), make_ds()])
    def test_map_blocks_errors_bad_template(obj):
        with pytest.raises(ValueError, match=r"unexpected coordinate variables"):
            xr.map_blocks(lambda x: x.assign_coords(a=10), obj, template=obj).compute()
        with pytest.raises(ValueError, match=r"does not contain coordinate variables"):
            xr.map_blocks(lambda x: x.drop_vars("cxy"), obj, template=obj).compute()
        with pytest.raises(ValueError, match=r"Dimensions {'x'} missing"):
            xr.map_blocks(lambda x: x.isel(x=1), obj, template=obj).compute()
        with pytest.raises(ValueError, match=r"Received dimension 'x' of length 1"):
            xr.map_blocks(lambda x: x.isel(x=[1]), obj, template=obj).compute()
        with pytest.raises(TypeError, match=r"must be a DataArray"):
            xr.map_blocks(lambda x: x.isel(x=[1]), obj, template=(obj,)).compute()
        with pytest.raises(ValueError, match=r"map_blocks requires that one block"):
            xr.map_blocks(
                lambda x: x.isel(x=[1]).assign_coords(x=10), obj, template=obj.isel(x=[1])
            ).compute()
        with pytest.raises(ValueError, match=r"Expected index 'x' to be"):
>           xr.map_blocks(
                lambda a: a.isel(x=[1]).assign_coords(x=[120]),  # assign bad index values
                obj,
                template=obj.isel(x=[1, 5, 9]),
            ).compute()

/testbed/xarray/tests/test_dask.py:1429: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

func = <function test_map_blocks_errors_bad_template.<locals>.<lambda> at 0x79d75e51a200>
obj = <xarray.DataArray 'a' (x: 10, y: 20)> Size: 2kB
dask.array<xarray-<this-array>, shape=(10, 20), dtype=float64, chunksi...=np.ndarray>
    cxy      (x, y) int64 2kB dask.array<chunksize=(4, 5), meta=np.ndarray>
Attributes:
    test:     test
args = (), kwargs = {}
template = <xarray.DataArray 'a' (x: 3, y: 20)> Size: 480B
dask.array<getitem, shape=(3, 20), dtype=float64, chunksize=(3, 5), ch...np.ndarray>
    cxy      (x, y) int64 480B dask.array<chunksize=(3, 5), meta=np.ndarray>
Attributes:
    test:     test

    def map_blocks(
        func: Callable[..., T_Xarray],
        obj: DataArray | Dataset,
        args: Sequence[Any] = (),
        kwargs: Mapping[str, Any] | None = None,
        template: DataArray | Dataset | None = None,
    ) -> T_Xarray:
        """Apply a function to each block of a DataArray or Dataset.

        .. warning::
            This function is experimental and its signature may change.

        Parameters
        ----------
        func : callable
            User-provided function that accepts a DataArray or Dataset as its first
            parameter ``obj``. The function will receive a subset or 'block' of ``obj`` (see below),
            corresponding to one chunk along each chunked dimension. ``func`` will be
            executed as ``func(subset_obj, *subset_args, **kwargs)``.

            This function must return either a single DataArray or a single Dataset.

            This function cannot add a new chunked dimension.
        obj : DataArray, Dataset
            Passed to the function as its first argument, one block at a time.
        args : sequence
            Passed to func after unpacking and subsetting any xarray objects by blocks.
            xarray objects in args must be aligned with obj, otherwise an error is raised.
        kwargs : mapping
            Passed verbatim to func after unpacking. xarray objects, if any, will not be
            subset to blocks. Passing dask collections in kwargs is not allowed.
        template : DataArray or Dataset, optional
            xarray object representing the final result after compute is called. If not provided,
            the function will be first run on mocked-up data, that looks like ``obj`` but
            has sizes 0, to determine properties of the returned object such as dtype,
            variable names, attributes, new dimensions and new indexes (if any).
            ``template`` must be provided if the function changes the size of existing dimensions.
            When provided, ``attrs`` on variables in `template` are copied over to the result. Any
            ``attrs`` set by ``func`` will be ignored.

        Returns
        -------
        obj : same as obj
            A single DataArray or Dataset with dask backend, reassembled from the outputs of the
            function.

        Notes
        -----
        This function is designed for when ``func`` needs to manipulate a whole xarray object
        subset to each block. Each block is loaded into memory. In the more common case where
        ``func`` can work on numpy arrays, it is recommended to use ``apply_ufunc``.

        If none of the variables in ``obj`` is backed by dask arrays, calling this function is
        equivalent to calling ``func(obj, *args, **kwargs)``.

        See Also
        --------
        dask.array.map_blocks, xarray.apply_ufunc, xarray.Dataset.map_blocks
        xarray.DataArray.map_blocks

        Examples
        --------
        Calculate an anomaly from climatology using ``.groupby()``. Using
        ``xr.map_blocks()`` allows for parallel operations with knowledge of ``xarray``,
        its indices, and its methods like ``.groupby()``.

        >>> def calculate_anomaly(da, groupby_type="time.month"):
        ...     gb = da.groupby(groupby_type)
        ...     clim = gb.mean(dim="time")
        ...     return gb - clim
        ...
        >>> time = xr.cftime_range("1990-01", "1992-01", freq="ME")
        >>> month = xr.DataArray(time.month, coords={"time": time}, dims=["time"])
        >>> np.random.seed(123)
        >>> array = xr.DataArray(
        ...     np.random.rand(len(time)),
        ...     dims=["time"],
        ...     coords={"time": time, "month": month},
        ... ).chunk()
        >>> array.map_blocks(calculate_anomaly, template=array).compute()
        <xarray.DataArray (time: 24)> Size: 192B
        array([ 0.12894847,  0.11323072, -0.0855964 , -0.09334032,  0.26848862,
                0.12382735,  0.22460641,  0.07650108, -0.07673453, -0.22865714,
               -0.19063865,  0.0590131 , -0.12894847, -0.11323072,  0.0855964 ,
                0.09334032, -0.26848862, -0.12382735, -0.22460641, -0.07650108,
                0.07673453,  0.22865714,  0.19063865, -0.0590131 ])
        Coordinates:
          * time     (time) object 192B 1990-01-31 00:00:00 ... 1991-12-31 00:00:00
            month    (time) int64 192B 1 2 3 4 5 6 7 8 9 10 ... 3 4 5 6 7 8 9 10 11 12

        Note that one must explicitly use ``args=[]`` and ``kwargs={}`` to pass arguments
        to the function being applied in ``xr.map_blocks()``:

        >>> array.map_blocks(
        ...     calculate_anomaly,
        ...     kwargs={"groupby_type": "time.year"},
        ...     template=array,
        ... )  # doctest: +ELLIPSIS
        <xarray.DataArray (time: 24)> Size: 192B
        dask.array<<this-array>-calculate_anomaly, shape=(24,), dtype=float64, chunksize=(24,), chunktype=numpy.ndarray>
        Coordinates:
          * time     (time) object 192B 1990-01-31 00:00:00 ... 1991-12-31 00:00:00
            month    (time) int64 192B dask.array<chunksize=(24,), meta=np.ndarray>
        """

        def _wrapper(
            func: Callable,
            args: list,
            kwargs: dict,
            arg_is_array: Iterable[bool],
            expected: ExpectedDict,
        ):
            """
            Wrapper function that receives datasets in args; converts to dataarrays when necessary;
            passes these to the user function `func` and checks returned objects for expected shapes/sizes/etc.
            """

            converted_args = [
                dataset_to_dataarray(arg) if is_array else arg
                for is_array, arg in zip(arg_is_array, args)
            ]

            result = func(*converted_args, **kwargs)

            merged_coordinates = merge(
                [arg.coords for arg in args if isinstance(arg, (Dataset, DataArray))]
            ).coords

            # check all dims are present
            missing_dimensions = set(expected["shapes"]) - set(result.sizes)
            if missing_dimensions:
                raise ValueError(
                    f"Dimensions {missing_dimensions} missing on returned object."
                )

            # check that index lengths and values are as expected
            for name, index in result._indexes.items():
                if name in expected["shapes"]:
                    if result.sizes[name] != expected["shapes"][name]:
                        raise ValueError(
                            f"Received dimension {name!r} of length {result.sizes[name]}. "
                            f"Expected length {expected['shapes'][name]}."
                        )

                # ChainMap wants MutableMapping, but xindexes is Mapping
                merged_indexes = collections.ChainMap(
                    expected["indexes"], merged_coordinates.xindexes  # type: ignore[arg-type]
                )
                expected_index = merged_indexes.get(name, None)
                if expected_index is not None and not index.equals(expected_index):
                    raise ValueError(
                        f"Expected index {name!r} to be {expected_index!r}. Received {index!r} instead."
                    )

            # check that all expected variables were returned
            check_result_variables(result, expected, "coords")
            if isinstance(result, Dataset):
                check_result_variables(result, expected, "data_vars")

            return make_dict(result)

        if template is not None and not isinstance(template, (DataArray, Dataset)):
            raise TypeError(
                f"template must be a DataArray or Dataset. Received {type(template).__name__} instead."
            )
        if not isinstance(args, Sequence):
            raise TypeError("args must be a sequence (for example, a list or tuple).")
        if kwargs is None:
            kwargs = {}
        elif not isinstance(kwargs, Mapping):
            raise TypeError("kwargs must be a mapping (for example, a dict)")

        for value in kwargs.values():
            if is_dask_collection(value):
                raise TypeError(
                    "Cannot pass dask collections in kwargs yet. Please compute or "
                    "load values before passing to map_blocks."
                )

        if not is_dask_collection(obj):
            return func(obj, *args, **kwargs)

        try:
            import dask
            import dask.array
            from dask.highlevelgraph import HighLevelGraph

        except ImportError:
            pass

        all_args = [obj] + list(args)
        is_xarray = [isinstance(arg, (Dataset, DataArray)) for arg in all_args]
        is_array = [isinstance(arg, DataArray) for arg in all_args]

        # there should be a better way to group this. partition?
        xarray_indices, xarray_objs = unzip(
            (index, arg) for index, arg in enumerate(all_args) if is_xarray[index]
        )
        others = [
            (index, arg) for index, arg in enumerate(all_args) if not is_xarray[index]
        ]

        # all xarray objects must be aligned. This is consistent with apply_ufunc.
        aligned = align(*xarray_objs, join="exact")
        xarray_objs = tuple(
            dataarray_to_dataset(arg) if isinstance(arg, DataArray) else arg
            for arg in aligned
        )
        # rechunk any numpy variables appropriately
        xarray_objs = tuple(arg.chunk(arg.chunksizes) for arg in xarray_objs)

        merged_coordinates = merge([arg.coords for arg in aligned]).coords

        _, npargs = unzip(
            sorted(list(zip(xarray_indices, xarray_objs)) + others, key=lambda x: x[0])
        )

        # check that chunk sizes are compatible
        input_chunks = dict(npargs[0].chunks)
        for arg in xarray_objs[1:]:
            assert_chunks_compatible(npargs[0], arg)
            input_chunks.update(arg.chunks)

        coordinates: Coordinates
        if template is None:
            # infer template by providing zero-shaped arrays
            template = infer_template(func, aligned[0], *args, **kwargs)
            template_coords = set(template.coords)
            preserved_coord_vars = template_coords & set(merged_coordinates)
            new_coord_vars = template_coords - set(merged_coordinates)

            preserved_coords = merged_coordinates.to_dataset()[preserved_coord_vars]
            # preserved_coords contains all coordinates variables that share a dimension
            # with any index variable in preserved_indexes
            # Drop any unneeded vars in a second pass, this is required for e.g.
            # if the mapped function were to drop a non-dimension coordinate variable.
            preserved_coords = preserved_coords.drop_vars(
                tuple(k for k in preserved_coords.variables if k not in template_coords)
            )

            coordinates = merge(
                (preserved_coords, template.coords.to_dataset()[new_coord_vars])
            ).coords
            output_chunks: Mapping[Hashable, tuple[int, ...]] = {
                dim: input_chunks[dim] for dim in template.dims if dim in input_chunks
            }

        else:
            # template xarray object has been provided with proper sizes and chunk shapes
            coordinates = template.coords
            output_chunks = template.chunksizes
            if not output_chunks:
                raise ValueError(
                    "Provided template has no dask arrays. "
                    " Please construct a template with appropriately chunked dask arrays."
                )

        new_indexes = set(template.xindexes) - set(merged_coordinates)
        modified_indexes = set(
            name
            for name, xindex in coordinates.xindexes.items()
            if not xindex.equals(merged_coordinates.xindexes.get(name, None))
        )

        for dim in output_chunks:
            if dim in input_chunks and len(input_chunks[dim]) != len(output_chunks[dim]):
>               raise ValueError(
                    "map_blocks requires that one block of the input maps to one block of output. "
                    f"Expected number of output chunks along dimension {dim!r} to be {len(input_chunks[dim])}. "
                    f"Received {len(output_chunks[dim])} instead. Please provide template if not provided, or "
                    "fix the provided template."
                )
E               ValueError: map_blocks requires that one block of the input maps to one block of output. Expected number of output chunks along dimension 'x' to be 3. Received 1 instead. Please provide template if not provided, or fix the provided template.

/testbed/xarray/core/parallel.py:495: ValueError

During handling of the above exception, another exception occurred:

obj = <xarray.DataArray 'a' (x: 10, y: 20)> Size: 2kB
dask.array<xarray-<this-array>, shape=(10, 20), dtype=float64, chunksi...=np.ndarray>
    cxy      (x, y) int64 2kB dask.array<chunksize=(4, 5), meta=np.ndarray>
Attributes:
    test:     test

    @pytest.mark.parametrize("obj", [make_da(), make_ds()])
    def test_map_blocks_errors_bad_template(obj):
        with pytest.raises(ValueError, match=r"unexpected coordinate variables"):
            xr.map_blocks(lambda x: x.assign_coords(a=10), obj, template=obj).compute()
        with pytest.raises(ValueError, match=r"does not contain coordinate variables"):
            xr.map_blocks(lambda x: x.drop_vars("cxy"), obj, template=obj).compute()
        with pytest.raises(ValueError, match=r"Dimensions {'x'} missing"):
            xr.map_blocks(lambda x: x.isel(x=1), obj, template=obj).compute()
        with pytest.raises(ValueError, match=r"Received dimension 'x' of length 1"):
            xr.map_blocks(lambda x: x.isel(x=[1]), obj, template=obj).compute()
        with pytest.raises(TypeError, match=r"must be a DataArray"):
            xr.map_blocks(lambda x: x.isel(x=[1]), obj, template=(obj,)).compute()
        with pytest.raises(ValueError, match=r"map_blocks requires that one block"):
            xr.map_blocks(
                lambda x: x.isel(x=[1]).assign_coords(x=10), obj, template=obj.isel(x=[1])
            ).compute()
>       with pytest.raises(ValueError, match=r"Expected index 'x' to be"):
E       AssertionError: Regex pattern did not match.
E        Regex: "Expected index 'x' to be"
E        Input: "map_blocks requires that one block of the input maps to one block of output. Expected number of output chunks along dimension 'x' to be 3. Received 1 instead. Please provide template if not provided, or fix the provided template."

/testbed/xarray/tests/test_dask.py:1428: AssertionError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_dask.py::test_map_blocks_errors_bad_template[obj1]</pre></summary><pre>
[gw0] linux -- Python 3.10.12 /testbed/.venv/bin/python3

obj = <xarray.Dataset> Size: 9kB
Dimensions:  (x: 10, y: 20, z: 4)
Coordinates:
  * x        (x) int64 80B 0 1 2 3 4 5 6 7 8...2B 1 1 1 1
    e        (x, y) int64 2kB 100 101 102 103 104 105 ... 124 125 126 127 128
Attributes:
    test:     test

    @pytest.mark.parametrize("obj", [make_da(), make_ds()])
    def test_map_blocks_errors_bad_template(obj):
        with pytest.raises(ValueError, match=r"unexpected coordinate variables"):
            xr.map_blocks(lambda x: x.assign_coords(a=10), obj, template=obj).compute()
        with pytest.raises(ValueError, match=r"does not contain coordinate variables"):
            xr.map_blocks(lambda x: x.drop_vars("cxy"), obj, template=obj).compute()
        with pytest.raises(ValueError, match=r"Dimensions {'x'} missing"):
            xr.map_blocks(lambda x: x.isel(x=1), obj, template=obj).compute()
        with pytest.raises(ValueError, match=r"Received dimension 'x' of length 1"):
            xr.map_blocks(lambda x: x.isel(x=[1]), obj, template=obj).compute()
        with pytest.raises(TypeError, match=r"must be a DataArray"):
            xr.map_blocks(lambda x: x.isel(x=[1]), obj, template=(obj,)).compute()
        with pytest.raises(ValueError, match=r"map_blocks requires that one block"):
            xr.map_blocks(
                lambda x: x.isel(x=[1]).assign_coords(x=10), obj, template=obj.isel(x=[1])
            ).compute()
        with pytest.raises(ValueError, match=r"Expected index 'x' to be"):
>           xr.map_blocks(
                lambda a: a.isel(x=[1]).assign_coords(x=[120]),  # assign bad index values
                obj,
                template=obj.isel(x=[1, 5, 9]),
            ).compute()

/testbed/xarray/tests/test_dask.py:1429: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

func = <function test_map_blocks_errors_bad_template.<locals>.<lambda> at 0x79d75df785e0>
obj = <xarray.Dataset> Size: 9kB
Dimensions:  (x: 10, y: 20, z: 4)
Coordinates:
  * x        (x) int64 80B 0 1 2 3 4 5 6 7 8...2B 1 1 1 1
    e        (x, y) int64 2kB 100 101 102 103 104 105 ... 124 125 126 127 128
Attributes:
    test:     test
args = (), kwargs = {}
template = <xarray.Dataset> Size: 3kB
Dimensions:  (x: 3, y: 20, z: 4)
Coordinates:
  * x        (x) int64 24B 1 5 9
  * y       ...B 1 1 1 1
    e        (x, y) int64 480B 101 102 103 104 105 106 ... 124 125 126 127 128
Attributes:
    test:     test

    def map_blocks(
        func: Callable[..., T_Xarray],
        obj: DataArray | Dataset,
        args: Sequence[Any] = (),
        kwargs: Mapping[str, Any] | None = None,
        template: DataArray | Dataset | None = None,
    ) -> T_Xarray:
        """Apply a function to each block of a DataArray or Dataset.

        .. warning::
            This function is experimental and its signature may change.

        Parameters
        ----------
        func : callable
            User-provided function that accepts a DataArray or Dataset as its first
            parameter ``obj``. The function will receive a subset or 'block' of ``obj`` (see below),
            corresponding to one chunk along each chunked dimension. ``func`` will be
            executed as ``func(subset_obj, *subset_args, **kwargs)``.

            This function must return either a single DataArray or a single Dataset.

            This function cannot add a new chunked dimension.
        obj : DataArray, Dataset
            Passed to the function as its first argument, one block at a time.
        args : sequence
            Passed to func after unpacking and subsetting any xarray objects by blocks.
            xarray objects in args must be aligned with obj, otherwise an error is raised.
        kwargs : mapping
            Passed verbatim to func after unpacking. xarray objects, if any, will not be
            subset to blocks. Passing dask collections in kwargs is not allowed.
        template : DataArray or Dataset, optional
            xarray object representing the final result after compute is called. If not provided,
            the function will be first run on mocked-up data, that looks like ``obj`` but
            has sizes 0, to determine properties of the returned object such as dtype,
            variable names, attributes, new dimensions and new indexes (if any).
            ``template`` must be provided if the function changes the size of existing dimensions.
            When provided, ``attrs`` on variables in `template` are copied over to the result. Any
            ``attrs`` set by ``func`` will be ignored.

        Returns
        -------
        obj : same as obj
            A single DataArray or Dataset with dask backend, reassembled from the outputs of the
            function.

        Notes
        -----
        This function is designed for when ``func`` needs to manipulate a whole xarray object
        subset to each block. Each block is loaded into memory. In the more common case where
        ``func`` can work on numpy arrays, it is recommended to use ``apply_ufunc``.

        If none of the variables in ``obj`` is backed by dask arrays, calling this function is
        equivalent to calling ``func(obj, *args, **kwargs)``.

        See Also
        --------
        dask.array.map_blocks, xarray.apply_ufunc, xarray.Dataset.map_blocks
        xarray.DataArray.map_blocks

        Examples
        --------
        Calculate an anomaly from climatology using ``.groupby()``. Using
        ``xr.map_blocks()`` allows for parallel operations with knowledge of ``xarray``,
        its indices, and its methods like ``.groupby()``.

        >>> def calculate_anomaly(da, groupby_type="time.month"):
        ...     gb = da.groupby(groupby_type)
        ...     clim = gb.mean(dim="time")
        ...     return gb - clim
        ...
        >>> time = xr.cftime_range("1990-01", "1992-01", freq="ME")
        >>> month = xr.DataArray(time.month, coords={"time": time}, dims=["time"])
        >>> np.random.seed(123)
        >>> array = xr.DataArray(
        ...     np.random.rand(len(time)),
        ...     dims=["time"],
        ...     coords={"time": time, "month": month},
        ... ).chunk()
        >>> array.map_blocks(calculate_anomaly, template=array).compute()
        <xarray.DataArray (time: 24)> Size: 192B
        array([ 0.12894847,  0.11323072, -0.0855964 , -0.09334032,  0.26848862,
                0.12382735,  0.22460641,  0.07650108, -0.07673453, -0.22865714,
               -0.19063865,  0.0590131 , -0.12894847, -0.11323072,  0.0855964 ,
                0.09334032, -0.26848862, -0.12382735, -0.22460641, -0.07650108,
                0.07673453,  0.22865714,  0.19063865, -0.0590131 ])
        Coordinates:
          * time     (time) object 192B 1990-01-31 00:00:00 ... 1991-12-31 00:00:00
            month    (time) int64 192B 1 2 3 4 5 6 7 8 9 10 ... 3 4 5 6 7 8 9 10 11 12

        Note that one must explicitly use ``args=[]`` and ``kwargs={}`` to pass arguments
        to the function being applied in ``xr.map_blocks()``:

        >>> array.map_blocks(
        ...     calculate_anomaly,
        ...     kwargs={"groupby_type": "time.year"},
        ...     template=array,
        ... )  # doctest: +ELLIPSIS
        <xarray.DataArray (time: 24)> Size: 192B
        dask.array<<this-array>-calculate_anomaly, shape=(24,), dtype=float64, chunksize=(24,), chunktype=numpy.ndarray>
        Coordinates:
          * time     (time) object 192B 1990-01-31 00:00:00 ... 1991-12-31 00:00:00
            month    (time) int64 192B dask.array<chunksize=(24,), meta=np.ndarray>
        """

        def _wrapper(
            func: Callable,
            args: list,
            kwargs: dict,
            arg_is_array: Iterable[bool],
            expected: ExpectedDict,
        ):
            """
            Wrapper function that receives datasets in args; converts to dataarrays when necessary;
            passes these to the user function `func` and checks returned objects for expected shapes/sizes/etc.
            """

            converted_args = [
                dataset_to_dataarray(arg) if is_array else arg
                for is_array, arg in zip(arg_is_array, args)
            ]

            result = func(*converted_args, **kwargs)

            merged_coordinates = merge(
                [arg.coords for arg in args if isinstance(arg, (Dataset, DataArray))]
            ).coords

            # check all dims are present
            missing_dimensions = set(expected["shapes"]) - set(result.sizes)
            if missing_dimensions:
                raise ValueError(
                    f"Dimensions {missing_dimensions} missing on returned object."
                )

            # check that index lengths and values are as expected
            for name, index in result._indexes.items():
                if name in expected["shapes"]:
                    if result.sizes[name] != expected["shapes"][name]:
                        raise ValueError(
                            f"Received dimension {name!r} of length {result.sizes[name]}. "
                            f"Expected length {expected['shapes'][name]}."
                        )

                # ChainMap wants MutableMapping, but xindexes is Mapping
                merged_indexes = collections.ChainMap(
                    expected["indexes"], merged_coordinates.xindexes  # type: ignore[arg-type]
                )
                expected_index = merged_indexes.get(name, None)
                if expected_index is not None and not index.equals(expected_index):
                    raise ValueError(
                        f"Expected index {name!r} to be {expected_index!r}. Received {index!r} instead."
                    )

            # check that all expected variables were returned
            check_result_variables(result, expected, "coords")
            if isinstance(result, Dataset):
                check_result_variables(result, expected, "data_vars")

            return make_dict(result)

        if template is not None and not isinstance(template, (DataArray, Dataset)):
            raise TypeError(
                f"template must be a DataArray or Dataset. Received {type(template).__name__} instead."
            )
        if not isinstance(args, Sequence):
            raise TypeError("args must be a sequence (for example, a list or tuple).")
        if kwargs is None:
            kwargs = {}
        elif not isinstance(kwargs, Mapping):
            raise TypeError("kwargs must be a mapping (for example, a dict)")

        for value in kwargs.values():
            if is_dask_collection(value):
                raise TypeError(
                    "Cannot pass dask collections in kwargs yet. Please compute or "
                    "load values before passing to map_blocks."
                )

        if not is_dask_collection(obj):
            return func(obj, *args, **kwargs)

        try:
            import dask
            import dask.array
            from dask.highlevelgraph import HighLevelGraph

        except ImportError:
            pass

        all_args = [obj] + list(args)
        is_xarray = [isinstance(arg, (Dataset, DataArray)) for arg in all_args]
        is_array = [isinstance(arg, DataArray) for arg in all_args]

        # there should be a better way to group this. partition?
        xarray_indices, xarray_objs = unzip(
            (index, arg) for index, arg in enumerate(all_args) if is_xarray[index]
        )
        others = [
            (index, arg) for index, arg in enumerate(all_args) if not is_xarray[index]
        ]

        # all xarray objects must be aligned. This is consistent with apply_ufunc.
        aligned = align(*xarray_objs, join="exact")
        xarray_objs = tuple(
            dataarray_to_dataset(arg) if isinstance(arg, DataArray) else arg
            for arg in aligned
        )
        # rechunk any numpy variables appropriately
        xarray_objs = tuple(arg.chunk(arg.chunksizes) for arg in xarray_objs)

        merged_coordinates = merge([arg.coords for arg in aligned]).coords

        _, npargs = unzip(
            sorted(list(zip(xarray_indices, xarray_objs)) + others, key=lambda x: x[0])
        )

        # check that chunk sizes are compatible
        input_chunks = dict(npargs[0].chunks)
        for arg in xarray_objs[1:]:
            assert_chunks_compatible(npargs[0], arg)
            input_chunks.update(arg.chunks)

        coordinates: Coordinates
        if template is None:
            # infer template by providing zero-shaped arrays
            template = infer_template(func, aligned[0], *args, **kwargs)
            template_coords = set(template.coords)
            preserved_coord_vars = template_coords & set(merged_coordinates)
            new_coord_vars = template_coords - set(merged_coordinates)

            preserved_coords = merged_coordinates.to_dataset()[preserved_coord_vars]
            # preserved_coords contains all coordinates variables that share a dimension
            # with any index variable in preserved_indexes
            # Drop any unneeded vars in a second pass, this is required for e.g.
            # if the mapped function were to drop a non-dimension coordinate variable.
            preserved_coords = preserved_coords.drop_vars(
                tuple(k for k in preserved_coords.variables if k not in template_coords)
            )

            coordinates = merge(
                (preserved_coords, template.coords.to_dataset()[new_coord_vars])
            ).coords
            output_chunks: Mapping[Hashable, tuple[int, ...]] = {
                dim: input_chunks[dim] for dim in template.dims if dim in input_chunks
            }

        else:
            # template xarray object has been provided with proper sizes and chunk shapes
            coordinates = template.coords
            output_chunks = template.chunksizes
            if not output_chunks:
                raise ValueError(
                    "Provided template has no dask arrays. "
                    " Please construct a template with appropriately chunked dask arrays."
                )

        new_indexes = set(template.xindexes) - set(merged_coordinates)
        modified_indexes = set(
            name
            for name, xindex in coordinates.xindexes.items()
            if not xindex.equals(merged_coordinates.xindexes.get(name, None))
        )

        for dim in output_chunks:
            if dim in input_chunks and len(input_chunks[dim]) != len(output_chunks[dim]):
>               raise ValueError(
                    "map_blocks requires that one block of the input maps to one block of output. "
                    f"Expected number of output chunks along dimension {dim!r} to be {len(input_chunks[dim])}. "
                    f"Received {len(output_chunks[dim])} instead. Please provide template if not provided, or "
                    "fix the provided template."
                )
E               ValueError: map_blocks requires that one block of the input maps to one block of output. Expected number of output chunks along dimension 'x' to be 3. Received 1 instead. Please provide template if not provided, or fix the provided template.

/testbed/xarray/core/parallel.py:495: ValueError

During handling of the above exception, another exception occurred:

obj = <xarray.Dataset> Size: 9kB
Dimensions:  (x: 10, y: 20, z: 4)
Coordinates:
  * x        (x) int64 80B 0 1 2 3 4 5 6 7 8...2B 1 1 1 1
    e        (x, y) int64 2kB 100 101 102 103 104 105 ... 124 125 126 127 128
Attributes:
    test:     test

    @pytest.mark.parametrize("obj", [make_da(), make_ds()])
    def test_map_blocks_errors_bad_template(obj):
        with pytest.raises(ValueError, match=r"unexpected coordinate variables"):
            xr.map_blocks(lambda x: x.assign_coords(a=10), obj, template=obj).compute()
        with pytest.raises(ValueError, match=r"does not contain coordinate variables"):
            xr.map_blocks(lambda x: x.drop_vars("cxy"), obj, template=obj).compute()
        with pytest.raises(ValueError, match=r"Dimensions {'x'} missing"):
            xr.map_blocks(lambda x: x.isel(x=1), obj, template=obj).compute()
        with pytest.raises(ValueError, match=r"Received dimension 'x' of length 1"):
            xr.map_blocks(lambda x: x.isel(x=[1]), obj, template=obj).compute()
        with pytest.raises(TypeError, match=r"must be a DataArray"):
            xr.map_blocks(lambda x: x.isel(x=[1]), obj, template=(obj,)).compute()
        with pytest.raises(ValueError, match=r"map_blocks requires that one block"):
            xr.map_blocks(
                lambda x: x.isel(x=[1]).assign_coords(x=10), obj, template=obj.isel(x=[1])
            ).compute()
>       with pytest.raises(ValueError, match=r"Expected index 'x' to be"):
E       AssertionError: Regex pattern did not match.
E        Regex: "Expected index 'x' to be"
E        Input: "map_blocks requires that one block of the input maps to one block of output. Expected number of output chunks along dimension 'x' to be 3. Received 1 instead. Please provide template if not provided, or fix the provided template."

/testbed/xarray/tests/test_dask.py:1428: AssertionError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_compression_check_encoding_h5py</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b68855d0>

    def test_compression_check_encoding_h5py(self) -> None:
        """When mismatched h5py and NetCDF4-Python encodings are expressed
        in to_netcdf(encoding=...), must raise ValueError
        """
        data = Dataset({"x": ("y", np.arange(10.0))})
        # Compatible encodings are graciously supported
        with create_tmp_file() as tmp_file:
>           data.to_netcdf(
                tmp_file,
                engine="h5netcdf",
                encoding={
                    "x": {
                        "compression": "gzip",
                        "zlib": True,
                        "compression_opts": 6,
                        "complevel": 6,
                    }
                },
            )

/testbed/xarray/tests/test_backends.py:3705: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_dump_encodings_h5py</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6885930>

    def test_dump_encodings_h5py(self) -> None:
        # regression test for #709
        ds = Dataset({"x": ("y", np.arange(10.0))})

        kwargs = {"encoding": {"x": {"compression": "gzip", "compression_opts": 9}}}
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:3754: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_open_twice</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6877820>

    def test_open_twice(self) -> None:
        expected = create_test_data()
        expected.attrs["foo"] = "bar"
        with create_tmp_file() as tmp_file:
>           expected.to_netcdf(tmp_file, engine="h5netcdf")

/testbed/xarray/tests/test_backends.py:3845: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_computation.py::test_cross[a5-b5-ae5-be5-cartesian--1-True]</pre></summary><pre>
[gw2] linux -- Python 3.10.12 /testbed/.venv/bin/python3

a = <xarray.DataArray (cartesian: 1)> Size: 8B
dask.array<xarray-<this-array>, shape=(1,), dtype=int64, chunksize=(1,), chunktype=numpy.ndarray>
Coordinates:
  * cartesian  (cartesian) <U1 4B 'z'
b = <xarray.DataArray (cartesian: 3)> Size: 24B
dask.array<xarray-<this-array>, shape=(3,), dtype=int64, chunksize=(3,), chunktype=numpy.ndarray>
Coordinates:
  * cartesian  (cartesian) <U1 12B 'x' 'y' 'z'
ae = array([0, 0, 1]), be = array([4, 5, 6]), dim = 'cartesian', axis = -1
use_dask = True

    @pytest.mark.parametrize("use_dask", [False, True])
    @pytest.mark.parametrize(
        "a, b, ae, be, dim, axis",
        [
            [
                xr.DataArray([1, 2, 3]),
                xr.DataArray([4, 5, 6]),
                np.array([1, 2, 3]),
                np.array([4, 5, 6]),
                "dim_0",
                -1,
            ],
            [
                xr.DataArray([1, 2]),
                xr.DataArray([4, 5, 6]),
                np.array([1, 2, 0]),
                np.array([4, 5, 6]),
                "dim_0",
                -1,
            ],
            [
                xr.Variable(dims=["dim_0"], data=[1, 2, 3]),
                xr.Variable(dims=["dim_0"], data=[4, 5, 6]),
                np.array([1, 2, 3]),
                np.array([4, 5, 6]),
                "dim_0",
                -1,
            ],
            [
                xr.Variable(dims=["dim_0"], data=[1, 2]),
                xr.Variable(dims=["dim_0"], data=[4, 5, 6]),
                np.array([1, 2, 0]),
                np.array([4, 5, 6]),
                "dim_0",
                -1,
            ],
            [  # Test dim in the middle:
                xr.DataArray(
                    np.arange(0, 5 * 3 * 4).reshape((5, 3, 4)),
                    dims=["time", "cartesian", "var"],
                    coords=dict(
                        time=(["time"], np.arange(0, 5)),
                        cartesian=(["cartesian"], ["x", "y", "z"]),
                        var=(["var"], [1, 1.5, 2, 2.5]),
                    ),
                ),
                xr.DataArray(
                    np.arange(0, 5 * 3 * 4).reshape((5, 3, 4)) + 1,
                    dims=["time", "cartesian", "var"],
                    coords=dict(
                        time=(["time"], np.arange(0, 5)),
                        cartesian=(["cartesian"], ["x", "y", "z"]),
                        var=(["var"], [1, 1.5, 2, 2.5]),
                    ),
                ),
                np.arange(0, 5 * 3 * 4).reshape((5, 3, 4)),
                np.arange(0, 5 * 3 * 4).reshape((5, 3, 4)) + 1,
                "cartesian",
                1,
            ],
            [  # Test 1 sized arrays with coords:
                xr.DataArray(
                    np.array([1]),
                    dims=["cartesian"],
                    coords=dict(cartesian=(["cartesian"], ["z"])),
                ),
                xr.DataArray(
                    np.array([4, 5, 6]),
                    dims=["cartesian"],
                    coords=dict(cartesian=(["cartesian"], ["x", "y", "z"])),
                ),
                np.array([0, 0, 1]),
                np.array([4, 5, 6]),
                "cartesian",
                -1,
            ],
            [  # Test filling in between with coords:
                xr.DataArray(
                    [1, 2],
                    dims=["cartesian"],
                    coords=dict(cartesian=(["cartesian"], ["x", "z"])),
                ),
                xr.DataArray(
                    [4, 5, 6],
                    dims=["cartesian"],
                    coords=dict(cartesian=(["cartesian"], ["x", "y", "z"])),
                ),
                np.array([1, 0, 2]),
                np.array([4, 5, 6]),
                "cartesian",
                -1,
            ],
        ],
    )
    def test_cross(a, b, ae, be, dim: str, axis: int, use_dask: bool) -> None:
        expected = np.cross(ae, be, axis=axis)

        if use_dask:
            if not has_dask:
                pytest.skip("test for dask.")
            a = a.chunk()
            b = b.chunk()

>       actual = xr.cross(a, b, dim=dim)

/testbed/xarray/tests/test_computation.py:2593: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/core/computation.py:1707: in cross
    c = apply_ufunc(
/testbed/xarray/core/computation.py:1268: in apply_ufunc
    return apply_dataarray_vfunc(
/testbed/xarray/core/computation.py:312: in apply_dataarray_vfunc
    result_var = func(*data_vars)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

func = <function cross at 0x7258e4595070>
signature = _UFuncSignature([('cartesian',), ('cartesian',)], [('cartesian',)])
exclude_dims = frozenset(), dask = 'parallelized'
output_dtypes = [dtype('int64')]

    def apply_variable_ufunc(
        func,
        *args,
        signature: _UFuncSignature,
        exclude_dims=frozenset(),
        dask="forbidden",
        output_dtypes=None,
        vectorize=False,
        keep_attrs="override",
        dask_gufunc_kwargs=None,
    ) -> Variable | tuple[Variable, ...]:
        """Apply a ndarray level function over Variable and/or ndarray objects."""
        from xarray.core.formatting import short_array_repr
        from xarray.core.variable import Variable, as_compatible_data

        dim_sizes = unified_dim_sizes(
            (a for a in args if hasattr(a, "dims")), exclude_dims=exclude_dims
        )
        broadcast_dims = tuple(
            dim for dim in dim_sizes if dim not in signature.all_core_dims
        )
        output_dims = [broadcast_dims + out for out in signature.output_core_dims]

        input_data = [
            (
                broadcast_compat_data(arg, broadcast_dims, core_dims)
                if isinstance(arg, Variable)
                else arg
            )
            for arg, core_dims in zip(args, signature.input_core_dims)
        ]

        if any(is_chunked_array(array) for array in input_data):
            if dask == "forbidden":
                raise ValueError(
                    "apply_ufunc encountered a chunked array on an "
                    "argument, but handling for chunked arrays has not "
                    "been enabled. Either set the ``dask`` argument "
                    "or load your data into memory first with "
                    "``.load()`` or ``.compute()``"
                )
            elif dask == "parallelized":
                chunkmanager = get_chunked_array_type(*input_data)

                numpy_func = func

                if dask_gufunc_kwargs is None:
                    dask_gufunc_kwargs = {}
                else:
                    dask_gufunc_kwargs = dask_gufunc_kwargs.copy()

                allow_rechunk = dask_gufunc_kwargs.get("allow_rechunk", None)
                if allow_rechunk is None:
                    for n, (data, core_dims) in enumerate(
                        zip(input_data, signature.input_core_dims)
                    ):
                        if is_chunked_array(data):
                            # core dimensions cannot span multiple chunks
                            for axis, dim in enumerate(core_dims, start=-len(core_dims)):
                                if len(data.chunks[axis]) != 1:
>                                   raise ValueError(
                                        f"dimension {dim} on {n}th function argument to "
                                        "apply_ufunc with dask='parallelized' consists of "
                                        "multiple chunks, but is also a core dimension. To "
                                        "fix, either rechunk into a single array chunk along "
                                        f"this dimension, i.e., ``.chunk(dict({dim}=-1))``, or "
                                        "pass ``allow_rechunk=True`` in ``dask_gufunc_kwargs`` "
                                        "but beware that this may significantly increase memory usage."
                                    )
E                                   ValueError: dimension cartesian on 0th function argument to apply_ufunc with dask='parallelized' consists of multiple chunks, but is also a core dimension. To fix, either rechunk into a single array chunk along this dimension, i.e., ``.chunk(dict(cartesian=-1))``, or pass ``allow_rechunk=True`` in ``dask_gufunc_kwargs`` but beware that this may significantly increase memory usage.

/testbed/xarray/core/computation.py:767: ValueError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFFileObject::test_open_fileobj</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFFileObject object at 0x7f42b6877a30>

    @requires_scipy
    def test_open_fileobj(self) -> None:
        # open in-memory datasets instead of local file paths
        expected = create_test_data().drop_vars("dim3")
        expected.attrs["foo"] = "bar"
        with create_tmp_file() as tmp_file:
>           expected.to_netcdf(tmp_file, engine="h5netcdf")

/testbed/xarray/tests/test_backends.py:3857: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_computation.py::test_cross[a6-b6-ae6-be6-cartesian--1-True]</pre></summary><pre>
[gw2] linux -- Python 3.10.12 /testbed/.venv/bin/python3

a = <xarray.DataArray (cartesian: 2)> Size: 16B
dask.array<xarray-<this-array>, shape=(2,), dtype=int64, chunksize=(2,), chunktype=numpy.ndarray>
Coordinates:
  * cartesian  (cartesian) <U1 8B 'x' 'z'
b = <xarray.DataArray (cartesian: 3)> Size: 24B
dask.array<xarray-<this-array>, shape=(3,), dtype=int64, chunksize=(3,), chunktype=numpy.ndarray>
Coordinates:
  * cartesian  (cartesian) <U1 12B 'x' 'y' 'z'
ae = array([1, 0, 2]), be = array([4, 5, 6]), dim = 'cartesian', axis = -1
use_dask = True

    @pytest.mark.parametrize("use_dask", [False, True])
    @pytest.mark.parametrize(
        "a, b, ae, be, dim, axis",
        [
            [
                xr.DataArray([1, 2, 3]),
                xr.DataArray([4, 5, 6]),
                np.array([1, 2, 3]),
                np.array([4, 5, 6]),
                "dim_0",
                -1,
            ],
            [
                xr.DataArray([1, 2]),
                xr.DataArray([4, 5, 6]),
                np.array([1, 2, 0]),
                np.array([4, 5, 6]),
                "dim_0",
                -1,
            ],
            [
                xr.Variable(dims=["dim_0"], data=[1, 2, 3]),
                xr.Variable(dims=["dim_0"], data=[4, 5, 6]),
                np.array([1, 2, 3]),
                np.array([4, 5, 6]),
                "dim_0",
                -1,
            ],
            [
                xr.Variable(dims=["dim_0"], data=[1, 2]),
                xr.Variable(dims=["dim_0"], data=[4, 5, 6]),
                np.array([1, 2, 0]),
                np.array([4, 5, 6]),
                "dim_0",
                -1,
            ],
            [  # Test dim in the middle:
                xr.DataArray(
                    np.arange(0, 5 * 3 * 4).reshape((5, 3, 4)),
                    dims=["time", "cartesian", "var"],
                    coords=dict(
                        time=(["time"], np.arange(0, 5)),
                        cartesian=(["cartesian"], ["x", "y", "z"]),
                        var=(["var"], [1, 1.5, 2, 2.5]),
                    ),
                ),
                xr.DataArray(
                    np.arange(0, 5 * 3 * 4).reshape((5, 3, 4)) + 1,
                    dims=["time", "cartesian", "var"],
                    coords=dict(
                        time=(["time"], np.arange(0, 5)),
                        cartesian=(["cartesian"], ["x", "y", "z"]),
                        var=(["var"], [1, 1.5, 2, 2.5]),
                    ),
                ),
                np.arange(0, 5 * 3 * 4).reshape((5, 3, 4)),
                np.arange(0, 5 * 3 * 4).reshape((5, 3, 4)) + 1,
                "cartesian",
                1,
            ],
            [  # Test 1 sized arrays with coords:
                xr.DataArray(
                    np.array([1]),
                    dims=["cartesian"],
                    coords=dict(cartesian=(["cartesian"], ["z"])),
                ),
                xr.DataArray(
                    np.array([4, 5, 6]),
                    dims=["cartesian"],
                    coords=dict(cartesian=(["cartesian"], ["x", "y", "z"])),
                ),
                np.array([0, 0, 1]),
                np.array([4, 5, 6]),
                "cartesian",
                -1,
            ],
            [  # Test filling in between with coords:
                xr.DataArray(
                    [1, 2],
                    dims=["cartesian"],
                    coords=dict(cartesian=(["cartesian"], ["x", "z"])),
                ),
                xr.DataArray(
                    [4, 5, 6],
                    dims=["cartesian"],
                    coords=dict(cartesian=(["cartesian"], ["x", "y", "z"])),
                ),
                np.array([1, 0, 2]),
                np.array([4, 5, 6]),
                "cartesian",
                -1,
            ],
        ],
    )
    def test_cross(a, b, ae, be, dim: str, axis: int, use_dask: bool) -> None:
        expected = np.cross(ae, be, axis=axis)

        if use_dask:
            if not has_dask:
                pytest.skip("test for dask.")
            a = a.chunk()
            b = b.chunk()

>       actual = xr.cross(a, b, dim=dim)

/testbed/xarray/tests/test_computation.py:2593: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/core/computation.py:1707: in cross
    c = apply_ufunc(
/testbed/xarray/core/computation.py:1268: in apply_ufunc
    return apply_dataarray_vfunc(
/testbed/xarray/core/computation.py:312: in apply_dataarray_vfunc
    result_var = func(*data_vars)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

func = <function cross at 0x7258e4595070>
signature = _UFuncSignature([('cartesian',), ('cartesian',)], [('cartesian',)])
exclude_dims = frozenset(), dask = 'parallelized'
output_dtypes = [dtype('int64')]

    def apply_variable_ufunc(
        func,
        *args,
        signature: _UFuncSignature,
        exclude_dims=frozenset(),
        dask="forbidden",
        output_dtypes=None,
        vectorize=False,
        keep_attrs="override",
        dask_gufunc_kwargs=None,
    ) -> Variable | tuple[Variable, ...]:
        """Apply a ndarray level function over Variable and/or ndarray objects."""
        from xarray.core.formatting import short_array_repr
        from xarray.core.variable import Variable, as_compatible_data

        dim_sizes = unified_dim_sizes(
            (a for a in args if hasattr(a, "dims")), exclude_dims=exclude_dims
        )
        broadcast_dims = tuple(
            dim for dim in dim_sizes if dim not in signature.all_core_dims
        )
        output_dims = [broadcast_dims + out for out in signature.output_core_dims]

        input_data = [
            (
                broadcast_compat_data(arg, broadcast_dims, core_dims)
                if isinstance(arg, Variable)
                else arg
            )
            for arg, core_dims in zip(args, signature.input_core_dims)
        ]

        if any(is_chunked_array(array) for array in input_data):
            if dask == "forbidden":
                raise ValueError(
                    "apply_ufunc encountered a chunked array on an "
                    "argument, but handling for chunked arrays has not "
                    "been enabled. Either set the ``dask`` argument "
                    "or load your data into memory first with "
                    "``.load()`` or ``.compute()``"
                )
            elif dask == "parallelized":
                chunkmanager = get_chunked_array_type(*input_data)

                numpy_func = func

                if dask_gufunc_kwargs is None:
                    dask_gufunc_kwargs = {}
                else:
                    dask_gufunc_kwargs = dask_gufunc_kwargs.copy()

                allow_rechunk = dask_gufunc_kwargs.get("allow_rechunk", None)
                if allow_rechunk is None:
                    for n, (data, core_dims) in enumerate(
                        zip(input_data, signature.input_core_dims)
                    ):
                        if is_chunked_array(data):
                            # core dimensions cannot span multiple chunks
                            for axis, dim in enumerate(core_dims, start=-len(core_dims)):
                                if len(data.chunks[axis]) != 1:
>                                   raise ValueError(
                                        f"dimension {dim} on {n}th function argument to "
                                        "apply_ufunc with dask='parallelized' consists of "
                                        "multiple chunks, but is also a core dimension. To "
                                        "fix, either rechunk into a single array chunk along "
                                        f"this dimension, i.e., ``.chunk(dict({dim}=-1))``, or "
                                        "pass ``allow_rechunk=True`` in ``dask_gufunc_kwargs`` "
                                        "but beware that this may significantly increase memory usage."
                                    )
E                                   ValueError: dimension cartesian on 0th function argument to apply_ufunc with dask='parallelized' consists of multiple chunks, but is also a core dimension. To fix, either rechunk into a single array chunk along this dimension, i.e., ``.chunk(dict(cartesian=-1))``, or pass ``allow_rechunk=True`` in ``dask_gufunc_kwargs`` but beware that this may significantly increase memory usage.

/testbed/xarray/core/computation.py:767: ValueError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_zero_dimensional_variable</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d76a0>

    def test_zero_dimensional_variable(self) -> None:
        expected = create_test_data()
        expected["float_var"] = ([], 1.0e9, {"units": "units of awesome"})
        expected["bytes_var"] = ([], b"foobar")
        expected["string_var"] = ([], "foobar")
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:350: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_write_store</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d78b0>

    def test_write_store(self) -> None:
        expected = create_test_data()
        with self.create_store() as store:
>           expected.dump_to_store(store)

/testbed/xarray/tests/test_backends.py:356: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/core/dataset.py:2170: in dump_to_store
    dump_to_store(self, store, **kwargs)
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_test_data</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d7520>

    def test_roundtrip_test_data(self) -> None:
        expected = create_test_data()
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:383: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_load</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d7340>

    def test_load(self) -> None:
        expected = create_test_data()

        @contextlib.contextmanager
        def assert_loads(vars=None):
            if vars is None:
                vars = expected
            with self.roundtrip(expected) as actual:
                for k, v in actual.variables.items():
                    # IndexVariables are eagerly loaded into memory
                    assert v._in_memory == (k in actual.dims)
                yield actual
                for k, v in actual.variables.items():
                    if k in vars:
                        assert v._in_memory
                assert_identical(expected, actual)

        with pytest.raises(AssertionError):
            # make sure the contextmanager works!
>           with assert_loads() as ds:

/testbed/xarray/tests/test_backends.py:406: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:394: in assert_loads
    with self.roundtrip(expected) as actual:
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_dataset_compute</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d6f50>

    def test_dataset_compute(self) -> None:
        expected = create_test_data()

>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:423: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_pickle</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d6bc0>

    def test_pickle(self) -> None:
        expected = Dataset({"foo": ("x", [42])})
>       with self.roundtrip(expected, allow_cleanup_failure=ON_WINDOWS) as roundtripped:

/testbed/xarray/tests/test_backends.py:441: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_pickle_dataarray</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d6b60>

    @pytest.mark.filterwarnings("ignore:deallocating CachingFileManager")
    def test_pickle_dataarray(self) -> None:
        expected = Dataset({"foo": ("x", [42])})
>       with self.roundtrip(expected, allow_cleanup_failure=ON_WINDOWS) as roundtripped:

/testbed/xarray/tests/test_backends.py:451: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_None_variable</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d65c0>

    @pytest.mark.filterwarnings("ignore:deallocating CachingFileManager")
    def test_roundtrip_None_variable(self) -> None:
        expected = Dataset({None: (("x", "y"), [[0, 1], [2, 3]])})
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:476: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_object_dtype</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d64a0>

    def test_roundtrip_object_dtype(self) -> None:
        floats = np.array([0.0, 0.0, 1.0, 2.0, 3.0], dtype=object)
        floats_nans = np.array([np.nan, np.nan, 1.0, 2.0, 3.0], dtype=object)
        bytes_ = np.array([b"ab", b"cdef", b"g"], dtype=object)
        bytes_nans = np.array([b"ab", b"cdef", np.nan], dtype=object)
        strings = np.array(["ab", "cdef", "g"], dtype=object)
        strings_nans = np.array(["ab", "cdef", np.nan], dtype=object)
        all_nans = np.array([np.nan, np.nan], dtype=object)
        original = Dataset(
            {
                "floats": ("a", floats),
                "floats_nans": ("a", floats_nans),
                "bytes": ("b", bytes_),
                "bytes_nans": ("b", bytes_nans),
                "strings": ("b", strings),
                "strings_nans": ("b", strings_nans),
                "all_nans": ("c", all_nans),
                "nan": ([], np.nan),
            }
        )
        expected = original.copy(deep=True)
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:500: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_string_data</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d6170>

    def test_roundtrip_string_data(self) -> None:
        expected = Dataset({"x": ("t", ["ab", "cdef"])})
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:516: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_string_encoded_characters</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d6050>

    def test_roundtrip_string_encoded_characters(self) -> None:
        expected = Dataset({"x": ("t", ["ab", "cdef"])})
        expected["x"].encoding["dtype"] = "S1"
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:522: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_numpy_datetime_data</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d5f60>

    def test_roundtrip_numpy_datetime_data(self) -> None:
        times = pd.to_datetime(["2000-01-01", "2000-01-02", "NaT"], unit="ns")
        expected = Dataset({"t": ("t", times), "t0": times[0]})
        kwargs = {"encoding": {"t0": {"units": "days since 1950-01-01"}}}
>       with self.roundtrip(expected, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:535: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_cftime_datetime_data</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d5cf0>

    @requires_cftime
    def test_roundtrip_cftime_datetime_data(self) -> None:
        from xarray.tests.test_coding_times import _all_cftime_date_types

        date_types = _all_cftime_date_types()
        for date_type in date_types.values():
            times = [date_type(1, 1, 1), date_type(1, 1, 2)]
            expected = Dataset({"t": ("t", times), "t0": times[0]})
            kwargs = {"encoding": {"t0": {"units": "days since 0001-01-01"}}}
            expected_decoded_t = np.array(times)
            expected_decoded_t0 = np.array([date_type(1, 1, 1)])
            expected_calendar = times[0].calendar

            with warnings.catch_warnings():
                if expected_calendar in {"proleptic_gregorian", "standard"}:
                    warnings.filterwarnings("ignore", "Unable to decode time axis")

>               with self.roundtrip(expected, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:556: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_timedelta_data</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d5840>

    def test_roundtrip_timedelta_data(self) -> None:
        time_deltas = pd.to_timedelta(["1h", "2h", "NaT"])  # type: ignore[arg-type]  #https://github.com/pandas-dev/pandas-stubs/issues/956
        expected = Dataset({"td": ("td", time_deltas), "td0": time_deltas[0]})
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:573: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_float64_data</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d5660>

    def test_roundtrip_float64_data(self) -> None:
        expected = Dataset({"x": ("y", np.array([1.0, 2.0, np.pi], dtype="float64"))})
>       with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:578: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_example_1_netcdf</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d53c0>

    def test_roundtrip_example_1_netcdf(self) -> None:
        with open_example_dataset("example_1.nc") as expected:
>           with self.roundtrip(expected) as actual:

/testbed/xarray/tests/test_backends.py:583: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:257: in set_dimension
    self.ds.dimensions[name] = None
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_coordinates</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b7413910>

    def test_roundtrip_coordinates(self) -> None:
        original = Dataset(
            {"foo": ("x", [0, 1])}, {"x": [2, 3], "y": ("a", [42]), "z": ("x", [4, 5])}
        )

>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:595: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_global_coordinates</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d5fc0>

    def test_roundtrip_global_coordinates(self) -> None:
        original = Dataset(
            {"foo": ("x", [0, 1])}, {"x": [2, 3], "y": ("a", [42]), "z": ("x", [4, 5])}
        )
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:610: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_boolean_dtype</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d7190>

    def test_roundtrip_boolean_dtype(self) -> None:
        original = create_boolean_data()
        assert original["x"].dtype == "bool"
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_orthogonal_indexing</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d5330>

    def test_orthogonal_indexing(self) -> None:
        in_memory = create_test_data()
>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_vectorized_indexing</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d4f40>

    def test_vectorized_indexing(self) -> None:
        in_memory = create_test_data()
>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:658: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_vectorized_indexing_negative_step</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d5090>

    def test_vectorized_indexing_negative_step(self) -> None:
        # use dask explicitly when present
        open_kwargs: dict[str, Any] | None
        if has_dask:
            open_kwargs = {"chunks": {}}
        else:
            open_kwargs = None
        in_memory = create_test_data()

        def multiple_indexing(indexers):
            # make sure a sequence of lazy indexings certainly works.
            with self.roundtrip(in_memory, open_kwargs=open_kwargs) as on_disk:
                actual = on_disk["var3"]
                expected = in_memory["var3"]
                for ind in indexers:
                    actual = actual.isel(ind)
                    expected = expected.isel(ind)
                    # make sure the array is not yet loaded into memory
                    assert not actual.variable._in_memory
                assert_identical(expected, actual.load())

        # with negative step slice.
        indexers = [
            {
                "dim1": DataArray([[0, 7], [2, 6], [3, 5]], dims=["a", "b"]),
                "dim3": slice(-1, 1, -1),
            }
        ]
>       multiple_indexing(indexers)

/testbed/xarray/tests/test_backends.py:748: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/tests/test_backends.py:731: in multiple_indexing
    with self.roundtrip(in_memory, open_kwargs=open_kwargs) as on_disk:
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_outer_indexing_reversed</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d4bb0>

    def test_outer_indexing_reversed(self) -> None:
        # regression test for GH6560
        ds = xr.Dataset(
            {"z": (("t", "p", "y", "x"), np.ones((1, 1, 31, 40)))},
        )

>       with self.roundtrip(ds) as on_disk:

/testbed/xarray/tests/test_backends.py:765: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_isel_dataarray</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d47f0>

    def test_isel_dataarray(self) -> None:
        # Make sure isel works lazily. GH:issue:1688
        in_memory = create_test_data()
>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:772: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_array_type_after_indexing</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d4640>

    def test_array_type_after_indexing(self) -> None:
        in_memory = create_test_data()
>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:799: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_dropna</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d4280>

    def test_dropna(self) -> None:
        # regression test for GH:issue:1694
        a = np.random.randn(4, 3)
        a[1, 1] = np.nan
        in_memory = xr.Dataset(
            {"a": (("y", "x"), a)}, coords={"y": np.arange(4), "x": np.arange(3)}
        )

        assert_identical(
            in_memory.dropna(dim="x"), in_memory.isel(x=slice(None, None, 2))
        )

>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:824: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_ondisk_after_print</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d4130>

    def test_ondisk_after_print(self) -> None:
        """Make sure print does not load file into memory"""
        in_memory = create_test_data()
>       with self.roundtrip(in_memory) as on_disk:

/testbed/xarray/tests/test_backends.py:833: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_bytes_with_fill_value</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c2ec0>

    def test_roundtrip_bytes_with_fill_value(self) -> None:
        values = np.array([b"ab", b"cdef", np.nan], dtype=object)
        encoding = {"_FillValue": b"X", "dtype": "S1"}
        original = Dataset({"x": ("t", values, {}, encoding)})
        expected = original.copy(deep=True)
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:844: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_empty_vlen_string_array</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69eb7f0>

    def test_roundtrip_empty_vlen_string_array(self) -> None:
        # checks preserving vlen dtype for empty arrays GH7862
        dtype = create_vlen_dtype(str)
        original = Dataset({"a": np.array([], dtype=dtype)})
        assert check_vlen_dtype(original["a"].dtype) is str
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:867: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_mask_and_scale[dtype0-create_unsigned_masked_scaled_data-create_encoded_unsigned_masked_scaled_data]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b6a1baf0>
decoded_fn = <function create_unsigned_masked_scaled_data at 0x7f42b692ac20>
encoded_fn = <function create_encoded_unsigned_masked_scaled_data at 0x7f42b692acb0>
dtype = dtype('float64')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_mask_and_scale[dtype0-create_signed_masked_scaled_data-create_encoded_signed_masked_scaled_data]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b7412170>
decoded_fn = <function create_signed_masked_scaled_data at 0x7f42b692ae60>
encoded_fn = <function create_encoded_signed_masked_scaled_data at 0x7f42b692aef0>
dtype = dtype('float64')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_mask_and_scale[dtype0-create_masked_and_scaled_data-create_encoded_masked_and_scaled_data]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b7411b40>
decoded_fn = <function create_masked_and_scaled_data at 0x7f42b692ab00>
encoded_fn = <function create_encoded_masked_and_scaled_data at 0x7f42b692ab90>
dtype = dtype('float64')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_mask_and_scale[dtype1-create_unsigned_masked_scaled_data-create_encoded_unsigned_masked_scaled_data]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b74117b0>
decoded_fn = <function create_unsigned_masked_scaled_data at 0x7f42b692ac20>
encoded_fn = <function create_encoded_unsigned_masked_scaled_data at 0x7f42b692acb0>
dtype = dtype('float32')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_mask_and_scale[dtype1-create_signed_masked_scaled_data-create_encoded_signed_masked_scaled_data]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b7411180>
decoded_fn = <function create_signed_masked_scaled_data at 0x7f42b692ae60>
encoded_fn = <function create_encoded_signed_masked_scaled_data at 0x7f42b692aef0>
dtype = dtype('float32')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_mask_and_scale[dtype1-create_masked_and_scaled_data-create_encoded_masked_and_scaled_data]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c2bf0>
decoded_fn = <function create_masked_and_scaled_data at 0x7f42b692ab00>
encoded_fn = <function create_encoded_masked_and_scaled_data at 0x7f42b692ab90>
dtype = dtype('float32')

    @pytest.mark.parametrize(
        "decoded_fn, encoded_fn",
        [
            (
                create_unsigned_masked_scaled_data,
                create_encoded_unsigned_masked_scaled_data,
            ),
            pytest.param(
                create_bad_unsigned_masked_scaled_data,
                create_bad_encoded_unsigned_masked_scaled_data,
                marks=pytest.mark.xfail(reason="Bad _Unsigned attribute."),
            ),
            (
                create_signed_masked_scaled_data,
                create_encoded_signed_masked_scaled_data,
            ),
            (create_masked_and_scaled_data, create_encoded_masked_and_scaled_data),
        ],
    )
    @pytest.mark.parametrize("dtype", [np.dtype("float64"), np.dtype("float32")])
    def test_roundtrip_mask_and_scale(self, decoded_fn, encoded_fn, dtype) -> None:
        if hasattr(self, "zarr_version") and dtype == np.float32:
            pytest.skip("float32 will be treated as float64 in zarr")
        decoded = decoded_fn(dtype)
        encoded = encoded_fn(dtype)
>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:902: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_distributed.py::test_dask_distributed_netcdf_roundtrip[h5netcdf-NETCDF4]</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

loop = <tornado.platform.asyncio.AsyncIOMainLoop object at 0x77d409d7ef80>
tmp_netcdf_filename = '/tmp/pytest-of-root/pytest-0/popen-gw1/test_dask_distributed_netcdf_r3/testfile.nc'
engine = 'h5netcdf', nc_format = 'NETCDF4'

    @pytest.mark.parametrize("engine,nc_format", ENGINES_AND_FORMATS)
    def test_dask_distributed_netcdf_roundtrip(
        loop, tmp_netcdf_filename, engine, nc_format
    ):
        if engine not in ENGINES:
            pytest.skip("engine not available")

        chunks = {"dim1": 4, "dim2": 3, "dim3": 6}

        with cluster() as (s, [a, b]):
            with Client(s["address"], loop=loop):
                original = create_test_data().chunk(chunks)

                if engine == "scipy":
                    with pytest.raises(NotImplementedError):
                        original.to_netcdf(
                            tmp_netcdf_filename, engine=engine, format=nc_format
                        )
                    return

>               original.to_netcdf(tmp_netcdf_filename, engine=engine, format=nc_format)

/testbed/xarray/tests/test_distributed.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_unsigned[fillvalue0]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c3790>
fillvalue = np.int8(-1)

    @pytest.mark.parametrize("fillvalue", [np.int8(-1), np.uint8(255), -1, 255])
    def test_roundtrip_unsigned(self, fillvalue):
        # regression/numpy2 test for
        encoding = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
            "dtype": "i1",
        }
        x = np.array([0, 1, 127, 128, 254, np.nan], dtype=np.float32)
        decoded = Dataset({"x": ("t", x, {}, encoding)})

        attributes = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
        }
        # Create unsigned data corresponding to [0, 1, 127, 128, 255] unsigned
        sb = np.asarray([0, 1, 127, -128, -2, -1], dtype="i1")
        encoded = Dataset({"x": ("t", sb, attributes)})

>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:947: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_unsigned[fillvalue1]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c3ac0>
fillvalue = np.uint8(255)

    @pytest.mark.parametrize("fillvalue", [np.int8(-1), np.uint8(255), -1, 255])
    def test_roundtrip_unsigned(self, fillvalue):
        # regression/numpy2 test for
        encoding = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
            "dtype": "i1",
        }
        x = np.array([0, 1, 127, 128, 254, np.nan], dtype=np.float32)
        decoded = Dataset({"x": ("t", x, {}, encoding)})

        attributes = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
        }
        # Create unsigned data corresponding to [0, 1, 127, 128, 255] unsigned
        sb = np.asarray([0, 1, 127, -128, -2, -1], dtype="i1")
        encoded = Dataset({"x": ("t", sb, attributes)})

>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:947: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_unsigned[-1]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c4640>
fillvalue = -1

    @pytest.mark.parametrize("fillvalue", [np.int8(-1), np.uint8(255), -1, 255])
    def test_roundtrip_unsigned(self, fillvalue):
        # regression/numpy2 test for
        encoding = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
            "dtype": "i1",
        }
        x = np.array([0, 1, 127, 128, 254, np.nan], dtype=np.float32)
        decoded = Dataset({"x": ("t", x, {}, encoding)})

        attributes = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
        }
        # Create unsigned data corresponding to [0, 1, 127, 128, 255] unsigned
        sb = np.asarray([0, 1, 127, -128, -2, -1], dtype="i1")
        encoded = Dataset({"x": ("t", sb, attributes)})

>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:947: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_unsigned[255]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c5a50>
fillvalue = 255

    @pytest.mark.parametrize("fillvalue", [np.int8(-1), np.uint8(255), -1, 255])
    def test_roundtrip_unsigned(self, fillvalue):
        # regression/numpy2 test for
        encoding = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
            "dtype": "i1",
        }
        x = np.array([0, 1, 127, 128, 254, np.nan], dtype=np.float32)
        decoded = Dataset({"x": ("t", x, {}, encoding)})

        attributes = {
            "_FillValue": fillvalue,
            "_Unsigned": "true",
        }
        # Create unsigned data corresponding to [0, 1, 127, 128, 255] unsigned
        sb = np.asarray([0, 1, 127, -128, -2, -1], dtype="i1")
        encoded = Dataset({"x": ("t", sb, attributes)})

>       with self.roundtrip(decoded) as actual:

/testbed/xarray/tests/test_backends.py:947: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_coordinate_variables_after_dataset_roundtrip</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b7412230>

    def test_coordinate_variables_after_dataset_roundtrip(self) -> None:
        original = self._create_cf_dataset()
>       with self.roundtrip(original, open_kwargs={"decode_coords": "all"}) as actual:

/testbed/xarray/tests/test_backends.py:1023: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_grid_mapping_and_bounds_are_coordinates_after_dataarray_roundtrip</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b74124a0>

    def test_grid_mapping_and_bounds_are_coordinates_after_dataarray_roundtrip(
        self,
    ) -> None:
        original = self._create_cf_dataset()
        # The DataArray roundtrip should have the same warnings as the
        # Dataset, but we already tested for those, so just go for the
        # new warnings.  It would appear that there is no way to tell
        # pytest "This warning and also this warning should both be
        # present".
        # xarray/tests/test_conventions.py::TestCFEncodedDataStore
        # needs the to_dataset. The other backends should be fine
        # without it.
        with pytest.warns(
            UserWarning,
            match=(
                r"Variable\(s\) referenced in bounds not in variables: "
                r"\['l(at|ong)itude_bnds'\]"
            ),
        ):
>           with self.roundtrip(
                original["variable"].to_dataset(), open_kwargs={"decode_coords": "all"}
            ) as actual:

/testbed/xarray/tests/test_backends.py:1055: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError

During handling of the above exception, another exception occurred:

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b74124a0>

    def test_grid_mapping_and_bounds_are_coordinates_after_dataarray_roundtrip(
        self,
    ) -> None:
        original = self._create_cf_dataset()
        # The DataArray roundtrip should have the same warnings as the
        # Dataset, but we already tested for those, so just go for the
        # new warnings.  It would appear that there is no way to tell
        # pytest "This warning and also this warning should both be
        # present".
        # xarray/tests/test_conventions.py::TestCFEncodedDataStore
        # needs the to_dataset. The other backends should be fine
        # without it.
>       with pytest.warns(
            UserWarning,
            match=(
                r"Variable\(s\) referenced in bounds not in variables: "
                r"\['l(at|ong)itude_bnds'\]"
            ),
        ):
E       Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.
E        Emitted warnings: [].

/testbed/xarray/tests/test_backends.py:1048: Failed
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_coordinates_encoding</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b7412980>

    def test_coordinates_encoding(self) -> None:
        def equals_latlon(obj):
            return obj == "lat lon" or obj == "lon lat"

        original = Dataset(
            {"temp": ("x", [0, 1]), "precip": ("x", [0, -1])},
            {"lat": ("x", [2, 3]), "lon": ("x", [4, 5])},
        )
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:1079: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_endian</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b7412bf0>

    def test_roundtrip_endian(self) -> None:
        ds = Dataset(
            {
                "x": np.arange(3, 10, dtype=">i2"),
                "y": np.arange(3, 20, dtype="<i4"),
                "z": np.arange(3, 30, dtype="=i8"),
                "w": ("x", np.arange(3, 10, dtype=float)),
            }
        )

>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_encoding_kwarg</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b74130d0>

    def test_encoding_kwarg(self) -> None:
        ds = Dataset({"x": ("y", np.arange(10.0))})

        kwargs: dict[str, Any] = dict(encoding={"x": {"dtype": "f4"}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1152: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_encoding_kwarg_dates</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b7413340>

    def test_encoding_kwarg_dates(self) -> None:
        ds = Dataset({"t": pd.date_range("2000-01-01", periods=3)})
        units = "days since 1900-01-01"
        kwargs = dict(encoding={"t": {"units": units}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_encoding_kwarg_fixed_width_string</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b74135b0>

    def test_encoding_kwarg_fixed_width_string(self) -> None:
        # regression test for GH2149
        for strings in [[b"foo", b"bar", b"baz"], ["foo", "bar", "baz"]]:
            ds = Dataset({"x": strings})
            kwargs = dict(encoding={"x": {"dtype": "S1"}})
>           with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1186: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_default_fill_value</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b7413820>

    def test_default_fill_value(self) -> None:
        # Test default encoding for float:
        ds = Dataset({"x": ("y", np.arange(10.0))})
        kwargs = dict(encoding={"x": {"dtype": "f4"}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1194: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_explicitly_omit_fill_value</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b7413a90>

    def test_explicitly_omit_fill_value(self) -> None:
        ds = Dataset({"x": ("y", [np.pi, -np.pi])})
        ds.x.encoding["_FillValue"] = None
>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1216: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_explicitly_omit_fill_value_via_encoding_kwarg</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b7413d00>

    def test_explicitly_omit_fill_value_via_encoding_kwarg(self) -> None:
        ds = Dataset({"x": ("y", [np.pi, -np.pi])})
        kwargs = dict(encoding={"x": {"_FillValue": None}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1222: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_explicitly_omit_fill_value_in_coord</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b7413f70>

    def test_explicitly_omit_fill_value_in_coord(self) -> None:
        ds = Dataset({"x": ("y", [np.pi, -np.pi])}, coords={"y": [0.0, 1.0]})
        ds.y.encoding["_FillValue"] = None
>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1229: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_explicitly_omit_fill_value_in_coord_via_encoding_kwarg</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d7c70>

    def test_explicitly_omit_fill_value_in_coord_via_encoding_kwarg(self) -> None:
        ds = Dataset({"x": ("y", [np.pi, -np.pi])}, coords={"y": [0.0, 1.0]})
        kwargs = dict(encoding={"y": {"_FillValue": None}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1235: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_encoding_same_dtype</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d7e80>

    def test_encoding_same_dtype(self) -> None:
        ds = Dataset({"x": ("y", np.arange(10.0, dtype="f4"))})
        kwargs = dict(encoding={"x": {"dtype": "f4"}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1242: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_append_write</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b7413850>

    def test_append_write(self) -> None:
        # regression for GH1215
        data = create_test_data()
>       with self.roundtrip_append(data) as actual:

/testbed/xarray/tests/test_backends.py:1251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:330: in roundtrip_append
    self.save(data[[key]], path, mode=mode, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_append_overwrite_values</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b7412f50>

    def test_append_overwrite_values(self) -> None:
        # regression for GH1215
        data = create_test_data()
        with create_tmp_file(allow_cleanup_failure=False) as tmp_file:
>           self.save(data, tmp_file, mode="w")

/testbed/xarray/tests/test_backends.py:1258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_append_with_invalid_dim_raises</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b7412380>

    def test_append_with_invalid_dim_raises(self) -> None:
        data = create_test_data()
        with create_tmp_file(allow_cleanup_failure=False) as tmp_file:
>           self.save(data, tmp_file, mode="w")

/testbed/xarray/tests/test_backends.py:1268: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_multiindex_not_implemented</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b73d7b80>

    def test_multiindex_not_implemented(self) -> None:
        ds = Dataset(coords={"y": ("x", [1, 2]), "z": ("x", ["a", "b"])}).set_index(
            x=["y", "z"]
        )
        with pytest.raises(NotImplementedError, match=r"MultiIndex"):
            with self.roundtrip(ds):
                pass

        # regression GH8628 (can serialize reset multi-index level coordinates)
        ds_reset = ds.reset_index("x")
>       with self.roundtrip(ds_reset) as actual:

/testbed/xarray/tests/test_backends.py:1286: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_refresh_from_disk</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c3130>

    @pytest.mark.skipif(
        ON_WINDOWS, reason="Windows does not allow modifying open files"
    )
    def test_refresh_from_disk(self) -> None:
        # regression test for https://github.com/pydata/xarray/issues/4862

        with create_tmp_file() as example_1_path:
            with create_tmp_file() as example_1_modified_path:
                with open_example_dataset("example_1.nc") as example_1:
>                   self.save(example_1, example_1_path)

/testbed/xarray/tests/test_backends.py:1302: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:257: in set_dimension
    self.ds.dimensions[name] = None
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_open_group</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c7460>

    def test_open_group(self) -> None:
        # Create a netCDF file with a dataset stored within a group
        with create_tmp_file() as tmp_file:
            with nc4.Dataset(tmp_file, "w") as rootgrp:
                foogrp = rootgrp.createGroup("foo")
                ds = foogrp
                ds.createDimension("time", size=10)
                x = np.arange(10)
                ds.createVariable("x", np.int32, dimensions=("time",))
                ds.variables["x"][:] = x

            expected = Dataset()
            expected["x"] = ("time", x)

            # check equivalent ways to specify group
            for group in "foo", "/foo", "foo/", "/foo/":
>               with self.open(tmp_file, group=group) as actual:

/testbed/xarray/tests/test_backends.py:1374: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:342: in open
    with open_dataset(path, engine=self.engine, **kwargs) as ds:
/testbed/xarray/backends/api.py:588: in open_dataset
    backend_ds = backend.open_dataset(
/testbed/xarray/backends/h5netcdf_.py:418: in open_dataset
    ds = store_entrypoint.open_dataset(
/testbed/xarray/backends/store.py:43: in open_dataset
    vars, attrs = filename_or_obj.load()
/testbed/xarray/backends/common.py:221: in load
    (_decode_variable_name(k), v) for k, v in self.get_variables().items()
/testbed/xarray/backends/h5netcdf_.py:237: in get_variables
    return FrozenDict(
/testbed/xarray/core/utils.py:436: in FrozenDict
    return Frozen(dict(*args, **kwargs))
/testbed/xarray/backends/h5netcdf_.py:238: in <genexpr>
    (k, self.open_store_variable(k, v)) for k, v in self.ds.variables.items()
/testbed/xarray/backends/h5netcdf_.py:200: in open_store_variable
    dimensions = var.dimensions
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:260: in dimensions
    self._dimensions = self._lookup_dimensions()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:154: in _lookup_dimensions
    if _unlabeled_dimension_mix(self._h5ds) == "labeled":
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in _unlabeled_dimension_mix
    dimset = set([len(j) for j in dimlist])
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in <listcomp>
    dimset = set([len(j) for j in dimlist])
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
/testbed/.venv/lib/python3.10/site-packages/h5py/_hl/dims.py:60: in __len__
    return h5ds.get_num_scales(self._id, self._dimension)
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:72: in h5py.h5ds.get_num_scales
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSget_num_scales (return value <0)

h5py/defs.pyx:4461: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_open_subgroup</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c73a0>

    def test_open_subgroup(self) -> None:
        # Create a netCDF file with a dataset stored within a group within a
        # group
        with create_tmp_file() as tmp_file:
            rootgrp = nc4.Dataset(tmp_file, "w")
            foogrp = rootgrp.createGroup("foo")
            bargrp = foogrp.createGroup("bar")
            ds = bargrp
            ds.createDimension("time", size=10)
            x = np.arange(10)
            ds.createVariable("x", np.int32, dimensions=("time",))
            ds.variables["x"][:] = x
            rootgrp.close()

            expected = Dataset()
            expected["x"] = ("time", x)

            # check equivalent ways to specify group
            for group in "foo/bar", "/foo/bar", "foo/bar/", "/foo/bar/":
>               with self.open(tmp_file, group=group) as actual:

/testbed/xarray/tests/test_backends.py:1402: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:342: in open
    with open_dataset(path, engine=self.engine, **kwargs) as ds:
/testbed/xarray/backends/api.py:588: in open_dataset
    backend_ds = backend.open_dataset(
/testbed/xarray/backends/h5netcdf_.py:418: in open_dataset
    ds = store_entrypoint.open_dataset(
/testbed/xarray/backends/store.py:43: in open_dataset
    vars, attrs = filename_or_obj.load()
/testbed/xarray/backends/common.py:221: in load
    (_decode_variable_name(k), v) for k, v in self.get_variables().items()
/testbed/xarray/backends/h5netcdf_.py:237: in get_variables
    return FrozenDict(
/testbed/xarray/core/utils.py:436: in FrozenDict
    return Frozen(dict(*args, **kwargs))
/testbed/xarray/backends/h5netcdf_.py:238: in <genexpr>
    (k, self.open_store_variable(k, v)) for k, v in self.ds.variables.items()
/testbed/xarray/backends/h5netcdf_.py:200: in open_store_variable
    dimensions = var.dimensions
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:260: in dimensions
    self._dimensions = self._lookup_dimensions()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:154: in _lookup_dimensions
    if _unlabeled_dimension_mix(self._h5ds) == "labeled":
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in _unlabeled_dimension_mix
    dimset = set([len(j) for j in dimlist])
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in <listcomp>
    dimset = set([len(j) for j in dimlist])
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
/testbed/.venv/lib/python3.10/site-packages/h5py/_hl/dims.py:60: in __len__
    return h5ds.get_num_scales(self._id, self._dimension)
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:72: in h5py.h5ds.get_num_scales
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSget_num_scales (return value <0)

h5py/defs.pyx:4461: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_write_groups</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c70a0>

    def test_write_groups(self) -> None:
        data1 = create_test_data()
        data2 = data1 * 2
        with create_tmp_file() as tmp_file:
>           self.save(data1, tmp_file, group="data/1")

/testbed/xarray/tests/test_backends.py:1409: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_encoding_kwarg_vlen_string[input_strings0-True]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c6ce0>
input_strings = [b'foo', b'bar', b'baz'], is_bytes = True

    @pytest.mark.parametrize(
        "input_strings, is_bytes",
        [
            ([b"foo", b"bar", b"baz"], True),
            (["foo", "bar", "baz"], False),
            (["foó", "bár", "baź"], False),
        ],
    )
    def test_encoding_kwarg_vlen_string(
        self, input_strings: list[str], is_bytes: bool
    ) -> None:
        original = Dataset({"x": input_strings})

        expected_string = ["foo", "bar", "baz"] if is_bytes else input_strings
        expected = Dataset({"x": expected_string})
        kwargs = dict(encoding={"x": {"dtype": str}})
>       with self.roundtrip(original, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1432: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_encoding_kwarg_vlen_string[input_strings1-False]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c6b90>
input_strings = ['foo', 'bar', 'baz'], is_bytes = False

    @pytest.mark.parametrize(
        "input_strings, is_bytes",
        [
            ([b"foo", b"bar", b"baz"], True),
            (["foo", "bar", "baz"], False),
            (["foó", "bár", "baź"], False),
        ],
    )
    def test_encoding_kwarg_vlen_string(
        self, input_strings: list[str], is_bytes: bool
    ) -> None:
        original = Dataset({"x": input_strings})

        expected_string = ["foo", "bar", "baz"] if is_bytes else input_strings
        expected = Dataset({"x": expected_string})
        kwargs = dict(encoding={"x": {"dtype": str}})
>       with self.roundtrip(original, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1432: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_encoding_kwarg_vlen_string[input_strings2-False]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c6950>
input_strings = ['foó', 'bár', 'baź'], is_bytes = False

    @pytest.mark.parametrize(
        "input_strings, is_bytes",
        [
            ([b"foo", b"bar", b"baz"], True),
            (["foo", "bar", "baz"], False),
            (["foó", "bár", "baź"], False),
        ],
    )
    def test_encoding_kwarg_vlen_string(
        self, input_strings: list[str], is_bytes: bool
    ) -> None:
        original = Dataset({"x": input_strings})

        expected_string = ["foo", "bar", "baz"] if is_bytes else input_strings
        expected = Dataset({"x": expected_string})
        kwargs = dict(encoding={"x": {"dtype": str}})
>       with self.roundtrip(original, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1432: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_string_with_fill_value_vlen[XXX]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c6650>
fill_value = 'XXX'

    @pytest.mark.parametrize("fill_value", ["XXX", "", "bár"])
    def test_roundtrip_string_with_fill_value_vlen(self, fill_value: str) -> None:
        values = np.array(["ab", "cdef", np.nan], dtype=object)
        expected = Dataset({"x": ("t", values)})

        original = Dataset({"x": ("t", values, {}, {"_FillValue": fill_value})})
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:1443: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_string_with_fill_value_vlen[]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c6590>
fill_value = ''

    @pytest.mark.parametrize("fill_value", ["XXX", "", "bár"])
    def test_roundtrip_string_with_fill_value_vlen(self, fill_value: str) -> None:
        values = np.array(["ab", "cdef", np.nan], dtype=object)
        expected = Dataset({"x": ("t", values)})

        original = Dataset({"x": ("t", values, {}, {"_FillValue": fill_value})})
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:1443: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_string_with_fill_value_vlen[b\xe1r]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c6380>
fill_value = 'bár'

    @pytest.mark.parametrize("fill_value", ["XXX", "", "bár"])
    def test_roundtrip_string_with_fill_value_vlen(self, fill_value: str) -> None:
        values = np.array(["ab", "cdef", np.nan], dtype=object)
        expected = Dataset({"x": ("t", values)})

        original = Dataset({"x": ("t", values, {}, {"_FillValue": fill_value})})
>       with self.roundtrip(original) as actual:

/testbed/xarray/tests/test_backends.py:1443: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_roundtrip_character_array</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c60e0>

    def test_roundtrip_character_array(self) -> None:
        with create_tmp_file() as tmp_file:
            values = np.array([["a", "b", "c"], ["d", "e", "f"]], dtype="S")

            with nc4.Dataset(tmp_file, mode="w") as nc:
                nc.createDimension("x", 2)
                nc.createDimension("string3", 3)
                v = nc.createVariable("x", np.dtype("S1"), ("x", "string3"))
                v[:] = values

            values = np.array(["abc", "def"], dtype="S")
            expected = Dataset({"x": ("x", values)})
            with open_dataset(tmp_file) as actual:
                assert_identical(expected, actual)
                # regression test for #157
>               with self.roundtrip(actual) as roundtripped:

/testbed/xarray/tests/test_backends.py:1465: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_distributed.py::test_dask_distributed_read_netcdf_integration_test[h5netcdf-NETCDF4]</pre></summary><pre>
[gw1] linux -- Python 3.10.12 /testbed/.venv/bin/python3

loop = <tornado.platform.asyncio.AsyncIOMainLoop object at 0x77d414a83190>
tmp_netcdf_filename = '/tmp/pytest-of-root/pytest-0/popen-gw1/test_dask_distributed_read_net3/testfile.nc'
engine = 'h5netcdf', nc_format = 'NETCDF4'

    @pytest.mark.parametrize("engine,nc_format", ENGINES_AND_FORMATS)
    def test_dask_distributed_read_netcdf_integration_test(
        loop, tmp_netcdf_filename, engine, nc_format
    ):
        if engine not in ENGINES:
            pytest.skip("engine not available")

        chunks = {"dim1": 4, "dim2": 3, "dim3": 6}

        with cluster() as (s, [a, b]):
            with Client(s["address"], loop=loop):
                original = create_test_data()
>               original.to_netcdf(tmp_netcdf_filename, engine=engine, format=nc_format)

/testbed/xarray/tests/test_distributed.py:207: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_default_to_char_arrays</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c5de0>

    def test_default_to_char_arrays(self) -> None:
        data = Dataset({"x": np.array(["foo", "zzzz"], dtype="S")})
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1470: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_dump_encodings</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c57b0>

    def test_dump_encodings(self) -> None:
        # regression test for #709
        ds = Dataset({"x": ("y", np.arange(10.0))})
        kwargs = dict(encoding={"x": {"zlib": True}})
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1505: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_compression_encoding_legacy</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c5150>

    def test_compression_encoding_legacy(self) -> None:
        data = create_test_data()
        data["var2"].encoding.update(
            {
                "zlib": True,
                "chunksizes": (5, 5),
                "fletcher32": True,
                "shuffle": True,
                "original_shape": data.var2.shape,
            }
        )
>       with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:1538: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_encoding_kwarg_compression</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c4e80>

    def test_encoding_kwarg_compression(self) -> None:
        ds = Dataset({"x": np.arange(10.0)})
        encoding = dict(
            dtype="f4",
            zlib=True,
            complevel=9,
            fletcher32=True,
            chunksizes=(5,),
            shuffle=True,
        )
        kwargs = dict(encoding=dict(x=encoding))

>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_keep_chunksizes_if_no_original_shape</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c4b20>

    def test_keep_chunksizes_if_no_original_shape(self) -> None:
        ds = Dataset({"x": [1, 2, 3]})
        chunksizes = (2,)
        ds.variables["x"].encoding = {"chunksizes": chunksizes}

>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1575: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_preferred_chunks_is_present</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c47f0>

    def test_preferred_chunks_is_present(self) -> None:
        ds = Dataset({"x": [1, 2, 3]})
        chunksizes = (2,)
        ds.variables["x"].encoding = {"chunksizes": chunksizes}

>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1586: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_auto_chunking_is_based_on_disk_chunk_sizes</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69ccd90>

    @requires_dask
    def test_auto_chunking_is_based_on_disk_chunk_sizes(self) -> None:
        x_size = y_size = 1000
        y_chunksize = y_size
        x_chunksize = 10

        with dask.config.set({"array.chunk-size": "100KiB"}):
>           with self.chunked_roundtrip(
                (1, y_size, x_size),
                (1, y_chunksize, x_chunksize),
                open_kwargs={"chunks": "auto"},
            ) as ds:

/testbed/xarray/tests/test_backends.py:1596: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:1641: in chunked_roundtrip
    with self.roundtrip(dataset, open_kwargs=open_kwargs) as ds:
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_base_chunking_uses_disk_chunk_sizes</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c5270>

    @requires_dask
    def test_base_chunking_uses_disk_chunk_sizes(self) -> None:
        x_size = y_size = 1000
        y_chunksize = y_size
        x_chunksize = 10

>       with self.chunked_roundtrip(
            (1, y_size, x_size),
            (1, y_chunksize, x_chunksize),
            open_kwargs={"chunks": {}},
        ) as ds:

/testbed/xarray/tests/test_backends.py:1612: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:1641: in chunked_roundtrip
    with self.roundtrip(dataset, open_kwargs=open_kwargs) as ds:
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_preferred_chunks_are_disk_chunk_sizes</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c6080>

    def test_preferred_chunks_are_disk_chunk_sizes(self) -> None:
        x_size = y_size = 1000
        y_chunksize = y_size
        x_chunksize = 10

>       with self.chunked_roundtrip(
            (1, y_size, x_size), (1, y_chunksize, x_chunksize)
        ) as ds:

/testbed/xarray/tests/test_backends.py:1649: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:1641: in chunked_roundtrip
    with self.roundtrip(dataset, open_kwargs=open_kwargs) as ds:
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_encoding_chunksizes_unlimited</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c7280>

    def test_encoding_chunksizes_unlimited(self) -> None:
        # regression test for GH1225
        ds = Dataset({"x": [1, 2, 3], "y": ("x", [2, 3, 4])})
        ds.variables["x"].encoding = {
            "zlib": False,
            "shuffle": False,
            "complevel": 0,
            "fletcher32": False,
            "contiguous": False,
            "chunksizes": (2**20,),
            "original_shape": (3,),
        }
>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:1670: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_raise_on_forward_slashes_in_names</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c3bb0>

    def test_raise_on_forward_slashes_in_names(self) -> None:
        # test for forward slash in variable names and dimensions
        # see GH 7943
        data_vars: list[dict[str, Any]] = [
            {"PASS/FAIL": (["PASSFAIL"], np.array([0]))},
            {"PASS/FAIL": np.array([0])},
            {"PASSFAIL": (["PASS/FAIL"], np.array([0]))},
        ]
        for dv in data_vars:
            ds = Dataset(data_vars=dv)
            with pytest.raises(ValueError, match="Forward slashes '/' are not allowed"):
>               with self.roundtrip(ds):

/testbed/xarray/tests/test_backends.py:1746: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_encoding_enum__no_fill_value</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c3910>

    @requires_netCDF4
    def test_encoding_enum__no_fill_value(self):
        with create_tmp_file() as tmp_file:
            cloud_type_dict = {"clear": 0, "cloudy": 1}
            with nc4.Dataset(tmp_file, mode="w") as nc:
                nc.createDimension("time", size=2)
                cloud_type = nc.createEnumType("u1", "cloud_type", cloud_type_dict)
                v = nc.createVariable(
                    "clouds",
                    cloud_type,
                    "time",
                    fill_value=None,
                )
                v[:] = 1
            with open_dataset(tmp_file) as original:
                save_kwargs = {}
                if self.engine == "h5netcdf":
                    save_kwargs["invalid_netcdf"] = True
>               with self.roundtrip(original, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1767: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_encoding_enum__multiple_variable_with_enum</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c3640>

    @requires_netCDF4
    def test_encoding_enum__multiple_variable_with_enum(self):
        with create_tmp_file() as tmp_file:
            cloud_type_dict = {"clear": 0, "cloudy": 1, "missing": 255}
            with nc4.Dataset(tmp_file, mode="w") as nc:
                nc.createDimension("time", size=2)
                cloud_type = nc.createEnumType("u1", "cloud_type", cloud_type_dict)
                nc.createVariable(
                    "clouds",
                    cloud_type,
                    "time",
                    fill_value=255,
                )
                nc.createVariable(
                    "tifa",
                    cloud_type,
                    "time",
                    fill_value=255,
                )
            with open_dataset(tmp_file) as original:
                save_kwargs = {}
                if self.engine == "h5netcdf":
                    save_kwargs["invalid_netcdf"] = True
>               with self.roundtrip(original, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:1803: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_complex</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69ccb80>

    def test_complex(self) -> None:
        expected = Dataset({"x": ("y", np.ones(5) + 1j * np.ones(5))})
        save_kwargs = {"invalid_netcdf": True}
        with pytest.warns(UserWarning, match="You are writing invalid netcdf features"):
>           with self.roundtrip(expected, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:3599: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_complex_error[None]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69cc790>
invalid_netcdf = None

    @pytest.mark.parametrize("invalid_netcdf", [None, False])
    def test_complex_error(self, invalid_netcdf) -> None:
        import h5netcdf

        expected = Dataset({"x": ("y", np.ones(5) + 1j * np.ones(5))})
        save_kwargs = {"invalid_netcdf": invalid_netcdf}
        with pytest.raises(
            h5netcdf.CompatibilityError, match="are not a supported NetCDF feature"
        ):
>           with self.roundtrip(expected, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:3611: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_complex_error[False]</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69cc6d0>
invalid_netcdf = False

    @pytest.mark.parametrize("invalid_netcdf", [None, False])
    def test_complex_error(self, invalid_netcdf) -> None:
        import h5netcdf

        expected = Dataset({"x": ("y", np.ones(5) + 1j * np.ones(5))})
        save_kwargs = {"invalid_netcdf": invalid_netcdf}
        with pytest.raises(
            h5netcdf.CompatibilityError, match="are not a supported NetCDF feature"
        ):
>           with self.roundtrip(expected, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:3611: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_numpy_bool_</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69cc340>

    def test_numpy_bool_(self) -> None:
        # h5netcdf loads booleans as numpy.bool_, this type needs to be supported
        # when writing invalid_netcdf datasets in order to support a roundtrip
        expected = Dataset({"x": ("y", np.ones(5), {"numpy_bool": np.bool_(True)})})
        save_kwargs = {"invalid_netcdf": True}
        with pytest.warns(UserWarning, match="You are writing invalid netcdf features"):
>           with self.roundtrip(expected, save_kwargs=save_kwargs) as actual:

/testbed/xarray/tests/test_backends.py:3620: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_cross_engine_read_write_netcdf4</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69cc070>

    def test_cross_engine_read_write_netcdf4(self) -> None:
        # Drop dim3, because its labels include strings. These appear to be
        # not properly read with python-netCDF4, which converts them into
        # unicode instead of leaving them as bytes.
        data = create_test_data().drop_vars("dim3")
        data.attrs["foo"] = "bar"
        valid_engines: list[T_NetcdfEngine] = ["netcdf4", "h5netcdf"]
        for write_engine in valid_engines:
            with create_tmp_file() as tmp_file:
                data.to_netcdf(tmp_file, engine=write_engine)
                for read_engine in valid_engines:
>                   with open_dataset(tmp_file, engine=read_engine) as actual:

/testbed/xarray/tests/test_backends.py:3634: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/backends/api.py:588: in open_dataset
    backend_ds = backend.open_dataset(
/testbed/xarray/backends/h5netcdf_.py:418: in open_dataset
    ds = store_entrypoint.open_dataset(
/testbed/xarray/backends/store.py:43: in open_dataset
    vars, attrs = filename_or_obj.load()
/testbed/xarray/backends/common.py:221: in load
    (_decode_variable_name(k), v) for k, v in self.get_variables().items()
/testbed/xarray/backends/h5netcdf_.py:237: in get_variables
    return FrozenDict(
/testbed/xarray/core/utils.py:436: in FrozenDict
    return Frozen(dict(*args, **kwargs))
/testbed/xarray/backends/h5netcdf_.py:238: in <genexpr>
    (k, self.open_store_variable(k, v)) for k, v in self.ds.variables.items()
/testbed/xarray/backends/h5netcdf_.py:200: in open_store_variable
    dimensions = var.dimensions
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:260: in dimensions
    self._dimensions = self._lookup_dimensions()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:154: in _lookup_dimensions
    if _unlabeled_dimension_mix(self._h5ds) == "labeled":
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in _unlabeled_dimension_mix
    dimset = set([len(j) for j in dimlist])
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in <listcomp>
    dimset = set([len(j) for j in dimlist])
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
/testbed/.venv/lib/python3.10/site-packages/h5py/_hl/dims.py:60: in __len__
    return h5ds.get_num_scales(self._id, self._dimension)
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:72: in h5py.h5ds.get_num_scales
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSget_num_scales (return value <0)

h5py/defs.pyx:4461: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_encoding_unlimited_dims</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c79d0>

    def test_encoding_unlimited_dims(self) -> None:
        ds = Dataset({"x": ("y", np.arange(10.0))})
>       with self.roundtrip(ds, save_kwargs=dict(unlimited_dims=["y"])) as actual:

/testbed/xarray/tests/test_backends.py:3647: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:257: in set_dimension
    self.ds.dimensions[name] = None
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_compression_encoding_h5py</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69c7610>

    def test_compression_encoding_h5py(self) -> None:
        ENCODINGS: tuple[tuple[dict[str, Any], dict[str, Any]], ...] = (
            # h5py style compression with gzip codec will be converted to
            # NetCDF4-Python style on round-trip
            (
                {"compression": "gzip", "compression_opts": 9},
                {"zlib": True, "complevel": 9},
            ),
            # What can't be expressed in NetCDF4-Python style is
            # round-tripped unaltered
            (
                {"compression": "lzf", "compression_opts": None},
                {"compression": "lzf", "compression_opts": None},
            ),
            # If both styles are used together, h5py format takes precedence
            (
                {
                    "compression": "lzf",
                    "compression_opts": None,
                    "zlib": True,
                    "complevel": 9,
                },
                {"compression": "lzf", "compression_opts": None},
            ),
        )

        for compr_in, compr_out in ENCODINGS:
            data = create_test_data()
            compr_common = {
                "chunksizes": (5, 5),
                "fletcher32": True,
                "shuffle": True,
                "original_shape": data.var2.shape,
            }
            data["var2"].encoding.update(compr_in)
            data["var2"].encoding.update(compr_common)
            compr_out.update(compr_common)
            data["scalar"] = ("scalar_dim", np.array([2.0]))
            data["scalar"] = data["scalar"][0]
>           with self.roundtrip(data) as actual:

/testbed/xarray/tests/test_backends.py:3694: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_compression_check_encoding_h5py</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69cc9a0>

    def test_compression_check_encoding_h5py(self) -> None:
        """When mismatched h5py and NetCDF4-Python encodings are expressed
        in to_netcdf(encoding=...), must raise ValueError
        """
        data = Dataset({"x": ("y", np.arange(10.0))})
        # Compatible encodings are graciously supported
        with create_tmp_file() as tmp_file:
>           data.to_netcdf(
                tmp_file,
                engine="h5netcdf",
                encoding={
                    "x": {
                        "compression": "gzip",
                        "zlib": True,
                        "compression_opts": 6,
                        "complevel": 6,
                    }
                },
            )

/testbed/xarray/tests/test_backends.py:3705: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_dump_encodings_h5py</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69cd6f0>

    def test_dump_encodings_h5py(self) -> None:
        # regression test for #709
        ds = Dataset({"x": ("y", np.arange(10.0))})

        kwargs = {"encoding": {"x": {"compression": "gzip", "compression_opts": 9}}}
>       with self.roundtrip(ds, save_kwargs=kwargs) as actual:

/testbed/xarray/tests/test_backends.py:3754: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::TestH5NetCDFViaDaskData::test_write_inconsistent_chunks</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends.TestH5NetCDFViaDaskData object at 0x7f42b69ccdc0>

    def test_write_inconsistent_chunks(self) -> None:
        # Construct two variables with the same dimensions, but different
        # chunk sizes.
        x = da.zeros((100, 100), dtype="f4", chunks=(50, 100))
        x = DataArray(data=x, dims=("lat", "lon"), name="x")
        x.encoding["chunksizes"] = (50, 100)
        x.encoding["original_shape"] = (100, 100)
        y = da.ones((100, 100), dtype="f4", chunks=(100, 50))
        y = DataArray(data=y, dims=("lat", "lon"), name="y")
        y.encoding["chunksizes"] = (100, 50)
        y.encoding["original_shape"] = (100, 100)
        # Put them both into the same dataset
        ds = Dataset({"x": x, "y": y})
>       with self.roundtrip(ds) as actual:

/testbed/xarray/tests/test_backends.py:3919: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:3897: in roundtrip
    with TestH5NetCDFData.roundtrip(
/usr/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/testbed/xarray/tests/test_backends.py:315: in roundtrip
    self.save(data, path, **save_kwargs)
/testbed/xarray/tests/test_backends.py:336: in save
    return dataset.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::test_source_encoding_always_present_with_fsspec</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

    @requires_h5netcdf
    @requires_fsspec
    def test_source_encoding_always_present_with_fsspec() -> None:
        import fsspec

        rnddata = np.random.randn(10)
        original = Dataset({"foo": ("x", rnddata)})
        with create_tmp_file() as tmp:
            original.to_netcdf(tmp)

            fs = fsspec.filesystem("file")
>           with fs.open(tmp) as f, open_dataset(f) as ds:

/testbed/xarray/tests/test_backends.py:5194: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/backends/api.py:588: in open_dataset
    backend_ds = backend.open_dataset(
/testbed/xarray/backends/h5netcdf_.py:418: in open_dataset
    ds = store_entrypoint.open_dataset(
/testbed/xarray/backends/store.py:43: in open_dataset
    vars, attrs = filename_or_obj.load()
/testbed/xarray/backends/common.py:221: in load
    (_decode_variable_name(k), v) for k, v in self.get_variables().items()
/testbed/xarray/backends/h5netcdf_.py:237: in get_variables
    return FrozenDict(
/testbed/xarray/core/utils.py:436: in FrozenDict
    return Frozen(dict(*args, **kwargs))
/testbed/xarray/backends/h5netcdf_.py:238: in <genexpr>
    (k, self.open_store_variable(k, v)) for k, v in self.ds.variables.items()
/testbed/xarray/backends/h5netcdf_.py:200: in open_store_variable
    dimensions = var.dimensions
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:260: in dimensions
    self._dimensions = self._lookup_dimensions()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:154: in _lookup_dimensions
    if _unlabeled_dimension_mix(self._h5ds) == "labeled":
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in _unlabeled_dimension_mix
    dimset = set([len(j) for j in dimlist])
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in <listcomp>
    dimset = set([len(j) for j in dimlist])
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
/testbed/.venv/lib/python3.10/site-packages/h5py/_hl/dims.py:60: in __len__
    return h5ds.get_num_scales(self._id, self._dimension)
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:72: in h5py.h5ds.get_num_scales
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSget_num_scales (return value <0)

h5py/defs.pyx:4461: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::test_load_single_value_h5netcdf</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw3/test_load_single_value_h5netcd0')

    @requires_h5netcdf
    @requires_netCDF4
    def test_load_single_value_h5netcdf(tmp_path: Path) -> None:
        """Test that numeric single-element vector attributes are handled fine.

        At present (h5netcdf v0.8.1), the h5netcdf exposes single-valued numeric variable
        attributes as arrays of length 1, as opposed to scalars for the NetCDF4
        backend.  This was leading to a ValueError upon loading a single value from
        a file, see #4471.  Test that loading causes no failure.
        """
        ds = xr.Dataset(
            {
                "test": xr.DataArray(
                    np.array([0]), dims=("x",), attrs={"scale_factor": 1, "add_offset": 0}
                )
            }
        )
        ds.to_netcdf(tmp_path / "test.nc")
>       with xr.open_dataset(tmp_path / "test.nc", engine="h5netcdf") as ds2:

/testbed/xarray/tests/test_backends.py:5478: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/backends/api.py:588: in open_dataset
    backend_ds = backend.open_dataset(
/testbed/xarray/backends/h5netcdf_.py:418: in open_dataset
    ds = store_entrypoint.open_dataset(
/testbed/xarray/backends/store.py:43: in open_dataset
    vars, attrs = filename_or_obj.load()
/testbed/xarray/backends/common.py:221: in load
    (_decode_variable_name(k), v) for k, v in self.get_variables().items()
/testbed/xarray/backends/h5netcdf_.py:237: in get_variables
    return FrozenDict(
/testbed/xarray/core/utils.py:436: in FrozenDict
    return Frozen(dict(*args, **kwargs))
/testbed/xarray/backends/h5netcdf_.py:238: in <genexpr>
    (k, self.open_store_variable(k, v)) for k, v in self.ds.variables.items()
/testbed/xarray/backends/h5netcdf_.py:200: in open_store_variable
    dimensions = var.dimensions
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:260: in dimensions
    self._dimensions = self._lookup_dimensions()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:154: in _lookup_dimensions
    if _unlabeled_dimension_mix(self._h5ds) == "labeled":
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in _unlabeled_dimension_mix
    dimset = set([len(j) for j in dimlist])
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/core.py:453: in <listcomp>
    dimset = set([len(j) for j in dimlist])
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
/testbed/.venv/lib/python3.10/site-packages/h5py/_hl/dims.py:60: in __len__
    return h5ds.get_num_scales(self._id, self._dimension)
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:72: in h5py.h5ds.get_num_scales
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSget_num_scales (return value <0)

h5py/defs.pyx:4461: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends.py::test_h5netcdf_entrypoint</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

tmp_path = PosixPath('/tmp/pytest-of-root/pytest-0/popen-gw3/test_h5netcdf_entrypoint0')

    @requires_h5netcdf
    def test_h5netcdf_entrypoint(tmp_path: Path) -> None:
        entrypoint = H5netcdfBackendEntrypoint()
        ds = create_test_data()

        path = tmp_path / "foo"
>       ds.to_netcdf(path, engine="h5netcdf")

/testbed/xarray/tests/test_backends.py:5614: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends_datatree.py::TestH5NetCDFDatatreeIO::test_to_netcdf</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends_datatree.TestH5NetCDFDatatreeIO object at 0x7f42b741f760>
tmpdir = local('/tmp/pytest-of-root/pytest-0/popen-gw3/test_to_netcdf1')
simple_datatree = <xarray.DataTree>
Group: /
│   Dimensions:  (y: 3, x: 2)
│   Dimensions without coordinates: y, x
│   Data variables:
...     a        (x) int64 16B 2 3
│   │       b        (x) float64 16B 0.1 0.2
│   └── Group: /set2/set1
└── Group: /set3

    def test_to_netcdf(self, tmpdir, simple_datatree):
        filepath = tmpdir / "test.nc"
        original_dt = simple_datatree
>       original_dt.to_netcdf(filepath, engine=self.engine)

/testbed/xarray/tests/test_backends_datatree.py:27: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/core/datatree.py:1553: in to_netcdf
    _datatree_to_netcdf(
/testbed/xarray/core/datatree_io.py:93: in _datatree_to_netcdf
    ds.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends_datatree.py::TestH5NetCDFDatatreeIO::test_to_netcdf_inherited_coords</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends_datatree.TestH5NetCDFDatatreeIO object at 0x7f42b741f9a0>
tmpdir = local('/tmp/pytest-of-root/pytest-0/popen-gw3/test_to_netcdf_inherited_coord1')

    def test_to_netcdf_inherited_coords(self, tmpdir):
        filepath = tmpdir / "test.nc"
        original_dt = DataTree.from_dict(
            {
                "/": xr.Dataset({"a": (("x",), [1, 2])}, coords={"x": [3, 4]}),
                "/sub": xr.Dataset({"b": (("x",), [5, 6])}),
            }
        )
>       original_dt.to_netcdf(filepath, engine=self.engine)

/testbed/xarray/tests/test_backends_datatree.py:40: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/core/datatree.py:1553: in to_netcdf
    _datatree_to_netcdf(
/testbed/xarray/core/datatree_io.py:93: in _datatree_to_netcdf
    ds.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>

<details><summary> <pre>xarray/tests/test_backends_datatree.py::TestH5NetCDFDatatreeIO::test_netcdf_encoding</pre></summary><pre>
[gw3] linux -- Python 3.10.12 /testbed/.venv/bin/python3

self = <xarray.tests.test_backends_datatree.TestH5NetCDFDatatreeIO object at 0x7f42b741fc40>
tmpdir = local('/tmp/pytest-of-root/pytest-0/popen-gw3/test_netcdf_encoding1')
simple_datatree = <xarray.DataTree>
Group: /
│   Dimensions:  (y: 3, x: 2)
│   Dimensions without coordinates: y, x
│   Data variables:
...     a        (x) int64 16B 2 3
│   │       b        (x) float64 16B 0.1 0.2
│   └── Group: /set2/set1
└── Group: /set3

    def test_netcdf_encoding(self, tmpdir, simple_datatree):
        filepath = tmpdir / "test.nc"
        original_dt = simple_datatree

        # add compression
        comp = dict(zlib=True, complevel=9)
        enc = {"/set2": {var: comp for var in original_dt["/set2"].ds.data_vars}}

>       original_dt.to_netcdf(filepath, encoding=enc, engine=self.engine)

/testbed/xarray/tests/test_backends_datatree.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/testbed/xarray/core/datatree.py:1553: in to_netcdf
    _datatree_to_netcdf(
/testbed/xarray/core/datatree_io.py:93: in _datatree_to_netcdf
    ds.to_netcdf(
/testbed/xarray/core/dataset.py:2329: in to_netcdf
    return to_netcdf(  # type: ignore  # mypy cannot resolve the overloads:(
/testbed/xarray/backends/api.py:1360: in to_netcdf
    dump_to_store(
/testbed/xarray/backends/api.py:1407: in dump_to_store
    store.store(variables, attrs, check_encoding, writer, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:366: in store
    self.set_dimensions(variables, unlimited_dims=unlimited_dims)
/testbed/xarray/backends/common.py:443: in set_dimensions
    self.set_dimension(dim, length, is_unlimited)
/testbed/xarray/backends/h5netcdf_.py:260: in set_dimension
    self.ds.dimensions[name] = length
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:28: in __setitem__
    self._objects[name] = Dimension(self._group, name, size, create_h5ds=True)
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:89: in __init__
    self._create_scale()
/testbed/.venv/lib/python3.10/site-packages/h5netcdf/dimensions.py:209: in _create_scale
    if not self._root._h5py.h5ds.is_scale(self._h5ds.id):
h5py/_objects.pyx:54: in h5py._objects.with_phil.wrapper
    ???
h5py/_objects.pyx:55: in h5py._objects.with_phil.wrapper
    ???
h5py/h5ds.pyx:35: in h5py.h5ds.is_scale
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   RuntimeError: Unspecified error in H5DSis_scale (return value <0)

h5py/defs.pyx:4505: RuntimeError
</pre>
</details>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.07f07601.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.56dfad97.min.js"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../javascripts/tablesort.js"></script>
      
        <script src="../javascripts/button_select.js"></script>
      
    
  </body>
</html>